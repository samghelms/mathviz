{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error with: data/1601/1601.06597.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import read_file, tokenize_latex\n",
    "df = read_file(\"data/1601/*\")\n",
    "df[\"processed\"] = df[\"text\"].apply(lambda x: tokenize_latex(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-04 18:38:51,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-11-04 18:38:52,751 : INFO : adding document #10000 to Dictionary(19919 unique tokens: [u'\\\\xi\\\\leq', u'4E+6F', u'0.000004', u'20\\\\%', u'i|S']...)\n",
      "2017-11-04 18:38:53,360 : INFO : adding document #20000 to Dictionary(33619 unique tokens: [u'\\\\xi\\\\leq', u'eF', u'q-1', u'q-2', u'+i+1']...)\n",
      "2017-11-04 18:38:54,097 : INFO : adding document #30000 to Dictionary(45883 unique tokens: [u'\\\\xi\\\\leq', u'eF', u'-5AB\\\\sqrt', u'JN2', u'q-1']...)\n",
      "2017-11-04 18:38:54,908 : INFO : adding document #40000 to Dictionary(57458 unique tokens: [u'\\\\xi\\\\leq', u'eF', u'-5AB\\\\sqrt', u'JN2', u'q-1']...)\n",
      "2017-11-04 18:38:55,629 : INFO : adding document #50000 to Dictionary(70025 unique tokens: [u'\\\\xi\\\\leq', u'eF', u'homomorphism', u'-5AB\\\\sqrt', u'JN2']...)\n",
      "2017-11-04 18:38:56,006 : INFO : built Dictionary(76641 unique tokens: [u'\\\\xi\\\\leq', u'eF', u'homomorphism', u'-5AB\\\\sqrt', u'JN2']...) from 56379 documents (total 3723199 corpus positions)\n",
      "2017-11-04 18:38:58,634 : INFO : storing corpus in Matrix Market format to /tmp/equations.mm\n",
      "2017-11-04 18:38:58,644 : INFO : saving sparse matrix to /tmp/equations.mm\n",
      "2017-11-04 18:38:58,645 : INFO : PROGRESS: saving document #0\n",
      "2017-11-04 18:38:58,786 : INFO : PROGRESS: saving document #1000\n",
      "2017-11-04 18:38:58,922 : INFO : PROGRESS: saving document #2000\n",
      "2017-11-04 18:38:59,092 : INFO : PROGRESS: saving document #3000\n",
      "2017-11-04 18:38:59,243 : INFO : PROGRESS: saving document #4000\n",
      "2017-11-04 18:38:59,380 : INFO : PROGRESS: saving document #5000\n",
      "2017-11-04 18:38:59,512 : INFO : PROGRESS: saving document #6000\n",
      "2017-11-04 18:38:59,648 : INFO : PROGRESS: saving document #7000\n",
      "2017-11-04 18:38:59,785 : INFO : PROGRESS: saving document #8000\n",
      "2017-11-04 18:38:59,921 : INFO : PROGRESS: saving document #9000\n",
      "2017-11-04 18:39:00,071 : INFO : PROGRESS: saving document #10000\n",
      "2017-11-04 18:39:00,216 : INFO : PROGRESS: saving document #11000\n",
      "2017-11-04 18:39:00,364 : INFO : PROGRESS: saving document #12000\n",
      "2017-11-04 18:39:00,520 : INFO : PROGRESS: saving document #13000\n",
      "2017-11-04 18:39:00,676 : INFO : PROGRESS: saving document #14000\n",
      "2017-11-04 18:39:00,840 : INFO : PROGRESS: saving document #15000\n",
      "2017-11-04 18:39:00,972 : INFO : PROGRESS: saving document #16000\n",
      "2017-11-04 18:39:01,103 : INFO : PROGRESS: saving document #17000\n",
      "2017-11-04 18:39:01,254 : INFO : PROGRESS: saving document #18000\n",
      "2017-11-04 18:39:01,383 : INFO : PROGRESS: saving document #19000\n",
      "2017-11-04 18:39:01,521 : INFO : PROGRESS: saving document #20000\n",
      "2017-11-04 18:39:01,669 : INFO : PROGRESS: saving document #21000\n",
      "2017-11-04 18:39:01,803 : INFO : PROGRESS: saving document #22000\n",
      "2017-11-04 18:39:01,937 : INFO : PROGRESS: saving document #23000\n",
      "2017-11-04 18:39:02,091 : INFO : PROGRESS: saving document #24000\n",
      "2017-11-04 18:39:02,244 : INFO : PROGRESS: saving document #25000\n",
      "2017-11-04 18:39:02,402 : INFO : PROGRESS: saving document #26000\n",
      "2017-11-04 18:39:02,546 : INFO : PROGRESS: saving document #27000\n",
      "2017-11-04 18:39:02,688 : INFO : PROGRESS: saving document #28000\n",
      "2017-11-04 18:39:02,840 : INFO : PROGRESS: saving document #29000\n",
      "2017-11-04 18:39:02,985 : INFO : PROGRESS: saving document #30000\n",
      "2017-11-04 18:39:03,151 : INFO : PROGRESS: saving document #31000\n",
      "2017-11-04 18:39:03,322 : INFO : PROGRESS: saving document #32000\n",
      "2017-11-04 18:39:03,487 : INFO : PROGRESS: saving document #33000\n",
      "2017-11-04 18:39:03,631 : INFO : PROGRESS: saving document #34000\n",
      "2017-11-04 18:39:03,770 : INFO : PROGRESS: saving document #35000\n",
      "2017-11-04 18:39:03,910 : INFO : PROGRESS: saving document #36000\n",
      "2017-11-04 18:39:04,059 : INFO : PROGRESS: saving document #37000\n",
      "2017-11-04 18:39:04,212 : INFO : PROGRESS: saving document #38000\n",
      "2017-11-04 18:39:04,384 : INFO : PROGRESS: saving document #39000\n",
      "2017-11-04 18:39:04,524 : INFO : PROGRESS: saving document #40000\n",
      "2017-11-04 18:39:04,678 : INFO : PROGRESS: saving document #41000\n",
      "2017-11-04 18:39:04,827 : INFO : PROGRESS: saving document #42000\n",
      "2017-11-04 18:39:04,970 : INFO : PROGRESS: saving document #43000\n",
      "2017-11-04 18:39:05,112 : INFO : PROGRESS: saving document #44000\n",
      "2017-11-04 18:39:05,300 : INFO : PROGRESS: saving document #45000\n",
      "2017-11-04 18:39:05,466 : INFO : PROGRESS: saving document #46000\n",
      "2017-11-04 18:39:05,618 : INFO : PROGRESS: saving document #47000\n",
      "2017-11-04 18:39:05,756 : INFO : PROGRESS: saving document #48000\n",
      "2017-11-04 18:39:05,903 : INFO : PROGRESS: saving document #49000\n",
      "2017-11-04 18:39:06,053 : INFO : PROGRESS: saving document #50000\n",
      "2017-11-04 18:39:06,187 : INFO : PROGRESS: saving document #51000\n",
      "2017-11-04 18:39:06,334 : INFO : PROGRESS: saving document #52000\n",
      "2017-11-04 18:39:06,475 : INFO : PROGRESS: saving document #53000\n",
      "2017-11-04 18:39:06,607 : INFO : PROGRESS: saving document #54000\n",
      "2017-11-04 18:39:06,734 : INFO : PROGRESS: saving document #55000\n",
      "2017-11-04 18:39:06,866 : INFO : PROGRESS: saving document #56000\n",
      "2017-11-04 18:39:06,928 : INFO : saved 56379x76641 matrix, density=0.032% (1388440/4320942939)\n",
      "2017-11-04 18:39:06,937 : INFO : saving MmCorpus index to /tmp/equations.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(2, 1), (4, 1), (5, 1), (6, 3), (8, 1), (11, 3), (14, 1), (15, 3), (16, 4), (17, 3), (21, 2), (23, 6), (25, 6), (26, 1), (27, 1), (28, 1)], [(2, 1), (3, 1), (4, 1), (5, 1), (6, 5), (7, 1), (8, 2), (11, 3), (14, 1), (15, 2), (16, 3), (17, 5), (18, 1), (19, 4), (21, 2), (23, 7), (24, 1), (25, 7), (27, 2), (29, 1), (30, 1), (31, 1)], [(1, 1), (2, 1), (4, 1), (5, 1), (8, 1), (10, 1), (14, 1), (16, 2), (17, 1), (21, 2), (23, 8), (25, 8), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)], [(0, 1), (1, 1), (2, 1), (4, 3), (5, 3), (6, 1), (8, 1), (10, 1), (12, 3), (14, 1), (17, 2), (18, 2), (21, 2), (23, 8), (25, 8), (34, 1), (45, 1), (46, 1), (47, 2), (48, 2)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "equations = df[\"processed\"].tolist()\n",
    "dictionary = corpora.Dictionary(equations)\n",
    "\n",
    "corpus = [dictionary.doc2bow(eq) for eq in equations]\n",
    "corpora.MmCorpus.serialize('/tmp/equations.mm', corpus)\n",
    "# our vector space model\n",
    "print(corpus[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-04 18:42:11,930 : INFO : collecting document frequencies\n",
      "2017-11-04 18:42:11,932 : INFO : PROGRESS: processing document #0\n",
      "2017-11-04 18:42:12,041 : INFO : PROGRESS: processing document #10000\n",
      "2017-11-04 18:42:12,109 : INFO : PROGRESS: processing document #20000\n",
      "2017-11-04 18:42:12,179 : INFO : PROGRESS: processing document #30000\n",
      "2017-11-04 18:42:12,249 : INFO : PROGRESS: processing document #40000\n",
      "2017-11-04 18:42:12,316 : INFO : PROGRESS: processing document #50000\n",
      "2017-11-04 18:42:12,363 : INFO : calculating IDF weights for 56379 documents and 76640 features (1388440 matrix non-zeros)\n",
      "2017-11-04 18:42:12,424 : INFO : starting similarity index under index/\n",
      "2017-11-04 18:42:16,153 : INFO : PROGRESS: fresh_shard size=10000\n",
      "2017-11-04 18:42:19,429 : INFO : PROGRESS: fresh_shard size=20000\n",
      "2017-11-04 18:42:23,654 : INFO : PROGRESS: fresh_shard size=30000\n",
      "2017-11-04 18:42:24,704 : INFO : creating sparse index\n",
      "2017-11-04 18:42:24,704 : INFO : creating sparse matrix from corpus\n",
      "2017-11-04 18:42:24,705 : INFO : PROGRESS: at document #0/32768\n",
      "2017-11-04 18:42:25,559 : INFO : PROGRESS: at document #10000/32768\n",
      "2017-11-04 18:42:26,314 : INFO : PROGRESS: at document #20000/32768\n",
      "2017-11-04 18:42:27,043 : INFO : PROGRESS: at document #30000/32768\n",
      "2017-11-04 18:42:27,257 : INFO : created <32768x76641 sparse matrix of type '<type 'numpy.float32'>'\n",
      "\twith 804611 stored elements in Compressed Sparse Row format>\n",
      "2017-11-04 18:42:27,258 : INFO : creating sparse shard #0\n",
      "2017-11-04 18:42:27,259 : INFO : saving index shard to index/.0\n",
      "2017-11-04 18:42:27,260 : INFO : saving SparseMatrixSimilarity object under index/.0, separately None\n",
      "2017-11-04 18:42:27,311 : INFO : saved index/.0\n",
      "2017-11-04 18:42:27,314 : INFO : loading SparseMatrixSimilarity object from index/.0\n",
      "2017-11-04 18:42:27,329 : INFO : loaded index/.0\n",
      "2017-11-04 18:42:27,435 : INFO : PROGRESS: fresh_shard size=0\n",
      "2017-11-04 18:42:31,140 : INFO : PROGRESS: fresh_shard size=10000\n",
      "2017-11-04 18:42:34,565 : INFO : PROGRESS: fresh_shard size=20000\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "from gensim import similarities\n",
    "index = similarities.Similarity(\"index/\", corpus_tfidf, len(dictionary.keys()), num_best = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like it works\n",
    "sims = index[tfidf[corpus][10]] # perform a similarity query against the corpus\n",
    "sims = sorted(sims, key=lambda item: -item[1])\n",
    "\n",
    "# [df[\"text\"].tolist()[i[0]] for i in sims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mathviz_hopper.src.table",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a7b043a267fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmathviz_hopper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mathviz_hopper.src.table"
     ]
    }
   ],
   "source": [
    "from mathviz_hopper.src.table import Table \n",
    "t = Table(index)\n",
    "t.print_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post('http://localhost:8082', json={\"query_vec\": [(0, 1), (1, 1)]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
