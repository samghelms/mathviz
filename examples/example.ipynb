{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from notebooks.utils import read_file, tokenize_latex\n",
    "df = read_file(\"notebooks/data/1601/1601.00400.json\")\n",
    "df[\"processed\"] = df[\"text\"].apply(lambda x: tokenize_latex(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-28 14:12:20,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-11-28 14:12:20,768 : INFO : built Dictionary(50 unique tokens: [u'\\\\frac', u'0', u'Ls', u'1-Y', u'&+']...) from 4 documents (total 443 corpus positions)\n",
      "2017-11-28 14:12:20,770 : INFO : storing corpus in Matrix Market format to /tmp/equations.mm\n",
      "2017-11-28 14:12:20,772 : INFO : saving sparse matrix to /tmp/equations.mm\n",
      "2017-11-28 14:12:20,773 : INFO : PROGRESS: saving document #0\n",
      "2017-11-28 14:12:20,776 : INFO : saved 4x50 matrix, density=69.000% (138/200)\n",
      "2017-11-28 14:12:20,778 : INFO : saving MmCorpus index to /tmp/equations.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (2, 2), (3, 5), (4, 30), (5, 11), (6, 1), (8, 2), (9, 30), (10, 2), (11, 4), (12, 2), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 2), (20, 2), (21, 1), (22, 2), (23, 6), (24, 1), (25, 4), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 12), (40, 2), (41, 1), (42, 3), (43, 4), (44, 1), (45, 1), (46, 2)], [(0, 1), (2, 2), (3, 5), (4, 27), (5, 10), (6, 1), (8, 2), (9, 27), (10, 2), (11, 4), (12, 2), (13, 1), (14, 1), (15, 1), (17, 1), (18, 2), (19, 2), (21, 1), (22, 2), (23, 5), (24, 1), (25, 3), (26, 2), (27, 1), (28, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 10), (40, 2), (42, 3), (43, 4), (44, 1), (46, 2), (47, 1)], [(0, 1), (2, 2), (3, 5), (4, 23), (5, 8), (6, 1), (8, 2), (9, 23), (10, 2), (11, 2), (12, 2), (13, 1), (15, 1), (17, 1), (18, 2), (19, 2), (20, 1), (21, 1), (22, 2), (23, 4), (24, 1), (25, 3), (26, 2), (27, 1), (29, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 8), (41, 1), (42, 3), (43, 2), (45, 1), (48, 1), (49, 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "equations = df[\"processed\"].tolist()\n",
    "dictionary = corpora.Dictionary(equations)\n",
    "\n",
    "corpus = [dictionary.doc2bow(eq) for eq in equations]\n",
    "corpora.MmCorpus.serialize('/tmp/equations.mm', corpus)\n",
    "# our vector space model\n",
    "print(corpus[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-28 14:12:20,800 : INFO : collecting document frequencies\n",
      "2017-11-28 14:12:20,807 : INFO : PROGRESS: processing document #0\n",
      "2017-11-28 14:12:20,813 : INFO : calculating IDF weights for 4 documents and 49 features (138 matrix non-zeros)\n",
      "2017-11-28 14:12:20,816 : INFO : starting similarity index under notebooks/index/\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "from gensim import similarities\n",
    "index = similarities.Similarity(\"notebooks/index/\", corpus_tfidf, len(dictionary.keys()), num_best = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\"\".join(eq) for eq in df[\"processed\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_exp(exp):\n",
    "    exp = re.sub(\"\\\\\\\\begin{equation[^}]*}\",\"\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\end{equation[^}]*}\",\"\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\begin{split[^}]*}\",\"\\\\\\\\begin{aligned}\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\end{split[^}]*}\",\"\\\\\\\\end{aligned}\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\begin{gather[^}]*}\",\"\\\\\\\\begin{aligned}\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\end{gather[^}]*}\",\"\\\\\\\\end{aligned}\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\begin{align[^}]*}\",\"\\\\\\\\begin{aligned}\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\end{align[^}]*}\",\"\\\\\\\\end{aligned}\" ,exp, flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\label{[^}]*}\",\"\" ,exp , flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\\\\\n\", \"\",exp, flags=re.IGNORECASE)\n",
    "    exp = re.sub(\"\\\\$\", \"\",exp , flags=re.IGNORECASE)\n",
    "    return exp\n",
    "\n",
    "clean_docs = map(clean_exp, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\\\begin{aligned}w^{m}=Ls^{m}\\\\end{aligned}',\n",
       " u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}',\n",
       " u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}',\n",
       " u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    '''\n",
    "    The important thing here is that the labels on the data coincide with the labels on the columns.\n",
    "    '''\n",
    "    def __init__(self, index, docs, dictionary, tokenize_latex, cols):\n",
    "        self.index = index\n",
    "        self.docs = docs\n",
    "        self.dictionary = dictionary\n",
    "        self.tokenize_latex = tokenize_latex\n",
    "        self.columns = cols\n",
    "    def _convert_query(self, query):\n",
    "        query = self.dictionary.doc2bow(self.tokenize_latex(query))\n",
    "        sims = self.index[query]\n",
    "        neighbors = sorted(sims, key=lambda item: -item[1])\n",
    "        neighbors = {\"neighbors\":[{self.columns[0]: {\"data\": self.docs[n[0]], \"fmt\": \"math\"}, self.columns[1]: {\"data\": float(n[1])}} for n in neighbors]} if neighbors else {\"neighbors\": []}\n",
    "        return neighbors\n",
    "    def query(self, q):\n",
    "        return self._convert_query(q)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-28 14:12:20,985 : INFO : creating matrix with 4 documents and 50 features\n",
      "2017-11-28 14:12:20,988 : INFO : creating dense shard #0\n",
      "2017-11-28 14:12:20,989 : INFO : saving index shard to notebooks/index/.0\n",
      "2017-11-28 14:12:20,992 : INFO : saving MatrixSimilarity object under notebooks/index/.0, separately None\n",
      "2017-11-28 14:12:20,998 : INFO : saved notebooks/index/.0\n",
      "2017-11-28 14:12:21,000 : INFO : loading MatrixSimilarity object from notebooks/index/.0\n",
      "2017-11-28 14:12:21,002 : INFO : loaded notebooks/index/.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neighbors': [{'neighbor': {'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}',\n",
       "    'fmt': 'math'},\n",
       "   'similarity_score': {'data': 0.07059364020824432}},\n",
       "  {'neighbor': {'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}',\n",
       "    'fmt': 'math'},\n",
       "   'similarity_score': {'data': 0.05906001478433609}},\n",
       "  {'neighbor': {'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}',\n",
       "    'fmt': 'math'},\n",
       "   'similarity_score': {'data': 0.05068068951368332}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Query(index, clean_docs, dictionary, tokenize_latex, [\"neighbor\", \"similarity_score\"])\n",
    "q.query(\"\\\\frac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.13-dev server starting up (using MyWSGIRefServer())...\n",
      "Listening on http://localhost:8081/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1,shrink-to-fit=no\"><meta name=\"theme-color\" content=\"#000000\"><link rel=\"manifest\" href=\"./viz/manifest.json\"><link rel=\"stylesheet\" href=\"./viz/katex.css\"><title>React App</title><link href=\"./viz/static/css/main.2d3f6c1d.css\" rel=\"stylesheet\"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"></div><script type=\"text/javascript\" src=\"./viz/static/js/main.c8de8a8a.js\"></script></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mathviz_hopper.src.table import Table\n",
    "t = Table(q)\n",
    "t.print_ipython()\n",
    "\n",
    "# TODO: lambda function to convert each column\n",
    "# Schema:\n",
    "# also, enable non-autocomplete selections (the models should be able to handle this)\n",
    "# also, add a warning if the settings are still loading, and other notifications.\n",
    "# Data: [{Column A: {name: A, index: [], filter_func: lambda x : f(x)}} , {Column B: {name: B, index: [], filter_func: lambda x : f(x)}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neighbors': [{'similarity_score': {'data': 0.2762615382671356}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}'}}, {'similarity_score': {'data': 0.2758598029613495}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}'}}, {'similarity_score': {'data': 0.2687106728553772}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2017 14:12:21] \"POST /query HTTP/1.1\" 200 914\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.post('http://localhost:8081/query', json={\"query\": \"\\\\begin{equation}\\n\\\\Phi_{z}(L) = \\\\sum_{i=1}^{N} \\\\frac{1}{C_{i} \\\\times V_{\\\\rm max, i}} ,\\n\\\\label{EQ1}\\n\\\\end{equation}\\n\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'neighbors': [{u'neighbor': {u'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}',\n",
       "    u'fmt': u'math'},\n",
       "   u'similarity_score': {u'data': 0.2762615382671356}},\n",
       "  {u'neighbor': {u'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}',\n",
       "    u'fmt': u'math'},\n",
       "   u'similarity_score': {u'data': 0.2758598029613495}},\n",
       "  {u'neighbor': {u'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}',\n",
       "    u'fmt': u'math'},\n",
       "   u'similarity_score': {u'data': 0.2687106728553772}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2017 14:12:21] \"GET /settings HTTP/1.1\" 200 1007\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('http://localhost:8081/settings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'columns': [{u'Header': u'neighbor', u'accessor': u'neighbor'},\n",
       "  {u'Header': u'similarity_score', u'accessor': u'similarity_score'}],\n",
       " u'docs': {u'\\\\': {u'b': {u'e': {u'g': {u'i': {u'n': {u'{': {u'a': {u'l': {u'i': {u'g': {u'n': {u'e': {u'd': {u'}': {u'\\\\': {u'm': {u'i': {u'n': {u'_': {u'{': {},\n",
       "                      u'{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}': {u'full_word': 1},\n",
       "                      u'{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}': {u'full_word': 1},\n",
       "                      u'{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}': {u'full_word': 1}}}}}},\n",
       "                 u'w': {u'^': {u'{': {u'm': {u'}': {u'=': {},\n",
       "                      u'=Ls^{m}\\\\end{aligned}': {u'full_word': 1}}}}}}}}}}}}}}}}}}}}}},\n",
       " u'port': 8081}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def insert(st, trie):\n",
    "    i = 0\n",
    "    for s in st:\n",
    "        if s not in trie.keys(): \n",
    "            trie[s] = {}\n",
    "        if i == 20:\n",
    "            break\n",
    "        trie = trie[s]\n",
    "        i+=1\n",
    "        \n",
    "    if i == 20: \n",
    "        trie[st[i:]] = {}\n",
    "        trie = trie[st[i:]]\n",
    "    trie[\"full_word\"] = 1\n",
    "        \n",
    "    \n",
    "def construct_trie(list_of_str):\n",
    "    trie = {}\n",
    "    for st in list_of_str:\n",
    "        insert(st, trie)\n",
    "    return trie\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_trie = construct_trie(clean_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "opts = {\n",
    "    \"columns\": [\n",
    "            {\n",
    "                \"Header\": \"Word\",\n",
    "                \"accessor\": \"word\"\n",
    "            },\n",
    "            {\n",
    "                \"Header\": \"Similarity\",\n",
    "                \"accessor\": \"sim\"\n",
    "            }\n",
    "   ],\n",
    "    \"port\": \"8081\",\n",
    "    \"docs\": docs_trie\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2017 14:12:21] \"GET /settings HTTP/1.1\" 200 1007\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'mathviz_hopper/webpage/mathviz-js-components/public/settings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ec57b2304264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mathviz_hopper/webpage/mathviz-js-components/public/settings.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'mathviz_hopper/webpage/mathviz-js-components/public/settings.json'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neighbors': [{'similarity_score': {'data': 0.32032012939453125}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}\\\\\\\\\\\\end{aligned}'}}, {'similarity_score': {'data': 0.31747668981552124}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\mu\\\\sum_{k=1}^{K}\\\\sum_{g=1}^{G}\\\\|s_{k}^{g}\\\\|_{2}+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}'}}, {'similarity_score': {'data': 0.2810024917125702}, 'neighbor': {'fmt': 'math', 'data': u'\\\\begin{aligned}\\\\min_{L,S}\\\\sum_{m=1}^{M}\\\\sum_{i=1}^{N_{m}}&\\\\frac{1}{2}[max(0,1-Y_{m}^{i}(Ls^{m})^{T}X_{m}^{i})]^{2}\\\\\\\\&+\\\\gamma\\\\|L\\\\|_{1}+\\\\lambda\\\\|L\\\\|^{2}_{F}\\\\\\\\\\\\end{aligned}'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2017 14:12:44] \"POST /query HTTP/1.1\" 200 916\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"mathviz_hopper/webpage/mathviz-js-components/public/settings.json\", \"w+\") as f:\n",
    "    json.dump(opts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_exists(trie, word):\n",
    "    \n",
    "    for i, s in enumerate(word):        \n",
    "        if s in trie.keys(): \n",
    "            trie = trie[s]\n",
    "        else: return False\n",
    "            \n",
    "        if i == 19: \n",
    "            break\n",
    "            \n",
    "    if i == 19:\n",
    "        s = word[i+1:]\n",
    "        if s not in trie.keys(): return False\n",
    "        trie = trie[s]\n",
    "\n",
    "    return True if 'full_word' in trie.keys() else False\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_exists(trie, \"fdakfkajshdfjkahsdfkjhadfdfdfdffdfdsdjkfhaskj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [\"\".join(eq) for eq in df[\"processed\"].tolist()]\n",
    "docs_trie = construct_trie(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
