[{"file": "1601.07054.tex", "nexttext": "\n\nwith $n_1$ and $n_2$ the number of events associated to $p_1$ and $p_2$, and $ \\hat{p} = (n_1 p_1 + n_2 p_2) / (n_1 + n_2)$. The corresponding $p$-value can be obtained through a Gaussian cumulative distribution function.\n\n\nWe first test the proposed metric with synthetic data. Fig. \\ref{fig:distributions} presents the evolution of the $p$-value for two vectors $\\mathcal{B}$ and $\\mathcal{C}$, whose values are drawn from different distributions. Two situations are compared. First, a real $\\mathcal{B} \\rightarrow \\mathcal{C}$ causality, such that $c_i = c_i + \\gamma b_i^n$ ($n$ being the order of the coupling) - solid lines in Fig. \\ref{fig:distributions}. Second, a confounding effect in which $b_i = b_i + \\gamma a_i^n$ and $c_i = c_i + \\gamma a_i^n$ - dashed lines in Fig. \\ref{fig:distributions}. It can be appreciated that the $p$-values of real causalities drop to zero with small values of coupling constants; and that non-linear couplings perform better than linear ones.\nIn some cases, a confounding effect (especially when highly non-linear) can foul the metric and yield a low $p$-value - see, for instance, the cubic confounding coupling for a gamma distribution in Fig. \\ref{fig:distributions}. Such situations can easily be identified by comparing the $p$-values for $\\mathcal{B} \\rightarrow \\mathcal{C}$ and $\\mathcal{C} \\rightarrow \\mathcal{B}$: in the case of a true causality, which is by definition directed, the $p$-value should be small only for one of them. An example of this is depicted in Fig. \\ref{fig:confounding}, which shows the evolution of the $p$-values for a confounding effect (top panel) and a causality (bottom panel), for vectors of Gamma distributed values. Discriminating between true and spurious causalities only requires calculating the two opposite $p$-values, and checking whether they are both small.\n\n\\begin{figure}[!tb]\n\\centering\n\\includegraphics[width=0.40\\textwidth]{Fig03.pdf}\n\\caption{\\label{fig:confounding} Evolution of the $p$-value of the causality, when considering both $\\mathcal{B} \\rightarrow \\mathcal{C}$ and $\\mathcal{C} \\rightarrow \\mathcal{B}$ tests for a cubic coupling and for data drawn from a Gamma distribution (as in green lines of the first panel of Fig. \\ref{fig:distributions}. The top panel reports the results for a confounding effect, the bottom one for a true causality between $\\mathcal{B}$ and $\\mathcal{C}$.}\n\\end{figure}\n\n\n\\begin{figure}[!tb]\n\\centering\n\\includegraphics[width=0.40\\textwidth]{Fig04.pdf}\n\\caption{\\label{fig:length} Evolution of the $p$-value of the causality, for a triangular distribution, as a function of the number of values included in the input vectors. Black, red and green lines respectively correspond to linear, quadratic and cubic couplings. }\n\\end{figure}\n\nThe necessity of detecting extreme events introduces a drawback in the method, {\\it i.e.} the need of having a large set of input values to reach a stable statistics. This problem is explored in Fig. \\ref{fig:length}, which depicts the $p$-value obtained as a function of the number of input values. Depending on the kind of relation to be detected, between $2$ and $4$ thousand values are required.\n\n\\begin{figure}[!tb]\n\\centering\n\\includegraphics[width=0.40\\textwidth]{Fig05a.pdf}\n\\includegraphics[width=0.40\\textwidth]{Fig05b.pdf}\n\\caption{\\label{fig:kuramoto} (Top) Evolution of the $p$-value of the causality test between two Kuramoto oscillators, for different values of the coupling constant $\\gamma$. The solid black line and the dashed blue one respectively correspond to a cross-sectional and longitudinal study - see main text for details. (Bottom) $p$-value for two coupled R\\\"ossler oscillators as a function of the coupling constant $\\gamma$, for a linear (top graph) and cubic (bottom graph) coupling.}\n\\end{figure}\n\nOne of the advantages of the proposed metric is that it can be applied both to cross-sectional and longitudinal ({\\it i.e.} time evolving) data. Here we show such flexibility in the detection of the causality between two noisy Kuramoto oscillators \\cite{Kuramoto2012wo, Rodrigues2015bc}. Suppose two oscillators whose phases are defined as:\n\n\\begin{eqnarray}\n\t\\dot{ \\phi_{\\mathcal{B}} } = \\kappa_{\\mathcal{B}} + \\xi \\\\\n\t\\dot{ \\phi_{\\mathcal{C}} } = \\kappa_{\\mathcal{C}} + \\gamma sin( \\phi_{\\mathcal{B}} - \\phi_{\\mathcal{C}} ) + \\xi.\n\\end{eqnarray}\n\n$\\kappa$ is the natural frequency of each oscillator ($\\kappa_{\\mathcal{B}} \\neq \\kappa_{\\mathcal{C}}$), and $\\xi$ an external uniform noise source. The coupling constant $\\gamma$ defines the way the two oscillators interact, with independent dynamics for $\\gamma \\approx 0$, and a causality $\\phi_{\\mathcal{B}} \\rightarrow \\phi_{\\mathcal{C}}$ for $\\gamma > 0$.\nThe longitudinal causality can be detected by considering the time series created by $\\dot{ \\phi_{\\mathcal{B}} }$ and $\\dot{ \\phi_{\\mathcal{C}} }$, thus focusing on how abnormal {\\it jumps} in the phase of the oscillators is transmitted from the former to the latter. The $p$-value of the metric is represented in Fig. \\ref{fig:kuramoto} Top by the blue dashed line.\nThe equivalent cross-sectional analysis requires multiple realisations of the previous dynamics; for each one of them, one single pair of values $(\\dot{ \\phi_{\\mathcal{B}} }, \\dot{ \\phi_{\\mathcal{C}} })$ is extracted, corresponding to the largest variation of $\\phi_{\\mathcal{B}}$ (and thus, to the most extreme jump in the phase of the first oscillator). The evolution of the corresponding $p$-value is shown in Fig. \\ref{fig:kuramoto} Top by the black solid line.\nBoth the longitudinal and cross-sectional analyses yield similar results, suggesting that dynamical and static causalities are equivalent under the proposed metric.\n\nAn important characteristic of complex systems is that their constituting elements usually have a chaotic dynamics \\cite{strogatz2014nonlinear}, making more complicated the task of detecting causality between them. We here test the proposed metrics by considering two unidirectionally coupled R\\\"ossler oscillators ($\\mathcal{B} \\rightarrow \\mathcal{C}$) in their chaotic regime - see \\cite{Rulkov:1995iq} for details. We consider both linear and cubic couplings; following the notation in \\cite{Rulkov:1995iq}, this means:\n\n\\begin{eqnarray}\n\t\\dot{y}_1 = - (y_2 + y_3) - \\gamma (y_1 - x_1), \\text{and} \\\\\n\t\\dot{y}_1 = - (y_2 + y_3) - \\gamma (y_1 - x_1) ^3.\n\\end{eqnarray}\n\nTime series are created by sampling the second dimension of each oscillator ({\\it i.e.} $x_2$ and $y_2$) with a resolution lower than the intrinsic frequency. Fig. \\ref{fig:kuramoto} Bottom depicts the evolution of the $p$-value for low coupling strengths $\\gamma$, thus ensuring that the system is {\\it generalised synchronised}. For $\\gamma \\approx 0.01$ ($\\gamma \\approx 2 \\cdot 10^{-4}$ for cubic coupling), a true causality is detected, while for $\\gamma > 0.015$ ($\\gamma > 4 \\cdot 10^{-4}$) the two oscillators start to synchronise.\n\n\\begin{figure*}[!tb]\n\\centering\n\\includegraphics[width=0.32\\textwidth]{Fig06a.pdf}\n\\includegraphics[width=0.32\\textwidth]{Fig06b.pdf}\n\\includegraphics[width=0.32\\textwidth]{Fig06c.pdf}\n\\caption{\\label{fig:EEG} Analysis of causality in EEG data. (Left) Proportion of pairs of channels in which causality has been detected, for cross-sectional (blue) and longitudinal (red) analyses, as a function of the significance level $\\alpha$. (Center) Top-10 causality links in the cross-sectional analysis. (Right) Top-10 causality links in the longitudinal analysis. In the central and right panel, the size of the node is proportional to its weight.}\n\\end{figure*}\n\nThe possibility of combining a cross-sectional analysis of extreme values with a longitudinal analysis opens new doors towards the understanding of systems for which both aspects can be studied at the same time. Here we show how this can be achieved in the analysis of functional networks representing the structure of brain activity in healthy subjects \\cite{bullmore2009complex, rubinov2010complex}. The data set corresponds to electroencephalographic (EEG) recordings of $40$ subjects during $50$ trials of an object recognition task (details can be found in \\cite{zhang1995event} and references within), obtained through the UCI KDD archive \\cite{bay2000uci}. For each trial and subject, $19$ time series (corresponding to $19$ EEG channels in the $10-20$ configuration) of $256$ samples were available. The longitudinal analysis was performed by calculating the causality using the raw time series. On the other hand, the cross-sectional analysis relies on identifying the propagation of extreme events, as in the case of the Kuramoto oscillators. Extreme events are defined as those for which the energy of the signal is maximum in a given time series; the energy is defined, at each time point, as the deviation with respect to the mean, normalised by the standard deviation of the signal - {\\it i.e.} as the absolute value of the Z-Score.\n\n\nFig. \\ref{fig:EEG} (Left) depicts a box plot of the proportion of significant pairs of channels ({\\it i.e.} pairs of channels for which a causality was detected), in both the cross-sectional (blue) and longitudinal (red) analyses, for different significance levels $\\alpha$. In the case of the cross-sectional analysis, each value corresponds to the results for a single subject. Results are qualitatively equivalent, with the longitudinal analysis detecting slightly less links than the cross-sectional one for small values of $\\alpha$. Fig. \\ref{fig:EEG} Center and Right depict the $10$ most significant links, as detected by both analyses. While not completely equivalent, both graphs suggest that some areas are identified as active by both methods, {\\it e.g.} the frontal lobe on the top and the visual and somatosensory integration area in the bottom. Remarkably, these two regions are expected to be relevant for the task studied, {\\it i.e.} object identification: the former for higher function planning (react to the image shown), the latter in the processing of visual inputs.\n\n\nIn conclusion, we presented a novel metric able to detect causality relationships both in static and time-evolving data sets, thus overcoming the limitation of existing metrics that rely on time series analysis. The proposed metric is designed to detect the propagation of extreme events, or shocks, and as such is more efficient when non-linear relations are present; it is further able to discriminate real from spurious causalities, thus enabling the detection of confounding effects. The effectiveness of the metric has been tested through synthetic data, data obtained from simple and chaotic dynamical systems (Kuramoto and R\\\"ossler oscillators), and on EEG data representing the activity of the human brain during an object recognition task.\n\nThe possibility of detecting causality in static data sets is expected to be of increasing importance in those research fields in which time dynamics are not available, and that require ensuring that a causality is not just the result of the presence of a confounding factor. For instance, one may considering the raising field of biomedical data analysis \\cite{prather1997medical, cios2002uniqueness, han2002can}. Time series are seldom available, as measuring gene expression or metabolite levels is an expensive and slow process. Additionally, confounding effects are frequently in place, as genes and metabolites create an intricate network of interactions. In spite of this, causality is an essential element to be detected: if one only focuses on correlations, there is a risk of detecting elements whose manipulation does not guarantee the expected results on the system \\cite{salmon2000voxel, cardon2003population, vakorin2009confounding}.\n\nA Python implementation of the proposed causality metric is freely available at \\url{www.mzanin.com/Causality}.\n\n\n\n\\bibliography{causality}{}\n\n\n\n", "itemtype": "equation", "pos": 7832, "prevtext": "\n\n\\title{On causality of extreme events}\n\n\\author{Massimiliano Zanin}\n\\affiliation{Innaxis Foundation \\& Research Institute,\nJos\\'e Ortega y Gasset 20, 28006, Madrid, Spain}\n\\affiliation{Departamento de Engenharia Electrot\\'ecnica, Faculdade de Ci\\^encias e Tecnologia, \nUniversidade Nova de Lisboa, Lisboa, Portugal}\n\n\n\\begin{abstract}\nMultiple metrics have been developed to detect causality relations between data describing the elements constituting complex systems, all of them considering their evolution through time. Here we propose a metric able to detect causality within static data sets, by analysing how extreme events in one element correspond to the appearance of extreme events in a second one. The metric is able to detect both linear and non-linear causalities; to analyse both cross-sectional and longitudinal data sets; and to discriminate between real causalities and correlations caused by confounding factors. We validate the metric through synthetic data, dynamical and chaotic systems, and data representing the human brain activity in a cognitive task.\n\nPACS: 05.45.Tp, 05.45.-a, 87.10.Vg\n\\end{abstract}\n\n\\maketitle\n\n\n\n\nDetecting causality relationships between the elements composing a (complex) system is an old, though unsolved problem \\cite{pearl2003causality, pearl2009causality}. \nThe origin of the concept of {\\it causality} goes back to the ancient Greek phylosophy, according to which causal investigation was the search for an answer to the question ``why?'' \\cite{evans1959causality, hankinson1998cause}; but the debate was still hot in the late 18th century, in the work of David Hume \\cite{hume1965enquiry}.\nMoving to the scientific research, in the last few decades there has been an increasing interest for detecting causality in real data, which has resulted in the creation of multiple metrics: Granger causality, cointegration, or transfer entropy \\cite{granger1988some, granger1988causality, schreiber2000measuring, staniek2008symbolic, verdes2005assessing}, to name a few.\n\nAll proposed metrics share a common characteristic: causality is defined as a relation existing in the temporal domain, and the metrics thus involve a time series analysis. This probably originated in the way the human brain conceives causality, as sequences of related events close in time \\cite{leslie1987six, tanaka2008calculating}. This is an important limitation, especially when studying systems whose dynamics through time cannot easily be observed. Consider, for instance, genetic analysis; one single measurement is usually available per subject and gene, precluding the estimation of gene-gene interactions through a causal analysis solely based on expression levels.\n\nAlthough correlation appears {\\it prima facie} as an interesting solution, it presents the important drawback of not being able of discriminating between real and spurious causalities.\nSuppose one is studying a system composed of three interconnected elements, as the one depicted in Fig. \\ref{fig:01} Left, with the aim of detecting if the dynamics of element $\\mathcal{C}$ is {\\it caused} by $\\mathcal{B}$; additionally, no time series are available, and elements are described through vectors of cross-sectional observations. A statistically significant correlation between $\\mathcal{B}$ and $\\mathcal{C}$ may be found both when a true causality is present (Fig. \\ref{fig:01} Right Bottom), and when both elements are driven by an unobserved (confounding) element $\\mathcal{A}$ (Fig. \\ref{fig:01} Right Top).\n\nIn order to tackle the scenario of Fig. \\ref{fig:01}, in this contribution we propose a novel metric for detecting causality from observational data. It entails three innovative points.\nFirst, it is defined on vectors of observation, which do not have to necessarily represent a time evolution. In other words, input vectors may correspond to gene expression levels measured in a population (a cross-sectional study), or (but not necessarily) to multiple observations of the same subject (a longitudinal study).\nSecond, the method is based on the detection of extreme events, and on their appearance statistics. This is not dissimilar to Granger causality, as the latter measures how shocks in one time series are explained by a second one; but without the need of a time evolution.\nThird, it is optimised for the detection of non-linear causal relations, which are common in many real-world complex systems \\cite{strogatz2014nonlinear}, but that may create problems in standard causality metrics \\cite{granger1993modelling}.\n\n\n\n\\begin{figure}[!tb]\n\\begin{center}\n\\includegraphics[width=0.4\\textwidth]{Fig01.pdf}\n\\caption{Distinguishing causality from correlation. (Left) General situation, in which three elements ($\\mathcal{A}$, $\\mathcal{B}$ and $\\mathcal{C}$) interact in a simple triangular configuration. If one is interested in the relation between $\\mathcal{B}$ and $\\mathcal{C}$, two different scenarios may arise. (Right top) When $\\mathcal{A}$ is dominating the dynamics, any common dynamics between $\\mathcal{B}$ and $\\mathcal{C}$ will be a correlation, generated by the external confounding factor. (Right bottom) The situation corresponding to a real causality between $\\mathcal{B}$ and $\\mathcal{C}$. \\label{fig:01}}\n\\end{center} \n\\end{figure}\n\n\n\n\\begin{figure*}[!tb]\n\\centering\n\\includegraphics[width=0.98\\textwidth]{Fig02.pdf}\n\\caption{\\label{fig:distributions} $p$-value obtained by the proposed causality metric, for vectors of synthetic data drawn from six different distributions, as a function of the coupling constant $\\gamma$ - see main text for details. Black, red and green lines respectively correspond to linear, quadratic and cubic couplings; solid lines depict true causalities (as in Fig. \\ref{fig:01} Right Bottom), dashed lines spurious ones (Fig. \\ref{fig:01} Right Top). Each point corresponds to $10.000$ realisations.}\n\\end{figure*}\n\n\nSuppose two vectors of elements $\\mathcal{B} = \\{ b_i \\}$ and $\\mathcal{C} = \\{ c_i \\}$ of equal size; some of these elements are labelled as extreme when they exceed a threshold, {\\it i.e.} $b > \\tau_b$ and $c > \\tau_c$. If a causality relation is present between them, such that $\\mathcal{B} \\rightarrow \\mathcal{C}$, this should affect the way extreme events appear.\nFirst, under non-extreme dynamics, the two systems $\\mathcal{B}$ and $\\mathcal{C}$ are loosely coupled. Especially when the relation is of a non-linear nature, small values in the former system are dampened during the transmission.\nSecond, most (ideally, all) of the extreme values of $\\mathcal{B}$ should correspond to extreme values of $\\mathcal{C}$, as extreme signals will be amplified from the former to the latter by the non-linear coupling.\nThird, extreme values of $\\mathcal{C}$ only partially correspond to extreme values of $\\mathcal{B}$; due to its internal dynamics, $\\mathcal{C}$ can display extreme events not triggered by the other element.\n\n\nLet us denote by $p_1$ the probability that an extreme event in $\\mathcal{C}$ also corresponds to an extreme event in $\\mathcal{B}$; and by $p_2$ the probability that an extreme event in $\\mathcal{B}$ corresponds to an extreme event in $\\mathcal{C}$. In the case of a real causality, the second condition implies that $p_1 \\approx 1$, the third one that $p_2 \\ll 1$.\nOn the other hand, in the case of an external confounding effect, and if the two thresholds are chosen such that the probability of finding extreme events is the same for both elements, it is easy to see that $p_1 \\approx p_2$. Notice that the same is true if $\\mathcal{B}$ and $\\mathcal{C}$ are bidirectionally interacting.\n\nThe previous analysis suggests that the necessary condition for having a $\\mathcal{B} \\rightarrow \\mathcal{C}$ causality is $p_1 > p_2$.\nThe statistical significance can be quantified through a binomial two-proportion z-test:\n\n\n", "index": 1, "text": "\\begin{equation}\n\tz = \\frac{ {p}_1 - {p}_2 }{ \\sqrt{ \\hat{p} (1 - \\hat{p}) ( \\frac{1}{n_1} + \\frac{1}{n_2} ) } },\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"z=\\frac{{p}_{1}-{p}_{2}}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_{1}}+\\frac{1}{n_{%&#10;2}})}},\" display=\"block\"><mrow><mrow><mi>z</mi><mo>=</mo><mfrac><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>-</mo><msub><mi>p</mi><mn>2</mn></msub></mrow><msqrt><mrow><mover accent=\"true\"><mi>p</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mover accent=\"true\"><mi>p</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mfrac><mn>1</mn><msub><mi>n</mi><mn>1</mn></msub></mfrac><mo>+</mo><mfrac><mn>1</mn><msub><mi>n</mi><mn>2</mn></msub></mfrac></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msqrt></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}]