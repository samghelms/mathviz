[{"file": "1601.06062.tex", "nexttext": "\nBy following Eq.~\\ref{eq:contrast}, we get frames for which the catheters and the diaphragm cancel out as much as possible.\nSee Figure~\\ref{fig:dsa} for an example.\nIn ${\\bm} I_{\\mathrm{DSA}}$, only pixels with positive values contain contrast agent. To extract them, we set the intensity of pixels with negative value to 0.\nAfterwards, we compute a filtered image ${\\bm} I_{\\mathrm f}$ by applying a median filter with a large kernel size.\nSmaller structures, e.g., caused by motion artifacts that remained despite the optimized choice of ${\\bm} I_{\\mathrm u}$, do not pass this filter,\nand the noise in the contrasted area is reduced as well.\nFinally, a binary image ${\\bm} I_{\\mathrm {thr}}$ of the filtered image ${\\bm} I_{\\mathrm f}$ is computed using a threshold at $\\mu_\\mathrm{f}+\\sigma_\\mathrm{f}$ where $\\mu_\\mathrm{f}$ and $\\sigma_\\mathrm{f}$ denote the mean and standard deviation of ${\\bm} I_{\\mathrm f}$, respectively. Thus, a contrasted pixel ${\\bm{\\mathit p}} \\in \\mathbb R^2$ is indicated by ${\\bm} I_{\\mathrm {thr}}({\\bm{\\mathit p}}) = 1$.\n\nA previous approach~\\cite{thivierge2012registration} tried to find a transformation $T$ of the 3-D model such that the projected shadows ${{\\bm} S^{\\mathrm{A}}_T},{{\\bm} S^{\\mathrm{B}}_T}$ of the model into the A-plane and the B-plane of a biplane C-arm system fit best to the contrasted region.\nUsing the normalized cross correlation (NCC), denoted as ${\\rho_\\mathrm{n}}$, of two images ${\\bm} I_1,{\\bm} I_2$ with corresponding mean values $\\mu_1,\\mu_2$ and standard deviations $\\sigma_1,\\sigma_2$\n\n", "itemtype": "equation", "pos": 9881, "prevtext": "\n\\include{responses}\n\\cleardoublepage\n\\twocolumn\n\\pagenumbering{arabic}\n\\setcounter{page}{1}\n\n\\title{3-D/2-D Registration of Cardiac Structures by 3-D Contrast Agent Distribution Estimation}\n\n\\author{Matthias~Hoffmann, Christopher~Kowalewski, Andreas~Maier, Klaus~Kurzidim, Norbert~Strobel, Joachim~Hornegger\n\\thanks{This work was supported by the German Federal Ministry of Education and Research (BMBF) in the context of the initiative Spitzencluster Medical Valley - Europ\\\"aische Metropolregion N\\\"urnberg, project grant Nos. 12EX1012A and 12EX1012E, respectively. Additional funding was provided by Siemens Healthcare GmbH.\nJ. Hornegger and A. Maier gratefully acknowledges funding of the Erlangen Graduate School in Advanced Optical Technologies (SAOT) by the German Research Foundation (DFG) in the framework of the German excellence initiative.\n\nThe concepts and information presented in this paper are based\non research and are not commercially available.} \n\\thanks{M. Hoffmann, A. Maier and J. Hornegger are with Pattern Recognition Lab, Friedrich-Alexander-Universit\\\"at Erlangen-N\\\"urnberg, Martensstr. 3, 91058 Erlangen, Germany. E-mail: Matthias.Hoffmann@cs.fau.de}\n\\thanks{A. Maier and J. Hornegger are with Erlangen Graduate School in Advanced Optical Technologies (SAOT), Friedrich-Alexander-Universit\\\"at Erlangen-N\\\"urnberg, Paul-Gordan-Str. 6, 91058 Erlangen, Germany}\n\\thanks{C. Kowalewski and K. Kurzidim are with\nKlinik f\\\"ur Herzrhythmusst\\\"orungen,\tKrankenhaus Barmherzige Br\\\"uder Regensburg, Pr\\\"ufeninger Stra\\ss e 86, 93049 Regensburg }\n\\thanks{\nN. Strobel is with\nSiemens Healthcare GmbH, Siemensstr. 1, 91301 Forchheim, Germany\n}}\n\n\n\\maketitle              \n\n\\begin{abstract}\nFor augmented fluoroscopy during cardiac catheter ablation procedures, a preoperatively acquired 3-D model of the left atrium of the patient can be registered to X-ray images.\nTherefore the 3D-model is matched with the contrast agent based appearance of the left atrium.\nCommonly, only small amounts of contrast agent (CA) are used to locate the left atrium.\nThis is why we focus on robust registration methods that work also if the structure of interest is only partially contrasted.\n\nIn particular, we propose two similarity measures for CA-based registration: \nThe first similarity measure, explicit apparent edges, focuses on edges of the patient anatomy made visible by contrast agent and can be computed quickly on the GPU. The second novel similarity measure computes a contrast agent distribution estimate (CADE) inside the 3-D model and rates its consistency with the CA seen in biplane fluoroscopic images.\nAs the CADE computation involves a reconstruction of CA in 3-D using the CA within the fluoroscopic images, it is slower. \n\nUsing a combination of both methods, our evaluation on 11 well-contrasted clinical datasets yielded an error of 7.9$\\pm$6.3\\,mm over all frames. For 10 datasets with little CA, we obtained an error of 8.8$\\pm$6.7\\,mm.\nOur new methods outperform a registration based on the projected shadow significantly ($p<0.05$).\n\\end{abstract}\n\n\\section{Introduction}\n\n\n\nAtrial fibrillation is the most common heart arrhythmia\naffecting around 2.2 million people in the US. \nA possible treatment option is catheter ablation, which is a minimally invasive procedure.\nIt is carried out using either electroanatomic mapping systems, a fluoroscopy guided approach or a combination of both.\nIn this paper, we refer to fluoroscopy guided approaches.\nUnfortunately, X-ray images suffer from poor soft-tissue contrast such that the left atrium (LA) can only be seen if contrast agent (CA) is injected.\nHowever, to reduce the risk of contrast-induced nephropathy, physicians try to keep the use of CA to a minimum often highlighting only a part of the left atrium.\nTo provide orientation to the physician when no CA is present, a model of the LA, e.g., generated by a CT or MRI scan of the patient can be overlaid~\\cite{deBuck2005AugmentedReality}. \nAs the coordinate systems of the preprocedurally acquired 3-D heart model and the patient during the intervention differ,\na registration step has to be performed. \nIn clinical practice, this registration is usually carried out manually often involving a CA injection~\\cite{bourier2012registration}.\nUnfortunately, manual registration complicates the workflow. \nIt either increases the workload of the treating physician, or it involves a trained assistant.\nTherefore, automatic registration is preferred.\n\n\n\n\nThere has been much research about registration of 3-D objects to 2-D fluoroscopic images, e.g. for bones~\\cite{Gueziec1998AnatomyBased,Hamadeh1998AutomatedRegistration} or implants~\\cite{Kaptein2003RSA}. \nAn overview is given by Markelj {\\textit{et al.}}~\\cite{Markelj2012reviewregistration}.\n\nCompared to implants, a registration of the LA is more complicated for two reasons: First, for implants and bones, usually the whole object is visible under fluoroscopy. \nDuring a contrast injection, however, only parts of the left atrium may be visible in the fluoroscopic images. \nSecond, the general visibility of the LA may be poor depending on how much CA is used.\nAs a consequence, further effort is needed to develop robust registration methods that can also be applied if CA is used sparingly.\n\nIn a first approach towards automatic LA registration, Thivierge-Gaulin {\\textit{et al.}}~\\cite{thivierge2012registration} tried to find a 3-D pose of a model such that its projected shadow matches the contrasted area in a selected image, enhanced by digital subtraction angiography (DSA), best.\nBased on CT images, a second approach by Zhao {\\textit{et al.}}~\\cite{Zhao2013Registration} relied on digitally rendered radiographies of the segmented left atrium.\nThe rendered image was compared to a DSA image using normalized gradient correlation where distinct regions of the atrium were weighted differently.\n\n\n\n\n\nWe propose two new registration techniques for contrast agent-based registration:\n\nIn our first method, we take explicitly apparent edges extracted from a 3-D model and compare them to LA edges present in the fluoroscopic images as proposed by~\\cite{Gueziec1998AnatomyBased,Hamadeh1998AutomatedRegistration} for automatic registration of bones and by \\cite{hoffmann2013Visualization} for manual registration of the LA, respectively.\nThis comparison can be carried out quickly on a GPU.\n\nSecond, we introduce a novel similarity measure for biplane fluoroscopy that is tailored for cases in which only parts of an object are visible.\nBased on a 3-D model of the LA, our second method estimates the contrast agent distribution inside the 3-D object from a simultaneously acquired pair of fluoroscopic images taken under two different view angles.\nThen we evaluate how consistent the contrast agent distribution estimate (CADE) is with the acquired fluoroscopic images.\nAs the CADE depends on the transformation used for registration, the transformation leading to the most plausible CADE is used as final position estimate.\n\n\n\\begin{figure}[t]\n\\begin{center}\n\\includegraphics[width=0.7\\linewidth]{objfktarea}\n\\end{center}\n\\caption{A correct (red) and wrong (cyan) registration result. \nIn both cases, the contrasted area is fully inside the projection shadow represented by the colored outline.\nThis leads to a similar NCC value when using only an area-based feature for automatic registration. \nThanks to the best reference frame selection, motion artifacts could be kept to a minimum. Only some remained in the vicinity of the moving coronary sinus (CS) catheter and the diaphragm, see white arrows.}\n\\label{fig:objfktarea}\n\\end{figure}\n\\section{Registration Method}\\label{sec:method}\nFor registration, two fluoroscopic sequences showing a CA injection are used.\nThese sequences are acquired simultaneously from two different angles using an angiography biplane system.\nFor each plane, the projection matrix that describes the X-ray camera setup is known.\nWe denote the associated projection operator by $P$.\nWe also assume that a 3-D model of the patient's LA is available, either as a triangle mesh or a binary volume, as they can be converted into each other.\n\n\\subsection{Contrast Agent Extraction}\\label{ssec:contrastExtraction}\nThe contrasted area is found based on a difference image (DSA) ${\\bm} I_{\\mathrm{DSA}}={\\bm} I_{\\mathrm u}-{\\bm} I_{\\mathrm c}$, ${\\bm} I\\in\\mathbb R^{m\\times n}$ involving a frame ${\\bm} I_{\\mathrm c}$ that contains contrast agent and an uncontrasted frame ${\\bm} I_{\\mathrm u}$.\nTo distinguish between contrasted and uncontrasted frames, either manual annotation, a threshold based method e.g. the method described in~\\cite{Zhao2013Registration} or an automatic contrast detection~\\cite{Hoffmann2015ContrastDetection} can be used.\nDepending on the chosen contrasted frame ${\\bm} I_{\\mathrm c}$, ${\\bm} I_{\\mathrm{DSA}}$ may contain artifacts due to motion of the diaphragm or from catheters if they are at different positions in ${\\bm} I_{\\mathrm u}$ and ${\\bm} I_{\\mathrm c}$.\nSuch motion artifacts depend, unlike the information about contrast agent, to a large degree on the choice of ${\\bm} I_{\\mathrm u}$.\nFor example, if the catheters in ${\\bm} I_{\\mathrm u}$ are at the same position as in ${\\bm} I_{\\mathrm c}$, their intensities cancel out in the subtraction image.\nOtherwise, ${\\bm} I_{\\mathrm{DSA}}$ has high positive values at the position of the catheter in ${\\bm} I_{\\mathrm c}$ and high negative values at the position of the catheter in ${\\bm} I_{\\mathrm u}$.\nTo keep motion artifacts to a minimum, we propose a best reference selection, which chooses an appropriate reference frame $\\hat{\\bm} I_{\\mathrm u}$ that matches the chosen contrasted frame ${\\bm} I_{\\mathrm c}$ as much as possible.\nOut of all uncontrasted frames, that frame $\\hat{\\bm} I_{\\mathrm u}$ is selected which minimizes the $L_1$-norm of the resulting DSA image\n\n", "index": 1, "text": "\\begin{equation}\\label{eq:contrast}\n\\hat{\\bm} I_{\\mathrm u}={\\operatorname{arg\\,min}}_{{\\bm} I_{\\mathrm u}} \\sum_{x=0}^n\\sum_{y=0}^m |{\\bm} I_{\\mathrm u}(x,y)-{\\bm} I_{\\mathrm c}(x,y)|.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\hat{\\bm}I_{\\mathrm{u}}={\\operatorname{arg\\,min}}_{{\\bm}I_{\\mathrm{u}}}\\sum_{x%&#10;=0}^{n}\\sum_{y=0}^{m}|{\\bm}I_{\\mathrm{u}}(x,y)-{\\bm}I_{\\mathrm{c}}(x,y)|.\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msub><mi>I</mi><mi mathvariant=\"normal\">u</mi></msub></mrow><mo>=</mo><mrow><msub><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mi mathvariant=\"normal\">u</mi></msub></mrow></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>y</mi><mo>=</mo><mn>0</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mi mathvariant=\"normal\">u</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mi mathvariant=\"normal\">c</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\nthe similarity of the projected shadow and ${\\bm} I_{\\mathrm{DSA}}$ can be measured. A registration transformation can be estimated by maximizing either one of the two functions\n\\begin{eqnarray}\n{\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}(T)=&{\\rho_\\mathrm{n}}({\\bm} I_{\\mathrm{DSA}}^{\\mathrm A},{{\\bm} S^{\\mathrm{A}}_T})&\\cdot{\\rho_\\mathrm{n}}({\\bm} I_{\\mathrm{DSA}}^{\\mathrm B},{{\\bm} S^{\\mathrm{B}}_T}),\\\\\n{\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}(T)=&{\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{A}_{\\mathrm {thr}},{{\\bm} S^{\\mathrm{A}}_T})&\\cdot{\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{B}_{\\mathrm {thr}},{{\\bm} S^{\\mathrm{B}}_T}).\n\\end{eqnarray}\n\n\n\n\\subsection{Edge Feature}\\label{ssec:edge}\n\n\\begin{figure}[tb]\n\\begin{center}\n\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{orig}\n \\label{fig:orig}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{dsa}\n \\label{fig:dsa}\n}\\quad\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{median}\n \\label{fig:median}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{sigmoid}\n \\label{fig:sigmoid}\n}\\quad\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{dog_large}\n \\label{fig:dog_large}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{rendering}\n \\label{fig:rendering}\n}\n\\end{center}\n\\caption{Using the original image (a), a DSA image (b) is computed. \nAfter median filtering (c), the remaining motion artifacts from the catheter have vanished. \nAfterwards, all pixels are weighted by a sigmoid function (d) to get a homogeneous value distribution inside the contrasted area.\nEdges are extracted using derivatives of Gaussian with a large kernel size (e).\nFinally, the similarity to the rendered edges (f) is evaluated. }\n\\label{fig:overview}\n\\end{figure}\n\n\n\nUnfortunately, a registration approach only based on contrasted area has multiple solutions if the amount of CA is so little that it can be located at different positions inside the LA, see \\figurename~\\ref{fig:objfktarea}.\nOften, CA is injected against the roof or into the pulmonary veins.\nThis results in perceivable edges of the contrasted area which can be used as registration features as well.\nEdge-based registration can be done using only the silhouette boundary of the projected object~\\cite{Kaptein2003RSA}, see \\figurename~\\ref{fig:objfktarea} or all apparent edges~\\cite{Gueziec1998AnatomyBased,Hamadeh1998AutomatedRegistration}, see \\figurename~\\ref{fig:rendering}.\n\nWe decided to go for the second approach, as the silhouette corresponds to the edges in the image only if the complete atrium is filled with contrast.\nFor a partially contrasted left atrium, internal contours may, however, also appear in the fluoroscopic images. \nThis was already found to be beneficial for manual LA registration~\\cite{hoffmann2013Visualization}.\nInstead of considering edges implicitly by comparing the DSA image to a DRR using gradient correlation~\\cite{Zhao2013Registration}, we computed them explicitly.\n\nTo extract edges in the fluoroscopic images, we used the previously computed filtered image ${\\bm} I_{\\mathrm f}$.\nAfter applying a median filter, edge-like variations \\emph{inside} the contrasted areas may remain. They would trigger a response, if an edge filter was applied. \nTo obtain an edge response only at the boundaries of the contrasted area, the image needs to be homogenized before applying an edge filter.\nUsing a simple threshold method would result in a loss of the intensity drop-off at the boundary which provides important information about the edge intensity.\nTherefore, we weigh all image pixels by a sigmoid function\n\n", "itemtype": "equation", "pos": 11640, "prevtext": "\nBy following Eq.~\\ref{eq:contrast}, we get frames for which the catheters and the diaphragm cancel out as much as possible.\nSee Figure~\\ref{fig:dsa} for an example.\nIn ${\\bm} I_{\\mathrm{DSA}}$, only pixels with positive values contain contrast agent. To extract them, we set the intensity of pixels with negative value to 0.\nAfterwards, we compute a filtered image ${\\bm} I_{\\mathrm f}$ by applying a median filter with a large kernel size.\nSmaller structures, e.g., caused by motion artifacts that remained despite the optimized choice of ${\\bm} I_{\\mathrm u}$, do not pass this filter,\nand the noise in the contrasted area is reduced as well.\nFinally, a binary image ${\\bm} I_{\\mathrm {thr}}$ of the filtered image ${\\bm} I_{\\mathrm f}$ is computed using a threshold at $\\mu_\\mathrm{f}+\\sigma_\\mathrm{f}$ where $\\mu_\\mathrm{f}$ and $\\sigma_\\mathrm{f}$ denote the mean and standard deviation of ${\\bm} I_{\\mathrm f}$, respectively. Thus, a contrasted pixel ${\\bm{\\mathit p}} \\in \\mathbb R^2$ is indicated by ${\\bm} I_{\\mathrm {thr}}({\\bm{\\mathit p}}) = 1$.\n\nA previous approach~\\cite{thivierge2012registration} tried to find a transformation $T$ of the 3-D model such that the projected shadows ${{\\bm} S^{\\mathrm{A}}_T},{{\\bm} S^{\\mathrm{B}}_T}$ of the model into the A-plane and the B-plane of a biplane C-arm system fit best to the contrasted region.\nUsing the normalized cross correlation (NCC), denoted as ${\\rho_\\mathrm{n}}$, of two images ${\\bm} I_1,{\\bm} I_2$ with corresponding mean values $\\mu_1,\\mu_2$ and standard deviations $\\sigma_1,\\sigma_2$\n\n", "index": 3, "text": "\\begin{equation}\n{\\rho_\\mathrm{n}}({\\bm} I_1,{\\bm} I_2)=\\sum_{x=0}^n\\sum_{y=0}^m \\frac{({\\bm} I_1(x,y)-\\mu_1)\\cdot({\\bm} I_2(x,y)-\\mu_2)}{\\sigma_1\\cdot\\sigma_2},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"{\\rho_{\\mathrm{n}}}({\\bm}I_{1},{\\bm}I_{2})=\\sum_{x=0}^{n}\\sum_{y=0}^{m}\\frac{(%&#10;{\\bm}I_{1}(x,y)-\\mu_{1})\\cdot({\\bm}I_{2}(x,y)-\\mu_{2})}{\\sigma_{1}\\cdot\\sigma_%&#10;{2}},\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi mathvariant=\"normal\">n</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>y</mi><mo>=</mo><mn>0</mn></mrow><mi>m</mi></munderover><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msub><mi>\u03bc</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msub><mi>\u03bc</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c3</mi><mn>1</mn></msub><mo>\u22c5</mo><msub><mi>\u03c3</mi><mn>2</mn></msub></mrow></mfrac></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\nThe value of $t$ is set to $\\mu_\\mathrm{f}-\\sigma_\\mathrm{f}$, and the parameter $s$ depends on the pixel intensity range of the input image.\nAn example of ${\\bm} I_\\mathrm{sig}$ is given in Figure~\\ref{fig:sigmoid}.\nFinally, ${\\bm} I_\\mathrm{sig}$ is filtered using a derivative of Gaussian (DOG) filter to obtain the edge image ${\\bm} I_\\mathrm{DOG}$.\nThe kernel size of the DOG-filter is set to a large value to get a smooth similarity measure, see Figure~\\ref{fig:dog_large}.\n\nThe projection of the 3-D triangle mesh edges into 2-D is done differently than in~\\cite{Gueziec1998AnatomyBased,hoffmann2013Visualization}.\nWe rendered the whole surface mesh and, depending on the viewing direction ${\\bm{\\mathit d}}$ and the surface normal ${\\bm{\\mathit n}}$ at a point, we set the opacity of projected triangles to $o=1-({\\bm{\\mathit d}} \\circ {\\bm{\\mathit n}})$, see Figure~\\ref{fig:rendering} for an example.\nBy doing so, areas that are parallel to the imaging plane are rendered transparent while areas with a normal vector orthogonal to the viewing direction are rendered opaque.\n\nThe similarity between edges extracted from the fluoroscopic images and the edge images ${\\bm{\\mathit E}}^{\\mathrm{A}}_{T},{\\bm{\\mathit E}}^{\\mathrm{B}}_{T}$ rendered from the 3-D model transformed by $T$ is measured by\n\n", "itemtype": "equation", "pos": 15380, "prevtext": "\nthe similarity of the projected shadow and ${\\bm} I_{\\mathrm{DSA}}$ can be measured. A registration transformation can be estimated by maximizing either one of the two functions\n\\begin{eqnarray}\n{\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}(T)=&{\\rho_\\mathrm{n}}({\\bm} I_{\\mathrm{DSA}}^{\\mathrm A},{{\\bm} S^{\\mathrm{A}}_T})&\\cdot{\\rho_\\mathrm{n}}({\\bm} I_{\\mathrm{DSA}}^{\\mathrm B},{{\\bm} S^{\\mathrm{B}}_T}),\\\\\n{\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}(T)=&{\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{A}_{\\mathrm {thr}},{{\\bm} S^{\\mathrm{A}}_T})&\\cdot{\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{B}_{\\mathrm {thr}},{{\\bm} S^{\\mathrm{B}}_T}).\n\\end{eqnarray}\n\n\n\n\\subsection{Edge Feature}\\label{ssec:edge}\n\n\\begin{figure}[tb]\n\\begin{center}\n\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{orig}\n \\label{fig:orig}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{dsa}\n \\label{fig:dsa}\n}\\quad\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{median}\n \\label{fig:median}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{sigmoid}\n \\label{fig:sigmoid}\n}\\quad\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{dog_large}\n \\label{fig:dog_large}\n}~~\n\\subfigure[]{\n \\includegraphics[width=0.45\\linewidth]{rendering}\n \\label{fig:rendering}\n}\n\\end{center}\n\\caption{Using the original image (a), a DSA image (b) is computed. \nAfter median filtering (c), the remaining motion artifacts from the catheter have vanished. \nAfterwards, all pixels are weighted by a sigmoid function (d) to get a homogeneous value distribution inside the contrasted area.\nEdges are extracted using derivatives of Gaussian with a large kernel size (e).\nFinally, the similarity to the rendered edges (f) is evaluated. }\n\\label{fig:overview}\n\\end{figure}\n\n\n\nUnfortunately, a registration approach only based on contrasted area has multiple solutions if the amount of CA is so little that it can be located at different positions inside the LA, see \\figurename~\\ref{fig:objfktarea}.\nOften, CA is injected against the roof or into the pulmonary veins.\nThis results in perceivable edges of the contrasted area which can be used as registration features as well.\nEdge-based registration can be done using only the silhouette boundary of the projected object~\\cite{Kaptein2003RSA}, see \\figurename~\\ref{fig:objfktarea} or all apparent edges~\\cite{Gueziec1998AnatomyBased,Hamadeh1998AutomatedRegistration}, see \\figurename~\\ref{fig:rendering}.\n\nWe decided to go for the second approach, as the silhouette corresponds to the edges in the image only if the complete atrium is filled with contrast.\nFor a partially contrasted left atrium, internal contours may, however, also appear in the fluoroscopic images. \nThis was already found to be beneficial for manual LA registration~\\cite{hoffmann2013Visualization}.\nInstead of considering edges implicitly by comparing the DSA image to a DRR using gradient correlation~\\cite{Zhao2013Registration}, we computed them explicitly.\n\nTo extract edges in the fluoroscopic images, we used the previously computed filtered image ${\\bm} I_{\\mathrm f}$.\nAfter applying a median filter, edge-like variations \\emph{inside} the contrasted areas may remain. They would trigger a response, if an edge filter was applied. \nTo obtain an edge response only at the boundaries of the contrasted area, the image needs to be homogenized before applying an edge filter.\nUsing a simple threshold method would result in a loss of the intensity drop-off at the boundary which provides important information about the edge intensity.\nTherefore, we weigh all image pixels by a sigmoid function\n\n", "index": 5, "text": "\\begin{equation}\\label{eq:sig}\n\t{\\bm} I_\\mathrm{sig}(x,y) = \\frac{1}{1 + \\mathrm e^{-({\\bm} I_\\mathrm{f}(x,y)+t)\\cdot s}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"{\\bm}I_{\\mathrm{sig}}(x,y)=\\frac{1}{1+\\mathrm{e}^{-({\\bm}I_{\\mathrm{f}}(x,y)+t%&#10;)\\cdot s}}.\" display=\"block\"><mrow><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mi>sig</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi mathvariant=\"normal\">e</mi><mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msub><mi>I</mi><mi mathvariant=\"normal\">f</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>s</mi></mrow></mrow></msup></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\n\n\n\\subsection{Contrast Agent Distribution Estimation (CADE)}\\label{ssec:CADE}\nPrevious approaches~\\cite{thivierge2012registration,Zhao2013Registration} for LA registration searched for a rigid transformation of the LA such that either its projected shadow or its DRR fit to the contrasted area in both fluoroscopic images.\n3-D information was integrated insofar as the resulting projections came from the same 3-D position of the model.\n\nUnfortunately, such an approach does not guarantee that corresponding objects in both fluoroscopic images are matched to the same 3-D structure of the LA.\nMore precisely, the registration result could be such that in plane A, the contrast agent is located in a left pulmonary vein (PV) whereas in plane B, the contrasted area corresponds to a right PV.\nThis is possible as for a given 2-D registration in one plane, the 2-D registration in the other plane has one degree of freedom, which corresponds to an out-of-plane motion in the first plane.\n\nTo solve this problem, we compute for a given transformation $T$ a CADE inside the LA using binary reconstruction. \nThen, $T$ is optimized such that the contrast agent distribution estimate is most consistent with the projection images.\nMore precicely, a voxel ${\\bm{\\mathit v}}$ is estimated as contrasted if it fulfills all of the following conditions:\nThe voxel ${\\bm{\\mathit v}}$ transformed by $T$ is (a) projected on a contrasted pixel in plane A, (b) projected on a contrasted pixel in plane B, and (c) ${\\bm{\\mathit v}}$ is part of the left atrium as contrast agent can only be found inside the left atrium.\nFor the computation of the CADE, we define therefore the indicator function\n\n", "itemtype": "equation", "pos": 16823, "prevtext": "\nThe value of $t$ is set to $\\mu_\\mathrm{f}-\\sigma_\\mathrm{f}$, and the parameter $s$ depends on the pixel intensity range of the input image.\nAn example of ${\\bm} I_\\mathrm{sig}$ is given in Figure~\\ref{fig:sigmoid}.\nFinally, ${\\bm} I_\\mathrm{sig}$ is filtered using a derivative of Gaussian (DOG) filter to obtain the edge image ${\\bm} I_\\mathrm{DOG}$.\nThe kernel size of the DOG-filter is set to a large value to get a smooth similarity measure, see Figure~\\ref{fig:dog_large}.\n\nThe projection of the 3-D triangle mesh edges into 2-D is done differently than in~\\cite{Gueziec1998AnatomyBased,hoffmann2013Visualization}.\nWe rendered the whole surface mesh and, depending on the viewing direction ${\\bm{\\mathit d}}$ and the surface normal ${\\bm{\\mathit n}}$ at a point, we set the opacity of projected triangles to $o=1-({\\bm{\\mathit d}} \\circ {\\bm{\\mathit n}})$, see Figure~\\ref{fig:rendering} for an example.\nBy doing so, areas that are parallel to the imaging plane are rendered transparent while areas with a normal vector orthogonal to the viewing direction are rendered opaque.\n\nThe similarity between edges extracted from the fluoroscopic images and the edge images ${\\bm{\\mathit E}}^{\\mathrm{A}}_{T},{\\bm{\\mathit E}}^{\\mathrm{B}}_{T}$ rendered from the 3-D model transformed by $T$ is measured by\n\n", "index": 7, "text": "\\begin{equation}\n{\\rho_{\\mathrm{edge}}}(T)={\\rho_\\mathrm{n}}({\\bm} I_\\mathrm{DOG}^\\mathrm{A},{\\bm{\\mathit E}}^{\\mathrm{A}}_{T}) \\cdot{\\rho_\\mathrm{n}}({\\bm} I_\\mathrm{DOG}^\\mathrm{B},{\\bm{\\mathit E}}^{\\mathrm{B}}_{T}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"{\\rho_{\\mathrm{edge}}}(T)={\\rho_{\\mathrm{n}}}({\\bm}I_{\\mathrm{DOG}}^{\\mathrm{A%&#10;}},{\\bm{\\mathit{E}}}^{\\mathrm{A}}_{T})\\cdot{\\rho_{\\mathrm{n}}}({\\bm}I_{\\mathrm%&#10;{DOG}}^{\\mathrm{B}},{\\bm{\\mathit{E}}}^{\\mathrm{B}}_{T}).\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi>edge</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi mathvariant=\"normal\">n</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>I</mi><mi>DOG</mi><mi mathvariant=\"normal\">A</mi></msubsup></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>E</mi><mi>T</mi><mi mathvariant=\"normal\">A</mi></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><msub><mi>\u03c1</mi><mi mathvariant=\"normal\">n</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>I</mi><mi>DOG</mi><mi mathvariant=\"normal\">B</mi></msubsup></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>E</mi><mi>T</mi><mi mathvariant=\"normal\">B</mi></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\n\nGiven the binary images ${\\bm} I^\\mathrm{A}_{\\mathrm {thr}}$ and ${\\bm} I^\\mathrm{B}_{\\mathrm {thr}}$ with corresponding projection operators $P_A, P_B$ and the indicator function $\\chi({\\bm{\\mathit v}})$, the CADE $C^{\\mathrm{3-D}}_T$ can be computed as\n\n", "itemtype": "equation", "pos": 18735, "prevtext": "\n\n\n\\subsection{Contrast Agent Distribution Estimation (CADE)}\\label{ssec:CADE}\nPrevious approaches~\\cite{thivierge2012registration,Zhao2013Registration} for LA registration searched for a rigid transformation of the LA such that either its projected shadow or its DRR fit to the contrasted area in both fluoroscopic images.\n3-D information was integrated insofar as the resulting projections came from the same 3-D position of the model.\n\nUnfortunately, such an approach does not guarantee that corresponding objects in both fluoroscopic images are matched to the same 3-D structure of the LA.\nMore precisely, the registration result could be such that in plane A, the contrast agent is located in a left pulmonary vein (PV) whereas in plane B, the contrasted area corresponds to a right PV.\nThis is possible as for a given 2-D registration in one plane, the 2-D registration in the other plane has one degree of freedom, which corresponds to an out-of-plane motion in the first plane.\n\nTo solve this problem, we compute for a given transformation $T$ a CADE inside the LA using binary reconstruction. \nThen, $T$ is optimized such that the contrast agent distribution estimate is most consistent with the projection images.\nMore precicely, a voxel ${\\bm{\\mathit v}}$ is estimated as contrasted if it fulfills all of the following conditions:\nThe voxel ${\\bm{\\mathit v}}$ transformed by $T$ is (a) projected on a contrasted pixel in plane A, (b) projected on a contrasted pixel in plane B, and (c) ${\\bm{\\mathit v}}$ is part of the left atrium as contrast agent can only be found inside the left atrium.\nFor the computation of the CADE, we define therefore the indicator function\n\n", "index": 9, "text": "\\begin{equation}\n\\chi({\\bm{\\mathit v}})=1 \\Leftrightarrow {\\bm{\\mathit v}} \\in \\mathbb R^3\\text{ is inside the left atrium}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\chi({\\bm{\\mathit{v}}})=1\\Leftrightarrow{\\bm{\\mathit{v}}}\\in\\mathbb{R}^{3}%&#10;\\text{ is inside the left atrium}.\" display=\"block\"><mrow><mrow><mrow><mrow><mi>\u03c7</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow><mo>\u21d4</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo>\u2208</mo><mrow><msup><mi>\u211d</mi><mn>3</mn></msup><mo>\u2062</mo><mtext>\u00a0is inside the left atrium</mtext></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\nfor a given rigid transformation $T$.\nThese three factors correspond to the aforementioned conditions.\n\n\\begin{figure}[tb]\n\\begin{center}\n \\includegraphics[width=0.9\\linewidth]{volRecon}\n\\end{center}\n\\caption{For the transformation shown, only voxel B is estimated as containing CA as it is inside the LA and contrasted in both planes. \nVoxel C is only contrasted in Plane A but not in Plane B. Voxel A is filled with contrast in both planes, but it is outside of the LA and therefore considered as uncontrasted.\nIf the LA is moved such that its projections in A and B cover the contrasted area, this voxel will also be estimated as contrasted.}\n\\label{fig:CAD}\n\\end{figure}\nIf $T$ is chosen suboptimally, the resulting 3-D CADE will be inconsistent with the CA observed in the 2-D images.\nI.e. a pixel in the 2-D image is constrasted but no corresponding voxel along its projection ray is estimated as contrasted.\nThis can be due to following reasons as shown in Figure~\\ref{fig:CAD}:\n\n\t(a) the projection ray from a contrasted pixel does not intersect the left atrium as the LA has not been placed at the proper position yet;\n\t(b) the projection ray hits the LA, but all voxels intersected by this ray cannot contain CA because their corresponding pixels in the other plane are uncontrasted.\n\nAdditional inconsistencies are introduced by pixels which are erroneously labeled as contrasted e.g. due to motion artifacts.\nTo verify the validity of the CADE, we compute 2-D images ${\\bm{\\mathit C}}^\\mathrm{A}_{T}, {\\bm{\\mathit C}}^\\mathrm{B}_{T}$ by forward projecting all contrasted voxels in $C^{\\mathrm{3-D}}_T$ using $P_A, P_B$.\nWe assess the consistency of the CADE for the given transformation $T$ by computing the similarity between the fluoroscopic images and the projected CADE by\n\n", "itemtype": "equation", "pos": 19131, "prevtext": "\n\nGiven the binary images ${\\bm} I^\\mathrm{A}_{\\mathrm {thr}}$ and ${\\bm} I^\\mathrm{B}_{\\mathrm {thr}}$ with corresponding projection operators $P_A, P_B$ and the indicator function $\\chi({\\bm{\\mathit v}})$, the CADE $C^{\\mathrm{3-D}}_T$ can be computed as\n\n", "index": 11, "text": "\\begin{equation}\nC^{\\mathrm{3-D}}_T({\\bm{\\mathit v}}) = {\\bm} I^\\mathrm{A}_{\\mathrm {thr}}\\left(P_A\\left(T({\\bm{\\mathit v}})\\right)\\right) \\cdot {\\bm} I^\\mathrm{B}_{\\mathrm {thr}}(P_B(T({\\bm{\\mathit v}}))) \\cdot \\chi({\\bm{\\mathit v}})\n\\label{eq:CADE}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"C^{\\mathrm{3-D}}_{T}({\\bm{\\mathit{v}}})={\\bm}I^{\\mathrm{A}}_{\\mathrm{thr}}%&#10;\\left(P_{A}\\left(T({\\bm{\\mathit{v}}})\\right)\\right)\\cdot{\\bm}I^{\\mathrm{B}}_{%&#10;\\mathrm{thr}}(P_{B}(T({\\bm{\\mathit{v}}})))\\cdot\\chi({\\bm{\\mathit{v}}})\" display=\"block\"><mrow><mrow><msubsup><mi>C</mi><mi>T</mi><mrow><mn>3</mn><mo>-</mo><mi mathvariant=\"normal\">D</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>I</mi><mi>thr</mi><mi mathvariant=\"normal\">A</mi></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mi>P</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>T</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u22c5</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror></mrow><mo>\u2062</mo><msubsup><mi>I</mi><mi>thr</mi><mi mathvariant=\"normal\">B</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>P</mi><mi>B</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mi>\u03c7</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06062.tex", "nexttext": "\n\n\\section{Experiments and Results}\\label{sec:experiments}\nWe evaluated our method on 21 clinical biplane X-ray sequences from 10 different patients.\nThe data set contained 11 sequences showing an initial contrast agent injection where CA was injected into the LA center through a sheath. \nBesides the sheath, only the coronary sinus catheter was present. \nThere were 10 more sequences showing a secondary injection for re-registration. \nHere, less CA was injected and additional catheters were present.\nFor all 133 contrasted frames, reference registrations performed by three clinical experts were available.\n\nThese reference registrations covered only translation as in~\\cite{bourier2012registration}.\n\nAs initialization for optimization, the 3-D model was placed at that 3-D position which corresponded to the centers of both 2-D images.\nIn some cases, the initialization was more than 30\\,mm away from the correct solution and beyond the capture range for gradient-based methods.\nTherefore we applied an octree-like coarse-to-fine scheme where we evaluated several positions at a coarse resolution.\nAt positions in space that yielded a good similarity value, we performed subsequent evaluations on an increasingly finer resolution.\nThe 3-D translation $\\hat {{\\bm{\\mathit t}}}={\\operatorname{arg\\,max}}_{{\\bm{\\mathit t}}}\\rho({{\\bm{\\mathit t}}})$ found by the optimization process of the respective objective function $\\rho$ was compared to the mean translation vector ${{\\bm{\\mathit t}}}^*$ of the three manual registration results.\nThe distance $||\\hat {{\\bm{\\mathit t}}} - {{\\bm{\\mathit t}}}^*||_2$ was used as error measure.\nThe significance of the results was measured using a Wilcoxon signed-rank test and a significance level of $0.05$.\n\nAll sequences contained 12-bit images of size $1024\\times1024$\\,pixels, all image processing, including rendering from the 3-D model, was performed on the full image size. \nThe kernel size for median filter was 30\\,pixels, the value $s$ of Eq.~\\ref{eq:sig} was 0.1. The standard deviation of the DOG filter was 24\\,pixels.\n\nIn the evaluation, we compared the similarity measures ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$, ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$, ${\\rho_\\mathrm{CADE}}$ and ${\\rho_{\\mathrm{edge}}}$ and \nthe combined similarity measures ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$+${\\rho_{\\mathrm{edge}}}$, ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$+${\\rho_{\\mathrm{edge}}}$ and ${\\rho_\\mathrm{CADE}}$+${\\rho_{\\mathrm{edge}}}$.\nWe investigated different weightings. Giving both terms equal weights turned out to be a good choice.\nDuring evaluation, a registration for all frames marked as contrasted was performed.\n\n\n\\begin{table}[tbp]\n\\begin{center}\n\\caption{Translation errors for all frames}\n    \\begin{tabular}{l|ll}\n    Objective function \t& initial injection\t\t\t\t& subsequent injections\t\t\t\t\\\\\n\t\t\\hline\n    ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$\t\t\t\t\t&9.3$\\pm$6.9\\,mm    \t\t\t&9.8$\\pm$4.8\\,mm\t\t\t\t\t\t\\\\\n    ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$\t\t\t\t\t&9.9$\\pm$7.9\\,mm    \t\t\t&12.1$\\pm$9.1\\,mm   \t\t\t\t\\\\\n\t\t${\\rho_{\\mathrm{edge}}}$\t\t\t\t\t  &12.0$\\pm$8.9\\,mm    \t\t&14.6$\\pm$8.7\\,mm   \t\t\t\t\\\\\n\t\t${\\rho_\\mathrm{CADE}}$\t\t\t\t\t\t&\\textbf{8.7$\\pm$6.4\\,mm}\t&\\textbf{9.0$\\pm$5.9\\,mm } \\\\\n\t\t\\hline\n    ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}+{\\rho_{\\mathrm{edge}}}$\t&8.3$\\pm$6.6\\,mm     \t\t\t&9.6$\\pm$5.4\\,mm    \t\t\t\t\\\\\n\t\t${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}+{\\rho_{\\mathrm{edge}}}$\t&8.3$\\pm$6.7\\,mm     \t\t\t&10.5$\\pm$7.6\\,mm   \t\t\t\t\\\\\n\t\t${\\rho_\\mathrm{CADE}}+{\\rho_{\\mathrm{edge}}}$\t\t&\\textbf{7.9$\\pm$6.3\\,mm} \t\t&\\textbf{8.8$\\pm$6.7\\,mm}  \\\\\n\t\t\\hline\n\t\tClinical experts\t\t&3.3$\\pm$2.7\\,mm &3.1$\\pm$1.7\\,mm  \\\\\n\t\t\\end{tabular}\n\t\t\\label{tab:allFrames}\n\t\t\\end{center}\n\\end{table}\n\nWe computed a registration for each contrasted frames and compared the result to the manual registration of the physicians.\nThese results are clinically relevant if the physician requires a registration for a frame he determines, e.g depending on the breathing phase.\nAs potentially every frame could be selected by the physician, the overall accuracy should be high.\nThe overall accuracy is also of importance if the results are post-processed, e.g. a temporal filtering is applied.\n\nThe evaluation results are presented in \\tablename~\\ref{tab:allFrames}.\nThe overall inter-user-variablity observed in the manual registrations was 3.2$\\pm$2.3\\,mm.\nConsidering all sequences, ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$ and ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$ gave significant better results when they are combined with ${\\rho_{\\mathrm{edge}}}$.\nAlso the performance of ${\\rho_\\mathrm{CADE}}+{\\rho_{\\mathrm{edge}}}$ was significantly better than ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$, ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$ and ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}+{\\rho_{\\mathrm{edge}}}$.\nCompared to other measures, ${\\rho_{\\mathrm{edge}}}$ gave significantly worse results.\nAn example for a result is given in \\figurename~\\ref{fig:qualiResults}.\n\n\nThe image preprocessing takes 0.5\\,s on an Intel Xeon E3 with 3.4 GHz and 16\\,GB RAM.\nThe evaluations of the similarity measures were performed completely on the GPU.\nOn an NVIDIA GeForce GTX 660 the evaluation of ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$, ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$ and ${\\rho_{\\mathrm{edge}}}$ took 1.8\\,ms for a given translation and 13.4$\\pm$3.7\\,ms for ${\\rho_\\mathrm{CADE}}$.\nThe whole registration for a single frame takes 2.9\\,s for ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$ and ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$ and 21.5$\\pm$5.9\\,s for ${\\rho_\\mathrm{CADE}}$.\nFor a combination with ${\\rho_{\\mathrm{edge}}}$ it takes 5.8\\,s and 27.1$\\pm$5.9\\,s, respectively.\n\n\n\\section{Discussion and Conclusions}\\label{sec:discussion}\n\\begin{figure}[tb]\n\\begin{center}\n\n\\subfigure[]{\n \\includegraphics[width=0.3\\linewidth]{72_3_fluoro}\n \\label{fig:resoirg}\n}~\n\\subfigure[]{\n \\includegraphics[width=0.3\\linewidth]{72_3_area_dsa}\n \\label{fig:resarea}\n}~\n\\subfigure[]{\n \\includegraphics[width=0.3\\linewidth]{72_3_cade_edge}\n \\label{fig:rescade}\n}~\n\\end{center}\n\\caption{(a) Contrasted fluoroscopic image. The registration result when using ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$ (b) had an error of 6.7\\,mm. By using ${\\rho_\\mathrm{CADE}}$+${\\rho_{\\mathrm{edge}}}$ (c), the left border of the LA model fits better to the left edge of the CA and the error reduced to 3.1\\,mm }\n\\label{fig:qualiResults}\n\\end{figure}\nOur novel CADE based method outperformed the shadow based similarity measures ${\\rho_{\\mathrm{shad}}^{\\mathrm{DSA}}}$ and ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$, especially for re-registration sequences where only a small amount of contrast agent was used.\nFor these sequences, registration errors leading to inconsistent results could be avoided by ${\\rho_\\mathrm{CADE}}$.\nFor well contrasted sequences, the improvement by ${\\rho_\\mathrm{CADE}}$ is less as inconsistencies play a minor role.\nWe found that the similarity measure using explicit apparent edges, ${\\rho_{\\mathrm{edge}}}$, yields poor results when used by its own, but can improve results significantly when combined with other similarity measures.\n\nIt remains open if the accuracy for all frames, which is between between 7\\,mm and 9\\,mm, is sufficient for a clinical application.\nIn a future work, temporal constraints on the heart movement could be included in the registration process or a temporal filtering could be applied afterwards.\n\nCompared to the approach by Zhao~{\\textit{et al.}}~\\cite{Zhao2013Registration}, the determination of special weightings for different heart regions, and, for ${\\rho_{\\mathrm{shad}}^{\\mathrm{thr}}}$+${\\rho_{\\mathrm{edge}}}$, a time consuming DRR generation was avoided.\nTo summarize, a registration based on a combination of shadow and edge features leads to a registration that can be computed fast.\nIf it is possible to use more time for registration, the novel CADE-based measure, which estimates consistency, should be used as it leads to better results.\n\n\\bibliographystyle{abbrv}\n\\bibliography{literature}\n\n", "itemtype": "equation", "pos": 21186, "prevtext": "\nfor a given rigid transformation $T$.\nThese three factors correspond to the aforementioned conditions.\n\n\\begin{figure}[tb]\n\\begin{center}\n \\includegraphics[width=0.9\\linewidth]{volRecon}\n\\end{center}\n\\caption{For the transformation shown, only voxel B is estimated as containing CA as it is inside the LA and contrasted in both planes. \nVoxel C is only contrasted in Plane A but not in Plane B. Voxel A is filled with contrast in both planes, but it is outside of the LA and therefore considered as uncontrasted.\nIf the LA is moved such that its projections in A and B cover the contrasted area, this voxel will also be estimated as contrasted.}\n\\label{fig:CAD}\n\\end{figure}\nIf $T$ is chosen suboptimally, the resulting 3-D CADE will be inconsistent with the CA observed in the 2-D images.\nI.e. a pixel in the 2-D image is constrasted but no corresponding voxel along its projection ray is estimated as contrasted.\nThis can be due to following reasons as shown in Figure~\\ref{fig:CAD}:\n\n\t(a) the projection ray from a contrasted pixel does not intersect the left atrium as the LA has not been placed at the proper position yet;\n\t(b) the projection ray hits the LA, but all voxels intersected by this ray cannot contain CA because their corresponding pixels in the other plane are uncontrasted.\n\nAdditional inconsistencies are introduced by pixels which are erroneously labeled as contrasted e.g. due to motion artifacts.\nTo verify the validity of the CADE, we compute 2-D images ${\\bm{\\mathit C}}^\\mathrm{A}_{T}, {\\bm{\\mathit C}}^\\mathrm{B}_{T}$ by forward projecting all contrasted voxels in $C^{\\mathrm{3-D}}_T$ using $P_A, P_B$.\nWe assess the consistency of the CADE for the given transformation $T$ by computing the similarity between the fluoroscopic images and the projected CADE by\n\n", "index": 13, "text": "\\begin{equation}\n{\\rho_\\mathrm{CADE}}(T)={\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{A}_{\\mathrm {thr}},{\\bm{\\mathit C}}^\\mathrm{A}_{T}) \\cdot{\\rho_\\mathrm{n}}({\\bm} I^\\mathrm{B}_{\\mathrm {thr}},{\\bm{\\mathit C}}^\\mathrm{B}_{T}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"{\\rho_{\\mathrm{CADE}}}(T)={\\rho_{\\mathrm{n}}}({\\bm}I^{\\mathrm{A}}_{\\mathrm{thr%&#10;}},{\\bm{\\mathit{C}}}^{\\mathrm{A}}_{T})\\cdot{\\rho_{\\mathrm{n}}}({\\bm}I^{\\mathrm%&#10;{B}}_{\\mathrm{thr}},{\\bm{\\mathit{C}}}^{\\mathrm{B}}_{T}).\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi>CADE</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi mathvariant=\"normal\">n</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>I</mi><mi>thr</mi><mi mathvariant=\"normal\">A</mi></msubsup></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>C</mi><mi>T</mi><mi mathvariant=\"normal\">A</mi></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><msub><mi>\u03c1</mi><mi mathvariant=\"normal\">n</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>I</mi><mi>thr</mi><mi mathvariant=\"normal\">B</mi></msubsup></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bm</mtext></merror><mo>\u2062</mo><msubsup><mi>C</mi><mi>T</mi><mi mathvariant=\"normal\">B</mi></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]