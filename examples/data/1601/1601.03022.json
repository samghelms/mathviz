[{"file": "1601.03022.tex", "nexttext": "\nwhere the superscript $T$ denotes the matrix transpose. \n\nBy construction, $\\mathbf{P}$ are symmetric and positive-definite matrices (SPD) that do not lie in a vector space but  on a Riemannian manifold \\cite{moakher2005}. Therefore, previous methods defined on a Euclidean structure are not longer adequate. The correct manipulation of these SPD matrices requires the application of Riemannian geometry concepts, described in Section \\ref{riemann}. \n\n\\subsection{Classification}\n\\label{classif}\n\\subsubsection{Classification of covariance matrices}\nThanks to the ability of covariance matrices to capture EEG spatial dynamics, a semi-supervised approach can be chosen to solve the classification problem in a BVI. \n\nIn semi-supervised algorithms, the availability of the labels from only one class is enough to classify instances from a second class, as the latter can be mapped in a different (distant) region of the space representation. In our framework,  motor cortex activation provoked during uncomfortable breathing should be different to that underlying normal, comfortable breathing (absence of motor cortical activity).\n\nThe objective of the classifier is to learn from $L$ data samples of the reference class SV  ($\\mathbf{X}_l^{(0)}, l=1 \\ldots L$) in order to label new trials $\\mathbf{X}$ in two classes, $\\mathcal{C}(\\mathbf{X}) = \\lbrace 0,1 \\rbrace $, which correspond to breathing comfort (SV condition) and discomfort (SN or LD conditions), respectively.\n  \nDuring the learning process, the algorithm first finds $K$ matrices, subsequently called prototypes, serving as reference to perform classification. Those prototypes constitute $K$ centers from the ensemble of covariance matrices $\\mathbf{P}_l^{(0)}$ and they are estimated by means of a general $K$-means clustering algorithm: \n \\begin{enumerate}\n\\item Initialize the prototypes $\\mathbf{C}_k$,  $k=1 \\ldots K$ by random selection of $K$ matrices from $\\mathbf{P}_l^{(0)}$,\n\\item For each sample covariance matrix, compute its distance $d$ to all the prototypes and assign it to the closest one in order to form the cluster $\\mathbf{S}_k$:\n\\begin{displaymath}\n\\mathbf{S}_k = \\left\\{ \\mathbf{P}_n: d(\\mathbf{P}_n, \\mathbf{C}_k)\\leqslant d(\\mathbf{P}_n, \\mathbf{C}_j)\\forall j, 1\\leqslant j \\leqslant K \\right\\}\n\\end{displaymath}\n\\item Update each prototype by averaging points in $\\mathbf{S}_k$ as \n\\begin{displaymath}\n\\mathbf{C}_k \\leftarrow {\\operatorname{arg\\,min}}_{\\mathbf{C}}\\sum_{\\mathbf{C}_i \\in \\mathbf{S}_k} d (\\mathbf{C}, \\mathbf{C}_i)\n\\end{displaymath}\nFor points lying in a vector space, $\\mathbf{C}_k$ corresponds to the arithmetic mean of points in $\\mathbf{S}_k$\n\\item Go to step (2) until convergence (e.g. the assignments no longer change) is achieved.\n \\end{enumerate}\n\nThe resulting prototypes $\\mathbf{C}_k$ represent the Class $0$, and are then used to classify the new unlabelled data $\\mathbf{X}_i$ (sub-index $i$ denotes the number of the $N_t$-sample window) according to:\n\n", "itemtype": "equation", "pos": 13192, "prevtext": "\n\\title{Riemannian geometry applied to detection of respiratory states from EEG signals: the basis for a brain-ventilator interface}\n\n\\author{X. Navarro-Sune, A.L. Hudson, F. De Vico Fallani, \\emph{Member, IEEE}, J. Martinerie, A. Witon, P. Pouget, M. Raux,\\\\T. Similowski and M. Chavez\n\\thanks{X. Navarro-Sune is with Sorbonne Universit\\'{e}s, UPMC Univ Paris 06 and the INSERM UMRS-1158, Neurophysiologie Respiratoire Exp\\'{e}rimentale et Clinique, Paris, France}\n\\thanks{A.L. Hudson is with Neuroscience Research Australia and University of New South Wales, Sydney, Australia.}\n\\thanks{F. De Vico Fallani is with the INRIA Paris-Rocquencourt, the CNRS UMR7225, the UPMC UMRS-1127, and the INSERM U1227 at the Institut du Cerveau et de la Moelle \\'{E}pini\\`ere. Paris, France.}\n\\thanks{J. Martinerie, P. Pouget and M. Chavez are with the CNRS UMR7225 at the Institut du Cerveau et de la Moelle \\'{E}pini\\`ere. Paris, France.}\n\\thanks{A. Witon is with the School of Computing, University of Kent, Canterbury, UK.}\n\\thanks{M. Raux is with Sorbonne Universit\\'{e}s, UPMC Univ Paris 06, INSERM, UMRS-1158, Neurophysiologie Respiratoire Exp\\'{e}rimentale et Clinique, Paris, France and with AP-HP, Groupe Hospitalier Piti\\'{e} Salp\\^{e}tri\\`{e}re-Charles Foix, D\\'{e}partement d'Anesth\\'{e}sie-R\\'{e}animation, Paris, France.}\n\\thanks{T. Similowski is with Sorbonne Universit\\'{e}s, UPMC Univ Paris 06, INSERM, UMRS-1158, Neurophysiologie Respiratoire Exp\\'{e}rimentale et Clinique, Paris, France and with AP-HP, Groupe Hospitalier Piti\\'{e} Salp\\^{e}tri\\`{e}re-Charles Foix, Service de Pneumologie et R\\'{e}animation M\\'{e}dicale, Paris, France.}\n\\thanks{Author for correspondence: xavier.navarro@upmc.fr}\n}\n\n\\markboth{IEEE Transactions On Biomedical Engineering, Vol. XX, No. Y, Month, 2015}\n{Navarro et~al.: Towards a brain-ventilator interface}\n\n\\maketitle\n\n\\begin{abstract}During mechanical ventilation, patient-ventilator disharmony is frequently observed and may result in increased breathing effort, compromising the patient's comfort and recovery. This circumstance requires clinical intervention and becomes challenging when patients are sedated or verbal communication is difficult. In this work, we propose a brain computer interface (BCI) to automatically and non-invasively detect patient-ventilator disharmony from electroencephalographic (EEG) signals: a brain-ventilator interface (BVI). Our framework exploits the cortical activation provoked by the inspiratory compensation when the patient and the ventilator are desynchronized. Use of a semi-supervised approach and Riemannian geometry of EEG covariance matrices allows effective classification of respiratory state. The BVI is validated on nine healthy subjects that performed different respiratory tasks that mimic a patient-ventilator disharmony. Results evidence that performance, in terms of areas under ROC curves (AUC), are significantly improved using EEG signals (AUC=0.91) compared to traditional detection based on air flow (AUC=0.76). Reduction in the number of electrodes that can achieve discrimination can often be desirable (e.g. for portable BCI systems). By using an iterative channel selection technique, the Common Highest Order Ranking (CHOrRa), we find that a reduced set of electrodes (n=6) can slightly improve AUC to 0.95 for an intra-subject configuration, and it still provides fairly good performances (AUC $\\geqslant$ 0.82) for a general inter-subject setting. In light of the promising results, the proposed framework opens the door to brain-ventilator interfaces for monitoring patient's breathing comfort and adapting ventilator parameters to patient respiratory needs.\n\\end{abstract}\n\n\\begin{keywords}\n\\small \\textbf{Biomedical signal processing, Brain-computer interfaces (BCI), Biomedical monitoring, Medical signal detection, Electroencephalography (EEG)}\n\\end{keywords}\n\n\n\n\n\n\\section{Introduction}\n\\IEEEPARstart{M}{echanical} ventilation is the most frequently used life-sustaining intervention in the intensive care unit (ICU), where approximately 50\\% of patients receive ventilatory support \\cite{carlucci2001}. At some point in their management, many patients on mechanical ventilation (MV) are described as ``fighting their ventilator\". This jargonistic expression is used to indicate a mismatch between patient respiratory efforts and ventilator ``breaths\". This form of disharmony between patient and ventilator results in an increased work of breathing and is a major source of discomfort for the patient with some deleterious effects such as dyspnea and anxiety. Dyspnea and anxiety are major drivers of post-traumatic stress disorders frequently observed in patients who survive the ICU \\cite{leung1997}.  Therefore, it is crucial to detect patient-ventilator disharmony as early as possible. \nCurrently, this relies on monitoring of physiological signals generated indirectly (pressure, air flow) or directly (electromyography) by the respiratory muscles in response to the descending neural drive to breathe. It is generally assumed that ventilatory support should be adapted to the neural drive to breathe~\\cite{Sinderby1999}. Some approaches address this issue by using the diaphragmatic EMG (e.g. the neurally adjusted ventilatory assist or NAVA~\\cite{Spahija2010}). Nevertheless, these techniques fail to take into account the fact that, under certain circumstances, the automatic respiratory activity of the brain stem is supplemented by respiratory-related cortical circuits. Indeed, inspiratory loading in awake humans elicits a cortical response that can be observed in EEG signals~\\cite{raux2007}. Such responses have been found to correlate with respiratory discomfort in healthy subjects fighting a ventilator~\\cite{raux2007b}. These observations give rise to the prospect of an effective brain-ventilator interface (BVI) that would target the neural correlates of respiratory discomfort rather than the automatic drive to breathe~\\cite{Grave2013}.  \n\nCurrent neuroscience research attempts to understand how brain functions result from dynamic interactions in large-scale cortical networks, and to further identify how cognitive tasks or brain diseases contribute to reshape this organization~\\cite{Varela2001}. Covariance analyses of brain data are widely used to elucidate the functional interactions between brain regions during different brain states. The relevance of covariance matrices as a feature for BCI has been already assessed~\\cite{barachant2012} and they constitute a very appropriate choice given their ability to reflect spatio-temporal dynamics in EEG. In this paper, we use elements of differential geometry to evaluate the ability of EEG covariance matrices to characterize changes in respiratory states in healthy subjects.\n\\vspace{-0.2cm}\n\n\\subsection*{A brain-ventilator interface}\n\\label{bvi}\nThe use of brain computer interfaces (BCI) is increasingly common in clinical environments as a technology to improve patient communication and rehabilitation using brain signals \\cite{mak2009}. However, the application of BCI in the respiratory context has not yet been explored.  \n\nIn this work, we propose a framework which provides the basis of a brain-ventilator interface (see Fig. \\ref{fig:plan_bvi}). A first possible implementation consists of an open loop configuration that generates an output signal to trigger an alarm in the case of breathing disharmony. The second implementation is a more advanced version that could generate a continuous output signal in a closed loop to directly adapt ventilator parameters to the patient's needs. \n\n \n\\begin{figure}[t!] \n   \\centering\n   \\includegraphics[width=\\linewidth]{BVI_blocks.pdf} \n   \\caption{Block diagram of the proposed brain-ventilator interface.}\n   \\label{fig:plan_bvi}\n\\end{figure} \n\nThe different blocks in the proposed BVI are as follows:\n\\begin{enumerate}\n\\item Acquisition: Set of electrodes, amplifiers and A/D converter providing digitized EEG signals.\n\\item Pre-processing: Improves signal-to-noise ratios in EEG signals by applying artifact correction/rejection and/or filters.\n\\item Feature extraction: Sample covariance matrices (CMs) are obtained from segmented, pre-processed signals. \n\\item Classification: CMs are labelled according to two possible classes: normal and altered breathing. Detection of anomalous respiratory states is achieved by semi-supervised learning,  measurement of the distance between a number of reference matrices learned during reference condition and the CM corresponding to a particular signal epoch. Since CMs do not lie in vector space, appropriate distance metrics must consider their natural geometry.\n\\item Translation: External application that converts the binary signal from the classifier to an alarm or ventilator command. \n\\end{enumerate}\n\nThe present paper focuses on the signal processing aspects of the BVI  --pre-processing, feature extraction and classification blocks--  as a detector of respiratory-related activities compatible with breathing discomfort. The framework is validated with EEG from healthy subjects under two breathing constraints to emulate patient-ventilator disharmony.  \n\nThe experimental protocol and data are detailed in Section \\ref{database}. Section \\ref{meth} describes the different signal processing blocks, and Section \\ref{setup} studies BVI settings for optimal detection of breathing discomfort. Section \\ref{res} provides the experimental results and evaluation of the proposed BVI. Finally, we conclude the paper with a discussion in Section \\ref{concl}.\n\n\n\\section{Database}\n\\label{database}\nThe database is composed of nine healthy subjects (21 - 29 years; 5 women) with no prior experience with respiratory or neurophysiology experiments (for more details see \\cite{hudson2015}). According to the declaration of Helsinki, written informed consent was obtained from each subject after explanation of the study, which was approved by the local institutional ethics committee (Comit\\'e de Protection des Personnes Ile-de-France VI, Groupe Hospitali\\`ere Piti\\'e-Salp\\^etri\\`ere, Paris, France).  \n\nSubjects were sitting in a comfortable chair and breathed continuously through a mouthpiece. They were asked to avoid body and head movements. They were distracted from the experimental context by watching a movie during the entire experiment, on a screen placed in front of them. To minimize emotional interference, the movie was a neutral animal documentary.  \n\nElectroencephalographic activity was recorded via surface electrodes (Acticap, BrainProducts GmbH, Germany) using 32 electrodes according to the standard 10-20 montage and sampled at 2500 Hz. Impedance between electrodes and skin were set below 5 k$\\Omega$.  The mouthpiece was connected to a pneumotachograph (Hans Ruldoph Inc., MO, USA) and a two-way valve to measure airflow and attached, when required, an inspiratory load (range 18-25 cmH20).  \n\nThe experiment was designed to activate cortical regions by altered breathing and consisted of three parts:\n\\begin{enumerate}\n\\item Normal, spontaneous ventilation (SV condition). Breathing is controlled automatically by the autonomous nervous system without cortical contribution.\n\\item Voluntary brisk inhalations or sniffs (SN condition). Breathing movements are planned before execution, thus motor and pre-motor cortical regions are solicited. \n\\item Inspiratory loaded breathing (LD condition). Ventilatory muscles perform a supplementary effort to overcome an inspiratory threshold load to maintain adequate air flow, a condition known to engage cortical networks.\n\\end{enumerate}\n\nIn contrast to the SV condition, where breathing is comfortable, LD is associated with respiratory discomfort. In a clinical context, SV would correspond to patient-ventilator harmony, whereas LD condition would correspond to patient-ventilator disharmony. SN can be considered as a positive control condition where cortical control is expected. For all subjects, 10 minutes of EEG was recorded for each condition.\n\n\n\\section{Methods}\n\\label{meth}\n\n\\subsection{Pre-processing}\n\\label{subsec:preproc}\nThe purpose of this block is to enhance motor cortical activity, whose main rhythms are between 8 and 24 Hz \\cite{pfurtscheller1999}. To this end, a linear phase FIR filter (to avoid group delay) with these cut-off frequencies was applied. Data segments with artifacts due to repetitive eye blinks and ocular movements were visually detected and removed from the original EEG dataset. Then, signals were down-sampled to 250 Hz and segmented in 5 second sliding, 50\\% overlapped windows to reduce computational cost in subsequent blocks. This time interval is in concordance with the slow breathing dynamics (a breath every 2.5 to 5 seconds).\n\n\\subsection{Feature extraction}\nAs mentioned above, the basis to classify the breathing state in the BVI are sample covariance matrices. The feature extraction block processed EEG data in epochs of $N_t$ samples and $N_c$ channels, as a matrix $\\mathbf{X}  \\in \\mathbb{R}^{N_t \\times N_c}$, and then transformed to a sample covariance matrix $\\mathbf{P} \\in \\mathbb{R}^{N_c \\times N_c}$. The latter was computed by the unbiased estimator:\n\n", "index": 1, "text": "\\begin{equation}\n\\mathbf{P} = \\frac{1}{N_t-1} \\mathbf{X} \\mathbf{X}^{T} \\: ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{P}=\\frac{1}{N_{t}-1}\\mathbf{X}\\mathbf{X}^{T}\\&gt;,\" display=\"block\"><mrow><mrow><mi>\ud835\udc0f</mi><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mi>t</mi></msub><mo>-</mo><mn>1</mn></mrow></mfrac><mo>\u2062</mo><mpadded width=\"+2.2pt\"><msup><mi>\ud835\udc17\ud835\udc17</mi><mi>T</mi></msup></mpadded></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nwhere $\\delta_i$ is the distance to the closest reference prototype, $\\delta_i = \\min_{k}  d (\\mathbf{P}_i, \\mathbf{C}_k)$; and $\\kappa>0$ is a scalar that can be adjusted to a performance criterion, like a statistical significance or a desired specificity/sensitivity value, for instance.\n\n\\subsubsection{Air flow based classification}\nAir flow is a commonly used measure to study breathing function in ventilated patients. \nThus, for comparison, this signal was used as a feature to classify the different ventilatory conditions as done with EEG.\nThe air flow-based feature is computed in $N_t$-sample windows as follows:\n\n", "itemtype": "equation", "pos": 16261, "prevtext": "\nwhere the superscript $T$ denotes the matrix transpose. \n\nBy construction, $\\mathbf{P}$ are symmetric and positive-definite matrices (SPD) that do not lie in a vector space but  on a Riemannian manifold \\cite{moakher2005}. Therefore, previous methods defined on a Euclidean structure are not longer adequate. The correct manipulation of these SPD matrices requires the application of Riemannian geometry concepts, described in Section \\ref{riemann}. \n\n\\subsection{Classification}\n\\label{classif}\n\\subsubsection{Classification of covariance matrices}\nThanks to the ability of covariance matrices to capture EEG spatial dynamics, a semi-supervised approach can be chosen to solve the classification problem in a BVI. \n\nIn semi-supervised algorithms, the availability of the labels from only one class is enough to classify instances from a second class, as the latter can be mapped in a different (distant) region of the space representation. In our framework,  motor cortex activation provoked during uncomfortable breathing should be different to that underlying normal, comfortable breathing (absence of motor cortical activity).\n\nThe objective of the classifier is to learn from $L$ data samples of the reference class SV  ($\\mathbf{X}_l^{(0)}, l=1 \\ldots L$) in order to label new trials $\\mathbf{X}$ in two classes, $\\mathcal{C}(\\mathbf{X}) = \\lbrace 0,1 \\rbrace $, which correspond to breathing comfort (SV condition) and discomfort (SN or LD conditions), respectively.\n  \nDuring the learning process, the algorithm first finds $K$ matrices, subsequently called prototypes, serving as reference to perform classification. Those prototypes constitute $K$ centers from the ensemble of covariance matrices $\\mathbf{P}_l^{(0)}$ and they are estimated by means of a general $K$-means clustering algorithm: \n \\begin{enumerate}\n\\item Initialize the prototypes $\\mathbf{C}_k$,  $k=1 \\ldots K$ by random selection of $K$ matrices from $\\mathbf{P}_l^{(0)}$,\n\\item For each sample covariance matrix, compute its distance $d$ to all the prototypes and assign it to the closest one in order to form the cluster $\\mathbf{S}_k$:\n\\begin{displaymath}\n\\mathbf{S}_k = \\left\\{ \\mathbf{P}_n: d(\\mathbf{P}_n, \\mathbf{C}_k)\\leqslant d(\\mathbf{P}_n, \\mathbf{C}_j)\\forall j, 1\\leqslant j \\leqslant K \\right\\}\n\\end{displaymath}\n\\item Update each prototype by averaging points in $\\mathbf{S}_k$ as \n\\begin{displaymath}\n\\mathbf{C}_k \\leftarrow {\\operatorname{arg\\,min}}_{\\mathbf{C}}\\sum_{\\mathbf{C}_i \\in \\mathbf{S}_k} d (\\mathbf{C}, \\mathbf{C}_i)\n\\end{displaymath}\nFor points lying in a vector space, $\\mathbf{C}_k$ corresponds to the arithmetic mean of points in $\\mathbf{S}_k$\n\\item Go to step (2) until convergence (e.g. the assignments no longer change) is achieved.\n \\end{enumerate}\n\nThe resulting prototypes $\\mathbf{C}_k$ represent the Class $0$, and are then used to classify the new unlabelled data $\\mathbf{X}_i$ (sub-index $i$ denotes the number of the $N_t$-sample window) according to:\n\n", "index": 3, "text": "\\begin{equation}\n\\label{eq:class}\n\\mathcal{C}(\\mathbf{X}_i) =\n  \\begin{cases}\n    0 & \\text{if }  \\delta_i  \\leq  \\kappa   \\\\\n    1 &  \\text{otherwise}\n  \\end{cases},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}(\\mathbf{X}_{i})=\\begin{cases}0&amp;\\text{if }\\delta_{i}\\leq\\kappa\\\\&#10;1&amp;\\text{otherwise}\\end{cases},\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc17</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><msub><mi>\u03b4</mi><mi>i</mi></msub></mrow><mo>\u2264</mo><mi>\u03ba</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>1</mn></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nwhere $AF(t)$ is the instantaneous amplitude of the air flow in $l/s$.\nDuring the training process, a set of $L$ scalars $\\alpha_l^{(0)}$ ($l=1 \\ldots L$) is used as a reference to perform classifications. Since $\\alpha \\in \\mathbb{R}$, the prototypes $q_k$ ($k=1 \\ldots K $), are simply given by splitting the values $\\alpha_l^{(0)}$  in $K$ intervals (i.e the $K$-quantiles). \n\nThen, the classifier associates $\\alpha_i$ ($i$ corresponding to the $i$-th sample window) to a label  $\\mathcal{C}(\\mathbf{X}) = \\lbrace 0,1 \\rbrace $ as done in (\\ref{eq:class}) using the Euclidean distance $\\delta_i$ for the one-dimensional case.  \n\n\\subsubsection*{Performance metrics}\n Classification performance was measured by the area under the curve (AUC) of the receiver operating characteristic (ROC). AUC values range from 0.5 (a random classification)  to 1 (perfect classification). All AUC values were computed by applying 10-fold cross validation, excluding the learning period in the classification. \n\n\\subsection{Computation with symmetric positive definite matrices}\n\\label{riemann}\nWithin an Euclidean framework, the $K$-means algorithm divides the dataset into groups and attempts to minimize the Euclidean distance between samples labeled to be in a cluster and a point designated as the arithmetic mean of that cluster. Nevertheless, the SPD manifold is not a linear space with the conventional matrix addition operation. A natural way to measure closeness on a manifold is by considering the geodesic distance between two points on the manifold~\\cite{bergerBOOK}. Such distance is defined as the length of the shortest curve connecting the two points.  As an example, consider the Earth\u00d5's surface as a manifold: the Riemannian distance between the two poles is given by a meridian, while the Euclidean distance corresponds to the straight line going through the Earth\u00d5's core from pole to pole.\n\nIn the space of SDP matrices, the clustering algorithm must minimize the geodesic distances between each point of the manifold (the covariance matrices $\\mathbf{P}_n$) and the reference matrix $\\mathbf{C}_k$. Each cluster center can be then obtained by an averaging process that employs the intrinsic geometrical structure of the underlying set.\n\nDerived from different geometrical, statistical or information-theoretic considerations, various distance measures have been proposed for the analysis of SPD matrices~\\cite{pennec2006, arsigny2006, dryden2009, vemuri2011, cherian2012}. Although many of these distances try to capture the non-linearity of SPD matrices, not all of them are geodesic distances.\n\nThe space of SPD matrices, $\\mathcal{P}_{N_c}$, constitutes a differentiable Riemannian manifold $\\mathcal{M}$ of dimension $Nc(Nc+1)/2$. At any point $\\mathbf{Q} \\in \\mathcal{P}_{N_c}$ there is a tangent Euclidean space, $T_{P_{N_c}}$. Let two points $\\mathbf{T}_1$ and $\\mathbf{T}_2$ be two points on the tangent space (e.g. the projection of two SPD matrices), the scalar product in the tangent space at $\\mathbf{Q}$ is defined by  \n\n", "itemtype": "equation", "pos": 17067, "prevtext": "\nwhere $\\delta_i$ is the distance to the closest reference prototype, $\\delta_i = \\min_{k}  d (\\mathbf{P}_i, \\mathbf{C}_k)$; and $\\kappa>0$ is a scalar that can be adjusted to a performance criterion, like a statistical significance or a desired specificity/sensitivity value, for instance.\n\n\\subsubsection{Air flow based classification}\nAir flow is a commonly used measure to study breathing function in ventilated patients. \nThus, for comparison, this signal was used as a feature to classify the different ventilatory conditions as done with EEG.\nThe air flow-based feature is computed in $N_t$-sample windows as follows:\n\n", "index": 5, "text": "\\begin{equation}\n\\alpha=  \\frac{1}{N_t}  \\sum_{t=1}^{N_t} \\left| AF(t)  \\right| ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\alpha=\\frac{1}{N_{t}}\\sum_{t=1}^{N_{t}}\\left|AF(t)\\right|,\" display=\"block\"><mrow><mrow><mi>\u03b1</mi><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mi>t</mi></msub></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>t</mi></msub></munderover><mrow><mo>|</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>F</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>|</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\n that depends on point $\\mathbf{Q}$.\n\nThe logarithmic map that locally projects a covariance matrix $\\mathbf{P}$ onto the tangent plane is given by:\n\n", "itemtype": "equation", "pos": 20208, "prevtext": "\nwhere $AF(t)$ is the instantaneous amplitude of the air flow in $l/s$.\nDuring the training process, a set of $L$ scalars $\\alpha_l^{(0)}$ ($l=1 \\ldots L$) is used as a reference to perform classifications. Since $\\alpha \\in \\mathbb{R}$, the prototypes $q_k$ ($k=1 \\ldots K $), are simply given by splitting the values $\\alpha_l^{(0)}$  in $K$ intervals (i.e the $K$-quantiles). \n\nThen, the classifier associates $\\alpha_i$ ($i$ corresponding to the $i$-th sample window) to a label  $\\mathcal{C}(\\mathbf{X}) = \\lbrace 0,1 \\rbrace $ as done in (\\ref{eq:class}) using the Euclidean distance $\\delta_i$ for the one-dimensional case.  \n\n\\subsubsection*{Performance metrics}\n Classification performance was measured by the area under the curve (AUC) of the receiver operating characteristic (ROC). AUC values range from 0.5 (a random classification)  to 1 (perfect classification). All AUC values were computed by applying 10-fold cross validation, excluding the learning period in the classification. \n\n\\subsection{Computation with symmetric positive definite matrices}\n\\label{riemann}\nWithin an Euclidean framework, the $K$-means algorithm divides the dataset into groups and attempts to minimize the Euclidean distance between samples labeled to be in a cluster and a point designated as the arithmetic mean of that cluster. Nevertheless, the SPD manifold is not a linear space with the conventional matrix addition operation. A natural way to measure closeness on a manifold is by considering the geodesic distance between two points on the manifold~\\cite{bergerBOOK}. Such distance is defined as the length of the shortest curve connecting the two points.  As an example, consider the Earth\u00d5's surface as a manifold: the Riemannian distance between the two poles is given by a meridian, while the Euclidean distance corresponds to the straight line going through the Earth\u00d5's core from pole to pole.\n\nIn the space of SDP matrices, the clustering algorithm must minimize the geodesic distances between each point of the manifold (the covariance matrices $\\mathbf{P}_n$) and the reference matrix $\\mathbf{C}_k$. Each cluster center can be then obtained by an averaging process that employs the intrinsic geometrical structure of the underlying set.\n\nDerived from different geometrical, statistical or information-theoretic considerations, various distance measures have been proposed for the analysis of SPD matrices~\\cite{pennec2006, arsigny2006, dryden2009, vemuri2011, cherian2012}. Although many of these distances try to capture the non-linearity of SPD matrices, not all of them are geodesic distances.\n\nThe space of SPD matrices, $\\mathcal{P}_{N_c}$, constitutes a differentiable Riemannian manifold $\\mathcal{M}$ of dimension $Nc(Nc+1)/2$. At any point $\\mathbf{Q} \\in \\mathcal{P}_{N_c}$ there is a tangent Euclidean space, $T_{P_{N_c}}$. Let two points $\\mathbf{T}_1$ and $\\mathbf{T}_2$ be two points on the tangent space (e.g. the projection of two SPD matrices), the scalar product in the tangent space at $\\mathbf{Q}$ is defined by  \n\n", "index": 7, "text": "\\begin{equation}\n\\label{e1}\n\\langle \\mathbf{T}_1,\\mathbf{T}_2 \\rangle_\\mathbf{Q} = {\\operatorname{tr}} (\\mathbf{T}_1\\mathbf{Q}^{-1}\\mathbf{T}_2\\mathbf{Q}^{-1}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\langle\\mathbf{T}_{1},\\mathbf{T}_{2}\\rangle_{\\mathbf{Q}}={\\operatorname{tr}}(%&#10;\\mathbf{T}_{1}\\mathbf{Q}^{-1}\\mathbf{T}_{2}\\mathbf{Q}^{-1}),\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>\ud835\udc13</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc13</mi><mn>2</mn></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mi>\ud835\udc10</mi></msub><mo>=</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc13</mi><mn>1</mn></msub><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mi>\ud835\udc13</mi><mn>2</mn></msub><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nwhere $\\mathrm{logm}$ is the matrix logarithm operator. Projecting SDP matrices onto $T_{P_{N_c}}$ is advantageous because this tangent space is Euclidean and distance computations in the manifold can be well approximated by Euclidean distances in $T_{P_{N_c}}$. \n\nThe inverse operation that projects a point $\\mathbf{S_Q}$ of the tangent space back to the manifold $\\mathcal{M}$ is given by the exponential mapping:\n\n", "itemtype": "equation", "pos": 20533, "prevtext": "\n that depends on point $\\mathbf{Q}$.\n\nThe logarithmic map that locally projects a covariance matrix $\\mathbf{P}$ onto the tangent plane is given by:\n\n", "index": 9, "text": "\\begin{equation}\n\\label{e2}\n\\mathrm{Log}_\\mathbf{Q} (\\mathbf{P}) = \\mathbf{S_Q} = \\mathbf{Q}^{\\frac{1}{2}} \\mathrm{logm} (\\mathbf{Q}^{-\\frac{1}{2}} \\mathbf{P} \\; \\mathbf{Q}^{-\\frac{1}{2}}) \\mathbf{Q}^{\\frac{1}{2}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\mathrm{Log}_{\\mathbf{Q}}(\\mathbf{P})=\\mathbf{S_{Q}}=\\mathbf{Q}^{\\frac{1}{2}}%&#10;\\mathrm{logm}(\\mathbf{Q}^{-\\frac{1}{2}}\\mathbf{P}\\;\\mathbf{Q}^{-\\frac{1}{2}})%&#10;\\mathbf{Q}^{\\frac{1}{2}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>Log</mi><mi>\ud835\udc10</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mi>\ud835\udc12</mi><mi>\ud835\udc10</mi></msub><mo>=</mo><mrow><msup><mi>\ud835\udc10</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo>\u2062</mo><mi>logm</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>\ud835\udc0f</mi></mpadded><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\n\nIn this paper, we have employed the two most widely used distance measures in the context of Riemannian manifolds: the affine-invariant distance~\\cite{pennec2006} and the log-Frobenius distance, also referred to as log-Euclidean distance ~\\cite{arsigny2006}. For comparative purposes, we have also used an Euclidean metric.\n\n\\subsubsection{The Euclidean metric}\nOn the space of real square matrices, we have the Frobenius inner product $\\langle \\mathbf{P}_1,\\mathbf{P}_2 \\rangle={\\operatorname{tr}}(\\mathbf{P}_1^T\\mathbf{P}_2)$ and the associated metric:\n\n", "itemtype": "equation", "pos": 21180, "prevtext": "\nwhere $\\mathrm{logm}$ is the matrix logarithm operator. Projecting SDP matrices onto $T_{P_{N_c}}$ is advantageous because this tangent space is Euclidean and distance computations in the manifold can be well approximated by Euclidean distances in $T_{P_{N_c}}$. \n\nThe inverse operation that projects a point $\\mathbf{S_Q}$ of the tangent space back to the manifold $\\mathcal{M}$ is given by the exponential mapping:\n\n", "index": 11, "text": "\\begin{equation}\n\\mathrm{Exp}_\\mathbf{Q} (\\mathbf{S_Q}) = \\mathbf{P} = \\mathbf{Q}^{\\frac{1}{2}} \\mathrm{expm} (\\mathbf{Q}^{-\\frac{1}{2}} \\mathbf{S_Q} \\; \\mathbf{Q}^{-\\frac{1}{2}}) \\mathbf{Q}^{\\frac{1}{2}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\mathrm{Exp}_{\\mathbf{Q}}(\\mathbf{S_{Q}})=\\mathbf{P}=\\mathbf{Q}^{\\frac{1}{2}}%&#10;\\mathrm{expm}(\\mathbf{Q}^{-\\frac{1}{2}}\\mathbf{S_{Q}}\\;\\mathbf{Q}^{-\\frac{1}{2%&#10;}})\\mathbf{Q}^{\\frac{1}{2}}\" display=\"block\"><mrow><mrow><msub><mi>Exp</mi><mi>\ud835\udc10</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc12</mi><mi>\ud835\udc10</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi>\ud835\udc0f</mi><mo>=</mo><mrow><msup><mi>\ud835\udc10</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo>\u2062</mo><mi>expm</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>\u2062</mo><mpadded width=\"+2.8pt\"><msub><mi>\ud835\udc12</mi><mi>\ud835\udc10</mi></msub></mpadded><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc10</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nGiven a set of $m$ real square matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, their arithmetic mean is given by:\n\n", "itemtype": "equation", "pos": 21956, "prevtext": "\n\nIn this paper, we have employed the two most widely used distance measures in the context of Riemannian manifolds: the affine-invariant distance~\\cite{pennec2006} and the log-Frobenius distance, also referred to as log-Euclidean distance ~\\cite{arsigny2006}. For comparative purposes, we have also used an Euclidean metric.\n\n\\subsubsection{The Euclidean metric}\nOn the space of real square matrices, we have the Frobenius inner product $\\langle \\mathbf{P}_1,\\mathbf{P}_2 \\rangle={\\operatorname{tr}}(\\mathbf{P}_1^T\\mathbf{P}_2)$ and the associated metric:\n\n", "index": 13, "text": "\\begin{equation}\n\\label{dE}\nd_E(\\mathbf{P}_1,\\mathbf{P}_2) = \\| \\mathbf{P}_1 - \\mathbf{P}_2\\|_F \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"d_{E}(\\mathbf{P}_{1},\\mathbf{P}_{2})=\\|\\mathbf{P}_{1}-\\mathbf{P}_{2}\\|_{F}\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mi>E</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc0f</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>-</mo><msub><mi>\ud835\udc0f</mi><mn>2</mn></msub></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\n\n\\subsubsection{The affine invariant Riemannian metric}\n Using~(\\ref{e1}), the Riemannian distance between two SPD matrices can be computed as:\n\n", "itemtype": "equation", "pos": 22202, "prevtext": "\nGiven a set of $m$ real square matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, their arithmetic mean is given by:\n\n", "index": 15, "text": "\\begin{equation}\n\\label{MdE}\n\\mathfrak{M}_{E}(\\mathbf{P}_1, \\ldots ,\\mathbf{P}_m) = \\frac{1}{m}\\sum_{k=1}^{m} \\mathbf{P}_k.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\mathfrak{M}_{E}(\\mathbf{P}_{1},\\ldots,\\mathbf{P}_{m})=\\frac{1}{m}\\sum_{k=1}^{%&#10;m}\\mathbf{P}_{k}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\ud835\udd10</mi><mi>E</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>\ud835\udc0f</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>\ud835\udc0f</mi><mi>k</mi></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nThis metric has several useful theoretical properties: it is symmetric and satisfies the triangle inequality. Furthermore, it is scale, rotation and inversion invariant~\\cite{arsigny2006, pennec2006}.\n\nTo find the mean of a set of $m$ covariance matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, the distance $d_R$ needs to be applied in the following expression \\cite{moakher2005, arsigny2007}:\n\n", "itemtype": "equation", "pos": 22485, "prevtext": "\n\n\\subsubsection{The affine invariant Riemannian metric}\n Using~(\\ref{e1}), the Riemannian distance between two SPD matrices can be computed as:\n\n", "index": 17, "text": "\\begin{equation}\n\\label{dR}\nd_R(\\mathbf{P}_1,\\mathbf{P}_2) = \\| \\mathrm{logm}(\\mathbf{P}_2^{-\\frac{1}{2}} \\mathbf{P}_1 \\mathbf{P}_2^{-\\frac{1}{2}}) \\|_F \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"d_{R}(\\mathbf{P}_{1},\\mathbf{P}_{2})=\\|\\mathrm{logm}(\\mathbf{P}_{2}^{-\\frac{1}%&#10;{2}}\\mathbf{P}_{1}\\mathbf{P}_{2}^{-\\frac{1}{2}})\\|_{F}\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mi>R</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc0f</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mi>logm</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\ud835\udc0f</mi><mn>2</mn><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>\u2062</mo><msubsup><mi>\ud835\udc0f</mi><mn>2</mn><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nAlthough no closed-form expression exists, this (geometric) mean can be computed efficiently\nusing an iterative algorithm. The geometric mean in $\\mathcal{P}_{N_c}$ converges into a unique solution \\cite{karcher1977} and can be computed efficiently by the algorithm described in~\\cite{fletcher2004}.\n\n\\subsubsection{The log-Euclidean Riemannian metric}\nThe log-Euclidean  distance between two SPD matrices is given by~\\cite{arsigny2006}: \n\n", "itemtype": "equation", "pos": 23068, "prevtext": "\nThis metric has several useful theoretical properties: it is symmetric and satisfies the triangle inequality. Furthermore, it is scale, rotation and inversion invariant~\\cite{arsigny2006, pennec2006}.\n\nTo find the mean of a set of $m$ covariance matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, the distance $d_R$ needs to be applied in the following expression \\cite{moakher2005, arsigny2007}:\n\n", "index": 19, "text": "\\begin{equation}\n\\label{MdR}\n\\mathfrak{M}_R(\\mathbf{P}_1, \\ldots ,\\mathbf{P}_m) = {\\operatorname{arg\\,min}}_{\\mathbf{P} \\in \\mathcal{P}_{N_c}} \\sum_{k=1}^{m} d_R(\\mathbf{P}_k,\\mathbf{P})^2.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\mathfrak{M}_{R}(\\mathbf{P}_{1},\\ldots,\\mathbf{P}_{m})={\\operatorname{arg\\,min%&#10;}}_{\\mathbf{P}\\in\\mathcal{P}_{N_{c}}}\\sum_{k=1}^{m}d_{R}(\\mathbf{P}_{k},%&#10;\\mathbf{P})^{2}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\ud835\udd10</mi><mi>R</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>\ud835\udc0f</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>\ud835\udc0f</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><msub><mi>N</mi><mi>c</mi></msub></msub></mrow></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>d</mi><mi>R</mi></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mi>k</mi></msub><mo>,</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\nThis metric maps SPD matrices to a flat Riemannian space (of zero curvature) so that classical Euclidean computations can be applied~\\cite{arsigny2006}. Under this metric, the geodesic distance on the manifold corresponds to a Euclidean distance in the tangent space at the identity matrix. This metric is easy to compute and preserves some important theoretical properties, such as scale, rotation and inversion invariance~\\cite{arsigny2006, cherian2012}.\n\nGiven a set of $m$ covariance matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, their log-Euclidean mean exists and is uniquely determined by~\\cite{arsigny2006}:\n\n", "itemtype": "equation", "pos": 23712, "prevtext": "\nAlthough no closed-form expression exists, this (geometric) mean can be computed efficiently\nusing an iterative algorithm. The geometric mean in $\\mathcal{P}_{N_c}$ converges into a unique solution \\cite{karcher1977} and can be computed efficiently by the algorithm described in~\\cite{fletcher2004}.\n\n\\subsubsection{The log-Euclidean Riemannian metric}\nThe log-Euclidean  distance between two SPD matrices is given by~\\cite{arsigny2006}: \n\n", "index": 21, "text": "\\begin{equation}\n\\label{dLE}\nd_{LE}(\\mathbf{P}_1,\\mathbf{P}_2) = \\| \\mathrm{Log}(\\mathbf{P}_1)-\\mathrm{Log}( \\mathbf{P}_2) \\|_F\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"d_{LE}(\\mathbf{P}_{1},\\mathbf{P}_{2})=\\|\\mathrm{Log}(\\mathbf{P}_{1})-\\mathrm{%&#10;Log}(\\mathbf{P}_{2})\\|_{F}\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mrow><mi>L</mi><mo>\u2062</mo><mi>E</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc0f</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mrow><mi>Log</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>Log</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.03022.tex", "nexttext": "\n\n\n\\begin{figure*}[th!] \n   \\centering\n   \\includegraphics[trim = 2cm 0cm 2cm 0cm,clip=true,width=\\linewidth]{dist_EEG_airFlow.pdf} \n   \n   \\caption{Example of $\\delta_i$ distances to the closest reference prototypes (with Log-Euclidean metric, $L=25$ and $K=3$) and the associated ROC curve obtained from a) EEG covariance matrices and b) air flow under SV (blue curve) and LD (red curve) conditions.}\n   \\label{fig:alpha_delta}\n\\end{figure*}\n\n\\subsubsection*{Detection with one-class SVMs}\nIn this paper, we have also evaluated the detection of altered respiratory states from EEG signals via an outlier detector based on the so-called one-class support vector machines (SVMs). One-class SVMs are a very popular machine learning technique used in semi-supervised settings of a variety of applications~\\cite{scholkopfBook}. In one-class SVMs (LIBSVM Toolbox), the support vector model is trained on data that has only one class, which represents the \\emph{normal} class. This model attempts to learn a decision boundary that achieves the maximum separation between the points and the origin. A one-class SVM firstly uses a transformation function defined by a kernel function to project the data into a higher dimensional space. The algorithm then learns a decision boundary that encloses the majority of the projected data, and that can be applied to the outliers detection problem. More details on the algorithmic aspects of one-class SVMs can be found in~\\cite{scholkopfBook}.\n\nTo guarantee the existence of a decision boundary we have used here a Gaussian kernel~\\cite{scholkopfBook}: $k(x_i,x_j)=\\exp^{\\|x_i-x_j\\|^2/\\sigma}$, where $x_i$ denotes the vector form of the upper triangular part of covariance matrix $\\mathbf{P}_i$, and the parameter $\\sigma$ set to be the median pairwise distances among training points~\\cite{quang2013}.\n\n\n\\section{BVI setup}\n\\label{setup}\n\n\\subsection{Channel selection}\n\\label{ch_selelct}\nIn brain computer interface design, the choice of the adequate number of sensors and their location is fundamental.  \nReducing the number of irrelevant electrodes avoids over-fitting and optimizes computational costs, but also improves patient comfort and reduces installation time.\n\nSeveral channel selection methods can be found in the literature to simplify the implementation of BCI. Common Spatial Pattern (CSP) is a popular technique that ranks channels based on their corresponding coefficients of the spatial filter~\\cite{ramoser2000, farquhar2006}.  Support vector machines have been also proposed to disregard task irrelevant channels by using a recursive feature elimination~\\cite{lal2004}. In~\\cite{lan2006} a channel selection technique based on mutual information maximization ranks the channels based on their correlation with class labels. \n\nIn this paper, we introduce an iterative channel selection procedure, the Common Highest Order Ranking (CHOrRa), for ranking the electrodes' contribution to classification performance. Combining ranking lists from all subjects, a general  configuration for a ready-to-use BVI device can be chosen. \n\nCHOrRa is performed in two steps. Firstly, an electrode ranking for each subject (intra-subject rankings) is found, a general ranking of the most significant electrodes is then computed over all subjects (inter-subject rankings). To estimate the intra-subject rank of electrodes, an iterative procedure was applied. From the set of $N_I$ central channels (labelled as  $s_i, i=1,2 \\ldots N_I$), the electrodes that contribute to the classification with the highest significance  were found as follows:\n\\begin{enumerate}\n\\item Compute $\\text{AUC}_0$ from the original ensemble of $N_I$ electrodes.\n\\item For each $i=1,2 \\ldots N_I$, data associated to channel $s_i$ is removed and  classification performances $\\text{AUC}_i$ are found.\n\\item Discard $s_k$ leading to the lowest $\\text{AUC}_i$ from the list of labels.\n\\item Update $\\text{AUC}_0 = \\text{AUC}_k$ and go to step 1 until the number of remaining electrodes is 2 (the minimal dimension to compute a covariance matrix).\n\\end{enumerate}\n\nAt the end of this procedure, a list of the best $N_I$ electrodes in terms of classification performances is provided for a particular subject.  \n\n\\subsubsection*{Channel ranking aggregation}\nFor each channel, the first rank aggregation method used here~\\cite{kolde2012} determines electrode position in the ranked list, compared to a null model where all the lists are randomly shuffled. Based on order statistics, this algorithm assigns a $p$-value to each electrode in the aggregated list describing the rank improvement compared to expected (a score of $1$ is assigned to channels that are preferentially ranked at the top of all lists). The procedure only takes into account the best rank, thus providing a robust re-ordering of elements~\\cite{kolde2012}. \n\nAlthough the above method is computationally efficient and statistically robust, we have also used a classical positional method (an average ranking), where the total score of an electrode is given by the arithmetic mean of the positions in which the channel appears in each ranking list. \n\nTo increase  rank robustness, several learning periods were used. Hence, after obtaining a set of $V$ lists ($V$-fold cross validation) per subject, the intra-subject ranking was computed according to a rank aggregation criterion applied to the $V$ lists of electrode rankings.\n\nFinally, a channel ranking aggregation procedure is applied to all intra-subject ranking lists to obtain a common and unique inter-subject electrode ranking.\n\n\\subsection{Choice of prototypes and learning time}\n\\label{ch_prt}\nAs mentioned above, the prototypes are local centers that represent the space defined by $\\mathbf{P}_l^{(0)}$. To this end, we adopted the $K$ prototypes provided by the general $K$-means algorithm as the centers $\\mathbf{C}_k$ introduced in Section \\ref{classif}. The structure of the manifold defined by $\\mathbf{P}_l^{(0)}$ is unknown. Covariance matrices may be organized in a compact, uniform manner so a few centers are enough to correctly represent the Class 0. On the contrary, $\\mathbf{P}_l^{(0)}$ may have a complex distribution and need more centers to be correctly represented. Therefore, in order to achieve good classification, there may be an optimal number of prototypes.\n\nTo satisfactorily exploit the BVI, previous knowledge about the learning time needed to train the classifier is necessary. Limited learning time may result in a small number of covariance matrices $L$ and hence, in a poor representation of the space defined by normal breathing. Moreover, the clustering algorithm would provide a less accurate center when few CMs are available. On the other hand, the learning time should meet clinical requirements, as long set-up times in these environments are impractical.\n\nSince the number of covariance matrices needed to represent Class 0 may impact on the optimal number of prototypes, the classification performance has to be computed by modifying $L$ and $K$. In next section, these parameters are tested experimentally to find the optimal values.\n\n\n\\section{Results}\n\\label{res}\nWe assessed the most relevant electrodes in the proposed BVI, starting from a set of 14 central electrodes from the original 32-electrode montage. Retained cortical activities include electrodes from primary sensorimotor cortices (C3, C4),  higher-level secondary and association cortices (Fz and Cz), pre-parietal (CP1 and CP2) and pre-frontal cortices (F3, F4), pre-motor and supplementary motor areas (FC1, FC2), central (FC5 and FC6) and parieto-occipital areas (CP5 and CP6). The choice of these areas follows results of earlier experiments describing the cortical networks elicited during respiratory load compensation~\\cite{macefield1991, raux2007, leupoldt2010, raux2013, morawiec2015}. \n\nThis section shows and discusses the results of applying the BVI to detect altered respiratory condition (LD or SN) after learning a reference period of normal breathing (SV). To find the best settings in the classification block,\nseveral tests assessed the discrimination power of the classifier calculating the distances ($\\delta_i$) to the reference prototypes from EEG and the air flow . Distances were then employed to estimate the areas under ROC curves (AUC) as a measure of the classifier's performance.\n\nFirstly, Euclidean, Riemannian and Log-euclidean distances were compared to select the best metric in term of classification performances. This metric was then used for evaluating the optimal electrode configuration, the impact of learning time, and the number of prototypes. \n\n\n\\begin{figure}[t!] \n   \\centering\n   \\includegraphics[trim = 0cm 0.65cm 1cm 0.75cm,clip=true,width=\\linewidth]{boxplots14el_ini_svm_mean.pdf} \n   \\caption{BVI performances for detecting LD (blue) and SN (red) conditions. Boxplots display the areas under ROC curves (AUCs) for detectors using the EEG (three different metrics and SVMs) and air flow (with $L=25$ and $K=3$). Asterisks (*) denote the mean AUC values across subjects.}\n   \\label{fig:AUC_ini}\n\\end{figure} \n\n\\subsection{Choice of the distance metric}\nThe first test used the 14 most central electrodes, thus covariance matrices were obtained from EEG signals $\\mathbf{X}  \\in \\mathbb{R}^{1250 \\times 14}$. The classifier settings were $L=25$ and $K=3$. \n\nFig. \\ref{fig:AUC_ini} clearly shows that the best performing metric is the Log-Euclidean, which provided slightly better AUC values than Riemannian distances in LD condition ($\\text{AUC}=0.91$ versus $\\text{AUC}=0.90$) and almost equal AUC values ($\\text{AUC}\\approx0.9$) for the SN condition. The classification performances for SN had the largest variability probably due to the discontinuous occurrence of sniffs (one every two breaths). Although the performances of Log-Euclidean are similar to those obtained by the affine invariant  Riemannian metric, the former is advantageous from the computational point of view due to its reduced algorithmic complexity (CPU times were\\footnote{Using a 2.8GHz dual-core Intel Core i7 processor, 16GB of memory}, on average, 3 time faster).   \n\nThe analysis of $\\text{AUC}$ values also proves that Riemannian geometry is a better framework to classify EEG covariance matrices, than the outlier detector based on SVMs. We notice, however, that the one-class SVMs detector provided better results than the classifier with Euclidean structure (mean values are $\\text{AUC}= 0.82$ versus $\\text{AUC}\\leqslant0.77$). Compared to detectors based on the air-flow signal, AUC values of SVM detector where also higher in LD condition (mean $\\text{AUC}=0.82$ versus $\\text{AUC}=0.76$), but not in SN (mean $\\text{AUC}=0.82$ versus $\\text{AUC}=0.91$).\n\nClassification performances obtained from EEG signals was superior than those obtained from air flow. The classifier based on air flow provided better classification in SN than LD (mean AUC values are $\\text{AUC}=0.95$ versus $\\text{AUC}=0.77$) because of the characteristic large pattern of air flow during sniffs. Nevertheless such a perturbation (SN) in airflow is unlikely in mechanically ventilated patients. \n\nEuclidean distances provided the lowest average classification rates and the most unstable AUC values, demonstrating the limitation of linear matrix operators (i.e. the arithmetic mean) for EEG covariance matrix classification. \n\n\n\\begin{figure*}[ht!] \n   \\centering\n   \\resizebox{0.97\\linewidth}{!}{\\includegraphics{AUC_vs_removedElectrodesV2.pdf}} \n    \\caption{Classification performance when individual optimization (a) or a common electrode set-up (b and c) are applied. AUC values are expressed as mean (solid lines) $\\pm$ standard error (shadowed areas). }\n    \\label{fig:AUC_elect}\n    \\end{figure*} \n\n\\subsection{Choice of electrodes}\nAccording to the CHOrRA procedure to find the best channels from the initial set-up (c.f Section \\ref{ch_selelct}), we first found  intra-subject rankings and then applied a global rank aggregation. As described above, we employed AUC as the measure of classification performance and performed the rankings from $V$=10 lists (i.e. 10 different learning periods) of each subject.\n\n\\subsubsection{Intra-subject optimal selection}\nThe classification results are shown in Fig.~\\ref{fig:AUC_elect}-(a), where AUC values are expressed as a function of the number of removed electrodes. For the Log-Euclidean metric, the evolution of the curves during the optimization process display a slight increasing tendency of AUC when electrodes contributing negatively to classifications are removed. Classification performances decrease with configurations smaller than six electrodes. \n\nResults show that a customized individual selection of electrodes can provide an optimal AUC within a single subject. \nUsing an intra-subject optimization, AUC rates can be improved up to 0.95 using the six most significant electrodes.  \n\nAs shown in different plots of Fig.~\\ref{fig:AUC_elect}, for a configuration with more than three electrodes, the Log-Euclidean metric performs better than the Euclidean distance at every optimization step. These results support the idea that large spatio-temporal information of the EEG (as reflected by the sample covariance matrices) is optimally captured when the intrinsic geometry structure of the underlying data is taken into account.\n\n\\subsubsection{Inter-subject optimal selection}\nAs the electrode positions leading to the maximal AUC in a particular subject isn't necessarily the same for another, we studied a common electrodes configuration that could be shared by any user. This general electrode set-up is more pertinent in a clinical context as an EEG headset could be interfaced promptly. \n\nTo find a general ranking of electrodes we applied the rank aggregation procedure to the lists of sorted electrodes of all subjects  (See Table \\ref{tab:rankings}). Following the rank of the final general list, we computed the AUC values by reducing the initial 14-electrode set to two sensors (see Fig. \\ref{fig:AUC_elect}-(b-c)). \n\nResults from the two ranking aggregation procedures indicate that a good compromise between a reduced number of electrodes and reasonable classifications can be reached by selecting the best 6 electrodes obtained by the CHOrRa procedure ($\\text{AUC} \\geqslant 0.82$ for both LD and SN conditions). Interestingly, for general configurations with more than three electrodes, Log-Euclidean metric still performs better than the Euclidean distance.\n\nThe aggregated CHOrRa scores displayed in Fig.~\\ref{fig:heads} indicate scalp zones with more influence for the classification of both SN and LD conditions. Although both optimization procedures (robust rank aggregation and rank averaging) provide similar classification performance, the spatial concentration of discriminating scalp regions obtained by the robust aggregation method is larger than those obtained by a classical averaging rank procedure. \n\nThe spatial distribution of scores and the rankings in Table~\\ref{tab:rankings} suggest that discrimination of the LD condition is better if the electrode configuration contains the pre-motor and supplementary motor area (FC1), the fronto-central region (FC6) and the supramarginal gyrus (the part covered by CP6 electrode). On the other hand, SN condition is better discriminated if electrodes include the supplementary motor area (FC1), the central motor area Cz and part of the somatosensory association cortex (covered by the electrode CP1). \n\n\\begin{table}[hb!]\n\\tiny\n\\caption{Electrode rankings, from more to less relevant, from classifications of loaded breathing (LD) and voluntary sniffs (SN) conditions.}\n\\centering\n\\begin{tabular}{ccccccccc}\n & \\multicolumn{4}{c}{Robust aggregation} & \\multicolumn{4}{c}{Mean rank} \\\\ \n\\hline \nRanking     & \\multicolumn{2}{c}{LD} & \\multicolumn{2}{c}{SN} &\\multicolumn{2}{c}{LD} & \\multicolumn{2}{c}{SN} \\\\ \n\\hline \n    & Sensor & Score & Sensor & Score & Sensor  \t& Score  & Sensor & Score \\\\ \n    \\cline{2-9}\n1  & FC1 \t& 1\t\t\t& CP1 \t& 1\t\t\t&\tFC1 \t\t& 0.606 \t\t & Cz\t& 0.677 \\\\ \n2  & FC6 \t& 1 \t\t\t& Cz\t\t& 1\t\t\t& \tFC6  \t& 0.604  \t \t& CP1 \t& 0.620 \\\\ \n3  & CP6\t& 1\t\t\t& FC1 \t& 1\t\t\t& \tCz \t\t& 0.588 \t\t & FC1\t& 0.607 \\\\ \n4  & F4\t\t& 1 \t\t\t& C3\t\t& 0.997\t& \tCP2 \t\t& 0.577 \t\t & F3\t& 0.604 \\\\ \n5  & CP1 \t& 0.991\t& C4\t\t& 0.953\t& \tF3 \t\t& 0.576 \t\t & CP2\t& 0.549 \\\\ \n6  & FC5\t& 0.991\t& CP2\t& 0.834\t&\tCP6   \t& 0.566\t\t & C3\t& 0.536 \\\\ \n7  & FC2\t& 0.893\t& FC2\t& 0.810\t&   F4 \t\t& 0.531\t \t & F4\t& 0.514 \\\\ \n8  & C4\t& 0.804\t& F3\t\t& 0.804\t&   C4 \t\t& 0.530\t\t & FC6 \t& 0.507 \\\\ \n9  & Cz\t\t& 0.804\t& FC5\t& 0.798\t&   Fz   \t& 0.530 \t\t & CP6\t& 0.498 \\\\ \n10 & Fz   & 0.804\t& Fz\t\t& 0.532\t&   FC5   \t& 0.523\t \t & C4\t& 0.496 \\\\ \n11 & F3\t& 0.621\t& F4\t\t& 0.457\t&   CP1   \t& 0.500\t \t& FC5\t& 0.493 \\\\ \n12 & CP2\t& 0.456\t& CP6\t& 0.279\t&   C3 \t\t& 0.485\t \t & CP5 \t& 0.473 \\\\ \n13 & C3\t& 0.188\t& CP5\t& 0.033\t&   FC2 \t& 0.481\t \t & FC2 \t& 0.461 \\\\ \n14 & CP5\t& 0.001\t& FC6\t& 0.011\t&   CP5   \t& 0.396\t \t & Fz \t& 0.457 \\\\ \n\\hline \n\\end{tabular} \n\\label{tab:rankings}\n\\end{table}\n\n\n\n\\begin{figure}[ht!] \n   \\centering\n   \\resizebox{0.75\\linewidth}{!}{\\includegraphics{chorrankingsCORREGIDOS.pdf}} \n   \n\\caption{Topographic plots of influence scores of channels in the classifications of LD and SN conditions (with Log-Euclidean metric, $L=25$ and $K=3$). Warm colors correspond to channels preferentially ranked at the top of all lists. See Table~\\ref{tab:rankings} for details about the ranking associated to a particular electrode.}\n    \\label{fig:heads}\n    \\end{figure} \n       \n\\subsection{Training time vs. number of prototypes}\nOnce the effect of different metrics and channels configurations were assessed, we tested the influence of the learning parameters, i.e. the number of covariance matrices used as a reference ($L$) and the number of prototypes ($K$) used to characterize the reference class.\n\nFor this, we assessed classification performance for different values of $K$, ranging from 1 to 7 and  and for different number of learning matrices, $L$, from 20 to 40 in steps of 5. This procedure was also repeated with 10-fold cross validation for LD and SN conditions. Three different electrode configurations were tested: 1) the initial 14-electrode configuration, 2) a selection of 6 electrodes optimized for every subject and 3) a general configuration with the best 6 electrodes after applying the global channel selection procedure. \n\nResults are depicted in the color maps of Fig. \\ref{fig:AUC_KL}, where average AUC values are expressed as a function of $K$ and $L$. Importantly, this figure shows a small effect of both parameters on overall classification rates, regardless of the electrode configuration. In view of these findings, the choice of a small number of prototypes ($K \\le 3$) and a short learning time ($L=20$ CMs) is an advantageous trade-off between computational complexity and classification performances, even for a common electrode configuration setting.\n\n\n\\begin{figure}[hb!] \n   \\centering\n  \\resizebox{\\linewidth}{!}{\\includegraphics[trim = 2.3cm 0cm 1.8cm 0cm,clip=true,width=\\linewidth]{AUC_K_L_LD_SNbis.pdf}}\n      \\caption{AUC values (colors in boxes) against the number of prototypes ($K$ centroids) and the learning time ($L$ CMs) obtained for classification of the LD and SN conditions with the Log-Euclidean metrics. The ladder-shaped grids are explained by the limitation of the clustering algorithm to compute reliable centroids when few CMs are available.}\n    \\label{fig:AUC_KL}\n\\end{figure}\n       \n\n\\section{Conclusion}\n\\label{concl}\nThis paper focuses on an important class of applications for BCI: monitoring of respiratory states from EEG signals. This work provides the first extensive evaluation of what could be a\tbrain-ventilator interface (BVI) designed to detect altered respiratory conditions in patients on mechanical ventilation. The novelty of our proposal relies on an EEG-based approach to identify a cortical signature of breathing discomfort. The proposed framework also involves concepts of Riemannian geometry in the manifold of covariance matrices, which are used as EEG signal descriptors. From a clinical perspective, the present work also introduces a completely non-invasive tool compared to techniques that use invasive measures (an esophageal catheter) of diaphragm EMG activity to optimise patient-ventilator interaction~\\cite{Sinderby1999}. \n\nThe proposed system aims at detecting abnormal spatio-temporal patterns of EEG activities during the altered respiratory behaviors. Due to its technical simplicity (portable, non-invasive, with few electrodes and real-time) the proposed BVI can be highly operable in clinical settings of intensive care units as well as in custom-designed systems.\n\nCompared to classification based on air-flow, our findings demonstrate a better discriminatory power of the covariance patterns of EEG signals to detect a patient-ventilator disharmony ($\\text{AUC} = 0.91$ versus $\\text{AUC} = 0.77$, in average, for the loaded breathing condition). The analysis of AUC values suggests that Riemannian geometry is a better framework to manipulate covariance matrices, even with a few number of channels, than classical matrix operators with an Euclidean structure. We notice that one-class SVMs detector also provides better results than a classifier with an Euclidean metrics. \n\nThe proposed recursive channel selection procedure may provide a subject-customized BVI setting with a reduced number of six channels and maintained performance ($\\text{AUC} \\approx 0.95$). If the channel configuration includes the most significant electrodes across subjects, classification rates are reduced compared to customized optimization. Nevertheless, this general setting provides a good compromise between a reduced number of electrodes (6 channels) and reasonable classification performances ($\\text{AUC}\\geqslant 0.82$), which is advantageous in general clinical practice where ready-to-use devices are necessary. Interestingly, overall classification performance do not significantly depend on the other parameters of the classifier (learning time and number of prototypes). An optimization of control parameters for other SVMs models might increase classification performances but this subject is beyond the scope of our paper.\n\nIn general, characterization of brain networks provides meaningful insights into the functional organization of cortical activities underlying breathing control and respiratory diseases. Our study supports the hypothesis of a strong correlation between voluntary and compensatory respiratory efforts and the activation of cortical circuits~\\cite{macefield1991, raux2007, leupoldt2010}. Indeed, our findings suggest that functional \ninteractions between central regions overlying pre-motor and primary motor areas, in particular the supplementary motor area, and the somatosensory association cortex (the part covered by the electrode CP1) may play a role on mechanisms of inspiratory load compensation.\n\nThe introduction of a BVI is a first step toward a critical class of interfaces for respiratory control applications in other clinical conditions (e.g. acute respiratory failure, coma, chronic obstructive pulmonary disease or neuromuscular disorders) where the use of mechanical ventilation is required to decrease the work of breathing in the patients~\\cite{covemPatent}. Future work should also integrate the detector of respiratory-related cortical activities in a feedback scheme to automatically set ventilator parameters almost without physician intervention.  \n\n\n\\section*{Acknowledgments}\nThis work was supported by the program Investissement d'Avenir ANR-11-EMMA-0030 and ANR-10-AIHU 06 of the French Government and by the grant Legs Poix from the Chancellerie de l'Universit\\'e de Paris, France. X. Navarro is financially supported by Air Liquide Medical Systems S.A., France. A.L. Hudson was supported by an NHMRC (Australia) Early Career Fellowship.\n\n\n\\bibliographystyle{ieeetr}\n\n\\begin{thebibliography}{10}\n\n\\bibitem{carlucci2001}\nA.~Carlucci, J.~C. Richard, M.~Wysocki, E.~Lepage, L.~Brochard, and {SRLF\n  Collaborative Group on Mechanical Ventilation}, ``Noninvasive versus\n  conventional mechanical ventilation. an epidemiologic survey,'' {\\em\n  Am. J. Respir. Crit. Care Med.}, vol.~163, no.~4,\n  pp.~874--880, 2001.\n\n\\bibitem{leung1997}\nP.~Leung, A.~Jubran, and M.~J. Tobin, ``Comparison of assisted ventilator modes\n  on triggering, patient effort, and dyspnea,'' {\\em Am. J. Respir. Crit. Care Med.}, vol.~155, no.~6, pp.~1940--1948,\n  1997.\n\n\\bibitem{Sinderby1999}\nC.~Sinderby, P.~Navalesi, J.~Beck, Y.~Skrobik, N.~Comtois, S.~Friberg, S.~B.\n  Gottfried, and L.~Lindstr\\\"om, ``Neural control of mechanical ventilation in\n  respiratory failure,'' {\\em Nat. Med.}, vol.~5, no.~12, pp.~1433--1436,\n  1999.\n\n\\bibitem{Spahija2010}\nJ.~Spahija, M.~de Marchie, M. Albert, P.~Bellemare, S.~Delisle, J.~Beck, C.~Sinderby, ``Patient-ventilator interaction during pressure support ventilation and neurally adjusted ventilatory assist,'' {\\em Crit. Care. Med.} vol.~38, pp.~518--526, 2010.\n\n\\bibitem{raux2007}\nM.~Raux, C.~Straus, S.~Redolfi, C.~Morelot-Panzini, A.~Couturier, F.~Hug, and\n  T.~Similowski, ``Electroencephalographic evidence for pre-motor cortex\n  activation during inspiratory loading in humans,'' {\\em J. Physiol.}, vol.~578, no.~Pt 2, pp.~569--578, 2007.\n\n\\bibitem{raux2007b}\nM.~Raux, P.~Ray, M.~Prella, A.~Duguet, A.~Demoule, T.~Similowski. \n\"Cerebral cortex activation during experimentally induced ventilator fighting in normal humans\nreceiving noninvasive mechanical ventilation,\" \n{\\em Anesthesiology.} vol.~107, no.~5, pp.~746--55, 2007.\n\n\\bibitem{Grave2013}\nR.~Grave de Peralta, S.~Gonzalez Andino and S.~Perrig.\n``Patient Machine Interface for the Control of Mechanical Ventilation Devices,\"\n{\\em Brain sci.}, vol.~3, no.~4, pp.~1554--1568, 2013.\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem{Varela2001}\nF.\\ Varela, J.-P.\\ Lachaux, E.\\ Rodriguez, and J.\\ Martinerie, ``The brainweb: phase synchronization and large-scale integration,'' {\\em Nat. Rev. Neurosci.}, vol.~2, pp.~229--239, 2001.\n\n\\bibitem{barachant2012}\nA.~Barachant, S.~Bonnet, M.~Congedo, and C.~Jutten, ``Multiclass brain-computer\n  interface classification by Riemannian geometry,'' {\\em {IEEE} Trans. Biomed. Eng.}, vol.~59, no.~4, pp.~920--928, 2012.\n\n\\bibitem{mak2009}\nJ.~N. Mak and J.~R. Wolpaw, ``Clinical applications of brain-computer\n  interfaces: current state and future prospects,'' {\\em IEEE Rev. Biomed. Eng.}, vol.~2, pp.~187--199, 2009.\n\n\\bibitem{hudson2015}\nA.~L. Hudson, X.~Navarro-Sune, J.~Martinerie, P.~Puget, M.~Raux, M.~Chavez, T.~Similowski, ``Improved detection of respiratory-related cortical activation using electroencephalographic (EEG) recordings,'' {\\em Submitted}, 2015.\n\n\\bibitem{pfurtscheller1999}\nG.~Pfurtscheller and F.~L. Da~Silva, ``Event-related EEG/MEG synchronization\n  and desynchronization: basic principles,'' {\\em Clin. Neurophysiol.},\n  vol.~110, no.~11, pp.~1842--1857, 1999.\n\n\\bibitem{moakher2005}\nM.~Moakher, ``A differential geometric approach to the geometric mean of\n  symmetric positive-definite matrices,'' {\\em SIAM J. Matrix Anal. Appl}, vol.~26, no.~3, pp.~735--747, 2005.\n\n\\bibitem{bergerBOOK}\nM.~Berger, {\\em A Panoramic View of Riemannian Geometry}.\n\\newblock Springer-Verlag Berlin Heildelberg, 2003.\n\n\\bibitem{pennec2006}\nX.~Pennec, P.~Fillard, and N.~Ayache, ``A Riemannian framework for tensor\n  computing,'' {\\em Int. J. Comput. Vision}, vol.~66, no.~1,\n  pp.~41--66, 2006.\n\n\\bibitem{arsigny2006}\nV.~Arsigny, P.~Fillard, X.~Pennec, and N.~Ayache, ``Log-Euclidean metrics for\n  fast and simple calculus on diffusion tensors,'' {\\em Magn. Reson. Med.}, vol.~56, no.~2, pp.~411--421, 2006.\n\n\\bibitem{dryden2009}\nI.~L. Dryden, A.~Koloydenko, and D.~Zhou, ``Non-Euclidean statistics for\n  covariance matrices, with applications to diffusion tensor imaging,'' {\\em\n  Ann. Appl. Stat.}, vol.~3, no.~3, pp.~1102--1123, 2009.\n\n\\bibitem{vemuri2011}\nB.~C. Vemuri, M.~Liu, S.~Amari, and F.~Nielsen, ``Total Bregman divergence and\n  its applications to DTI analysis,'' {\\em IEEE Trans. Med. Imaging}, vol.~30,\n  no.~2, pp.~475--483, 2011.\n\n\\bibitem{cherian2012}\nA.~Cherian, S.~Sra, A.~Banerjee, and N.~Papanikolopoulos, ``Jensen-Bregman\n  LogDet divergence with application to efficient similarity search for\n  covariance matrices,'' {\\em IEEE Trans. Pattern Anal. Mach. Intell.}, vol.~35, no.~9, pp.~2161--2174, 2012.\n\n\\bibitem{arsigny2007}\nV.~Arsigny, P.~Fillard, X.~Pennec, and N.~Ayache, ``Geometric means in a novel\n  vector space structure on symmetric positive-definite matrices,'' {\\em SIAM J. Matrix Anal. Appl}, vol.~29, no.~1, pp.~328--347, 2007.\n\n\\bibitem{karcher1977}\nH.~Karcher, ``Riemannian center of mass and mollifier smoothing,'' {\\em\n  Comm. Pure Appl. Math.}, vol.~30, no.~5,\n  pp.~509--541, 1977.\n\n\\bibitem{fletcher2004}\nP.~T. Fletcher and S.~Joshi, ``Principal geodesic analysis on symmetric spaces:\n  Statistics of diffusion tensors,'' in {\\em Computer Vision and Mathematical\n  Methods in Medical and Biomedical Image Analysis}, no.~3117 in Lecture Notes\n  in Computer Science, pp.~87--98, 2004.\n\n\\bibitem{scholkopfBook}\nB.~Sch\\\"{o}lkopf and A.~J. Smola, {\\em Learning with Kernels}.\n\\newblock The MIT Press Cambridge, MA, USA, 2002.\n\n\\bibitem{quang2013}\n M.~H. Quang, L. Bazzani, and V. Murino,  ``A unifying framework for vector-valued manifold regularization and multi-view learning,'' in {\\em Proc. 30th International Conference on Machine Learning (ICML-13)}, pp.~100--108, 2013.\n\n\\bibitem{ramoser2000}\nH.~Ramoser, J.~M\\\"uller-Gerking, and G.~Pfurtscheller, ``Optimal spatial\n  filtering of single trial {EEG} during imagined hand movement,'' {\\em\n  IEEE Trans. Neural Syst. Rehabil. Eng.}, vol.~8, no.~4,\n  pp.~441--446, 2000.\n\n\\bibitem{farquhar2006}\nJ.~Farquhar, N.~Hill, T.~N. Lal, and B.~Sch{\\\"o}lkopf, ``Regularised CSP for\n sensor selection in BCI,'' in {\\em Proc. 3rd Int. BCI Workshop and Training Course}, pp.~14--15, 2006.\n\n\\bibitem{lal2004}\nT.~N. Lal, M.~Schr{\\\"o}der, T.~Hinterberger, J.~Weston, M.~Bogdan,\n  N.~Birbaumer, and B.~Sch{\\\"o}lkopf, ``Support vector channel selection in\n  BCI,'' {\\em IEEE Trans. Biomed. Eng}, vol.~51, no.~6,\n  pp.~1003--1010, 2004.\n\n\\bibitem{lan2006}\nT.~Lan, D.~Erdogmus, A.~Adami, M.~Pavel, and S.~Mathan, ``Salient EEG channel\n  selection in brain computer interfaces by mutual information maximization,''\n  in {\\em 27th Annual International Conference of the Engineering in Medicine\n  and Biology Society, 2005. IEEE-EMBS 2005}, pp.~7064--7067, IEEE, 2006.\n\n\\bibitem{kolde2012}\nR.~Kolde, S.~Laur, P.~Adler, and J.~Vilo, ``Robust rank aggregation for gene\n  list integration and meta-analysis,'' {\\em Bioinformatics}, vol.~28, no.~4,\n  pp.~573--580, 2012.\n\n\\bibitem{macefield1991}\nG.~Macefield and S.~C. Gandevia, ``The cortical drive to human respiratory\n  muscles in the awake state assessed by premotor cerebral potentials,'' {\\em\n  J. Physiol.}, vol.~439, pp.~545--558, 1991.\n\n\\bibitem{leupoldt2010}\nA.~von Leupoldt, A.~Keils, P.~Y. Chan, M.~M. Bradley, P.~J. Lang, and P.~W.\n  Davenport, ``Cortical sources of the respiratory-related evoked potential,''\n  {\\em Respir Physiol Neurobiol}, vol.~170, no.~2, pp.~198--201,\n  2010.\n\n\\bibitem{raux2013}\nM.~Raux, L.~Tyvaert, M.~Ferreira, F.~Kindler, E. Bardinet, C.~Karachi,\nC.~Morelot-Panzini, J.~Gotman, G.B.~Pike, L.~Koski, T.~Similowski.\n\"Functional magnetic resonance imaging suggests automatization of the cortical response to inspiratory\nthreshold loading in humans,\" {\\em Respir. Physiol. Neurobiol.}, vol.~189, no.~3, pp.~571--80, 2013.\n\n\\bibitem{morawiec2015}\nE.~Morawiec, M.~Raux, F.~Kindler, L.~Laviolette, and T.~Similowski,\n  ``Expiratory load compensation is associated with electroencephalographic\n  premotor potentials in humans,'' {\\em J. Appl. Physiol.},\n  vol.~118, no.~8, pp.~1023--1030, 2015.\n\n\n\n\n\n\\bibitem{covemPatent}\nT. Similowski, M. Raux, M. Chavez, J. Martinerie, and  P. Pouget,\n  ``Method for characterising the physiological state of a patient from the analysis of the cerebral electrical activity of said patient, and monitoring device applying said method,'' WO Patent WO2013164462 (A1), May 3, 2013.\n\n\\end{thebibliography}\n\n\n", "itemtype": "equation", "pos": 24493, "prevtext": "\nThis metric maps SPD matrices to a flat Riemannian space (of zero curvature) so that classical Euclidean computations can be applied~\\cite{arsigny2006}. Under this metric, the geodesic distance on the manifold corresponds to a Euclidean distance in the tangent space at the identity matrix. This metric is easy to compute and preserves some important theoretical properties, such as scale, rotation and inversion invariance~\\cite{arsigny2006, cherian2012}.\n\nGiven a set of $m$ covariance matrices $\\mathbf{P}_1, \\ldots,\\mathbf{P}_m \\in \\mathcal{P}_{N_c}$, their log-Euclidean mean exists and is uniquely determined by~\\cite{arsigny2006}:\n\n", "index": 23, "text": "\\begin{equation}\n\\label{MdLE}\n\\mathfrak{M}_{LE}(\\mathbf{P}_1, \\ldots ,\\mathbf{P}_m) = \\mathrm{Exp} \\left( \\frac{1}{m}\\sum_{k=1}^{m} \\mathrm{Log} (\\mathbf{P}_k) \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\mathfrak{M}_{LE}(\\mathbf{P}_{1},\\ldots,\\mathbf{P}_{m})=\\mathrm{Exp}\\left(%&#10;\\frac{1}{m}\\sum_{k=1}^{m}\\mathrm{Log}(\\mathbf{P}_{k})\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mi>\ud835\udd10</mi><mrow><mi>L</mi><mo>\u2062</mo><mi>E</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>\ud835\udc0f</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>Exp</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mi>Log</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0f</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]