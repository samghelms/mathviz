[{"file": "1601.06014.tex", "nexttext": "\nwhere $I(X_1^k;\\mathcal{I})$ is the mutual information between block\n$X_1^k$ and the shift-invariant algebra $\\mathcal{I}$ of the process\n$(X_i)_{i=-\\infty}^{\\infty}$. Whereas $I(X_1^k;\\mathcal{I})$ can grow\nas fast as any sublinear function, cf.\\ \\cite{Debowski12,Debowski15g},\nit is not clear whether the gap between $H^+(k)$ and $H^-(k)$ is\nnecessarily closing when divided by $k$, i.e., whether\n\n", "itemtype": "equation", "pos": 3365, "prevtext": "\n\n\\author{\\IEEEauthorblockN{{\\L}ukasz D\\k{e}bowski}\n  \\IEEEauthorblockA{Institute of Computer Science\\\\ Polish Academy of\n    Sciences\\\\ 01-248 Warszawa, Poland \\\\ Email:\n    ldebowsk@ipipan.waw.pl}}\n\n\n\n\\title{Consistency of the Plug-In Estimator of the Entropy Rate for\n  Ergodic Processes} \\date{}\n\n\n\\pagestyle{empty}   \n\n\n\\maketitle\n\n\\begin{abstract}\n  A plug-in estimator of entropy is the entropy of the distribution\n  where the probabilities of symbols or blocks have been replaced with\n  their relative frequencies in the sample. Consistency and asymptotic\n  unbiasedness of the plug-in estimator can be easily demonstrated in\n  the IID case. In this paper, we ask whether the plug-in estimator\n  can be used for consistent estimation of the entropy rate $h$ of a\n  stationary ergodic process. The answer is positive if, to estimate\n  block entropy of order $k$, we use a sample longer than\n  $k2^{k(h+\\epsilon)}$, whereas it is negative if we use a sample\n  shorter than $k2^{k(h-\\epsilon)}$. In particular, if we do not know\n  the entropy rate $h$, it is sufficient to use a sample of length\n  $k(A+\\epsilon)^{k}$ where $A$ is the alphabet size. The result is\n  derived using $k$-block coding.\n\n\n\n\n\n\n\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Introduction}\n\\label{secIntroduction}\n\nNonparametric estimation entropy is a task that requires a very large\namount of data. This problem has been studied mostly in the IID case,\nsee a review of literature in \\cite{JiaoOthers15}. Moreover, the novel\nresults of \\cite{JiaoOthers15} state that it is impossible to estimate\nentropy of a distribution with a support size $S$ using an IID sample\nshorter than of order $S/\\log S$, whereas it is possible for a sample\nlonger than of order $S/\\log S$, and a practical estimator achieving\nthis bound has been exhibited. Earlier, in \\cite{Zhang12}, another\nentropy estimator was proposed which, for a finite alphabet, has a\nbias exponentially decreasing with the sample length. The exponential\ndecay of the bias is, however, too slow to beat the $S/\\log S$ sample\nbound.\n\nIn this paper we would like to pursue the more difficult and less\nrecognized question of entropy estimation for general stationary\nergodic processes.  For a stationary process\n$(X_i)_{i=-\\infty}^{\\infty}$ over a finite alphabet $\\mathbb{X}$,\nconsider the blocks of consecutive random symbols $X_k^l=(X_i)_{k\\le\n  i\\le l}$, the block entropy $H(k)=H(p_k)$, where\n$p_k(w)=P(X_{i+1}^{i+k}=w)$ and $H(p)=-\\sum_{w:p(w)>0} p(w)\\log p(w)$,\nand the entropy rate $h=\\lim_{n\\rightarrow\\infty} H(k)/k$. Basically,\nthere are two different kinds of random entropy bounds for stationary\nprocesses:\n\\begin{enumerate}\n\\item Random upper bounds $H^+(k)$ based on universal coding\n  \\cite{ZivLempel77,NeuhoffShields98} or universal prediction\n  \\cite{Ryabko10}: For these bounds we have ${\\operatorname{\\mathbf{E}}} H^+(k)\\ge H(k)$.\n\\item Random lower bounds $H^-(k)$ based on maximum likelihood\n  estimation of block probabilities, such as the plug-in estimator\n  \\cite{ZhangZhang12}: As we will see, for these bounds we have ${\\operatorname{\\mathbf{E}}}\n  H^-(k)\\le H(k)$.\n\\end{enumerate}\n\nInequalities ${\\operatorname{\\mathbf{E}}} H^+(k)\\ge H(k)$ and ${\\operatorname{\\mathbf{E}}} H^-(k)\\le H(k)$ hold\nfor any stationary process, regardless whether it is ergodic or\nnot. Hence, by the ergodic decomposition, we obtain that\n\n", "index": 1, "text": "\\begin{align}\n  {\\operatorname{\\mathbf{E}}}\\left[ {H^+(k)-H^-(k)} \\right]\\ge I(X_1^k;\\mathcal{I}),\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{\\mathbf{E}}}\\left[{H^{+}(k)-H^{-}(k)}\\right]\\geq I%&#10;(X_{1}^{k};\\mathcal{I}),\" display=\"inline\"><mrow><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mrow><mo>[</mo><mrow><mrow><msup><mi>H</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>H</mi><mo>-</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>k</mi></msubsup><mo>;</mo><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nAn equivalent statement of this problem is whether there exist such\nrandom entropy bounds $H^\\pm(k)$ that\n\n", "itemtype": "equation", "pos": 3875, "prevtext": "\nwhere $I(X_1^k;\\mathcal{I})$ is the mutual information between block\n$X_1^k$ and the shift-invariant algebra $\\mathcal{I}$ of the process\n$(X_i)_{i=-\\infty}^{\\infty}$. Whereas $I(X_1^k;\\mathcal{I})$ can grow\nas fast as any sublinear function, cf.\\ \\cite{Debowski12,Debowski15g},\nit is not clear whether the gap between $H^+(k)$ and $H^-(k)$ is\nnecessarily closing when divided by $k$, i.e., whether\n\n", "index": 3, "text": "\\begin{align}\n  \\lim_{k\\rightarrow\\infty}  {\\operatorname{\\mathbf{E}}} \\left[ {H^+(k)-H^-(k)} \\right]/k=0\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}{\\operatorname{\\mathbf{E}}}\\left[{H^{+}(%&#10;k)-H^{-}(k)}\\right]/k=0.\" display=\"inline\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mrow><mo>[</mo><mrow><mrow><msup><mi>H</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>H</mi><mo>-</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>/</mo><mi>k</mi></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nWhereas there are many known random upper entropy bounds $H^+(k)$ that\nsatisfy the above condition, such as the lengths of universal codes\n\\cite{ZivLempel77,NeuhoffShields98} or universal predictors\n\\cite{Ryabko10}, we are not aware of any explicit construction of a\nrandom lower bound $H^-(k)$ that satisfies this requirement.\n\nConsequently, in this paper, we would like to propose a simple random\nlower entropy bound $H^-(k)$ that satisfies condition\n(\\ref{Consistency}). Our bound will have form\n$H^-(k)=H(k,X_1^{n(k)})$, where the latter quantity is the plug-in\nestimator\n\n", "itemtype": "equation", "pos": 4103, "prevtext": "\nAn equivalent statement of this problem is whether there exist such\nrandom entropy bounds $H^\\pm(k)$ that\n\n", "index": 5, "text": "\\begin{align}\n  \\label{Consistency}\n  \\lim_{k\\rightarrow\\infty}  {\\operatorname{\\mathbf{E}}} H^\\pm(k)/k=h\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}{\\operatorname{\\mathbf{E}}}H^{\\pm}(k)/k=h.\" display=\"inline\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><msup><mi>H</mi><mo>\u00b1</mo></msup></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mi>k</mi></mrow></mrow><mo>=</mo><mi>h</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nwith the empirical distribution\n\n", "itemtype": "equation", "pos": 4801, "prevtext": "\nWhereas there are many known random upper entropy bounds $H^+(k)$ that\nsatisfy the above condition, such as the lengths of universal codes\n\\cite{ZivLempel77,NeuhoffShields98} or universal predictors\n\\cite{Ryabko10}, we are not aware of any explicit construction of a\nrandom lower bound $H^-(k)$ that satisfies this requirement.\n\nConsequently, in this paper, we would like to propose a simple random\nlower entropy bound $H^-(k)$ that satisfies condition\n(\\ref{Consistency}). Our bound will have form\n$H^-(k)=H(k,X_1^{n(k)})$, where the latter quantity is the plug-in\nestimator\n\n", "index": 7, "text": "\\begin{align}\n  H(k,X_1^n)&=H(p_k(\\,\\cdot\\,,X_1^n))\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle H(k,X_{1}^{n})\" display=\"inline\"><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=H(p_{k}(\\,\\cdot\\,,X_{1}^{n}))\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo rspace=\"4.2pt\" stretchy=\"false\">(</mo><mo rspace=\"4.2pt\">\u22c5</mo><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nSince ${\\operatorname{\\mathbf{E}}} p_k(w,X_1^n)=P(X_{i+1}^{i+k}=w)$, applying the Jensen\ninequality,\nwe obtain\n\n", "itemtype": "equation", "pos": 4897, "prevtext": "\nwith the empirical distribution\n\n", "index": 9, "text": "\\begin{align}\n  p_k(w,X_1^n)&=\n  \\frac{1}{\\left\\lfloor {n/k} \\right\\rfloor}\\sum_{i=1}^{\\left\\lfloor {n/k} \\right\\rfloor} {\\bf 1}{\\left\\{ {{X_{i(k-1)+1}^{ik}=w}} \\right\\}}\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle p_{k}(w,X_{1}^{n})\" display=\"inline\"><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{\\left\\lfloor{n/k}\\right\\rfloor}\\sum_{i=1}^{\\left\\lfloor%&#10;{n/k}\\right\\rfloor}{\\bf 1}{\\left\\{{{X_{i(k-1)+1}^{ik}=w}}\\right\\}}.\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mo>\u230a</mo><mrow><mi>n</mi><mo>/</mo><mi>k</mi></mrow><mo>\u230b</mo></mrow></mfrac></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo>\u230a</mo><mrow><mi>n</mi><mo>/</mo><mi>k</mi></mrow><mo>\u230b</mo></mrow></munderover></mstyle><mn>\ud835\udfcf</mn><mrow><mo>{</mo><msubsup><mi>X</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msubsup><mo>=</mo><mi>w</mi><mo>}</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nso the plug-in estimator is a biased estimator of $H(k)$ and in\nparticular, ${\\operatorname{\\mathbf{E}}} H^-(k)\\le H(k)$ regardless of $n(k)$. The bias of\nthe plug-in estimator can be quite large since by inequality\n$p_k(w,X_1^n)\\ge \\left\\lfloor {n/k} \\right\\rfloor^{-1}$ for $p_k(w,X_1^n)>0$ we also have\n\n", "itemtype": "equation", "pos": 5195, "prevtext": "\nSince ${\\operatorname{\\mathbf{E}}} p_k(w,X_1^n)=P(X_{i+1}^{i+k}=w)$, applying the Jensen\ninequality,\nwe obtain\n\n", "index": 11, "text": "\\begin{align}\n  \\label{ExpPlugIn}\n  {\\operatorname{\\mathbf{E}}} H(k,X_1^n)&\\le H(k)\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{\\mathbf{E}}}H(k,X_{1}^{n})\" display=\"inline\"><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mi>H</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq H(k)\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\nThe plug-in estimator $H(k,X_1^n)$ depends on two arguments: the block\nlength $k$ and the sample $X_1^n$. If we fix the block length $k$ and\nlet the sample size $n$ tend to infinity, we obtain a consistent and\nasymptotically unbiased estimator of the block entropy $H(k)$. Namely,\nfor a stationary ergodic process,\n$\\lim_{n\\rightarrow\\infty} H(k,X_1^n)=H(k)$ almost surely by the\nergodic theorem and hence\n$\\lim_{n\\rightarrow\\infty} {\\operatorname{\\mathbf{E}}} H(k,X_1^n)=H(k)$ by inequality\n(\\ref{ExpPlugIn}) and the Fatou lemma. These results generalize what\nis known for the IID case \\cite{ZhangZhang12}.\n\nNow the question arises what $n(k)$ we should choose so that the lower\nbound $H^-(k)=H(k,X_1^{n(k)})$ satisfy condition\n(\\ref{Consistency}). The following result states that $n(k)\\ge\nk2^{k(h+\\epsilon)}$ is sufficient:\n\\begin{theorem}\n  \\label{theoPlugIn}\n  Let $(X_i)_{i=-\\infty}^{\\infty}$ be a stationary ergodic process\n  over a finite alphabet $\\mathbb{X}$.  For any $\\epsilon>0$,\n  $A>2^{h+\\epsilon}$, and $n(k)\\in [k2^{k(h+\\epsilon)}, kA^k]$, we\n  have\n  \n", "itemtype": "equation", "pos": 5597, "prevtext": "\nso the plug-in estimator is a biased estimator of $H(k)$ and in\nparticular, ${\\operatorname{\\mathbf{E}}} H^-(k)\\le H(k)$ regardless of $n(k)$. The bias of\nthe plug-in estimator can be quite large since by inequality\n$p_k(w,X_1^n)\\ge \\left\\lfloor {n/k} \\right\\rfloor^{-1}$ for $p_k(w,X_1^n)>0$ we also have\n\n", "index": 13, "text": "\\begin{align}\n  \\label{ASPlugIn}\n  H(k,X_1^n)&\\le\\log \\left\\lfloor {n/k} \\right\\rfloor\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle H(k,X_{1}^{n})\" display=\"inline\"><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\log\\left\\lfloor{n/k}\\right\\rfloor.\" display=\"inline\"><mrow><mrow><mi/><mo>\u2264</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>\u230a</mo><mrow><mi>n</mi><mo>/</mo><mi>k</mi></mrow><mo>\u230b</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\\end{theorem}\n\nAccording to Theorem \\ref{theoPlugIn}, for $n(k)\\in\n[k2^{k(h+\\epsilon)}, kA^k]$ the plug-in estimator $H(k,X_1^{n(k)})/k$\nof the entropy rate $h$ is consistent in probability.  In contrast,\napplying inequality (\\ref{ASPlugIn}) for $\\epsilon>0$ and $n(k)\\le\nk2^{k(h-\\epsilon)}$ yields\n\n", "itemtype": "equation", "pos": 6770, "prevtext": "\n\nThe plug-in estimator $H(k,X_1^n)$ depends on two arguments: the block\nlength $k$ and the sample $X_1^n$. If we fix the block length $k$ and\nlet the sample size $n$ tend to infinity, we obtain a consistent and\nasymptotically unbiased estimator of the block entropy $H(k)$. Namely,\nfor a stationary ergodic process,\n$\\lim_{n\\rightarrow\\infty} H(k,X_1^n)=H(k)$ almost surely by the\nergodic theorem and hence\n$\\lim_{n\\rightarrow\\infty} {\\operatorname{\\mathbf{E}}} H(k,X_1^n)=H(k)$ by inequality\n(\\ref{ExpPlugIn}) and the Fatou lemma. These results generalize what\nis known for the IID case \\cite{ZhangZhang12}.\n\nNow the question arises what $n(k)$ we should choose so that the lower\nbound $H^-(k)=H(k,X_1^{n(k)})$ satisfy condition\n(\\ref{Consistency}). The following result states that $n(k)\\ge\nk2^{k(h+\\epsilon)}$ is sufficient:\n\\begin{theorem}\n  \\label{theoPlugIn}\n  Let $(X_i)_{i=-\\infty}^{\\infty}$ be a stationary ergodic process\n  over a finite alphabet $\\mathbb{X}$.  For any $\\epsilon>0$,\n  $A>2^{h+\\epsilon}$, and $n(k)\\in [k2^{k(h+\\epsilon)}, kA^k]$, we\n  have\n  \n", "index": 15, "text": "\\begin{align}\n    \\label{PlugInExp}\n    \\lim_{k\\rightarrow\\infty} {\\operatorname{\\mathbf{E}}} H(k,X_1^{n(k)})/k&=h\n                                                    ,\n    \\\\\n    \\label{PlugInAS}\n    \\liminf_{k\\rightarrow\\infty} H(k,X_1^{n(k)})/k&= h \\text{ a.s.}\n                                                    ,\n                                                    \\\\\n    \\label{PlugInProb}\n    \\forall_{\\eta>0} \\lim_{k\\rightarrow\\infty} P(H(k,X_1^{n(k)})/k-h>\\eta)&= 0\n                                                       .\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}{\\operatorname{\\mathbf{E}}}H(k,X_{1}^{n(%&#10;k)})/k\" display=\"inline\"><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mi>H</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mi>k</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=h,\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mi>h</mi></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\liminf_{k\\rightarrow\\infty}H(k,X_{1}^{n(k)})/k\" display=\"inline\"><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mi>k</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=h\\text{ a.s.},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>h</mi><mo>\u2062</mo><mtext>\u00a0a.s.</mtext></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\forall_{\\eta&gt;0}\\lim_{k\\rightarrow\\infty}P(H(k,X_{1}^{n(k)})/k-h&gt;\\eta)\" display=\"inline\"><mrow><msub><mo>\u2200</mo><mrow><mi>\u03b7</mi><mo>&gt;</mo><mn>0</mn></mrow></msub><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mi>k</mi><mo>-</mo><mi>h</mi><mo>&gt;</mo><mi>\u03b7</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nHence the sample size $n(k)\\le k2^{k(h-\\epsilon)}$ is insufficient to\nobtain a consistent estimate of the entropy rate $h$ using the plug-in\nestimator.\n\nWhen applying Theorem \\ref{theoPlugIn} for estimation of entropy rate\n$h$, we are supposed not to know the exact value of $h$. In that case\nwe may put $n(k)=k(\\left| {\\mathbb{X}} \\right|+\\epsilon)^k$. This bound is,\nhowever, pessimistic, especially for processes with a vanishing\nentropy rate $h=0$, cf. \\cite{Debowski15g}. Having a random upper\nbound of the block entropy $H^+(k)$, we may also put $n(k)=k2^{{\\operatorname{\\mathbf{E}}}\n  H^+(k)+k\\epsilon}$. \n\nA question arises whether we can improve our result. Thus, we conclude\nthe Introduction with four open problems:\n\\begin{enumerate}\n\\item Is the plug-in estimator $H(k,X_1^{n(k)})/k$ an almost surely\n  consistent estimator of the entropy rate in some cases?\n\\item What happens for $n(k)\\in (k2^{k(h-\\epsilon)},\n  k2^{k(h+\\epsilon)})$, especially if $h=0$, and for $n(k)> kA^k$?\n\\item Can Theorem \\ref{theoPlugIn} be strengthened by\n  setting $n(k)$ equal to some random stopping time, such as\n\n", "itemtype": "equation", "pos": 7616, "prevtext": "\n\\end{theorem}\n\nAccording to Theorem \\ref{theoPlugIn}, for $n(k)\\in\n[k2^{k(h+\\epsilon)}, kA^k]$ the plug-in estimator $H(k,X_1^{n(k)})/k$\nof the entropy rate $h$ is consistent in probability.  In contrast,\napplying inequality (\\ref{ASPlugIn}) for $\\epsilon>0$ and $n(k)\\le\nk2^{k(h-\\epsilon)}$ yields\n\n", "index": 17, "text": "\\begin{align}\n  \\limsup_{k\\rightarrow\\infty} H(k,X_1^{n(k)})/k\\le h-\\epsilon \\text{ a.s.}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\limsup_{k\\rightarrow\\infty}H(k,X_{1}^{n(k)})/k\\leq h-\\epsilon%&#10;\\text{ a.s.}\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim sup</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mi>k</mi></mrow></mrow><mo>\u2264</mo><mrow><mi>h</mi><mo>-</mo><mrow><mi>\u03f5</mi><mo>\u2062</mo><mtext>\u00a0a.s.</mtext></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nwhere the random upper bound $H^+(k)$ is a length of a universal code\nfor $X_1^k$?\n\\item The plug-in estimator is not optimal in the IID case\n  \\cite{JiaoOthers15}. Can we propose a better estimator of the\n  entropy rate also for an arbitrary stationary ergodic process?\n\\end{enumerate}\n\n\\section{Proof of Theorem \\ref{theoPlugIn}}\n\\label{secProof}\n\nOur proof of Theorem \\ref{theoPlugIn} applies source coding. To be\nprecise, it rests on a modification of the simplistic universal code\nby Neuhoff and Shields \\cite{NeuhoffShields98}. The Neuhoff-Shields\ncode is basically a $k$-block code with parameter $k$ depending on the\ncompressed string $X_1^n$. In the following, we will show that the\nplug-in estimator $H(k,X_1^n)$ multiplied by $n/k$ is the dominating\nterm in the length of the $k$-block code for $X_1^n$ by the results of\n\\cite{NeuhoffShields98,OrnsteinWeiss90}. This length cannot be shorter\nthan $nh$ so the expectation of $H(k,X_1^n)/k$ must tend to $h$.\n\nThe idea of a $k$-block code is that we first describe a code book,\ni.e., we enumerate the collection of blocks $w$ of length $k$\ncontained in the compressed string $X_1^n$ and their frequencies\n$np_k(w,X_1^n)$, and then we apply Shannon-Fano coding to $X_1^n$\npartitioned into blocks from the code book.  Let $D(k,X_1^n)$ be the\nnumber of distinct blocks of length $k$ contained in the compressed\nstring $X_1^n$. Formally,\n\n", "itemtype": "equation", "pos": 8824, "prevtext": "\nHence the sample size $n(k)\\le k2^{k(h-\\epsilon)}$ is insufficient to\nobtain a consistent estimate of the entropy rate $h$ using the plug-in\nestimator.\n\nWhen applying Theorem \\ref{theoPlugIn} for estimation of entropy rate\n$h$, we are supposed not to know the exact value of $h$. In that case\nwe may put $n(k)=k(\\left| {\\mathbb{X}} \\right|+\\epsilon)^k$. This bound is,\nhowever, pessimistic, especially for processes with a vanishing\nentropy rate $h=0$, cf. \\cite{Debowski15g}. Having a random upper\nbound of the block entropy $H^+(k)$, we may also put $n(k)=k2^{{\\operatorname{\\mathbf{E}}}\n  H^+(k)+k\\epsilon}$. \n\nA question arises whether we can improve our result. Thus, we conclude\nthe Introduction with four open problems:\n\\begin{enumerate}\n\\item Is the plug-in estimator $H(k,X_1^{n(k)})/k$ an almost surely\n  consistent estimator of the entropy rate in some cases?\n\\item What happens for $n(k)\\in (k2^{k(h-\\epsilon)},\n  k2^{k(h+\\epsilon)})$, especially if $h=0$, and for $n(k)> kA^k$?\n\\item Can Theorem \\ref{theoPlugIn} be strengthened by\n  setting $n(k)$ equal to some random stopping time, such as\n\n", "index": 19, "text": "\\begin{align}\n  \\label{PossibleN}\n  n(k)=k2^{H^+(k)}\n  ,\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle n(k)=k2^{H^{+}(k)},\" display=\"inline\"><mrow><mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>k</mi><mo>\u2062</mo><msup><mn>2</mn><mrow><msup><mi>H</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nTo fully describe $X_1^n$ in terms of a $k$-block code we have to\nspecify, cf. \\cite{NeuhoffShields98}:\n\\begin{enumerate}\n\\item what $k$ is (description length $2\\log k$),\n\\item what $D(k,X_1^n)$ is (description length $\\log\\left\\lfloor {n/k} \\right\\rfloor$),\n\\item what the code book is (description length\n  $(k\\log\\left| {\\mathbb{X}} \\right|+\\log\\left\\lfloor {n/k} \\right\\rfloor) D(k,X_1^n)$),\n\\item what the Shannon-Fano code words for block $X_1^{k\\left\\lfloor {n/k} \\right\\rfloor}$\n  are (description length $\\left\\lfloor {n/k} \\right\\rfloorH(k,X_1^n)$),\n\\item what the remaining block $X_{k\\left\\lfloor {n/k} \\right\\rfloor+1}^n$ is (description\n  length $\\le k\\log\\left| {\\mathbb{X}} \\right|$).\n\\end{enumerate}\nHence quantity \n\n", "itemtype": "equation", "pos": 10286, "prevtext": "\nwhere the random upper bound $H^+(k)$ is a length of a universal code\nfor $X_1^k$?\n\\item The plug-in estimator is not optimal in the IID case\n  \\cite{JiaoOthers15}. Can we propose a better estimator of the\n  entropy rate also for an arbitrary stationary ergodic process?\n\\end{enumerate}\n\n\\section{Proof of Theorem \\ref{theoPlugIn}}\n\\label{secProof}\n\nOur proof of Theorem \\ref{theoPlugIn} applies source coding. To be\nprecise, it rests on a modification of the simplistic universal code\nby Neuhoff and Shields \\cite{NeuhoffShields98}. The Neuhoff-Shields\ncode is basically a $k$-block code with parameter $k$ depending on the\ncompressed string $X_1^n$. In the following, we will show that the\nplug-in estimator $H(k,X_1^n)$ multiplied by $n/k$ is the dominating\nterm in the length of the $k$-block code for $X_1^n$ by the results of\n\\cite{NeuhoffShields98,OrnsteinWeiss90}. This length cannot be shorter\nthan $nh$ so the expectation of $H(k,X_1^n)/k$ must tend to $h$.\n\nThe idea of a $k$-block code is that we first describe a code book,\ni.e., we enumerate the collection of blocks $w$ of length $k$\ncontained in the compressed string $X_1^n$ and their frequencies\n$np_k(w,X_1^n)$, and then we apply Shannon-Fano coding to $X_1^n$\npartitioned into blocks from the code book.  Let $D(k,X_1^n)$ be the\nnumber of distinct blocks of length $k$ contained in the compressed\nstring $X_1^n$. Formally,\n\n", "index": 21, "text": "\\begin{align}\n  D(k,X_1^n)=\n  \\left| {\\left\\{ {w\\in\\mathbb{X}^k:\\exists_{i\\in{1,...,\\left\\lfloor {n/k} \\right\\rfloor}}   X_{i(k-1)+1}^{ik}=w} \\right\\}} \\right|\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle D(k,X_{1}^{n})=\\left|{\\left\\{{w\\in\\mathbb{X}^{k}:\\exists_{i\\in{1%&#10;,...,\\left\\lfloor{n/k}\\right\\rfloor}}X_{i(k-1)+1}^{ik}=w}\\right\\}}\\right|.\" display=\"inline\"><mrow><mrow><mrow><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mo>{</mo><mrow><mi>w</mi><mo>\u2208</mo><msup><mi>\ud835\udd4f</mi><mi>k</mi></msup></mrow><mo>:</mo><mrow><mrow><msub><mo>\u2203</mo><mrow><mi>i</mi><mo>\u2208</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><mo>\u230a</mo><mrow><mi>n</mi><mo>/</mo><mi>k</mi></mrow><mo>\u230b</mo></mrow></mrow></mrow></msub><msubsup><mi>X</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msubsup></mrow><mo>=</mo><mi>w</mi></mrow><mo>}</mo></mrow><mo>|</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nis an upper bound for the length of the $k$-block code.\n\nSince the $k$-block code is an instantaneous code, the upper bound for\nits length satisfies Kraft inequality\n$\\sum_{k,x_1^n}2^{-K(k,x_1^n)}\\le 1$.  Therefore, we have ${\\operatorname{\\mathbf{E}}}\nK(k,X_1^n)\\ge H(n)$, whereas by the Barron inequality\n\n", "itemtype": "equation", "pos": 11196, "prevtext": "\nTo fully describe $X_1^n$ in terms of a $k$-block code we have to\nspecify, cf. \\cite{NeuhoffShields98}:\n\\begin{enumerate}\n\\item what $k$ is (description length $2\\log k$),\n\\item what $D(k,X_1^n)$ is (description length $\\log\\left\\lfloor {n/k} \\right\\rfloor$),\n\\item what the code book is (description length\n  $(k\\log\\left| {\\mathbb{X}} \\right|+\\log\\left\\lfloor {n/k} \\right\\rfloor) D(k,X_1^n)$),\n\\item what the Shannon-Fano code words for block $X_1^{k\\left\\lfloor {n/k} \\right\\rfloor}$\n  are (description length $\\left\\lfloor {n/k} \\right\\rfloorH(k,X_1^n)$),\n\\item what the remaining block $X_{k\\left\\lfloor {n/k} \\right\\rfloor+1}^n$ is (description\n  length $\\le k\\log\\left| {\\mathbb{X}} \\right|$).\n\\end{enumerate}\nHence quantity \n\n", "index": 23, "text": "\\begin{align}\n  K(k,X_1^n)&=2\\log k+\\log\\frac{n}{k}+\n  \\nonumber\\\\\n  &\\phantom{=}+\\left( {k\\log\\left| {\\mathbb{X}} \\right|+\\log\\frac{n}{k}} \\right) D(k,X_1^n)+\n  \\nonumber\\\\\n  &\\phantom{=}+\\frac{n}{k}H(k,X_1^n)+k\\log\\left| {\\mathbb{X}} \\right|\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle K(k,X_{1}^{n})\" display=\"inline\"><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=2\\log k+\\log\\frac{n}{k}+\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mi>k</mi></mrow></mrow><mo>+</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mi>k</mi></mfrac></mstyle></mrow><mo>+</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phantom{=}+\\left({k\\log\\left|{\\mathbb{X}}\\right|+\\log\\frac{n}{k}%&#10;}\\right)D(k,X_{1}^{n})+\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mrow><mo>(</mo><mrow><mrow><mi>k</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>|</mo><mi>\ud835\udd4f</mi><mo>|</mo></mrow></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mi>k</mi></mfrac></mstyle></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phantom{=}+\\frac{n}{k}H(k,X_{1}^{n})+k\\log\\left|{\\mathbb{X}}\\right|\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mi>k</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>|</mo><mi>\ud835\udd4f</mi><mo>|</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\\cite[Theorem 3.1]{Barron85b}, the Borrel-Cantelli lemma, and the\nShannon-McMillan-Breiman theorem\n\n", "itemtype": "equation", "pos": 11759, "prevtext": "\nis an upper bound for the length of the $k$-block code.\n\nSince the $k$-block code is an instantaneous code, the upper bound for\nits length satisfies Kraft inequality\n$\\sum_{k,x_1^n}2^{-K(k,x_1^n)}\\le 1$.  Therefore, we have ${\\operatorname{\\mathbf{E}}}\nK(k,X_1^n)\\ge H(n)$, whereas by the Barron inequality\n\n", "index": 25, "text": "\\begin{align}\n  \\label{Barron}\n  P\\left( {K(k,X_1^{n})+\\log P(X_1^{n})\\le -m} \\right)\\le 2^{-m}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P\\left({K(k,X_{1}^{n})+\\log P(X_{1}^{n})\\leq-m}\\right)\\leq 2^{-m}\" display=\"inline\"><mrow><mi>P</mi><mrow><mo>(</mo><mi>K</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>log</mi><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><mo>-</mo><mi>m</mi><mo>)</mo></mrow><mo>\u2264</mo><msup><mn>2</mn><mrow><mo>-</mo><mi>m</mi></mrow></msup></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\\cite{AlgoetCover88}, we obtain\n\n", "itemtype": "equation", "pos": 11966, "prevtext": "\n\\cite[Theorem 3.1]{Barron85b}, the Borrel-Cantelli lemma, and the\nShannon-McMillan-Breiman theorem\n\n", "index": 27, "text": "\\begin{align}\n  \\label{SMB}\n  \\lim_{n\\rightarrow\\infty} \\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n} = h\n  \\text{ a.s.}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{\\left[{-\\log P(X_{1}^{n})}\\right]}%&#10;{n}=h\\text{ a.s.}\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle></mrow><mo>=</mo><mrow><mi>h</mi><mo>\u2062</mo><mtext>\u00a0a.s.</mtext></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\nAccording to \\cite[Theorem 2]{OrnsteinWeiss90},\nfor each $\\delta>0$ almost surely there exists $k_0$ such that for\nall $k\\ge k_0$ and $n>2^{kh}$ we have\n\n", "itemtype": "equation", "pos": 12129, "prevtext": "\n\\cite{AlgoetCover88}, we obtain\n\n", "index": 29, "text": "\\begin{align}\n  \\liminf_{k\\rightarrow\\infty} \\frac{K(k,X_1^{n(k)})}{n(k)}\n  \\ge\n  \\lim_{k\\rightarrow\\infty} \\frac{\\left[ {-\\log P(X_1^{n(k)})} \\right]}{n(k)}\n  =\n  h\n  \\text{ a.s.}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\liminf_{k\\rightarrow\\infty}\\frac{K(k,X_{1}^{n(k)})}{n(k)}\\geq%&#10;\\lim_{k\\rightarrow\\infty}\\frac{\\left[{-\\log P(X_{1}^{n(k)})}\\right]}{n(k)}=h%&#10;\\text{ a.s.}\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo>\u2265</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo>=</mo><mrow><mi>h</mi><mo>\u2062</mo><mtext>\u00a0a.s.</mtext></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nHence for $n(k)\\in [k2^{k(h+\\epsilon)}, kA^k]$ and\n$\\delta<\\epsilon$, we obtain almost surely\nthat\n\n", "itemtype": "equation", "pos": 12476, "prevtext": "\n\nAccording to \\cite[Theorem 2]{OrnsteinWeiss90},\nfor each $\\delta>0$ almost surely there exists $k_0$ such that for\nall $k\\ge k_0$ and $n>2^{kh}$ we have\n\n", "index": 31, "text": "\\begin{align}\n  D(k,X_1^n)\\le 2^{k(h+\\delta)}+\\frac{n}{k}\\delta\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle D(k,X_{1}^{n})\\leq 2^{k(h+\\delta)}+\\frac{n}{k}\\delta.\" display=\"inline\"><mrow><mrow><mrow><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><msup><mn>2</mn><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>h</mi><mo>+</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mi>\u03b4</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nSince $\\delta$ can be chosen arbitrarily small then\n\n", "itemtype": "equation", "pos": 12655, "prevtext": "\nHence for $n(k)\\in [k2^{k(h+\\epsilon)}, kA^k]$ and\n$\\delta<\\epsilon$, we obtain almost surely\nthat\n\n", "index": 33, "text": "\\begin{align}\n  h&\\le \\liminf_{k\\rightarrow\\infty} \\frac{K(k,X_1^{n(k)})}{n(k)}\n  \\nonumber\\\\\n   &=\\liminf_{k\\rightarrow\\infty} \n     \\left(\\left( {\\frac{k}{n(k)}\\log\\left| {\\mathbb{X}} \\right|+\\frac{1}{n(k)}\\log\\frac{n(k)}{k}} \\right)\\times\n     \\right.\n  \\nonumber\\\\\n     &\\qquad\\qquad\\qquad\\qquad\\qquad\n     \\left.\\times D(k,X_1^{n(k)})+\\frac{H(k,X_1^{n(k)})}{k}\\right)\n  \\nonumber\\\\\n   &\\le\\liminf_{k\\rightarrow\\infty} \n     \\left(\\left( {\\log\\left| {\\mathbb{X}} \\right|+\\log A} \\right)\n     \\left( {2^{-k(\\epsilon-\\delta)}      +\\delta} \\right)+\\right.\n  \\nonumber\\\\\n     &\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\n     \\left.+\\frac{H(k,X_1^{n(k)})}{k}\\right)\n  \\nonumber\\\\\n   &=\\left( {\\log\\left| {\\mathbb{X}} \\right|+\\log A} \\right)\n     \\delta+\\liminf_{k\\rightarrow\\infty} \\frac{H(k,X_1^{n(k)})}{k}\n     .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle h\" display=\"inline\"><mi>h</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\liminf_{k\\rightarrow\\infty}\\frac{K(k,X_{1}^{n(k)})}{n(k)}\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\liminf_{k\\rightarrow\\infty}\\left(\\left({\\frac{k}{n(k)}\\log\\left%&#10;|{\\mathbb{X}}\\right|+\\frac{1}{n(k)}\\log\\frac{n(k)}{k}}\\right)\\times\\right.\" display=\"inline\"><mrow><mo>=</mo><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mrow><mo>(</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mi>k</mi><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mi>log</mi><mo>|</mo><mi>\ud835\udd4f</mi><mo>|</mo><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mi>log</mi><mstyle displaystyle=\"true\"><mfrac><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>)</mo></mrow><mo>\u00d7</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\times D(k,X_{1}^{n(k)})+%&#10;\\frac{H(k,X_{1}^{n(k)})}{k}\\right)\" display=\"inline\"><mrow><mi>\u2003\u2003</mi><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003</mo><mo>\u00d7</mo><mi>D</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\liminf_{k\\rightarrow\\infty}\\left(\\left({\\log\\left|{\\mathbb{X%&#10;}}\\right|+\\log A}\\right)\\left({2^{-k(\\epsilon-\\delta)}+\\delta}\\right)+\\right.\" display=\"inline\"><mrow><mo>\u2264</mo><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mrow><mo>(</mo><mrow><mo>(</mo><mi>log</mi><mo>|</mo><mi>\ud835\udd4f</mi><mo>|</mo><mo>+</mo><mi>log</mi><mi>A</mi><mo>)</mo></mrow><mrow><mo>(</mo><msup><mn>2</mn><mrow><mo>-</mo><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03f5</mi><mo>-</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>+</mo><mi>\u03b4</mi><mo>)</mo></mrow><mo>+</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.+\\frac{H(k,%&#10;X_{1}^{n(k)})}{k}\\right)\" display=\"inline\"><mrow><mi>\u2003\u2003</mi><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003</mo><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left({\\log\\left|{\\mathbb{X}}\\right|+\\log A}\\right)\\delta+%&#10;\\liminf_{k\\rightarrow\\infty}\\frac{H(k,X_{1}^{n(k)})}{k}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo>(</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>|</mo><mi>\ud835\udd4f</mi><mo>|</mo></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>\u2061</mo><mi>A</mi></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><mi>\u03b4</mi></mrow><mo>+</mo><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\nIn contrast, inequality (\\ref{ExpPlugIn}) implies\n\n", "itemtype": "equation", "pos": 13540, "prevtext": "\nSince $\\delta$ can be chosen arbitrarily small then\n\n", "index": 35, "text": "\\begin{align}\n  \\label{LimInf}\n  \\liminf_{k\\rightarrow\\infty}  \\frac{H(k,X_1^{n(k)})}{k}\\ge h \n  \\text{ a.s.}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\liminf_{k\\rightarrow\\infty}\\frac{H(k,X_{1}^{n(k)})}{k}\\geq h%&#10;\\text{ a.s.}\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow><mo>\u2265</mo><mrow><mi>h</mi><mo>\u2062</mo><mtext>\u00a0a.s.</mtext></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\nHence, by the Fatou lemma and inequality (\\ref{LimInf}), we have\n\n", "itemtype": "equation", "pos": 13713, "prevtext": "\n\nIn contrast, inequality (\\ref{ExpPlugIn}) implies\n\n", "index": 37, "text": "\\begin{align}\n  \\limsup_{k\\rightarrow\\infty} \\frac{{\\operatorname{\\mathbf{E}}} H(k,X_1^{n(k)})}{k}\\le h\n  .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\limsup_{k\\rightarrow\\infty}\\frac{{\\operatorname{\\mathbf{E}}}H(k,%&#10;X_{1}^{n(k)})}{k}\\leq h.\" display=\"inline\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim sup</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mi>H</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow><mo>\u2264</mo><mi>h</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\ni.e., equality (\\ref{PlugInExp}) is established. By inequality\n(\\ref{LimInf}) and equality (\\ref{ELimInf}), we also obtain equality \n(\\ref{PlugInAS}).\n\nThe proof of statement (\\ref{PlugInProb}) requires a few additional\nsteps. Denoting $X^+=X{\\bf 1}{\\left\\{ {{X>0}} \\right\\}}$ and $X^-=-X{\\bf 1}{\\left\\{ {{X<0}} \\right\\}}$, we obtain\nfrom Markov inequality, inequality (\\ref{ExpPlugIn}), and inequality\n$(X+Y)^-\\le X^-+Y^-$ that\n \n", "itemtype": "equation", "pos": 13898, "prevtext": "\nHence, by the Fatou lemma and inequality (\\ref{LimInf}), we have\n\n", "index": 39, "text": "\\begin{align}\n  \\label{ELimInf}\n  h={\\operatorname{\\mathbf{E}}} \\liminf_{k\\rightarrow\\infty} \\frac{H(k,X_1^{n(k)})}{k}\n  =\\lim_{k\\rightarrow\\infty} \\frac{{\\operatorname{\\mathbf{E}}} H(k,X_1^{n(k)})}{k}\n  ,\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle h={\\operatorname{\\mathbf{E}}}\\liminf_{k\\rightarrow\\infty}\\frac{H%&#10;(k,X_{1}^{n(k)})}{k}=\\lim_{k\\rightarrow\\infty}\\frac{{\\operatorname{\\mathbf{E}}%&#10;}H(k,X_{1}^{n(k)})}{k},\" display=\"inline\"><mrow><mrow><mi>h</mi><mo>=</mo><mrow><mo>\ud835\udc04</mo><mo>\u2062</mo><mrow><munder><mo movablelimits=\"false\">lim inf</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow></mrow><mo>=</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mi>H</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n\n Now we will show that all four terms on the RHS of (\\ref{FourTerms})\n tend to $0$, which is sufficient to establish\n (\\ref{PlugInProb}). First,\n \n", "itemtype": "equation", "pos": 14546, "prevtext": "\ni.e., equality (\\ref{PlugInExp}) is established. By inequality\n(\\ref{LimInf}) and equality (\\ref{ELimInf}), we also obtain equality \n(\\ref{PlugInAS}).\n\nThe proof of statement (\\ref{PlugInProb}) requires a few additional\nsteps. Denoting $X^+=X{\\bf 1}{\\left\\{ {{X>0}} \\right\\}}$ and $X^-=-X{\\bf 1}{\\left\\{ {{X<0}} \\right\\}}$, we obtain\nfrom Markov inequality, inequality (\\ref{ExpPlugIn}), and inequality\n$(X+Y)^-\\le X^-+Y^-$ that\n \n", "index": 41, "text": "\\begin{align}\n   &\\eta P\\left( {\\frac{H(k,X_1^{n(k)})}{k}-h>\\eta} \\right)\\le\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{H(k,X_1^{n(k)})}{k}-h} \\right]^+\n   \\nonumber\n   \\\\\n   &=\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{H(k,X_1^{n(k)})}{k}-h} \\right]+\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{H(k,X_1^{n(k)})}{k}-h} \\right]^-\n   \\nonumber\n    \\\\\n   &\\le\n   \\left[ {\\frac{H(k)}{k}-h} \\right]+\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{K(k,X_1^{n(k)})}{n(k)}-\\frac{H(k,X_1^{n(k)})}{k}} \\right]+\n   \\nonumber\n   \\\\\n   &\\phantom{=}+\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{K(k,X_1^{n(k)})}{n(k)}+\\frac{\\log P(X_1^{n(k)})}{n(k)}} \\right]^-+\n   \\nonumber\n   \\\\\n   &\\phantom{=}+\n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{\\left[ {-\\log P(X_1^{n(k)})} \\right]}{n(k)}-h} \\right]^-\n   \\label{FourTerms}\n   .\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\eta P\\left({\\frac{H(k,X_{1}^{n(k)})}{k}-h&gt;\\eta}\\right)\\leq{%&#10;\\operatorname{\\mathbf{E}}}\\left[{\\frac{H(k,X_{1}^{n(k)})}{k}-h}\\right]^{+}\" display=\"inline\"><mrow><mi>\u03b7</mi><mi>P</mi><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>&gt;</mo><mi>\u03b7</mi><mo>)</mo></mrow><mo>\u2264</mo><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>+</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle={\\operatorname{\\mathbf{E}}}\\left[{\\frac{H(k,X_{1}^{n(k)})}{k}-h}%&#10;\\right]+{\\operatorname{\\mathbf{E}}}\\left[{\\frac{H(k,X_{1}^{n(k)})}{k}-h}\\right%&#10;]^{-}\" display=\"inline\"><mrow><mo>=</mo><mo>\ud835\udc04</mo><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>+</mo><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>-</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\left[{\\frac{H(k)}{k}-h}\\right]+{\\operatorname{\\mathbf{E}}}%&#10;\\left[{\\frac{K(k,X_{1}^{n(k)})}{n(k)}-\\frac{H(k,X_{1}^{n(k)})}{k}}\\right]+\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mrow><mo>[</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi></mrow><mo>]</mo></mrow><mo>+</mo><mrow><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mrow><mo>[</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow><mo>]</mo></mrow></mrow><mo>+</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phantom{=}+{\\operatorname{\\mathbf{E}}}\\left[{\\frac{K(k,X_{1}^{n(%&#10;k)})}{n(k)}+\\frac{\\log P(X_{1}^{n(k)})}{n(k)}}\\right]^{-}+\" display=\"inline\"><mrow><mo>+</mo><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>]</mo></mrow><mo>-</mo></msup><mo>+</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phantom{=}+{\\operatorname{\\mathbf{E}}}\\left[{\\frac{\\left[{-\\log P%&#10;(X_{1}^{n(k)})}\\right]}{n(k)}-h}\\right]^{-}.\" display=\"inline\"><mrow><mo>+</mo><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>-</mo></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n by the definition of the entropy rate. Second, \n \n", "itemtype": "equation", "pos": 15517, "prevtext": "\n\n Now we will show that all four terms on the RHS of (\\ref{FourTerms})\n tend to $0$, which is sufficient to establish\n (\\ref{PlugInProb}). First,\n \n", "index": 43, "text": "\\begin{align}\n   \\lim_{k\\rightarrow\\infty} \\left[ {\\frac{H(k)}{k}-h} \\right]=0\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}\\left[{\\frac{H(k)}{k}-h}\\right]=0\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mo>[</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>-</mo><mi>h</mi></mrow><mo>]</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n since\n \n", "itemtype": "equation", "pos": 15659, "prevtext": "\n by the definition of the entropy rate. Second, \n \n", "index": 45, "text": "\\begin{align}\n   \\lim_{k\\rightarrow\\infty} \n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{K(k,X_1^{n(k)})}{n(k)}-\\frac{H(k,X_1^{n(k)})}{k}} \\right]=0\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}{\\operatorname{\\mathbf{E}}}\\left[{\\frac{%&#10;K(k,X_{1}^{n(k)})}{n(k)}-\\frac{H(k,X_{1}^{n(k)})}{k}}\\right]=0\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mrow><mo>[</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mi>k</mi></mfrac></mstyle></mrow><mo>]</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n by the result of \\cite[Eq. (8)]{NeuhoffShields98}. Third,\n \n", "itemtype": "equation", "pos": 15828, "prevtext": "\n since\n \n", "index": 47, "text": "\\begin{align}\n   \\lim_{k\\rightarrow\\infty} \\frac{k}{n(k)}{\\operatorname{\\mathbf{E}}}\n   D(k,X_1^{n(k)})=0\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{k\\rightarrow\\infty}\\frac{k}{n(k)}{\\operatorname{\\mathbf{E}}%&#10;}D(k,X_{1}^{n(k)})=0\" display=\"inline\"><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>k</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>k</mi><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mo>\ud835\udc04</mo><mo>\u2061</mo><mi>D</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n since\n \n", "itemtype": "equation", "pos": 16007, "prevtext": "\n by the result of \\cite[Eq. (8)]{NeuhoffShields98}. Third,\n \n", "index": 49, "text": "\\begin{align}\n   \\lim_{n\\rightarrow\\infty} \n   \\frac{1}{n}{\\operatorname{\\mathbf{E}}}\\left[ {K(k,X_1^{n})+\\log P(X_1^{n})} \\right]^-=0\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{n\\rightarrow\\infty}\\frac{1}{n}{\\operatorname{\\mathbf{E}}}%&#10;\\left[{K(k,X_{1}^{n})+\\log P(X_{1}^{n})}\\right]^{-}=0\" display=\"inline\"><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>n</mi></mfrac></mstyle><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mi>K</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>log</mi><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow><mo>-</mo></msup><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n by the Barron inequality (\\ref{Barron}). Fourth,\n \n", "itemtype": "equation", "pos": 16163, "prevtext": "\n since\n \n", "index": 51, "text": "\\begin{align}\n   {\\operatorname{\\mathbf{E}}}\\left[ {K(k,X_1^{n})+\\log P(X_1^{n})} \\right]^-\\le \\sum_{m=0}^\\infty m\n   2^{-m}<\\infty\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{\\mathbf{E}}}\\left[{K(k,X_{1}^{n})+\\log P(X_{1}^{n}%&#10;)}\\right]^{-}\\leq\\sum_{m=0}^{\\infty}m2^{-m}&lt;\\infty\" display=\"inline\"><mrow><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mi>K</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>log</mi><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow><mo>-</mo></msup><mo>\u2264</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant=\"normal\">\u221e</mi></munderover></mstyle><mi>m</mi><msup><mn>2</mn><mrow><mo>-</mo><mi>m</mi></mrow></msup><mo>&lt;</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n since the Shannon-McMillan-Breiman theorem (\\ref{SMB}) implies\n convergence in probability, i.e., for all $\\epsilon>0$, we have\n \n", "itemtype": "equation", "pos": 16359, "prevtext": "\n by the Barron inequality (\\ref{Barron}). Fourth,\n \n", "index": 53, "text": "\\begin{align}\n   \\lim_{n\\rightarrow\\infty} \n   {\\operatorname{\\mathbf{E}}}\\left[ {\\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n}-h} \\right]^-=0\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{n\\rightarrow\\infty}{\\operatorname{\\mathbf{E}}}\\left[{\\frac{%&#10;\\left[{-\\log P(X_{1}^{n})}\\right]}{n}-h}\\right]^{-}=0\" display=\"inline\"><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>-</mo></msup><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n Hence\n \n", "itemtype": "equation", "pos": 16643, "prevtext": "\n since the Shannon-McMillan-Breiman theorem (\\ref{SMB}) implies\n convergence in probability, i.e., for all $\\epsilon>0$, we have\n \n", "index": 55, "text": "\\begin{align}\n   \\lim_{n\\rightarrow\\infty}\n   P\\left( {\\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n} - h < -\\epsilon} \\right)=0\n   .\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lim_{n\\rightarrow\\infty}P\\left({\\frac{\\left[{-\\log P(X_{1}^{n})}%&#10;\\right]}{n}-h&lt;-\\epsilon}\\right)=0.\" display=\"inline\"><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mi>P</mi><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>&lt;</mo><mo>-</mo><mi>\u03f5</mi><mo>)</mo></mrow><mo>=</mo><mn>0</mn><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06014.tex", "nexttext": "\n tends to a value smaller than $\\epsilon$, where $\\epsilon$ is\n arbitrarily small.\n\n\\bibliographystyle{IEEEtran}\n\n\n\n\\bibliography{0-journals-abbrv,0-publishers-abbrv,ai,mine,tcs,ql,nlp,books}\n\n\n\n", "itemtype": "equation", "pos": 16795, "prevtext": "\n Hence\n \n", "index": 57, "text": "\\begin{align}\n   &{\\operatorname{\\mathbf{E}}}\\left[ {\\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n}-h} \\right]^-\n   \\nonumber\n   \\\\\n   &\\le h P\\left( {\\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n} - h < -\\epsilon} \\right)\n   \\nonumber\n   \\\\\n   &\\phantom{=}\n   + \\epsilon P\\left( {\\frac{\\left[ {-\\log P(X_1^{n})} \\right]}{n} - h \\ge -\\epsilon} \\right)\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{\\mathbf{E}}}\\left[{\\frac{\\left[{-\\log P(X_{1}^{n})%&#10;}\\right]}{n}-h}\\right]^{-}\" display=\"inline\"><mrow><mo>\ud835\udc04</mo><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>]</mo></mrow><mo>-</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq hP\\left({\\frac{\\left[{-\\log P(X_{1}^{n})}\\right]}{n}-h&lt;-%&#10;\\epsilon}\\right)\" display=\"inline\"><mrow><mo>\u2264</mo><mi>h</mi><mi>P</mi><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>&lt;</mo><mo>-</mo><mi>\u03f5</mi><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phantom{=}+\\epsilon P\\left({\\frac{\\left[{-\\log P(X_{1}^{n})}%&#10;\\right]}{n}-h\\geq-\\epsilon}\\right)\" display=\"inline\"><mrow><mo>+</mo><mi>\u03f5</mi><mi>P</mi><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>P</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>X</mi><mn>1</mn><mi>n</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mi>n</mi></mfrac></mstyle><mo>-</mo><mi>h</mi><mo>\u2265</mo><mo>-</mo><mi>\u03f5</mi><mo>)</mo></mrow></mrow></math>", "type": "latex"}]