[{"file": "1601.03411.tex", "nexttext": "\nwhere\n\\( P \\) is a probability measure on \\( \\Omega \\),\n$D$ is a discount function \\cite{frederick2002time},\nand\n$r(\\omega)$ is a reward (a.k.a.\\ utility) value associated with obtaining the\nsolution to $\\omega$.\nThe expression $S(A)$ may be interpreted as the expected discounted reward that\n$A$ receives if run on a random input,\nand the practice of comparing scores among algorithms we call\n\\emph{expected-reward analysis}.\nA higher score indicates a more efficient algorithm.\n\n\nThe functions \\( D \\) and \\( r \\) are arbitrary and are free to be set in the\ncontext of a particular application.\nE.g.\\ in graphical user interface software we often desire near-instant\nresponses, with utility rapidly dropping off with time.\nAssuming \\(0 \\leq r \\leq 1\\), we immediately see that for all \\(A\\), partial\nor not, we have\n", "itemtype": "equation", "pos": 5148, "prevtext": "\n\n\\title{Analysis of algorithms and partial algorithms}\n\\author{Andrew MacFie}\n\\newdateformat{amdate}{\\THEYEAR.\\shortmonthname[\\THEMONTH].\\twodigit{\\THEDAY}}\n\\date{\\vspace{-5ex}}\n\n\\maketitle\n\n\n\\begin{abstract}\n  We present an alternative methodology for the analysis of algorithms,\n  based on the concept of expected discounted reward.\n  This methodology naturally handles algorithms that do not always terminate,\n  so it can (theoretically) be used with partial\n  algorithms for undecidable problems, such as those found in artificial\n  general intelligence (AGI) and automated theorem proving.\n  We mention new approaches to self-improving AGI and logical uncertainty\n  enabled by this methodology.\n\\end{abstract}\n\n\n\n\\section{Introduction: Shortcomings of traditional analysis of algorithms}\n\nCurrently, the (running time) analysis of algorithms takes the following form.\nGiven two algorithms \\( A \\), \\( B \\) that solve the same problem,\nwe find which is more efficient by asymptotically comparing the running time\nsequences \\( (a_n) \\), \\( (b_n) \\) \\cite{clr,iaofa}.\nThis could be using worst-case or average-case running times or even\nsmoothed analysis \\cite{spielman2009smoothed}.\nWe refer to this general method as \\emph{traditional analysis of algorithms}.\n\nAs with any model, traditional analysis of algorithms is not perfect.\nAuthors have noted\n\\cite{aaronson2012philosophers,gurevich1993feasible}\nthat comparing sequence tails avoids the arbitrariness of any particular range\nof input lengths but leads us to say \\( a_n = n^{100} \\) is superior to\n\\( b_n = \\left( 1 + \\exp(-10^{10}) \\right )^n \\) which is false for\npractical purposes.\nGurevich \\cite{gurevich1993feasible} even says,\n``A good theory of non-asymptotic complexity is a biggest challenge of all in\n[computational complexity theory].''\n\nA further issue with traditional analysis of algorithms is illustrated by\nthe following situation.\nSay we have a function \\(F: \\{0, 1\\}^* \\rightarrow \\{0, 1\\} \\)\nand an algorithm \\( A \\) that computes \\(F\\) such that for\n\\( n \\geq 0 \\), \\(A\\) takes \\( (n!)! \\) steps on the input \\( 0^n \\)\nand \\( n \\) steps on any other input of length \\(n\\).\nThe algorithm \\(A\\) then has worst-case running time \\( (n!)! \\) and\naverage-case running time slightly greater than \\( 2^{-n} (n!)! \\),\nwhich are both terrible.\nHowever, if the inputs are generated according to a uniform distribution, the\nprobability of taking more than \\( n \\) steps is  \\( 2^{-n} \\) which is quickly\nnegligible.\nWe see that \\(A\\) should be considered an excellent algorithm but traditional\nanalysis does not tell us that, unless we add ``with high probability''.\n\nThe same issue arises if \\( A \\) simply does not halt on \\(0^n\\),\nin which case the worst-case and average-case running times are infinite.\nIndeed, this is not an esoteric phenomenon.\nFor any problem with Turing degree \\( {\\mathbf{0}'} \\) we cannot have an algorithm\nthat halts on every input, but we develop\npartial solutions that work on a subset of inputs.\nSuch problems include string compression (Kolmogorov complexity),\nthe halting problem in program analysis \\cite{looper}, algebraic\nsimplification, program optimization, automated theorem proving, and Solomonoff\ninduction (central to artificial general intelligence \\cite{lv}).\nE.g.\\ in the case of automated theorem proving, Buss, describing the main\nopen problems in proof theory \\cite{2000}, states,\n``Computerized proof search \\dots is widely used, but almost no mathematical\ntheory is known about the effectiveness or optimality of present-day\nalgorithms.''\n\n\\begin{defin}\n  An algorithm $A$ is a \\emph{partial algorithm} (a.k.a.\\\n  computational method \\cite[p5]{knut}) for a given problem if on all\n  inputs, $A$ either outputs the correct value, or does not terminate.\n\\end{defin}\n\n\\begin{defin}\n  We refer to partial algorithms for problems with Turing degree \\( {\\mathbf{0}'} \\)\n  as \\emph{\\( {\\mathbf{0}'} \\) algorithms}.\n\\end{defin}\n\nTo analyze {\\( \\mathbf{0}' \\) algorithms}, and perhaps to better analyze normal terminating algorithms,\nwe need a new approach that is not based on worst-case or average-case running\ntime sequences.\nIn \\S~\\ref{sec:er} we present a new method for analyzing algorithms,\ncalled expected-reward analysis, and in \\S~\\ref{sec:other} we survey\nsome other nontraditional methods that also avoid some of the issues mentioned\nabove.\nThen in \\S~\\ref{subsec:selfimprovement} we mention how these methods can be\nused in self-improving AI systems and in \\S~\\ref{subsec:logicaluncertainty} we\nshow how analyzing \\( {\\mathbf{0}'} \\) algorithms can clarify the problem of logical\nuncertainty.\nWe give directions for further work in \\S~\\ref{sec:furtherwork}.\n\n\\begin{notation}\n  Given a (possibly partial) algorithm \\(A\\) and an input \\(\\omega\\),\n  we denote the number of steps taken by \\(A\\) on \\(\\omega\\) by\n  \\( c_A(\\omega),\\)\n  which takes the value \\( \\infty \\) if \\(A\\) does not halt on \\(\\omega\\).\n\\end{notation}\n\n\n\n\n\n\n\\section{Expected-reward analysis of algorithms} \\label{sec:er}\n\n\\subsection{Definition}\n\nLet $A$ be a (possibly partial) algorithm with inputs in \\( \\Omega \\).\nWe say the \\emph{score} of $A$ is\n\n", "index": 1, "text": "\\begin{equation*}\n  S(A)\n    = \\sum_{\\omega \\in \\Omega} P(\\{\\omega\\}) r(\\omega) D(c_A(\\omega))\n    = E(r \\cdot (D \\circ c_A)),\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"S(A)=\\sum_{\\omega\\in\\Omega}P(\\{\\omega\\})r(\\omega)D(c_{A}(\\omega))=E(r\\cdot(D%&#10;\\circ c_{A})),\" display=\"block\"><mrow><mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>\u03c9</mi><mo>\u2208</mo><mi mathvariant=\"normal\">\u03a9</mi></mrow></munder><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mi>\u03c9</mi><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>r</mi><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>D</mi><mo>\u2218</mo><msub><mi>c</mi><mi>A</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nFor simplicity in this paper we assume \\(r(\\omega) = 1\\) and \\(D\\) is an\nexponential discount function, i.e.\\\n\n", "itemtype": "equation", "pos": 6108, "prevtext": "\nwhere\n\\( P \\) is a probability measure on \\( \\Omega \\),\n$D$ is a discount function \\cite{frederick2002time},\nand\n$r(\\omega)$ is a reward (a.k.a.\\ utility) value associated with obtaining the\nsolution to $\\omega$.\nThe expression $S(A)$ may be interpreted as the expected discounted reward that\n$A$ receives if run on a random input,\nand the practice of comparing scores among algorithms we call\n\\emph{expected-reward analysis}.\nA higher score indicates a more efficient algorithm.\n\n\nThe functions \\( D \\) and \\( r \\) are arbitrary and are free to be set in the\ncontext of a particular application.\nE.g.\\ in graphical user interface software we often desire near-instant\nresponses, with utility rapidly dropping off with time.\nAssuming \\(0 \\leq r \\leq 1\\), we immediately see that for all \\(A\\), partial\nor not, we have\n", "index": 3, "text": "\n\\[\n  0 \\leq S(A) \\leq 1.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"0\\leq S(A)\\leq 1.\" display=\"block\"><mrow><mrow><mn>0</mn><mo>\u2264</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mn>1</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nwhere $\\lambda > 0$ is a discount rate.\n\n\nWe note that the choice of $\\lambda$ can determine the relative scores of two\nalgorithms, e.g.\n\n", "itemtype": "equation", "pos": 6247, "prevtext": "\nFor simplicity in this paper we assume \\(r(\\omega) = 1\\) and \\(D\\) is an\nexponential discount function, i.e.\\\n\n", "index": 5, "text": "$$\n    D(c_A(\\omega)) = \\exp(-\\lambda \\, c_A(\\omega)),\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"D(c_{A}(\\omega))=\\exp(-\\lambda\\,c_{A}(\\omega)),\" display=\"block\"><mrow><mrow><mrow><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mi>\u03bb</mi></mpadded><mo>\u2062</mo><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\ndepends on \\( \\lambda \\).\n\n\nThe choice of \\(P\\) is also arbitrary;\nwe remark on two special cases.\nIf all inputs of a given length are weighted equally, \\(P\\) is determined\nby a probability mass function on \\( \\mathbb{Z}_{0+} \\).\nIn this case any common probability distribution may be used as appropriate.\nThe measure \\(P\\) is also determined by a probability mass function on\n\\(\\mathbb{Z}_{0+}\\) if we weight equal-length inputs according to the\nuniversal distribution \\(m\\) \\cite{lv}, which is a particularly good general\nmodel, although computationally difficult.\n\n\n\nExpected-reward analysis is non-asymptotic, in the sense that all inputs\nmatter.\nThus, while expected-reward analysis can be used on terminating algorithms, we\nexpect it to give different results from traditional analysis, in general.\n\nSince particular inputs can make a difference to \\(S(A)\\), it may be\nadvantageous to ``hardcode'' initial cases into an algorithm.\nThis practice certainly exists, e.g. humans may store the \\(12 \\times 12\\)\nmultiplication table as well as knowing a general integer multiplication\nalgorithm.\nOf course, the meta-algorithm ``compute all values and put them into a\nlookup table as they are found'' is as useless as the solution to Goldbach's\nconjecture ``enumerate all proofs until a proof or disproof of the conjecture\nis found''.\n\n\nComputational complexity theory often works with classes of problems whose\ndefinitions are equivalent for all ``reasonable'' models of computation\n\\cite{boas}.\nHowever, even a varying constant factor could arbitrarily change a score.\nThis is simply the price of concreteness,\nand outside of complexity theory, traditional analysis of algorithms generally\nselects a particular model of computation and gives precise results that do not\nnecessarily apply to other models \\cite{ac}.\n\n\nUnlike traditional analysis, experimental data is relevant to score values\nin a statistical sense.\nIf we are able to generate inputs according to \\(P\\), either artificially or by\nsampling inputs found in practice, \\(S(A)\\) is a quantity amenable to\nstatistical estimation.\nThis suggests a form of experimental analysis of algorithms which focuses on a\nsingle real number rather than plotting the estimated running time for\nevery input length, which, in the necessary absence of asymptotics in\nexperimental analysis, may not conclusively rank two competing algorithms\nanyway.\n\n\nThe expected-reward paradigm already appears in the analysis of artificial\nagents, rather than algorithms \\cite{defi}.\nAs we see in \\S~\\ref{subsec:selfimprovement}, however, even in applications\nto AI, working in the more classical domain of algorithms brings benefits.\n\n\n\n\n\n\\subsection{Theory and practice} \\label{sec:tp}\n\nTraditional analysis of algorithms has an established literature going\nback decades which provides a set of techniques for performing traditional\nanalysis on algorithms developed for various problems.\nWe do not significantly develop a mathematical theory of expected-reward\nanalysis here, but we make some very brief initial remarks.\n\nBy way of introductory example, we consider expected-reward analysis applied to\nsome well-known sorting algorithms.\nLet \\(S_n\\) be the set of permutations of\n\\([1..n]\\) and let \\(\\Pi_n\\) be a uniform random element of \\(S_n\\).\nWe denote the algorithms mergesort and quicksort by\n\\(M\\) and \\(Q\\), as defined in \\cite{iaofa}, and set\n", "itemtype": "equation", "pos": 6442, "prevtext": "\nwhere $\\lambda > 0$ is a discount rate.\n\n\nWe note that the choice of $\\lambda$ can determine the relative scores of two\nalgorithms, e.g.\n\n", "index": 7, "text": "$$\n  {\\operatorname{sgn}}( (e^{-\\lambda} + e^{-3\\lambda} + e^{-3\\lambda}) -\n  (e^{-2\\lambda} + e^{-2\\lambda} + e^{-2\\lambda}) )\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"{\\operatorname{sgn}}((e^{-\\lambda}+e^{-3\\lambda}+e^{-3\\lambda})-(e^{-2\\lambda}%&#10;+e^{-2\\lambda}+e^{-2\\lambda}))\" display=\"block\"><mrow><mo>sgn</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>e</mi><mrow><mo>-</mo><mi>\u03bb</mi></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>3</mn><mo>\u2062</mo><mi>\u03bb</mi></mrow></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>3</mn><mo>\u2062</mo><mi>\u03bb</mi></mrow></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi></mrow></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi></mrow></mrow></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi></mrow></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nwhere \\(c_A(\\Pi_n), A=M,Q\\) is the number of comparison operations used by\n\\(A\\) to sort \\(\\Pi_n\\).\n\n\\begin{pro} \\label{pro:miq}\n  For \\(n \\geq 1\\) we have\n \n", "itemtype": "equation", "pos": 9959, "prevtext": "\ndepends on \\( \\lambda \\).\n\n\nThe choice of \\(P\\) is also arbitrary;\nwe remark on two special cases.\nIf all inputs of a given length are weighted equally, \\(P\\) is determined\nby a probability mass function on \\( \\mathbb{Z}_{0+} \\).\nIn this case any common probability distribution may be used as appropriate.\nThe measure \\(P\\) is also determined by a probability mass function on\n\\(\\mathbb{Z}_{0+}\\) if we weight equal-length inputs according to the\nuniversal distribution \\(m\\) \\cite{lv}, which is a particularly good general\nmodel, although computationally difficult.\n\n\n\nExpected-reward analysis is non-asymptotic, in the sense that all inputs\nmatter.\nThus, while expected-reward analysis can be used on terminating algorithms, we\nexpect it to give different results from traditional analysis, in general.\n\nSince particular inputs can make a difference to \\(S(A)\\), it may be\nadvantageous to ``hardcode'' initial cases into an algorithm.\nThis practice certainly exists, e.g. humans may store the \\(12 \\times 12\\)\nmultiplication table as well as knowing a general integer multiplication\nalgorithm.\nOf course, the meta-algorithm ``compute all values and put them into a\nlookup table as they are found'' is as useless as the solution to Goldbach's\nconjecture ``enumerate all proofs until a proof or disproof of the conjecture\nis found''.\n\n\nComputational complexity theory often works with classes of problems whose\ndefinitions are equivalent for all ``reasonable'' models of computation\n\\cite{boas}.\nHowever, even a varying constant factor could arbitrarily change a score.\nThis is simply the price of concreteness,\nand outside of complexity theory, traditional analysis of algorithms generally\nselects a particular model of computation and gives precise results that do not\nnecessarily apply to other models \\cite{ac}.\n\n\nUnlike traditional analysis, experimental data is relevant to score values\nin a statistical sense.\nIf we are able to generate inputs according to \\(P\\), either artificially or by\nsampling inputs found in practice, \\(S(A)\\) is a quantity amenable to\nstatistical estimation.\nThis suggests a form of experimental analysis of algorithms which focuses on a\nsingle real number rather than plotting the estimated running time for\nevery input length, which, in the necessary absence of asymptotics in\nexperimental analysis, may not conclusively rank two competing algorithms\nanyway.\n\n\nThe expected-reward paradigm already appears in the analysis of artificial\nagents, rather than algorithms \\cite{defi}.\nAs we see in \\S~\\ref{subsec:selfimprovement}, however, even in applications\nto AI, working in the more classical domain of algorithms brings benefits.\n\n\n\n\n\n\\subsection{Theory and practice} \\label{sec:tp}\n\nTraditional analysis of algorithms has an established literature going\nback decades which provides a set of techniques for performing traditional\nanalysis on algorithms developed for various problems.\nWe do not significantly develop a mathematical theory of expected-reward\nanalysis here, but we make some very brief initial remarks.\n\nBy way of introductory example, we consider expected-reward analysis applied to\nsome well-known sorting algorithms.\nLet \\(S_n\\) be the set of permutations of\n\\([1..n]\\) and let \\(\\Pi_n\\) be a uniform random element of \\(S_n\\).\nWe denote the algorithms mergesort and quicksort by\n\\(M\\) and \\(Q\\), as defined in \\cite{iaofa}, and set\n", "index": 9, "text": "\n\\[\n  m_n = E\\left(e^{-\\lambda c_M(\\Pi_n)} \\right),\\ \\ \n  q_n = E\\left(e^{-\\lambda c_Q(\\Pi_n)} \\right),\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"m_{n}=E\\left(e^{-\\lambda c_{M}(\\Pi_{n})}\\right),\\ \\ q_{n}=E\\left(e^{-\\lambda c%&#10;_{Q}(\\Pi_{n})}\\right),\" display=\"block\"><mrow><mrow><mrow><msub><mi>m</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo>(</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>c</mi><mi>M</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>)</mo></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msub><mi>q</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo>(</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>c</mi><mi>Q</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\n \n", "itemtype": "equation", "pos": 10224, "prevtext": "\nwhere \\(c_A(\\Pi_n), A=M,Q\\) is the number of comparison operations used by\n\\(A\\) to sort \\(\\Pi_n\\).\n\n\\begin{pro} \\label{pro:miq}\n  For \\(n \\geq 1\\) we have\n \n", "index": 11, "text": "\\[\n    \\frac{e^{-2 \\lambda(n-1)}}{(n!)^{\\lambda /\\log(2)}} \\leq m_n\n      \\leq \\frac{e^{-\\lambda(n-1)}}{(n!)^{\\lambda /\\log(2)}}\n        \\qquad m_0 = 1,\n  \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\frac{e^{-2\\lambda(n-1)}}{(n!)^{\\lambda/\\log(2)}}\\leq m_{n}\\leq\\frac{e^{-%&#10;\\lambda(n-1)}}{(n!)^{\\lambda/\\log(2)}}\\qquad m_{0}=1,\" display=\"block\"><mrow><mrow><mrow><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>\u03bb</mi><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mfrac><mo>\u2264</mo><msub><mi>m</mi><mi>n</mi></msub><mo>\u2264</mo><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>\u03bb</mi><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mfrac></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><msub><mi>m</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\n\\end{pro}\n\\begin{proof}\n\nFrom \\cite{iaofa}, \n\\(M\\) makes the same number of comparisons for all inputs of length $n$:\n\n", "itemtype": "equation", "pos": 10384, "prevtext": "\n \n", "index": 13, "text": "\\[\n    q_n = \\frac{e^{-\\lambda(n+1)}}{n} \\sum_{k=1}^n q_{k-1} q_{n-k},\n      \\qquad q_0 = 1.\n  \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"q_{n}=\\frac{e^{-\\lambda(n+1)}}{n}\\sum_{k=1}^{n}q_{k-1}q_{n-k},\\qquad q_{0}=1.\" display=\"block\"><mrow><mrow><mrow><msub><mi>q</mi><mi>n</mi></msub><mo>=</mo><mrow><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>q</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msub><mi>q</mi><mrow><mi>n</mi><mo>-</mo><mi>k</mi></mrow></msub></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><msub><mi>q</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nThe first result follows since\n", "itemtype": "equation", "pos": 10600, "prevtext": "\n\\end{pro}\n\\begin{proof}\n\nFrom \\cite{iaofa}, \n\\(M\\) makes the same number of comparisons for all inputs of length $n$:\n\n", "index": 15, "text": "$$\nc_M(\\Pi_n) = \\sum_{k=1}^{n-1} \\left( \\lfloor \\lg k \\rfloor + 2 \\right).\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"c_{M}(\\Pi_{n})=\\sum_{k=1}^{n-1}\\left(\\lfloor\\lg k\\rfloor+2\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mi>c</mi><mi>M</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mo>(</mo><mrow><mrow><mo stretchy=\"false\">\u230a</mo><mrow><mi>lg</mi><mo>\u2061</mo><mi>k</mi></mrow><mo stretchy=\"false\">\u230b</mo></mrow><mo>+</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\n\nWhen \\(Q\\) is called on \\(\\Pi_n\\), let $x(\\Pi_n)$ be the pivot\nelement, and let \\(l(\\Pi_n), r(\\Pi_n)\\) be the subarrays constructed for\nrecursive calls to \\(Q\\),\nwhere the elements in \\(l(\\Pi_n)\\) are less than \\(x(\\Pi_n)\\),\nand the elements in \\(r(\\Pi_n)\\) are greater.\n\nWe have\n\n", "itemtype": "equation", "pos": 10708, "prevtext": "\nThe first result follows since\n", "index": 17, "text": "\n\\[\n  \\log(k)/\\log(2) + 1 \\leq \\lfloor \\lg k \\rfloor + 2 \\leq \\log(k)/\\log(2) + 2.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\log(k)/\\log(2)+1\\leq\\lfloor\\lg k\\rfloor+2\\leq\\log(k)/\\log(2)+2.\" display=\"block\"><mrow><mrow><mrow><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>\u2264</mo><mrow><mrow><mo stretchy=\"false\">\u230a</mo><mrow><mi>lg</mi><mo>\u2061</mo><mi>k</mi></mrow><mo stretchy=\"false\">\u230b</mo></mrow><mo>+</mo><mn>2</mn></mrow><mo>\u2264</mo><mrow><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mn>2</mn></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nIt can be seen that given \\(x(\\Pi_n)=k\\), \\(r(\\Pi_n)\\) and \\(l(\\Pi_n)\\) are\nindependent, thus\n\n", "itemtype": "equation", "pos": 11075, "prevtext": "\n\nWhen \\(Q\\) is called on \\(\\Pi_n\\), let $x(\\Pi_n)$ be the pivot\nelement, and let \\(l(\\Pi_n), r(\\Pi_n)\\) be the subarrays constructed for\nrecursive calls to \\(Q\\),\nwhere the elements in \\(l(\\Pi_n)\\) are less than \\(x(\\Pi_n)\\),\nand the elements in \\(r(\\Pi_n)\\) are greater.\n\nWe have\n\n", "index": 19, "text": "\\begin{align*}\n  E[ &\\exp(-\\lambda c_Q(\\Pi_n)) ] \\\\\n  &= \\frac{1}{n} \\sum_{k=1}^n\n    E[\\exp(\\,-\\lambda(n + 1 + c_Q(l(\\Pi_n)) +\n    c_Q(r(\\Pi_n)))\\,) |x(\\Pi_n)=k] \\\\\n  &= \\frac{e^{-\\lambda(n+1)}}{n} \\sum_{k=1}^n E[\\exp(\\,-\\lambda(c_Q(l(\\Pi_n)) +\n    c_Q(r(\\Pi_n)))\\,) |x(\\Pi_n)=k].\n  \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E[\" display=\"inline\"><mrow><mi>E</mi><mo stretchy=\"false\">[</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\exp(-\\lambda c_{Q}(\\Pi_{n}))]\" display=\"inline\"><mrow><mi>exp</mi><mrow><mo stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{n}\\sum_{k=1}^{n}E[\\exp(\\,-\\lambda(n+1+c_{Q}(l(\\Pi_{n}))%&#10;+c_{Q}(r(\\Pi_{n})))\\,)|x(\\Pi_{n})=k]\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>n</mi></mfrac></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mi>E</mi><mrow><mo stretchy=\"false\">[</mo><mi>exp</mi><mrow><mo rspace=\"4.2pt\" stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo>+</mo><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>l</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{e^{-\\lambda(n+1)}}{n}\\sum_{k=1}^{n}E[\\exp(\\,-\\lambda(c_{Q}%&#10;(l(\\Pi_{n}))+c_{Q}(r(\\Pi_{n})))\\,)|x(\\Pi_{n})=k].\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mi>n</mi></mfrac></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mi>E</mi><mrow><mo stretchy=\"false\">[</mo><mi>exp</mi><mrow><mo rspace=\"4.2pt\" stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>l</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\n\\end{proof}\n\\begin{cor}\n  If \\(\\lambda = \\log(2)\\), then \\(q_n = {4^{-n}}/{n!}\\).\n\\end{cor}\n\\begin{proof}\n  Immediate by induction.\n\\end{proof}\n\nIn order to perform expected-reward analysis on an algorithm, our main\ndesideratum is a way to quickly compute the score value to within a given\nprecision for each possible parameter value \\(P, \\lambda\\).\nProposition~\\ref{pro:miq} gives a way of computing scores or bounds on scores\nof \\(M\\) and \\(Q\\) for measures \\(P\\) that give equal length inputs\nequal weight, although it does not immediately suggest an efficient way in all\ncases.\n\n\\begin{q} \\label{q:sup}\n  If we fix a computational problem and parameters \\(P, \\lambda\\), \n  what is \\( \\sup_A S(A) \\), and is it attained?\n\\end{q}\n\nIf \\( \\sup_A S(A) \\) is not attained then the situation is similar to\nthat in Blum's speedup theorem.\nComparing \\(\\sup_A S(A)\\) among problems would be the expected-reward\nanalog of computational complexity theory but because of the sensitivity\nof \\(S\\) to parameters and the model of computation, this is not useful.\n\n\n\n\n\n\n\n\n\\section{Further nontraditional methods of analysis of algorithms}\n  \\label{sec:other}\n\n\\subsection{Minimum-proof-length analysis} \\label{subsec:mpl}\n\nSuppose $F:\\{0,1\\}^* \\rightarrow \\{0,1\\}$ is a function with Turing degree\n$\\mathbf{0}'$ and $A$ is a partial algorithm for $F$.\nIn traditional analysis we consider sets\n\\(\n  \\Omega_n = \\{ 0, 1 \\}^n\n\\)\nof all inputs of length $n$.\nThen the (worst-case) running time of $A$ is defined as\n", "itemtype": "equation", "pos": 11466, "prevtext": "\nIt can be seen that given \\(x(\\Pi_n)=k\\), \\(r(\\Pi_n)\\) and \\(l(\\Pi_n)\\) are\nindependent, thus\n\n", "index": 21, "text": "\\begin{align*}\n  E[ &\\exp(-\\lambda c_Q(\\Pi_n)) ] \\\\\n  &= \\frac{e^{-\\lambda(n+1)}}{n} \\sum_{k=1}^n \n    E[\\exp(-\\lambda c_Q(l(\\Pi_n)))|x(\\Pi_n)=k] \\cdot \\\\\n    &\\hspace{25ex} E[\\exp(-\\lambda c_Q(r(\\Pi_n)))|x(\\Pi_n)=k] \\\\\n  &= \\frac{e^{-\\lambda(n+1)}}{n} \\sum_{k=1}^n\n    E[\\exp(-\\lambda c_Q(\\Pi_{k-1}))]\n    E[\\exp(-\\lambda c_Q(\\Pi_{n-k}))]. \\qedhere\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E[\" display=\"inline\"><mrow><mi>E</mi><mo stretchy=\"false\">[</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\exp(-\\lambda c_{Q}(\\Pi_{n}))]\" display=\"inline\"><mrow><mi>exp</mi><mrow><mo stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{e^{-\\lambda(n+1)}}{n}\\sum_{k=1}^{n}E[\\exp(-\\lambda c_{Q}(l%&#10;(\\Pi_{n})))|x(\\Pi_{n})=k]\\cdot\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mi>n</mi></mfrac></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mi>E</mi><mrow><mo stretchy=\"false\">[</mo><mi>exp</mi><mrow><mo stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>l</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u22c5</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0E[\\exp(-\\lambda c_{Q}(r(\\Pi_{n})%&#10;))|x(\\Pi_{n})=k]\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mi>E</mi><mrow><mo stretchy=\"false\">[</mo><mi>exp</mi><mrow><mo stretchy=\"false\">(</mo><mo>-</mo><mi>\u03bb</mi><msub><mi>c</mi><mi>Q</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{e^{-\\lambda(n+1)}}{n}\\sum_{k=1}^{n}E[\\exp(-\\lambda c_{Q}(%&#10;\\Pi_{k-1}))]E[\\exp(-\\lambda c_{Q}(\\Pi_{n-k}))].\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mi>n</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>c</mi><mi>Q</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>c</mi><mi>Q</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a0</mi><mrow><mi>n</mi><mo>-</mo><mi>k</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nwhich in general has value \\(\\infty\\).\n\nWe make the following adaptation to avoid infinite terms in running time\nsequences.\nInstead of running time as a function of the input length, we look at\nrunning time as a function of the length of the shortest proof of a\ncorrect output.\nThat is, with some suitable formal logic system fixed,\nlet $\\lambda(\\omega)$ be the length of the shortest proof of\n``$F(\\omega) = 0$'' or \n``$F(\\omega) = 1$'', or $\\infty$ if there is no such proof.\nWe define the sets $\\Omega^{\\lambda}_n = \\{ \\omega : \\lambda(\\omega) = n \\}$,\nand the sequence\n\n", "itemtype": "equation", "pos": 13325, "prevtext": "\n\\end{proof}\n\\begin{cor}\n  If \\(\\lambda = \\log(2)\\), then \\(q_n = {4^{-n}}/{n!}\\).\n\\end{cor}\n\\begin{proof}\n  Immediate by induction.\n\\end{proof}\n\nIn order to perform expected-reward analysis on an algorithm, our main\ndesideratum is a way to quickly compute the score value to within a given\nprecision for each possible parameter value \\(P, \\lambda\\).\nProposition~\\ref{pro:miq} gives a way of computing scores or bounds on scores\nof \\(M\\) and \\(Q\\) for measures \\(P\\) that give equal length inputs\nequal weight, although it does not immediately suggest an efficient way in all\ncases.\n\n\\begin{q} \\label{q:sup}\n  If we fix a computational problem and parameters \\(P, \\lambda\\), \n  what is \\( \\sup_A S(A) \\), and is it attained?\n\\end{q}\n\nIf \\( \\sup_A S(A) \\) is not attained then the situation is similar to\nthat in Blum's speedup theorem.\nComparing \\(\\sup_A S(A)\\) among problems would be the expected-reward\nanalog of computational complexity theory but because of the sensitivity\nof \\(S\\) to parameters and the model of computation, this is not useful.\n\n\n\n\n\n\n\n\n\\section{Further nontraditional methods of analysis of algorithms}\n  \\label{sec:other}\n\n\\subsection{Minimum-proof-length analysis} \\label{subsec:mpl}\n\nSuppose $F:\\{0,1\\}^* \\rightarrow \\{0,1\\}$ is a function with Turing degree\n$\\mathbf{0}'$ and $A$ is a partial algorithm for $F$.\nIn traditional analysis we consider sets\n\\(\n  \\Omega_n = \\{ 0, 1 \\}^n\n\\)\nof all inputs of length $n$.\nThen the (worst-case) running time of $A$ is defined as\n", "index": 23, "text": "\n\\[\n  f_n = \\max \\left\\{ c_A(\\omega) : \\omega \\in \\Omega_n \\right\\},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"f_{n}=\\max\\left\\{c_{A}(\\omega):\\omega\\in\\Omega_{n}\\right\\},\" display=\"block\"><mrow><mrow><msub><mi>f</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mrow><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:</mo><mrow><mi>\u03c9</mi><mo>\u2208</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>n</mi></msub></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nwhich we call the \\emph{minimum-proof-length running time} of $A$.\nIf \\( A \\) simply performs a brute-force proof search, there is an\nexponential upper bound on $f_n^{\\lambda}$ even though \\(F\\) is\nincomputable.\nWe call \\emph{minimum-proof-length analysis} the method of comparing algorithms\nby minimum-proof-length running times.\n\nWell-known concepts from computational complexity theory can be used to\nshow a rough correspondence between the existence of {\\( \\mathbf{0}' \\) algorithms}\\ with\npolynomial minimum-proof-length running time and \\(\\mathbf{P}\\) vs.\n\\(\\mathbf{NP}\\)\n\\cite{cook2000p, let, sipser1992history}.\n\n\n\n\n\n\n\n\n\n\n\\subsection{Solution rate analysis} \\label{subsec:nt}\n\nWe could imagine giving to an algorithm a ``quiz'' consisting of a list of\nproblem instances which must be completed in order, and assigning a ``grade''\nbased on the number of instances solved in a given time \\(t\\).\nThe following may be thought of as a formalization of this method of analysis.\n\nLet $A$ be a (possibly partial) algorithm with inputs in \\( \\Omega \\).\nFixing probability measures \\(P\\) on \\(\\Omega\\) and \\(P^\\infty\\) on the\nmeasurable space\n\\( \\left( \\Omega^\\infty, \\left( 2^\\Omega \\right)^\\infty \\right)\\) we define a\nrenewal process \\( N_t : \\Omega^\\infty \\rightarrow \\mathbb{Z}_{0+}\\) as\n", "itemtype": "equation", "pos": 13970, "prevtext": "\nwhich in general has value \\(\\infty\\).\n\nWe make the following adaptation to avoid infinite terms in running time\nsequences.\nInstead of running time as a function of the input length, we look at\nrunning time as a function of the length of the shortest proof of a\ncorrect output.\nThat is, with some suitable formal logic system fixed,\nlet $\\lambda(\\omega)$ be the length of the shortest proof of\n``$F(\\omega) = 0$'' or \n``$F(\\omega) = 1$'', or $\\infty$ if there is no such proof.\nWe define the sets $\\Omega^{\\lambda}_n = \\{ \\omega : \\lambda(\\omega) = n \\}$,\nand the sequence\n\n", "index": 25, "text": "\\begin{equation*}\n  f_n^{\\lambda} = \\max \\left\\{ c_A(\\omega) : \\omega \\in \\Omega^{\\lambda}_n \\right\\},\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"f_{n}^{\\lambda}=\\max\\left\\{c_{A}(\\omega):\\omega\\in\\Omega^{\\lambda}_{n}\\right\\},\" display=\"block\"><mrow><mrow><msubsup><mi>f</mi><mi>n</mi><mi>\u03bb</mi></msubsup><mo>=</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mrow><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:</mo><mrow><mi>\u03c9</mi><mo>\u2208</mo><msubsup><mi mathvariant=\"normal\">\u03a9</mi><mi>n</mi><mi>\u03bb</mi></msubsup></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nThen the object \\(E(N_t), t \\geq 0\\) represents the performance of\n\\(A\\).\n\nIf \\(P^\\infty\\) is the product measure and\n\\( E(c) = \\infty, \\) we know from renewal theory \\cite{ross} that\n", "itemtype": "equation", "pos": 15379, "prevtext": "\nwhich we call the \\emph{minimum-proof-length running time} of $A$.\nIf \\( A \\) simply performs a brute-force proof search, there is an\nexponential upper bound on $f_n^{\\lambda}$ even though \\(F\\) is\nincomputable.\nWe call \\emph{minimum-proof-length analysis} the method of comparing algorithms\nby minimum-proof-length running times.\n\nWell-known concepts from computational complexity theory can be used to\nshow a rough correspondence between the existence of {\\( \\mathbf{0}' \\) algorithms}\\ with\npolynomial minimum-proof-length running time and \\(\\mathbf{P}\\) vs.\n\\(\\mathbf{NP}\\)\n\\cite{cook2000p, let, sipser1992history}.\n\n\n\n\n\n\n\n\n\n\n\\subsection{Solution rate analysis} \\label{subsec:nt}\n\nWe could imagine giving to an algorithm a ``quiz'' consisting of a list of\nproblem instances which must be completed in order, and assigning a ``grade''\nbased on the number of instances solved in a given time \\(t\\).\nThe following may be thought of as a formalization of this method of analysis.\n\nLet $A$ be a (possibly partial) algorithm with inputs in \\( \\Omega \\).\nFixing probability measures \\(P\\) on \\(\\Omega\\) and \\(P^\\infty\\) on the\nmeasurable space\n\\( \\left( \\Omega^\\infty, \\left( 2^\\Omega \\right)^\\infty \\right)\\) we define a\nrenewal process \\( N_t : \\Omega^\\infty \\rightarrow \\mathbb{Z}_{0+}\\) as\n", "index": 27, "text": "\n\\[\n  N_t( (\\omega_1, \\omega_2, \\ldots) ) = \\max \\left\\{ N: N \\in \\mathbb{Z}_{0+},\n    \\sum_{i=1}^N c_A(\\omega_i) \\leq t \\right\\}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"N_{t}((\\omega_{1},\\omega_{2},\\ldots))=\\max\\left\\{N:N\\in\\mathbb{Z}_{0+},\\sum_{i%&#10;=1}^{N}c_{A}(\\omega_{i})\\leq t\\right\\}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>N</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c9</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03c9</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mi>N</mi><mo>:</mo><mrow><mrow><mi>N</mi><mo>\u2208</mo><msub><mi>\u2124</mi><mrow><mn>0</mn><mo>+</mo></mrow></msub></mrow><mo>,</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>c</mi><mi>A</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c9</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2264</mo><mi>t</mi></mrow></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\nThe values of \\(E(N_t)\\) for different algorithms may be compared,\nasymptotically or otherwise, where greater values indicate a more efficient\nalgorithm.\nWe call this method \\emph{solution rate analysis}.\n\n\n\n\n\n\n\n\n\\section{Other theoretical applications of analysis of {\\( \\mathbf{0}' \\) algorithms}}\n\n\\subsection{Self-improving AI} \\label{subsec:selfimprovement}\n\nThe generality of \\({\\mathbf{0}'}\\) problems allows us to view design and analysis\nof {\\( \\mathbf{0}' \\) algorithms}\\ as a task which itself may be given to a {\\( \\mathbf{0}' \\) algorithm}, bringing about\nrecursive self-improvement.\nHere we present one possible concrete example of this notion and discuss\nconnections with AI.\n\nComputational problems with Turing degree \\({\\mathbf{0}'}\\) are Turing-equivalent so\nwithout loss of generality in this subsection we assume {\\( \\mathbf{0}' \\) algorithms}\\ are\nautomated theorem provers.\nSpecifically, we fix a formal logic system, say ZFC, and take the set of inputs\nto be ZFC sentences, and the possible outputs to be \\texttt{provable} and\n\\texttt{not provable}.\n\nLet a predicate \\(c\\) be such that \\(c(Z)\\) holds\niff \\(Z\\) is a {\\( \\mathbf{0}' \\) algorithm}\\ which is correct on provable inputs and does not terminate\notherwise.\nIn pseudocode we write the instruction to run some \\(Z\\) on input \\(\\omega\\) as\n\\(Z(\\omega)\\), and if \\(\\omega\\) contains \\(c\\) or \\(S\\) (the score function),\ntheir definitions are implicitly included.\n\nWe give an auxiliary procedure \\textsc{Search} which takes as input\na {\\( \\mathbf{0}' \\) algorithm}\\ \\(Z\\) and a rational number \\(x\\) and uses \\(Z\\) to obtain a {\\( \\mathbf{0}' \\) algorithm}\\ which\nsatisfies \\(c\\) and has score greater than \\(x\\) (if possible).\nSymbols in bold within a string literal get replaced by the value of the\ncorresponding variable.\nWe assume {\\( \\mathbf{0}' \\) algorithms}\\ are encoded as strings in a binary prefix code.\n\n\\vspace{0.5cm}\n\\begin{algorithmic}[1]\n  \\Procedure{Search}{$x, Z$}\n    \\State \\(u \\gets \\epsilon\\)\n    \\Loop\n    \\StartDo in parallel until one returns \\texttt{provable}:\n        \\State A: \\(Z(\\text{``}\\exists v:\n          (Z^* = \\mathbf{u}0v \\implies\n          c(Z^*) \\land S(Z^*)> \\mathbf{x}\\text{''}))\\)\n        \\State B: \\(Z(\\text{``}\\exists v:\n          (Z^* = \\mathbf{u}1v \\implies\n          c(Z^*) \\land S(Z^*)>\\mathbf{x}\\text{''}))\\)\n        \\State C: \\(Z(\\text{``} Z^*=\\mathbf{u} \\implies\n          c(Z^*) \\land S(Z^*)> \\mathbf{x}\\text{''})\\)\n      \\EndDo\n      \\If{A returned \\texttt{provable}}\n        \\State \\( u\\gets u0 \\)\n      \\EndIf\n      \\If{B returned \\texttt{provable}}\n        \\State \\(u \\gets u1 \\)\n      \\EndIf\n      \\If{C returned \\texttt{provable}}\n        \\State return \\( u \\)\n      \\EndIf\n    \\EndLoop\n  \\EndProcedure\n\\end{algorithmic}\n\\vspace{0.5cm}\n\nWe remark that the mechanism of \\textsc{Search} is purely syntactic and does\nnot rely on consistency or completeness of ZFC, or the provability thereof.\n\nThe following procedure \\textsc{Improve}\ntakes an initial {\\( \\mathbf{0}' \\) algorithm}\\ \\(Z_0\\) and uses dovetailed calls to \\textsc{Search} to\noutput a sequence of {\\( \\mathbf{0}' \\) algorithms}\\ that tend toward optimality.\n\\vspace{0.5cm}\n\\begin{algorithmic}[1]\n  \\Procedure{Improve}{$Z_0$}\n  \\State \\(best\\) \\( \\gets Z_0 \\),\\ \\ \n    \\( pool \\gets \\{ \\} \\),\\ \\ \n    \\( score \\gets 0 \\)\n  \\For{\\( n \\gets 1 \\textbf{ to } \\infty \\)}\n    \\State \\(a_n \\gets n\\)th term in Stern-Brocot enumeration of \\(\\mathbb{Q}\n      \\cap (0,1] \\)\n    \\If{\\( a_n > score \\)}\n      \\State \\(initialState \\gets\\) initial state of\n        \\textsc{Search}\\((a_n, best)\\)\n      \\State add \\( (a_n, best, initialState) \\) to \\(pool\\)\n    \\EndIf\n    \\State \\(improvementFound \\gets false\\)\n    \\For{\\((a, Z, state)\\) in \\(pool\\)}\n      \\State run \\textsc{Search}(\\(a, Z\\)) one step starting in state \\(state\\)\n      \\State \\(newState \\gets\\) new current state of \\textsc{Search}(\\(a, Z\\))\n      \\If{\\(state\\) is not a terminating state}\n      \\State in \\(pool\\), mutate \\((a,Z,state)\\) into \\((a,Z,newState)\\)\n        \\State continue\n      \\EndIf\n      \\State \\(improvementFound \\gets true\\)\n      \\State \\(best \\gets \\) output of \\textsc{Search}(\\(a, Z\\))\n      \\State \\(score \\gets a\\)\n      \\For{ \\((\\hat{a},\\hat{Z},\\hat{state})\\) in \\(pool\\)\n        where \\( \\hat{a} \\leq score \\)}\n        \\State remove \\((\\hat{a},\\hat{Z},\\hat{state})\\) from \\(pool\\)\n      \\EndFor\n      \\State print \\(best\\)\n    \\EndFor\n    \\If{\\(improvementFound\\)}\n      \\For{ \\((a,Z,state)\\) in \\(pool\\) }\n        \\State \\(initialState \\gets\\) initial state of\n          \\textsc{Search}\\((a, best)\\)\n        \\State add \\((a, best, initialState) \\) to \\(pool\\)\n      \\EndFor\n    \\EndIf\n  \\EndFor\n  \\EndProcedure\n\\end{algorithmic}\n\\vspace{0.5cm}\n\nThe procedure \\textsc{Improve} has the following basic property.\n\n\\begin{pro}\n  Let \\((Z_n)\\) be the sequence of {\\( \\mathbf{0}' \\) algorithms}\\ printed by \\textsc{Improve}.\n  If \\(c(Z_0)\\) holds, and if there are a {\\( \\mathbf{0}' \\) algorithm}\\ \\(B\\) and \\(s \\in \\mathbb{Q}\n  \\) where \\(S(B) > s > 0\\) is provable, we have\n", "itemtype": "equation", "pos": 15696, "prevtext": "\nThen the object \\(E(N_t), t \\geq 0\\) represents the performance of\n\\(A\\).\n\nIf \\(P^\\infty\\) is the product measure and\n\\( E(c) = \\infty, \\) we know from renewal theory \\cite{ross} that\n", "index": 29, "text": "\n\\[\n  E(N_t) = o(t), \\qquad t \\rightarrow \\infty.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"E(N_{t})=o(t),\\qquad t\\rightarrow\\infty.\" display=\"block\"><mrow><mrow><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>N</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>o</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>t</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03411.tex", "nexttext": "\n\\end{pro}\n\\begin{proof}\n  We note that if \\(x,y \\in \\mathbb{Q}\\) and \\(S(Z) > x\\) is provable for some\n  \\(Z\\) then \\(x > y\\) implies \\( S(Z) > y \\) is provable.\n  Let \\(\\epsilon \\in \\mathbb{Q}\\) be such that \\(\\epsilon\n  > 0, s - \\epsilon > 0\\).\n  Then \\( s - \\epsilon \\) appears as a value \\(a_n\\).\n  For \\(a_n = s - \\epsilon\\), if \\(a_n > score\\) in line 5, then\n  \\textsc{Search}\\((s-\\epsilon, best)\\) will be run one step\n  for each greater or equal value of \\(n\\) and either terminates and\n  \\(score\\) is set to \\(s - \\epsilon\\), or is interrupted if we eventually\n  have \\(score \\geq s-\\epsilon\\).\n  It suffices to note that when \\(score\\) attains any value \\(x\\),\n  all further outputs \\(Z\\) satisfy \\(S(Z) > x\\).\n\\end{proof}\nThe procedure \\textsc{Improve} also makes an attempt to use\nrecently printed {\\( \\mathbf{0}' \\) algorithms}\\ in calls to \\textsc{Search}.\nHowever, it is not true in general that \\( S(Z_{n+1}) \\geq S(Z_n) \\).\nChecking if a particular output \\(Z_n\\) is actually an improvement over \\(Z_0\\)\nor \\(Z_{n-1}\\)\nrequires extra work.\n\nIn artificial general intelligence (AGI) it is desirable to have intelligent\nsystems with the ability to make unsupervised improvements to themselves\n\\cite{gm}.\nIf an AGI system such\nas an AIXI approximation \\cite{aixi}\nalready uses a {\\( \\mathbf{0}' \\) algorithm}\\ \\(Z\\) to compute the universal distribution \\(m\\), we can\ngive the system the ability to improve \\(Z\\) over time by devoting some of its\ncomputational resources to running \\textsc{Improve}.\nThis yields a fully general artificial agent whose environment\nprediction ability tends toward optimality.\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Logical uncertainty} \\label{subsec:logicaluncertainty}\n\nLogical uncertainty refers to the concept that as-yet unproven mathematical\npropositions may be assigned a meaningful probability value representing\nsubjective belief that they are true or provable, given the current state of\nknowledge.\n\nSome examples follow:\n\n\\begin{enumerate}\n  \\item Some people would say now \\cite{sciencase} that the probability\n    that $\\mathbf{P} = \\mathbf{NP}$ is some value other than $1/2$.\n  \\item If we have some unfamiliar expression which defines a computable sequence\n    \\((a_n)\\), but we have not yet inspected the expression closely or computed\n    initial values, it is\n    possible that \\((a_n)\\) is, say \\((2^n)\\), but not very likely because a\n    priori it could be any other computable sequence.\n    If we then compute values  and figure out that \\(a_n\\) starts out $1,\n    2, 4, 8, 16, 32$, our low prior credence would be significantly increased\n    (a process reminiscent of Bayesian updating).\n  \\item If we have an algorithm and are told it runs in time $O(n \\lg(n))$, we\n    usually assume that good asymptotics implies good practical performance so\n    the probability that the running time is actually $ 10^{10!} n\n    \\lceil \\lg(n) \\rceil$ is\n    considered particularly low.\n\\end{enumerate}\n\nLogical uncertainty is not brand new.\nE.g.\\ Goedel expressed the basic idea in 1951 \\cite{gocol}:\n\n\\blockquote{\n  If mathematics describes an objective world just like physics, there is no\n  reason why inductive methods should not be applied in mathematics just the\n  same as in physics.\n\n  (\\dots)\n\n  The probability that for each $n$ there is at least one digit $\\neq 0$\n  between\n  the $n$-th and the $n^2$-th digits of the decimal expansion of $\\pi$\n  converges toward $1$ as one goes on verifying it for greater and greater\n  $n$.\n  One may, however, be uncertain whether it makes sense to ask what the\n  probability is of that general statement, given that it has not\n  been falsified below $n = 1000000$, or to ask for which $n$ the probability\n  would exceed $.999$.\n}\n\nLet us write \\( \\mu(P) \\) for the probability assigned to a proposition\n\\(s\\) given current knowledge.\nIt seems reasonable that if all we know is that $s$ is an\nelement of a finite set $S$ of propositions, and the fraction of propositions\nin $S$ that are provable is $ x $, then \\(\\mu(s) = x\\).\nAn example is the Fermat primality test \\cite{fermat}.\nIf $n$ is an integer, $n>2$, and $ 2^{n-1}  \\equiv 1 \\pmod{n}$, and $n$\nis not prime, then $n$ is called a pseudoprime to base $2$.\nBetween $3$ and $25 \\cdot 10^9$\nthere are $N_1 = 21853$ pseudoprimes to base $2$ and\n$N_2 = 1091987404$ primes.\nTherefore, if we only know $3 \\leq n \\leq 25 \\cdot 10^9$ and\n$ 2^{n-1}  \\equiv 1 \\pmod{n}$, we could say \\(\\mu(\\text{``}n \\text{ is prime''})\n= N_2 / (N_1 + N_2) \\doteq 0.99998\\).\n\nIn general, however, defining \\(\\mu\\) is not so obvious.\nThe value \\(\\mu(s)\\) must be computed quickly or we might have time to simply\nprove \\(s\\) or \\(\\neg s \\) and not bother with probabilities.\nThere is a temptation to look into Solomonoff\ninduction as a model of inductive reasoning applied to mathematical knowledge.\nThis would be an attempt to formalize,\ne.g.\\ P\\'olya's patterns of plausible reasoning \\cite{polya}, such as\n``$A$ analogous to $B$, $B$ more credible $\\implies A$ somewhat more\ncredible''.\nHowever we must be cautious, because an incomputable prior is the complete\nopposite of a quickly-computable value.\n\nAt present many works have been written on the topic\n\\cite{zo2,zo3,zo4,zo5,zo6,zo7,zo8,zo9,zo10,zo11,zo12,zo13,zo14,zo15,zo16}.\nDespite the progress, Soares et al.\\ \\cite{zo15} conclude,\n``a theoretical understanding of logically uncertain reasoning \\ldots does not\nyet exist''.\n\nWe make the following proposal.\nAs Wilf states \\cite[VIII.5]{companion}, the process of \\emph{proving} a\nproposition usually involves gathering data by computing initial cases or\nedge cases, comparing with analogous propositions, etc., and using this\nevidence to form conjectures in which mathematicians have some degree of\nbelief.\nThe implications of these conjectures then direct the proof (or disproof)\nstrategy.\nTherefore a system for dealing with logical uncertainty\nwill be implicitly or explicitly part of any automated theorem prover that\nworks at all similarly to humans in this manner.\nIf automated theorem provers can be analyzed according to any of the\nmethods we mention in this paper, the goal of formally modeling logical\nuncertainty is related to the goal of designing better automated theorem\nprovers.\nThat is, if the underlying goal behind logical uncertainty is really to help\ndevelop systems that actually prove propositions, we can simply analyze\nthe whole systems and not the logical uncertainty components separately.\nEven if we are interested in logical uncertainty for other reasons, we may\ncompare logical uncertainty schemes by comparing automated theorem provers\nthat incorporate them.\n\n\n\n\n\n\n\n\n\n\n\\section{Future work} \\label{sec:furtherwork}\n\nCertainly there may be additional useful methods of analysis of algorithms\nbeyond those mentioned in this article.\nThere may also be conditions under which one method is more appropriate than\nanother.\nIn general, we wish to explore more deeply how to model the ``efficiency''\nof an algorithm.\n\nAs mentioned in \\S~\\ref{subsec:mpl}, minimum-proof-length analysis is\nclosely related to computational complexity theory so the open problems in\nthat field are of interest.\n\nWe would like to be able to practically use expected-reward and solution rate\nanalysis with various parameter values, probability measures, and discount\nfunctions, on both terminating and non-terminating algorithms.\nParticularly, we would like to know whether {\\( \\mathbf{0}' \\) algorithms}\\ may be practically\nanalyzed.\nIt may be possible to develop general mathematical tools and techniques to\nenhance the practicality of these methods, such as exist for traditional\nanalysis;\nthis is a broad and open-ended research goal.\n\n\n\n\n\n\n\n\n\\addcontentsline{toc}{section}{Acknowledgements}\n\n\\section*{Acknowledgements}\n\nI would like to thank\n    Zhicheng Gao,\n    Nima Hoda, and\n    Saran Neti\n    for helpful comments.\n    The method in \\S~\\ref{subsec:nt} is based on ideas due to Vadim Kosoy.\n\n\n\n\n\\addcontentsline{toc}{section}{References}\n\n\\bibliographystyle{plain}\n\\setlength{\\bibsep}{0pt plus 0.3ex}\n\\small\\bibliography{AoAaPA}\n\n", "itemtype": "equation", "pos": 20798, "prevtext": "\nThe values of \\(E(N_t)\\) for different algorithms may be compared,\nasymptotically or otherwise, where greater values indicate a more efficient\nalgorithm.\nWe call this method \\emph{solution rate analysis}.\n\n\n\n\n\n\n\n\n\\section{Other theoretical applications of analysis of {\\( \\mathbf{0}' \\) algorithms}}\n\n\\subsection{Self-improving AI} \\label{subsec:selfimprovement}\n\nThe generality of \\({\\mathbf{0}'}\\) problems allows us to view design and analysis\nof {\\( \\mathbf{0}' \\) algorithms}\\ as a task which itself may be given to a {\\( \\mathbf{0}' \\) algorithm}, bringing about\nrecursive self-improvement.\nHere we present one possible concrete example of this notion and discuss\nconnections with AI.\n\nComputational problems with Turing degree \\({\\mathbf{0}'}\\) are Turing-equivalent so\nwithout loss of generality in this subsection we assume {\\( \\mathbf{0}' \\) algorithms}\\ are\nautomated theorem provers.\nSpecifically, we fix a formal logic system, say ZFC, and take the set of inputs\nto be ZFC sentences, and the possible outputs to be \\texttt{provable} and\n\\texttt{not provable}.\n\nLet a predicate \\(c\\) be such that \\(c(Z)\\) holds\niff \\(Z\\) is a {\\( \\mathbf{0}' \\) algorithm}\\ which is correct on provable inputs and does not terminate\notherwise.\nIn pseudocode we write the instruction to run some \\(Z\\) on input \\(\\omega\\) as\n\\(Z(\\omega)\\), and if \\(\\omega\\) contains \\(c\\) or \\(S\\) (the score function),\ntheir definitions are implicitly included.\n\nWe give an auxiliary procedure \\textsc{Search} which takes as input\na {\\( \\mathbf{0}' \\) algorithm}\\ \\(Z\\) and a rational number \\(x\\) and uses \\(Z\\) to obtain a {\\( \\mathbf{0}' \\) algorithm}\\ which\nsatisfies \\(c\\) and has score greater than \\(x\\) (if possible).\nSymbols in bold within a string literal get replaced by the value of the\ncorresponding variable.\nWe assume {\\( \\mathbf{0}' \\) algorithms}\\ are encoded as strings in a binary prefix code.\n\n\\vspace{0.5cm}\n\\begin{algorithmic}[1]\n  \\Procedure{Search}{$x, Z$}\n    \\State \\(u \\gets \\epsilon\\)\n    \\Loop\n    \\StartDo in parallel until one returns \\texttt{provable}:\n        \\State A: \\(Z(\\text{``}\\exists v:\n          (Z^* = \\mathbf{u}0v \\implies\n          c(Z^*) \\land S(Z^*)> \\mathbf{x}\\text{''}))\\)\n        \\State B: \\(Z(\\text{``}\\exists v:\n          (Z^* = \\mathbf{u}1v \\implies\n          c(Z^*) \\land S(Z^*)>\\mathbf{x}\\text{''}))\\)\n        \\State C: \\(Z(\\text{``} Z^*=\\mathbf{u} \\implies\n          c(Z^*) \\land S(Z^*)> \\mathbf{x}\\text{''})\\)\n      \\EndDo\n      \\If{A returned \\texttt{provable}}\n        \\State \\( u\\gets u0 \\)\n      \\EndIf\n      \\If{B returned \\texttt{provable}}\n        \\State \\(u \\gets u1 \\)\n      \\EndIf\n      \\If{C returned \\texttt{provable}}\n        \\State return \\( u \\)\n      \\EndIf\n    \\EndLoop\n  \\EndProcedure\n\\end{algorithmic}\n\\vspace{0.5cm}\n\nWe remark that the mechanism of \\textsc{Search} is purely syntactic and does\nnot rely on consistency or completeness of ZFC, or the provability thereof.\n\nThe following procedure \\textsc{Improve}\ntakes an initial {\\( \\mathbf{0}' \\) algorithm}\\ \\(Z_0\\) and uses dovetailed calls to \\textsc{Search} to\noutput a sequence of {\\( \\mathbf{0}' \\) algorithms}\\ that tend toward optimality.\n\\vspace{0.5cm}\n\\begin{algorithmic}[1]\n  \\Procedure{Improve}{$Z_0$}\n  \\State \\(best\\) \\( \\gets Z_0 \\),\\ \\ \n    \\( pool \\gets \\{ \\} \\),\\ \\ \n    \\( score \\gets 0 \\)\n  \\For{\\( n \\gets 1 \\textbf{ to } \\infty \\)}\n    \\State \\(a_n \\gets n\\)th term in Stern-Brocot enumeration of \\(\\mathbb{Q}\n      \\cap (0,1] \\)\n    \\If{\\( a_n > score \\)}\n      \\State \\(initialState \\gets\\) initial state of\n        \\textsc{Search}\\((a_n, best)\\)\n      \\State add \\( (a_n, best, initialState) \\) to \\(pool\\)\n    \\EndIf\n    \\State \\(improvementFound \\gets false\\)\n    \\For{\\((a, Z, state)\\) in \\(pool\\)}\n      \\State run \\textsc{Search}(\\(a, Z\\)) one step starting in state \\(state\\)\n      \\State \\(newState \\gets\\) new current state of \\textsc{Search}(\\(a, Z\\))\n      \\If{\\(state\\) is not a terminating state}\n      \\State in \\(pool\\), mutate \\((a,Z,state)\\) into \\((a,Z,newState)\\)\n        \\State continue\n      \\EndIf\n      \\State \\(improvementFound \\gets true\\)\n      \\State \\(best \\gets \\) output of \\textsc{Search}(\\(a, Z\\))\n      \\State \\(score \\gets a\\)\n      \\For{ \\((\\hat{a},\\hat{Z},\\hat{state})\\) in \\(pool\\)\n        where \\( \\hat{a} \\leq score \\)}\n        \\State remove \\((\\hat{a},\\hat{Z},\\hat{state})\\) from \\(pool\\)\n      \\EndFor\n      \\State print \\(best\\)\n    \\EndFor\n    \\If{\\(improvementFound\\)}\n      \\For{ \\((a,Z,state)\\) in \\(pool\\) }\n        \\State \\(initialState \\gets\\) initial state of\n          \\textsc{Search}\\((a, best)\\)\n        \\State add \\((a, best, initialState) \\) to \\(pool\\)\n      \\EndFor\n    \\EndIf\n  \\EndFor\n  \\EndProcedure\n\\end{algorithmic}\n\\vspace{0.5cm}\n\nThe procedure \\textsc{Improve} has the following basic property.\n\n\\begin{pro}\n  Let \\((Z_n)\\) be the sequence of {\\( \\mathbf{0}' \\) algorithms}\\ printed by \\textsc{Improve}.\n  If \\(c(Z_0)\\) holds, and if there are a {\\( \\mathbf{0}' \\) algorithm}\\ \\(B\\) and \\(s \\in \\mathbb{Q}\n  \\) where \\(S(B) > s > 0\\) is provable, we have\n", "index": 31, "text": "\n\\[\n  \\lim_{n \\rightarrow \\infty} S(Z_n) \\geq s.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"\\lim_{n\\rightarrow\\infty}S(Z_{n})\\geq s.\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>Z</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2265</mo><mi>s</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}]