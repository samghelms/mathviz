[{"file": "1601.07555.tex", "nexttext": "\nwhere $\\left\\langle {A_xB_y} \\right\\rangle=\\sum (-1)^{a_x+b_y}p(a_x,b_y)$ stand for the expectation value. Its entropic version \\cite{Braunstein1988,Chaves2012},\n\n", "itemtype": "equation", "pos": 10743, "prevtext": "\n\\title{Entropic nonsignalling correlations}\n\\date{\\today}\n\n\n\\author{Rafael Chaves}\n\\affiliation{Institute for Physics \\& FDM, University of Freiburg, 79104 Freiburg, Germany}\n\\affiliation{Institute for Theoretical Physics, University of Cologne, 50937 Cologne, Germany}\n\\author{Costantino Budroni}\n\\affiliation{Naturwissenschaftlich-Technische Fakult\\\"at, Universit\\\"at Siegen, Walter-Flex-Str. 3, D-57068 Siegen, Germany}\n\n\n\\begin{abstract}\nWe introduce the concept of entropic nonsignalling  correlations, i.e., entropies arising from\nprobabilistic theories that are compatible with the fact that we cannot transmit information instantaneously. We characterize and show the relevance of these entropic correlations in a variety of different scenarios, ranging from typical Bell experiments to more refined descriptions such as bilocality and information causality. In particular, we apply the framework to derive the first entropic inequality testing genuine tripartite nonlocality in quantum systems of arbitrary dimension and also prove the first known monogamy relation for entropic Bell inequalities. Further, within the context of complex Bell networks, we show that entropic nonlocal correlations can be activated.\n\\end{abstract}\n\n\n\\maketitle\n\nQuantum nonlocality --the fact that correlations obtained in quantum experiments performed\nby distant parties are incompatible with local hidden variable (LHV) models\n\\cite{Bell1964}-- brings to light an intriguing aspect of quantum mechanics (QM) and\nrelativistic causality \\cite{popescu2014nonlocality}. QM is in accordance with the\nnonsignalling (NS) principle, that is, local manipulations by an experimenter cannot\ninfluence the measurement outcomes of other distant experimenters. However, as demonstrated\nby Popescu and Rohrlich \\cite{Popescu1994}, special relativity alone cannot single out\nquantum mechanical correlations as there are theories, beyond QM,  also in agreement with\nNS. This result not only has triggered the search for physically well motivated principles\nfor quantum mechanics\n\\cite{Navascues2010glance,Navascues2014almost,Pawlowski2009,Fritz2013local,Cabello2013,Sainz2014}\nbut also has led to new insights about its limitations for information processing\n\\cite{Van1999nonlocality,Brassard2006limit,Chiribella2010,Almeida2010,Chaves2015a}.\n\nGiven the intrinsic statistical nature of QM, probabilities give a natural framework for\nnonlocality. Indeed, Bell inequalities and NS relations are nothing else than constraints on\nprobabilities arising in a given theory, local and NS, respectively \\cite{Brunner2014}.\nNevertheless, different approaches are possible\n\\cite{abramsky2011sheaf,Braunstein1988,Chaves2012}. In particular, in the\ninformation-theoretic approach to nonlocality\n\\cite{Braunstein1988,Cerf1997,Chaves2012,FritzChaves2013,Chaves2014,\nDagomir2014,raeisi2015entropic} the basic objects are the Shannon entropies \\cite{Yeung2008}\nof the observed data.\n\nThe information-theoretic approach provides a novel and useful alternative for both\nconceptual and technical reasons. First, entropy is a key concept in both classical and\nquantum information theory, thus developing a framework that focus on entropies rather than\nprobabilities leads to new insights and applications\n\\cite{Barnum2010entropy,Dahlsten2012tsirelson,Janzing2013,Chaves2014b,Henson2014,poh2015probing,Chaves2015entropy,janzing2015algorithmic}.\nFor instance, the celebrated principle of information causality \\cite{Pawlowski2009} is\nnothing else than an entropic inequality bounding the correlations that can be achieved by\nimposing a certain causal structure to quantum mechanics \\cite{Chaves2015a}. Second,\nentropies allow for a much simpler and compact characterization of classical and quantum\ncorrelations in a variety of scenarios, most notably generalized Bell scenarios\n\\cite{Chaves2012,Fritz2012,Chaves2014,Henson2014}.\nIn spite of that, as opposed to the usual probabilistic description, little is known about\nentropic Bell inequalities beyond very simple cases and remarkably nothing is known about\nthe structure imposed by the nonsignalling principle on the entropies of measurement\noutcomes.\n\nIn this paper, we aim to further develop the information-theoretic approach to nonlocality\nand, in particular, to define the concept of entropic nonsignalling correlations, i.e., the\nentropies compatible with the nonsignalling principle. We characterize NS entropic\ncorrelations in a variety scenarios: from usual bipartite and tripartite, to genuine\nmultipartite nonlocality \\cite{Svetlichny1987,Gallego2012,Pironio2013,Pironio2013},\nbilocality \\cite{Branciard2010}, and information causality \\cite{Pawlowski2009} scenarios.\nOur framework can also be employed to derive monogamy relations\n\\cite{Masanes2006,Pawlowski2009b} between entropic Bell inequalities.\nFurthermore, our methods highlight the use of entropic NS correlations as novel tool to derive Bell inequalities in scenarios otherwise intractable.\n\n\\textit{Marginal scenarios, local and NS correlations.---}\nIn a quantum experiment, only some of the relevant observables are jointly measurable,\nhence, we face fundamental restriction on the empirically accessible joint probability\ndistributions. This fact is encoded in the notion of a marginal scenario. Given $n$ random\nvariables $\\left\\{ X_1,\\dots,X_n \\right\\}$, a marginal scenario $\\mathcal{M}$ is defined as\n$\\mathcal{M}=\\left\\{ S_1,\\dots, S_{\\vert \\mathcal{M} \\vert} \\right\\}$, $S_i \\subseteq \\left\\{ X_1,\\dots,X_n \\right\\}$, such that for each $S_i$ a joint probability distribution\n$P((X_s)_{s\\in S_i})$ is accessible \\cite{Chaves2012,FritzChaves2013}. Clearly, it is\nsufficient to consider maximal subsets.\n\nA typical example is a Bell experiment: two separated parties, Alice and Bob, at each run of the experiment can perform one of $m$ different measurements, labelled as $A_x$ and $B_y$, respectively, on their shares of a joint system. Their marginal scenario is, then, $\\mathcal{M}_{\\mathrm{Bell}}=\\left\\{\\left\\{A_x,B_y \\right\\}\\right\\}_{x,y=1,\\ldots,m}$, corresponding to the probability distributions ${\\mathbf{p}}_{\\mathrm{Obs}}=p(a_x,b_y)$ \\cite{fnote1} --where $a_x$ labels the outcome when measurement $x$ has been performed (similarly for $b$)--\nestimated from the statistical data. As shown by Fine \\cite{Fine1982}, a LHV model for the data can be equivalently defined as a joint probability distribution ${\\mathbf{p}}=p(a_1,\\dots,a_{m},b_1,\\dots,b_m)$. Hence, a set of marginals is called local if it is consistent with a single joint probability distribution for all measurements.\nThis, in turn, implies the existence of a joint entropy of all possible measurements $H_{A_1 \\dots A_{m} B_1 \\dots B_m}$ and all its marginals \\cite{Braunstein1988}, where $H_{X}:= H(X):=-\\sum_{x}p(x)\\log_2 p(x)$ stands for the Shannon entropy. They can be represented as a {$2^{2m}$-dimensional} vector ${\\mathbf{h}}=\\left\\{H_{\\emptyset}, H_{A_1},\\dots, H_{A_1 \\dots A_{m} B_1\\dots B_m}) \\right)$.\n\nThe difference between the probabilistic and entropic description solely relies on how we quantify correlations. A marginal probability distribution ${\\mathbf{p}}_{\\mathrm{Obs}}$ is local if we can construct a well defined joint probability distribution ${\\mathbf{p}}$. Similarly, marginal entropies ${\\mathbf{h}}_{\\mathrm{Obs}}=H(A_x,B_z)$ are local if a joint entropy (and all its marginals) ${\\mathbf{h}}$ can be defined.\nThe existence of a well defined joint description ${\\mathbf{p}}$ imposes strict constraints --the famous Bell inequalities-- on the empirically observable marginal correlations ${\\mathbf{p}}_{\\mathrm{Obs}}$ \\cite{Fine1982,Pitowsky1989,Pitowsky1991}. Similarly, marginal entropic correlations ${\\mathbf{h}}_{\\mathrm{Obs}}$ admitting an extension to ${\\mathbf{h}}$ also obey strict constraints. The closure set of well defined entropy vectors ${\\mathbf{h}}$ defines a convex cone $\\Gamma_{\\rm E}$ for which a explicit characterization is yet to be found (cf. Appendix). Nicely, however, an outer approximation, characterized by finitely many linear inequalities \\cite{Yeung2008} or, equivalently, in terms of finitely many extremal rays (vectors defined up to a positive factor  \\cite{aliprantis2007cones}), is known: the Shannon cone $\\Gamma_{\\mathrm{Sh}}$. In full analogy with the probabilistic case \\cite{Budroni12}, entropic Bell inequalities can be understood as the constraints arising from the projection of $\\Gamma_{\\rm E}$ onto observable coordinates, that is, the projection of ${\\mathbf{h}}$ into ${\\mathbf{h}}_{\\mathrm{Obs}}$ defining the Bell entropic cone $\\Gamma_{\\mathrm{Bell}}$.\n\nOn the other hand, NS probabilities are defined as those where the outcomes of a part do not depend on the measurements performed by another distant part, i.e.,\nsuch that $p(a_x)=\\sum_{b}p(a_x,b_y)=\\sum_{b}p(a_x,b_{y^{\\prime}})$ (similarly for $b$ and for any number of parties). NS correlations are then defined by the above linear constraints (NS conditions) together with the non-negativity condition $p\\geq 0$, i.e., they are classical probability distribution whenever restricted to $p(a_x,b_y)$, with consistent marginals. Geometrically, they can be seen as the intersection of the simplex polytopes \\cite{boyd_convex_2009} defining each of the probabilities $p(a_x,b_y)$ and thus overlapping over the marginals $p(a_x)$ and $p(b_y)$. We can then naturally define NS entropic cone, for a marginal scenario  $\\mathcal{M}=\\left\\{ S_1,\\dots, S_{\\vert \\mathcal{M} \\vert} \\right\\}$, as the intersection $\\Gamma_{\\mathrm{NS}}=\\Gamma_i \\cap \\dots \\cap \\Gamma_{\\vert \\mathcal{M} \\vert}$, where $\\Gamma_i$ is the entropy cone associated with $S_i$ (see {Fig.~\\ref{{fig:NScone}}}).\n\nIn the following, we apply the above framework to analyze from an entropic perspective a broad range of scenarios. Notice that for $n\\leq 3$ variables, the entropy cone corresponds to the Shannon cone, i.e., $\\Gamma_{\\rm E}^n = \\Gamma_{\\rm Sh}^n$ \\cite{Yeung2008}, hence all results for the bipartite and tripartite cases lead to the exact description of the NS cones. Further discussions and technical details can be found in the appendix.\n\n\n\\begin{figure}[ht]\n\\vspace{0.6cm}\n\\center\n\\includegraphics[width=0.51\\columnwidth]{cones4}\n\\caption{Pictorial illustration of the NS entropic cone.\n}\n\\label{fig:NScone}\n\\end{figure}\n\n\n\n\\textit{Bipartite and tripartite scenarios.---}\nWe start with the simplest Bell scenario as above, for $m=2$. In contrast to the probabilistic case, entropic correlations are concisely defined for an arbitrary number of measurement outcomes, highlighting another advantage of the entropic approach. For dichotomic observables ($a_x,b_y=0,1$), the only non-trivial probabilistic Bell inequality is the CHSH inequality \\cite{Clauser1969}\n\n", "index": 1, "text": "\\begin{equation}\n\\label{CHSH}\nS=\\left\\langle {A_0B_0} \\right\\rangle+\\left\\langle {A_0B_1} \\right\\rangle+\\left\\langle {A_1B_0} \\right\\rangle-\\left\\langle {A_1B_1} \\right\\rangle-2 \\leq 0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"S=\\left\\langle{A_{0}B_{0}}\\right\\rangle+\\left\\langle{A_{0}B_{1}}\\right\\rangle+%&#10;\\left\\langle{A_{1}B_{0}}\\right\\rangle-\\left\\langle{A_{1}B_{1}}\\right\\rangle-2%&#10;\\leq 0,\" display=\"block\"><mrow><mrow><mi>S</mi><mo>=</mo><mrow><mrow><mrow><mo>\u27e8</mo><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>B</mi><mn>0</mn></msub></mrow><mo>\u27e9</mo></mrow><mo>+</mo><mrow><mo>\u27e8</mo><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>B</mi><mn>1</mn></msub></mrow><mo>\u27e9</mo></mrow><mo>+</mo><mrow><mo>\u27e8</mo><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>B</mi><mn>0</mn></msub></mrow><mo>\u27e9</mo></mrow></mrow><mo>-</mo><mrow><mo>\u27e8</mo><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>B</mi><mn>1</mn></msub></mrow><mo>\u27e9</mo></mrow><mo>-</mo><mn>2</mn></mrow><mo>\u2264</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nis valid for any number of outcomes, where $I_{A_x:B_y}=H_{A_x}+H_{B_y}-H_{A_xB_y}$ represents the mutual information.\n\nBoth inequalities are maximally violated by an extremal point/ray characterizing the NS correlations. Eq.~\\eqref{CHSH} is maximally violated by the Popescu-Rohrlich (PR)-box $p_{\\mathrm{PR}}(a_x,b_y)=(1/2)\\delta_{a\\oplus b,xy}$. However, $p_{\\mathrm{PR}}$ is entropically equivalent to the classical correlation $p_{\\mathrm{C}}(a_x,b_y)=(1/2)\\delta_{a\\oplus b,0}$ and thus cannot violate \\eqref{ECHSH}. On the other hand, Eq.~\\eqref{ECHSH} is maximally violated by $H(A_x,B_y)=\\log_2(d)(1+xy)$, with marginals $H(A_x)=H(B_y)=\\log_2(d)$ and $d$ the number of outcomes. Thus, this correlation can be interpreted as the entropic counterpart of a PR-box. For $d=2$, these entropies are obtained as an equal mixture of $p_{\\mathrm{PR}}$ and $p_{\\mathrm{C}}$. The mixing with $p_{\\mathrm{C}}$ is exactly the method proposed in \\cite{Chaves2013a} to turn entropic inequalities into necessary and sufficient conditions for nonlocality detection. It is thus appealing that the NS entropic cone naturally retrieves this sort of correlations.\n\nAnother important result of our approach is the derivation of the first entropic monogamy relation for Bell inequalities.\nThe monogamy of Bell inequalities violations is a general feature of NS theories \\cite{Masanes2006}, and it can be understood by the following example. For a tripartite distribution $p(a_x,b_y,c_z)$ with binary inputs/outputs, whenever the marginal distribution $p(a_x,b_y)$ violates the CHSH inequality necessarily $p(a_x,c_z)$ must be local. Similarly, from the definition of NS entropic cone, we are able to prove that\n\n", "itemtype": "equation", "pos": 11106, "prevtext": "\nwhere $\\left\\langle {A_xB_y} \\right\\rangle=\\sum (-1)^{a_x+b_y}p(a_x,b_y)$ stand for the expectation value. Its entropic version \\cite{Braunstein1988,Chaves2012},\n\n", "index": 3, "text": "\\begin{equation}\n\\label{ECHSH}\nS_{\\mathrm{E}}=I_{A_0:B_0} +I_{A_0:B_1} +I_{A_1:B_0}-I_{A_1:B_1} -H_{A_0}-H_{B_0} \\leq 0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"S_{\\mathrm{E}}=I_{A_{0}:B_{0}}+I_{A_{0}:B_{1}}+I_{A_{1}:B_{0}}-I_{A_{1}:B_{1}}%&#10;-H_{A_{0}}-H_{B_{0}}\\leq 0,\" display=\"block\"><mrow><mrow><msub><mi>S</mi><mi mathvariant=\"normal\">E</mi></msub><mo>=</mo><mrow><mrow><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>B</mi><mn>0</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>B</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>B</mi><mn>0</mn></msub></mrow></msub></mrow><mo>-</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>B</mi><mn>1</mn></msub></mrow></msub><mo>-</mo><msub><mi>H</mi><msub><mi>A</mi><mn>0</mn></msub></msub><mo>-</mo><msub><mi>H</mi><msub><mi>B</mi><mn>0</mn></msub></msub></mrow><mo>\u2264</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nmeaning that both entropic Bell inequalities, between Alice-Bob and Alice-Charlie, cannot be violated at the same time, with the notable difference that this monogamy inequality is valid for any number of outcomes.\n\nThe similarities between the probabilistic and entropic approaches, which may suggest a deeper geometric connection \\cite{Chaves2014}, already disappear in the tripartite scenario. For the case of three parties and two settings, the probabilistic NS correlations for dichotomic measurements consist of $46$ different classes of extremal points, with $45$ of them nonlocal \\cite{pironio2011extremal}. In turn, the entropic NS cone is characterized by $1292$ different classes of extremal rays, $1164$ of which correspond to nonlocal correlations. As it turns out, already at the tripartite case we obtain a much more complex structure than the one we could naively presume from the probabilistic description.\n\n\n\\textit{Genuine tripartite entropic nonlocality.---}\nIn analogy to entanglement \\cite{horodecki2009quantum}, when moving beyond the bipartite\ncase, different classes of nonlocality arise. With three parties, one can introduce the\nnotion of genuine tripartite nonlocality, that is, a stronger form of nonlocality that\ncannot be reproduced even if any two of the parties are allowed to share some nonlocal\nresources \\cite{Svetlichny1987,Gallego2012,Pironio2013}.\nWe focus our attention to nonsignalling resources (e.g., a PR-box) and two possible\nmeasurements per party, extensions to more measurements and parties are straightforward. For a given bipartition, say $A|BC$, a hybrid local-nonsignalling (L$|$NS)\nmodel is equivalent to the existence of probability distributions $p(a_0,a_1,b_j,c_k)$, with\nconsistent marginal $p(a_0,a_1,b_j), p(a_0,a_1,c_k)$, i.e., Alice has local correlations and\nBob and Charlie share nonsignalling correlations. Genuine tripartite nonlocal (GTNL)\ncorrelations correspond to marginals $p(a_i,b_j,c_k)$ that cannot be explained as a convex\ncombination of models of the type $A|BC$, $B|AC$, and $C|AB$.\n\nAnalogously to the NS case, an entropic $A|BC$ model corresponds to the joint entropies\n$H(A_0,A_1,B_j,C_k)$, $j,k=0,1$, and all its marginals, and similarly for $B|AC$, and\n$C|AB$.  We can then define the L$|$NS entropic correlations via the cone\n$\\Gamma_{\\mathrm{L}|\\mathrm{NS}}$, constructed as the convex hull (i.e., set of convex\ncombinations) of the entropic cones for each of the model $A|BC$, $B|AC$, and $C|AB$. In\nturn, GTNL entropic correlations are those lying outside $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}$.\n\nFrom the $1164$ different classes of extremal nonlocal rays defining the tripartite\nscenario, $932$ correspond to GTNL correlations. One of these rays correspond to the\ndistribution $(1/2)(p_{\\mathrm{XYZ}}+p_{\\mathrm{C}})$, that is, the mixing of\n$p_{\\mathrm{XYZ}}(a,b,c \\vert x,y,z)=(1/4)\\delta_{a\\oplus b \\oplus c,xyz}$\n\\cite{Barrett2005b} with classical correlations\n$p_{\\mathrm{C}}(a,b,c \\vert x,y,z)=(1/4)\\delta_{a\\oplus b \\oplus c,0}$. The GTNL character\nof this correlation can be witnessed by the violation of the following entropic inequality\nvalid for any L$|$NS correlation with arbitrary number of outcomes:\n\\begin{eqnarray}\n\\nonumber\n\\label{EGTNL}\n& & S_{\\mathrm{L}|\\mathrm{NS}} = H_{A_1B_1C_0} + H_{A_1B_0C_0} + H_{A_1B_0C_1} + H_{A_0B_1C_0}  \\\\\n& &- H_{A_1B_1C_1} -H_{A_1B_0}- H_{A_1C_0}- H_{A_0C_1} - H_{B_1C_0} \\geq 0.\n\\end{eqnarray}\nFurthermore, inequality \\eqref{EGTNL} can also be used to witness the GTNL in quantum\nstates, for instance using d-dimensional GHZ states\n${| {\\mathrm{GHZ}} \\rangle}=(1/\\sqrt{d})\\sum_{j=0}^{d-1} {| {jjj} \\rangle}$ and projective measurements \\cite{Collins2002}. Results are plotted in Fig.~\\ref{fig:GTNL_GHZ} up to $d=40$.\n\n\\begin{figure}[ht]\n\\vspace{0.6cm}\n\\center\n\\includegraphics[width=0.98\\columnwidth]{GHZ_GTNL2}\n\\caption{The violation of inequality $S_{\\mathrm{L}|\\mathrm{NS}} \\geq 0$ using GHZ states. The black points stand for the violation obtained via numerical optimization over the projective measurements in \\cite{Collins2002}.\n}\n\\label{fig:GTNL_GHZ}\n\\end{figure}\n\n\n\n\\textit{Activating entropic nonlocality in networks.---}\nThe tripartite scenario permits also another possibility: that the correlations between the\nparties are mediated by independent sources. The paradigmatic example is the entanglement\nswapping experiment \\cite{Zukowski1993}. Two independent pairs of entangled particles are\ndistributed among three spatially separated parties: Bob receives one particle of each pair,\nand Alice and Charlie the remaining two. By jointly measuring his particles, Bob can\ngenerate (upon conditioning on outcomes) entanglement and nonlocal correlations between the\ntwo remaining particles, even thought the latter have never interacted. A probabilistic and local\nrealistic description of this experiment involves two independent hidden variables, the so\ncalled bilocality assumption \\cite{Branciard2010,Tavakoli2014,Chaves2015b,Chaves2016,Rosset2016}, implying the independence relation\n$p(a,c)=p(a)p(c)$, i.e., no correlations between Alice and Charlie. The local and NS\ncorrelations in the bilocality scenario are defined by infinitely many extremal points and\nis extremely challenging to characterize \\cite{Chaves2016}.\n\nThe advantages of the entropic description are here apparent: independence\nconstraints are encoded in simple linear relations, e.g.,\n${p(a,c)=p(a)p(c) \\rightarrow I(A:C)=0}$. Geometrically,\na set of extra linear constraints\n$L{\\mathbf{h}}=0$, as the one above, corresponds to the intersection of the (polyhedral) convex cone\n(e.g.,$\\Gamma_{\\mathrm{Bell}}$ or $\\Gamma_{\\mathrm{NS}}$)  with a linear subspace, which is\nstill a (polyhedral) convex cone \\cite{fnote2}.\n\nFor the case of two settings per party, we have fully characterized the set of NS bilocal correlations: we found $329$ different classes of extremal rays, of which $314$ are nonlocal. Out of these, $40$ are genuinely nonbilocal, i.e., the correlations admit a LHV model but not a bilocal LHV model. A particularly interesting extremal correlation is the following $H(A_0,B,C)=H(A_1,B,C)=H(A_1,B)=H(A_0,C)=H(A_1,C)=H(B,C)=2$ and $H(A_0,B)=H(A_0)=H(A_0)=H(B)=H(C)=1$. It can be understood as the case where Bob and Charlie always measure the same observable (no measurement choice) while Alice still can perform two different measurements. Clearly, since only one of the parties has measurements choices, all correlations arising in this scenario are compatible with a LHV model. However, this correlation is not bilocal, as it can be witnessed by the violation of the entropic inequality valid for any bilocal decomposition:\n\n", "itemtype": "equation", "pos": 12939, "prevtext": "\nis valid for any number of outcomes, where $I_{A_x:B_y}=H_{A_x}+H_{B_y}-H_{A_xB_y}$ represents the mutual information.\n\nBoth inequalities are maximally violated by an extremal point/ray characterizing the NS correlations. Eq.~\\eqref{CHSH} is maximally violated by the Popescu-Rohrlich (PR)-box $p_{\\mathrm{PR}}(a_x,b_y)=(1/2)\\delta_{a\\oplus b,xy}$. However, $p_{\\mathrm{PR}}$ is entropically equivalent to the classical correlation $p_{\\mathrm{C}}(a_x,b_y)=(1/2)\\delta_{a\\oplus b,0}$ and thus cannot violate \\eqref{ECHSH}. On the other hand, Eq.~\\eqref{ECHSH} is maximally violated by $H(A_x,B_y)=\\log_2(d)(1+xy)$, with marginals $H(A_x)=H(B_y)=\\log_2(d)$ and $d$ the number of outcomes. Thus, this correlation can be interpreted as the entropic counterpart of a PR-box. For $d=2$, these entropies are obtained as an equal mixture of $p_{\\mathrm{PR}}$ and $p_{\\mathrm{C}}$. The mixing with $p_{\\mathrm{C}}$ is exactly the method proposed in \\cite{Chaves2013a} to turn entropic inequalities into necessary and sufficient conditions for nonlocality detection. It is thus appealing that the NS entropic cone naturally retrieves this sort of correlations.\n\nAnother important result of our approach is the derivation of the first entropic monogamy relation for Bell inequalities.\nThe monogamy of Bell inequalities violations is a general feature of NS theories \\cite{Masanes2006}, and it can be understood by the following example. For a tripartite distribution $p(a_x,b_y,c_z)$ with binary inputs/outputs, whenever the marginal distribution $p(a_x,b_y)$ violates the CHSH inequality necessarily $p(a_x,c_z)$ must be local. Similarly, from the definition of NS entropic cone, we are able to prove that\n\n", "index": 5, "text": "\\begin{equation}\n\\label{monogamy}\nS^{AB}_{\\mathrm{E}}+S^{AC}_{\\mathrm{E}}\\leq 0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"S^{AB}_{\\mathrm{E}}+S^{AC}_{\\mathrm{E}}\\leq 0,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msubsup><mo>+</mo><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>C</mi></mrow></msubsup></mrow><mo>\u2264</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nThe entropic correlation above arises from a probability distribution $p(a,b,c \\vert x)=(1/4)\\delta_{a\\oplus b,xc}$, obtained when Alice and Bob share a PR-box $p_{\\mathrm{PR}}$\nwhile Bob and Charlie share a classical correlated distribution $p_{\\mathrm{C}}$. To that\naim, Bob assigns $b$ to the output of his share of the PR-box that takes as input the bit\nthat is classically correlated with the output $c$ of Charlie. This result illustrates two\nnovel aspects of the bilocality scenario. First, we see that the nonlocality of the PR-box,\nwhich in CHSH scenario is entropically equivalent to a classical correlation, can be\nactivated by employing it in a network. Even more remarkable is the fact that the emergence\nof nonlocal correlations only requires one out of the three parties to have access to\nmeasurement choices. This is similar to what has been observed in\n\\cite{Branciard2012,Fritz2012}, where it has been argued that since the role of Charlie can be\ninterpreted as defining measurement choices for Bob, this scenario can me mapped to the CHSH\none. In our case, however, we do not need to hinge on this mapping, since we violate a new\nsort of entropic Bell inequality. Thus, as opposed to Refs. \\cite{Branciard2012,Fritz2012},\nour result does not rely on Bell's theorem.\n\nAnother genuinely nonbilocal extremal entropic ray is associated with the probability $p(a,b,c\\vert x,y,z)=(1/8)(\\delta_{a\\oplus b \\oplus c,xyz\\oplus xy \\oplus xz \\oplus yz \\oplus z \\oplus 1}+\\delta_{a \\oplus b \\oplus c,0})$. Its nonbilocality can be witnessed via the violation of\n\\begin{eqnarray}\n\\label{bilocal_ineq2}\nS_{\\mathrm{BL}}= & & -H_{A_0B_0C_0}+H_{A_1B_1C_0}  \\\\ \\nonumber\n& & +H_{A_0B_0C_1}+H_{A_1B_1C_1}-H_{A_1,C_1}-H_{A_1,B_1} \\geq 0,\n\\end{eqnarray}\nspecifically, with value $S_{\\mathrm{BL}}=-1$. As opposed to other known inequalities \\cite{Branciard2010,Branciard2012,Chaves2016,Rosset2016}, Eq.~\\eqref{bilocal_ineq2} includes marginal terms, and it is valid for an arbitrary number of outcomes.\n\n\\textit{Information Causality.---}\nInformation causality (IC) \\cite{Pawlowski2009} is a principle introduced to explain the limitation of quantum correlations, i.e., Tsirelson bound \\cite{Cirel1980quantum}. It can be understood as a game: Alice receives two independent random bits $X_0$ and $X_1$ and the task of Bob is to guess, at each run of the experiment, the value of one of them, having as resources some pre-shared correlations with Alice and some classical communication ($H(M)$ bits) sent by her. For shared quantum correlations, the following inequality holds \\cite{Pawlowski2009}:\n\n", "itemtype": "equation", "pos": 19692, "prevtext": "\nmeaning that both entropic Bell inequalities, between Alice-Bob and Alice-Charlie, cannot be violated at the same time, with the notable difference that this monogamy inequality is valid for any number of outcomes.\n\nThe similarities between the probabilistic and entropic approaches, which may suggest a deeper geometric connection \\cite{Chaves2014}, already disappear in the tripartite scenario. For the case of three parties and two settings, the probabilistic NS correlations for dichotomic measurements consist of $46$ different classes of extremal points, with $45$ of them nonlocal \\cite{pironio2011extremal}. In turn, the entropic NS cone is characterized by $1292$ different classes of extremal rays, $1164$ of which correspond to nonlocal correlations. As it turns out, already at the tripartite case we obtain a much more complex structure than the one we could naively presume from the probabilistic description.\n\n\n\\textit{Genuine tripartite entropic nonlocality.---}\nIn analogy to entanglement \\cite{horodecki2009quantum}, when moving beyond the bipartite\ncase, different classes of nonlocality arise. With three parties, one can introduce the\nnotion of genuine tripartite nonlocality, that is, a stronger form of nonlocality that\ncannot be reproduced even if any two of the parties are allowed to share some nonlocal\nresources \\cite{Svetlichny1987,Gallego2012,Pironio2013}.\nWe focus our attention to nonsignalling resources (e.g., a PR-box) and two possible\nmeasurements per party, extensions to more measurements and parties are straightforward. For a given bipartition, say $A|BC$, a hybrid local-nonsignalling (L$|$NS)\nmodel is equivalent to the existence of probability distributions $p(a_0,a_1,b_j,c_k)$, with\nconsistent marginal $p(a_0,a_1,b_j), p(a_0,a_1,c_k)$, i.e., Alice has local correlations and\nBob and Charlie share nonsignalling correlations. Genuine tripartite nonlocal (GTNL)\ncorrelations correspond to marginals $p(a_i,b_j,c_k)$ that cannot be explained as a convex\ncombination of models of the type $A|BC$, $B|AC$, and $C|AB$.\n\nAnalogously to the NS case, an entropic $A|BC$ model corresponds to the joint entropies\n$H(A_0,A_1,B_j,C_k)$, $j,k=0,1$, and all its marginals, and similarly for $B|AC$, and\n$C|AB$.  We can then define the L$|$NS entropic correlations via the cone\n$\\Gamma_{\\mathrm{L}|\\mathrm{NS}}$, constructed as the convex hull (i.e., set of convex\ncombinations) of the entropic cones for each of the model $A|BC$, $B|AC$, and $C|AB$. In\nturn, GTNL entropic correlations are those lying outside $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}$.\n\nFrom the $1164$ different classes of extremal nonlocal rays defining the tripartite\nscenario, $932$ correspond to GTNL correlations. One of these rays correspond to the\ndistribution $(1/2)(p_{\\mathrm{XYZ}}+p_{\\mathrm{C}})$, that is, the mixing of\n$p_{\\mathrm{XYZ}}(a,b,c \\vert x,y,z)=(1/4)\\delta_{a\\oplus b \\oplus c,xyz}$\n\\cite{Barrett2005b} with classical correlations\n$p_{\\mathrm{C}}(a,b,c \\vert x,y,z)=(1/4)\\delta_{a\\oplus b \\oplus c,0}$. The GTNL character\nof this correlation can be witnessed by the violation of the following entropic inequality\nvalid for any L$|$NS correlation with arbitrary number of outcomes:\n\\begin{eqnarray}\n\\nonumber\n\\label{EGTNL}\n& & S_{\\mathrm{L}|\\mathrm{NS}} = H_{A_1B_1C_0} + H_{A_1B_0C_0} + H_{A_1B_0C_1} + H_{A_0B_1C_0}  \\\\\n& &- H_{A_1B_1C_1} -H_{A_1B_0}- H_{A_1C_0}- H_{A_0C_1} - H_{B_1C_0} \\geq 0.\n\\end{eqnarray}\nFurthermore, inequality \\eqref{EGTNL} can also be used to witness the GTNL in quantum\nstates, for instance using d-dimensional GHZ states\n${| {\\mathrm{GHZ}} \\rangle}=(1/\\sqrt{d})\\sum_{j=0}^{d-1} {| {jjj} \\rangle}$ and projective measurements \\cite{Collins2002}. Results are plotted in Fig.~\\ref{fig:GTNL_GHZ} up to $d=40$.\n\n\\begin{figure}[ht]\n\\vspace{0.6cm}\n\\center\n\\includegraphics[width=0.98\\columnwidth]{GHZ_GTNL2}\n\\caption{The violation of inequality $S_{\\mathrm{L}|\\mathrm{NS}} \\geq 0$ using GHZ states. The black points stand for the violation obtained via numerical optimization over the projective measurements in \\cite{Collins2002}.\n}\n\\label{fig:GTNL_GHZ}\n\\end{figure}\n\n\n\n\\textit{Activating entropic nonlocality in networks.---}\nThe tripartite scenario permits also another possibility: that the correlations between the\nparties are mediated by independent sources. The paradigmatic example is the entanglement\nswapping experiment \\cite{Zukowski1993}. Two independent pairs of entangled particles are\ndistributed among three spatially separated parties: Bob receives one particle of each pair,\nand Alice and Charlie the remaining two. By jointly measuring his particles, Bob can\ngenerate (upon conditioning on outcomes) entanglement and nonlocal correlations between the\ntwo remaining particles, even thought the latter have never interacted. A probabilistic and local\nrealistic description of this experiment involves two independent hidden variables, the so\ncalled bilocality assumption \\cite{Branciard2010,Tavakoli2014,Chaves2015b,Chaves2016,Rosset2016}, implying the independence relation\n$p(a,c)=p(a)p(c)$, i.e., no correlations between Alice and Charlie. The local and NS\ncorrelations in the bilocality scenario are defined by infinitely many extremal points and\nis extremely challenging to characterize \\cite{Chaves2016}.\n\nThe advantages of the entropic description are here apparent: independence\nconstraints are encoded in simple linear relations, e.g.,\n${p(a,c)=p(a)p(c) \\rightarrow I(A:C)=0}$. Geometrically,\na set of extra linear constraints\n$L{\\mathbf{h}}=0$, as the one above, corresponds to the intersection of the (polyhedral) convex cone\n(e.g.,$\\Gamma_{\\mathrm{Bell}}$ or $\\Gamma_{\\mathrm{NS}}$)  with a linear subspace, which is\nstill a (polyhedral) convex cone \\cite{fnote2}.\n\nFor the case of two settings per party, we have fully characterized the set of NS bilocal correlations: we found $329$ different classes of extremal rays, of which $314$ are nonlocal. Out of these, $40$ are genuinely nonbilocal, i.e., the correlations admit a LHV model but not a bilocal LHV model. A particularly interesting extremal correlation is the following $H(A_0,B,C)=H(A_1,B,C)=H(A_1,B)=H(A_0,C)=H(A_1,C)=H(B,C)=2$ and $H(A_0,B)=H(A_0)=H(A_0)=H(B)=H(C)=1$. It can be understood as the case where Bob and Charlie always measure the same observable (no measurement choice) while Alice still can perform two different measurements. Clearly, since only one of the parties has measurements choices, all correlations arising in this scenario are compatible with a LHV model. However, this correlation is not bilocal, as it can be witnessed by the violation of the entropic inequality valid for any bilocal decomposition:\n\n", "index": 7, "text": "\\begin{equation}\n\\label{bilocal_ineq1}\nH(A_0,C) \\leq H(A_0,B)+ H(C \\vert A_1,B).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"H(A_{0},C)\\leq H(A_{0},B)+H(C|A_{1},B).\" display=\"block\"><mrow><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>A</mi><mn>0</mn></msub><mo>,</mo><mi>C</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>A</mi><mn>0</mn></msub><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>C</mi><mo stretchy=\"false\">|</mo><msub><mi>A</mi><mn>1</mn></msub><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwhere $G_{s}$ denotes Bob's guess of $X_s$.\n\nTo characterize of the set of NS entropic correlations associated to IC scenario (i.e,\nincluding post-quantum correlations violating \\eqref{IC_ineq}), first notice that the mutual\ninformation between Alice's inputs and Bob's guesses should be limited, according to the assumed causal structure, by the amount of\ncommunication, that is, $I(X_s:G_s) \\leq H(M)$, otherwise they could also communicate\nsuperluminally \\cite{popescu2014nonlocality}. Here, similarly to what has been done in\n\\cite{Pawlowski2009}, we consider the marginals $\\mathcal{M}_{\\textrm{IC}}=\\left\\{ \\left\\{ X_0,G_0 \\right\\},\\left\\{ X_1,G_1 \\right\\},\\left\\{ M \\right\\}  \\right\\}$. The NS cone\n$\\Gamma_{\\mathrm{IC}}$ is thus given by the intersection of the Shannon cone defined by\n$\\mathcal{M}_{\\textrm{IC}}$ with the constraints $I(X_y:G_y) \\leq H(M)$ ($y=0,1$) arising\nfrom the causal structure of the game \\cite{Chaves2015a}. We found $\\Gamma_{\\mathrm{IC}}$ to\nbe characterized by $8$ extremal rays, $7$ of which respect Eq.~\\eqref{IC_ineq}. The\nextremal ray violating Eq.~\\eqref{IC_ineq} is given by\n$H(X_0)=H(X_1)=H(G_0)=H(G_1)=H(X_0,G_0)=H(X_1,G_1)=H(M)=1$. It is achieved when the parties\nshare a PR-box and apply the protocol used in \\cite{Pawlowski2009}.\nIt is once more appealing that the NS cone approach naturally retrieves an entropic correlation of special importance.\n\n\\textit{Discussion.---}\nNonlocality stands nowadays as one of the cornerstones in our understanding of quantum\ntheory. In turn, entropy is a key concept in the foundations and applications of quantum\ninformation science. It is thus surprising that still so little is known about their\nrelations and in particular what nonsignalling  --another guiding principle permeating all\nphysics-- has to say about the entropies that can be generated by the outcomes of physical\nmeasurements.\nHere, we introduced the notion of entropic nonsignalling correlations characterizing the\nentropies compatible with the fact that we cannot transmit information instantaneously. To\nillustrate its relevance and novelty, we have applied it to understand a broad range of\ndifferent phenomena from an entropic perspective: from monogamy relations and nonlocality activation in networks, to\ngenuine multipartite nonlocality.\n\nNonsignalling also lies at the heart of the device-independent (DI) approach to quantum information, which has lately attracted growing attention  \\cite{Ekert1991,Barrett2005,colbeck2009quantum,pironio2010random,colbeck2012free,Gallego2010,Chaves2015entropy}, and we believe our results provide a new tool also for practical applications.\nIn addition, the entropic approach provides the natural ground to treat generalized Bell scenarios \\cite{Tavakoli2014,Chaves2015b,\n Chaves2016,Rosset2016} and understand novel form of nonlocal correlations emerging from it. Future lines of research also include monogamy relations \\cite{Pawlowski2009b}, the role of non-Shannon type inequalities \\cite{Yeung2008} in multipartite scenarios and possible applications in nonlocal games \\cite{Brukner2004}.\n\n Finally, as demonstrated by information causality \\cite{Pawlowski2009,Chaves2015a}, many of our current guiding principles are stated in terms of entropy. Our current framework can help to devise new entropic principles, in particular for the multipartite case \\cite{gallego2012quantum}.\n\n\n{\\it Acknowledgments.---} The authors thank Nikolai Miklin for discussions.\nRC acknowledges financial support from the Excellence Initiative of the German Federal and State Governments (Grants ZUK 43 \\& 81), the FQXi Fund, the US Army Research Office under contracts W911NF-14-1-0098 and W911NF-14-1-0133 (Quantum Characterization, Verification, and Validation), the DFG (GRO 4334 \\& SPP 1798). CB acknowledges financial support from the EU (Marie Curie CIG 293993/ENFOQI), the FQXi Fund (Silicon Valley Community Foundation), and the DFG.\n\n\n\\section{Appendix}\n\n\\subsection{The Shannon and Bell entropic cones}\nGiven a collection of $n$ discrete random variables $X_1, \\dots, X_n$, we denote by $[n]=\\{1, \\dots, n\\}$ the set of indices and $2^{[n]}$ its power set. For every $S\\in 2^{[n]}$, let $X_S$ be the vector $(X_i)_{i\\in S}$ and $H(S):=H(X_S)$  the associated Shannon entropy,  given by $H(X_S) :=-\\sum_{x_s}p(x_s)\\log_2 p(x_s)$.\nWe can define the vector ${\\mathbf{h}}=(H(\\emptyset),H(X_1), \\ldots, H(X_1, \\dots, X_n)) \\in R_n := \\mathbb{R}^{2^n}$. Not every vector ${\\mathbf{h}}\\in R_n$ will correspond to an entropy vector, as, e.g., entropies are nonnegative. The entropy cone is defined as the closure of the region\n\\begin{eqnarray*}\n\t\\Gamma_{\\rm E} := \\overline{\\left\\{ h \\in R_n \\,|\\, h_S = H(S) \\text{ for some entropy\n\t} H \\right\\}}.\n\\end{eqnarray*}\n$\\Gamma_{\\rm E}$ is known to be a convex cone but a tight and explicit description is still to be found \\cite{Yeung2008}. However, an outer approximation to the entropic cone is known, the so-called Shannon cone.\n\nThe Shannon cone $\\Gamma_{\\mathrm{Sh}}$ is a polyhedral closed convex cone, i.e., a subset of $R_n$ defined by a finite set of linear inequalities, known as basic Shannon-type inequalities, plus a normalization constraint. The first type of inequalities are given by monotonicity conditions, for example, $H( X_{S \\cup\\{i\\}}) \\geq H(X_{S})$, stating that the uncertainty about a set of variables should always be larger than or equal to the uncertainty about any subset of it. The second type is the strong subadditivity condition given by $I(X_{i}:X_{ j} \\vert X_S)= H(X_{S \\cup i}) +H(X_{ S \\cup j})-H( X_{S \\cup\\{i,j\\}})-H(X_{S}) \\geq 0$ which is equivalent to the positivity of the conditional mutual information. The normalization constraint imposes that $H(\\emptyset)=0$.\n\nGiven $n$ variables, all the associated Shannon type inequalities (and thus the Shannon cone) are characterized by the following elemental (non-redundant) inequalities \\cite{Yeung2008}\n\\begin{eqnarray}\n\tH_{}([n]\\setminus\\{i\\}) &\\leq& H_{}([n]),\n\t\\label{shannonineqs_basic}\\\\\n\tH_{}(S) + H_{}(S\\cup\\{i,j\\}) &\\leq& H_{}(S\\cup \\{i\\}) + H_{}(S\\cup \\{j\\}),\n\t\\nonumber\n\t\\\\\n\tH_{}(\\emptyset) &=& 0,\n\t\\nonumber\n\\end{eqnarray}\nfor all $S \\subset [n] \\setminus\\{i,j\\}$, $i \\neq j$ and $i, j\\in [n]$. Thus, the Shannon cone associated with $n$ variables is described by $2^{n-2}\\binom{n}{2}+n$ inequalities plus one normalization constraint.\n\nGiven a marginal scenario $\\mathcal{M}$, we are interested in the projection of $\\Gamma_{\\mathrm{Sh}}$ in the subspace of $R_n$ representing only observable terms, that is, the Bell cone $\\Gamma_{\\mathrm{Bell}}$ associated with the marginal scenario in question. Since we are given a description of the Shannon cone in terms of linear inequalities, to perform this projection we need to eliminate from this system of inequalities all terms corresponding to non-observables terms. In practice, this is achieved via a Fourier-Motzkin (FM) elimination \\cite{Williams1986}. The final set of inequalities obtained via the FM elimination (and after eliminating over redundant inequalities) gives all the facets of the associated Bell cone, the non-trivial of which are exactly the entropic Bell inequalities \\cite{Braunstein1988,Chaves2012,FritzChaves2013,Chaves2014}. By non-trivial, we denote those inequalities that are not simply basic Shannon type inequalities like \\eqref{shannonineqs_basic}.\n\nTo exemplify the general framework it is useful to analyze the particular case of the CHSH scenario discussed in the main text. In this case, the existence of an underlying LHV model implies the existence of $H(A_0,A_1,B_0,B_1)$ (and all its marginals) respecting the elementary inequalities in \\eqref{shannonineqs_basic}. Proceeding with the FM elimination and keeping only the observable terms $H(A_i,B_j)$, $H(A_i)$ and $H(B_j)$ (with $i,j=0,1$) we observe that the only non-trivial inequality (up to permutations) is given by\n\\begin{eqnarray}\n\\label{ECHSH_ap}\n& & H(A_0,B_0)+H(A_0,B_1)+H(A_1,B_0) \\\\ \\nonumber\n& &-H(A_1,B_1)-H(A_0)-H(B_0) \\geq 0.\n\\end{eqnarray}\nThis is exactly the inequality originally derived in \\cite{Braunstein1988}. Replacing the bipartite entropies by mutual informations in \\eqref{ECHSH_ap}, that is, using $H(A_x,B_y)=H(A_x)+H(B_y)-I(A_x:B_y)$, we obtain the form \\eqref{ECHSH} discussed in the main text and that can be understood as the entropic analogue of the CHSH inequality \\eqref{CHSH}. However, opposed to the probabilistic version of the CHSH inequality, its entropic version can be used as a nonlocality witness for an arbitrary finite number of measurement outcomes.\n\n\n\\subsection{A tool for the derivation of entropic Bell inequalities}\n\\label{subsec:tool}\nThe formalism outlined above provides a general framework for the derivation of entropic Bell inequalities in basically any scenario \\cite{Chaves2012,FritzChaves2013,Chaves2014}. In short, we have to perform the projection --via a Fourier-Motzkin (FM) elimination -- of the Shannon cone $\\Gamma_{\\mathrm{Sh}}$ to the subspace of observable coordinates defining the Bell cone $\\Gamma_{\\mathrm{Bell}}$.\nThe problem with this approach is that it turns out to be computationally extremely demanding. The FM algorithm eliminate a variable $x$ from a system of inequalities by summing, after proper normalization, inequalities where $x$ appears with coefficient $+1$ and with coefficient $-1$, and keeping the rest. Eliminating over $m$ variables in a system of $N$ inequalities can lead to a number $O(N^{2^m})$ of inequalities, that is, double exponential. Since the number of initial inequalities describing $\\Gamma_{\\mathrm{Sh}}$ is itself exponential \\cite{Yeung2008}, this leads to a triple-exponential complexity algorithm, which is limited, in practice, to very simple cases. In fact, no systematic characterization of entropic inequalities is known beyond particular instances of the bipartite case, although particular multipartite inequalities have been derived \\cite{Chaves2014,raeisi2015entropic}. In particular, no entropic Bell inequality witnessing genuine multipartite nonlocality \\cite{Svetlichny1987} was known to this date.\n\nNevertheless, checking whether a given inequality is valid for a scenario of interest is computationally much simpler. First, notice\nthat any valid entropic inequality must follow from a FM elimination over the system of\ninequalities defining the scenario at question, for example, entropic Bell inequalities\nfollow from the basic Shannon type inequalities \\eqref{shannonineqs_basic} plus possible additional linear constraints.\nGiven the entropy vector $\\boldsymbol{h} \\in R_n$, any linear inequality can be written\nas the inner product $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle \\geq 0$, where $\\boldsymbol{\\mathcal{I}}$ is a vector to the inequality. Similarly, a system of inequalities, e.g., Eq.~\\eqref{shannonineqs_basic}, can be represented as a matrix $M$,\nsuch that $\\Gamma := \\{ \\boldsymbol{h} | M\\boldsymbol{h} \\geq \\boldsymbol{0}\\}$.\nTo check the validity of an inequality $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle \\geq 0$ with respect to the system $M\\boldsymbol{h} \\geq \\boldsymbol{0}$, one simply needs to solve the following (efficient) linear program \\cite{Yeung2008}:\n\\begin{eqnarray}\n\\underset{\\boldsymbol{h} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP} \\\\\n{\\textrm{subject to }} & &  M\\boldsymbol{h} \\geq \\boldsymbol{0}. \\nonumber\n\\end{eqnarray}\nIf the minimum of $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle$ is larger or equal to zero, then the inequality is valid.\n\nMoreover, one can extend this result to inequalities for the projected cone, even without performing the corresponding FM elimination on the system $M\\boldsymbol{h} \\geq \\boldsymbol{0}$.  More precisely, given\n${\\Gamma := \\{\\ \\boldsymbol{h}\\ |\\ M\\boldsymbol{h}\\geq 0\\ \\}}$ and\n${\\Pi_k(\\Gamma) = \\{\\ \\boldsymbol{h}\\ |\\ \\tilde{M}\\boldsymbol{h}\\geq 0,\\ (\\boldsymbol{h})_l = 0 \\text{ for } l> k\\ \\}}$, where $\\Pi_k$\nis the projection on the first $k$ coordinates, we prove that the inequality $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle\\geq 0$, with\n$(\\boldsymbol{\\mathcal{I}})_l = 0$ for $l>k$ is valid for the polyhedral cone\n$\\Pi_k(\\Gamma)$ if and only if it is valid for the polyhedral cone $\\Gamma$.\nIf there exists $\\boldsymbol{p} \\in \\Gamma$\nsuch that $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{p} \\rangle < 0$, then\n$\\Pi_k( \\boldsymbol{p})\\in  \\Pi_k(\\Gamma)$ and $\\langle \\boldsymbol{\\mathcal{I}}, \\Pi_k( \\boldsymbol{p}) \\rangle = \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{p} \\rangle$. Vice\nversa, given $\\tilde{\\boldsymbol{p}}\\in \\Pi_k(\\Gamma)$ such that\n$\\langle \\boldsymbol{\\mathcal{I}}, \\tilde{\\boldsymbol{p}} \\rangle<0$, there exists\n$\\boldsymbol{p} \\in \\Gamma$ such that $\\Pi_k(\\boldsymbol{p})=\\tilde{\\boldsymbol{p}}$ and\n$\\langle \\boldsymbol{\\mathcal{I}},  \\boldsymbol{p} \\rangle = \\langle \\boldsymbol{\\mathcal{I}}, \\tilde{\\boldsymbol{p}} \\rangle$.\n\n\nSimilarly, it is again a linear program (in fact, a feasibility problem) to check if a given observed entropic correlation $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$ is local or nonlocal. It is simply given by\n\\begin{eqnarray}\n\\underset{\\boldsymbol{h} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP2} \\\\\n{\\textrm{subject to }} & &  M\\boldsymbol{h} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& & {\\mathbf{h}}_{\\mathrm{Obs}}=\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}.\n\\end{eqnarray}\nwhere $\\boldsymbol{\\mathcal{I}}$ in this case can be any linear objective function. We see that in this case, we not only impose the constraints $ M\\boldsymbol{h} \\geq \\boldsymbol{0}$ but also impose that some of the coordinates of the vector $\\boldsymbol{h}$ (those given by ${\\mathbf{h}}_{\\mathrm{Obs}}$) should correspond to the observable quantities $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$. In case the linear program above has no solution (non-feasible), the correlations $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$ at question are thus nonlocal.\n\nThese linear programs together with the characterization of the entropic NS cone provide novel tools in the derivation of entropic Bell inequalities, as explained below.\n\nA nonlocal extremal correlation given by $\\tilde{{\\mathbf{h}}}^{\\mathrm{NS}}_{\\mathrm{Obs}}$ will\nimply a non-feasible LP of the form \\eqref{LP2}. However, not all the constraints encoded in\nthe matrix $M$ will be necessary for witnessing this non-feasibility: many of the\ninequalities in $M$ can be eliminated until we reach a (not unique) minimum set of\ninequalities that will still lead to a non-feasible LP. Given this minimum set we can then\nperform a FM elimination that thus will lead to an inequality that is violated by the given\ncorrelation $\\tilde{{\\mathbf{h}}}^{\\mathrm{NS}}_{\\mathrm{Obs}}$. Notice that in general the obtained\ninequalities are not necessarily going to be facets of the marginal cone of interest.\nHowever, we can obtain tight inequalities by adding noise to the extremal correlations (for\ninstance, white noise). By doing that we guarantee that we are deriving inequalities probing\nthe nonlocal character of the given correlation until the noise is strong enough to make it\nenter in the marginal cone of interest (and thus become local). Notice that a similar\nprocedure can be applied to obtain the minimum set of inequalities required to prove the\nvalidity of a given inequality bounding the marginal cone of interest.\n\n\n\\subsection{Entropic NS cones in a variety of scenarios}\nFor the entropic NS cone description, we use the elemental Shannon type inequalities\n\\eqref{shannonineqs_basic} for each subset of mutually compatible variables defined by a\ngiven marginal scenario. In the sections below, we describe in details the entropic NS cone\nin the bipartite and tripartite scenario, and the hybrid local-nonsignalling models. Notice\nthat for $n\\geq 3$, the Shannon cone correspond with the true entropy cone, so our bounds\nare tight. For each of the scenarios we consider, we have catalogued all\nthe inequivalent classes of extremal rays and characterized whether they correspond to local\nor nonlocal correlations.\n\n\\subsubsection{Bipartite}\nIn a bipartite Bell scenario, two parties Alice and Bob can measure $m$ possible different observables. Thus, the bipartite entropic NS cone $\\Gamma^{2}_{\\mathrm{NS}}$  is defined by the elemental inequalities for each subset of mutually compatible observables $A_x,B_y$, that is, it is simply described in terms of the elemental inequalities $I(A_x:B_y) \\geq 0$, $H(A_X,B_y) \\geq H(A_x)$ and $H(A_X,B_y) \\geq H(B_y)$ for $x,y=0,\\dots,m-1$.\n\nAs discussed in the main text, for the case $m=2$ (corresponding to the CHSH scenario) $\\Gamma^{2}_{\\mathrm{NS}}$ is characterized by $5$ different classes of extremal NS rays, $4$ of which correspond to local correlations and only $1$ correspond to nonlocal correlations. In Table \\eqref{tab:bipartite} we list all the different classes (a class is defined by the inequalities that are equivalent up to the permutation of parties and/or observables).\n\n\\begin{table*}\n\\begin{tabular}{|c| c c| c c| c c c c|} \\hline\n\\multicolumn{9}{|c|}{Extremal ray}\\\\\n\\hline\n      \\multicolumn{1}{|c|}{\\textbf{\\#}}\n    & \\multicolumn{2}{c|}{\\scriptsize$H(A_x)$}\n    & \\multicolumn{2}{c|}{\\scriptsize$H(B_y)$}\n    & \\multicolumn{4}{c|}{\\scriptsize$H(A_xB_y)$}\\\\\n\\small{$x$ / $y$ / $xy$}\n&\\small{0}&\\small{1}\n&\\small{0}&\\small{1}\n&\\small{00}&\\small{01}&\\small{10}&\\small{11}\n\\\\\n\\hline\n\\textbf{1}\n&\\small{1}&\\small{0}\n&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{2}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{3}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{4}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{5}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{2}\n\\\\\n\\hline\n\\end{tabular}\n\\caption{Inequivalent classes of extremal rays in the bipartite scenario where both parties measure two possible observables. Extremal rays $1$-$4$ correspond to local entropies while ray $5$ correspond to the entropic analog of the PR-box \\cite{Popescu1994}. All rays are defined up to a positive constant multiplicative factor, that is, the rays are described by a vector in some real space $v\\in\\mathbbm{R}^n$ such that $\\{ \\lambda v \\,|\\, \\lambda \\geq 0\\}$}. \\label{tab:bipartite}\n\\end{table*}\n\nThe class $\\# 1$ of extremal rays corresponds to the case where one of the variables has maximal entropy, e.g, $H(A_0)= \\log_2 d$ (where $d$ is the number of outcomes), while all other variables have null entropy (that is, they represent probability distributions with deterministic outcomes). Class $\\# 2$ represents perfect (anti)correlations between one observable of Alice and one of Bob, e.g., $H(A_0)=H(B_0)=I(A_0:B_0)=\\log_2 d$ while all other entropies are null. Class $\\# 3$ represents perfect (anti)correlations between the two observables of Alice with one observable of Bob, e.g, $H(A_x)=H(B_0)=I(A_x:B_0)=\\log_2 d$, while the other observable of Bob has null entropy. Class $\\# 4$ represents perfect (anti)correlations between all the observables of Alice and Bob, that is, $H(A_x)=H(B_y)=I(A_x:B_y)=\\log_2 d$. All these rays clearly correspond to local correlations.\n\nIn turn, the class $\\# 5$ corresponds to entropic nonlocal correlations. For $d=2$, it can be understood as the entropic version of the paradigmatic PR-box \\cite{Popescu1994}\n\n", "itemtype": "equation", "pos": 22382, "prevtext": "\nThe entropic correlation above arises from a probability distribution $p(a,b,c \\vert x)=(1/4)\\delta_{a\\oplus b,xc}$, obtained when Alice and Bob share a PR-box $p_{\\mathrm{PR}}$\nwhile Bob and Charlie share a classical correlated distribution $p_{\\mathrm{C}}$. To that\naim, Bob assigns $b$ to the output of his share of the PR-box that takes as input the bit\nthat is classically correlated with the output $c$ of Charlie. This result illustrates two\nnovel aspects of the bilocality scenario. First, we see that the nonlocality of the PR-box,\nwhich in CHSH scenario is entropically equivalent to a classical correlation, can be\nactivated by employing it in a network. Even more remarkable is the fact that the emergence\nof nonlocal correlations only requires one out of the three parties to have access to\nmeasurement choices. This is similar to what has been observed in\n\\cite{Branciard2012,Fritz2012}, where it has been argued that since the role of Charlie can be\ninterpreted as defining measurement choices for Bob, this scenario can me mapped to the CHSH\none. In our case, however, we do not need to hinge on this mapping, since we violate a new\nsort of entropic Bell inequality. Thus, as opposed to Refs. \\cite{Branciard2012,Fritz2012},\nour result does not rely on Bell's theorem.\n\nAnother genuinely nonbilocal extremal entropic ray is associated with the probability $p(a,b,c\\vert x,y,z)=(1/8)(\\delta_{a\\oplus b \\oplus c,xyz\\oplus xy \\oplus xz \\oplus yz \\oplus z \\oplus 1}+\\delta_{a \\oplus b \\oplus c,0})$. Its nonbilocality can be witnessed via the violation of\n\\begin{eqnarray}\n\\label{bilocal_ineq2}\nS_{\\mathrm{BL}}= & & -H_{A_0B_0C_0}+H_{A_1B_1C_0}  \\\\ \\nonumber\n& & +H_{A_0B_0C_1}+H_{A_1B_1C_1}-H_{A_1,C_1}-H_{A_1,B_1} \\geq 0,\n\\end{eqnarray}\nspecifically, with value $S_{\\mathrm{BL}}=-1$. As opposed to other known inequalities \\cite{Branciard2010,Branciard2012,Chaves2016,Rosset2016}, Eq.~\\eqref{bilocal_ineq2} includes marginal terms, and it is valid for an arbitrary number of outcomes.\n\n\\textit{Information Causality.---}\nInformation causality (IC) \\cite{Pawlowski2009} is a principle introduced to explain the limitation of quantum correlations, i.e., Tsirelson bound \\cite{Cirel1980quantum}. It can be understood as a game: Alice receives two independent random bits $X_0$ and $X_1$ and the task of Bob is to guess, at each run of the experiment, the value of one of them, having as resources some pre-shared correlations with Alice and some classical communication ($H(M)$ bits) sent by her. For shared quantum correlations, the following inequality holds \\cite{Pawlowski2009}:\n\n", "index": 9, "text": "\\begin{equation}\n\\label{IC_ineq}\nI(X_0:G_0)+I(X_1:G_1) \\leq H(M).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"I(X_{0}:G_{0})+I(X_{1}:G_{1})\\leq H(M).\" display=\"block\"><mrow><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mn>0</mn></msub><mo>:</mo><msub><mi>G</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>:</mo><msub><mi>G</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nFirst, notice that $p_{\\mathrm{PR}}$ is entropically equivalent to the purely classical correlations \\cite{Chaves2013a}\n\n", "itemtype": "equation", "pos": 42079, "prevtext": "\nwhere $G_{s}$ denotes Bob's guess of $X_s$.\n\nTo characterize of the set of NS entropic correlations associated to IC scenario (i.e,\nincluding post-quantum correlations violating \\eqref{IC_ineq}), first notice that the mutual\ninformation between Alice's inputs and Bob's guesses should be limited, according to the assumed causal structure, by the amount of\ncommunication, that is, $I(X_s:G_s) \\leq H(M)$, otherwise they could also communicate\nsuperluminally \\cite{popescu2014nonlocality}. Here, similarly to what has been done in\n\\cite{Pawlowski2009}, we consider the marginals $\\mathcal{M}_{\\textrm{IC}}=\\left\\{ \\left\\{ X_0,G_0 \\right\\},\\left\\{ X_1,G_1 \\right\\},\\left\\{ M \\right\\}  \\right\\}$. The NS cone\n$\\Gamma_{\\mathrm{IC}}$ is thus given by the intersection of the Shannon cone defined by\n$\\mathcal{M}_{\\textrm{IC}}$ with the constraints $I(X_y:G_y) \\leq H(M)$ ($y=0,1$) arising\nfrom the causal structure of the game \\cite{Chaves2015a}. We found $\\Gamma_{\\mathrm{IC}}$ to\nbe characterized by $8$ extremal rays, $7$ of which respect Eq.~\\eqref{IC_ineq}. The\nextremal ray violating Eq.~\\eqref{IC_ineq} is given by\n$H(X_0)=H(X_1)=H(G_0)=H(G_1)=H(X_0,G_0)=H(X_1,G_1)=H(M)=1$. It is achieved when the parties\nshare a PR-box and apply the protocol used in \\cite{Pawlowski2009}.\nIt is once more appealing that the NS cone approach naturally retrieves an entropic correlation of special importance.\n\n\\textit{Discussion.---}\nNonlocality stands nowadays as one of the cornerstones in our understanding of quantum\ntheory. In turn, entropy is a key concept in the foundations and applications of quantum\ninformation science. It is thus surprising that still so little is known about their\nrelations and in particular what nonsignalling  --another guiding principle permeating all\nphysics-- has to say about the entropies that can be generated by the outcomes of physical\nmeasurements.\nHere, we introduced the notion of entropic nonsignalling correlations characterizing the\nentropies compatible with the fact that we cannot transmit information instantaneously. To\nillustrate its relevance and novelty, we have applied it to understand a broad range of\ndifferent phenomena from an entropic perspective: from monogamy relations and nonlocality activation in networks, to\ngenuine multipartite nonlocality.\n\nNonsignalling also lies at the heart of the device-independent (DI) approach to quantum information, which has lately attracted growing attention  \\cite{Ekert1991,Barrett2005,colbeck2009quantum,pironio2010random,colbeck2012free,Gallego2010,Chaves2015entropy}, and we believe our results provide a new tool also for practical applications.\nIn addition, the entropic approach provides the natural ground to treat generalized Bell scenarios \\cite{Tavakoli2014,Chaves2015b,\n Chaves2016,Rosset2016} and understand novel form of nonlocal correlations emerging from it. Future lines of research also include monogamy relations \\cite{Pawlowski2009b}, the role of non-Shannon type inequalities \\cite{Yeung2008} in multipartite scenarios and possible applications in nonlocal games \\cite{Brukner2004}.\n\n Finally, as demonstrated by information causality \\cite{Pawlowski2009,Chaves2015a}, many of our current guiding principles are stated in terms of entropy. Our current framework can help to devise new entropic principles, in particular for the multipartite case \\cite{gallego2012quantum}.\n\n\n{\\it Acknowledgments.---} The authors thank Nikolai Miklin for discussions.\nRC acknowledges financial support from the Excellence Initiative of the German Federal and State Governments (Grants ZUK 43 \\& 81), the FQXi Fund, the US Army Research Office under contracts W911NF-14-1-0098 and W911NF-14-1-0133 (Quantum Characterization, Verification, and Validation), the DFG (GRO 4334 \\& SPP 1798). CB acknowledges financial support from the EU (Marie Curie CIG 293993/ENFOQI), the FQXi Fund (Silicon Valley Community Foundation), and the DFG.\n\n\n\\section{Appendix}\n\n\\subsection{The Shannon and Bell entropic cones}\nGiven a collection of $n$ discrete random variables $X_1, \\dots, X_n$, we denote by $[n]=\\{1, \\dots, n\\}$ the set of indices and $2^{[n]}$ its power set. For every $S\\in 2^{[n]}$, let $X_S$ be the vector $(X_i)_{i\\in S}$ and $H(S):=H(X_S)$  the associated Shannon entropy,  given by $H(X_S) :=-\\sum_{x_s}p(x_s)\\log_2 p(x_s)$.\nWe can define the vector ${\\mathbf{h}}=(H(\\emptyset),H(X_1), \\ldots, H(X_1, \\dots, X_n)) \\in R_n := \\mathbb{R}^{2^n}$. Not every vector ${\\mathbf{h}}\\in R_n$ will correspond to an entropy vector, as, e.g., entropies are nonnegative. The entropy cone is defined as the closure of the region\n\\begin{eqnarray*}\n\t\\Gamma_{\\rm E} := \\overline{\\left\\{ h \\in R_n \\,|\\, h_S = H(S) \\text{ for some entropy\n\t} H \\right\\}}.\n\\end{eqnarray*}\n$\\Gamma_{\\rm E}$ is known to be a convex cone but a tight and explicit description is still to be found \\cite{Yeung2008}. However, an outer approximation to the entropic cone is known, the so-called Shannon cone.\n\nThe Shannon cone $\\Gamma_{\\mathrm{Sh}}$ is a polyhedral closed convex cone, i.e., a subset of $R_n$ defined by a finite set of linear inequalities, known as basic Shannon-type inequalities, plus a normalization constraint. The first type of inequalities are given by monotonicity conditions, for example, $H( X_{S \\cup\\{i\\}}) \\geq H(X_{S})$, stating that the uncertainty about a set of variables should always be larger than or equal to the uncertainty about any subset of it. The second type is the strong subadditivity condition given by $I(X_{i}:X_{ j} \\vert X_S)= H(X_{S \\cup i}) +H(X_{ S \\cup j})-H( X_{S \\cup\\{i,j\\}})-H(X_{S}) \\geq 0$ which is equivalent to the positivity of the conditional mutual information. The normalization constraint imposes that $H(\\emptyset)=0$.\n\nGiven $n$ variables, all the associated Shannon type inequalities (and thus the Shannon cone) are characterized by the following elemental (non-redundant) inequalities \\cite{Yeung2008}\n\\begin{eqnarray}\n\tH_{}([n]\\setminus\\{i\\}) &\\leq& H_{}([n]),\n\t\\label{shannonineqs_basic}\\\\\n\tH_{}(S) + H_{}(S\\cup\\{i,j\\}) &\\leq& H_{}(S\\cup \\{i\\}) + H_{}(S\\cup \\{j\\}),\n\t\\nonumber\n\t\\\\\n\tH_{}(\\emptyset) &=& 0,\n\t\\nonumber\n\\end{eqnarray}\nfor all $S \\subset [n] \\setminus\\{i,j\\}$, $i \\neq j$ and $i, j\\in [n]$. Thus, the Shannon cone associated with $n$ variables is described by $2^{n-2}\\binom{n}{2}+n$ inequalities plus one normalization constraint.\n\nGiven a marginal scenario $\\mathcal{M}$, we are interested in the projection of $\\Gamma_{\\mathrm{Sh}}$ in the subspace of $R_n$ representing only observable terms, that is, the Bell cone $\\Gamma_{\\mathrm{Bell}}$ associated with the marginal scenario in question. Since we are given a description of the Shannon cone in terms of linear inequalities, to perform this projection we need to eliminate from this system of inequalities all terms corresponding to non-observables terms. In practice, this is achieved via a Fourier-Motzkin (FM) elimination \\cite{Williams1986}. The final set of inequalities obtained via the FM elimination (and after eliminating over redundant inequalities) gives all the facets of the associated Bell cone, the non-trivial of which are exactly the entropic Bell inequalities \\cite{Braunstein1988,Chaves2012,FritzChaves2013,Chaves2014}. By non-trivial, we denote those inequalities that are not simply basic Shannon type inequalities like \\eqref{shannonineqs_basic}.\n\nTo exemplify the general framework it is useful to analyze the particular case of the CHSH scenario discussed in the main text. In this case, the existence of an underlying LHV model implies the existence of $H(A_0,A_1,B_0,B_1)$ (and all its marginals) respecting the elementary inequalities in \\eqref{shannonineqs_basic}. Proceeding with the FM elimination and keeping only the observable terms $H(A_i,B_j)$, $H(A_i)$ and $H(B_j)$ (with $i,j=0,1$) we observe that the only non-trivial inequality (up to permutations) is given by\n\\begin{eqnarray}\n\\label{ECHSH_ap}\n& & H(A_0,B_0)+H(A_0,B_1)+H(A_1,B_0) \\\\ \\nonumber\n& &-H(A_1,B_1)-H(A_0)-H(B_0) \\geq 0.\n\\end{eqnarray}\nThis is exactly the inequality originally derived in \\cite{Braunstein1988}. Replacing the bipartite entropies by mutual informations in \\eqref{ECHSH_ap}, that is, using $H(A_x,B_y)=H(A_x)+H(B_y)-I(A_x:B_y)$, we obtain the form \\eqref{ECHSH} discussed in the main text and that can be understood as the entropic analogue of the CHSH inequality \\eqref{CHSH}. However, opposed to the probabilistic version of the CHSH inequality, its entropic version can be used as a nonlocality witness for an arbitrary finite number of measurement outcomes.\n\n\n\\subsection{A tool for the derivation of entropic Bell inequalities}\n\\label{subsec:tool}\nThe formalism outlined above provides a general framework for the derivation of entropic Bell inequalities in basically any scenario \\cite{Chaves2012,FritzChaves2013,Chaves2014}. In short, we have to perform the projection --via a Fourier-Motzkin (FM) elimination -- of the Shannon cone $\\Gamma_{\\mathrm{Sh}}$ to the subspace of observable coordinates defining the Bell cone $\\Gamma_{\\mathrm{Bell}}$.\nThe problem with this approach is that it turns out to be computationally extremely demanding. The FM algorithm eliminate a variable $x$ from a system of inequalities by summing, after proper normalization, inequalities where $x$ appears with coefficient $+1$ and with coefficient $-1$, and keeping the rest. Eliminating over $m$ variables in a system of $N$ inequalities can lead to a number $O(N^{2^m})$ of inequalities, that is, double exponential. Since the number of initial inequalities describing $\\Gamma_{\\mathrm{Sh}}$ is itself exponential \\cite{Yeung2008}, this leads to a triple-exponential complexity algorithm, which is limited, in practice, to very simple cases. In fact, no systematic characterization of entropic inequalities is known beyond particular instances of the bipartite case, although particular multipartite inequalities have been derived \\cite{Chaves2014,raeisi2015entropic}. In particular, no entropic Bell inequality witnessing genuine multipartite nonlocality \\cite{Svetlichny1987} was known to this date.\n\nNevertheless, checking whether a given inequality is valid for a scenario of interest is computationally much simpler. First, notice\nthat any valid entropic inequality must follow from a FM elimination over the system of\ninequalities defining the scenario at question, for example, entropic Bell inequalities\nfollow from the basic Shannon type inequalities \\eqref{shannonineqs_basic} plus possible additional linear constraints.\nGiven the entropy vector $\\boldsymbol{h} \\in R_n$, any linear inequality can be written\nas the inner product $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle \\geq 0$, where $\\boldsymbol{\\mathcal{I}}$ is a vector to the inequality. Similarly, a system of inequalities, e.g., Eq.~\\eqref{shannonineqs_basic}, can be represented as a matrix $M$,\nsuch that $\\Gamma := \\{ \\boldsymbol{h} | M\\boldsymbol{h} \\geq \\boldsymbol{0}\\}$.\nTo check the validity of an inequality $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle \\geq 0$ with respect to the system $M\\boldsymbol{h} \\geq \\boldsymbol{0}$, one simply needs to solve the following (efficient) linear program \\cite{Yeung2008}:\n\\begin{eqnarray}\n\\underset{\\boldsymbol{h} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP} \\\\\n{\\textrm{subject to }} & &  M\\boldsymbol{h} \\geq \\boldsymbol{0}. \\nonumber\n\\end{eqnarray}\nIf the minimum of $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle$ is larger or equal to zero, then the inequality is valid.\n\nMoreover, one can extend this result to inequalities for the projected cone, even without performing the corresponding FM elimination on the system $M\\boldsymbol{h} \\geq \\boldsymbol{0}$.  More precisely, given\n${\\Gamma := \\{\\ \\boldsymbol{h}\\ |\\ M\\boldsymbol{h}\\geq 0\\ \\}}$ and\n${\\Pi_k(\\Gamma) = \\{\\ \\boldsymbol{h}\\ |\\ \\tilde{M}\\boldsymbol{h}\\geq 0,\\ (\\boldsymbol{h})_l = 0 \\text{ for } l> k\\ \\}}$, where $\\Pi_k$\nis the projection on the first $k$ coordinates, we prove that the inequality $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle\\geq 0$, with\n$(\\boldsymbol{\\mathcal{I}})_l = 0$ for $l>k$ is valid for the polyhedral cone\n$\\Pi_k(\\Gamma)$ if and only if it is valid for the polyhedral cone $\\Gamma$.\nIf there exists $\\boldsymbol{p} \\in \\Gamma$\nsuch that $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{p} \\rangle < 0$, then\n$\\Pi_k( \\boldsymbol{p})\\in  \\Pi_k(\\Gamma)$ and $\\langle \\boldsymbol{\\mathcal{I}}, \\Pi_k( \\boldsymbol{p}) \\rangle = \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{p} \\rangle$. Vice\nversa, given $\\tilde{\\boldsymbol{p}}\\in \\Pi_k(\\Gamma)$ such that\n$\\langle \\boldsymbol{\\mathcal{I}}, \\tilde{\\boldsymbol{p}} \\rangle<0$, there exists\n$\\boldsymbol{p} \\in \\Gamma$ such that $\\Pi_k(\\boldsymbol{p})=\\tilde{\\boldsymbol{p}}$ and\n$\\langle \\boldsymbol{\\mathcal{I}},  \\boldsymbol{p} \\rangle = \\langle \\boldsymbol{\\mathcal{I}}, \\tilde{\\boldsymbol{p}} \\rangle$.\n\n\nSimilarly, it is again a linear program (in fact, a feasibility problem) to check if a given observed entropic correlation $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$ is local or nonlocal. It is simply given by\n\\begin{eqnarray}\n\\underset{\\boldsymbol{h} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP2} \\\\\n{\\textrm{subject to }} & &  M\\boldsymbol{h} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& & {\\mathbf{h}}_{\\mathrm{Obs}}=\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}.\n\\end{eqnarray}\nwhere $\\boldsymbol{\\mathcal{I}}$ in this case can be any linear objective function. We see that in this case, we not only impose the constraints $ M\\boldsymbol{h} \\geq \\boldsymbol{0}$ but also impose that some of the coordinates of the vector $\\boldsymbol{h}$ (those given by ${\\mathbf{h}}_{\\mathrm{Obs}}$) should correspond to the observable quantities $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$. In case the linear program above has no solution (non-feasible), the correlations $\\tilde{{\\mathbf{h}}}_{\\mathrm{Obs}}$ at question are thus nonlocal.\n\nThese linear programs together with the characterization of the entropic NS cone provide novel tools in the derivation of entropic Bell inequalities, as explained below.\n\nA nonlocal extremal correlation given by $\\tilde{{\\mathbf{h}}}^{\\mathrm{NS}}_{\\mathrm{Obs}}$ will\nimply a non-feasible LP of the form \\eqref{LP2}. However, not all the constraints encoded in\nthe matrix $M$ will be necessary for witnessing this non-feasibility: many of the\ninequalities in $M$ can be eliminated until we reach a (not unique) minimum set of\ninequalities that will still lead to a non-feasible LP. Given this minimum set we can then\nperform a FM elimination that thus will lead to an inequality that is violated by the given\ncorrelation $\\tilde{{\\mathbf{h}}}^{\\mathrm{NS}}_{\\mathrm{Obs}}$. Notice that in general the obtained\ninequalities are not necessarily going to be facets of the marginal cone of interest.\nHowever, we can obtain tight inequalities by adding noise to the extremal correlations (for\ninstance, white noise). By doing that we guarantee that we are deriving inequalities probing\nthe nonlocal character of the given correlation until the noise is strong enough to make it\nenter in the marginal cone of interest (and thus become local). Notice that a similar\nprocedure can be applied to obtain the minimum set of inequalities required to prove the\nvalidity of a given inequality bounding the marginal cone of interest.\n\n\n\\subsection{Entropic NS cones in a variety of scenarios}\nFor the entropic NS cone description, we use the elemental Shannon type inequalities\n\\eqref{shannonineqs_basic} for each subset of mutually compatible variables defined by a\ngiven marginal scenario. In the sections below, we describe in details the entropic NS cone\nin the bipartite and tripartite scenario, and the hybrid local-nonsignalling models. Notice\nthat for $n\\geq 3$, the Shannon cone correspond with the true entropy cone, so our bounds\nare tight. For each of the scenarios we consider, we have catalogued all\nthe inequivalent classes of extremal rays and characterized whether they correspond to local\nor nonlocal correlations.\n\n\\subsubsection{Bipartite}\nIn a bipartite Bell scenario, two parties Alice and Bob can measure $m$ possible different observables. Thus, the bipartite entropic NS cone $\\Gamma^{2}_{\\mathrm{NS}}$  is defined by the elemental inequalities for each subset of mutually compatible observables $A_x,B_y$, that is, it is simply described in terms of the elemental inequalities $I(A_x:B_y) \\geq 0$, $H(A_X,B_y) \\geq H(A_x)$ and $H(A_X,B_y) \\geq H(B_y)$ for $x,y=0,\\dots,m-1$.\n\nAs discussed in the main text, for the case $m=2$ (corresponding to the CHSH scenario) $\\Gamma^{2}_{\\mathrm{NS}}$ is characterized by $5$ different classes of extremal NS rays, $4$ of which correspond to local correlations and only $1$ correspond to nonlocal correlations. In Table \\eqref{tab:bipartite} we list all the different classes (a class is defined by the inequalities that are equivalent up to the permutation of parties and/or observables).\n\n\\begin{table*}\n\\begin{tabular}{|c| c c| c c| c c c c|} \\hline\n\\multicolumn{9}{|c|}{Extremal ray}\\\\\n\\hline\n      \\multicolumn{1}{|c|}{\\textbf{\\#}}\n    & \\multicolumn{2}{c|}{\\scriptsize$H(A_x)$}\n    & \\multicolumn{2}{c|}{\\scriptsize$H(B_y)$}\n    & \\multicolumn{4}{c|}{\\scriptsize$H(A_xB_y)$}\\\\\n\\small{$x$ / $y$ / $xy$}\n&\\small{0}&\\small{1}\n&\\small{0}&\\small{1}\n&\\small{00}&\\small{01}&\\small{10}&\\small{11}\n\\\\\n\\hline\n\\textbf{1}\n&\\small{1}&\\small{0}\n&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{2}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{3}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{4}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{5}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{2}\n\\\\\n\\hline\n\\end{tabular}\n\\caption{Inequivalent classes of extremal rays in the bipartite scenario where both parties measure two possible observables. Extremal rays $1$-$4$ correspond to local entropies while ray $5$ correspond to the entropic analog of the PR-box \\cite{Popescu1994}. All rays are defined up to a positive constant multiplicative factor, that is, the rays are described by a vector in some real space $v\\in\\mathbbm{R}^n$ such that $\\{ \\lambda v \\,|\\, \\lambda \\geq 0\\}$}. \\label{tab:bipartite}\n\\end{table*}\n\nThe class $\\# 1$ of extremal rays corresponds to the case where one of the variables has maximal entropy, e.g, $H(A_0)= \\log_2 d$ (where $d$ is the number of outcomes), while all other variables have null entropy (that is, they represent probability distributions with deterministic outcomes). Class $\\# 2$ represents perfect (anti)correlations between one observable of Alice and one of Bob, e.g., $H(A_0)=H(B_0)=I(A_0:B_0)=\\log_2 d$ while all other entropies are null. Class $\\# 3$ represents perfect (anti)correlations between the two observables of Alice with one observable of Bob, e.g, $H(A_x)=H(B_0)=I(A_x:B_0)=\\log_2 d$, while the other observable of Bob has null entropy. Class $\\# 4$ represents perfect (anti)correlations between all the observables of Alice and Bob, that is, $H(A_x)=H(B_y)=I(A_x:B_y)=\\log_2 d$. All these rays clearly correspond to local correlations.\n\nIn turn, the class $\\# 5$ corresponds to entropic nonlocal correlations. For $d=2$, it can be understood as the entropic version of the paradigmatic PR-box \\cite{Popescu1994}\n\n", "index": 11, "text": "\\begin{equation}\n\\label{pr}\np_{\\mathrm{PR}}\\left(  a,b | x,y \\right)  =\\left\\{\n\\begin{array}{ll}\n1/2 & \\text{, } a\\oplus b =xy\\\\\n0 & \\text{, otherwise}\n\\end{array}\n\\right. .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"p_{\\mathrm{PR}}\\left(a,b|x,y\\right)=\\left\\{\\begin{array}[]{ll}1/2&amp;\\text{, }a%&#10;\\oplus b=xy\\\\&#10;0&amp;\\text{, otherwise}\\end{array}\\right..\" display=\"block\"><mrow><msub><mi>p</mi><mi>PR</mi></msub><mrow><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>,\u00a0</mtext><mo>\u2062</mo><mi>a</mi></mrow><mo>\u2295</mo><mi>b</mi></mrow><mo>=</mo><mrow><mi>x</mi><mo>\u2062</mo><mi>y</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>, otherwise</mtext></mtd></mtr></mtable><mo>.</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nThat is, both \\eqref{pr} and \\eqref{pc} correspond to the class $\\# 4$ of extremal rays. The reason for this equivalence is due to the fact that entropies are unable to distinguish between correlations and anti-correlations \\cite{Chaves2013a}. Interestingly, the class $\\# 5$ correspond to a probability distribution obtained by mixing with equal weights the distributions \\eqref{pr} and \\eqref{pc}, that is, $p_{\\mathrm{class} \\# 5}=(1/2)(p_{\\mathrm{PR}}+p_{\\mathrm{PC}})$ corresponding to three perfect (anti)correlated pairs of variables $I(A_0:B_0)=I(A_0:B_1)=I(A_1:B_0)=1$ and one uncorrelated pair $I(A_1:B_1)=0$. The class $\\# 5$ violates the entropic version of the CHSH inequality \\eqref{ECHSH} up to the algebraic maximum, achieving $S_{\\mathrm{E}}=\\log_2 d$.\n\n\nWe have performed the same analysis for the case $m=3$ and obtained $20$ different classes of extremal rays, $7$ of which correspond local and $13$ to nonlocal correlations. The different classes of extremal rays are listed in Table \\eqref{tab:bipartite3}. The interpretation of the local rays is identical to the one we have detailed above to the case of $2$ measurement settings. Regarding the nonlocal rays, we focus attention to the classes $\\# 8$ an $\\# 19$. Class $\\# 8$ basically correspond to the entropic version of the PR-box discussed above, since  $H(A_2)=H(B_2)=0$. In turn, class $\\# 19$ can be understood as the NS correlation that maximally violates the entropic version of the Collins-Gisin inequality \\cite{Collins2004} given by \\cite{Chaves2014}\n\\begin{eqnarray}\n& & S_{3}= I(A_0:B_2)-I(A_0:B_1)+I(A_1:B_1)\\\\ \\nonumber\n& & -I(A_1:B_0)+I(A_1:B_2)+I(A_2:B_2)+I(A_2:B_1) \\\\ \\nonumber\n& & +I(A_2:B_0)-H(A_2)-2H(B_2)-H(B_1)  \\leq 0,\n\\end{eqnarray}\nreaching $S_3=2\\log_2 d$.\n\n\n\n\\begin{table*}\n\\begin{tabular}{|c| c c c| c c c| c c c c c c c c c|} \\hline\n\\multicolumn{16}{|c|}{Extremal rays}\\\\\n\\hline\n      \\multicolumn{1}{|c|}{\\textbf{\\#}}\n    & \\multicolumn{3}{c|}{\\scriptsize$H(A_x)$}\n    & \\multicolumn{3}{c|}{\\scriptsize$H(B_y)$}\n    & \\multicolumn{9}{c|}{\\scriptsize$H(A_xB_y)$}\\\\\n\\small{$x$ / $y$ / $xy$}\n&\\small{0}&\\small{1}&\\small{2}\n&\\small{0}&\\small{1}&\\small{2}\n&\\small{00}&\\small{01}&\\small{02}&\\small{10}&\\small{11}&\\small{12}&\\small{20}&\\small{21}&\\small{22}\n\\\\\n\\hline\n\\textbf{1}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{0}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}&\\small{0}&\\small{0}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{2}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{3}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{4}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}\n\\\\\n\\hline\n\\textbf{5}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{1}\n\\\\\n\\hline\n\\textbf{6}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{7}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{8}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{0}\n\\\\\n\\hline\n\\textbf{9}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{10}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{2}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{11}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{12}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{2}&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{13}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{14}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{15}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{2}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{16}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{17}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{18}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{19}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{20}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\end{tabular}\n\\caption{Inequivalent classes of extremal rays in the bipartite scenario where both parties measure three possible observables. Extremal rays $1$-$7$ correspond to local entropies while rays $8$-$20$ correspond to nonlocal correlations.} \\label{tab:bipartite3}\n\\end{table*}\n\n\n\\subsubsection{Tripartite}\nIn a tripartite Bell scenario, three parties Alice, Bob and Charlie perform different measurements in their shares of a joint state. Thus, the tripartite entropic NS cone $\\Gamma^{3}_{\\mathrm{NS}}$  is defined by the elemental inequalities for each subset of mutually compatible observables $A_x,B_y,C_z$ (with $x,y,z=0,\\dots,m-1$).\n\nWe have obtained the full characterization of $\\Gamma^{3}_{\\mathrm{NS}}$ in terms of extremal rays for $m=2$. There are $1292$ different inequivalent classes of extremal rays, $128$ of which are local and $1164$ are nonlocal. Furthermore, as discussed in details below, in the tripartite case we can introduce the notion of genuine tripartite nonlocal (GTNL) correlations. From the $1164$ different classes of extremal nonlocal rays, $932$ of them are GTNL.\n\nThere are thus $232$ rays corresponding to nonlocal correlations but displaying no GTNL. We focus our attention to a particular class of these rays, given by $H(A_x)=H(B_y)=H(C_z)=1$, $H(A_x,B_y)=H(A_x,C_z)=H(B_y,C_z)=2$ and $H(A_0,B_0,C_0)=H(A_1,B_1,C_0)=H(A_1,B_0,C_1)=H(A_1,B_1,C_1)=2$ and $H(A_1,B_0,C_0)=H(A_0,B_1,C_0)=H(A_0,B_0,C_1)=H(A_0,B_1,C_1)=3$. It can be obtained by the mixing of the nonlocal correlation\n\n", "itemtype": "equation", "pos": 42388, "prevtext": "\nFirst, notice that $p_{\\mathrm{PR}}$ is entropically equivalent to the purely classical correlations \\cite{Chaves2013a}\n\n", "index": 13, "text": "\\begin{equation}\n\\label{pc}\np_{\\mathrm{PC}}\\left(  a,b | x,y \\right)  =\\left\\{\n\\begin{array}{ll}\n1/2 & \\text{, }  a \\oplus b =0\\\\\n0 & \\text{, otherwise}\n\\end{array}\n\\right. .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"p_{\\mathrm{PC}}\\left(a,b|x,y\\right)=\\left\\{\\begin{array}[]{ll}1/2&amp;\\text{, }a%&#10;\\oplus b=0\\\\&#10;0&amp;\\text{, otherwise}\\end{array}\\right..\" display=\"block\"><mrow><msub><mi>p</mi><mi>PC</mi></msub><mrow><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>,\u00a0</mtext><mo>\u2062</mo><mi>a</mi></mrow><mo>\u2295</mo><mi>b</mi></mrow><mo>=</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>, otherwise</mtext></mtd></mtr></mtable><mo>.</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwith the classical correlation\n\n", "itemtype": "equation", "pos": 49866, "prevtext": "\nThat is, both \\eqref{pr} and \\eqref{pc} correspond to the class $\\# 4$ of extremal rays. The reason for this equivalence is due to the fact that entropies are unable to distinguish between correlations and anti-correlations \\cite{Chaves2013a}. Interestingly, the class $\\# 5$ correspond to a probability distribution obtained by mixing with equal weights the distributions \\eqref{pr} and \\eqref{pc}, that is, $p_{\\mathrm{class} \\# 5}=(1/2)(p_{\\mathrm{PR}}+p_{\\mathrm{PC}})$ corresponding to three perfect (anti)correlated pairs of variables $I(A_0:B_0)=I(A_0:B_1)=I(A_1:B_0)=1$ and one uncorrelated pair $I(A_1:B_1)=0$. The class $\\# 5$ violates the entropic version of the CHSH inequality \\eqref{ECHSH} up to the algebraic maximum, achieving $S_{\\mathrm{E}}=\\log_2 d$.\n\n\nWe have performed the same analysis for the case $m=3$ and obtained $20$ different classes of extremal rays, $7$ of which correspond local and $13$ to nonlocal correlations. The different classes of extremal rays are listed in Table \\eqref{tab:bipartite3}. The interpretation of the local rays is identical to the one we have detailed above to the case of $2$ measurement settings. Regarding the nonlocal rays, we focus attention to the classes $\\# 8$ an $\\# 19$. Class $\\# 8$ basically correspond to the entropic version of the PR-box discussed above, since  $H(A_2)=H(B_2)=0$. In turn, class $\\# 19$ can be understood as the NS correlation that maximally violates the entropic version of the Collins-Gisin inequality \\cite{Collins2004} given by \\cite{Chaves2014}\n\\begin{eqnarray}\n& & S_{3}= I(A_0:B_2)-I(A_0:B_1)+I(A_1:B_1)\\\\ \\nonumber\n& & -I(A_1:B_0)+I(A_1:B_2)+I(A_2:B_2)+I(A_2:B_1) \\\\ \\nonumber\n& & +I(A_2:B_0)-H(A_2)-2H(B_2)-H(B_1)  \\leq 0,\n\\end{eqnarray}\nreaching $S_3=2\\log_2 d$.\n\n\n\n\\begin{table*}\n\\begin{tabular}{|c| c c c| c c c| c c c c c c c c c|} \\hline\n\\multicolumn{16}{|c|}{Extremal rays}\\\\\n\\hline\n      \\multicolumn{1}{|c|}{\\textbf{\\#}}\n    & \\multicolumn{3}{c|}{\\scriptsize$H(A_x)$}\n    & \\multicolumn{3}{c|}{\\scriptsize$H(B_y)$}\n    & \\multicolumn{9}{c|}{\\scriptsize$H(A_xB_y)$}\\\\\n\\small{$x$ / $y$ / $xy$}\n&\\small{0}&\\small{1}&\\small{2}\n&\\small{0}&\\small{1}&\\small{2}\n&\\small{00}&\\small{01}&\\small{02}&\\small{10}&\\small{11}&\\small{12}&\\small{20}&\\small{21}&\\small{22}\n\\\\\n\\hline\n\\textbf{1}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{0}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}&\\small{0}&\\small{0}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{2}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{3}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{0}\n\\\\\n\\hline\n\\textbf{4}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}\n\\\\\n\\hline\n\\textbf{5}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{0}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{0}&\\small{1}\n\\\\\n\\hline\n\\textbf{6}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{7}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{8}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{0}\n\\\\\n\\hline\n\\textbf{9}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{10}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{2}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{11}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{12}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{2}&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{13}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{14}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{15}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{2}&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{16}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{17}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{0}\n&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{18}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{19}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{2}&\\small{1}&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\textbf{20}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{1}&\\small{1}&\\small{1}\n&\\small{2}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}&\\small{1}\n\\\\\n\\hline\n\\end{tabular}\n\\caption{Inequivalent classes of extremal rays in the bipartite scenario where both parties measure three possible observables. Extremal rays $1$-$7$ correspond to local entropies while rays $8$-$20$ correspond to nonlocal correlations.} \\label{tab:bipartite3}\n\\end{table*}\n\n\n\\subsubsection{Tripartite}\nIn a tripartite Bell scenario, three parties Alice, Bob and Charlie perform different measurements in their shares of a joint state. Thus, the tripartite entropic NS cone $\\Gamma^{3}_{\\mathrm{NS}}$  is defined by the elemental inequalities for each subset of mutually compatible observables $A_x,B_y,C_z$ (with $x,y,z=0,\\dots,m-1$).\n\nWe have obtained the full characterization of $\\Gamma^{3}_{\\mathrm{NS}}$ in terms of extremal rays for $m=2$. There are $1292$ different inequivalent classes of extremal rays, $128$ of which are local and $1164$ are nonlocal. Furthermore, as discussed in details below, in the tripartite case we can introduce the notion of genuine tripartite nonlocal (GTNL) correlations. From the $1164$ different classes of extremal nonlocal rays, $932$ of them are GTNL.\n\nThere are thus $232$ rays corresponding to nonlocal correlations but displaying no GTNL. We focus our attention to a particular class of these rays, given by $H(A_x)=H(B_y)=H(C_z)=1$, $H(A_x,B_y)=H(A_x,C_z)=H(B_y,C_z)=2$ and $H(A_0,B_0,C_0)=H(A_1,B_1,C_0)=H(A_1,B_0,C_1)=H(A_1,B_1,C_1)=2$ and $H(A_1,B_0,C_0)=H(A_0,B_1,C_0)=H(A_0,B_0,C_1)=H(A_0,B_1,C_1)=3$. It can be obtained by the mixing of the nonlocal correlation\n\n", "index": 15, "text": "\\begin{equation}\n\\label{NLtri}\np\\left(  a,b,c | x,y,z \\right)  =\\left\\{\n\\begin{array}{ll}\n1/2 & \\text{, } a\\oplus b \\oplus c =yz\\oplus x \\oplus y \\oplus z \\\\\n0 & \\text{, otherwise}\n\\end{array}\n\\right. ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"p\\left(a,b,c|x,y,z\\right)=\\left\\{\\begin{array}[]{ll}1/2&amp;\\text{, }a\\oplus b%&#10;\\oplus c=yz\\oplus x\\oplus y\\oplus z\\\\&#10;0&amp;\\text{, otherwise}\\end{array}\\right.,\" display=\"block\"><mrow><mi>p</mi><mrow><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>,\u00a0</mtext><mo>\u2062</mo><mi>a</mi></mrow><mo>\u2295</mo><mi>b</mi><mo>\u2295</mo><mi>c</mi></mrow><mo>=</mo><mrow><mrow><mi>y</mi><mo>\u2062</mo><mi>z</mi></mrow><mo>\u2295</mo><mi>x</mi><mo>\u2295</mo><mi>y</mi><mo>\u2295</mo><mi>z</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>, otherwise</mtext></mtd></mtr></mtable><mo>,</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\n\nThe nonlocal character of this distribution can be witnessed via the following tripartite entropic inequality (obtained via the approach described in Sec. \\ref{subsec:tool})\n\\begin{eqnarray}\nM_3= & & H_{A_0B_1C_1} - H_{A_1B_1C_1} - H_{A_1B_1C_0} - H_{A_1B_0C_1} \\\\ \\nonumber\n& &-H_{A_0B_0C_0}+H_{B_0C_0} + H_{A_1C_1} +H_{A_1B_1} \\leq 0,\n\\end{eqnarray}\nsince the correlations above imply that $M_3=1$ thus violating the inequality. To prove this inequality analytically it is sufficient to consider the chain rule for entropies, implying that\n\\begin{eqnarray}\nH_{A_1B_1C_1A_0B_0C_0}=& &H_{A_0\\vert B_1C_1A_1B_0C_0}+  H_{B_0 \\vert C_1A_1B_1C_0}  \\\\ \\nonumber\n& & + H_{C_1 \\vert A_1B_1C_0}  +H_{A_1 \\vert B_1C_0} +H_{B_1\\vert C_0} +H_{C_0}.\n\\end{eqnarray}\nUsing the basic inequalities saying that $H(A) \\leq H(A,B) $ and $H(A\\vert B,C) \\leq H(A\\vert B)$, we can turn the chain rule decomposition above in the inequality\n\\begin{eqnarray}\nH_{A_0B_1C_1}=& &H_{A_0\\vert B_0C_0}+  H_{B_0 \\vert C_1A_1} + H_{C_1 \\vert A_1B_1} \\\\ \\nonumber\n& &  +H_{A_1 \\vert B_1C_0} +H_{B_1\\vert C_0} +H_{C_0},\n\\end{eqnarray}\nthat can be rewrite exactly as $M_3 \\leq 0$ if we use that $H(A \\vert B)= H(A,B)-H(B)$.\n\n\n\\subsubsection{Proving the monogamy inequality for the entropic CHSH}\nIn order to prove that the monogamy inequality \\eqref{monogamy} in the main text holds for nonsignalling correlations, we must show that if follows from the elemental inequalities for each subset of mutually compatible observables $A_x,B_y,C_z$. It is sufficient to add the the following elemental inequalities\n\\begin{eqnarray}\nH_{A_0B_0}+H_{A_0C_1} & &\\geq H_{A_0B_0C_1}+H_{A_0}, \\\\\nH_{A_0B_1}+H_{A_0C_0} & &\\geq H_{A_0B_1C_0}+H_{A_0}, \\\\\nH_{A_1B_0}+H_{B_0C_1} & &\\geq H_{A_1B_0C_1}+H_{B_0}, \\\\\nH_{A_1C_0}+H_{B_1C_0} & &\\geq H_{A_1B_1C_0}+H_{C_0}, \\\\\nH_{A_0B_0C_1} & &\\geq H_{B_0C_1}, \\\\\nH_{A_0B_1C_0} & &\\geq H_{B_1C_0}, \\\\\nH_{A_1B_0C_1} & &\\geq H_{A_1C_1}, \\\\\nH_{A_1B_1C_0} & &\\geq H_{A_1B_1},\n\\end{eqnarray}\nleading to\n\\begin{eqnarray}\n& &H_{A_0B_0}+H_{A_0B_1}+H_{A_1B_0}- H_{A_1B_1} -H_{A_0} -H_{B_0} \\\\ \\nonumber\n& & +H_{A_0C_0}+H_{A_0C_1}+H_{A_1C_0}-H_{A_1C_1}-H_{A_0} -H_{C_0} \\geq 0,\n\\end{eqnarray}\nthat can be rewritten exactly as\n\n", "itemtype": "equation", "pos": 50115, "prevtext": "\nwith the classical correlation\n\n", "index": 17, "text": "\\begin{equation}\n\\label{pctri}\np_{\\mathrm{PC}}\\left(  a,b,c | x,y,z \\right)  =\\left\\{\n\\begin{array}{ll}\n1/2 & \\text{, }  a \\oplus b \\oplus c =0\\\\\n0 & \\text{, otherwise}\n\\end{array}\n\\right..\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"p_{\\mathrm{PC}}\\left(a,b,c|x,y,z\\right)=\\left\\{\\begin{array}[]{ll}1/2&amp;\\text{, %&#10;}a\\oplus b\\oplus c=0\\\\&#10;0&amp;\\text{, otherwise}\\end{array}\\right..\" display=\"block\"><mrow><msub><mi>p</mi><mi>PC</mi></msub><mrow><mo>(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>,\u00a0</mtext><mo>\u2062</mo><mi>a</mi></mrow><mo>\u2295</mo><mi>b</mi><mo>\u2295</mo><mi>c</mi></mrow><mo>=</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>, otherwise</mtext></mtd></mtr></mtable><mo>.</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwith\n\n", "itemtype": "equation", "pos": 52522, "prevtext": "\n\nThe nonlocal character of this distribution can be witnessed via the following tripartite entropic inequality (obtained via the approach described in Sec. \\ref{subsec:tool})\n\\begin{eqnarray}\nM_3= & & H_{A_0B_1C_1} - H_{A_1B_1C_1} - H_{A_1B_1C_0} - H_{A_1B_0C_1} \\\\ \\nonumber\n& &-H_{A_0B_0C_0}+H_{B_0C_0} + H_{A_1C_1} +H_{A_1B_1} \\leq 0,\n\\end{eqnarray}\nsince the correlations above imply that $M_3=1$ thus violating the inequality. To prove this inequality analytically it is sufficient to consider the chain rule for entropies, implying that\n\\begin{eqnarray}\nH_{A_1B_1C_1A_0B_0C_0}=& &H_{A_0\\vert B_1C_1A_1B_0C_0}+  H_{B_0 \\vert C_1A_1B_1C_0}  \\\\ \\nonumber\n& & + H_{C_1 \\vert A_1B_1C_0}  +H_{A_1 \\vert B_1C_0} +H_{B_1\\vert C_0} +H_{C_0}.\n\\end{eqnarray}\nUsing the basic inequalities saying that $H(A) \\leq H(A,B) $ and $H(A\\vert B,C) \\leq H(A\\vert B)$, we can turn the chain rule decomposition above in the inequality\n\\begin{eqnarray}\nH_{A_0B_1C_1}=& &H_{A_0\\vert B_0C_0}+  H_{B_0 \\vert C_1A_1} + H_{C_1 \\vert A_1B_1} \\\\ \\nonumber\n& &  +H_{A_1 \\vert B_1C_0} +H_{B_1\\vert C_0} +H_{C_0},\n\\end{eqnarray}\nthat can be rewrite exactly as $M_3 \\leq 0$ if we use that $H(A \\vert B)= H(A,B)-H(B)$.\n\n\n\\subsubsection{Proving the monogamy inequality for the entropic CHSH}\nIn order to prove that the monogamy inequality \\eqref{monogamy} in the main text holds for nonsignalling correlations, we must show that if follows from the elemental inequalities for each subset of mutually compatible observables $A_x,B_y,C_z$. It is sufficient to add the the following elemental inequalities\n\\begin{eqnarray}\nH_{A_0B_0}+H_{A_0C_1} & &\\geq H_{A_0B_0C_1}+H_{A_0}, \\\\\nH_{A_0B_1}+H_{A_0C_0} & &\\geq H_{A_0B_1C_0}+H_{A_0}, \\\\\nH_{A_1B_0}+H_{B_0C_1} & &\\geq H_{A_1B_0C_1}+H_{B_0}, \\\\\nH_{A_1C_0}+H_{B_1C_0} & &\\geq H_{A_1B_1C_0}+H_{C_0}, \\\\\nH_{A_0B_0C_1} & &\\geq H_{B_0C_1}, \\\\\nH_{A_0B_1C_0} & &\\geq H_{B_1C_0}, \\\\\nH_{A_1B_0C_1} & &\\geq H_{A_1C_1}, \\\\\nH_{A_1B_1C_0} & &\\geq H_{A_1B_1},\n\\end{eqnarray}\nleading to\n\\begin{eqnarray}\n& &H_{A_0B_0}+H_{A_0B_1}+H_{A_1B_0}- H_{A_1B_1} -H_{A_0} -H_{B_0} \\\\ \\nonumber\n& & +H_{A_0C_0}+H_{A_0C_1}+H_{A_1C_0}-H_{A_1C_1}-H_{A_0} -H_{C_0} \\geq 0,\n\\end{eqnarray}\nthat can be rewritten exactly as\n\n", "index": 19, "text": "\\begin{equation}\n\\label{mono_app}\nS^{AB}_{\\mathrm{E}}+S^{AC}_{\\mathrm{E}}\\leq 0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"S^{AB}_{\\mathrm{E}}+S^{AC}_{\\mathrm{E}}\\leq 0,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msubsup><mo>+</mo><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>C</mi></mrow></msubsup></mrow><mo>\u2264</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nand\n\n", "itemtype": "equation", "pos": 52623, "prevtext": "\nwith\n\n", "index": 21, "text": "\\begin{equation}\n\\label{ECHSH_AB_app}\nS^{AB}_{\\mathrm{E}}=I_{A_0:B_0} +I_{A_0:B_1} +I_{A_1:B_0}-I_{A_1:B_1} -H_{A_0}-H_{B_0},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"S^{AB}_{\\mathrm{E}}=I_{A_{0}:B_{0}}+I_{A_{0}:B_{1}}+I_{A_{1}:B_{0}}-I_{A_{1}:B%&#10;_{1}}-H_{A_{0}}-H_{B_{0}},\" display=\"block\"><mrow><mrow><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msubsup><mo>=</mo><mrow><mrow><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>B</mi><mn>0</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>B</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>B</mi><mn>0</mn></msub></mrow></msub></mrow><mo>-</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>B</mi><mn>1</mn></msub></mrow></msub><mo>-</mo><msub><mi>H</mi><msub><mi>A</mi><mn>0</mn></msub></msub><mo>-</mo><msub><mi>H</mi><msub><mi>B</mi><mn>0</mn></msub></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\n\nA similar construction can be used to show that the monogamy relation \\eqref{mono_app} holds for any symmetry of the entropic CHSH inequalities \\eqref{ECHSH_AB_app} and \\eqref{ECHSH_AC_app}, thus proving that whenever entropic the marginal correlations $H(A_x,B_y)$ display nonlocality necessarily $H(A_x,C_z)$ must be local.\n\n\n\n\n\\subsubsection{Genuine tripartite nonlocality}\nSimilarly to what happens to entanglement \\cite{horodecki2009quantum}, when moving from the bipartite case, different classes of nonlocality can be categorized. In the tripartite scenario one can introduce the notion of genuine tripartite nonlocality, that is, a stronger form of nonlocality that cannot be reproduced by LHV models even if two of the parties are allowed to share some nonlocal resources. As discussed in the main text, hybrid local-nonsignalling (L$|$NS) models are those that can be decomposed as\n\\begin{eqnarray}\n\\label{LHV_tri_gen}\np(a,b,c\\vert x,y,z) = & & \\sum_{\\lambda} p(a \\vert x, \\lambda ) p(b,c \\vert y,z, \\lambda) p( \\lambda ) + \\\\ \\nonumber\n& & \\sum_{\\mu} p(a,b \\vert x,y, \\mu ) p(c \\vert z, \\mu) p( \\mu ) + \\\\ \\nonumber\n& &\\sum_{\\nu} p(a,c \\vert x,z, \\nu ) p(b \\vert y, \\nu) p( \\nu ).\n\\end{eqnarray}\nwhere $\\sum_\\lambda p( \\lambda )+ \\sum_\\mu p( \\mu )+ \\sum_\\nu p( \\nu )=1$ and where  $p(b,c \\vert y,z, \\lambda)$ (similarly to the other permutations) represent some nonlocal resource. The different nonlocal resources we allow the parties to share will lead to distinct notions of genuine multipartite nonlocality. See \\cite{Gallego2012,Pironio2013} for a discussion of the different (non-signalling or signalling) nonlocal resources that can be used in the definition of genuine multipartite nonlocality. Here we will focus our attention to nonsignalling nonlocal resources, as for example, nonlocal quantum correlations or PR-boxes \\cite{Popescu1994}. In this case, \\eqref{LHV_tri_gen} is equivalent to the existence of probability distributions $p(a_0,a_1,b_j,c_k)$, $p(a_i,b_0,b_1,c_k)$ and $p(a_i,b_j,c_0,c_1)$  such that the marginals $p(a_i,b_j,c_k)$ coincide $\\forall i,j,k=0,1$.\n\nTo simplify the discussion let us consider that each of the parties can perform two possible measurements. The first term in the decomposition \\eqref{LHV_tri_gen}, that is, a model with decomposition given by\n\n", "itemtype": "equation", "pos": 52768, "prevtext": "\nand\n\n", "index": 23, "text": "\\begin{equation}\n\\label{ECHSH_AC_app}\nS^{AC}_{\\mathrm{E}}=I_{A_0:C_0} +I_{A_0:C_1} +I_{A_1:C_0}-I_{A_1:C_1} -H_{A_0}-H_{C_0}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"S^{AC}_{\\mathrm{E}}=I_{A_{0}:C_{0}}+I_{A_{0}:C_{1}}+I_{A_{1}:C_{0}}-I_{A_{1}:C%&#10;_{1}}-H_{A_{0}}-H_{C_{0}}.\" display=\"block\"><mrow><mrow><msubsup><mi>S</mi><mi mathvariant=\"normal\">E</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>C</mi></mrow></msubsup><mo>=</mo><mrow><mrow><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>C</mi><mn>0</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>0</mn></msub><mo>:</mo><msub><mi>C</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>C</mi><mn>0</mn></msub></mrow></msub></mrow><mo>-</mo><msub><mi>I</mi><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>:</mo><msub><mi>C</mi><mn>1</mn></msub></mrow></msub><mo>-</mo><msub><mi>H</mi><msub><mi>A</mi><mn>0</mn></msub></msub><mo>-</mo><msub><mi>H</mi><msub><mi>C</mi><mn>0</mn></msub></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nis equivalent, in the entropic description, to the existence of $H(A_0,A_1,B_j,C_k)$ and all its marginals. For each value of $j,k=0,1$ we have therefore a collection of four variables respecting the Shannon type inequalities \\eqref{shannonineqs_basic}.\n\nSimilarly, the two other terms in \\eqref{LHV_tri_gen}, namely\n\\begin{eqnarray}\n\\label{LHV_tri2}\np(a,b,c\\vert x,y,z) = & & \\sum_{\\mu} p^{\\mathrm{NS}}(a,b \\vert x,y, \\mu ) p(c \\vert z, \\mu) p( \\mu ), \\\\\\label{LHV_tri3}\np(a,b,c\\vert x,y,z) =& & \\sum_{\\nu} p^{\\mathrm{NS}}(a,c \\vert x,z, \\nu ) p(b \\vert y, \\nu) p( \\nu ),\n\\end{eqnarray}\nimply the existence of $H(A_i,B_0,B_1,C_k)$ and $H(A_i,B_j,C_0,C_1)$ respectively. Thus, following the general prescription, the entropic description of hybrid local-nonsignalling (L$|$NS) correlations corresponds to the intersection of the Shannon cones defined for each of subsets of variables $\\left\\{A_0,A_1,B_j,C_k\\right\\}$, $\\left\\{A_i,B_0,B_1,C_k\\right\\}$ and $\\left\\{A_i,B_j,C_0,C_1\\right\\}$ with $i,j,k=0,1$.\n\nThe marginal entropic cone $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ characterizing \\eqref{LHV_tri_gen} will be the convex hull of the of the cones $\\Gamma^a_{\\mathrm{L}|\\mathrm{NS}}\n$, $\\Gamma^b_{\\mathrm{L}|\\mathrm{NS}}\n$ and $\\Gamma^c_{\\mathrm{L}|\\mathrm{NS}}\n$, characterizing, respectively, \\eqref{LHV_tri1}, \\eqref{LHV_tri2} and \\eqref{LHV_tri3}. We have tried computationally to compute the extremal rays of $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ however the computation seems to be out of reach. In spite of that, checking whether a given nonlocal extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$ defines or not a genuine tripartite nonlocal correlation is computationally much simpler.\n\nNotice that $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n \\subset \\Gamma^{3}_{\\mathrm{NS}}$ and since $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ is obtained as the convex hull of $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$), checking whether a given extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$ lies inside $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ is equivalent to check whether it lies inside each of the cones $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$). This can be seen as follows.let $r\\in \\Gamma^{3}_{\\mathrm{NS}}$, then $\\boldsymbol{r}\\in \\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ if $\\boldsymbol{r} =\\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3}$, where $\\boldsymbol{h_i} \\in \\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}$\nNotice that, by cone properties, the sum can be interpreted as a the convex sum $\\frac{1}{3}(3\\boldsymbol{h}_1 +3\\boldsymbol{h}_2 +3\\boldsymbol{h}_3)$. This can be written as a linear program (actually, as feasibility problem, i.e., $\\boldsymbol{\\mathcal{I}}$ is irrelevant)\n\n\\begin{eqnarray}\n\\underset{\\boldsymbol{r} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP3} \\\\\n{\\textrm{subject to }} & &  M_1\\boldsymbol{h_1} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_2\\boldsymbol{h_2} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_3\\boldsymbol{h_3} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& & \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} = \\boldsymbol{r}.\n\\end{eqnarray}\n\nIn addition, if $\\boldsymbol{r}$ is an extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$, then\n $\\boldsymbol{r} =\\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3}$ implies that at\n least two of the $\\boldsymbol{h_i}$ are zero (extremal rays cannot be written as convex\n combinations). Hence, for extremal rays it is sufficient to check that they belong to at\n least one of the $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}$.\n\nThus, running three sets of linear programs, one for each cone $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$), we can decide whether a given extremal entropic NS ray displays or not genuine tripartite nonlocality.\n\n\n\nA similar construction holds to check whether a given entropic inequality is a valid witness of GTNL. An entropic inequality $\\boldsymbol{\\mathcal{I}}$ for GTNL should be satisfied by any correlation that can be written as the convex sum over points within $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=1,2,3$), that is,\n\n", "itemtype": "equation", "pos": 55215, "prevtext": "\n\nA similar construction can be used to show that the monogamy relation \\eqref{mono_app} holds for any symmetry of the entropic CHSH inequalities \\eqref{ECHSH_AB_app} and \\eqref{ECHSH_AC_app}, thus proving that whenever entropic the marginal correlations $H(A_x,B_y)$ display nonlocality necessarily $H(A_x,C_z)$ must be local.\n\n\n\n\n\\subsubsection{Genuine tripartite nonlocality}\nSimilarly to what happens to entanglement \\cite{horodecki2009quantum}, when moving from the bipartite case, different classes of nonlocality can be categorized. In the tripartite scenario one can introduce the notion of genuine tripartite nonlocality, that is, a stronger form of nonlocality that cannot be reproduced by LHV models even if two of the parties are allowed to share some nonlocal resources. As discussed in the main text, hybrid local-nonsignalling (L$|$NS) models are those that can be decomposed as\n\\begin{eqnarray}\n\\label{LHV_tri_gen}\np(a,b,c\\vert x,y,z) = & & \\sum_{\\lambda} p(a \\vert x, \\lambda ) p(b,c \\vert y,z, \\lambda) p( \\lambda ) + \\\\ \\nonumber\n& & \\sum_{\\mu} p(a,b \\vert x,y, \\mu ) p(c \\vert z, \\mu) p( \\mu ) + \\\\ \\nonumber\n& &\\sum_{\\nu} p(a,c \\vert x,z, \\nu ) p(b \\vert y, \\nu) p( \\nu ).\n\\end{eqnarray}\nwhere $\\sum_\\lambda p( \\lambda )+ \\sum_\\mu p( \\mu )+ \\sum_\\nu p( \\nu )=1$ and where  $p(b,c \\vert y,z, \\lambda)$ (similarly to the other permutations) represent some nonlocal resource. The different nonlocal resources we allow the parties to share will lead to distinct notions of genuine multipartite nonlocality. See \\cite{Gallego2012,Pironio2013} for a discussion of the different (non-signalling or signalling) nonlocal resources that can be used in the definition of genuine multipartite nonlocality. Here we will focus our attention to nonsignalling nonlocal resources, as for example, nonlocal quantum correlations or PR-boxes \\cite{Popescu1994}. In this case, \\eqref{LHV_tri_gen} is equivalent to the existence of probability distributions $p(a_0,a_1,b_j,c_k)$, $p(a_i,b_0,b_1,c_k)$ and $p(a_i,b_j,c_0,c_1)$  such that the marginals $p(a_i,b_j,c_k)$ coincide $\\forall i,j,k=0,1$.\n\nTo simplify the discussion let us consider that each of the parties can perform two possible measurements. The first term in the decomposition \\eqref{LHV_tri_gen}, that is, a model with decomposition given by\n\n", "index": 25, "text": "\\begin{equation}\n\\label{LHV_tri1}\np(a,b,c\\vert x,y,z) = \\sum_{\\lambda} p(a \\vert x, \\lambda ) p^{\\mathrm{NS}}(b,c \\vert y,z, \\lambda) p( \\lambda ),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"p(a,b,c|x,y,z)=\\sum_{\\lambda}p(a|x,\\lambda)p^{\\mathrm{NS}}(b,c|y,z,\\lambda)p(%&#10;\\lambda),\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>\u03bb</mi></munder><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow><msup><mi>p</mi><mi>NS</mi></msup><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">|</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>,</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwhere $\\boldsymbol{h}_i \\in \\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$.  Any inequality satisfying $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_1 \\rangle \\geq 0$, $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_2 \\rangle \\geq 0$ and $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_3 \\rangle \\geq 0$ will also satisfy \\eqref{ineqCs}. This means that in practice to check if a given inequality is a valid GTNL inequality, we need to solve three linear programs like \\eqref{LP}, one for each set of inequalities characterizing the cones $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=1,2,3$) .\nThis can be seen as follows. Consider the LP\n\\begin{eqnarray}\n\\underset{\\boldsymbol{r} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} \\rangle  \t\\label{LP4} \\\\\n{\\textrm{subject to }} & &  M_1\\boldsymbol{h_1} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_2\\boldsymbol{h_2} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_3\\boldsymbol{h_3} \\geq \\boldsymbol{0}.\n\\end{eqnarray}\nThe inequality is valid if and only if $\\min \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} \\rangle \\geq 0$. However, since $\\boldsymbol{h_i}=\\boldsymbol{0}$ is a valid solution for all three cones, the above is equivalent to require separately that $\\min \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_i} \\rangle \\geq 0$.\n\n\n\n\nWe now turn our attention to the entropic inequality \\eqref{EGTNL} witnessing GTNL discussed in the main text and given by\n\\begin{eqnarray}\n\\nonumber\n\\label{EGTNL_app}\n& & S_{\\mathrm{L}|\\mathrm{NS}}\n=H_{A_1B_1C_0}+H_{A_1B_0C_0}+H_{A_1B_0C_1}+H_{A_0B_1C_0}+H_{A_0B_1C_1} \\\\\n& &- H_{A_1B_1C_1} -H_{A_1B_0}- H_{A_1C_0}- H_{A_0C_1} - H_{B_1C_0} \\geq 0.\n\\end{eqnarray}\n\nTo prove that this inequality is valid for the cone $\\Gamma^a_{\\mathrm{L}|\\mathrm{NS}}\n$, it is sufficient to consider the sum of the following basic inequalities (valid for the subsets of variables $\\left\\{A_0,A_1,B_j,C_k\\right\\}$):\n\\begin{eqnarray}\n\\label{ineq_sum}\nH_{A_0A_1B_1C_0}  & & \\geq H_{A_0A_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_1C_1}  & & \\geq H_{A_1B_1C_1}, \\\\ \\nonumber\nH_{A_0A_1B_0C_0}  & & \\geq H_{A_0A_1B_0}, \\\\ \\nonumber\nH_{A_0A_1B_0C_1}  & & \\geq H_{A_0A_1C_1}, \\\\ \\nonumber\nH_{A_1B_1C_0} +H_{A_0B_1C_0} & & \\geq H_{A_0A_1B_1C_0} + H_{B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1C_1} +H_{A_0B_1C_1}  & &\\geq H_{A_0A_1B_1C_1} + H_{A_0C_1}, \\\\ \\nonumber\nH_{A_0A_1C_0} +H_{A_1B_0C_0}  & &\\geq H_{A_0A_1B_0C_0} + H_{A_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0} +H_{A_1B_0C_1}  & &\\geq H_{A_0A_1B_0C_1} + H_{A_1B_0}.\n\\end{eqnarray}\nTo prove the validity of \\eqref{EGTNL_app} for the cones $\\Gamma^b_{\\mathrm{L}|\\mathrm{NS}}\n$ and $\\Gamma^c_{\\mathrm{L}|\\mathrm{NS}}\n$ a similar sum of eight basic inequalities is again enough.\n\nAs discussed in the main text, the entropic inequality \\eqref{EGTNL_app} can be used to witness the presence of genuine tripartite nonlocality in quantum states. To that aim we consider d-dimensional GHZ states\n\n", "itemtype": "equation", "pos": 59444, "prevtext": "\nis equivalent, in the entropic description, to the existence of $H(A_0,A_1,B_j,C_k)$ and all its marginals. For each value of $j,k=0,1$ we have therefore a collection of four variables respecting the Shannon type inequalities \\eqref{shannonineqs_basic}.\n\nSimilarly, the two other terms in \\eqref{LHV_tri_gen}, namely\n\\begin{eqnarray}\n\\label{LHV_tri2}\np(a,b,c\\vert x,y,z) = & & \\sum_{\\mu} p^{\\mathrm{NS}}(a,b \\vert x,y, \\mu ) p(c \\vert z, \\mu) p( \\mu ), \\\\\\label{LHV_tri3}\np(a,b,c\\vert x,y,z) =& & \\sum_{\\nu} p^{\\mathrm{NS}}(a,c \\vert x,z, \\nu ) p(b \\vert y, \\nu) p( \\nu ),\n\\end{eqnarray}\nimply the existence of $H(A_i,B_0,B_1,C_k)$ and $H(A_i,B_j,C_0,C_1)$ respectively. Thus, following the general prescription, the entropic description of hybrid local-nonsignalling (L$|$NS) correlations corresponds to the intersection of the Shannon cones defined for each of subsets of variables $\\left\\{A_0,A_1,B_j,C_k\\right\\}$, $\\left\\{A_i,B_0,B_1,C_k\\right\\}$ and $\\left\\{A_i,B_j,C_0,C_1\\right\\}$ with $i,j,k=0,1$.\n\nThe marginal entropic cone $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ characterizing \\eqref{LHV_tri_gen} will be the convex hull of the of the cones $\\Gamma^a_{\\mathrm{L}|\\mathrm{NS}}\n$, $\\Gamma^b_{\\mathrm{L}|\\mathrm{NS}}\n$ and $\\Gamma^c_{\\mathrm{L}|\\mathrm{NS}}\n$, characterizing, respectively, \\eqref{LHV_tri1}, \\eqref{LHV_tri2} and \\eqref{LHV_tri3}. We have tried computationally to compute the extremal rays of $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ however the computation seems to be out of reach. In spite of that, checking whether a given nonlocal extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$ defines or not a genuine tripartite nonlocal correlation is computationally much simpler.\n\nNotice that $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n \\subset \\Gamma^{3}_{\\mathrm{NS}}$ and since $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ is obtained as the convex hull of $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$), checking whether a given extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$ lies inside $\\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ is equivalent to check whether it lies inside each of the cones $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$). This can be seen as follows.let $r\\in \\Gamma^{3}_{\\mathrm{NS}}$, then $\\boldsymbol{r}\\in \\Gamma_{\\mathrm{L}|\\mathrm{NS}}\n$ if $\\boldsymbol{r} =\\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3}$, where $\\boldsymbol{h_i} \\in \\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}$\nNotice that, by cone properties, the sum can be interpreted as a the convex sum $\\frac{1}{3}(3\\boldsymbol{h}_1 +3\\boldsymbol{h}_2 +3\\boldsymbol{h}_3)$. This can be written as a linear program (actually, as feasibility problem, i.e., $\\boldsymbol{\\mathcal{I}}$ is irrelevant)\n\n\\begin{eqnarray}\n\\underset{\\boldsymbol{r} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h} \\rangle  \t\\label{LP3} \\\\\n{\\textrm{subject to }} & &  M_1\\boldsymbol{h_1} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_2\\boldsymbol{h_2} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_3\\boldsymbol{h_3} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& & \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} = \\boldsymbol{r}.\n\\end{eqnarray}\n\nIn addition, if $\\boldsymbol{r}$ is an extremal ray of $\\Gamma^{3}_{\\mathrm{NS}}$, then\n $\\boldsymbol{r} =\\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3}$ implies that at\n least two of the $\\boldsymbol{h_i}$ are zero (extremal rays cannot be written as convex\n combinations). Hence, for extremal rays it is sufficient to check that they belong to at\n least one of the $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}$.\n\nThus, running three sets of linear programs, one for each cone $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=a,b,c$), we can decide whether a given extremal entropic NS ray displays or not genuine tripartite nonlocality.\n\n\n\nA similar construction holds to check whether a given entropic inequality is a valid witness of GTNL. An entropic inequality $\\boldsymbol{\\mathcal{I}}$ for GTNL should be satisfied by any correlation that can be written as the convex sum over points within $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=1,2,3$), that is,\n\n", "index": 27, "text": "\\begin{equation}\n\\label{ineqCs}\n\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_1 +\\boldsymbol{h}_2 +\\boldsymbol{h}_3 \\rangle \\geq 0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\langle\\bm{\\mathcal{I}},\\bm{h}_{1}+\\bm{h}_{2}+\\bm{h}_{3}\\rangle\\geq 0,\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcd8</mi><mo>,</mo><mrow><msub><mi>\ud835\udc89</mi><mn>1</mn></msub><mo>+</mo><msub><mi>\ud835\udc89</mi><mn>2</mn></msub><mo>+</mo><msub><mi>\ud835\udc89</mi><mn>3</mn></msub></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>\u2265</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nand projective measurements given by \\cite{Collins2002}\n\n", "itemtype": "equation", "pos": 62591, "prevtext": "\nwhere $\\boldsymbol{h}_i \\in \\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$.  Any inequality satisfying $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_1 \\rangle \\geq 0$, $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_2 \\rangle \\geq 0$ and $\\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h}_3 \\rangle \\geq 0$ will also satisfy \\eqref{ineqCs}. This means that in practice to check if a given inequality is a valid GTNL inequality, we need to solve three linear programs like \\eqref{LP}, one for each set of inequalities characterizing the cones $\\Gamma^i_{\\mathrm{L}|\\mathrm{NS}}\n$ ($i=1,2,3$) .\nThis can be seen as follows. Consider the LP\n\\begin{eqnarray}\n\\underset{\\boldsymbol{r} \\in {\\mathbbm{R}}^{2^n}}{{\\textrm{minimize}}} & & \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} \\rangle  \t\\label{LP4} \\\\\n{\\textrm{subject to }} & &  M_1\\boldsymbol{h_1} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_2\\boldsymbol{h_2} \\geq \\boldsymbol{0}, \\\\ \\nonumber\n& &  M_3\\boldsymbol{h_3} \\geq \\boldsymbol{0}.\n\\end{eqnarray}\nThe inequality is valid if and only if $\\min \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_1} + \\boldsymbol{h_2} +\\boldsymbol{h_3} \\rangle \\geq 0$. However, since $\\boldsymbol{h_i}=\\boldsymbol{0}$ is a valid solution for all three cones, the above is equivalent to require separately that $\\min \\langle \\boldsymbol{\\mathcal{I}}, \\boldsymbol{h_i} \\rangle \\geq 0$.\n\n\n\n\nWe now turn our attention to the entropic inequality \\eqref{EGTNL} witnessing GTNL discussed in the main text and given by\n\\begin{eqnarray}\n\\nonumber\n\\label{EGTNL_app}\n& & S_{\\mathrm{L}|\\mathrm{NS}}\n=H_{A_1B_1C_0}+H_{A_1B_0C_0}+H_{A_1B_0C_1}+H_{A_0B_1C_0}+H_{A_0B_1C_1} \\\\\n& &- H_{A_1B_1C_1} -H_{A_1B_0}- H_{A_1C_0}- H_{A_0C_1} - H_{B_1C_0} \\geq 0.\n\\end{eqnarray}\n\nTo prove that this inequality is valid for the cone $\\Gamma^a_{\\mathrm{L}|\\mathrm{NS}}\n$, it is sufficient to consider the sum of the following basic inequalities (valid for the subsets of variables $\\left\\{A_0,A_1,B_j,C_k\\right\\}$):\n\\begin{eqnarray}\n\\label{ineq_sum}\nH_{A_0A_1B_1C_0}  & & \\geq H_{A_0A_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_1C_1}  & & \\geq H_{A_1B_1C_1}, \\\\ \\nonumber\nH_{A_0A_1B_0C_0}  & & \\geq H_{A_0A_1B_0}, \\\\ \\nonumber\nH_{A_0A_1B_0C_1}  & & \\geq H_{A_0A_1C_1}, \\\\ \\nonumber\nH_{A_1B_1C_0} +H_{A_0B_1C_0} & & \\geq H_{A_0A_1B_1C_0} + H_{B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1C_1} +H_{A_0B_1C_1}  & &\\geq H_{A_0A_1B_1C_1} + H_{A_0C_1}, \\\\ \\nonumber\nH_{A_0A_1C_0} +H_{A_1B_0C_0}  & &\\geq H_{A_0A_1B_0C_0} + H_{A_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0} +H_{A_1B_0C_1}  & &\\geq H_{A_0A_1B_0C_1} + H_{A_1B_0}.\n\\end{eqnarray}\nTo prove the validity of \\eqref{EGTNL_app} for the cones $\\Gamma^b_{\\mathrm{L}|\\mathrm{NS}}\n$ and $\\Gamma^c_{\\mathrm{L}|\\mathrm{NS}}\n$ a similar sum of eight basic inequalities is again enough.\n\nAs discussed in the main text, the entropic inequality \\eqref{EGTNL_app} can be used to witness the presence of genuine tripartite nonlocality in quantum states. To that aim we consider d-dimensional GHZ states\n\n", "index": 29, "text": "\\begin{equation}\n{| {\\mathrm{GHZ}} \\rangle}= \\frac{1}{\\sqrt{d}} \\sum_{j=0}^{d-1} {| {jjj} \\rangle},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"{|{\\mathrm{GHZ}}\\rangle}=\\frac{1}{\\sqrt{d}}\\sum_{j=0}^{d-1}{|{jjj}\\rangle},\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>GHZ</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msqrt><mi>d</mi></msqrt></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>d</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mrow><mi>j</mi><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><mi>j</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwhere $p=1,2,3$ denotes the party, $m=0,1$ denotes its measurement choice and $k$ denotes its outcome. For this sort of measurements on GHZ states the probabilities of outcomes can readily be computed to be given by\n\n", "itemtype": "equation", "pos": 62762, "prevtext": "\nand projective measurements given by \\cite{Collins2002}\n\n", "index": 31, "text": "\\begin{equation}\n\\label{f_measurements}\n{| {k} \\rangle}_{p,m}= \\frac{1}{\\sqrt{d}}\\sum_{j=0}^{d-1} e^{i \\frac{2\\pi}{d} j (k+\\alpha_{p,m})} {| {j} \\rangle},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"{|{k}\\rangle}_{p,m}=\\frac{1}{\\sqrt{d}}\\sum_{j=0}^{d-1}e^{i\\frac{2\\pi}{d}j(k+%&#10;\\alpha_{p,m})}{|{j}\\rangle},\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>k</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mrow><mi>p</mi><mo>,</mo><mi>m</mi></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><msqrt><mi>d</mi></msqrt></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>d</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><msup><mi>e</mi><mrow><mi>i</mi><mo>\u2062</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mi>d</mi></mfrac><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>+</mo><msub><mi>\u03b1</mi><mrow><mi>p</mi><mo>,</mo><mi>m</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>j</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nwith $\\gamma_{a,b,c,x,y,z}=\\pi (a+b+c+\\alpha_{1,x}+\\alpha_{2,y}+\\alpha_{3,z})$.\n\nUsing this expression we can readily compute the associated Shannon entropies and thus perform numerical optimizations to obtain the optimal violation of inequality \\eqref{EGTNL_app}. We have performed such analysis up to $d=40$ and the results are shown in  {Fig.~\\ref{{fig:GTNL_GHZ}}}.\n\n\n\n\\subsubsection{Bilocality}\nThe so-called bilocality scenario \\cite{Branciard2010} has been introduced as the classical\nanalogue of an entanglement swapping experiment \\cite{Zukowski1993}, where two independent\npairs of entangled particles are distributed among three parties. Joint measurements on one\nparticle of each pair (e.g. in a Bell basis) can create entanglement and nonlocal\ncorrelations among the remaining two particles, even though they have never interacted.\nFormally, we consider that a central node, Bob, receives one particle from both pairs while\ntwo other parts, Alice and Charlie, receive each one particle from a given entangled pair.\nAs usual in a Bell scenario, we consider that at each run of the experiment each of the\nparties can perform different possible measurements labelled by random variables $X$, $Y$\nand $Z$ and obtain, respectively, outcomes labelled by $A$, $B$, $C$. The observed probability distribution $p(a,b,c \\vert x,y,z)$\ncan thus be decomposed as\n\\begin{eqnarray}\n\\label{LHV_bilocal}\np(a,b,c \\vert x,y,z)= \\sum_{\\lambda_1,\\lambda_2} & &  p(\\lambda_1)p(\\lambda_2) \\\\ \\nonumber\n& &p(a \\vert x,\\lambda_1 ) p(b \\vert y,\\lambda_1,\\lambda_2 ) p(c \\vert z,\\lambda_2 ).\n\\end{eqnarray}\nNotice that in \\eqref{LHV_bilocal} the finer structure of the underlying causal structure is taken into account, namely in the fact that $p(\\lambda_1,\\lambda_2)=p(\\lambda_1)p(\\lambda_2)$ (independence of the sources) and that the outcomes $A$ of Alice ($C$ of Charlie) only depend on $\\Lambda_1$ ($\\Lambda_2$).\n\nConsidering that each of the parties perform two possible measurements, the entropic description of bilocality is equivalent to the existence of a joint entropy $H(A_0,A_1,B_0,B_1,C_0,C_1)$ respecting the Shannon type inequalities together with the bilocality constraint $H(A_0,A_1,C_0,C_1)=H(A_0,A_1)+H(C_0,C_1)$.\n\nWe further notice that in the bilocality scenario there are two possible slightly different situations we may want to consider. In the first scenario the random variables $B_0$ and $B_1$ stand for the measurement outcomes of two different measurements performed by Bob. In this case $H(B_0,B_1)$ will correspond to a non-observable quantity. In the second situation, we can understand $B_0$ and $B_1$ as standing for a finer description of a single measurement performed by Bob. For instance, consider that Bob always measure in a Bell basis $\\left\\{ {| {\\Psi^{\\pm}} \\rangle},{| {\\Phi^{\\pm}} \\rangle} \\right\\}$. The variable $B_0$ could stand for the information regarding whether the measurement outcome correspond to ${| {\\Psi} \\rangle}$ or ${| {\\Phi} \\rangle}$ while $B_1$ would stand for the information about phase, for instance,\n${| {\\Psi^{+}} \\rangle}$ or ${| {\\Psi^{-}} \\rangle}$. In this situation, $H(B_0,B_1)$ corresponds to an observable quantity. In the following we will focus our attention to the first case, that is, we have to eliminate from our description terms like $H(B_0,B_1)$.\n\nSimilarly to what happens in the usual tripartite case, the complete description of the bilocality scenario in terms of a FM elimination is out of computational reach. However, characterizing the extremal rays of the bilocal entropic NS cone is much simpler. We have obtained $329$ different classes of extremal NS bilocal entropic rays, $15$ of which are bilocal while $314$ correspond to nonbilocal correlations. From this $314$ rays, $40$ are genuine-nonbilocal in the sense of admitting a LHV model but not a bilocal LHV model. Using the tool described in Sec. \\ref{subsec:tool} one can derive entropic inequalities detecting the nonbilocality of these rays. Next we employ the framework in Sec. \\ref{subsec:tool} to provide an analytical proof the inequalities \\eqref{bilocal_ineq1} and \\eqref{bilocal_ineq2} discussed in the main text.\nTo prove \\eqref{bilocal_ineq1}, we have to sum the following basic inequalities\n\\begin{eqnarray}\nH_{A_0}+H_{C} & &\\geq H_{A0C}, \\\\ \\nonumber\nH_{A_0A_1BC} & &\\geq H_{A_0A_1C}, \\\\ \\nonumber\nH_{A_0A_1}+H_{A_0B} & &\\geq H_{A_0A_1B} +H_{A_0}, \\\\ \\nonumber\nH_{A_0A_1B}+H_{A_1BC} & &\\geq H_{A_0A_1BC}+H_{A_1B}.\n\\end{eqnarray}\nand use the bilocality constraint $H_{A_0,A_1}+H_{C}=H_{A_0A_1C}$.\n\nIn turn, to prove inequality \\eqref{bilocal_ineq2} we have to sum the following Shannon type inequalities\n\\begin{eqnarray}\nH_{A_0A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0C_0C_1}, \\\\ \\nonumber\nH_{B_0C_1}+H_{C_0C_1} & & \\geq H_{B_0C_0C_1}+H_{C_1,} \\\\ \\nonumber\nH_{A_0A_1}+H_{A_1C_1} & & \\geq H_{A_0A_1C_1}+H_{A_1,} \\\\ \\nonumber\nH_{A_0B_0C_1}+H_{B_0C_0C_1} & & \\geq H_{A_0B_0C_0C_1}+H_{B_0C_1}, \\\\ \\nonumber\nH_{A_1B_1C_0}+H_{A_1B_1C_1} & & \\geq H_{A_1B_1C_0C_1} +H_{A_1B_1}, \\\\ \\nonumber\nH_{A_0A_1C_1}+H_{A_1C_0C_1} & & \\geq H_{A_0A_1C_0C_1}+H_{A_1C_1}, \\\\ \\nonumber\nH_{A_0B_0B_1C_0}+H_{A_0B_0C_0C_1} & & \\geq  H_{A_0B_0B_1C_0C_1}+H_{A_0B_0C_0}, \\\\ \\nonumber\nH_{A_1B_0C_0C_1}+H_{A_1B_1C_0C_1} & & \\geq H_{A_1B_0B_1C_0C_1} +H_{A_1C_0C_1}, \\\\ \\nonumber\nH_{A_0A_1B_0B_1C_0}+H_{A_0B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0C_1}+H_{A_0B_0B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0C_0C_1}+H_{A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0C_1}+H_{A_1B_0C_0C_1}. \\\\ \\nonumber\n\\end{eqnarray}\nand use the bilocality constraint $H_{A_0,A_1}+H_{C_0,C_1}=H_{A_0A_1C_0C_1}$.\n\n\n\\begin{table*}\n\\label{tab_IC}\n  \\begin{tabular}{|c|l|l|l|l|l|l|l|}\n    \\hline\nExtremal ray & $H(X_0)$ & $H(X_1)$ & $H(Y_0)$ & $H(Y_1)$ & $H(X_0,Y_0)$ & $H(X_1,Y_1)$ & $H(M)$  \\\\ \\hline\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\ \\hline\n2 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\\\ \\hline\n3 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\\\ \\hline\n4 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\ \\hline\n5 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\\\ \\hline\n6 & 0 & 1 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline\n7 & 1 & 0 & 1 & 0 & 1 & 0 & 1 \\\\ \\hline\n8 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ \\hline\n\\end{tabular}\n\\caption{All the extremal rays defining the entropic NS cone of the information causality scenario.}\n\\end{table*}\n\n\\subsubsection{Information Causality}\nInformation causality (IC) \\cite{Pawlowski2009} has been introduced as a principle to\nexplain the degree of nonlocality of quantum mechanics. It basically states that the amount\nof information a given part, Bo,b can have over some bits in possession of another part,\n Alice, is limited by the amount of information communicated from Alice to Bob. Information\ncausality is respected by quantum correlations, however, as shown in \\cite{Pawlowski2009}\nany nonlocal correlation stronger then maximum permitted by quantum mechanics, in sense of\nsurpassing the Tsirelson's bound \\cite{Cirel1980quantum} for the CHSH inequality, will\nviolate it.\n\nIC can be understood as a game between Alice and Bob: Alice receives two independent random bits $X_0$ and $X_1$ and the aim of Bob at each run of the game is to guess the value of one of them, having as resources some pre-shared correlations with Alice and a certain amount of communication sent by her. Which of the two bits he should guess is decided by a random variable $S$. In a classical description we have the variables $X_0,X_1$ representing the input bits of Alice; the variables $Y_0,Y_1$ standing for the guesses of Bob ($Y_s$ is the guess of bit $X_s$ given that $S=s$); $M$ stands for the message sent from Alice to Bob and $\\Lambda$ corresponds to the pre-shared correlations between them.\n\nThe (classical) entropic description of IC is equivalent to the existence of a joint entropy $H(X_0,X_1,B_0,B_1,M,\\Lambda)$ fulfilling the following causal constraints imposed by the rules of the game: $I(X_0:X_1)=0$, $I(X_0,X_1:\\Lambda)=0$ and $I(X_0,X_1:B_0,B_1 \\vert M, \\Lambda)=0$. The first constraint encodes the fact that both bits are uncorrelated and thus have null mutual information (though this is not strictly necessary \\cite{Safi2011,Chaves2015a}). The second constraint encodes the fact that the bits received by Alice are independent of the pre-shared correlation with Bob. Finally, the third constraint encodes the fact that conditioned on the message sent by Alice and on the pre-shared correlations, the guesses of Bob should becomes completely uncorrelated with the input bits. A similar description can be given for the case where the pre-shared correlations arise from an entangled state ${\\varrho}$ rather than a classical variable $\\Lambda$ \\cite{Chaves2015a}.\n\n\nProceeding with the FM elimination we obtain the description of the marginal entropic cone characterizing the information causality game. To that aim, first one needs to define the marginal scenario of interest. Here, similarly to what has been done in \\cite{Pawlowski2009}, we will focus on the marginal scenario $\\mathcal{M}_{\\textrm{IC}}=\\left\\{ \\left\\{ X_0,Y_0 \\right\\},\\left\\{ X_1,Y_1 \\right\\},\\left\\{ M \\right\\}  \\right\\}$. Notice, however, that more general marginal scenarios can be defined \\cite{Chaves2015a}. It follows that the only non-trivial entropic inequality describing the IC game (for classical and quantum pre-shared correlations) is given by:\n\n", "itemtype": "equation", "pos": 63148, "prevtext": "\nwhere $p=1,2,3$ denotes the party, $m=0,1$ denotes its measurement choice and $k$ denotes its outcome. For this sort of measurements on GHZ states the probabilities of outcomes can readily be computed to be given by\n\n", "index": 33, "text": "\\begin{equation}\n\\nonumber\n\\label{probfourier}\np(a,b,c\\vert x,y,z)=  \\frac{1}{d^4}\\csc^2 \\left( \\frac{\\gamma_{a,b,c,x,y,z}}{d} \\right) \\sin^2 \\left( \\gamma_{a,b,c,x,y,z} \\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"p(a,b,c|x,y,z)=\\frac{1}{d^{4}}\\csc^{2}\\left(\\frac{\\gamma_{a,b,c,x,y,z}}{d}%&#10;\\right)\\sin^{2}\\left(\\gamma_{a,b,c,x,y,z}\\right),\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><msup><mi>d</mi><mn>4</mn></msup></mfrac><msup><mi>csc</mi><mn>2</mn></msup><mrow><mo>(</mo><mfrac><msub><mi>\u03b3</mi><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi></mrow></msub><mi>d</mi></mfrac><mo>)</mo></mrow><msup><mi>sin</mi><mn>2</mn></msup><mrow><mo>(</mo><msub><mi>\u03b3</mi><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi></mrow></msub><mo>)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07555.tex", "nexttext": "\nThis inequality quantifies the qualitative expectation that the amount of information Bob has about Alice's inputs is bounded by the amount of information contained in the message (as quantified by $H(M)$).\n\nWe are now in position to define the set of entropic NS correlation for the IC scenario. For the marginal scenario under consideration, the NS set is simply characterized by the Shannon type inequalities $I(X_s:Y_s) \\geq 0$, $H(X_s,Y_s) \\geq H(X_s)$, $H(X_s,Y_s) \\geq H(Y_s)$, $H(M) \\geq 0$ together with the constraint $I(X_s:Y_s) \\leq H(M)$. The NS cone is described in terms of $8$ extremal rays (shown in the Table \\eqref{tab_IC}), $7$ corresponding to correlations that respect the information causality constraint (rays $1$ to $7$) and only $1$ violating it (ray $8$). The extremal ray violating \\eqref{IC_ineq_app} is exactly given by the entropic correlations obtained if we replace the pre-shared correlation by a PR-box and apply the protocol discussed in the original IC paper \\cite{Pawlowski2009}: Alice inputs $x=x_0\\oplus x_1$ in her part of the PR-box, obtaining an outcome $a$ that is then used to encode the message $m=x_0\\oplus a$. Bob inputs in his part of the PR-box, $y=0,1$ depending on which bit $X_y$ he is interested and obtains an outcome $b_y$. His guess is given by $g_y=m\\oplus b_y=x_0\\oplus a\\oplus b_y=x_0\\oplus y(x_0\\oplus x_1)$, that is, he can perfectly guess both outputs of Alice thought only one bit of information ($H(M)=1$) has been sent.\n\n\n\n\n\n\n\n\n\n\n\n\\bibliography{EntNS}\n\n\n\n\n\n", "itemtype": "equation", "pos": 72674, "prevtext": "\nwith $\\gamma_{a,b,c,x,y,z}=\\pi (a+b+c+\\alpha_{1,x}+\\alpha_{2,y}+\\alpha_{3,z})$.\n\nUsing this expression we can readily compute the associated Shannon entropies and thus perform numerical optimizations to obtain the optimal violation of inequality \\eqref{EGTNL_app}. We have performed such analysis up to $d=40$ and the results are shown in  {Fig.~\\ref{{fig:GTNL_GHZ}}}.\n\n\n\n\\subsubsection{Bilocality}\nThe so-called bilocality scenario \\cite{Branciard2010} has been introduced as the classical\nanalogue of an entanglement swapping experiment \\cite{Zukowski1993}, where two independent\npairs of entangled particles are distributed among three parties. Joint measurements on one\nparticle of each pair (e.g. in a Bell basis) can create entanglement and nonlocal\ncorrelations among the remaining two particles, even though they have never interacted.\nFormally, we consider that a central node, Bob, receives one particle from both pairs while\ntwo other parts, Alice and Charlie, receive each one particle from a given entangled pair.\nAs usual in a Bell scenario, we consider that at each run of the experiment each of the\nparties can perform different possible measurements labelled by random variables $X$, $Y$\nand $Z$ and obtain, respectively, outcomes labelled by $A$, $B$, $C$. The observed probability distribution $p(a,b,c \\vert x,y,z)$\ncan thus be decomposed as\n\\begin{eqnarray}\n\\label{LHV_bilocal}\np(a,b,c \\vert x,y,z)= \\sum_{\\lambda_1,\\lambda_2} & &  p(\\lambda_1)p(\\lambda_2) \\\\ \\nonumber\n& &p(a \\vert x,\\lambda_1 ) p(b \\vert y,\\lambda_1,\\lambda_2 ) p(c \\vert z,\\lambda_2 ).\n\\end{eqnarray}\nNotice that in \\eqref{LHV_bilocal} the finer structure of the underlying causal structure is taken into account, namely in the fact that $p(\\lambda_1,\\lambda_2)=p(\\lambda_1)p(\\lambda_2)$ (independence of the sources) and that the outcomes $A$ of Alice ($C$ of Charlie) only depend on $\\Lambda_1$ ($\\Lambda_2$).\n\nConsidering that each of the parties perform two possible measurements, the entropic description of bilocality is equivalent to the existence of a joint entropy $H(A_0,A_1,B_0,B_1,C_0,C_1)$ respecting the Shannon type inequalities together with the bilocality constraint $H(A_0,A_1,C_0,C_1)=H(A_0,A_1)+H(C_0,C_1)$.\n\nWe further notice that in the bilocality scenario there are two possible slightly different situations we may want to consider. In the first scenario the random variables $B_0$ and $B_1$ stand for the measurement outcomes of two different measurements performed by Bob. In this case $H(B_0,B_1)$ will correspond to a non-observable quantity. In the second situation, we can understand $B_0$ and $B_1$ as standing for a finer description of a single measurement performed by Bob. For instance, consider that Bob always measure in a Bell basis $\\left\\{ {| {\\Psi^{\\pm}} \\rangle},{| {\\Phi^{\\pm}} \\rangle} \\right\\}$. The variable $B_0$ could stand for the information regarding whether the measurement outcome correspond to ${| {\\Psi} \\rangle}$ or ${| {\\Phi} \\rangle}$ while $B_1$ would stand for the information about phase, for instance,\n${| {\\Psi^{+}} \\rangle}$ or ${| {\\Psi^{-}} \\rangle}$. In this situation, $H(B_0,B_1)$ corresponds to an observable quantity. In the following we will focus our attention to the first case, that is, we have to eliminate from our description terms like $H(B_0,B_1)$.\n\nSimilarly to what happens in the usual tripartite case, the complete description of the bilocality scenario in terms of a FM elimination is out of computational reach. However, characterizing the extremal rays of the bilocal entropic NS cone is much simpler. We have obtained $329$ different classes of extremal NS bilocal entropic rays, $15$ of which are bilocal while $314$ correspond to nonbilocal correlations. From this $314$ rays, $40$ are genuine-nonbilocal in the sense of admitting a LHV model but not a bilocal LHV model. Using the tool described in Sec. \\ref{subsec:tool} one can derive entropic inequalities detecting the nonbilocality of these rays. Next we employ the framework in Sec. \\ref{subsec:tool} to provide an analytical proof the inequalities \\eqref{bilocal_ineq1} and \\eqref{bilocal_ineq2} discussed in the main text.\nTo prove \\eqref{bilocal_ineq1}, we have to sum the following basic inequalities\n\\begin{eqnarray}\nH_{A_0}+H_{C} & &\\geq H_{A0C}, \\\\ \\nonumber\nH_{A_0A_1BC} & &\\geq H_{A_0A_1C}, \\\\ \\nonumber\nH_{A_0A_1}+H_{A_0B} & &\\geq H_{A_0A_1B} +H_{A_0}, \\\\ \\nonumber\nH_{A_0A_1B}+H_{A_1BC} & &\\geq H_{A_0A_1BC}+H_{A_1B}.\n\\end{eqnarray}\nand use the bilocality constraint $H_{A_0,A_1}+H_{C}=H_{A_0A_1C}$.\n\nIn turn, to prove inequality \\eqref{bilocal_ineq2} we have to sum the following Shannon type inequalities\n\\begin{eqnarray}\nH_{A_0A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0C_0C_1}, \\\\ \\nonumber\nH_{B_0C_1}+H_{C_0C_1} & & \\geq H_{B_0C_0C_1}+H_{C_1,} \\\\ \\nonumber\nH_{A_0A_1}+H_{A_1C_1} & & \\geq H_{A_0A_1C_1}+H_{A_1,} \\\\ \\nonumber\nH_{A_0B_0C_1}+H_{B_0C_0C_1} & & \\geq H_{A_0B_0C_0C_1}+H_{B_0C_1}, \\\\ \\nonumber\nH_{A_1B_1C_0}+H_{A_1B_1C_1} & & \\geq H_{A_1B_1C_0C_1} +H_{A_1B_1}, \\\\ \\nonumber\nH_{A_0A_1C_1}+H_{A_1C_0C_1} & & \\geq H_{A_0A_1C_0C_1}+H_{A_1C_1}, \\\\ \\nonumber\nH_{A_0B_0B_1C_0}+H_{A_0B_0C_0C_1} & & \\geq  H_{A_0B_0B_1C_0C_1}+H_{A_0B_0C_0}, \\\\ \\nonumber\nH_{A_1B_0C_0C_1}+H_{A_1B_1C_0C_1} & & \\geq H_{A_1B_0B_1C_0C_1} +H_{A_1C_0C_1}, \\\\ \\nonumber\nH_{A_0A_1B_0B_1C_0}+H_{A_0B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0C_1}+H_{A_0B_0B_1C_0}, \\\\ \\nonumber\nH_{A_0A_1B_0C_0C_1}+H_{A_1B_0B_1C_0C_1} & & \\geq H_{A_0A_1B_0B_1C_0C_1}+H_{A_1B_0C_0C_1}. \\\\ \\nonumber\n\\end{eqnarray}\nand use the bilocality constraint $H_{A_0,A_1}+H_{C_0,C_1}=H_{A_0A_1C_0C_1}$.\n\n\n\\begin{table*}\n\\label{tab_IC}\n  \\begin{tabular}{|c|l|l|l|l|l|l|l|}\n    \\hline\nExtremal ray & $H(X_0)$ & $H(X_1)$ & $H(Y_0)$ & $H(Y_1)$ & $H(X_0,Y_0)$ & $H(X_1,Y_1)$ & $H(M)$  \\\\ \\hline\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\ \\hline\n2 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\\\ \\hline\n3 & 0 & 0 & 1 & 0 & 1 & 0 & 0 \\\\ \\hline\n4 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\\\ \\hline\n5 & 1 & 0 & 0 & 0 & 1 & 0 & 0 \\\\ \\hline\n6 & 0 & 1 & 0 & 1 & 0 & 1 & 1 \\\\ \\hline\n7 & 1 & 0 & 1 & 0 & 1 & 0 & 1 \\\\ \\hline\n8 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\ \\hline\n\\end{tabular}\n\\caption{All the extremal rays defining the entropic NS cone of the information causality scenario.}\n\\end{table*}\n\n\\subsubsection{Information Causality}\nInformation causality (IC) \\cite{Pawlowski2009} has been introduced as a principle to\nexplain the degree of nonlocality of quantum mechanics. It basically states that the amount\nof information a given part, Bo,b can have over some bits in possession of another part,\n Alice, is limited by the amount of information communicated from Alice to Bob. Information\ncausality is respected by quantum correlations, however, as shown in \\cite{Pawlowski2009}\nany nonlocal correlation stronger then maximum permitted by quantum mechanics, in sense of\nsurpassing the Tsirelson's bound \\cite{Cirel1980quantum} for the CHSH inequality, will\nviolate it.\n\nIC can be understood as a game between Alice and Bob: Alice receives two independent random bits $X_0$ and $X_1$ and the aim of Bob at each run of the game is to guess the value of one of them, having as resources some pre-shared correlations with Alice and a certain amount of communication sent by her. Which of the two bits he should guess is decided by a random variable $S$. In a classical description we have the variables $X_0,X_1$ representing the input bits of Alice; the variables $Y_0,Y_1$ standing for the guesses of Bob ($Y_s$ is the guess of bit $X_s$ given that $S=s$); $M$ stands for the message sent from Alice to Bob and $\\Lambda$ corresponds to the pre-shared correlations between them.\n\nThe (classical) entropic description of IC is equivalent to the existence of a joint entropy $H(X_0,X_1,B_0,B_1,M,\\Lambda)$ fulfilling the following causal constraints imposed by the rules of the game: $I(X_0:X_1)=0$, $I(X_0,X_1:\\Lambda)=0$ and $I(X_0,X_1:B_0,B_1 \\vert M, \\Lambda)=0$. The first constraint encodes the fact that both bits are uncorrelated and thus have null mutual information (though this is not strictly necessary \\cite{Safi2011,Chaves2015a}). The second constraint encodes the fact that the bits received by Alice are independent of the pre-shared correlation with Bob. Finally, the third constraint encodes the fact that conditioned on the message sent by Alice and on the pre-shared correlations, the guesses of Bob should becomes completely uncorrelated with the input bits. A similar description can be given for the case where the pre-shared correlations arise from an entangled state ${\\varrho}$ rather than a classical variable $\\Lambda$ \\cite{Chaves2015a}.\n\n\nProceeding with the FM elimination we obtain the description of the marginal entropic cone characterizing the information causality game. To that aim, first one needs to define the marginal scenario of interest. Here, similarly to what has been done in \\cite{Pawlowski2009}, we will focus on the marginal scenario $\\mathcal{M}_{\\textrm{IC}}=\\left\\{ \\left\\{ X_0,Y_0 \\right\\},\\left\\{ X_1,Y_1 \\right\\},\\left\\{ M \\right\\}  \\right\\}$. Notice, however, that more general marginal scenarios can be defined \\cite{Chaves2015a}. It follows that the only non-trivial entropic inequality describing the IC game (for classical and quantum pre-shared correlations) is given by:\n\n", "index": 35, "text": "\\begin{equation}\n\\label{IC_ineq_app}\nI(X_0:Y_0)+I(X_1:Y_1) \\leq H(M).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"I(X_{0}:Y_{0})+I(X_{1}:Y_{1})\\leq H(M).\" display=\"block\"><mrow><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mn>0</mn></msub><mo>:</mo><msub><mi>Y</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>:</mo><msub><mi>Y</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}]