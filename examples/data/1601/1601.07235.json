[{"file": "1601.07235.tex", "nexttext": "\nwith the variance ranging from 0 (all respondents in the same category,\nfor example \\emph{Passives}), to a maximum of 1 (data equally split\nbetween \\emph{Promoters} and \\emph{Detractors}). It's worth noting\nthat these two extreme examples would both produce an $NPS$ of 0;\nunlike a binomial proportion, we cannot derive an $NPS$ from its\nvariance.\n\n\n\\section{Interval estimation}\n\n\n\\subsection{Wald Intervals, and Variations}\n\n\n\\subsubsection{The Wald Interval}\n\nA commonly taught and used method for sample proportions is the Wald\nconfidence interval (first proposed by Laplace, \\citeyear{de1820theorie}),\n$p\\pm z_{\\alpha/2}\\sqrt{p(1-p)/n}$, where $z_{\\alpha/2}$ denotes\nthe $1-(\\alpha/2)$ quantile of a standard normal distribution. It\nis straightforward to use the variance calculation (1) to produce\na Wald interval for the $NPS$:\n\n\n", "itemtype": "equation", "pos": 5913, "prevtext": "\n\n\\title{Interval Estimation for the `Net Promoter Score'}\n\n\n\\author{Brendan Rocks}\n\n\\maketitle\n\n\nSatmetrix Systems Inc., 3 Twin Dolphin Dr, Redwood\nCity, CA 94065 \\\\ e-mail: \\texttt{rocks.brendan@gmail.com}\n\\\\\n\\begin{abstract}\nThe Net Promoter Score (NPS) is a novel summary statistic used by\nthousands of companies as a key performance indicator of customer\nloyalty. While adoption of the statistic has grown rapidly over the\nlast decade, there has been little published on its statistical properties.\nCommon interval estimation techniques are adapted for use with the\nNPS, and performance assessed on the largest available database of\ncompanies' Net Promoter Scores. Variations on the Adjusted Wald, and\nan iterative Score test are found to have superior performance.\n\nKey words: confidence interval, Net Promoter, net score, NPS, significance\ntest\n\\end{abstract}\n\n\\section{The Net Promoter Score}\n\n\n\\subsection{Usage and Calculation}\n\nThe Net Promoter Score (NPS) is a summary statistic proposed by Reichheld\n\\citeyearpar{reichheld2003one,reichheld2006ultimate}, commonly used\nin commercial survey research to estimate the propensity of a business'\ncustomers to exhibit desirable behaviors, such as recommending friends,\nor spending a greater share of their income (Owen \\& Brooks, \\citeyear{owen2008answering};\n\\citealp{reichheld2011ultimate}). General practice is to ask the\nquestion \\emph{``How likely is it that you would recommend Company\nX to a friend or colleague?}'', with responses captured on a 0 to\n10 Likert scale. The NPS statistic is then calculated as follows;\nrespondents who rate 0 to 6 are classified as \\emph{Detractors}, 7\nor 8 as \\emph{Passives}, and 9 or 10 as \\emph{Promoters}. The NPS\nis calculated as the percentage of \\emph{Promoters}, less the percentage\nof \\emph{Detractors}, producing a score between -1 and 1. \\footnote{Net Promoter Scores are often multiplied by 100 (and occasionally\naccompanied by a percentage sign) for presentational purposes, although\nthis is omitted in this paper.}\n\nWe'll consider the number of respondents in each category a vector\nof length three, $x=[x_{det},\\:x_{pas,\\:}x_{pro}]$, with their relative\nproportions the corresponding probability vector $p=[p_{det},\\:p_{pas,\\:}p_{pro}]$,\nthe score itself being $NPS=p_{pro}-p_{det}$. The score may also\nbe reached by recoding \\emph{Promoter, Passive} and \\emph{Detractor}\nresponses as 1, 0, and -1, respectively, and taking the arithmetic\nmean.\n\nThis paper focuses on estimating intervals for the \\emph{$NPS$} statistic\nitself, as opposed to other measures which might describe the trinomial\ndistribution used to derive it. This is an important distinction;\na single $NPS$ can come from many (potentially rather different)\ndistributions.\n\n\n\\subsection{Critiques}\n\nA variety of metrics thought to predict customer behaviors exist within\nmarketing, and Riechheld's (\\citeyear{reichheld2003one}) claim that\nthe $NPS$ is superior has been challenged by several authors. In\nparticular, on the grounds that $NPS$ and alternative metrics have\nsimilar relationships to business-outcomes (\\citealt{van2013satisfaction,pingitore2007,keiningham2007a});\nthat an 11-point Likert scale may not be the optimal measurement instrument\n(\\citealt{schneider2008}); and that multiple measures combined and\nweighted via a regression model provide better predictions (\\citealt{keiningham2007b}).\nCompared to taking the mean on the original scale, the novel calculation\nhas been argued to both lose information (\\citealt{eskildsen2011}),\nand improve performance in predicting customer retention (\\citealt{de2015predictiv}).\nDespite these critiques, the Net Promoter Score is used to estimate\ncustomer sentiment by thousands of companies (\\citealt{owen2008answering,reichheld2011ultimate}).\nThis paper investigates its statistical properties.\n\n\n\\subsection{Properties}\n\nMany possible trinomial probability mass distributions (TPMDs) can\nresult in an $NPS$ of 0, half that number for an $NPS$ of $\\frac{1}{2}$,\nand only 1 for an $NPS$ of 1 (or -1). For any $n$, there are $2n+1$\npossible Net Promoter scores, the distribution having a peak 1 score\nwide at 0, with $n$ `steps' of two scores width either side for even\n$n$, and a peak of 3 scores wide, with $n-1$ steps for odd numbered\n$n.$\n\nUnlike the {[}0,1{]} uniform distribution of possible values of a\nbinomial proportion, possible values of the $NPS$ from a simplex\nlattice follow a triangular distribution ($a=1,b=-1,c=0$) as $n$\napproaches infinity.\n\nThis is an important distinction with regard to assessing interval\nmethods; performance averaged uniformly across possible TPMDs is not\nperformance averaged uniformly over Net Promoter Scores (Figure \\ref{fig:properties}).\n\nTesting a method for $NPS$ with equal weight across TPMDs, means\nthat (for example) performance at $NPS=0$ will have twice the weight\nof performance at $NPS=\\frac{1}{2}$, as for arbitrary trinomial distributions,\nan $NPS$ of $0$ is twice as likely to occur.\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{nps_properties-1.pdf}\n\n\n\n\\caption{Illustrations of Net Promoter Scores drawn from simplex lattices.\nThe left panel illustrates the discrete distribution of possible Net\nPromoter Scores for $n=10$. The center panel shows the smooth triangular\ndistribution when $n$ approaches infinity - the binomial equivalent\nwould be uniform. The rightmost panel shows the range of possible\nNet Promoter Scores and variances for infinite $n$, the possible\ndistributions being uniformly distributed within the \\emph{inverted\nshield} shape.\\label{fig:properties}}\n\\end{figure}\n\n\n\n\\subsection{Variance of the NPS}\n\nMethods for the variance of the difference of two proportions can\nbe applied to the $NPS$ (e.g. \\citealp{gold1963tests}; \\citealp{goodman1965simultaneous})\\footnote{More recently, an alternative, but equivalent derivation, for the\nvariance of the $NPS$ was published online by \\citet{whuber}.}\n", "index": 1, "text": "\n\\[\n\\sigma_{NPS}=p_{pro}+p_{det}-(p_{pro}-p_{det})^{2},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\sigma_{NPS}=p_{pro}+p_{det}-(p_{pro}-p_{det})^{2},\" display=\"block\"><mrow><mrow><msub><mi>\u03c3</mi><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mo>=</mo><mrow><mrow><msub><mi>p</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></msub><mo>+</mo><msub><mi>p</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>p</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></msub><mo>-</mo><msub><mi>p</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\n\n\n\n\\subsubsection{The Goodman method}\n\n\\citet{goodman1964simultaneous}, proposed a method for estimating\nnet differences between multinomial parameters. It functions in a\nsimilar form to the Wald interval, with the sample $NPS$ forming\nthe central point of the interval\n", "itemtype": "equation", "pos": 6808, "prevtext": "\nwith the variance ranging from 0 (all respondents in the same category,\nfor example \\emph{Passives}), to a maximum of 1 (data equally split\nbetween \\emph{Promoters} and \\emph{Detractors}). It's worth noting\nthat these two extreme examples would both produce an $NPS$ of 0;\nunlike a binomial proportion, we cannot derive an $NPS$ from its\nvariance.\n\n\n\\section{Interval estimation}\n\n\n\\subsection{Wald Intervals, and Variations}\n\n\n\\subsubsection{The Wald Interval}\n\nA commonly taught and used method for sample proportions is the Wald\nconfidence interval (first proposed by Laplace, \\citeyear{de1820theorie}),\n$p\\pm z_{\\alpha/2}\\sqrt{p(1-p)/n}$, where $z_{\\alpha/2}$ denotes\nthe $1-(\\alpha/2)$ quantile of a standard normal distribution. It\nis straightforward to use the variance calculation (1) to produce\na Wald interval for the $NPS$:\n\n\n", "index": 3, "text": "\\begin{equation}\nNPS\\pm z_{\\alpha/2}\\sqrt{\\frac{\\sigma_{NPS}}{n}}.\\label{eq:wald}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"NPS\\pm z_{\\alpha/2}\\sqrt{\\frac{\\sigma_{NPS}}{n}}.\" display=\"block\"><mrow><mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo>\u00b1</mo><mrow><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><msqrt><mfrac><msub><mi>\u03c3</mi><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mi>n</mi></mfrac></msqrt></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\n where $\\chi$ is the upper $(a/K)\\ensuremath{\\times}100th$ percentile\nof the $\\chi^{2}$ distribution with one degree of freedom.\n\n\n\\subsubsection{The Adjusted Wald}\n\nThe `Adjusted Wald' test proposed by Agresti \\& Coull (\\citeyear{agresti1998approximate})\nin its original binomial form is to perform the Wald test, after the\nadjustment of adding $\\frac{z_{\\alpha/2}^{2}}{2}$ to the number of\nsuccesses, and $z_{\\alpha/2}^{2}$ to the number of trails. Similarly,\nAgresti \\& Min \\citeyearpar{agresti2005simple} proposed an Adjusted\nWald for matched pairs in $2\\times2$ contingency table designs.\n\nWe can adapt this to the $NPS$ by adding $\\frac{z_{\\alpha/2}^{2}}{3}$\nto the number of respondents in each category, so that $\\hat{x}=x+\\frac{z_{\\alpha/2}^{2}}{3}$,\nand $\\hat{n}=n+z_{\\alpha/2}^{2}$, making our adjusted estimate of\nthe TPMD $\\hat{p}=\\frac{\\hat{x}}{\\hat{n}}$, the new central estimate\n$\\widehat{NPS}=\\hat{{p}}_{pro}-\\hat{{p}}_{det}$, and new variance\n$\\hat{\\sigma}_{NPS}=\\hat{{p}}{}_{pro}+\\hat{{p}}_{det}-(\\hat{{p}}_{pro}-\\hat{{p}}_{det})^{2}$.\nWe then use these adjusted parameters to create intervals using the\nWald method in \\ref{eq:wald} above:\n\n", "itemtype": "equation", "pos": 7174, "prevtext": "\n\n\n\n\\subsubsection{The Goodman method}\n\n\\citet{goodman1964simultaneous}, proposed a method for estimating\nnet differences between multinomial parameters. It functions in a\nsimilar form to the Wald interval, with the sample $NPS$ forming\nthe central point of the interval\n", "index": 5, "text": "\n\\[\n\\pm\\sqrt{\\chi\\frac{\\sigma_{NPS}}{n}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\pm\\sqrt{\\chi\\frac{\\sigma_{NPS}}{n}}\" display=\"block\"><mrow><mo>\u00b1</mo><msqrt><mrow><mi>\u03c7</mi><mo>\u2062</mo><mfrac><msub><mi>\u03c3</mi><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mi>n</mi></mfrac></mrow></msqrt></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nThese adjustments shrink the estimated TPMD towards the uniform, the\nadditions to $\\hat{x}$ bringing $\\widehat{NPS}$ closer to 0, and\nthe estimated variance closer to $\\frac{2}{3}$.\n\nThe weights added to $x$ need not necessarily sum to $z_{\\alpha/2}^{2}$,\nor be equally distributed across the trinomial categories. Agresti\n\\& Coull \\citeyearpar{agresti1998approximate} proposed a total weight\nof 4 (as opposed to $z_{\\alpha/2}^{2}$). Agresti \\& Min's (2005)\nspecification for matched-pairs advocates adding the same weight to\neach of the four categories in a $2\\times2$ table, which when respecified\nfor a TPMD, can be considered adding twice the weight to $p_{pas}$\nthan is added to $p_{pro}$ and $p_{det}$. This does not affect the\ncentral estimate of the interval, but has the effect of reducing the\nestimated variance and interval width.\n\nBonett \\& Price \\citeyearpar{bonett2012adjusted} suggested another\nnovel adjustment for the Wald, again in the context of matched pairs\nand $2\\times2$ tables, which is to add the weight to just the cells\nsubject to the statistic's calculation - in our case, the weight split\nequally between the trinomial extremes of $p_{pro}$ and $p_{det}$.\n\n\n\\paragraph{Notation for Adjusted Wald Interval Estimates}\n\nThis paper uses the notation $AW(w,shape)$ to denote an Adjusted\nWald interval, where $w$ is the total weight added to $\\hat{x}$,\nand $shape$ can be extreme (E), triangular (T), or uniform (U); denoting\n$p_{pas}$ having no weight, twice the weight, or the same weight\nas the other categories, respectively. This results in the prior having\na variance of $1$ (for E) $\\frac{2}{3}$ (for U) or $\\frac{1}{2}$\n(for T). For example, an Adjusted Wald interval with one response\nadded to each trinomial category would be denoted $AW(3,U)$. This\npaper assesses Adjusted Wald 95\\% intervals where $w$ is equal to\n$2$, $3$, and $z_{\\alpha/2}^{2}$ ($\\approx3.84$), for all three\nshape types.\n\n\n\\subsection{Score Tests}\n\n\n\\subsubsection{The Score Test}\n\nThe score test, originally proposed by \\citet{wilson1927probable}\nhas the binomial formula\n\n\n", "itemtype": "equation", "pos": 8377, "prevtext": "\n where $\\chi$ is the upper $(a/K)\\ensuremath{\\times}100th$ percentile\nof the $\\chi^{2}$ distribution with one degree of freedom.\n\n\n\\subsubsection{The Adjusted Wald}\n\nThe `Adjusted Wald' test proposed by Agresti \\& Coull (\\citeyear{agresti1998approximate})\nin its original binomial form is to perform the Wald test, after the\nadjustment of adding $\\frac{z_{\\alpha/2}^{2}}{2}$ to the number of\nsuccesses, and $z_{\\alpha/2}^{2}$ to the number of trails. Similarly,\nAgresti \\& Min \\citeyearpar{agresti2005simple} proposed an Adjusted\nWald for matched pairs in $2\\times2$ contingency table designs.\n\nWe can adapt this to the $NPS$ by adding $\\frac{z_{\\alpha/2}^{2}}{3}$\nto the number of respondents in each category, so that $\\hat{x}=x+\\frac{z_{\\alpha/2}^{2}}{3}$,\nand $\\hat{n}=n+z_{\\alpha/2}^{2}$, making our adjusted estimate of\nthe TPMD $\\hat{p}=\\frac{\\hat{x}}{\\hat{n}}$, the new central estimate\n$\\widehat{NPS}=\\hat{{p}}_{pro}-\\hat{{p}}_{det}$, and new variance\n$\\hat{\\sigma}_{NPS}=\\hat{{p}}{}_{pro}+\\hat{{p}}_{det}-(\\hat{{p}}_{pro}-\\hat{{p}}_{det})^{2}$.\nWe then use these adjusted parameters to create intervals using the\nWald method in \\ref{eq:wald} above:\n\n", "index": 7, "text": "\n\\[\n\\widehat{NPS}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{NPS}}{\\hat{n}}.}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\widehat{NPS}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{NPS}}{\\hat{n}}.}\" display=\"block\"><mrow><mover accent=\"true\"><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo>^</mo></mover><mo>\u00b1</mo><mrow><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><msqrt><mrow><mfrac><msub><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mover accent=\"true\"><mi>n</mi><mo stretchy=\"false\">^</mo></mover></mfrac><mo>.</mo></mrow></msqrt></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nAs presented in Agresti \\& Coull's illuminating \\citeyear{agresti1998approximate}\npaper, the central point of the interval can be alternatively specified\nas a weighted average, $p(w_{1})+\\frac{1}{2}(w_{2})$, the two weights\nbeing $w_{1}=\\frac{n}{n+z^{2}}$ and $w_{2}=\\frac{z^{2}}{n+z^{2}}$\nrespectively. This weighted average shrinks $\\hat{p}$ towards $\\frac{1}{2}$,\nwith this effect diminishing as $n$ increases. Standard errors either\nside of this midpoint are $z_{\\alpha/2}\\sqrt{\\frac{p(1-p)w_{1}+\\frac{1}{4}w_{2}}{n+z^{2}}}$,\nproviding a weighted average between the sample variance, and the\nmaximum possible variance of $\\frac{1}{4}$.\n\nUsing the the weighted average principle, we can adapt this to the\n$NPS$, with the two weights shrinking the central estimate towards\n0 as opposed to $\\frac{1}{2}$, as follows:\n\n", "itemtype": "equation", "pos": 10535, "prevtext": "\nThese adjustments shrink the estimated TPMD towards the uniform, the\nadditions to $\\hat{x}$ bringing $\\widehat{NPS}$ closer to 0, and\nthe estimated variance closer to $\\frac{2}{3}$.\n\nThe weights added to $x$ need not necessarily sum to $z_{\\alpha/2}^{2}$,\nor be equally distributed across the trinomial categories. Agresti\n\\& Coull \\citeyearpar{agresti1998approximate} proposed a total weight\nof 4 (as opposed to $z_{\\alpha/2}^{2}$). Agresti \\& Min's (2005)\nspecification for matched-pairs advocates adding the same weight to\neach of the four categories in a $2\\times2$ table, which when respecified\nfor a TPMD, can be considered adding twice the weight to $p_{pas}$\nthan is added to $p_{pro}$ and $p_{det}$. This does not affect the\ncentral estimate of the interval, but has the effect of reducing the\nestimated variance and interval width.\n\nBonett \\& Price \\citeyearpar{bonett2012adjusted} suggested another\nnovel adjustment for the Wald, again in the context of matched pairs\nand $2\\times2$ tables, which is to add the weight to just the cells\nsubject to the statistic's calculation - in our case, the weight split\nequally between the trinomial extremes of $p_{pro}$ and $p_{det}$.\n\n\n\\paragraph{Notation for Adjusted Wald Interval Estimates}\n\nThis paper uses the notation $AW(w,shape)$ to denote an Adjusted\nWald interval, where $w$ is the total weight added to $\\hat{x}$,\nand $shape$ can be extreme (E), triangular (T), or uniform (U); denoting\n$p_{pas}$ having no weight, twice the weight, or the same weight\nas the other categories, respectively. This results in the prior having\na variance of $1$ (for E) $\\frac{2}{3}$ (for U) or $\\frac{1}{2}$\n(for T). For example, an Adjusted Wald interval with one response\nadded to each trinomial category would be denoted $AW(3,U)$. This\npaper assesses Adjusted Wald 95\\% intervals where $w$ is equal to\n$2$, $3$, and $z_{\\alpha/2}^{2}$ ($\\approx3.84$), for all three\nshape types.\n\n\n\\subsection{Score Tests}\n\n\n\\subsubsection{The Score Test}\n\nThe score test, originally proposed by \\citet{wilson1927probable}\nhas the binomial formula\n\n\n", "index": 9, "text": "\\begin{equation}\n\\left(p+\\frac{z_{\\alpha/2}^{2}}{2n}\\pm z_{\\alpha/2}\\sqrt{\\left[p(1-p)+z_{\\alpha/2}^{2}/4n\\right]/n}\\right)/(1+z_{\\alpha/2}^{2}/n).\\label{eq:wilson}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\left(p+\\frac{z_{\\alpha/2}^{2}}{2n}\\pm z_{\\alpha/2}\\sqrt{\\left[p(1-p)+z_{%&#10;\\alpha/2}^{2}/4n\\right]/n}\\right)/(1+z_{\\alpha/2}^{2}/n).\" display=\"block\"><mrow><mrow><mrow><mo>(</mo><mrow><mrow><mi>p</mi><mo>+</mo><mfrac><msubsup><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow><mn>2</mn></msubsup><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi></mrow></mfrac></mrow><mo>\u00b1</mo><mrow><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><msqrt><mrow><mrow><mo>[</mo><mrow><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>p</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msubsup><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo>/</mo><mn>4</mn></mrow><mo>\u2062</mo><mi>n</mi></mrow></mrow><mo>]</mo></mrow><mo>/</mo><mi>n</mi></mrow></msqrt></mrow></mrow><mo>)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo>/</mo><mi>n</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nThe formula for the intervals,\n\n", "itemtype": "equation", "pos": 11533, "prevtext": "\nAs presented in Agresti \\& Coull's illuminating \\citeyear{agresti1998approximate}\npaper, the central point of the interval can be alternatively specified\nas a weighted average, $p(w_{1})+\\frac{1}{2}(w_{2})$, the two weights\nbeing $w_{1}=\\frac{n}{n+z^{2}}$ and $w_{2}=\\frac{z^{2}}{n+z^{2}}$\nrespectively. This weighted average shrinks $\\hat{p}$ towards $\\frac{1}{2}$,\nwith this effect diminishing as $n$ increases. Standard errors either\nside of this midpoint are $z_{\\alpha/2}\\sqrt{\\frac{p(1-p)w_{1}+\\frac{1}{4}w_{2}}{n+z^{2}}}$,\nproviding a weighted average between the sample variance, and the\nmaximum possible variance of $\\frac{1}{4}$.\n\nUsing the the weighted average principle, we can adapt this to the\n$NPS$, with the two weights shrinking the central estimate towards\n0 as opposed to $\\frac{1}{2}$, as follows:\n\n", "index": 11, "text": "\n\\[\n\\widehat{NPS}=\\left(NPS+1\\right)w_{1}+w_{2}-1,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\widehat{NPS}=\\left(NPS+1\\right)w_{1}+w_{2}-1,\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo>^</mo></mover><mo>=</mo><mrow><mrow><mrow><mrow><mo>(</mo><mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>\u2062</mo><msub><mi>w</mi><mn>1</mn></msub></mrow><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><mo>-</mo><mn>1</mn></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\n is similar in form to the original Wilson score test, but with the\nweighted average drawing the variance towards the $NPS$ maximum of\n1. This prior variance can be altered by the addition of a multiplier\nto $w_{2}$; in this paper prior variances of $\\frac{2}{3}$ and $\\frac{1}{2}$\nare tested, to provide equivalence with the prior variances of the\nuniform and triangular Adjusted Wald tests.\n\n\n\\subsubsection{The Iterative Score Method}\n\nInverting the score test was first proposed for paired sample designs,\nand applications to $2\\times2$ tables by \\citet{tango1998equivalence}.\nThis test can be reinterpreted to cover the $NPS$ of a trinomial\ndistribution. Modifying Agresti \\& Min's \\citeyearpar{agresti2005simple}\npresentation, its interval would be the set of values $\\Delta$, satisfying\n\n", "itemtype": "equation", "pos": 11618, "prevtext": "\nThe formula for the intervals,\n\n", "index": 13, "text": "\\begin{equation}\n\\widehat{NPS}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\sigma_{NPS}w_{1}+w_{2}}{n+z^{2}}}\\label{eq:score_interval}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\widehat{NPS}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\sigma_{NPS}w_{1}+w_{2}}{n+z^{2}}}\" display=\"block\"><mrow><mover accent=\"true\"><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo>^</mo></mover><mo>\u00b1</mo><mrow><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><msqrt><mfrac><mrow><mrow><msub><mi>\u03c3</mi><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mo>\u2062</mo><msub><mi>w</mi><mn>1</mn></msub></mrow><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><mrow><mi>n</mi><mo>+</mo><msup><mi>z</mi><mn>2</mn></msup></mrow></mfrac></msqrt></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nwhere $\\tilde{p}_{i}(\\Delta)$ is the MLE of $p_{i}$, under the constraint\n$\\Delta=NPS$. This can be solved iteratively; for this paper, the\nimplementation was adapted from code for the \\citet{tango1998equivalence}\nmethod by \\citet{agresti2003tangocode}.\n\n\n\\subsubsection{The May-Johnson Score Method}\n\nMay \\& Johnson \\citeyearpar{may1997confidence} proposed a closed\nform version of Tango's method, again originally intended for $2\\times2$\ntables from matched pairs designs. It can be adapted to trinomial\ndata and the \\emph{$NPS$} as follows\n\n", "itemtype": "equation", "pos": 12545, "prevtext": "\n is similar in form to the original Wilson score test, but with the\nweighted average drawing the variance towards the $NPS$ maximum of\n1. This prior variance can be altered by the addition of a multiplier\nto $w_{2}$; in this paper prior variances of $\\frac{2}{3}$ and $\\frac{1}{2}$\nare tested, to provide equivalence with the prior variances of the\nuniform and triangular Adjusted Wald tests.\n\n\n\\subsubsection{The Iterative Score Method}\n\nInverting the score test was first proposed for paired sample designs,\nand applications to $2\\times2$ tables by \\citet{tango1998equivalence}.\nThis test can be reinterpreted to cover the $NPS$ of a trinomial\ndistribution. Modifying Agresti \\& Min's \\citeyearpar{agresti2005simple}\npresentation, its interval would be the set of values $\\Delta$, satisfying\n\n", "index": 15, "text": "\n\\[\n\\frac{|(NPS)-\\Delta|}{\\sqrt{\\frac{(\\tilde{p}_{pro}(\\Delta)+\\tilde{p}_{det}(\\Delta))-\\Delta^{2}}{n}}}<z_{\\alpha/2}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\frac{|(NPS)-\\Delta|}{\\sqrt{\\frac{(\\tilde{p}_{pro}(\\Delta)+\\tilde{p}_{det}(%&#10;\\Delta))-\\Delta^{2}}{n}}}&lt;z_{\\alpha/2}\" display=\"block\"><mrow><mfrac><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mi mathvariant=\"normal\">\u0394</mi></mrow><mo stretchy=\"false\">|</mo></mrow><msqrt><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mover accent=\"true\"><mi>p</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mover accent=\"true\"><mi>p</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><msup><mi mathvariant=\"normal\">\u0394</mi><mn>2</mn></msup></mrow><mi>n</mi></mfrac></msqrt></mfrac><mo>&lt;</mo><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nwhere $\\hat{n}=n+z_{\\alpha/2}^{2}$.\n\n\n\\subsection{Similarity Between Methods}\n\nThe Score Method, May-Joshnson Score Method, and Adjusted Wald tests\nwith a weight of $z_{\\alpha/2}^{2}$, all produce identical central\nestimates for the interval. Both the Goodman and Wald methods take\nthe sample $NPS$ as the central estimate.\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{observed_model-1.pdf}\n\n\n\n\\caption{The $NPS$ and variance of the 1,098 observed TPMDs from the Satmetrix\ndata set, illustrated with a scatter plot (upper left panel), and\ncontour plot (upper right panel) of the two-dimensional kernel density\nestimate. The area outside the range of possible distributions is\nshaded gray. Marginal density estimates from the same model for the\n$NPS$ (lower left panel), and variance (lower right panel) are also\nshown, compared to those from the samples from the simplex lattice.\nCompared to the range of possible TPMDs, those observed have higher\nmean Net Promoter Scores and variances, and are much more tightly\ngrouped.\\label{fig:obs-plots}}\n\\end{figure}\n\n\n\n\\section{Assessment of Coverage Probabilities}\n\n\n\\subsection{Methods}\n\nThe methods of Agresti \\& Coull \\citeyearpar{agresti1998approximate}\ninform the simulation based approach for coverage probability assessment.\nThe specified confidence level of a procedure is compared to the long\nrun average of times that a procedure's interval contains the `true'\npopulation parameter, when supplied data from a random sample of the\npopulation. For the this analysis, the nominal confidence level chosen\nis 95\\%. This means that the results indicate \\emph{average}, as opposed\nto \\emph{worst possible} performance; procedures where coverage probabilities\nare greater than the nominal confidence level will be seen as overly\nconservative, those with lower than nominal coverage probabilities\nwill be seen as overly liberal.\n\n\n\\subsubsection{Arbitrary Trinomial Distributions}\n\nTrinomial probability mass distributions were generated by randomly\nsampling $J=10,000$ points from a (3, 400) simplex lattice. Performance\nat each TPMD was assessed at 20 $n$ counts\\footnote{$n=$ 5 to 100 in intervals of 5. Additionally, performance at $n=$\n120 to 300 (in intervals of 20) was assessed for descriptive purposes,\nbut not not used in the final selection criteria.}; \\ensuremath{2\\times 10^{5}} trinomial distributions in total. Performance\nat each trinomial distribution was assessed with 10,000 simulations.\nThis is a sample of trinomial distributions from those which are \\emph{arbitrarily\npossible}.\n\n\n\\subsubsection{Observed Trinomial Distributions}\n\nWhile sampling from a simplex lattice gives a good indication of performance\nover\\emph{ possible} distributions, in psychometric practice, some\ndistributions are more likely than others. The Satmetrix US Consumer\nNet Promoter Study \\citep{satm} is the largest available database\nof companies' Net Promoter Scores. Aggregating at the interaction\nof year-of-response and company, 347,788 Likelihood to Recommend ratings\nfor 236 companies over 14 years yielded 1,098 trinomial Net Promoter\ndistributions (with at least 250 responses). The data illustrate that\nsamples from a simplex lattice are not an ideal model of human response\nbehaviors (Figure \\ref{fig:obs-plots}). The observed TPMDs have much\nmore narrowly distributed Net Promoter Scores (mean = .26, standard\ndeviation = .24) and variances (mean = .59, standard deviation = .12)\nthan the simplex lattice samples, and occupy a relatively small small\narea of the possible parameter space.\n\n\n\\paragraph{Performance more likely to be observed in practice}\n\nTo create statistics which reflect performance across values sampled\nfrom the simplex lattice, performance is averaged across the $J$\nTPMDs sampled from it. For statistics which might better reflect performance\n\\emph{in practice}, we can make this a weighted average, the weights\nreflecting how frequently such a TPMD has been observed. To create\nthese weights, a two-dimensional kernel density estimate was fit to\nthe $NPS$ and variance of the trinomial distributions observed in\nthe Satmetrix data-set \\footnote{Bivariate kernel density estimate fit using pilot bandwidth selection\n(Chac{\\'o}n \\& Duong, \\citeyear{chacon2010multivariate}), resulting\nin 151 evaluation points) via the \\texttt{R }package \\texttt{ks} \\citep{ks}. }, the weights being the density estimate of a given distribution (rescaled\nso that the sum of the weights across the $J$ samples is 1). This\npaper presents performance both with and without these observational\nweights applied.\n\n\n\\subsubsection{Desirable Performance Characteristics}\n\nIn addition to a test having an average coverage level close to 95\\%,\nthe following characteristics are desirable:\n\\begin{itemize}\n\\item Good performance across values for $n$, especially $\\leqslant100$\n\\item Low \\emph{variation} in performance across trinomial distributions.\nFor example, a test may have an \\emph{average} coverage probability\nof 95\\%, by returning extremely conservative results for certain distributions,\nand extremely liberal results for others\n\\item Good performance for both the observed and simplex distributions\n\\end{itemize}\nA convenient summary of these properties is the mean absolute error\n(MAE) of the test, defined at a particular $n$ value, as\n", "itemtype": "equation", "pos": 13209, "prevtext": "\nwhere $\\tilde{p}_{i}(\\Delta)$ is the MLE of $p_{i}$, under the constraint\n$\\Delta=NPS$. This can be solved iteratively; for this paper, the\nimplementation was adapted from code for the \\citet{tango1998equivalence}\nmethod by \\citet{agresti2003tangocode}.\n\n\n\\subsubsection{The May-Johnson Score Method}\n\nMay \\& Johnson \\citeyearpar{may1997confidence} proposed a closed\nform version of Tango's method, again originally intended for $2\\times2$\ntables from matched pairs designs. It can be adapted to trinomial\ndata and the \\emph{$NPS$} as follows\n\n", "index": 17, "text": "\n\\[\nNPS\\left(\\frac{n}{\\hat{n}}\\right)\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{n}(p_{pro}+p_{det})-n(p_{pro}-p_{det})^{2}}{\\hat{n}}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"NPS\\left(\\frac{n}{\\hat{n}}\\right)\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{n}(p_{pro}+p%&#10;_{det})-n(p_{pro}-p_{det})^{2}}{\\hat{n}}}\" display=\"block\"><mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mi>n</mi><mover accent=\"true\"><mi>n</mi><mo stretchy=\"false\">^</mo></mover></mfrac><mo>)</mo></mrow></mrow><mo>\u00b1</mo><mrow><msub><mi>z</mi><mrow><mi>\u03b1</mi><mo>/</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><msqrt><mfrac><mrow><mrow><mover accent=\"true\"><mi>n</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>p</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></msub><mo>+</mo><msub><mi>p</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>n</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>p</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></msub><mo>-</mo><msub><mi>p</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mover accent=\"true\"><mi>n</mi><mo stretchy=\"false\">^</mo></mover></mfrac></msqrt></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07235.tex", "nexttext": "\nwhere $C_{j}$ is the coverage probability of the test for the $j^{th}$\nTPMD sampled from the simplex lattice, and $w_{j}$ is the weight\nfor that distribution. The tests' MAE for $n\\leqslant100$ will be\nused as our ultimate criteria for recommendation. This paper considers\nperformance both with, and without ($w_{1,\\ldots,J}=\\frac{1}{J}$)\nobservational weights applied to the MAE.\n\n\\begin{table}\n\n\n\\includegraphics[width=6.5in]{covp-table-1.pdf}\n\n\n\n\\caption{A coverage probability heat map for the different interval estimation\nmethods varying with sample $n$ counts, for the observed (left panel)\nand simplex (right panel) distributions. Tests are ordered by average\ncoverage probability for the observed distribution, where $n\\leqslant100$.\nCoverage probabilities below $90\\%$ are filled solid black with white\ntext.\\label{tab:ff-cov-tab}}\n\\end{table}\n\n\n\n\\subsection{Results}\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{pool-plot-1.pdf}\n\n\n\n\\caption{A coverage probability heat map for the different interval estimation\nmethods, with varying Net Promoter Scores and $n$ counts. Rug plots\nabove and below each panel illustrate the observed distribution of\nNet Promoter Scores. Coverage probabilities below $90\\%$ are shaded\ngray.\\label{fig:ff-pool-plot}}\n\\end{figure}\n\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{shield-1.pdf}\n\n\n\n\\caption{Coverage probabilities for the $AW(3,T)$, Iterative Score, May-Johnson\nScore, and Wald methods, across the TPMD parameter space, for varying\n$n$. The mean $NPS$ and variance of the observed distribution is\nindicated on each small multiple with cross-hairs. Areas with coverage\nprobabilities below 90\\% are shaded dark gray. Note that for the $AW(3,T)$,\nthe area around the mean of the bivariate distribution is closest\nto its region of optimal performance, compared to the Iterative Score,\nwhere it is in a region of conservative bias.\\label{fig:shield}}\n\\end{figure}\nTable \\ref{tab:ff-cov-tab} shows the average coverage probabilities\nfor the tests at 95\\% intervals. The tests share the same general\ncharacteristic of performance closer to the nominal level with increasing\n$n$, the exception being the Goodman method. It produces intervals\nwhich are too small with low $n$, and to wide with large $n$, the\ntest passing through the nominal coverage level at $n$ of around\n20 for the simplex distribution.\n\nThe Wald test for $NPS$ fares better than its binomial equivalent\nin Agresti \\& Coull \\citeyearpar{agresti1998approximate}, though\nperformance is still overly liberal. Coverage improves with increasing\n$n$, though doesn't quite reach the nominal 95\\% level by $n=300$.\n\n\\begin{table}\n\n\n\\includegraphics[width=6.5in]{mae-table-1.pdf}\n\n\n\n\\caption{Mean Absolute Error (multiplied by 100 for presentational purposes)\nand rank, for interval estimation methods, for both the simplex and\nobserved distributions. Tests are ordered by descending total MAE\nfor the observed distribution, where $n\\leqslant100$. \\label{tab:rmse}}\n\\end{table}\n\n\nThe May-Johnson Score test has the best \\emph{average} coverage probability\nfor the observed distribution. However, this comes at the expense\nof \\emph{variation} in performance (illustrated in Figure \\ref{fig:ff-pool-plot}),\nwhich is rather high, the coverage probability falling to below 90\\%\nat $n=5$ on the simplex distribution, and being overly liberal at\nextreme and central $NPS$ values at low $n$.\n\n\n\\paragraph{Weighted Average Variations on the Score Test}\n\nFor the `weighted average' variations on the Wilson type score tests,\ndrawing the variance towards $\\frac{1}{2}$ and $\\frac{2}{3}$ produces\nan on-average improvement in coverage probability over the original\nspecification of a prior variance of 1 (Table  \\ref{tab:ff-cov-tab}).\nUnfortunately, this comes at the expense of greater variance in performance\nacross Net Promoter Scores at low $n$ (Figure \\ref{fig:ff-pool-plot}).\n\n\n\\paragraph{Variations on the Adjusted Wald}\n\nAll Adjusted Wald methods are superior to the Wald, with the $AW(3,T)$\nthe best of those tested, on both the observed and simplex distributions.\nFor the observed distribution, it has the lowest MAE for $n\\leqslant100$\nof any test, and the second lowest for the simplex (Table \\ref{tab:rmse}),\nvery little coverage below the nominal level (Figure \\ref{fig:ff-pool-plot}),\nand superb average coverage probabilities (Table \\ref{tab:ff-cov-tab}),\nfor both the observed and simplex distributions.\n\n\n\\paragraph{The Iterative Score}\n\nThe Iterative Score method also has excellent performance. Summing\nMAE for all $n$, it has the lowest total for the simplex distribution,\nand its performance is very rarely over-liberal, the test returning\ncoverage below 90\\% the least frequently of any considered (less than\n0.01\\% of simplex samples), and having the highest minimum coverage\nobserved in the simulations (83\\%). However, it has the disadvantage\nof being overly conservative at low n. Like the Adjusted Wald tests,\nit's more conservative at the extremes of $NPS$ for small $n$.\n\n\n\\paragraph{Performance with varying \\emph{n}}\n\nOur main performance statistic for recommending a test (MAE for $n\\leqslant100$)\ncontains an intentional bias, in that it favors tests which have better\nperformance at low $n$ values, where MAE tends to be higher, making\na greater contribution to the aggregate. The $AW(3,T)$ benefits from\nthis the most, having better relative performance for observed and\nsimplex distributions at $n$ below around 15 and 20, respectively.\n\nAn alternative statistic might be to rank our tests' performance at\neach value of $n$, and then select the method with the lowest average\nrank. For the simplex distribution, using this criteria makes little\ndifference, with the Iterative Score, followed by the $AW(3,T)$ having\nthe lowest average rank. However, for the observed distribution, the\n$AW(3,T)$ falls to eighth place, with the May-Johnson score coming\nout the best, followed by the $AW(z_{\\alpha/2}^{2},T)$.\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{ac-mae-1.pdf}\n\n\n\n\\caption{Mean Absolute Error with varying $n$, for the Iterative score, AW(3,\nT), and AW$(z_{\\alpha/2}^{2}$, T) tests.\\label{fig:ac-mae}}\n\\end{figure}\n\n\nOf course, $n$ counts are known at the time of interval construction;\nit is possible to select the best performing test at any of the intervals\nfor $n$ analyzed in this paper, or create a single `method' where\nthe underlying calculations change based on the total $n$. However,\ndoing so offers extremely modest performance improvements (reducing\nthe MAE by \\ensuremath{4.09\\times 10^{-4}} and \\ensuremath{5.38\\times 10^{-4}}\nfor the simplex and observed distributions respectively).\n\nThe difference between the MAEs of the tests decreases rapidly with\n$n$, meaning that there is very little difference in MAE between\nthe ranks after around $n=30$. Figure \\ref{fig:ac-mae} illustrates\nthis pattern, the $AW(3,T)$ having superior performance, when differences\nin performance are of the highest magnitude.\n\n\n\\paragraph{Observed vs. Simplex distributions}\n\nOur choice of two distributions provides us with two different sets\nof results to judge our tests by. It's clear from the observational\ndata (Figure \\ref{fig:obs-plots}) that performance in a relatively\nsmall region of parameter space is of much greater importance under\nthe conditions observed. Figure \\ref{fig:shield} illustrates the\noverlap of observational data and coverage probability in parameter\nspace, explaining the large increase in performance in the $AW(3,T)$\nand May-Johnson Score tests that are seen on the observed vs. simplex\ndistributions.\n\nThe observations have been selected to be representative of US Consumers\nusing the standard survey methodology, and thus perhaps the data generating\nmechanism from which practitioners are most likely to encounter the\n$NPS$. However, response behaviors are known to vary by both industry\nand country (Owen \\& Brooks, \\citeyear{owen2008answering}), and interval\nestimation methods may be applied to `net proportion' statistics outside\nof traditional data collection for a Net Promoter Score. Performance\non both distributions are presented here, and it is left to the reader\nto select the best test for their particular application.\n\n\n\\subsection{Additional Confidence Levels}\n\nWhile the 95\\% confidence interval is perhaps the most commonly used,\nan important consideration for a test is performance at a range of\ncommon confidence levels. The analysis above was replicated for a\nsubset of tests (the Iterative Score, the Score $\\left(\\frac{2}{3}\\right)$,\nthe $AW(3,T)$, and the $AW(z^{2},T)$), for 99\\%, 90\\% and 80\\% confidence\nintervals\\footnote{Tested at $n$ from 5 to 100 in intervals of 5.}.\nThe tests represent the best performing test of each type (closed-form\nscore, Adjusted Wald, and Iterative score) at 95\\% confidence, with\nthe addition of the $AW(z^{2},T)$, which varies weights based on\n$\\alpha$.\n\nResults are presented in Table \\ref{tab:mae-ci}. Averaged across\nconfidence levels and $n$ values, the test with the lowest $MAE$\nremains the $AW(3,T)$ for the observed distribution, and the Iterative\nScore for the simplex distribution. However, these averages are affected\nby the higher $MAE$ seen in lower confidence levels. Results vary,\nwith tests which were generally liberal at 95\\% performing better\nat lower confidence levels, and vice versa. Averaging $MAE$ across\n$n$, the best test for the 99\\% level on both distributions is the\nIterative Score, followed by the $AW(3,T)$. For 80\\% and 90\\% confidence\nlevels, the best performing test is the Score $\\left(\\frac{2}{3}\\right)$\nfor the observed distribution, and the $AW(z^{2},T)$ for the simplex.\n\n\\begin{table}\n\n\n\\includegraphics[width=6.5in]{mae-ci-tab-1.pdf}\n\n\n\n\\caption{Mean Absolute Error of estimation methods (multiplied by 100 for presentational\npurposes) and rank, for the simplex and observed distributions across\nconfidence levels. Tests are ordered by descending total MAE for the\nobserved distribution, where $n\\leqslant100$.\\label{tab:mae-ci}}\n\\end{table}\n\n\n\n\\section{Conclusion \\& Summary}\n\nThe Wald and Goodman tests perform poorly; their use should be avoided.\nAll Adjusted Wald variations considered provided substantial improvement,\nwith the best of those (weights of $3$ and $z_{\\alpha/2}^{2}$) outperforming\nnon-iterative Score methods.\n\nThe best performing Adjusted Wald is $AW(3,T)$ which can be used\nby adding $\\frac{3}{4}$ to the counts of both \\emph{Promoters} and\n\\emph{Detractors}, and $\\frac{3}{2}$ to the count of \\emph{Passives,}\nbefore construction of a Wald interval. The method has good performance\nacross the $n$ values and confidence levels examined, especially\nfor data likely to be observed in practice.\n\nThe Iterative Score method also has excellent performance, with the\nadvantage that it has very few regions of parameter space where coverage\ndrops below 95\\%, providing accurate coverage probabilities for almost\nany trinomial distribution. Its disadvantage is its greater computational\ncomplexity, and slight conservatism at low $n$ values ($<20$ for\na 95\\% interval) for trinomial distributions likely to be observed\nin practice.\n\n\n\\section{Acknowledgements}\n\nThe author would like to thank two anonymous reviewers and an assistant\neditor for comments which greatly helped improve this manuscript.\n\n\n\\section{Trademark Information}\n\nNet Promoter, Net Promoter Score, and NPS are trademarks of Satmetrix\nSystems, Inc., Bain \\& Company, Inc., and Fred Reichheld.\n\n\\bibliography{nps_interval_estimation.bbl}\n\n\n", "itemtype": "equation", "pos": 18635, "prevtext": "\nwhere $\\hat{n}=n+z_{\\alpha/2}^{2}$.\n\n\n\\subsection{Similarity Between Methods}\n\nThe Score Method, May-Joshnson Score Method, and Adjusted Wald tests\nwith a weight of $z_{\\alpha/2}^{2}$, all produce identical central\nestimates for the interval. Both the Goodman and Wald methods take\nthe sample $NPS$ as the central estimate.\n\n\\begin{figure}\n\n\n\\includegraphics[width=6.5in]{observed_model-1.pdf}\n\n\n\n\\caption{The $NPS$ and variance of the 1,098 observed TPMDs from the Satmetrix\ndata set, illustrated with a scatter plot (upper left panel), and\ncontour plot (upper right panel) of the two-dimensional kernel density\nestimate. The area outside the range of possible distributions is\nshaded gray. Marginal density estimates from the same model for the\n$NPS$ (lower left panel), and variance (lower right panel) are also\nshown, compared to those from the samples from the simplex lattice.\nCompared to the range of possible TPMDs, those observed have higher\nmean Net Promoter Scores and variances, and are much more tightly\ngrouped.\\label{fig:obs-plots}}\n\\end{figure}\n\n\n\n\\section{Assessment of Coverage Probabilities}\n\n\n\\subsection{Methods}\n\nThe methods of Agresti \\& Coull \\citeyearpar{agresti1998approximate}\ninform the simulation based approach for coverage probability assessment.\nThe specified confidence level of a procedure is compared to the long\nrun average of times that a procedure's interval contains the `true'\npopulation parameter, when supplied data from a random sample of the\npopulation. For the this analysis, the nominal confidence level chosen\nis 95\\%. This means that the results indicate \\emph{average}, as opposed\nto \\emph{worst possible} performance; procedures where coverage probabilities\nare greater than the nominal confidence level will be seen as overly\nconservative, those with lower than nominal coverage probabilities\nwill be seen as overly liberal.\n\n\n\\subsubsection{Arbitrary Trinomial Distributions}\n\nTrinomial probability mass distributions were generated by randomly\nsampling $J=10,000$ points from a (3, 400) simplex lattice. Performance\nat each TPMD was assessed at 20 $n$ counts\\footnote{$n=$ 5 to 100 in intervals of 5. Additionally, performance at $n=$\n120 to 300 (in intervals of 20) was assessed for descriptive purposes,\nbut not not used in the final selection criteria.}; \\ensuremath{2\\times 10^{5}} trinomial distributions in total. Performance\nat each trinomial distribution was assessed with 10,000 simulations.\nThis is a sample of trinomial distributions from those which are \\emph{arbitrarily\npossible}.\n\n\n\\subsubsection{Observed Trinomial Distributions}\n\nWhile sampling from a simplex lattice gives a good indication of performance\nover\\emph{ possible} distributions, in psychometric practice, some\ndistributions are more likely than others. The Satmetrix US Consumer\nNet Promoter Study \\citep{satm} is the largest available database\nof companies' Net Promoter Scores. Aggregating at the interaction\nof year-of-response and company, 347,788 Likelihood to Recommend ratings\nfor 236 companies over 14 years yielded 1,098 trinomial Net Promoter\ndistributions (with at least 250 responses). The data illustrate that\nsamples from a simplex lattice are not an ideal model of human response\nbehaviors (Figure \\ref{fig:obs-plots}). The observed TPMDs have much\nmore narrowly distributed Net Promoter Scores (mean = .26, standard\ndeviation = .24) and variances (mean = .59, standard deviation = .12)\nthan the simplex lattice samples, and occupy a relatively small small\narea of the possible parameter space.\n\n\n\\paragraph{Performance more likely to be observed in practice}\n\nTo create statistics which reflect performance across values sampled\nfrom the simplex lattice, performance is averaged across the $J$\nTPMDs sampled from it. For statistics which might better reflect performance\n\\emph{in practice}, we can make this a weighted average, the weights\nreflecting how frequently such a TPMD has been observed. To create\nthese weights, a two-dimensional kernel density estimate was fit to\nthe $NPS$ and variance of the trinomial distributions observed in\nthe Satmetrix data-set \\footnote{Bivariate kernel density estimate fit using pilot bandwidth selection\n(Chac{\\'o}n \\& Duong, \\citeyear{chacon2010multivariate}), resulting\nin 151 evaluation points) via the \\texttt{R }package \\texttt{ks} \\citep{ks}. }, the weights being the density estimate of a given distribution (rescaled\nso that the sum of the weights across the $J$ samples is 1). This\npaper presents performance both with and without these observational\nweights applied.\n\n\n\\subsubsection{Desirable Performance Characteristics}\n\nIn addition to a test having an average coverage level close to 95\\%,\nthe following characteristics are desirable:\n\\begin{itemize}\n\\item Good performance across values for $n$, especially $\\leqslant100$\n\\item Low \\emph{variation} in performance across trinomial distributions.\nFor example, a test may have an \\emph{average} coverage probability\nof 95\\%, by returning extremely conservative results for certain distributions,\nand extremely liberal results for others\n\\item Good performance for both the observed and simplex distributions\n\\end{itemize}\nA convenient summary of these properties is the mean absolute error\n(MAE) of the test, defined at a particular $n$ value, as\n", "index": 19, "text": "\n\\[\nMAE=\\frac{\\sum(C_{j}-0.95)w_{j}}{\\sum w_{j}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"MAE=\\frac{\\sum(C_{j}-0.95)w_{j}}{\\sum w_{j}}\" display=\"block\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>A</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>=</mo><mfrac><mrow><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>C</mi><mi>j</mi></msub><mo>-</mo><mn>0.95</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>w</mi><mi>j</mi></msub></mrow></mrow><mrow><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><msub><mi>w</mi><mi>j</mi></msub></mrow></mfrac></mrow></math>", "type": "latex"}]