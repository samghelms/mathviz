[{"file": "1601.06750.tex", "nexttext": "\n\\end{lemma}\n\\begin{proof}\n\nIf $p$ and $q$ denote the true and approximate posterior joint distributions of the parameters respectively, we know that,\n$\\ln p(\\mathcal{D}) =  \\mathcal{L}(q)+ KL(q \\mid\\mid p)$\n, where, $\n\\mathcal{L}(q)= \\int q(\\Theta) \\ln \\left\\lbrace \\frac{p(\\mathcal{D}, \\Theta)}{q(\\Theta)} \\right\\rbrace d\\Theta\n$ and $KL(q||p) = - \\int q(\\Theta) \\ln \\left[ \\frac{p(\\Theta \\mid \\mathcal{D})W}{q(\\Theta)}\\right] d\\Theta\n$ is the KL divergence between the distributions $q$ and $p$. \n\n\nBy the mean field assumption, the joint distribution $q(\\bold{w}, \\beta_1, \\cdots, \\beta_m)$\nfactorizes as follows, $ q(\\bold{w}, \\beta_1, \\cdots, \\beta_m) $ $= q(\\bold{w})\\prod_{j=1}^{m} q(\\beta_j)$.\nFor simplicity we denote by $q_{\\bold{w}}$ the distribution $q(\\bold{w})$ and by $q_{\\bold{\\beta_j}}$ the distribution\n $q(\\beta_j)$.\n\n", "itemtype": "equation", "pos": 15992, "prevtext": "\n\n\n\n\n\n\n\\title{A Robust UCB Scheme for Active Learning in Regression from Strategic Crowds}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\author{ Divya Padmanabhan \\inst{1} \\and Satyanath Bhat\\inst{1} \\and Dinesh Garg\\inst{2}\n \\and Shirish Shevade\\inst{1} \\and Y. Narahari\\inst{1}}\n\n\\institute{Indian Institute of Science, Bangalore,\\\\\n\\and\nIBM India Research Labs\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\\begin{abstract}\nWe study the problem of training an accurate linear regression model by procuring labels from multiple noisy crowd annotators, under a budget constraint. We propose a Bayesian model  for linear regression in crowdsourcing and use variational inference for parameter estimation. To minimize the number of labels crowdsourced from the annotators, we adopt an active learning approach. In this specific context, we prove the equivalence of well-studied criteria of active learning like entropy minimization and expected error reduction. Interestingly, we observe that we can decouple the problems of identifying an optimal unlabeled instance and identifying an annotator to label it. We observe a useful connection between the multi-armed bandit framework and the annotator selection in active learning. Due to the nature of the distribution of the rewards on the arms, we use the Robust Upper Confidence Bound (UCB) scheme with truncated empirical mean estimator to solve the annotator selection problem. This yields provable guarantees on the regret. We further apply our model to the scenario where annotators are strategic and design suitable incentives to induce them to put in their best efforts.\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Introduction}\n\nCrowdsourcing platforms such as Amazon Mechanical Turk are becoming popular avenues for getting large scale human intelligence tasks executed at a much lower cost. In particular, they have been widely used\nto procure labels to train learning models. \nThese platforms are characterized by a large pool of diverse yet inexpensive annotators.\nTo leverage these platforms for learning tasks, the following issues need to be addressed:\n(1) A learning model that encompasses parameter estimation and annotator quality estimation. \n(2) Identifying the best yet minimal set of instances from the pool of unlabeled data.\n(3) Determining an optimal subset of annotators to label the instances.\n(4) Providing suitable incentives to elicit best efforts from the chosen annotators under a budget constraint. \nWe provide an end to end solution to address the above issues for a regression task.\\par  \nIdentifying the best yet minimal set of instances to be labeled is important to minimize the generalization error, as the learner only has limited budget.\nThis involves selection of those unlabeled instances, the labels of which when fed to the learner, yield  maximum performance enhancement of the \nunderlying model. The question of choosing an optimal set of unlabeled examples occupies center\nstage in the realm of active learning. \nPast work on active learning in crowdsourcing apply to classification ~\\cite{rodrigues2014,  RaykarAISTATS14} and most of these do not directly apply to regression where the space of labels is unbounded. For instance, the Markov Decision Processes (MDP) based method \\cite{RaykarAISTATS14} \nrelies on label space and thereby the state space being finite, which is not the case in regression.\\par\nSimilar to the instance selection problem, the annotator choice to label an instance also has a bearing on the accuracy of the learnt model. Optimal annotator selection, in the context of classification, has been addressed using multi-armed bandit (MAB) algorithms \\cite{AbrahamAKS13}.\nHere the annotators are considered as the arms and their qualities as the stochastic rewards. In classification, the quality of the annotators is\nmodeled as a \nBernoulli random variable, thereby making it suitable for application of algorithms such as UCB1 \\cite{UCBAuer2002, Bubeck2012a}. However for regression tasks, the labels provided by the annotators\nare naturally modeled to have Gaussian noise, the variance of which is a measure of the quality of the annotator. This \nin turn is a function of the effort put in. Therefore, optimal annotator set selection problem involves identifying annotators with low variance.\nThough existing work  has adopted MAB algorithms for estimating variance \\cite{Neufeld14} and several other applications \\cite{Sen2015}, there is a research gap in its applicability to active learning and regression tasks\nand in particular where heavy tailed distributions arise as a result of squaring the Gaussian noise. To bridge this gap, we invoke ideas from \nRobust UCB \\cite{Bubeck2012b} and set up  theoretical guarantees for annotator selection in active learning. \n\nAnother non-trivial challenge emerges when we are required to account for the  strategic behavior of the human agents.\nAn agent, in the absence of suitable incentives, may not find it beneficial to put in efforts while labeling the data.\n\n\nTo induce best efforts from agents, the learner could appropriately incentivize  \nthem. In the field of mechanism design, several incentive schemes exist \\cite{Dayama2015, TranThanh2014}. To the best of our knowledge, \nsuch schemes have not been explored\nin the context of active learning for regression. \n\\\\\\\\\n\\textbf{Contributions}:\nThe key contributions of this paper are as follows.\\\\\n\n\n(1)\\textbf{Bayesian model for Regression}: In Section \\ref{sec:bayesian-lr}, we set up a novel   Bayesian model for regression using labels from multiple annotators with varying noise levels, which makes the problem  challenging. \nWe use variational inference for parameter estimation\nto overcome intractability issues.\\\\ \n\n(2)\\textbf{Active learning for crowd regression and decoupling instance selection and annotator selection}: In Section \\ref{sec:criteria-al}, we focus on various active learning criteria as applicable to the proposed regression model.  \n\nInterestingly, in our setting, we show that the  criteria of {\\em minimizing estimator error} and {\\em minimizing estimator's entropy} \nare equivalent.\n\n\nThese criteria also remarkably enable us to  decouple the problems of\ninstance selection and annotator selection. \\\\\n(3)\\textbf{Annotator selection with multi-armed bandits}:\n In Section \\ref{sec:al-annotator}, we describe the problem of selecting an\nannotator having least variance. We establish an interesting connection of this problem to\nthe multi-armed bandit problem. In our formulation, we\nwork with the square of the label noise to cast the problem\ninto a variance minimization framework; the square of the\nnoise follows a sub-exponential distribution. We show that\nstandard UCB strategies based on $\\psi$-UCB \\cite{Bubeck2012a} are not applicable\nand we propose the use of robust UCB \\cite{Bubeck2012b} with truncated empirical mean. We show that the logarithmic regret bound of robust UCB is\npreserved in this setting as well. Moreover the number of samples discarded is also logarithmic.\\\\\n(4)\\textbf{Handling strategic agents}: In Section \\ref{sec:payment_strategic}, we consider the case of strategic annotators where the learner needs to induce them to put in their best efforts. For\nthis, we propose the notion of `\\emph{quality compatibility}' and introduce a payment scheme that induces agents to put in their\nbest efforts and is also individually rational. \\\\\n(5)\\textbf{Experimental validation}: We describe our experimental findings in Section \\ref{sec:experiments}. We compare the RMSE\nand regret of our proposed models with state-of-the-art benchmarks on several real world datasets. Our experiments demonstrate a superior performance.\n\\section{Related Work}\nA rich body of literature exists in the field of active learning for statistical models where labels are provided by a single source\n\\cite{Roeder12,Cohn1996,Burbidge2007,CaiICDM2013}. Popular techniques include minimizing the variance or uncertainty of the learner, \nquery by committee schemes \\cite{Seung1992}\nand expected gradient length \\cite{SettlesNIPS2007} to name a few.\nIn the literature on Optimal Experimental Design in Statistics,\nthe selection of most informative data instances is captured\nby concepts such as A-optimality, D-optimality, etc. \\cite{FedorovOED,varunThesis}. The idea is to construct confidence regions for the learner \nand bound these regions. \nA survey on active learning approaches for  various problems is presented in\n \\cite{Settles10activelearning}.\n\\par The works that have looked into active learning for  regression are applicable only  for a single noisy source, and not to a  crowd. In crowdsourcing,\nseveral learning models for regression have been proposed, for instance, \\cite{ Raykar2012JMLR, Ristovski2010} obtain the maximum likelihood estimate \n(MLE) and maximum-a-posteriori (MAP) estimate respectively.\n\\cite{groot} proposes a scheme to aggregate information from multiple annotators for regression  \nusing Gaussian Processes. \\cite{BiUAI2014, Raykar2009} develop models for classification using crowds. However, these do not employ techniques from active learning. Also, they do not obtain a posterior distribution \nover the parameters,\nand hence do not perform probabilistic inference.\nOf late, there have been a few crowdsourcing classification models employing the active learning paradigm \\cite{rodrigues2014, Zhao13, WauthierNIPS2011,RaykarAISTATS14,Dekel2012}. \nThese include uncertainty-based methods and MDPs.\nTo the best of our knowledge, active learning for regression using the crowds has not been looked at explicitly.\n\\par  When an annotator is requested to label an instance, and the annotator, being strategic, does not put\nin the best effort, the learning algorithm could seriously underperform. So we must incentivize the annotator to\ninduce the best effort. \nSuch studies are not reported in the current literature.\n~\\cite{papadimitriou, Dekel2010759} propose payment schemes for linear regression  \nfor crowds.  Both  ~\\cite{papadimitriou, Dekel2010759} make the assumption that an instance is provided only to a single annotator\nand also do not look at the active learning paradigm.\nThe idea in our work is to design incentives for active learning in the context of crowdsourced regression which would\ninduce the annotators to put in their best efforts.\n\nIn the next section, we explain our model for regression using the crowd, assuming non-strategic annotators.\n\\section{Bayesian Linear Regression from a Non-strategic Crowd}\n\\label{sec:bayesian-lr}\nGiven a data instance $\\textbf{x}\\in {\\mathbb{R}}^d$, the linear regression model aims at predicting its \nlabel  \n$y$ such that $y = \\textbf{w}^\\top \\textbf{x}$. Instead of  \n$\\textbf{x}$, non-linear functions $\\Phi(.)$ of $\\textbf{x}$, \ncan be used. To avoid notational clutter, we work with $\\textbf{x}$ throughout this paper. The coefficient vector $\\textbf{w} \\in \\mathbb{R}^d$ is unknown and training a linear regression model essentially \ninvolves finding $\\textbf{w}$. Let  $\\mathcal{D}$ be the initially procured training dataset and let $\\mathcal{U}$ denote  the pool of unlabeled instances. We later (in Section \\ref{sec:criteria-al}) select instances from $\\mathcal{U}$ \nvia active learning to enhance our model.\n\\par\n\nIn classical linear regression, the labels are assumed to be provided by a single noisy source.\nIn crowdsourcing, however, there are multiple annotators denoted by the set $S = \\{1, \\ldots, m\\}$.\n Each of the annotators provides a label vector which we denote by $\\textbf{y}_1, \\ldots, \\textbf{y}_m$,\nwhere $\\textbf{y}_j \\in {\\mathbb{R}}^n$ for $j = 1 ,\\ldots, m$. \nEach annotator may or may not provide the label for every instance in the training set. We, therefore, define an indicator matrix \n$I \\in \\{ 0,1\\}^{n \\times m}$, where $I_{ij} = 1$ if annotator $j$ labels instance $\\textbf{x}_i$, else $I_{ij} = 0$. \nWe denote by $n_j$, the number of labels provided by annotator $j$. That is, $n_j = \\sum_{i} I_{ij}$. We also define a matrix \n$\\textbf{X}^j \\in \\mathbb{R}^{n_j \\times d}$ whose rows contain the instances that are labeled by annotator $j$. Also, we denote by $y_{ij}$,\nthe label provided by annotator $j$ for $\\textbf{x}_i$, which is the same as  $i^{\\text{th}}$ element of the label vector $\\textbf{y}_j$. \nThe true label of a data instance $\\textbf{x}_i$ is given by $\\textbf{w}^\\top\\textbf{x}_i$. Each annotator $j$ introduces \na Gaussian noise in the label he provides. That is,\n$ y_{ij} \\sim \\mathcal{N}(\\textbf{w}^\\top\\textbf{x}_i,\\beta_j^{-1})$\nwhere, $\\beta_j$ is the precision or inverse variance of the distribution followed by $y_{ij}$. Intuitively, $\\beta_j$ is directly proportional to the\neffort put in by annotator $j$. We assume that there is always a maximum level of effort that annotator $j$ can put in and \ninverse variance corresponding to his best effort is given by $\\beta_j^*$, which is unknown to the learner as well as other annotators.\\\\\nIn general, an annotator may be strategic and may exert a lower effort level $\\beta_j < \\beta_j^*$ if \nappropriate incentives are not provided. In this section, however, we adhere to the assumption that annotators are non-strategic and \nannotator $j$ always introduces a precision of $\\beta_j^*$, thereby setting $\\beta_j = \\beta_j^*$. The parameters of the linear regression model\nfrom crowds, therefore, become $\\Theta = \\{\\textbf{w} ,  \\beta_1 , \\cdots, \\beta_m  \\}$. The aim of training a\nlinear regression model is to obtain estimates of  $\\Theta$ using the training data $\\mathcal{D}$. \n\nWe now describe a Bayesian framework for this.\n\n\n \\begin{figure}[h] \n \n   \n  \n        \\centering\n        \n        \n        \\includegraphics[width = 0.5\\textwidth]{plate_notation_3.pdf}\n        \\caption{Plate notation for our model }\n         \\label{fig:plate-notation}\n   \n\n\n\n\n\n\n\n \n\n  \\end{figure}\n\\noindent\n\\textbf{Bayesian Model and Variational Inference for Parameter Estimation}: \n\n A Bayesian framework for parameter estimation is well suited for active learning as incremental learning can be done conveniently. \n Bayesian framework has been developed for estimating the parameters of the linear regression model when labels of training data \n are supplied by a single noisy source~\\cite{prml_bishop}. To the best of our knowledge, the counterpart of such a Bayesian framework \n in the presence of multiple annotators has not been explicitly explored. \n \\setlength{\\intextsep}{0.2pt}\n We assume a Gaussian prior for $\\textbf{w}$ with mean $\\mu_0$ and precision matrix or inverse covariance \nmatrix $\\Lambda_0$.\nWe assume Gamma priors for $\\beta_j$'s, that is, \n $p(\\textbf{w}) \\sim \\mathcal{N}(\\mu_0, \\Lambda_0^{-1}), \n p(\\beta_j) \\sim \\mathcal{G}(\\gamma_{a0}^j, \\gamma_{b0}^j) \\text{ for } j=1,\\ldots, m $.\n The plate notation of the Bayesian model described above is provided in Figure\n\\ref{fig:plate-notation}.\nThe computation of the posterior distributions\n$p(\\textbf{w} \\mid \\mathcal{D})$ and $p(\\beta_j \\mid \\mathcal{D}) $ for $j= 1, \\cdots, m$  is not tractable. Therefore, \nwe appeal to variational approximation methods \\cite{BealThesis2003Variational}. These methods approximate the posterior distributions using mean field assumptions.\nWe use $q(\\bold{w})$ and $q(\\beta_j)$ to represent the mean field variational approximation of  $p(\\textbf{w}\\mid\\mathcal{D})$ and\n$p(\\beta_j \\mid \\mathcal{D})$ respectively.\nThe variational approximation begins by initializing the parameters of the prior distributions,\n$\\{ \\mu_0, \\Lambda_0\\}$ and\n$\\{ \\gamma_{a0}^j, \\gamma_{b0} ^j\\}$ for all $j =1, \\cdots, m$.\nAt each iteration of the algorithm, the parameters of the posterior approximation are updated and the steps are repeated until convergence.\n\n\n\\begin{lemma}\nThe variational update rules for the posterior approximations using mean field assumptions are\n$\n q(\\bold{w}) \\sim \\mathcal{N}(\\mu_n, \\Lambda_n^{-1})\n$ and $\n q(\\beta_j) \\sim \\mathcal{G}( \\gamma_{an}^{j}, \\gamma_{bn}^{j} )\n$\n where\n \n \\allowdisplaybreaks\n \n", "index": 1, "text": "\\begin{align}\n\\Lambda_n &=  \\left[\\Lambda_0 + \\sum\\nolimits_j \\mathbb{E}[\\beta_j] \\sum\\nolimits_{{i : I_{ij} = 1}} \\textbf{x}_i \\textbf{x}_i^\\top \\right] \\label{lambda_w_var_upd}\\\\\n\\mu_n &= \\Lambda_n^{-1}\\left[\\Lambda_0 \\mu_0 +  \\sum\\nolimits_j \\mathbb{E}[\\beta_j] \\sum\\nolimits_{{i : I_{ij} = 1}} y_{ij}\\textbf{x}_i\\right] \\label{mu_w_var_upd}\\\\\n\n\n\\gamma_{an}^{j} &= \\gamma_{a0}^{j} + {n_j}/{2} \\label{gamma_a_var_upd}\\\\\n\n\n\n\\gamma_{bn}^{j} &= \n\\gamma_{b0}^{j} + \\frac{1}{2}  \\sum\\nolimits_{{i : I_{ij} = 1}} \\left( y_{ij}^2 - y_{ij}\\mu_n^ \\top \\bold{x}_i \\right) \\nonumber \\\\\n &\\quad +  \\frac{1}{2} Tr\\left({\\textbf{X}^j}^\\top \\textbf{X}^j\\Lambda_n^{-1}\\right) + \\frac{1}{2}\\mu_n^\\top {\\textbf{X}^j}^\\top\\textbf{X}^j\\mu_n   \\label{gamma_b_var_upd}\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\Lambda_{n}\" display=\"inline\"><msub><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left[\\Lambda_{0}+\\sum\\nolimits_{j}\\mathbb{E}[\\beta_{j}]\\sum%&#10;\\nolimits_{{i:I_{ij}=1}}\\textbf{x}_{i}\\textbf{x}_{i}^{\\top}\\right]\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>[</mo><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>+</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub></mstyle><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><msub><mtext>\ud835\udc31</mtext><mi>i</mi></msub><mo>\u2062</mo><msubsup><mtext>\ud835\udc31</mtext><mi>i</mi><mo>\u22a4</mo></msubsup></mrow></mrow></mrow></mrow></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{n}\" display=\"inline\"><msub><mi>\u03bc</mi><mi>n</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\Lambda_{n}^{-1}\\left[\\Lambda_{0}\\mu_{0}+\\sum\\nolimits_{j}%&#10;\\mathbb{E}[\\beta_{j}]\\sum\\nolimits_{{i:I_{ij}=1}}y_{ij}\\textbf{x}_{i}\\right]\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub></mstyle><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mtext>\ud835\udc31</mtext><mi>i</mi></msub></mrow></mrow></mrow></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\par&#10;\\par&#10;\\gamma_{an}^{j}\" display=\"inline\"><msubsup><mi>\u03b3</mi><mrow><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow><mi>j</mi></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\gamma_{a0}^{j}+{n_{j}}/{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msubsup><mi>\u03b3</mi><mrow><mi>a</mi><mo>\u2062</mo><mn>0</mn></mrow><mi>j</mi></msubsup><mo>+</mo><mrow><msub><mi>n</mi><mi>j</mi></msub><mo>/</mo><mn>2</mn></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\par&#10;\\par&#10;\\par&#10;\\gamma_{bn}^{j}\" display=\"inline\"><msubsup><mi>\u03b3</mi><mrow><mi>b</mi><mo>\u2062</mo><mi>n</mi></mrow><mi>j</mi></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\gamma_{b0}^{j}+\\frac{1}{2}\\sum\\nolimits_{{i:I_{ij}=1}}\\left(y_{%&#10;ij}^{2}-y_{ij}\\mu_{n}^{\\top}\\mathbb{x}_{i}\\right)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msubsup><mi>\u03b3</mi><mrow><mi>b</mi><mo>\u2062</mo><mn>0</mn></mrow><mi>j</mi></msubsup><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><mo>(</mo><mrow><msubsup><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mn>2</mn></msubsup><mo>-</mo><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msubsup><mi>\u03bc</mi><mi>n</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><msub><mi>\ud835\udd69</mi><mi>i</mi></msub></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad+\\frac{1}{2}Tr\\left({\\textbf{X}^{j}}^{\\top}\\textbf{X}^{j}%&#10;\\Lambda_{n}^{-1}\\right)+\\frac{1}{2}\\mu_{n}^{\\top}{\\textbf{X}^{j}}^{\\top}%&#10;\\textbf{X}^{j}\\mu_{n}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mi>T</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mmultiscripts><mtext>\ud835\udc17</mtext><none/><mi>j</mi><none/><mo>\u22a4</mo></mmultiscripts><mo>\u2062</mo><msup><mtext>\ud835\udc17</mtext><mi>j</mi></msup><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mi>\u03bc</mi><mi>n</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><mmultiscripts><mtext>\ud835\udc17</mtext><none/><mi>j</mi><none/><mo>\u22a4</mo></mmultiscripts><mo>\u2062</mo><msup><mtext>\ud835\udc17</mtext><mi>j</mi></msup><mo>\u2062</mo><msub><mi>\u03bc</mi><mi>n</mi></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nwhere,\n$\\tilde{p}(\\mathcal{D}, \\bold{w}) = E_{\\beta}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right] + \\;\\;\\text{constant}$ and\n$\\beta = \\{\\beta_1, \\ldots, \\beta_m\\} $.\nIn order to minimize $KL(q || p)$, we must maximise\n $\\mathcal{L}(q)$. Eqn (\\ref{eqn:l-q}) shows that $\\mathcal{L}(q)$\nis the negative KL-divergence between $\\tilde{p}(\\mathcal{D}, \\bold{w})$ and $q_{\\bold{w}}$. $\\mathcal{L}(q)$ is maximised \nwhen the KL-divergence between $\\tilde{p}(\\mathcal{D}, \\bold{w})$ and $q_{\\bold{w}}$ is minimized. Therefore, we must set\n$q_{\\bold{w}} =\\tilde{p}(\\mathcal{D}, \\bold{w}) =  E_{\\beta}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right]$.\nBy similar calculations, we must set,\n$q_{\\beta_j} =\\tilde{p}(\\mathcal{D}, \\beta_j) =  E_{\\bold{w},\\beta_{-j}}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right]$, where\n$\\beta_{-j} = \\{\\beta_1, \\cdots, \\beta_{j-1}, \\beta_{j+1},\n\\cdots, \\beta_m\\}$.\n\\allowdisplaybreaks\n\n", "itemtype": "equation", "pos": 17590, "prevtext": "\n\\end{lemma}\n\\begin{proof}\n\nIf $p$ and $q$ denote the true and approximate posterior joint distributions of the parameters respectively, we know that,\n$\\ln p(\\mathcal{D}) =  \\mathcal{L}(q)+ KL(q \\mid\\mid p)$\n, where, $\n\\mathcal{L}(q)= \\int q(\\Theta) \\ln \\left\\lbrace \\frac{p(\\mathcal{D}, \\Theta)}{q(\\Theta)} \\right\\rbrace d\\Theta\n$ and $KL(q||p) = - \\int q(\\Theta) \\ln \\left[ \\frac{p(\\Theta \\mid \\mathcal{D})W}{q(\\Theta)}\\right] d\\Theta\n$ is the KL divergence between the distributions $q$ and $p$. \n\n\nBy the mean field assumption, the joint distribution $q(\\bold{w}, \\beta_1, \\cdots, \\beta_m)$\nfactorizes as follows, $ q(\\bold{w}, \\beta_1, \\cdots, \\beta_m) $ $= q(\\bold{w})\\prod_{j=1}^{m} q(\\beta_j)$.\nFor simplicity we denote by $q_{\\bold{w}}$ the distribution $q(\\bold{w})$ and by $q_{\\bold{\\beta_j}}$ the distribution\n $q(\\beta_j)$.\n\n", "index": 3, "text": "\\begin{align}\n\\label{eqn:l-q}\n\\mathcal{L}&(q) = \\int q_{\\bold{w}} \\prod_{i=1}^m q_{\\beta_j}\n\\left\\lbrace \\ln p(\\mathcal{D}, \\Theta) - \\sum_{i \\in {w,\\beta_1,\\cdots,\\beta_m}} q_i \\right\\rbrace d\\beta_j d\\bold{w}\\nonumber \\\\\n&\\propto \\int q_\\bold{w} \\left \\lbrace \\int \\ln  p(\\mathcal{D}, \\Theta)\n\\prod_{i=1}^{m} q_{\\beta_i} d\\bold{\\beta_i} \\right\\rbrace d\\bold{w} - \\int q_{\\bold{w}} \\ln q_{\\bold{w}} d\\bold{w} \\nonumber\\\\\n& =\\int q_\\bold{w} \\ln \\tilde{p}(\\mathcal{D}, \\bold{w}) d\\bold{w} - \\int q_{\\bold{w}} \\ln q_{\\bold{w}} d\\bold{w}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{L}\" display=\"inline\"><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle(q)=\\int q_{\\mathbb{w}}\\prod_{i=1}^{m}q_{\\beta_{j}}\\left\\{\\ln p(%&#10;\\mathcal{D},\\Theta)-\\sum_{i\\in{w,\\beta_{1},\\cdots,\\beta_{m}}}q_{i}\\right\\}d%&#10;\\beta_{j}d\\mathbb{w}\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">(</mo><mi>q</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>q</mi><msub><mi>\u03b2</mi><mi>j</mi></msub></msub><mo>\u2062</mo><mrow><mo>{</mo><mrow><mrow><mrow><mi>ln</mi><mo>\u2061</mo><mi>p</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>,</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><mrow><mi>w</mi><mo>,</mo><msub><mi>\u03b2</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>,</mo><msub><mi>\u03b2</mi><mi>m</mi></msub></mrow></mrow></munder><msub><mi>q</mi><mi>i</mi></msub></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></mrow></mstyle></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto\\int q_{\\mathbb{w}}\\left\\{\\int\\ln p(\\mathcal{D},\\Theta)%&#10;\\prod_{i=1}^{m}q_{\\beta_{i}}d\\mathbb{\\beta_{i}}\\right\\}d\\mathbb{w}-\\int q_{%&#10;\\mathbb{w}}\\ln q_{\\mathbb{w}}d\\mathbb{w}\" display=\"inline\"><mrow><mi/><mo>\u221d</mo><mrow><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mrow><mo>{</mo><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mrow><mi>ln</mi><mo>\u2061</mo><mi>p</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>,</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>q</mi><msub><mi>\u03b2</mi><mi>i</mi></msub></msub><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><msub><mi>\u03b2</mi><mi>\ud835\udd5a</mi></msub></mrow></mrow></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></mrow></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int q_{\\mathbb{w}}\\ln\\tilde{p}(\\mathcal{D},\\mathbb{w})d\\mathbb{%&#10;w}-\\int q_{\\mathbb{w}}\\ln q_{\\mathbb{w}}d\\mathbb{w}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mover accent=\"true\"><mi>p</mi><mo stretchy=\"false\">~</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>,</mo><mi>\ud835\udd68</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><msub><mi>q</mi><mi>\ud835\udd68</mi></msub><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></mrow></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n   By completing the squares we get the update rules for $\\bold{w}$.\n   The similar steps can be performed to get the variational updates for $\\beta_j$. Due to constraints on space, we have not included the steps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \\end{proof}\n\n The variational updates for $\\mu_n$ and $\\Lambda_n$ defined in  Eqns (\\ref{lambda_w_var_upd}) and (\\ref{mu_w_var_upd}) involve \n $\\mathbb{E}[\\beta_j] = \\gamma_{an}^{j}/\\gamma_{bn}^{j} $.\n The updates for $\\gamma_{bn}^{j}$ given in Eqn (\\ref{gamma_b_var_upd}) \n involve $\\mu_n$ and $\\Lambda_n$. This interdependency between the update\n equations leads to an iterative algorithm.\n \n \\begin{remark}[Parameter Estimation]: Our approach is not tied to the variational inference approximation scheme. For example, MCMC can be used instead.\n \\end{remark} \n \n  \\begin{lemma}\n\\label{lemma:var_upd_aysmptotics}\n\\textbf{Asymptotic convergence of Bayes estimators}:\n\n\n \n Let $\\textbf{w}^*$ be the true underlying value of $\\textbf{w}$ and the Bayes estimator for $\\textbf{w}$ under the least squares loss be $\\mu_n$.\nThen, $ \\lim_{n \\to \\infty}  \\mathbb{E}_{\\mathcal{D}}[\\mu_n] \\rightarrow \\textbf{w}^*$.\n\\end{lemma}\n\\begin{proof}\nLet $\\mu_n$ and $\\Lambda_n$ be the mean and precision respectively, of the approximate posterior distribution $q(w)$ , estimated from the\ntraining set $\\mathcal{D}$. Let $\\bold{w^*}$ be the realized value of the underlying $\\bold{w}$.\n\n", "itemtype": "equation", "pos": 19027, "prevtext": "\nwhere,\n$\\tilde{p}(\\mathcal{D}, \\bold{w}) = E_{\\beta}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right] + \\;\\;\\text{constant}$ and\n$\\beta = \\{\\beta_1, \\ldots, \\beta_m\\} $.\nIn order to minimize $KL(q || p)$, we must maximise\n $\\mathcal{L}(q)$. Eqn (\\ref{eqn:l-q}) shows that $\\mathcal{L}(q)$\nis the negative KL-divergence between $\\tilde{p}(\\mathcal{D}, \\bold{w})$ and $q_{\\bold{w}}$. $\\mathcal{L}(q)$ is maximised \nwhen the KL-divergence between $\\tilde{p}(\\mathcal{D}, \\bold{w})$ and $q_{\\bold{w}}$ is minimized. Therefore, we must set\n$q_{\\bold{w}} =\\tilde{p}(\\mathcal{D}, \\bold{w}) =  E_{\\beta}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right]$.\nBy similar calculations, we must set,\n$q_{\\beta_j} =\\tilde{p}(\\mathcal{D}, \\beta_j) =  E_{\\bold{w},\\beta_{-j}}\n\\left[\\ln p(\\mathcal{D}, \\Theta) \\right]$, where\n$\\beta_{-j} = \\{\\beta_1, \\cdots, \\beta_{j-1}, \\beta_{j+1},\n\\cdots, \\beta_m\\}$.\n\\allowdisplaybreaks\n\n", "index": 5, "text": "\\begin{align*}\n\\log\\; & q(\\bold{w}) \\propto E_{\\beta} \\left[ \\log p(Y, \\bold{w}, \\beta\\mid \\textbf{X}, \\bold{\\delta}, \\bold{\\gamma})\\right] \n\\nonumber \\\\ &= E_{\\beta} \\left[ \\log p( \\bold{w}, \\beta ) + \\log p(Y\\mid\\textbf{X}, \\bold{w}, \\beta)\\right] \\nonumber \\\\\n&=\\log p(\\bold{w} \\mid \\bold{\\delta}) + E_\\beta \\left[ \\log p(\\beta\\mid \\gamma) \\right] \n+  E_{\\beta} \\left[\n\\log p(Y\\mid\\textbf{X}, \\bold{w}, \\beta)\\right]  \\nonumber \\\\\n&\\propto \\frac{1}{2\\pi} | \\Lambda_0 |- \\frac{1}{2} (\\bold{w} - \\mu_0)^\\top \\Lambda_0  (\\bold{w} - \\mu_0) \\\\\n&\\;\\;\\;+ E_{\\beta}\\left[ \\log \\prod_{ij} \\frac{\\beta_j}{2\\pi} \\exp \\left( -\\frac{\\beta_j (y_{ij} - \\bold{w}^\\top x_i)^2}{2} \\right)\\right] \\nonumber \\\\\n&\\propto - \\frac{1}{2} (\\bold{w} - \\mu_0)^\\top \\Lambda_0  (\\bold{w} - \\mu_0) \\\\\n&\\;\\;\\;+  E_{\\beta}\\left[ \\sum_{ij}\\log  \\frac{\\beta_j}{2\\pi} - \\left( \\frac{\\beta_j (y_{ij} - \\bold{w}^\\top x_i)^2}{2} \\right)\\right]  \\nonumber \\\\\n &= - \\frac{1}{2} (\\bold{w} - \\mu_0)^\\top \\Lambda_0  (\\bold{w} - \\mu_0) \\\\\n &\\;\\;\\;+\n  \\sum_{ij}E_{\\beta_j}\\left[\\log  \\frac{\\beta_j}{2\\pi} - \\left( \\frac{\\beta_j (y_{ij} - \\bold{w}^\\top x_i)^2}{2} \\right)\\right] \\nonumber \\\\\n  & \\propto - \\frac{1}{2} (\\bold{w} - \\mu_0)^\\top \\Lambda_0  (\\bold{w} - \\mu_0) \\\\\n & \\;\\;\\;+\n  \\sum_{j}E_{\\beta_j}\\left[ - \\left( \\frac{\\beta_j \\sum_i (y_{ij} - \\bold{w}^\\top x_i)^2}{2} \\right)\\right] \\nonumber \\nonumber \\\\\n  &= - \\frac{1}{2} (\\bold{w}^\\top \\Lambda_0\\bold{w} - 2\\bold{w}^\\top \\Lambda_0\\mu_0 + \\mu_0^\\top \\Lambda_0\\mu_0 \\\\\n  & \\;\\;\\; +\n \\sum_{ij} \\frac{E_{\\beta_j}\\left[ \\beta_j\\right]}{2}(y_{ij}^2 + x_i^\\top \\bold{w}\\bold{w}^\\top x_i - 2y_{ij} \\bold{w}^\\top x_i)\\nonumber \\\\\n  &\\propto - \\frac{1}{2} \\bold{w}^\\top \\left[\\Lambda_0 + \\left(\\sum\\nolimits_jE[\\beta_j]  \\sum\\nolimits_{{i:I_{ij} = 1}}  \\textbf{x}_i\\textbf{x}_i^\\top\n  \\right)\\right]\\bold{w} \\\\\n  &\\;\\;\\;\n  + \\bold{w}^\\top \\left[\\Lambda_0\\mu_0 - \\frac{1}{2}  \\sum\\nolimits_jE[\\beta_j]  \\sum\\nolimits_{{i:I_{ij} = 1}}  y_{ij}\\bold{x}_i\\right]\n  \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\log\" display=\"inline\"><mi>log</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle q(\\mathbb{w})\\propto E_{\\beta}\\left[\\log p(Y,\\mathbb{w},\\beta%&#10;\\mid\\textbf{X},\\mathbb{\\delta},\\mathbb{\\gamma})\\right]\" display=\"inline\"><mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udd68</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><msub><mi>E</mi><mi>\u03b2</mi></msub><mrow><mo>[</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>,</mo><mi>\ud835\udd68</mi><mo>,</mo><mi>\u03b2</mi><mo>\u2223</mo><mtext>\ud835\udc17</mtext><mo>,</mo><mi>\u03b4</mi><mo>,</mo><mi>\u03b3</mi><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E_{\\beta}\\left[\\log p(\\mathbb{w},\\beta)+\\log p(Y\\mid\\textbf{X},%&#10;\\mathbb{w},\\beta)\\right]\" display=\"inline\"><mrow><mo>=</mo><msub><mi>E</mi><mi>\u03b2</mi></msub><mrow><mo>[</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udd68</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>\u2223</mo><mtext>\ud835\udc17</mtext><mo>,</mo><mi>\ud835\udd68</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\log p(\\mathbb{w}\\mid\\mathbb{\\delta})+E_{\\beta}\\left[\\log p(%&#10;\\beta\\mid\\gamma)\\right]+E_{\\beta}\\left[\\log p(Y\\mid\\textbf{X},\\mathbb{w},\\beta%&#10;)\\right]\" display=\"inline\"><mrow><mo>=</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udd68</mi><mo>\u2223</mo><mi>\u03b4</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><msub><mi>E</mi><mi>\u03b2</mi></msub><mrow><mo>[</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b2</mi><mo>\u2223</mo><mi>\u03b3</mi><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow><mo>+</mo><msub><mi>E</mi><mi>\u03b2</mi></msub><mrow><mo>[</mo><mi>log</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>\u2223</mo><mtext>\ud835\udc17</mtext><mo>,</mo><mi>\ud835\udd68</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto\\frac{1}{2\\pi}|\\Lambda_{0}|-\\frac{1}{2}(\\mathbb{w}-\\mu_{0}%&#10;)^{\\top}\\Lambda_{0}(\\mathbb{w}-\\mu_{0})\" display=\"inline\"><mrow><mi/><mo>\u221d</mo><mrow><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo stretchy=\"false\">|</mo></mrow></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+E_{\\beta}\\left[\\log\\prod_{ij}\\frac{\\beta_{j}}{2\\pi}\\exp%&#10;\\left(-\\frac{\\beta_{j}(y_{ij}-\\mathbb{w}^{\\top}x_{i})^{2}}{2}\\right)\\right]\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><msub><mi>E</mi><mi>\u03b2</mi></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mi>log</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03b2</mi><mi>j</mi></msub><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mrow><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto-\\frac{1}{2}(\\mathbb{w}-\\mu_{0})^{\\top}\\Lambda_{0}(\\mathbb%&#10;{w}-\\mu_{0})\" display=\"inline\"><mrow><mi/><mo>\u221d</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+E_{\\beta}\\left[\\sum_{ij}\\log\\frac{\\beta_{j}}{2\\pi}-\\left(%&#10;\\frac{\\beta_{j}(y_{ij}-\\mathbb{w}^{\\top}x_{i})^{2}}{2}\\right)\\right]\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><msub><mi>E</mi><mi>\u03b2</mi></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder></mstyle><mrow><mi>log</mi><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03b2</mi><mi>j</mi></msub><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></mfrac></mstyle></mrow></mrow><mo>-</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mrow><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\frac{1}{2}(\\mathbb{w}-\\mu_{0})^{\\top}\\Lambda_{0}(\\mathbb{w}-%&#10;\\mu_{0})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+\\sum_{ij}E_{\\beta_{j}}\\left[\\log\\frac{\\beta_{j}}{2\\pi}-%&#10;\\left(\\frac{\\beta_{j}(y_{ij}-\\mathbb{w}^{\\top}x_{i})^{2}}{2}\\right)\\right]\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder></mstyle><mrow><msub><mi>E</mi><msub><mi>\u03b2</mi><mi>j</mi></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03b2</mi><mi>j</mi></msub><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></mfrac></mstyle></mrow><mo>-</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mrow><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto-\\frac{1}{2}(\\mathbb{w}-\\mu_{0})^{\\top}\\Lambda_{0}(\\mathbb%&#10;{w}-\\mu_{0})\" display=\"inline\"><mrow><mi/><mo>\u221d</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udd68</mi><mo>-</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+\\sum_{j}E_{\\beta_{j}}\\left[-\\left(\\frac{\\beta_{j}\\sum_{i}(%&#10;y_{ij}-\\mathbb{w}^{\\top}x_{i})^{2}}{2}\\right)\\right]\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder></mstyle><mrow><msub><mi>E</mi><msub><mi>\u03b2</mi><mi>j</mi></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mo>-</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>i</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mrow><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mn>2</mn></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\frac{1}{2}(\\mathbb{w}^{\\top}\\Lambda_{0}\\mathbb{w}-2\\mathbb{w}^%&#10;{\\top}\\Lambda_{0}\\mu_{0}+\\mu_{0}^{\\top}\\Lambda_{0}\\mu_{0}\" display=\"inline\"><mrow><mo>=</mo><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mi>\ud835\udd68</mi><mo>-</mo><mn>2</mn><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><msub><mi>\u03bc</mi><mn>0</mn></msub><mo>+</mo><msubsup><mi>\u03bc</mi><mn>0</mn><mo>\u22a4</mo></msubsup><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+\\sum_{ij}\\frac{E_{\\beta_{j}}\\left[\\beta_{j}\\right]}{2}(y_{%&#10;ij}^{2}+x_{i}^{\\top}\\mathbb{w}\\mathbb{w}^{\\top}x_{i}-2y_{ij}\\mathbb{w}^{\\top}x%&#10;_{i})\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>E</mi><msub><mi>\u03b2</mi><mi>j</mi></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo>]</mo></mrow></mrow><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mn>2</mn></msubsup><mo>+</mo><mrow><msubsup><mi>x</mi><mi>i</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><mi>\ud835\udd68</mi><mo>\u2062</mo><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto-\\frac{1}{2}\\mathbb{w}^{\\top}\\left[\\Lambda_{0}+\\left(\\sum%&#10;\\nolimits_{j}E[\\beta_{j}]\\sum\\nolimits_{{i:I_{ij}=1}}\\textbf{x}_{i}\\textbf{x}_%&#10;{i}^{\\top}\\right)\\right]\\mathbb{w}\" display=\"inline\"><mrow><mi/><mo>\u221d</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>[</mo><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>+</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub></mstyle><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><msub><mtext>\ud835\udc31</mtext><mi>i</mi></msub><mo>\u2062</mo><msubsup><mtext>\ud835\udc31</mtext><mi>i</mi><mo>\u22a4</mo></msubsup></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mo>\u2062</mo><mi>\ud835\udd68</mi></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;+\\mathbb{w}^{\\top}\\left[\\Lambda_{0}\\mu_{0}-\\frac{1}{2}\\sum%&#10;\\nolimits_{j}E[\\beta_{j}]\\sum\\nolimits_{{i:I_{ij}=1}}y_{ij}\\mathbb{x}_{i}\\right]\" display=\"inline\"><mrow><mpadded width=\"+5.6pt\"><mi mathvariant=\"normal\">\u2004</mi></mpadded><mo>+</mo><mrow><msup><mi>\ud835\udd68</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub></mstyle><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>\ud835\udd69</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow></mrow></mrow><mo>]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nIf the second term in Eqn \\ref{lambda_n_exp} approaches $0$ as $n \\to \\infty$, the estimate $\\mu_n$ is an asymptotically unbiased\nestimate for $\\bold{w}$.\nUsing standard linear algebra results, we can prove that the determinant of the precision matrix $\\det(\\Lambda_n)$ approaches $\\infty$ with\nlarge number of samples, that is, $\\lim_{n \\rightarrow \\infty} \\det(\\Lambda_n) \\rightarrow \\infty$. Hence the second term in \nEqn \\ref{lambda_n_exp} approaches \nzero. Therefore $\\lim_{n \\rightarrow \\infty} E_\\mathcal{D}[\\mu_n] \\rightarrow \\bold{w}^* $.\n\\end{proof}\nLemma \\ref{lemma:var_upd_aysmptotics} is a desirable property of the estimators, and in general\nholds true for Bayes estimators. \n\n\n\\subsubsection*{Inference:}\n\\label{sec:inference} \nWe now describe an inference scheme to make prediction about the label of a test data instance.\nWe denote by $\\widehat{y}_{\\text{test}}$ the predicted label for the test instance $\\textbf{x}_{\\text{test}}$.\nFrom the Bayesian framework of parameter estimation, \nThe posterior predictive distribution for $\\widehat{y}_{\\text{test}}$ turns out to be as follows: $p(\\widehat{y}_{\\text{test}}\\mid \\textbf{x}_{\\text{test}}, \\mathcal{D})\n\\sim \\mathcal{N}(\\textbf{x}_{\\text{test}}^\\top\\mu_n, \\textbf{x}_{\\text{test}}^\\top \\Lambda_{n}^{-1} \\textbf{x}_{\\text{test}})$.\nThis follows from standard results in \\cite{prml_bishop}.\n\nWe can use this distribution later in scenarios like active learning.\n\n\\section{Active Learning for Linear Regression from the Crowd}\n\\label{sec:seq-estimation}\nWe now discuss various active learning  \\cite{Settles10activelearning} strategies in our framework.\nLet $\\mathcal{U}$ be the set of unlabeled instances.\nThe goal is to identify an instance, say $\\textbf{x}_k \\in \\mathcal{U}$, for which seeking a label and retraining the model with this\nadditional training example will improve the model in terms of the generalization error. In the crowdsourcing context, since multiple annotators are involved, \nwe also need to identify the annotator $t$ from whom we should obtain the label for $\\textbf{x}_k$. The active learning criterion, thus,\ninvolves finding a pair $(k,t)$ so that retraining with the new labeled set $\\mathcal{D} \\cup \\{(\\textbf{x}_k, y_{kt})\\}$ would provide maximum improvement \nin the model.\n\\subsection{Instance Selection}\n\\label{sec:criteria-al}\n \n \n To our crowdsourcing model, we now apply  two   criteria well-studied in active learning from a single source.  \n We also show that all these seemingly different criteria embody the same logic. \n\\subsubsection{Minimizing Estimator Error}\n\\label{point:estimator_error}\nMinimizing estimator error is a natural criterion for active learning  \\cite{Roy2001}. \nThe error in the estimator $\\mu_{n+1}$, if we choose a pair $(k,t)$, is given by,\n$\\text{Err}(\\mu_{n+1}) = \\mathbb{E}_{y_{kt}} \\left[\\mu_{n+1} \\right] - \\textbf{w} $. The error in the estimator $\\mu_{n}$, before including the instance $(\\textbf{x}_k, y_{kt})$ in the training set is,\n$\\text{Err}(\\mu_{n}) = \\mu_{n} - \\textbf{w} $.\n\\begin{lemma}\n\\label{lemma:min-est-error}\nThe relation between errors in $\\mu_{n+1}$ and $\\mu_n$ is given by,\n\\begin{eqnarray}\n\n\\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert /(1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1}\\textbf{x}_k )\\leq \\left \\Vert \\text{Err} (\\mu_{n+1}) \\right \\Vert  \\leq  \\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert\n  \\label{mu_w_error_bound}\n\\end{eqnarray}\n\\end{lemma}\n\\begin{proof}\n\nWe first compute $E_{y_{kt}}[ \\mu_{n+1}]$. \n\n\n", "itemtype": "equation", "pos": 22422, "prevtext": "\n   By completing the squares we get the update rules for $\\bold{w}$.\n   The similar steps can be performed to get the variational updates for $\\beta_j$. Due to constraints on space, we have not included the steps.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \\end{proof}\n\n The variational updates for $\\mu_n$ and $\\Lambda_n$ defined in  Eqns (\\ref{lambda_w_var_upd}) and (\\ref{mu_w_var_upd}) involve \n $\\mathbb{E}[\\beta_j] = \\gamma_{an}^{j}/\\gamma_{bn}^{j} $.\n The updates for $\\gamma_{bn}^{j}$ given in Eqn (\\ref{gamma_b_var_upd}) \n involve $\\mu_n$ and $\\Lambda_n$. This interdependency between the update\n equations leads to an iterative algorithm.\n \n \\begin{remark}[Parameter Estimation]: Our approach is not tied to the variational inference approximation scheme. For example, MCMC can be used instead.\n \\end{remark} \n \n  \\begin{lemma}\n\\label{lemma:var_upd_aysmptotics}\n\\textbf{Asymptotic convergence of Bayes estimators}:\n\n\n \n Let $\\textbf{w}^*$ be the true underlying value of $\\textbf{w}$ and the Bayes estimator for $\\textbf{w}$ under the least squares loss be $\\mu_n$.\nThen, $ \\lim_{n \\to \\infty}  \\mathbb{E}_{\\mathcal{D}}[\\mu_n] \\rightarrow \\textbf{w}^*$.\n\\end{lemma}\n\\begin{proof}\nLet $\\mu_n$ and $\\Lambda_n$ be the mean and precision respectively, of the approximate posterior distribution $q(w)$ , estimated from the\ntraining set $\\mathcal{D}$. Let $\\bold{w^*}$ be the realized value of the underlying $\\bold{w}$.\n\n", "index": 7, "text": "\\begin{align}\n\\label{lambda_n_exp}\n E_\\mathcal{D}[\\mu_n] &= \\Lambda_n^{-1}(\\Lambda_0 \\mu_0 + \\sum\\nolimits_j E[\\beta_j] \\sum\\nolimits_{{i:I_{ij} = 1}} \\bold{x}_i E_\\mathcal{D} [y_{ij}]) \\nonumber\\\\\n  &= \\Lambda_n^{-1}(\\Lambda_0 \\mu_0 + (\\Lambda_n - \\Lambda_0)) \\bold{w^*} \\nonumber \\\\ \n  &= \\bold{w}^* + \\Lambda_n^{-1}\\Lambda_0(\\mu_0 - \\bold{w}^*)\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E_{\\mathcal{D}}[\\mu_{n}]\" display=\"inline\"><mrow><msub><mi>E</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03bc</mi><mi>n</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\Lambda_{n}^{-1}(\\Lambda_{0}\\mu_{0}+\\sum\\nolimits_{j}E[\\beta_{j}%&#10;]\\sum\\nolimits_{{i:I_{ij}=1}}\\mathbb{x}_{i}E_{\\mathcal{D}}[y_{ij}])\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub></mstyle><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03b2</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></msub></mstyle><mrow><msub><mi>\ud835\udd69</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>E</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\Lambda_{n}^{-1}(\\Lambda_{0}\\mu_{0}+(\\Lambda_{n}-\\Lambda_{0}))%&#10;\\mathbb{w^{*}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mn>0</mn></msub></mrow><mo>+</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi></msub><mo>-</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udd68</mi><mo>*</mo></msup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mathbb{w}^{*}+\\Lambda_{n}^{-1}\\Lambda_{0}(\\mu_{0}-\\mathbb{w}^{*})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msup><mi>\ud835\udd68</mi><mo>*</mo></msup><mo>+</mo><mrow><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03bc</mi><mn>0</mn></msub><mo>-</mo><msup><mi>\ud835\udd68</mi><mo>*</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n\n\n\n\n\n\n\nMaking necessary substitutions and rearranging the terms, \n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 26253, "prevtext": "\nIf the second term in Eqn \\ref{lambda_n_exp} approaches $0$ as $n \\to \\infty$, the estimate $\\mu_n$ is an asymptotically unbiased\nestimate for $\\bold{w}$.\nUsing standard linear algebra results, we can prove that the determinant of the precision matrix $\\det(\\Lambda_n)$ approaches $\\infty$ with\nlarge number of samples, that is, $\\lim_{n \\rightarrow \\infty} \\det(\\Lambda_n) \\rightarrow \\infty$. Hence the second term in \nEqn \\ref{lambda_n_exp} approaches \nzero. Therefore $\\lim_{n \\rightarrow \\infty} E_\\mathcal{D}[\\mu_n] \\rightarrow \\bold{w}^* $.\n\\end{proof}\nLemma \\ref{lemma:var_upd_aysmptotics} is a desirable property of the estimators, and in general\nholds true for Bayes estimators. \n\n\n\\subsubsection*{Inference:}\n\\label{sec:inference} \nWe now describe an inference scheme to make prediction about the label of a test data instance.\nWe denote by $\\widehat{y}_{\\text{test}}$ the predicted label for the test instance $\\textbf{x}_{\\text{test}}$.\nFrom the Bayesian framework of parameter estimation, \nThe posterior predictive distribution for $\\widehat{y}_{\\text{test}}$ turns out to be as follows: $p(\\widehat{y}_{\\text{test}}\\mid \\textbf{x}_{\\text{test}}, \\mathcal{D})\n\\sim \\mathcal{N}(\\textbf{x}_{\\text{test}}^\\top\\mu_n, \\textbf{x}_{\\text{test}}^\\top \\Lambda_{n}^{-1} \\textbf{x}_{\\text{test}})$.\nThis follows from standard results in \\cite{prml_bishop}.\n\nWe can use this distribution later in scenarios like active learning.\n\n\\section{Active Learning for Linear Regression from the Crowd}\n\\label{sec:seq-estimation}\nWe now discuss various active learning  \\cite{Settles10activelearning} strategies in our framework.\nLet $\\mathcal{U}$ be the set of unlabeled instances.\nThe goal is to identify an instance, say $\\textbf{x}_k \\in \\mathcal{U}$, for which seeking a label and retraining the model with this\nadditional training example will improve the model in terms of the generalization error. In the crowdsourcing context, since multiple annotators are involved, \nwe also need to identify the annotator $t$ from whom we should obtain the label for $\\textbf{x}_k$. The active learning criterion, thus,\ninvolves finding a pair $(k,t)$ so that retraining with the new labeled set $\\mathcal{D} \\cup \\{(\\textbf{x}_k, y_{kt})\\}$ would provide maximum improvement \nin the model.\n\\subsection{Instance Selection}\n\\label{sec:criteria-al}\n \n \n To our crowdsourcing model, we now apply  two   criteria well-studied in active learning from a single source.  \n We also show that all these seemingly different criteria embody the same logic. \n\\subsubsection{Minimizing Estimator Error}\n\\label{point:estimator_error}\nMinimizing estimator error is a natural criterion for active learning  \\cite{Roy2001}. \nThe error in the estimator $\\mu_{n+1}$, if we choose a pair $(k,t)$, is given by,\n$\\text{Err}(\\mu_{n+1}) = \\mathbb{E}_{y_{kt}} \\left[\\mu_{n+1} \\right] - \\textbf{w} $. The error in the estimator $\\mu_{n}$, before including the instance $(\\textbf{x}_k, y_{kt})$ in the training set is,\n$\\text{Err}(\\mu_{n}) = \\mu_{n} - \\textbf{w} $.\n\\begin{lemma}\n\\label{lemma:min-est-error}\nThe relation between errors in $\\mu_{n+1}$ and $\\mu_n$ is given by,\n\\begin{eqnarray}\n\n\\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert /(1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1}\\textbf{x}_k )\\leq \\left \\Vert \\text{Err} (\\mu_{n+1}) \\right \\Vert  \\leq  \\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert\n  \\label{mu_w_error_bound}\n\\end{eqnarray}\n\\end{lemma}\n\\begin{proof}\n\nWe first compute $E_{y_{kt}}[ \\mu_{n+1}]$. \n\n\n", "index": 9, "text": "\\begin{align}\nE_{y_{kt}} \\left[ \\Lambda_{n+1}\\mu_{n+1} \\right] &= \\Lambda_{n+1} E_{y_{kt}} \\left[\\mu_{n+1}\\right] \\nonumber  \\\\\n\n\n\n&= \\Lambda_n\\mu_n + \\textbf{x}_k (\\textbf{x}_{k}^\\top\\textbf{w}  )\\beta_t\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E_{y_{kt}}\\left[\\Lambda_{n+1}\\mu_{n+1}\\right]\" display=\"inline\"><mrow><msub><mi>E</mi><msub><mi>y</mi><mrow><mi>k</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\Lambda_{n+1}E_{y_{kt}}\\left[\\mu_{n+1}\\right]\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msub><mi>E</mi><msub><mi>y</mi><mrow><mi>k</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><msub><mi>\u03bc</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\Lambda_{n}\\mu_{n}+\\textbf{x}_{k}(\\textbf{x}_{k}^{\\top}\\textbf{w%&#10;})\\beta_{t}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><mi>n</mi></msub></mrow><mo>+</mo><mrow><msub><mtext>\ud835\udc31</mtext><mi>k</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mtext>\ud835\udc31</mtext><mi>k</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><mtext>\ud835\udc30</mtext></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03b2</mi><mi>t</mi></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nAgain rearranging the terms and subtracting $\\textbf{w}$ from both the sides yields,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$\\text{Err}(\\mu_{n+1})  = \\left(I + \\Lambda_n^{-1}\\textbf{x}_k  \\textbf{x}_k ^\\top \\beta_t \\right)^{-1} \\text{Err}(\\mu_n)$.\n\n\n\n\n\n\nWe now bound  $\\text{Err}(\\mu_{n+1})$,  in terms of the old error, \n$\\text{Err}(\\mu_n)$ as follows:\n$\n\\left \\Vert \\text{Err} (\\mu_{n+1}) \\right \\Vert \\leq \\left \\Vert(I + \\Sigma_{n} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}\\right \\Vert \\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert\n$\nwhere, $\\left \\Vert(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}\\right \\Vert$ is the spectral norm of the matrix \n$(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}$. Since $\\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top$ is a rank one matrix, \nthe matrix $I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t$ has $d-1$ eigenvalues equal to 1 and one eigenvalue equal to \n$1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$. Note, $ \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k > 0$ since $\\Lambda_n^{-1}$ is a\npositive definite matrix. Therefore, spectral norm of the matrix $(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1} $ is $1$ and\nits minimum eigenvalue is $1/(1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k)$ and we  arrive at the error bound.\n\\end{proof}\nFrom Theorem\\nobreakspace \\ref {lemma:min-est-error}, it is clear that to reduce the value of the lower bound, we must pick a pair $(k,t)$  for which the score \n$\\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$ is maximum. \n\\subsubsection{Minimizing Estimator's Entropy}\n\\label{point:estimator_entropy}\nThis is another natural criterion for active learning which suggests that the entropy of the estimator after adding an\nexample should decrease  \\cite{Lindley:OnMeasureInformationExperiment,MacKay_information-basedobjective}. Formally, \nlet $H(\\textbf{w} \\mid \\mathcal{D})$ and $H(\\textbf{w}\\mid \\mathcal{D'})$ denote the entropies of the estimator before and after adding an example, respectively, \nwhere we have $\\mathcal{D'} = \\mathcal{D} \\cup \\{(\\textbf{x}_k, y_{kt})\\}$. Again, let us assume $\\beta_j$'s are known for the time being. \nThe entropy of the distribution before adding an example satisfies: $H(\\textbf{w}\\mid \\mathcal{D}) \\propto \\det( \\Lambda_n^{-1})$. After adding the example, entropy function behaves as follows.\n$H(\\textbf{w}\\mid \\mathcal{D'}) \\propto  \\det(\\Lambda_{n+1}^{-1})$, where \n\n", "itemtype": "equation", "pos": 26544, "prevtext": "\n\n\n\n\n\n\n\nMaking necessary substitutions and rearranging the terms, \n\n\n\n\n\n\n\n\n\n", "index": 11, "text": "\\begin{align*}\n E_{y_{kt}} \\left[\\mu_{n+1}\\right] -\\mu_n  = - \\Lambda_n^{-1}\\textbf{x}_k  \\textbf{x}_k ^\\top \\text{Err}(\\mu_{n+1}) \\beta_t\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E_{y_{kt}}\\left[\\mu_{n+1}\\right]-\\mu_{n}=-\\Lambda_{n}^{-1}%&#10;\\textbf{x}_{k}\\textbf{x}_{k}^{\\top}\\text{Err}(\\mu_{n+1})\\beta_{t}\" display=\"inline\"><mrow><mrow><mrow><msub><mi>E</mi><msub><mi>y</mi><mrow><mi>k</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msub><mo>\u2062</mo><mrow><mo>[</mo><msub><mi>\u03bc</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>]</mo></mrow></mrow><mo>-</mo><msub><mi>\u03bc</mi><mi>n</mi></msub></mrow><mo>=</mo><mrow><mo>-</mo><mrow><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mtext>\ud835\udc31</mtext><mi>k</mi></msub><mo>\u2062</mo><msubsup><mtext>\ud835\udc31</mtext><mi>k</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><mtext>Err</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bc</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03b2</mi><mi>t</mi></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nFrom  (\\ref{entropy-exact-relation}), we would like to\nchoose an instance $\\textbf{x}_k$ and an annotator $t$ that jointly maximize $ \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$\nso that $\\det(\\Lambda_{n+1}^{-1})$ as well as estimator's entropy are minimized. Recall, the same selection strategy was obtained while using the\n {\\em minimize estimator error} criterion. \nLet $\\lambda^{*}=\\lambda_{\\text{max}}( \\Lambda_n^{-1})$ and $\\lambda_{*}=\\lambda_{\\text{min}}( \\Lambda_n^{-1})$. We can further bound the estimator precision as follows. \n", "itemtype": "equation", "pos": 29168, "prevtext": "\nAgain rearranging the terms and subtracting $\\textbf{w}$ from both the sides yields,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n$\\text{Err}(\\mu_{n+1})  = \\left(I + \\Lambda_n^{-1}\\textbf{x}_k  \\textbf{x}_k ^\\top \\beta_t \\right)^{-1} \\text{Err}(\\mu_n)$.\n\n\n\n\n\n\nWe now bound  $\\text{Err}(\\mu_{n+1})$,  in terms of the old error, \n$\\text{Err}(\\mu_n)$ as follows:\n$\n\\left \\Vert \\text{Err} (\\mu_{n+1}) \\right \\Vert \\leq \\left \\Vert(I + \\Sigma_{n} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}\\right \\Vert \\left \\Vert \\text{Err}(\\mu_n)\\right \\Vert\n$\nwhere, $\\left \\Vert(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}\\right \\Vert$ is the spectral norm of the matrix \n$(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1}$. Since $\\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top$ is a rank one matrix, \nthe matrix $I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t$ has $d-1$ eigenvalues equal to 1 and one eigenvalue equal to \n$1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$. Note, $ \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k > 0$ since $\\Lambda_n^{-1}$ is a\npositive definite matrix. Therefore, spectral norm of the matrix $(I + \\Lambda_n^{-1} \\textbf{x}_k \\textbf{x}_k^\\top \\beta_t)^{-1} $ is $1$ and\nits minimum eigenvalue is $1/(1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k)$ and we  arrive at the error bound.\n\\end{proof}\nFrom Theorem\\nobreakspace \\ref {lemma:min-est-error}, it is clear that to reduce the value of the lower bound, we must pick a pair $(k,t)$  for which the score \n$\\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$ is maximum. \n\\subsubsection{Minimizing Estimator's Entropy}\n\\label{point:estimator_entropy}\nThis is another natural criterion for active learning which suggests that the entropy of the estimator after adding an\nexample should decrease  \\cite{Lindley:OnMeasureInformationExperiment,MacKay_information-basedobjective}. Formally, \nlet $H(\\textbf{w} \\mid \\mathcal{D})$ and $H(\\textbf{w}\\mid \\mathcal{D'})$ denote the entropies of the estimator before and after adding an example, respectively, \nwhere we have $\\mathcal{D'} = \\mathcal{D} \\cup \\{(\\textbf{x}_k, y_{kt})\\}$. Again, let us assume $\\beta_j$'s are known for the time being. \nThe entropy of the distribution before adding an example satisfies: $H(\\textbf{w}\\mid \\mathcal{D}) \\propto \\det( \\Lambda_n^{-1})$. After adding the example, entropy function behaves as follows.\n$H(\\textbf{w}\\mid \\mathcal{D'}) \\propto  \\det(\\Lambda_{n+1}^{-1})$, where \n\n", "index": 13, "text": "\\begin{align}\n\\label{entropy-exact-relation}\n\\det(\\Lambda_{n+1}^{-1}) &= \\det(\\Lambda_n^{-1})/(1 + \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k)\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\det(\\Lambda_{n+1}^{-1})\" display=\"inline\"><mrow><mo movablelimits=\"false\">det</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\det(\\Lambda_{n}^{-1})/(1+\\beta_{t}\\textbf{x}_{k}^{\\top}\\Lambda_%&#10;{n}^{-1}\\textbf{x}_{k})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo movablelimits=\"false\">det</mo><mo>\u2061</mo><mrow><mrow><mo stretchy=\"false\">(</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msub><mi>\u03b2</mi><mi>t</mi></msub><mo>\u2062</mo><msubsup><mtext>\ud835\udc31</mtext><mi>k</mi><mo>\u22a4</mo></msubsup><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mtext>\ud835\udc31</mtext><mi>k</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nWe observe that the selection of the best instance $\\textbf{x}_k$ and the best annotator $S_t$ can be decoupled. That is, we can first select an instance \n$\\textbf{x}_k$ for which $\\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$ is maximum and independently select an annotator for whom $\\beta_t$ is maximum.\nBut this scheme of annotator selection\nmay lead to starvation of best annotators if \nthe annotators have not been explored sufficiently.  Hence we only use\nthis strategy for selecting an instance and not for selecting the annotator. \n\\subsection{Selection of an Annotator}\n \\label{sec:al-annotator}\n Having chosen the instance $\\textbf{x}_k$, next the learner must decide which annotator should label it.  Consider any arbitary sequential selection algorithm $\\emph{A}$ for the annotators.\n If the variance of the annotators' labels were known upfront, the best strategy would be to always select the annotator introducing  the minimum variance \n$1/\\beta^* = \\min_{1\\leq j \\leq m} 1/\\beta_j$.  The variances\nof the annotators' labels are unknown and hence a sequential selection algorithm $\\emph{A}$\nincurs a regret defined by Regret-Seq($\\emph{A}$) below. \n\nWe denote\nthe sub-optimality of annotator $j$ by $\\Delta_j = (1/\\beta_j) - (1/\\beta^*)$.\n\n\\begin{definition}{\\textbf{Regret-Seq(A,{\\tiny{ }}t):}}\n If $T_j(t)$ is the number of times annotator $j$ is selected in\n$t$ runs of $\\emph{A}$, the expected regret of $\\emph{A}$ in $t$ runs, with respect to the choice of annotator, is computed as, \n\n $\\text{Regret-Seq}(\\emph{A},t) = \\sum_{j=1}^{m} \\Delta_j \\mathbb{E}[T_j(t)]$.\n\n\\end{definition}\nThe problem is to formally establish an annotator selection strategy which yields a regret as low as possible. \nThe main challenge is that the annotators' noise level is \nunknown and must be estimated simultaneously while also deciding on the selection strategy. \nWe observe the connections of this problem to the multi-armed bandit (MAB) problem. \nIn MAB problems, there are $m$ arms each producing rewards from fixed distributions\n$P_1, \\cdots, P_m$ with unknown means $\\gamma_1, \\cdots, \\gamma_m$. The goal is to maximise the overall reward and for this, at every time-step a decision has to be made as to which arm must be pulled.\nWe denote the sub-optimality of arm $i$ by $\\Delta_i^{\\text{MAB}} = \\gamma_* - \\gamma_i$, where $\\gamma^* = \\max_{1 \\leq i \\leq m} \\gamma_i$. \n\n\\begin{definition}{\\textbf{Regret-MAB(M,{\\tiny{ }}t):}}\n If $T_i(t)$ is the number of times arm $i$ is selected in\n$t$ runs of any MAB algorithm $M$, the expected regret of $M$ in $t$ runs, Regret-MAB($M , t$), is computed as,\n\n $\\text{Regret-MAB}(M, t) = \\sum_{i=1}^{m} \\Delta_i^{\\text{MAB}} \\mathbb{E}[T_i(t)]$.\n\n\\end{definition}\nWe now show that the active learning problem in crowdsourcing regression tasks can be mapped to the MAB problem. \nWe know that,\n$\\mathbb{E}[(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2] =  1/\\beta_j$. \nSince we are interested in the annotator introducing the minimum variance,\nwe could work with a MAB framework where the rewards of the arms (annotators in our case) are drawn from the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$.\nThis idea was used in \\cite{Neufeld14} in the context of sequential selection from a pool of Monte Carlo estimators. \nIf the selection strategy $A$ appeals to  any MAB algorithm $M$ defined on the\ndistributions $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$,  Regret-MAB($M, t$) will be the same as Regret-Seq($A, t$), as proved\nby \\cite{Neufeld14}.\nThis implies that for the selection strategy, \nwe could work with any standard MAB algorithm such as UCB on the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ and \n $\\text{Regret-Seq(\\emph{A}, \\emph{t})}$ would be the same as $\\text{Regret-MAB(\\emph{M}, \\emph{t})}$, for an appropriately formulated MAB algorithm $\\emph{M}$.\n \\subsubsection{UCB Algorithm on $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$}\nAs mentioned, we can work with MAB algorithms on $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ for which we look at the widely used UCB family of MAB algorithms. The UCB algorithm is an index based scheme which, at time instant $t$ selects an arm $i$ that has the maximum value of sum of the estimated mean \n($\\hat{\\gamma_i}$) and a carefully designed confidence interval $c_{i,t}$ to provide desired guarantees.  \nTo design the UCB confidence interval $c_{i,t}$, a fairly general class of algorithms called $\\psi$-UCB \\cite{Bubeck2012a} can be used.\nThe procedure for applying $\\psi$-UCB for a random variable $G$ with some arbitrary distribution,\ninvolves choosing a convex function $\\psi_G(\\lambda)$, such that, $\\ln \\mathbb{E}[\\exp(|\\lambda(G - \\mathbb{E}[G])|] \n\\leq \\psi_G(\\lambda)$ for all $\\lambda \\geq 0$. Further, an application of Chernoff bounds gives the confidence interval. \nIn particular when $G$ satisfies the sub-Gaussian property, the choice of $\\psi_G(\\lambda)$ is easy. \nIn our setting, we will see that $\\psi$-UCB\nis inapplicable.\n\\begin{lemma}{Inapplicability of $\\psi$-UCB:}\n\\label{lemma:psi-ucb-not-possible}\n\n\nLet the distribution of random variables $G_j$ follow a zero-mean normal distribution for $j= 1, \\cdots, m$. \nThe distribution of $-G_j^2$ is sub-exponential \nwhich is a heavy-tailed distribution. For an MAB framework where the rewards of the \narms are sampled from $-G_j^2$,  $\\psi$-UCB is not applicable.\n\\end{lemma}\n\n\\begin{proof}\n\nA variable $G$ is sub-exponential if $\\mathbb{E}[\\exp(\\lambda G)] \\leq 1/(1-\\lambda/a)$ for $0 < \\lambda < a$.\nWe now prove that the random variable $G^2$, where $G \\sim \\mathcal{N}(0,\\sigma^2)$ is sub-exponential.\n\n", "itemtype": "equation", "pos": 29883, "prevtext": "\nFrom  (\\ref{entropy-exact-relation}), we would like to\nchoose an instance $\\textbf{x}_k$ and an annotator $t$ that jointly maximize $ \\beta_t \\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$\nso that $\\det(\\Lambda_{n+1}^{-1})$ as well as estimator's entropy are minimized. Recall, the same selection strategy was obtained while using the\n {\\em minimize estimator error} criterion. \nLet $\\lambda^{*}=\\lambda_{\\text{max}}( \\Lambda_n^{-1})$ and $\\lambda_{*}=\\lambda_{\\text{min}}( \\Lambda_n^{-1})$. We can further bound the estimator precision as follows. \n", "index": 15, "text": "\n\\[ 1/(1 + \\beta_t  \\lambda^{*}\\left \\Vert\\textbf{x}_k\\right \\Vert^2 ) \\leq \\det(\\Lambda_{n+1}^{-1})/\\det(\\Lambda_{n}^{-1}) \\leq 1/(1 + \\beta_t  \\lambda_{*}\\left \\Vert\\textbf{x}_k\\right \\Vert^2)  \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"1/(1+\\beta_{t}\\lambda^{*}\\left\\|\\textbf{x}_{k}\\right\\|^{2})\\leq\\det(\\Lambda_{n%&#10;+1}^{-1})/\\det(\\Lambda_{n}^{-1})\\leq 1/(1+\\beta_{t}\\lambda_{*}\\left\\|\\textbf{x%&#10;}_{k}\\right\\|^{2})\" display=\"block\"><mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msub><mi>\u03b2</mi><mi>t</mi></msub><mo>\u2062</mo><msup><mi>\u03bb</mi><mo>*</mo></msup><mo>\u2062</mo><msup><mrow><mo>\u2225</mo><msub><mtext>\ud835\udc31</mtext><mi>k</mi></msub><mo>\u2225</mo></mrow><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mo movablelimits=\"false\">det</mo><mo>\u2061</mo><mrow><mrow><mo stretchy=\"false\">(</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo movablelimits=\"false\">det</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi mathvariant=\"normal\">\u039b</mi><mi>n</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>\u2264</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msub><mi>\u03b2</mi><mi>t</mi></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><mo>*</mo></msub><mo>\u2062</mo><msup><mrow><mo>\u2225</mo><msub><mtext>\ud835\udc31</mtext><mi>k</mi></msub><mo>\u2225</mo></mrow><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nSetting $ a = 1/\\sigma^2$ shows that $G$ is sub-exponential. A random variable $-G^2$ is sub-exponential iff $G^2$ is sub-exponential.\nTherefore $-G^2$ is sub-exponential. \n\n\n\n\n\n\n\n\n\n\n Let $G_j \\sim \\mathcal{N}(0,\\sigma_j^2)$. We now compute the functions, $\\mathbb{E}[\\exp(\\lambda(-G_j^2 + \\mathbb{E}[G_j^2]))]$ and \n $\\mathbb{E}[\\exp(\\lambda( \\mathbb{E}[-G_j^2] + (G_j^2 )))]$.\n $\\mathbb{E}[G_j^2] = \\sigma_j^2$.\n\n", "itemtype": "equation", "pos": 35694, "prevtext": "\nWe observe that the selection of the best instance $\\textbf{x}_k$ and the best annotator $S_t$ can be decoupled. That is, we can first select an instance \n$\\textbf{x}_k$ for which $\\textbf{x}_k^\\top \\Lambda_n^{-1} \\textbf{x}_k$ is maximum and independently select an annotator for whom $\\beta_t$ is maximum.\nBut this scheme of annotator selection\nmay lead to starvation of best annotators if \nthe annotators have not been explored sufficiently.  Hence we only use\nthis strategy for selecting an instance and not for selecting the annotator. \n\\subsection{Selection of an Annotator}\n \\label{sec:al-annotator}\n Having chosen the instance $\\textbf{x}_k$, next the learner must decide which annotator should label it.  Consider any arbitary sequential selection algorithm $\\emph{A}$ for the annotators.\n If the variance of the annotators' labels were known upfront, the best strategy would be to always select the annotator introducing  the minimum variance \n$1/\\beta^* = \\min_{1\\leq j \\leq m} 1/\\beta_j$.  The variances\nof the annotators' labels are unknown and hence a sequential selection algorithm $\\emph{A}$\nincurs a regret defined by Regret-Seq($\\emph{A}$) below. \n\nWe denote\nthe sub-optimality of annotator $j$ by $\\Delta_j = (1/\\beta_j) - (1/\\beta^*)$.\n\n\\begin{definition}{\\textbf{Regret-Seq(A,{\\tiny{ }}t):}}\n If $T_j(t)$ is the number of times annotator $j$ is selected in\n$t$ runs of $\\emph{A}$, the expected regret of $\\emph{A}$ in $t$ runs, with respect to the choice of annotator, is computed as, \n\n $\\text{Regret-Seq}(\\emph{A},t) = \\sum_{j=1}^{m} \\Delta_j \\mathbb{E}[T_j(t)]$.\n\n\\end{definition}\nThe problem is to formally establish an annotator selection strategy which yields a regret as low as possible. \nThe main challenge is that the annotators' noise level is \nunknown and must be estimated simultaneously while also deciding on the selection strategy. \nWe observe the connections of this problem to the multi-armed bandit (MAB) problem. \nIn MAB problems, there are $m$ arms each producing rewards from fixed distributions\n$P_1, \\cdots, P_m$ with unknown means $\\gamma_1, \\cdots, \\gamma_m$. The goal is to maximise the overall reward and for this, at every time-step a decision has to be made as to which arm must be pulled.\nWe denote the sub-optimality of arm $i$ by $\\Delta_i^{\\text{MAB}} = \\gamma_* - \\gamma_i$, where $\\gamma^* = \\max_{1 \\leq i \\leq m} \\gamma_i$. \n\n\\begin{definition}{\\textbf{Regret-MAB(M,{\\tiny{ }}t):}}\n If $T_i(t)$ is the number of times arm $i$ is selected in\n$t$ runs of any MAB algorithm $M$, the expected regret of $M$ in $t$ runs, Regret-MAB($M , t$), is computed as,\n\n $\\text{Regret-MAB}(M, t) = \\sum_{i=1}^{m} \\Delta_i^{\\text{MAB}} \\mathbb{E}[T_i(t)]$.\n\n\\end{definition}\nWe now show that the active learning problem in crowdsourcing regression tasks can be mapped to the MAB problem. \nWe know that,\n$\\mathbb{E}[(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2] =  1/\\beta_j$. \nSince we are interested in the annotator introducing the minimum variance,\nwe could work with a MAB framework where the rewards of the arms (annotators in our case) are drawn from the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$.\nThis idea was used in \\cite{Neufeld14} in the context of sequential selection from a pool of Monte Carlo estimators. \nIf the selection strategy $A$ appeals to  any MAB algorithm $M$ defined on the\ndistributions $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$,  Regret-MAB($M, t$) will be the same as Regret-Seq($A, t$), as proved\nby \\cite{Neufeld14}.\nThis implies that for the selection strategy, \nwe could work with any standard MAB algorithm such as UCB on the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ and \n $\\text{Regret-Seq(\\emph{A}, \\emph{t})}$ would be the same as $\\text{Regret-MAB(\\emph{M}, \\emph{t})}$, for an appropriately formulated MAB algorithm $\\emph{M}$.\n \\subsubsection{UCB Algorithm on $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$}\nAs mentioned, we can work with MAB algorithms on $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ for which we look at the widely used UCB family of MAB algorithms. The UCB algorithm is an index based scheme which, at time instant $t$ selects an arm $i$ that has the maximum value of sum of the estimated mean \n($\\hat{\\gamma_i}$) and a carefully designed confidence interval $c_{i,t}$ to provide desired guarantees.  \nTo design the UCB confidence interval $c_{i,t}$, a fairly general class of algorithms called $\\psi$-UCB \\cite{Bubeck2012a} can be used.\nThe procedure for applying $\\psi$-UCB for a random variable $G$ with some arbitrary distribution,\ninvolves choosing a convex function $\\psi_G(\\lambda)$, such that, $\\ln \\mathbb{E}[\\exp(|\\lambda(G - \\mathbb{E}[G])|] \n\\leq \\psi_G(\\lambda)$ for all $\\lambda \\geq 0$. Further, an application of Chernoff bounds gives the confidence interval. \nIn particular when $G$ satisfies the sub-Gaussian property, the choice of $\\psi_G(\\lambda)$ is easy. \nIn our setting, we will see that $\\psi$-UCB\nis inapplicable.\n\\begin{lemma}{Inapplicability of $\\psi$-UCB:}\n\\label{lemma:psi-ucb-not-possible}\n\n\nLet the distribution of random variables $G_j$ follow a zero-mean normal distribution for $j= 1, \\cdots, m$. \nThe distribution of $-G_j^2$ is sub-exponential \nwhich is a heavy-tailed distribution. For an MAB framework where the rewards of the \narms are sampled from $-G_j^2$,  $\\psi$-UCB is not applicable.\n\\end{lemma}\n\n\\begin{proof}\n\nA variable $G$ is sub-exponential if $\\mathbb{E}[\\exp(\\lambda G)] \\leq 1/(1-\\lambda/a)$ for $0 < \\lambda < a$.\nWe now prove that the random variable $G^2$, where $G \\sim \\mathcal{N}(0,\\sigma^2)$ is sub-exponential.\n\n", "index": 17, "text": "\\begin{align}\n  \\mathbb{E}&[\\exp(\\lambda G^2)] = 1/(\\sigma \\sqrt{2 \\pi}) \\int_{-\\infty}^{\\infty} \\exp(z^2 (\\lambda - (1/2\\sigma^2))) dz \\\\\n  & = 1/(\\sigma \\sqrt{2 \\pi}) \\int_{-\\infty}^{\\infty} \\exp(-z^2 ((1-2\\lambda\\sigma^2 /2\\sigma^2))) dz \\\\\n  &= 1/(\\sigma \\sqrt{2 \\pi}) \\int_{-\\infty}^{\\infty} \\exp(-z^2 /(2\\sigma^2/(1-2\\lambda\\sigma^2 ))) dz \\\\\n  & = 1/\\sqrt{1-2\\lambda\\sigma^2} \\\\\n  & < 1/(1-2 \\lambda \\sigma^2)  \\text{ for } 0\\leq \\lambda < 1/2\\sigma^2\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}\" display=\"inline\"><mi>\ud835\udd3c</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle[\\exp(\\lambda G^{2})]=1/(\\sigma\\sqrt{2\\pi})\\int_{-\\infty}^{\\infty%&#10;}\\exp(z^{2}(\\lambda-(1/2\\sigma^{2})))dz\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>G</mi><mn>2</mn></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mo>=</mo><mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup></mstyle><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>z</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>z</mi></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1/(\\sigma\\sqrt{2\\pi})\\int_{-\\infty}^{\\infty}\\exp(-z^{2}((1-2%&#10;\\lambda\\sigma^{2}/2\\sigma^{2})))dz\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup></mstyle><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><msup><mi>z</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow><mo>/</mo><mn>2</mn></mrow><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>z</mi></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1/(\\sigma\\sqrt{2\\pi})\\int_{-\\infty}^{\\infty}\\exp(-z^{2}/(2\\sigma%&#10;^{2}/(1-2\\lambda\\sigma^{2})))dz\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup></mstyle><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><msup><mi>z</mi><mn>2</mn></msup><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>z</mi></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1/\\sqrt{1-2\\lambda\\sigma^{2}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>1</mn><mo>/</mo><msqrt><mrow><mn>1</mn><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow></msqrt></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;1/(1-2\\lambda\\sigma^{2})\\text{ for }0\\leq\\lambda&lt;1/2\\sigma^{2}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mtext>\u00a0for\u00a0</mtext><mo>\u2062</mo><mn>0</mn></mrow><mo>\u2264</mo><mi>\u03bb</mi><mo>&lt;</mo><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nSimilar calculations also yield,\n\n", "itemtype": "equation", "pos": 36579, "prevtext": "\nSetting $ a = 1/\\sigma^2$ shows that $G$ is sub-exponential. A random variable $-G^2$ is sub-exponential iff $G^2$ is sub-exponential.\nTherefore $-G^2$ is sub-exponential. \n\n\n\n\n\n\n\n\n\n\n Let $G_j \\sim \\mathcal{N}(0,\\sigma_j^2)$. We now compute the functions, $\\mathbb{E}[\\exp(\\lambda(-G_j^2 + \\mathbb{E}[G_j^2]))]$ and \n $\\mathbb{E}[\\exp(\\lambda( \\mathbb{E}[-G_j^2] + (G_j^2 )))]$.\n $\\mathbb{E}[G_j^2] = \\sigma_j^2$.\n\n", "index": 19, "text": "\\begin{align*}\n \\mathbb{E}&[\\exp(\\lambda(-G_j^2 + \\mathbb{E}[G_j^2]))] = \\mathbb{E}[\\exp(\\lambda(-G_j^2 + \\sigma_j^2))] \\\\\n &= \\frac{\\exp(\\lambda\\sigma_j^2)}{\\sigma_j\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} \\exp(-\\lambda x^2) \\exp(\\dfrac{-x^2}{2\\sigma_j^2}) dx \\\\\n & =  \\exp(\\lambda\\sigma_j^2)/(\\sigma_j\\sqrt{2\\pi}) \\int_{-\\infty}^{\\infty} \\exp(-x^2 / 2(\\sigma_j^2/(1+ 2\\lambda \\sigma_j^2))) dx\\\\\n &= \\exp(\\lambda \\sigma_j^2)/\\sqrt{1 + 2\\lambda\\sigma_j^2}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}\" display=\"inline\"><mi>\ud835\udd3c</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle[\\exp(\\lambda(-G_{j}^{2}+\\mathbb{E}[G_{j}^{2}]))]=\\mathbb{E}[\\exp%&#10;(\\lambda(-G_{j}^{2}+\\sigma_{j}^{2}))]\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo>-</mo><msubsup><mi>G</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo>+</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>G</mi><mi>j</mi><mn>2</mn></msubsup><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mo>=</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo>-</mo><msubsup><mi>G</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo>+</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{\\exp(\\lambda\\sigma_{j}^{2})}{\\sigma_{j}\\sqrt{2\\pi}}\\int_{-%&#10;\\infty}^{\\infty}\\exp(-\\lambda x^{2})\\exp(\\dfrac{-x^{2}}{2\\sigma_{j}^{2}})dx\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c3</mi><mi>j</mi></msub><mo>\u2062</mo><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup></mstyle><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>-</mo><msup><mi>x</mi><mn>2</mn></msup></mrow><mrow><mn>2</mn><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>x</mi></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\exp(\\lambda\\sigma_{j}^{2})/(\\sigma_{j}\\sqrt{2\\pi})\\int_{-\\infty%&#10;}^{\\infty}\\exp(-x^{2}/2(\\sigma_{j}^{2}/(1+2\\lambda\\sigma_{j}^{2})))dx\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03c3</mi><mi>j</mi></msub><mo>\u2062</mo><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup></mstyle><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>/</mo><mn>2</mn></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>x</mi></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\exp(\\lambda\\sigma_{j}^{2})/\\sqrt{1+2\\lambda\\sigma_{j}^{2}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><msqrt><mrow><mn>1</mn><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mrow></msqrt></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n\n\n \n\n\n\n\nIn order to apply $\\psi$-UCB for the MAB framework where the rewards of the  arms are sampled from $-G_j^2$, we need to compute a function\n$\\psi(\\lambda)$ such that for all $\\lambda \\geq 0$,  $ \\ln \\mathbb{E}[\\exp(\\lambda(G_j^2 - \\mathbb{E}[G_j^2]))] \\leq \\psi(\\lambda) $\nand $\\ln \\mathbb{E}[\\exp(\\lambda(-G_j^2 + \\mathbb{E}[G_j^2]))] \\leq \\psi(\\lambda) $. $ \\mathbb{E}[\\exp(\\lambda(G_j^2 - \\mathbb{E}[G_j^2]))]$\nis not even defined for $\\lambda \\geq 1/(2\\sigma_j^2)$ and hence the function $\\psi(\\lambda)$ cannot be computed. Therefore $\\psi$-UCB cannot be \napplied to this framework.\n\\end{proof}\nIn our setting, $y_{kj} - \\textbf{w}^\\top \\textbf{x}_k$ follows a normal distribution and $-(y_{kj} - \\textbf{w}^\\top \\textbf{x}_k)^2$ \nhas a sub-exponential distribution which is heavy tailed. Therefore from Lemma \\ref{lemma:psi-ucb-not-possible},\nan upper confidence interval cannot be obtained using $\\psi$-UCB.\n\n\\subsubsection{Robust-UCB with Truncated Empirical Mean}\nTo devise upper confidence intervals for heavy tailed distributions,\nRobust UCB \\cite{Bubeck2012b} prescribes working with `robust' estimators such as a truncated empirical mean, \nwhere samples that lie beyond a carefully chosen range are discarded.\n\nThe necessary condition to be satisfied while applying Robust UCB is that the reward distribution of the arms should have\nmoments of order $1+ \\epsilon$ for some $\\epsilon \\in (0,1]$. \nSince the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ has finite variance, Robust UCB with the truncated empirical mean\ncan be used by setting $\\epsilon = 1$.\nAt round $t$, the truncated empirical mean of the samples, \nthe absolute value of which do not exceed $\\sqrt{ut/\\log \\delta^{-1}}$, is computed as,\n\n\n", "itemtype": "equation", "pos": 37077, "prevtext": "\nSimilar calculations also yield,\n\n", "index": 21, "text": "\\begin{align*}\n \\mathbb{E}&[\\exp(\\lambda(G_j^2 - \\mathbb{E}[G_j^2]))] \n = \\exp(-\\lambda \\sigma_j^2)/\\sqrt{1 -2\\lambda\\sigma_j^2}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}\" display=\"inline\"><mi>\ud835\udd3c</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle[\\exp(\\lambda(G_{j}^{2}-\\mathbb{E}[G_{j}^{2}]))]=\\exp(-\\lambda%&#10;\\sigma_{j}^{2})/\\sqrt{1-2\\lambda\\sigma_{j}^{2}}\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">[</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>G</mi><mi>j</mi><mn>2</mn></msubsup><mo>-</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msubsup><mi>G</mi><mi>j</mi><mn>2</mn></msubsup><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mo>=</mo><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><msqrt><mrow><mn>1</mn><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mrow></msqrt></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nwhere $\\xi_{ij} = -(y_{ij}- \\mu_w^\\top \\textbf{x}_i)^2$ and \n $\\mu_w$ is the estimator of $\\textbf{w}$ obtained from the variational inference algorithm. \n In Eqn \\ref{eqn:truncated-mean}, $n_j^c$ is the number of samples that are actually considered, $\\delta$ is the desired confidence on the \ndeviation of $\\hat{\\mu}_{t}^j$ from  $1/\\beta_j$ for all $j$, $u$ is an upper bound on $\\xi_{ij}^{1 +\\epsilon}$. \nFrom Lemma \\ref{lemma:var_upd_aysmptotics} $\\mu_w$ is an unbiased estimate for $\\textbf{w}$ and hence we use $\\mu_w$ \ninstead of $\\textbf{w}$. The parameter $\\delta$ can be tuned appropriately to get \ntight bounds on the regret.\nWe now describe the algorithm. \n\\\\\\hrule\n\\begin{algorithm} [h]\n \\caption{Robust UCB for selecting the annotators}\n \\label{alg:robust-ucb}\n \\KwIn{No. of annotators $m$, Unlabeled set $\\mathcal{U}$, Labeled set $\\mathcal{D}$, $n_j$, $n_j^c$, for $j = 1, \\cdots, m$}\n \n\n \n Set $\\mu_w, \\Lambda_w$ using variational inference procedure described earlier;\n \n $t := 0 $ \\;\n Set $\\hat{\\mu}_t^j$ for the\n annotators using Eqn (\\ref{eqn:truncated-mean})\\;\n \\While{ ( the learner has budget or the model has not attained the desired RMSE )}{\n \\begin{itemize}\n     \\item Choose an instance $\\textbf{x}_k = \n     {\\operatorname{arg\\,max}}_{\\textbf{x} \\in \\mathcal{U}} \\textbf{x}^\\top \\Lambda_w^{-1} \\textbf{x}$ ;\\\\\n   \\item Get a label $y_{kj^*}$ from an annotator $j^*$ such that $j^* \\in \\underset{1 \\leq j \\leq m}{{\\operatorname{arg\\,max}}} ~ \\hat{\\mu}_{t}^j + \\sqrt{32u (\\log t)/n_j} $  ;\\\\\n  \n  \n   \\item $t :=  t+1$ ; $n_{j^*} :=  n_{j^*} + 1$\n   ; $\\mathcal{D} :=  \\mathcal{D} \\cup \\{(\\textbf{x}_k,  y_{kj^*})\\}$ ;\n   \\item Run variational inference procedure described earlier \\\\and update $\\mu_w$;\n   \n   \\item If $(y_{kj^*}- \\mu_w^\\top \\textbf{x}_i)^2 < \\sqrt{ut/\\log \\delta^{-1}}$ \n   \\begin{itemize}\n     \\item $n_{j^*}^c := n_{j^*}^c + 1$ ;\n     \\item Update $ \\hat{\\mu}_t^{j*}$ using Eqn (\\ref{eqn:truncated-mean});\n   \\end{itemize}\n \\end{itemize}\n }\n\\end{algorithm}\n\\hrule\n\n\\begin{theorem}\n\\label{thm:regret-seq-A}\n  Regret-Seq$(\\text{Algo } \\ref{alg:robust-ucb},T) \\leq \\sum_{i:\\Delta_i>0} \\dfrac{32u \\log T}{\\Delta_i} + 5 \\Delta_i $.\n\\end{theorem}\n\\begin{proof}\nWe first prove that, with probability at least $1-\\delta$, \n\n", "itemtype": "equation", "pos": 38959, "prevtext": "\n\n\n \n\n\n\n\nIn order to apply $\\psi$-UCB for the MAB framework where the rewards of the  arms are sampled from $-G_j^2$, we need to compute a function\n$\\psi(\\lambda)$ such that for all $\\lambda \\geq 0$,  $ \\ln \\mathbb{E}[\\exp(\\lambda(G_j^2 - \\mathbb{E}[G_j^2]))] \\leq \\psi(\\lambda) $\nand $\\ln \\mathbb{E}[\\exp(\\lambda(-G_j^2 + \\mathbb{E}[G_j^2]))] \\leq \\psi(\\lambda) $. $ \\mathbb{E}[\\exp(\\lambda(G_j^2 - \\mathbb{E}[G_j^2]))]$\nis not even defined for $\\lambda \\geq 1/(2\\sigma_j^2)$ and hence the function $\\psi(\\lambda)$ cannot be computed. Therefore $\\psi$-UCB cannot be \napplied to this framework.\n\\end{proof}\nIn our setting, $y_{kj} - \\textbf{w}^\\top \\textbf{x}_k$ follows a normal distribution and $-(y_{kj} - \\textbf{w}^\\top \\textbf{x}_k)^2$ \nhas a sub-exponential distribution which is heavy tailed. Therefore from Lemma \\ref{lemma:psi-ucb-not-possible},\nan upper confidence interval cannot be obtained using $\\psi$-UCB.\n\n\\subsubsection{Robust-UCB with Truncated Empirical Mean}\nTo devise upper confidence intervals for heavy tailed distributions,\nRobust UCB \\cite{Bubeck2012b} prescribes working with `robust' estimators such as a truncated empirical mean, \nwhere samples that lie beyond a carefully chosen range are discarded.\n\nThe necessary condition to be satisfied while applying Robust UCB is that the reward distribution of the arms should have\nmoments of order $1+ \\epsilon$ for some $\\epsilon \\in (0,1]$. \nSince the distribution of $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$ has finite variance, Robust UCB with the truncated empirical mean\ncan be used by setting $\\epsilon = 1$.\nAt round $t$, the truncated empirical mean of the samples, \nthe absolute value of which do not exceed $\\sqrt{ut/\\log \\delta^{-1}}$, is computed as,\n\n\n", "index": 23, "text": "\\begin{equation}\n\\label{eqn:truncated-mean}\n\\hat{\\mu}_{t}^j =\\dfrac{1}{n_j^c}\\sum_{i:I_{ij}=1 } \\xi_{ij} \\;\\;\\; \\mathbbm{1}\\left(\n  |\\xi_{ij}| \\leq \\sqrt{ut/\\log \\delta^{-1}} \\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\hat{\\mu}_{t}^{j}=\\dfrac{1}{n_{j}^{c}}\\sum_{i:I_{ij}=1}\\xi_{ij}\\;\\;\\;\\mathbbm{%&#10;1}\\left(|\\xi_{ij}|\\leq\\sqrt{ut/\\log\\delta^{-1}}\\right)\" display=\"block\"><mrow><msubsup><mover accent=\"true\"><mi>\u03bc</mi><mo stretchy=\"false\">^</mo></mover><mi>t</mi><mi>j</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><msubsup><mi>n</mi><mi>j</mi><mi>c</mi></msubsup></mfrac><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi>I</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mrow></munder><msub><mi>\u03be</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mn mathvariant=\"double-struck\">\u2004\u2004\u20041</mn><mrow><mo>(</mo><mo stretchy=\"false\">|</mo><msub><mi>\u03be</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msqrt><mrow><mrow><mi>u</mi><mo>\u2062</mo><mi>t</mi></mrow><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><msup><mi>\u03b4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></msqrt><mo>)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nLet $C_t= \\sqrt{ut/\\log \\delta^{-1}}$. Let the random variable \n$\\xi$ = $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$. As mentioned earlier $\\xi^{1+\\epsilon} = \\xi^2 < u$. Note that \n\n", "itemtype": "equation", "pos": 41421, "prevtext": "\nwhere $\\xi_{ij} = -(y_{ij}- \\mu_w^\\top \\textbf{x}_i)^2$ and \n $\\mu_w$ is the estimator of $\\textbf{w}$ obtained from the variational inference algorithm. \n In Eqn \\ref{eqn:truncated-mean}, $n_j^c$ is the number of samples that are actually considered, $\\delta$ is the desired confidence on the \ndeviation of $\\hat{\\mu}_{t}^j$ from  $1/\\beta_j$ for all $j$, $u$ is an upper bound on $\\xi_{ij}^{1 +\\epsilon}$. \nFrom Lemma \\ref{lemma:var_upd_aysmptotics} $\\mu_w$ is an unbiased estimate for $\\textbf{w}$ and hence we use $\\mu_w$ \ninstead of $\\textbf{w}$. The parameter $\\delta$ can be tuned appropriately to get \ntight bounds on the regret.\nWe now describe the algorithm. \n\\\\\\hrule\n\\begin{algorithm} [h]\n \\caption{Robust UCB for selecting the annotators}\n \\label{alg:robust-ucb}\n \\KwIn{No. of annotators $m$, Unlabeled set $\\mathcal{U}$, Labeled set $\\mathcal{D}$, $n_j$, $n_j^c$, for $j = 1, \\cdots, m$}\n \n\n \n Set $\\mu_w, \\Lambda_w$ using variational inference procedure described earlier;\n \n $t := 0 $ \\;\n Set $\\hat{\\mu}_t^j$ for the\n annotators using Eqn (\\ref{eqn:truncated-mean})\\;\n \\While{ ( the learner has budget or the model has not attained the desired RMSE )}{\n \\begin{itemize}\n     \\item Choose an instance $\\textbf{x}_k = \n     {\\operatorname{arg\\,max}}_{\\textbf{x} \\in \\mathcal{U}} \\textbf{x}^\\top \\Lambda_w^{-1} \\textbf{x}$ ;\\\\\n   \\item Get a label $y_{kj^*}$ from an annotator $j^*$ such that $j^* \\in \\underset{1 \\leq j \\leq m}{{\\operatorname{arg\\,max}}} ~ \\hat{\\mu}_{t}^j + \\sqrt{32u (\\log t)/n_j} $  ;\\\\\n  \n  \n   \\item $t :=  t+1$ ; $n_{j^*} :=  n_{j^*} + 1$\n   ; $\\mathcal{D} :=  \\mathcal{D} \\cup \\{(\\textbf{x}_k,  y_{kj^*})\\}$ ;\n   \\item Run variational inference procedure described earlier \\\\and update $\\mu_w$;\n   \n   \\item If $(y_{kj^*}- \\mu_w^\\top \\textbf{x}_i)^2 < \\sqrt{ut/\\log \\delta^{-1}}$ \n   \\begin{itemize}\n     \\item $n_{j^*}^c := n_{j^*}^c + 1$ ;\n     \\item Update $ \\hat{\\mu}_t^{j*}$ using Eqn (\\ref{eqn:truncated-mean});\n   \\end{itemize}\n \\end{itemize}\n }\n\\end{algorithm}\n\\hrule\n\n\\begin{theorem}\n\\label{thm:regret-seq-A}\n  Regret-Seq$(\\text{Algo } \\ref{alg:robust-ucb},T) \\leq \\sum_{i:\\Delta_i>0} \\dfrac{32u \\log T}{\\Delta_i} + 5 \\Delta_i $.\n\\end{theorem}\n\\begin{proof}\nWe first prove that, with probability at least $1-\\delta$, \n\n", "index": 25, "text": "\\begin{align}\n\\label{robust-estimator-assumption}\n\\hat{\\mu}_{t}^j \\leq  (-1/\\beta_j) + 4\\sqrt{u \\log \\delta^{-1}/n_j}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\mu}_{t}^{j}\\leq(-1/\\beta_{j})+4\\sqrt{u\\log\\delta^{-1}/n_{j}}\" display=\"inline\"><mrow><msubsup><mover accent=\"true\"><mi>\u03bc</mi><mo stretchy=\"false\">^</mo></mover><mi>t</mi><mi>j</mi></msubsup><mo>\u2264</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><msub><mi>\u03b2</mi><mi>j</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mrow><mn>4</mn><mo>\u2062</mo><msqrt><mrow><mi>u</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><msup><mi>\u03b4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>/</mo><msub><mi>n</mi><mi>j</mi></msub></mrow></mrow></mrow></msqrt></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 41733, "prevtext": "\nLet $C_t= \\sqrt{ut/\\log \\delta^{-1}}$. Let the random variable \n$\\xi$ = $-(y_{kj}-(\\textbf{w}^\\top \\textbf{x}_k))^2$. As mentioned earlier $\\xi^{1+\\epsilon} = \\xi^2 < u$. Note that \n\n", "index": 27, "text": "\\begin{align}\n\\mathbb{E}\\left[\\xi^2 \n\\mathbbm{1}_{ \\xi\\leq C_t}\\right]&=\\mathbb{E}\\left[|\\xi^2| \n\\mathbbm{1}_{ \\xi\\leq C_t}\\right] \\leq u \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}\\left[\\xi^{2}\\mathbbm{1}_{\\xi\\leq C_{t}}\\right]\" display=\"inline\"><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo>[</mo><mrow><msup><mi>\u03be</mi><mn>2</mn></msup><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mi>\u03be</mi><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mathbb{E}\\left[|\\xi^{2}|\\mathbbm{1}_{\\xi\\leq C_{t}}\\right]\\leq u\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><mo stretchy=\"false\">|</mo><msup><mi>\u03be</mi><mn>2</mn></msup><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mi>\u03be</mi><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo>]</mo></mrow></mrow><mo>\u2264</mo><mi>u</mi></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n\n\n\n\n\n\n\n\n\n\nEquation\\nobreakspace \\textup {(\\ref {holder-ineq})} arises due to Holder's inequality. Further,\n\n", "itemtype": "equation", "pos": 41884, "prevtext": "\n\n", "index": 29, "text": "\\begin{align}\n\\label{holder-ineq}\n\\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi| > C_t }]& \\leq \\mathbb{E}[|\\xi|^2]^{1/2}\n\\mathbb{E}[|\\mathbbm{1}_{ \\xi \\geq C_t}|^2]^{1/2} \\leq \\sqrt{u} (P\\{\\xi \\geq C_t\\})^{1/2} \\nonumber \\\\\n& \\leq \\sqrt{u}(\\mathbb{E}[\\xi^2]/C_t^2)^{1/2} = u/C_t  \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi|&gt;C_{t}}]\" display=\"inline\"><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\u03be</mi><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo></mrow><mo>&gt;</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\mathbb{E}[|\\xi|^{2}]^{1/2}\\mathbb{E}[|\\mathbbm{1}_{\\xi\\geq C%&#10;_{t}}|^{2}]^{1/2}\\leq\\sqrt{u}(P\\{\\xi\\geq C_{t}\\})^{1/2}\" display=\"inline\"><mrow><mo>\u2264</mo><mi>\ud835\udd3c</mi><msup><mrow><mo stretchy=\"false\">[</mo><mo stretchy=\"false\">|</mo><mi>\u03be</mi><msup><mo stretchy=\"false\">|</mo><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mi>\ud835\udd3c</mi><msup><mrow><mo stretchy=\"false\">[</mo><mo stretchy=\"false\">|</mo><msub><mn>\ud835\udfd9</mn><mrow><mi>\u03be</mi><mo>\u2265</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub><msup><mo stretchy=\"false\">|</mo><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>\u2264</mo><msqrt><mi>u</mi></msqrt><msup><mrow><mo stretchy=\"false\">(</mo><mi>P</mi><mrow><mo stretchy=\"false\">{</mo><mi>\u03be</mi><mo>\u2265</mo><msub><mi>C</mi><mi>t</mi></msub><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\sqrt{u}(\\mathbb{E}[\\xi^{2}]/C_{t}^{2})^{1/2}=u/C_{t}\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><msqrt><mi>u</mi></msqrt><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msup><mi>\u03be</mi><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow></mrow><mo>/</mo><msubsup><mi>C</mi><mi>t</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow><mo>=</mo><mrow><mi>u</mi><mo>/</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nThe first term in Eqn (\\ref{bernstein-eq}) arises as a consequence of Eqn (\\ref{holder-ineq}) and the remaining terms arise as a result of Bernstein's inequality with some simplification. Further algebraic simplification of Eqn (\\ref{bernstein-eq}) gives us Eqn (\\ref{robust-estimator-assumption}).\n\\\\For a MAB algorithm $A$ using $\\hat{\\mu}_t^j$ as an estimator\nfor $-1/\\beta_j$, the regret satisfies the following bound when $\\delta = T^{-2}$, where $T$ is the total time horizon of plays of the  MAB algorithm.\n\n", "itemtype": "equation", "pos": 42271, "prevtext": "\n\n\n\n\n\n\n\n\n\n\nEquation\\nobreakspace \\textup {(\\ref {holder-ineq})} arises due to Holder's inequality. Further,\n\n", "index": 31, "text": "\\begin{align}\n\\mathbb{E}&[\\xi] - \\frac{1}{n_j} \\sum_{t=1}^{n_j} \\xi_t \\mathbbm{1}_{[\\xi_t \\leq C_t]} = \\frac{1}{n_j}\\sum_{t=1}^{n_j}(\\mathbb{E}[\\xi]  - \\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi| \\leq C_t }]) \\nonumber\\\\\n&\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; + \\frac{1}{n_j}( \\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi| \\leq C_t }] -  \\xi_t \\mathbbm{1}_{[\\xi_t \\leq C_t]}) \\nonumber \\\\\n&=  \\frac{1}{n_j}\\sum_{t=1}^{n_j}\\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi| > C_t }] +  \\frac{1}{n_j}( \\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi| \\leq C_t }] -  \\xi_t \\mathbbm{1}_{[\\xi_t \\leq C_t]}) \\nonumber \\\\\n&\\leq \\frac{u}{C_t} + \\sqrt{\\frac{2u \\log \\delta^{-1}}{n_j}}\n + \\frac{2C_n \\log \\delta^{-1}}{3n_j}\n \\label{bernstein-eq}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}\" display=\"inline\"><mi>\ud835\udd3c</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle[\\xi]-\\frac{1}{n_{j}}\\sum_{t=1}^{n_{j}}\\xi_{t}\\mathbbm{1}_{[\\xi_{%&#10;t}\\leq C_{t}]}=\\frac{1}{n_{j}}\\sum_{t=1}^{n_{j}}(\\mathbb{E}[\\xi]-\\mathbb{E}[%&#10;\\xi\\mathbbm{1}_{|\\xi|\\leq C_{t}}])\" display=\"inline\"><mrow><mrow><mrow><mo stretchy=\"false\">[</mo><mi>\u03be</mi><mo stretchy=\"false\">]</mo></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mi>j</mi></msub></munderover></mstyle><mrow><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub><mo stretchy=\"false\">]</mo></mrow></msub></mrow></mrow></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mi>j</mi></msub></munderover></mstyle><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>\u03be</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\u03be</mi><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex31.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\frac{1}{n_{j}}(\\mathbb{E}[\\xi\\mathbbm{1}_{|%&#10;\\xi|\\leq C_{t}}]-\\xi_{t}\\mathbbm{1}_{[\\xi_{t}\\leq C_{t}]})\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2004</mi><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003\u2002</mo><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\u03be</mi><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub><mo stretchy=\"false\">]</mo></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex32.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{n_{j}}\\sum_{t=1}^{n_{j}}\\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi%&#10;|&gt;C_{t}}]+\\frac{1}{n_{j}}(\\mathbb{E}[\\xi\\mathbbm{1}_{|\\xi|\\leq C_{t}}]-\\xi_{t}%&#10;\\mathbbm{1}_{[\\xi_{t}\\leq C_{t}]})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mi>j</mi></msub></munderover></mstyle><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\u03be</mi><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo></mrow><mo>&gt;</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\u03be</mi><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo stretchy=\"false\">[</mo><msub><mi>\u03be</mi><mi>t</mi></msub><mo>\u2264</mo><msub><mi>C</mi><mi>t</mi></msub><mo stretchy=\"false\">]</mo></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\frac{u}{C_{t}}+\\sqrt{\\frac{2u\\log\\delta^{-1}}{n_{j}}}+\\frac{%&#10;2C_{n}\\log\\delta^{-1}}{3n_{j}}\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>u</mi><msub><mi>C</mi><mi>t</mi></msub></mfrac></mstyle><mo>+</mo><msqrt><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><msup><mi>\u03b4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><msub><mi>n</mi><mi>j</mi></msub></mfrac></mstyle></msqrt><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>C</mi><mi>n</mi></msub><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><msup><mi>\u03b4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mrow><mn>3</mn><mo>\u2062</mo><msub><mi>n</mi><mi>j</mi></msub></mrow></mfrac></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n Proof of Eqn (\\ref{robust-ucb-regret}) involves bounding the number of trials where a sub-optimal arm is pulled, similar to the technique in \\cite{UCBAuer2002,Bubeck2012b}. A pull of a sub-optimal arm indicates one of the following three events occur:(1) The mean corresponding to the best arm is underestimated (2) the mean corresponding to a sub-optimal arm is over-estimated (3) the mean corresponding to the sub-optimal arm is close to that of the optimal arm. Next we bound each of the three events and use union bound to get the final result.  Eqn (\\ref{robust-estimator-assumption}) is used to get bounds for events (1) and (2). \nRegret-Seq$(\\text{Algo } 1, T) = $ Regret-MAB$(\\text{Robust-UCB},T )$ from \\cite{Neufeld14}. \n\\end{proof}\n\\begin{theorem}\n\\label{thm:wasteage}\n The expected number of samples discarded by the Robust UCB algorithm in $t$ trials of the algorithm,\n $\\mathbb{E}[W(t)]\\leq 4 (\\log t)^2$. \n\\end{theorem}\n\\begin{proof}\\let\\qed\\relax\n As per the robust UCB algorithm, at the $t^{th}$ time instant, the probability of the random variable $ \\xi = (y_{kj} - \\textbf{w}^\\top \\textbf{x}_k))^2$ exceeding \n $(ut/(4\\log t))^{1/(1+\\epsilon)}$,\n \n", "itemtype": "equation", "pos": 43458, "prevtext": "\nThe first term in Eqn (\\ref{bernstein-eq}) arises as a consequence of Eqn (\\ref{holder-ineq}) and the remaining terms arise as a result of Bernstein's inequality with some simplification. Further algebraic simplification of Eqn (\\ref{bernstein-eq}) gives us Eqn (\\ref{robust-estimator-assumption}).\n\\\\For a MAB algorithm $A$ using $\\hat{\\mu}_t^j$ as an estimator\nfor $-1/\\beta_j$, the regret satisfies the following bound when $\\delta = T^{-2}$, where $T$ is the total time horizon of plays of the  MAB algorithm.\n\n", "index": 33, "text": "\\begin{align}\n\\label{robust-ucb-regret} \n \\text{Regret-MAB(}A,T) \\leq \\sum_{i:\\Delta_i>0} \\dfrac{32u \\log T}{\\Delta_i} + 5 \\Delta_i .\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{Regret-MAB(}A,T)\\leq\\sum_{i:\\Delta_{i}&gt;0}\\dfrac{32u\\log T}{%&#10;\\Delta_{i}}+5\\Delta_{i}.\" display=\"inline\"><mrow><mtext>Regret-MAB(</mtext><mi>A</mi><mo>,</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo>\u2264</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo></mstyle><msub><mi/><mrow><mi>i</mi><mo>:</mo><mrow><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub><mo>&gt;</mo><mn>0</mn></mrow></mrow></msub><mstyle displaystyle=\"true\"><mfrac><mrow><mn>32</mn><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mi>T</mi></mrow></mrow><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mfrac></mstyle><mo>+</mo><mn>5</mn><mi mathvariant=\"normal\">\u0394</mi><msub><mi/><mi>i</mi></msub><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\nThe number of samples discarded upto a time $n$ is \n\n", "itemtype": "equation", "pos": 44771, "prevtext": "\n Proof of Eqn (\\ref{robust-ucb-regret}) involves bounding the number of trials where a sub-optimal arm is pulled, similar to the technique in \\cite{UCBAuer2002,Bubeck2012b}. A pull of a sub-optimal arm indicates one of the following three events occur:(1) The mean corresponding to the best arm is underestimated (2) the mean corresponding to a sub-optimal arm is over-estimated (3) the mean corresponding to the sub-optimal arm is close to that of the optimal arm. Next we bound each of the three events and use union bound to get the final result.  Eqn (\\ref{robust-estimator-assumption}) is used to get bounds for events (1) and (2). \nRegret-Seq$(\\text{Algo } 1, T) = $ Regret-MAB$(\\text{Robust-UCB},T )$ from \\cite{Neufeld14}. \n\\end{proof}\n\\begin{theorem}\n\\label{thm:wasteage}\n The expected number of samples discarded by the Robust UCB algorithm in $t$ trials of the algorithm,\n $\\mathbb{E}[W(t)]\\leq 4 (\\log t)^2$. \n\\end{theorem}\n\\begin{proof}\\let\\qed\\relax\n As per the robust UCB algorithm, at the $t^{th}$ time instant, the probability of the random variable $ \\xi = (y_{kj} - \\textbf{w}^\\top \\textbf{x}_k))^2$ exceeding \n $(ut/(4\\log t))^{1/(1+\\epsilon)}$,\n \n", "index": 35, "text": "\\begin{align*}\n  P(\\xi &> (ut/(4\\log t))^{1/(1+\\epsilon)}) = P(\\xi^{1+\\epsilon} > ut/(4 \\log t)) \\\\\n  & \\leq    \\dfrac{\\mathbb{E}[\\xi]^{1+\\epsilon} 4 \\log t }{ut} \\text{ (by Markov inequality)} \\\\\n  & \\leq 4 \\log t/t\n \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\xi\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03be</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&gt;(ut/(4\\log t))^{1/(1+\\epsilon)})=P(\\xi^{1+\\epsilon}&gt;ut/(4\\log t))\" display=\"inline\"><mrow><mo>&gt;</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mi>t</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mn>4</mn><mi>log</mi><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mi>\u03f5</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mi>P</mi><mo stretchy=\"false\">(</mo><msup><mi>\u03be</mi><mrow><mn>1</mn><mo>+</mo><mi>\u03f5</mi></mrow></msup><mo>&gt;</mo><mi>u</mi><mi>t</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mn>4</mn><mi>log</mi><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex34.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\dfrac{\\mathbb{E}[\\xi]^{1+\\epsilon}4\\log t}{ut}\\text{ (by %&#10;Markov inequality)}\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">[</mo><mi>\u03be</mi><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03f5</mi></mrow></msup><mo>\u2062</mo><mn>4</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mi>t</mi></mrow></mrow><mrow><mi>u</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mtext>\u00a0(by Markov inequality)</mtext></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex35.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq 4\\log t/t\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mn>4</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mi>t</mi><mo>/</mo><mi>t</mi></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": " \n\\end{proof}\n\n\\section{The Case of Strategic Annotators}\n\\label{sec:payment_strategic}\nTill now, we have inherently assumed that annotators are non-strategic. Now we look at the scenario where an annotator who has been allocated an instance\n is strategic about how much effort to put in. For this, we assume that, for each annotator $j$, the precision $\\beta_j$ introduced while labeling an instance is proportional to the effort put in by annotator $j$.\nWe now refer to the effort as $\\beta_j$ for simplicity. \nIt is best for the learning algorithm when the annotator $j$ puts in as much effort (high $\\beta_j$) as possible thereby reducing the\nvariance in the labeled data. A given level of effort incurs a cost to the annotator $c_j(\\beta_j)$. We assume that $c_j(.)$ is a non-negative strictly increasing function of $\\beta_j$ with $c_j(0) = 0$. The exact form of $c_j(.)$ is unknown to the learner.\nFrom the annotator's point of view, a high value of effort $\\beta_j$ might incur a higher cost and thus \nthe annotator might not be motivated to put \nin higher effort.\n\\par \nIn order to take into account the strategic play of the human annotators, we appeal to mechanism design techniques. Mechanism design comprises allocation \nand payment rules. \nThe mechanism is to be designed to meet at least the following objectives.\n\\begin{definition}{ Individual Rationality (IR):}\n A mechanism is IR if the expected utility of every participating agent is non-negative.\n\\end{definition}\n\\begin{definition}{ Quality Compatibility:}\nWe say a mechanism is `quality compatible' at level\n$\\underline{\\beta}$ if it induces every participating agent \nto operate under precision $\\beta \\geq \\underline{\\beta}$.\n\\end{definition}\nWe now present a mechanism design solution which meets the above design goals.\\\\\n\\textbf{Proposed Mechanism:}\n\n (1) We use Algorithm \\ref{alg:robust-ucb} as the allocation rule. \n (2)The payment rule for annotator $j$ when his estimated precision is $\\hat{\\beta}_j$ is,  \n \n", "itemtype": "equation", "pos": -1, "prevtext": "\nThe number of samples discarded upto a time $n$ is \n\n", "index": 37, "text": "\\begin{align*}\n \\mathbb{E}[W(n)]&= \\sum_{t=1}^n \\mathbb{E}[\\mathbbm{1}[Z_t > (ut/(4 \\log t))^{\\epsilon/(1+\\epsilon)}]] \\nonumber\\\\\n & = \\sum_{t=1}^n 4 \\log t/t \\leq 4 (\\log n)^2 \\;\\;\\;\\hfill \\square\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex36.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbb{E}[W(n)]\" display=\"inline\"><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>W</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex36.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{t=1}^{n}\\mathbb{E}[\\mathbbm{1}[Z_{t}&gt;(ut/(4\\log t))^{%&#10;\\epsilon/(1+\\epsilon)}]]\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mi>\ud835\udd3c</mi><mrow><mo stretchy=\"false\">[</mo><mn>\ud835\udfd9</mn><mrow><mo stretchy=\"false\">[</mo><msub><mi>Z</mi><mi>t</mi></msub><mo>&gt;</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mi>t</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mn>4</mn><mi>log</mi><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>\u03f5</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mi>\u03f5</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo stretchy=\"false\">]</mo></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex37.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{t=1}^{n}4\\log t/t\\leq 4(\\log n)^{2}\\;\\;\\;\\hfill\\square\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><mn>4</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mi>t</mi><mo>/</mo><mi>t</mi></mrow></mrow></mrow></mrow><mo>\u2264</mo><mrow><mn>4</mn><mo>\u2062</mo><mpadded width=\"+8.4pt\"><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>log</mi><mo>\u2061</mo><mi>n</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mpadded><mo>\u2062</mo><mi mathvariant=\"normal\">\u25a1</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06750.tex", "nexttext": "\n We assume that the learner has a finite budget $B$ per example.\nAlso the annotators are expected to have precisions in the\nrange $[\\underline{\\beta}, \\overline{\\beta} ]$. An effort level in this expected range fetches a corresponding proportional payment to the annotator. If an annotator puts in \nan effort less than $\\underline{\\beta}$, he does not receive any payment.  An effort level higher than $\\overline{\\beta}$ fetches an annotator a maximum\npayment of $B$, due to the limitation on the willingness of the learner.\n\n\\textbf{Annotator's optimization problem:}\n\nThe utility of the annotator when operating at the effort level $\\beta_j$ is \n$U(\\beta_j) =  P(\\beta_j) - c_j (\\beta_j)$. The optimal effort for the annotator, \n$\\beta_j^* = \\underset{\\beta_j}{\\text{argmax}} \\quad U(\\beta_j)  $.\n\\begin{theorem}{}\n\\label{thm:ir-ic-payment}\n The proposed mechanism is IR and quality compatible. \n\\end{theorem}\n\\begin{proof}\\let\\qed\\relax\n\n\\begin{figure}\n\\centering\n   \\includegraphics[scale=0.55]{fig_v3.pdf}\n    \\caption{Realizations of $c_j(\\beta_j)$ in relation to the payment rule $P(\\beta_j)$  }\n   \\label{fig:ic-proof}\n\\end{figure}\nThe payment scheme is individually rational as annotators participate only when $P(\\beta_j) > c_j(\\beta_j)$ in that case, they obtain a positive utility.\nThe utility is therefore non-negative and hence the mechanism is IR.\n\nIn order to prove that the payment scheme is quality compatible, we consider the\nthree possible realizations of $c_j(\\beta_j)$ in relation to the payment rule $P(\\beta_j)$.\n\\begin{enumerate}\n \\item There exists no $\\beta_j$ for which $P(\\beta_j) > c_j(\\beta_j)$. In this scenario, an annotator will choose to not participate,\n as there is clearly no benefit from participation. The cost function $c_1(\\beta)$ in Figure\\nobreakspace \\ref {fig:ic-proof} captures this.\n \\item There exists some $\\beta_j$ such that $ \\underline{\\beta}< \\beta_j \\leq \\overline{\\beta}$, for which $P(\\beta_j) > c_j(\\beta_j)$ and the maximum utility \n is attained at $\\beta_{j^*}$, such that, $ \\underline{\\beta} <\\beta_{j^*} < \\overline{\\beta}$. The cost function $c_2(\\beta)$ in  Figure\\nobreakspace \\ref {fig:ic-proof} demonstrates this scenario where an effort $\\beta_2 > \\underline{\\beta}$ maximizes his utility. \n \\item There exists $\\beta_j$ such that $ \\underline{\\beta} < \\beta_j\\leq \\overline{\\beta}$, for which  $P(\\beta_j) > c_j(\\beta_j)$ and the maximum utility \n is attained at $\\beta_{j^*} = \\overline{\\beta}$.\n The cost function $c_3(\\beta)$ in  Figure\\nobreakspace \\ref {fig:ic-proof} demonstrates this.\\hfill$\\square$\n\\end{enumerate}\n\\end{proof}\n\n \\section{Experimental Results}\n \\label{sec:experiments}\n\n We conducted experiments on three real world datasets from the UCI repository  \\cite{Lichman:2013} - Housing, Redwine and Whitewine, the details of which are provided in Table \\ref{tab:dataset-detail}.\nTo simulate the annotators, we added zero-mean Gaussian noise to the output variables.\n$1/\\sqrt{\\beta_j}$ values of the annotators were randomly chosen from two sets of intervals\n$U1 = [0.1, 1]$ and $U2 = [1,2]$. \n\nAnnotators with $1/\\sqrt{\\beta_j}$  chosen from interval $U1$ are clearly better than those chosen from $U2$.\n\n     \\begin{figure}[t]\n \n      \\begin{subfigure}{0.49\\linewidth}\n        \\includegraphics[height=3cm]{whitewine_rmse_new_vi.pdf}\n          \\subcaption{ }\n        \\label{fig:whitewine_rmse}\n            \\end{subfigure}\n              \\begin{subfigure}{0.49\\linewidth}\n        \n        \n        \\includegraphics[height=3cm]{whitewine_regret_new_vi.pdf}\n        \\subcaption{ }\n        \\label{fig:payment_whitewine_regret}\n    \\end{subfigure} \\\\    \n    \\begin{subfigure}{0.49\\linewidth}\n        \n       \n       \\includegraphics[height=3cm]{housing_rmse_new_vi.pdf}\n       \\subcaption{ }\n        \\label{fig:housing_rmse}\n    \\end{subfigure}\n        \\begin{subfigure}{0.49\\linewidth}\n        \n        \n        \\includegraphics[height=3cm]{housing_regret_new_vi.pdf}\n        \\subcaption{ }\n         \\label{fig:payment_housing_regret}\n    \\end{subfigure}\n    \\\\\n   \n         \\begin{subfigure}{0.49\\linewidth}\n         \\includegraphics[height=3cm]{redwine_rmse_new_vi.pdf}\n         \\subcaption{ }\n         \\label{fig:redwine_rmse}\n     \\end{subfigure}\n         \n\n\n\n\n\n\n       \\begin{subfigure}{0.49\\linewidth}\n         \n         \n         \\includegraphics[height=3cm]{redwine_regret_new_vi.pdf}\n \\subcaption{ }\n         \\label{fig:payment_redwine_regret}\n         \\end{subfigure}    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\vspace{-3mm}\n    \\caption{Active learning results on various datasets.\n The legends for the figures in\n    each row are provided on the corresponding figure in the first row}\n    \\label{fig:al-plots}\n    \\vspace{-5mm}\n    \\end{figure}\n    \n    \\subsection{Data Preprocessing}\nWe worked with a transformation $\\Phi: {\\mathbb{R}}^d \\rightarrow {\\mathbb{R}}^d$ of the original data matrix $\\textbf{X}$. For the Housing and the Whitewine datasets, we worked with the following non-linear transformation\n$\n \\label{sigmoid-transform}\n \\Phi_b(\\textbf{x}; R_b, s) = 1/(1+\\exp(- \\left \\Vert\\textbf{x} - R_b\\right \\Vert/s))\n$, $b = 1 \\rightarrow d $\nwhereas, for the Redwine dataset, the\noriginal data matrix $\\bold{X}$ was used.\nThe value of $s$ was fixed using cross-validation.\nThe parameters $R_b$ for $b = 1 \\rightarrow d$,  were set as the $k$-means cluster representatives of the dataset.\nAll the features were normalized.\n\n \\subsection{Performance of Bayesian Parametric Model}\nWe compared our Bayesian parameter estimation algorithm (without active learning) with\n MLE  \\cite{Raykar2012JMLR} and Gaussian Process based method  \\cite{groot}. From\n the complete dataset $\\mathcal{C}$, a random $30\\%$ of data was used as test dataset $\\mathcal{T}$. \n We refer to the set $\\mathcal{C} \\setminus \\mathcal{T}$ as the\n full pool of training instances $\\mathcal{F}$. 50 annotators were used, out of which,  for $40$ of them,\n the parameter $1/\\sqrt{\\beta_j}$ was chosen from $U1$,\nand for the remaining, from $U2$. The parameters of the Bayesian model described earlier \nwere learnt\n using the full pool $\\mathcal{F}$ labeled by the 50 annotators, as the training data.\n The experiments were repeated with 10 different splits of the data.\n We report the Average Root Mean Square Error (RMSE) scores on the test set $\\mathcal{T}$. The RMSE for the test dataset containing\n $N_\\text{test}$ instances\n with true output vector $\\bold{z}$ and predicted output vector $\\hat{\\bold{y}}$, is calculated as,\n$\n  \\text{RMSE}(\\hat{\\bold{y}};\\bold{z}) = \\sqrt{ \\sum\\nolimits_{i=1}^{N_\\text{test}} \\left(\\hat{\\bold{y}}_i -\n  \\bold{z}_i\\right)^2 /N_\\text{test}}\n$.\nOur results are provided in Table \\ref{tab:var_inf_results_real_bad_annot_more_data}. Our method consistently outperforms Groot's method and compares well with MLE. \n\\begin{remark}\nWith increasing size of the dataset, the performance of our model approaches MLE (as demonstrated in Table\\nobreakspace \\ref {tab:var_inf_results_real_bad_annot_more_data}, Whitewine dataset). This is consistent with the result that with increased size of training data set, Bayesian estimates perform similar to MLE \\cite{BishopBook}. It further shows the efficacy of our learning scheme explained in  Section\\nobreakspace \\ref {sec:bayesian-lr}. The additional advantage that our model offers is the suitability to further apply active learning methods, which is not offered by other learning schemes like MLE\\cite{Raykar2012JMLR} and Groot et al \\cite{Ristovski2010}. \n\\end{remark}\n\n\n\n\n\n \\begin{table}[ht]\n\n \\begin{subtable}{0.48\\textwidth}\n  \\centering\n  \\begin{tabular}{|l|l|l|l|}\n  \\hline  Dataset & Size & $d$ &  $\\Phi$ \\\\\\hline\n  Housing & 506  & 12 & Nonlinear \\\\\n  \n  Redwine &  1599 & 11 & Linear \\\\\n  Whitewine & 4898 & 11 & Nonlinear \\\\\n   \\hline\n  \\end{tabular}\n   \\subcaption{Details of datasets}\n\\label{tab:dataset-detail}\n \\end{subtable}\n\\begin{subtable}{0.48\\textwidth}\n\n  \n \n \n   \n\n\\centering\n  \\begin{tabular}{|l|l|l|l|}\n  \\hline  Dataset & Our method & MLE & Groot et al.\\\\\\hline\n  Housing & \\textbf{4.7209} & 4.93834  & 5.998169 \\\\\n \n  Redwine & \\textbf{0.51490}  & 0.65868\t & 0.67354 \\\\\n  Whitewine & \\textbf{0.75740} & 0.75748\t&  1.235 \\\\\n   \\hline\n  \\end{tabular}\n\n \n \\subcaption{Average test RMSE values when the whole dataset is used (without active learning). `Our method' refers to the variational inference based learning scheme explained in Section\\nobreakspace \\ref {sec:bayesian-lr}}\n   \\label{tab:var_inf_results_real_bad_annot_more_data}\n\n \n \\end{subtable}\n \\vspace{-3mm}\n  \\caption{Details of datasets and performance of the model}\n  \\vspace{-2mm}\n \\end{table}\n \n \n\\subsection{Active Learning Experiments}\nWe now describe our experiments with the active learning criteria.\n\n\n\n\\label{sec:AL_expts}\n In order to test the results of active learning on linear regression, we used the set $\\mathcal{T}$ as the test dataset as in the previous case.\n  Initially, only 10 instances from $\\mathcal{F}$ labeled by all annotators were used as the training set $\\mathcal{D}$.\n $\\mathcal{F} \\setminus \\mathcal{D}$ was used as the unlabeled\n  set $\\mathcal{U}$.   \n At every step of active learning, the label $y_{kj^*}$ of one instance $\\textbf{x}_k$ was procured from an annotator $j^*$,\n chosen using Algorithm \\ref{alg:robust-ucb}. The model was relearnt using the new training set\n $\\mathcal{D} = \\mathcal{D} \\cup \\{(\\textbf{x}_k, y_{kj^*}) \\}$.\n The RMSE was calculated on $\\mathcal{T}$ and the results were  plotted at every step. We also plotted the regret \n for Algorithm \\ref{alg:robust-ucb} at \n every step.\n The experiments were repeated for 10 different splits of the dataset. The test RMSE when the set $\\mathcal{F}$ was used for training (so that $\\mathcal{D} = \\mathcal{F}$) was also plotted.  This error is the best achievable error in the crowdsourcing scenario. \\\\\n To the best of our knowledge, our work is the first attempt towards active learning for regression from the crowd and therefore there are no other baselines in the literature to compare our method against.\n However we have used the following baselines for comparison:\\\\\n(1)Random: Random selection of instances and annotators.\\\\\n(2)Instance: Algorithm \\ref{alg:robust-ucb} for selecting the instances and random selection of annotators.\\\\\n(3)Single Source AL: The labels were provided by a single source with negligible noise. Active selection of instances was performed using uncertainty sampling.  \n The RMSE and regret plots are provided in Figure \\ref{fig:al-plots}. \nClearly the Robust UCB strategy outperforms `Random' as well as `Instance' with respect to RMSE as well as regret\n and approaches the `Single Source AL' with fewer number of labeled examples.  \n\n \\begin{remark}\n Our active learning algorithm demonstrates a superior performance with just a few additional labels (Figure\\nobreakspace \\ref {fig:al-plots}).\nA similar trend was observed for the rest of the curve, which was omitted in the plots for the sake of clarity. \n \\end{remark}\n \n\\section{Conclusions and Future Work}\nWe set up a Bayesian framework to infer the parameters of linear regression using crowds. As closed form Bayesian solution is intractable, we used approximation schemes. \nTo improve this initially learnt regression model, we used various active learning techniques \nand studied their theoretical foundations. We  established the connections with MAB algorithms and  explored the use of\nRobust UCB for annotator selection in active learning, providing theoretical guarantees and also performing a wastage analysis.\nNext, we introduced a payment scheme for annotators to\n ensure that they put in their best efforts while labeling the data. \n\n\nOur experiments on real data show the efficacy of our techniques.   \n\n\\par\nOur approach of Bayesian learning, MAB algorithm for annotator selection, uncertainty sampling for instance selection and design of quality compatible mechanisms to elicit best efforts from crowd workers is applicable for a wide range of tasks like classification, ordinal regression etc. It would be interesting to study the suitability of various MAB algorithms depending on the form of the distributions used to model the annotators' qualities.\n\nModeling the subjectivity of the annotators, their dynamic entry and exit, and the design of incentives in these scenarios is also challenging.\n\n\n\n\n\n\\newpage\n\n\\bibliographystyle{abbrvnat}\n\\bibliography{IncentiveALRegression_V15}  \n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 47256, "prevtext": " \n\\end{proof}\n\n\\section{The Case of Strategic Annotators}\n\\label{sec:payment_strategic}\nTill now, we have inherently assumed that annotators are non-strategic. Now we look at the scenario where an annotator who has been allocated an instance\n is strategic about how much effort to put in. For this, we assume that, for each annotator $j$, the precision $\\beta_j$ introduced while labeling an instance is proportional to the effort put in by annotator $j$.\nWe now refer to the effort as $\\beta_j$ for simplicity. \nIt is best for the learning algorithm when the annotator $j$ puts in as much effort (high $\\beta_j$) as possible thereby reducing the\nvariance in the labeled data. A given level of effort incurs a cost to the annotator $c_j(\\beta_j)$. We assume that $c_j(.)$ is a non-negative strictly increasing function of $\\beta_j$ with $c_j(0) = 0$. The exact form of $c_j(.)$ is unknown to the learner.\nFrom the annotator's point of view, a high value of effort $\\beta_j$ might incur a higher cost and thus \nthe annotator might not be motivated to put \nin higher effort.\n\\par \nIn order to take into account the strategic play of the human annotators, we appeal to mechanism design techniques. Mechanism design comprises allocation \nand payment rules. \nThe mechanism is to be designed to meet at least the following objectives.\n\\begin{definition}{ Individual Rationality (IR):}\n A mechanism is IR if the expected utility of every participating agent is non-negative.\n\\end{definition}\n\\begin{definition}{ Quality Compatibility:}\nWe say a mechanism is `quality compatible' at level\n$\\underline{\\beta}$ if it induces every participating agent \nto operate under precision $\\beta \\geq \\underline{\\beta}$.\n\\end{definition}\nWe now present a mechanism design solution which meets the above design goals.\\\\\n\\textbf{Proposed Mechanism:}\n\n (1) We use Algorithm \\ref{alg:robust-ucb} as the allocation rule. \n (2)The payment rule for annotator $j$ when his estimated precision is $\\hat{\\beta}_j$ is,  \n \n", "index": 39, "text": "\\begin{align}\n    P(\\hat{\\beta}_j)= B \\min \\left\\lbrace 1, \\max \\left\\lbrace 0,  \\left( \\frac{\\hat{\\beta}_j -\\underline{\\beta}}{\\overline{\\beta} -\\underline{\\beta}} \\right)\\right \\rbrace \\right \\rbrace\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\hat{\\beta}_{j})=B\\min\\left\\{1,\\max\\left\\{0,\\left(\\frac{\\hat{%&#10;\\beta}_{j}-\\underline{\\beta}}{\\overline{\\beta}-\\underline{\\beta}}\\right)\\right%&#10;\\}\\right\\}\" display=\"inline\"><mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03b2</mi><mo stretchy=\"false\">^</mo></mover><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>B</mi><mo>\u2062</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>0</mn><mo>,</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mover accent=\"true\"><mi>\u03b2</mi><mo stretchy=\"false\">^</mo></mover><mi>j</mi></msub><mo>-</mo><munder accentunder=\"true\"><mi>\u03b2</mi><mo>\u00af</mo></munder></mrow><mrow><mover accent=\"true\"><mi>\u03b2</mi><mo>\u00af</mo></mover><mo>-</mo><munder accentunder=\"true\"><mi>\u03b2</mi><mo>\u00af</mo></munder></mrow></mfrac></mstyle><mo>)</mo></mrow><mo>}</mo></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}]