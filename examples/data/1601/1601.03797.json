[{"file": "1601.03797.tex", "nexttext": "\nWhere $\\phi$ is a convex function in $\\theta$.\nFor example, in a linear regression $\\phi$ is:\n", "itemtype": "equation", "pos": 9294, "prevtext": "\n\n\n\n\n\n\n\\newtheorem{theorem}{Theorem}\n\\newtheorem{example}{Example}\n\\newtheorem{definition}{Definition}\n\\newtheorem{problem}{Problem}\n\\newtheorem{property}{Property}\n\\newtheorem{proposition}{Proposition}\n\\newtheorem{lemma}{Lemma}\n\\newtheorem{corollary}{Corollary}\n\n\n\n\n\n\n\n\\newcommand{\\specialcell}[2][c]{   \\begin{tabular}[#1]{@{}c@{}}#2\\end{tabular}}\n\n\n\n\n\n\\pagestyle{plain}\n\n\n\\title{ActiveClean: Interactive Data Cleaning While Learning Convex Loss Models}\n\n\\numberofauthors{1}\n\\author{\\large Sanjay Krishnan, Jiannan Wang, Eugene Wu{$\\,^\\dag$}, Michael J. Franklin, Ken Goldberg \\\\\n\\vspace{.2em}\\affaddr{\\large UC Berkeley, ~~ $^\\dag$Columbia University} \\\\\n\\vspace{.1em}\\affaddr{\\large \\{sanjaykrishnan, jnwang, franklin, goldberg\\}@berkeley.edu}\\\\\n\\affaddr{\\large ewu@cs.columbia.edu}\n}\n\n\n\n\n\n\\maketitle\n\n\\begin{abstract}\nData cleaning is often an important step to ensure that predictive models, such as regression and classification, are not affected by systematic errors such as inconsistent, out-of-date, or outlier data.\n\nIdentifying dirty data is often a manual and iterative process, and can be challenging on large datasets.\nHowever, many data cleaning workflows can introduce subtle biases into the training processes due to violation of independence assumptions.\nWe propose {ActiveClean\\xspace}, a progressive cleaning approach where the model is updated incrementally instead of re-training and can guarantee accuracy on partially cleaned data.\n{ActiveClean\\xspace} supports a popular class of models called convex loss models (e.g., linear regression and SVMs).\n{ActiveClean\\xspace} also leverages the structure of a user's model to prioritize cleaning those records likely to affect the results.\nWe evaluate {ActiveClean\\xspace} on five real-world datasets UCI Adult, UCI EEG, MNIST, Dollars For Docs, and WorldBank with both real and synthetic errors.\nOur results suggest that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned.\nFurthermore for a fixed cleaning budget and on all real dirty datasets, {ActiveClean\\xspace} returns more accurate models than uniform sampling and Active Learning. \n\n\n\\end{abstract}\n\n\\if{0}\n\\begin{abstract}\nDatabases are susceptible to various forms of corruption, or \\emph{dirtiness}, such as missing, incorrect, or inconsistent values.\nIncreasingly, modern data analysis pipelines involve Machine Learning for predictive models which can be sensitive to dirty data.\nDirty data is often expensive to repair, and naive sampling solutions are not suited for training high dimensional models.\nIn this paper, we propose {ActiveClean\\xspace}, an anytime framework for training Machine Learning models with budgeted data cleaning.\nOur framework updates a model iteratively as small samples of data are cleaned, and includes numerous optimizations such as importance weighting and dirty data detection.\nWe evaluate {ActiveClean\\xspace} on 4 real datasets and find that our methodology can return more accurate models for a smaller cost  than alternatives such as uniform sampling and active learning.\n\\end{abstract}\n\\fi\n\n\\setcounter{page}{1}\n\n\\section{Introduction}\nMachine Learning on large and growing datasets is a key data management challenge with significant interest in both industry and academia~\\cite{bdas, alexandrov2014stratosphere, crotty2014tupleware, tensor}.\nDespite a number of breakthroughs in reducing training time, predictive modeling can still be a tedious and time-consuming task for an analyst. \nData often arrive \\emph{dirty}, including missing, incorrect, or inconsistent attributes, and analysts widely report that data cleaning and other forms of pre-processing account for up to 80\\% of their effort~\\cite{nytimes, kandel2012}.\nWhile data cleaning is an extensively studied problem, the predictive modeling setting poses a number of new challenges: (1) high dimensionality can amplify even a small amount of erroneous records~\\cite{xiaofeature}, (2) the complexity can make it difficult to trace the consequnces of an error, and (3) there are often subtle technical cconditions (e.g., independent and identically distributed) that can be violated by data cleaning.\nConsequently, techniques that have been designed for traditional SQL analytics may be inefficient or even unreliable.\nIn this paper, we study the relationship between data cleaning and model training workflows and explore how to apply existing data cleaning approaches with provable guarantees.\n\nOne of the main bottlenecks in data cleaning is the human effort in determining which data are dirty and then developing rules or software to correct the problems.\nFor some types of dirty data, such as inconsistent values, model training may seemingly succeed albeit, with potential subtle inaccuracies in the model.\nFor example, battery-powered sensors can transmit unreliable measurements when battery levels are low \\cite{DBLP:conf/pervasive/JefferyAFHW06}. \nSimilarly, data entered by humans can be susceptible to a variety of inconsistencies (e.g., typos), and unintentional cognitive biases~\\cite{DBLP:conf/recsys/KrishnanPFG14}.\nSuch problems are often addressed in time-consuming loop where the analys trains a model, inspects the model and its predictions, clean some data, and re-train.\n\nThis iterative process is the de facto standard, but without appropriate care, can lead to several serious statistical issues.\nDue to the well-known Simpson's paradox, models trained on a mix of dirty and clean data can have very misleading results even in simple scenarios (Figure \\ref{update-arch1}).\nFurthermore, if the candidate dirty records are not identified with a known sampling distribution, the statistical independence assumptions for most training methods are violated. \nThe violations of these assumptions can introduce confounding biases.\nTo this end, we designed {ActiveClean\\xspace} which trains predictive models while allowing for iterative data cleaning and has accuracy guarantees.\n{ActiveClean\\xspace} automates the dirty data identification process and the model update process, thereby abstracting these two error-prone steps away from the analyst.\n\n{ActiveClean\\xspace} is inspired by the recent success of progressive data cleaning where a user can gradually clean more data until the desired accuracy is reached~\\cite{altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental, mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}.\nWe focus on a popular class of models called convex loss models (e.g., includes linear regression and SVMs) and show that the Simpson's paradox problem can be avoided using iterative maintenance of a model rather than re-training.\nThis process leverages the convex structure of the model rather than treating it like a black-box, and we apply convergence arguments from convex optimization theory.\nWe propose several novel optimizations that leverage information from the model to guide data cleaning towards the records most likely to be dirty and most likely to affect the results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\noindent To summarize the contributions:\n\\begin{itemize}[noitemsep]\n\\item \\textbf{Correctness} (Section \\ref{model-update}). We show how to update a dirty model given newly cleaned data. This update converges monotonically in expectation. For a batch size $b$ and iterations $T$, it converges with rate $O(\\frac{1}{\\sqrt{bT}})$. \n\\item \\textbf{Efficiency} (Section \\ref{dist-samp}). We derive a theoretical optimal sampling distribution that minimizes the update error and an approximation to estimate the theoretical optimum.\n\\item \\textbf{Detection and Estimation} (Section \\ref{opti}). We show how {ActiveClean\\xspace} can be integrated with data detection to guide data cleaning towards records expected to be dirty.\n\\item The experiments evaluate these components on four datasets with real and synthetic corruption (Section \\ref{eval}). Results suggests that for a fixed cleaning budget, {ActiveClean\\xspace} returns more accurate models than uniform sampling and Active Learning when systematic corruption is sparse.\n\n\n\\end{itemize}\n\n\n\n\n\n\n\n\\section{Background and Problem Setup}\\label{background}\nThis section formalizes the iterative data cleaning and training process and highlights an example application.\n\n\\subsection{Predictive Modeling}\nThe user provides a relation $R$ and wishes to train a model using the data in $R$.\nThis work focuses on a class of well-analyzed predictive analytics problems; ones that can be expressed as the minimization of convex loss functions.\nConvex loss minimization problems are amenable to a variety of incremental optimization methodologies with provable guarantees (see Friedman, Hastie, and Tibshirani \\cite{friedman2001elements} for an introduction).\nExamples include generalized linear models (including linear and logistic regression), support vector machines, and in fact, means and medians are also special cases. \n\nWe assume that the user provides a featurizer $F(\\cdot)$ that maps every record $r \\in R$ to a feature vector $x$ and label $y$.\nFor labeled training examples $\\{(x_{i},y_{i})\\}_{i=1}^{N}$, the problem is to find a vector of \\emph{model parameters} $\\theta$ by minimizing a loss function $\\phi$ over all training examples:\n", "index": 1, "text": "\n\\[\n \\theta^{*}=\\arg\\min_{\\theta}\\sum_{i=1}^{N}\\phi(x_{i},y_{i},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\theta^{*}=\\arg\\min_{\\theta}\\sum_{i=1}^{N}\\phi(x_{i},y_{i},\\theta)\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mo>*</mo></msup><mo>=</mo><mrow><mrow><mi>arg</mi><mo>\u2061</mo><munder><mi>min</mi><mi>\u03b8</mi></munder></mrow><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nTypically, a \\emph{regularization} term $r(\\theta)$ is added to this problem.\n$r(\\theta)$ penalizes high or low values of feature weights in $\\theta$ to avoid overfitting to noise in the training examples.\n\n", "itemtype": "equation", "pos": 9462, "prevtext": "\nWhere $\\phi$ is a convex function in $\\theta$.\nFor example, in a linear regression $\\phi$ is:\n", "index": 3, "text": "\n\\[\n\\phi(x_{i},y_{i},\\theta) = \\|\\theta^Tx_{i} - y_i \\|_2^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\phi(x_{i},y_{i},\\theta)=\\|\\theta^{T}x_{i}-y_{i}\\|_{2}^{2}\" display=\"block\"><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msup><mi>\u03b8</mi><mi>T</mi></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>-</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><mo>\u2225</mo></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIn this work, without loss of generality, we will include the regularization as part of the loss function i.e., $\\phi(x_{i},y_{i},\\theta)$ includes $r(\\theta)$.\n\n\\subsection{Data Cleaning}\nWe consider corruption that affects the attribute values of records. This does \\emph{not} cover errors that simultaneously affect multiple records such as record duplication or structure such as schema transformation.\nExamples of supported cleaning operations include, batch resolving common inconsistencies (e.g., merging ``U.S.A\" and ``United States\"), filtering outliers (e.g., removing records with values $>1e6$), and standardizing attribute semantics (e.g., ``1.2 miles\" and ``1.93 km\").\n\nWe are particularly interested in those errors that are difficult or time-consuming to clean, and require the analyst to examine an erroneous record, and determine the appropriate action--possibly leveraging knowledge of the current best model.\n\nWe represent this operation as $Clean(\\cdot)$ which can be applied to a record $r$ (or a set of records) to recover the clean record $r' = Clean(r)$.\nFormally, we treat the $Clean(\\cdot)$ as an expensive user-defined function composed of deterministic schema-preserving \\textsf{map} and \\textsf{filter} operations applied to a subset of rows in the relation.\nA relation is defined as \\emph{clean} if $R_{clean} = Clean(R_{clean})$.\nTherefore, for every $r \\in R_{clean}$ there exists a unique $r' \\in R$ in the dirty data.\nThe \\textsf{map} and \\textsf{filter} cleaning model is not a fundamental restriction of {ActiveClean\\xspace}, and Appendix~\\ref{set-of-r} discusses a compatible ``set of records\" cleaning model.\n\n\\subsection{Iteration}\nAs an example of how $Clean(\\cdot)$ fits into an iterative analysis process, consider an analyst training a regression and identifying outliers. \nWhen she examines one of the outliers, she realizes that the base data (prior to featurization) has a formatting inconsistency that leads to incorrect parsing of the numerical values.\nShe applies a batch fix (i.e., $Clean(\\cdot)$) to all of the outliers with the same error, and re-trains the model. \nThis iterative process can be described as the following pseudocode loop:\n\\begin{enumerate}[leftmargin=1em]\\scriptsize\\sloppy\n  \\item \\texttt{Init(iter)}\n  \\item \\texttt{current\\_model = Train(R)}\n  \\item For each t in $\\{1,...,iter\\}$\n  \\begin{enumerate}\n    \\item \\texttt{dirty\\_sample $=$ Identify(R,current\\_model)}\n    \\item \\texttt{clean\\_sample $=$ Clean(dirty\\_sample)}\n    \\item \\texttt{current\\_model $=$ Update(clean\\_sample, R)}\n  \\end{enumerate}\n  \\item \\texttt{Output: current\\_model}\n  \\end{enumerate}\n\n\\vspace{0.5em}\n\nWhile we have already discussed $Train(\\cdot)$ and $Clean(\\cdot)$, the analyst still has to define the primitives $Identify(\\cdot)$ and $Update(\\cdot)$.\nFor $Identify(\\cdot)$, given a the current best model, the analyst must specify some criteria to select a set of records to examine.\nAnd in $Update(\\cdot)$, the analyst must decide how to update the model given newly cleaned data.\nIt turns out that these primitives are not trivial to implement since the straight-forward solutions can actually lead to divergence of the trained models.\n\n\\subsection{Challenges}\\label{correctness} \n\\vspace{0.5em} \n\\textbf{Correctness: } Let us assume that the analyst has implemented an $Identify(\\cdot)$ function that returns $k$ candidate dirty records.\nThe straight-forward application data cleaning is to repair the corruption in place, and re-train the model after each repair.\nSuppose $k \\ll N$ records are cleaned, but all of the remaining dirty records are retained in the dataset.\nFigure \\ref{update-arch1} highlights the dangers of this approach on a very simple dirty dataset and a linear regression model i.e., the best fit line for two variables. \nOne of the variables is systematically corrupted with a translation in the x-axis (Figure \\ref{update-arch1}a).\nThe dirty data is marked in red and the clean data in blue, and they are shown with their respective best fit lines.\nAfter cleaning only two of the data points (Figure \\ref{update-arch1}b), the resulting best fit line is in the opposite direction of the true model.\n\nAggregates over mixtures of different populations of data can result in spurious relationships due to the well-known phenomenon called Simpson's paradox \\cite{simpson1951interpretation}.\nSimpson's paradox is by no means a corner case, and it has affected the validity of a number of high-profile studies~\\cite{simpsonsparadox}; even in the simple case of taking an average over a dataset.\nPredictive models are high-dimensional generalizations of these aggregates without closed form techniques to compensate for these biases.\nThus, training models on a mixture of dirty and clean data can lead to unreliable results, where artificial trends introduced by the mixture can be confused for the effects of data cleaning.\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/update-arch.png}\n \\caption{(a) Systematic corruption in one variable can lead to a shifted model. \n (b) Mixed dirty and clean data results in a less accurate model than no cleaning.\n(c) Small samples of only clean data can result in similarly inaccurate models. \\label{update-arch1}}\n\\end{figure}\n\nAn alternative is to avoid the dirty data altogether instead of mixing the two populations, and the model re-training is restricted to only data that are known to be clean.\nThis approach is similar to SampleClean \\cite{wang1999sample}, which was proposed to approximate the results of aggregate queries by applying them to a clean sample of data.\nHowever, high-dimensional models are highly sensitive to sample size.\nFigure \\ref{update-arch1}c illustrates that, even in two dimensions, models trained from small samples can be as incorrect as the mixing solution described before.\n\n\\vspace{0.5em} \n\n\\textbf{Efficiency: } Conversely, hypothetically assume that the analyst has implemented a correct $Update(\\cdot)$ primitive and implements $Identify(\\cdot)$ with a technique such as Active Learning to select records to clean~\\cite{yakout2013don,DBLP:journals/pvldb/YakoutENOI11,gokhale2014corleone}.\nActive learning is a technique to carefully select the set of examples to learn the most accurate model.\nHowever, these selection criteria are designed for stationary data distributions, an assumption which is not true in this setting.\nAs more data are cleaned, the data distribution changes.\nData which may look unimportant in the dirty data might be very valuable to clean in reality, and thus any prioritization has to predict a record's value with respect to an anticipated clean model.\n\n\\subsection{The Need For Automation}\\label{alrw}\n{ActiveClean\\xspace} is a framework that implements the $Identify(\\cdot)$ and $Update(\\cdot)$ primitives for the analyst. \nBy automating the iterative process, {ActiveClean\\xspace} ensures reliable models with convergence guarantees.\nThe analyst first initializes {ActiveClean\\xspace} with a dirty model.\n{ActiveClean\\xspace} carefuly selects small batches of data to clean based on data that are likely to be dirty and likely to affect the model.\nThe analyst applies data cleaning to these batches, and {ActiveClean\\xspace} updates the model with an incremental optimization technique.\n\nMachine learning has been applied in prior work to improve the efficiency of data cleaning~\\cite{yakout2013don,DBLP:journals/pvldb/YakoutENOI11,gokhale2014corleone}.\nHuman input, either for cleaning or validation of automated cleaning, is often expensive and impractical for large datasets.\nA model can learn rules from a small set of examples cleaned (or validated) by a human, and active learning is a technique to carefully select the set of examples to learn the most accurate model.\nThis model can be used to extrapolate repairs to not-yet-cleaned data, and the goal of these approaches is to provide the cleanest possible dataset--independent of the subsequent analytics or query processing.\nThese approaches, while very effective, suffer from composibility problems when placed inside cleaning and training loops.\nTo summarize, {ActiveClean\\xspace} considers data cleaning \\emph{during} model training, while these techniques consider model training \\emph{for} data cleaning.\nOne of the primary contributions of this work is an incremental model update algorithm with correctness guarantees for mixtures of data.\n\n\\subsection{Use Case: Dollars for Docs \\cite{dollarsfordocs}}\\label{s:usecase}\nProPublica collected a dataset of corporate donations to doctors to analyze conflicts of interest. \nThey reported that some doctors received over \\$500,000 in travel, meals, and consultation expenses \\cite{dollarsfordocsa}.\nProPublica laboriously curated and cleaned a dataset from the Centers for Medicare and Medicaid Services that listed nearly 250,000 research donations, and aggregated these donations by physician, drug, and pharmaceutical company.\nWe collected the raw unaggregated data and explored whether suspect donations could be predicted with a model.\nThis problem is typical of analysis scenarios based on observational data seen in finance, insurance, medicine, and investigative journalism.\nThe dataset has the following schema:\n\\begin{lstlisting}[mathescape,basicstyle={\\scriptsize}]\nContribution(pi_specialty$\\textrm{,}$ drug_name$\\textrm{,}$ device_name$\\textrm{,}$\ncorporation$\\textrm{,}$ amount$\\textrm{,}$ dispute$\\textrm{,}$ status)\n\\end{lstlisting}\n\n\\noindent\\texttt{pi\\_specialty} is a textual attribute describing the specialty of the doctor receiving the donation.\n\n\\noindent\\texttt{drug\\_name} is the branded name of the drug in the research study (null if not a drug).\n\n\\noindent\\texttt{device\\_name} is the branded name of the device in the study (null if not a device).\n\n\\noindent\\texttt{corporation} is the name of the pharmaceutical providing the donation.\n\n\\noindent\\texttt{amount} is a numerical attribute representing the donation amount.\n\n\\noindent\\texttt{dispute} is a Boolean attribute describing whether the research was disputed.\n\n\\noindent\\texttt{status} is a string label describing whether the  donation was allowed under the declared research protocol. The goal is to predict disallowed  donation. \n\n\\vspace{0.5em}\n\nHowever, this dataset is very dirty, and the systematic nature of the data corruption can result in an inaccurate model.\nOn the ProPublica website \\cite{dollarsfordocs}, they list numerous types of data problems that had to be cleaned before publishing the data (see Appendix \\ref{dfd-errors}).\nFor example, the most significant donations were made by large companies whose names were also more often inconsistently represented in the data, e.g., ``Pfizer Inc.\", ``Pfizer Incorporated\", ``Pfizer\".\nIn such scenarios, the effect of systematic error can be serious.\nDuplicate representations could artificially reduce the correlation between these entities and suspected contributions.\nThere were nearly 40,000 of the 250,000 records that had either naming inconsistencies or other inconsistencies in labeling the allowed or disallowed \\texttt{status}.\nWithout data cleaning, the detection rate using a Support Vector Machine was 66\\%.\nApplying the data cleaning to the entire dataset improved this rate to 97\\% in the clean data (Section \\ref{dfd-exp}), and the experiments describe how {ActiveClean\\xspace} can achieve an 80\\% detection rate for less than 1.6\\% of the records cleaned.\n\n\n\n\n\\iffalse\n{ActiveClean\\xspace} avoids both pitfalls, Simpson's paradox and sample size dependence.\nIn Section \\ref{model-update}, we show how we do this with iterative gradient steps (i.e., incrementally moving the line based on the clean data).\nThis takes advantage of the dirty data as well as the clean data, but still have provable properties about the intermediate results.\nThe intuition is that it smoothly and iteratively transitions the model from one population (the dirty data) to another (the clean data).\nIn Figure \\ref{sys-arch2}, we illustrate our ideal tradeoff space of sampling and data cleaning.\nAt two extremes we have no cleaning (just using the dirty data) and full cleaning.\n\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.5\\columnwidth]{figs/arch2.png}\n \\caption{{ActiveClean\\xspace} is designed to converge to an accurate model with fewer cleaned records than a uniform sampling approach (SampleClean). \\label{sys-arch2}}\\vspace{-1em}\n\\end{figure}\n\n\nWe design {ActiveClean\\xspace} to make greater progress at these small sample sizes using the dirty model as an initialization.\nDoing so is not trivial since it requires analysis of both the Machine Learning model and the data cleaning operations.\nData may look unimportant to a dirty model but when cleaned are very important.\nAlso, data cleaning and model training can happen at very different time scales, we have to carefully budget our effort to ensure that any optimizations actually address rate-determining steps in the workflow.\nFinally, in this line of work, the tradeoff space is enormous, and we have to carefully pick a design point and tailor our optimizations to this preferred regime.\n\\fi\n\n\n\n\n\n\n\n\n\\section{Problem Formalization}\\label{statements}\n\\noindent This section formalizes the problems addressed in the paper.\n\n\\subsection{Notation and Setup}\\label{notation}\nThe user provides a relation $R$, a cleaner $C(\\cdot)$, a featurizer $F(\\cdot)$, and a convex loss problem defined by the loss $\\phi(\\cdot)$.\nA total of $k$ records will be cleaned in batches of size $b$, so there will be $\\frac{k}{b}$ iterations. \nWe use the following notation to represent relevant intermediate states:\n\\begin{itemize}[noitemsep]\n\\item \\textbf{Dirty Model: } $\\theta^{(d)}$ is the model trained on $R$ (without cleaning) with the featurizer $F(\\cdot)$ and loss $\\phi(\\cdot)$. This serves as an initialization to {ActiveClean\\xspace}.\n\\item \\textbf{Dirty Records: } $R_{dirty} \\subseteq R$ is the subset of records that are still dirty. As more data are cleaned $R_{dirty} \\rightarrow \\{\\}$.\n\\item \\textbf{Clean Records: } $R_{clean} \\subseteq R$ is the subset of records that are clean, i.e., the complement of $R_{dirty}$.\n\\item \\textbf{Samples: } $S$ is a sample (possibly non-uniform but with known probabilities) of the records $R_{dirty}$. The clean sample is denoted by $S_{clean} = C(S)$.\n\\item \\textbf{Clean Model: } $\\theta^{(c)}$ is the optimal clean model, i.e., the model trained on a fully cleaned relation.\n\\item \\textbf{Current Model: } $\\theta^{(t)}$ is the current best model at iteration $t \\in \\{1,...,\\frac{k}{b}\\}$, and $\\theta^{(0)} = \\theta^{(d)}$. \n\\end{itemize}\n\nThere are two metrics that we will use to measure the performance of {ActiveClean\\xspace}:\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Model Error. } The model error is defined as $\\|\\theta^{(t)} - \\theta^{(c)}\\|$.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Testing Error. } Let $T(\\theta^{(t)})$ be the out-of-sample testing error when the current best model is applied to the clean data, and $T(\\theta^{(c)})$ be the test error when the clean model is applied to the clean data. The testing error is defined as $T(\\theta^{(t)}) - T(\\theta^{(c)})$\n\n\\subsection{Problem 1. Correct Update Problem}\\label{updp}\nGiven newly cleaned data $S_{clean}$ and the current best model $\\theta^{(t)}$, the model update problem is to calculate $\\theta^{(t+1)}$. \n$\\theta^{(t+1)}$ will have some error with respect to the true model $\\theta^{(c)}$, which we denote as:\n", "itemtype": "equation", "pos": 9731, "prevtext": "\nTypically, a \\emph{regularization} term $r(\\theta)$ is added to this problem.\n$r(\\theta)$ penalizes high or low values of feature weights in $\\theta$ to avoid overfitting to noise in the training examples.\n\n", "index": 5, "text": "\\begin{equation}\n \\theta^{*}=\\arg\\min_{\\theta}\\sum_{i=1}^{N}\\phi(x_{i},y_{i},\\theta) + r(\\theta)\n \\label{ideal}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\theta^{*}=\\arg\\min_{\\theta}\\sum_{i=1}^{N}\\phi(x_{i},y_{i},\\theta)+r(\\theta)\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mo>*</mo></msup><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><munder><mi>min</mi><mi>\u03b8</mi></munder></mrow><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nSince a sample of data are cleaned, it is only meaningful to talk about expected errors.\nWe call the update algorithm ``reliable\" if the expected error is upper bounded by a monotonically decreasing function $\\mu$ of the amount of cleaned data:\n", "itemtype": "equation", "pos": 25318, "prevtext": "\nIn this work, without loss of generality, we will include the regularization as part of the loss function i.e., $\\phi(x_{i},y_{i},\\theta)$ includes $r(\\theta)$.\n\n\\subsection{Data Cleaning}\nWe consider corruption that affects the attribute values of records. This does \\emph{not} cover errors that simultaneously affect multiple records such as record duplication or structure such as schema transformation.\nExamples of supported cleaning operations include, batch resolving common inconsistencies (e.g., merging ``U.S.A\" and ``United States\"), filtering outliers (e.g., removing records with values $>1e6$), and standardizing attribute semantics (e.g., ``1.2 miles\" and ``1.93 km\").\n\nWe are particularly interested in those errors that are difficult or time-consuming to clean, and require the analyst to examine an erroneous record, and determine the appropriate action--possibly leveraging knowledge of the current best model.\n\nWe represent this operation as $Clean(\\cdot)$ which can be applied to a record $r$ (or a set of records) to recover the clean record $r' = Clean(r)$.\nFormally, we treat the $Clean(\\cdot)$ as an expensive user-defined function composed of deterministic schema-preserving \\textsf{map} and \\textsf{filter} operations applied to a subset of rows in the relation.\nA relation is defined as \\emph{clean} if $R_{clean} = Clean(R_{clean})$.\nTherefore, for every $r \\in R_{clean}$ there exists a unique $r' \\in R$ in the dirty data.\nThe \\textsf{map} and \\textsf{filter} cleaning model is not a fundamental restriction of {ActiveClean\\xspace}, and Appendix~\\ref{set-of-r} discusses a compatible ``set of records\" cleaning model.\n\n\\subsection{Iteration}\nAs an example of how $Clean(\\cdot)$ fits into an iterative analysis process, consider an analyst training a regression and identifying outliers. \nWhen she examines one of the outliers, she realizes that the base data (prior to featurization) has a formatting inconsistency that leads to incorrect parsing of the numerical values.\nShe applies a batch fix (i.e., $Clean(\\cdot)$) to all of the outliers with the same error, and re-trains the model. \nThis iterative process can be described as the following pseudocode loop:\n\\begin{enumerate}[leftmargin=1em]\\scriptsize\\sloppy\n  \\item \\texttt{Init(iter)}\n  \\item \\texttt{current\\_model = Train(R)}\n  \\item For each t in $\\{1,...,iter\\}$\n  \\begin{enumerate}\n    \\item \\texttt{dirty\\_sample $=$ Identify(R,current\\_model)}\n    \\item \\texttt{clean\\_sample $=$ Clean(dirty\\_sample)}\n    \\item \\texttt{current\\_model $=$ Update(clean\\_sample, R)}\n  \\end{enumerate}\n  \\item \\texttt{Output: current\\_model}\n  \\end{enumerate}\n\n\\vspace{0.5em}\n\nWhile we have already discussed $Train(\\cdot)$ and $Clean(\\cdot)$, the analyst still has to define the primitives $Identify(\\cdot)$ and $Update(\\cdot)$.\nFor $Identify(\\cdot)$, given a the current best model, the analyst must specify some criteria to select a set of records to examine.\nAnd in $Update(\\cdot)$, the analyst must decide how to update the model given newly cleaned data.\nIt turns out that these primitives are not trivial to implement since the straight-forward solutions can actually lead to divergence of the trained models.\n\n\\subsection{Challenges}\\label{correctness} \n\\vspace{0.5em} \n\\textbf{Correctness: } Let us assume that the analyst has implemented an $Identify(\\cdot)$ function that returns $k$ candidate dirty records.\nThe straight-forward application data cleaning is to repair the corruption in place, and re-train the model after each repair.\nSuppose $k \\ll N$ records are cleaned, but all of the remaining dirty records are retained in the dataset.\nFigure \\ref{update-arch1} highlights the dangers of this approach on a very simple dirty dataset and a linear regression model i.e., the best fit line for two variables. \nOne of the variables is systematically corrupted with a translation in the x-axis (Figure \\ref{update-arch1}a).\nThe dirty data is marked in red and the clean data in blue, and they are shown with their respective best fit lines.\nAfter cleaning only two of the data points (Figure \\ref{update-arch1}b), the resulting best fit line is in the opposite direction of the true model.\n\nAggregates over mixtures of different populations of data can result in spurious relationships due to the well-known phenomenon called Simpson's paradox \\cite{simpson1951interpretation}.\nSimpson's paradox is by no means a corner case, and it has affected the validity of a number of high-profile studies~\\cite{simpsonsparadox}; even in the simple case of taking an average over a dataset.\nPredictive models are high-dimensional generalizations of these aggregates without closed form techniques to compensate for these biases.\nThus, training models on a mixture of dirty and clean data can lead to unreliable results, where artificial trends introduced by the mixture can be confused for the effects of data cleaning.\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/update-arch.png}\n \\caption{(a) Systematic corruption in one variable can lead to a shifted model. \n (b) Mixed dirty and clean data results in a less accurate model than no cleaning.\n(c) Small samples of only clean data can result in similarly inaccurate models. \\label{update-arch1}}\n\\end{figure}\n\nAn alternative is to avoid the dirty data altogether instead of mixing the two populations, and the model re-training is restricted to only data that are known to be clean.\nThis approach is similar to SampleClean \\cite{wang1999sample}, which was proposed to approximate the results of aggregate queries by applying them to a clean sample of data.\nHowever, high-dimensional models are highly sensitive to sample size.\nFigure \\ref{update-arch1}c illustrates that, even in two dimensions, models trained from small samples can be as incorrect as the mixing solution described before.\n\n\\vspace{0.5em} \n\n\\textbf{Efficiency: } Conversely, hypothetically assume that the analyst has implemented a correct $Update(\\cdot)$ primitive and implements $Identify(\\cdot)$ with a technique such as Active Learning to select records to clean~\\cite{yakout2013don,DBLP:journals/pvldb/YakoutENOI11,gokhale2014corleone}.\nActive learning is a technique to carefully select the set of examples to learn the most accurate model.\nHowever, these selection criteria are designed for stationary data distributions, an assumption which is not true in this setting.\nAs more data are cleaned, the data distribution changes.\nData which may look unimportant in the dirty data might be very valuable to clean in reality, and thus any prioritization has to predict a record's value with respect to an anticipated clean model.\n\n\\subsection{The Need For Automation}\\label{alrw}\n{ActiveClean\\xspace} is a framework that implements the $Identify(\\cdot)$ and $Update(\\cdot)$ primitives for the analyst. \nBy automating the iterative process, {ActiveClean\\xspace} ensures reliable models with convergence guarantees.\nThe analyst first initializes {ActiveClean\\xspace} with a dirty model.\n{ActiveClean\\xspace} carefuly selects small batches of data to clean based on data that are likely to be dirty and likely to affect the model.\nThe analyst applies data cleaning to these batches, and {ActiveClean\\xspace} updates the model with an incremental optimization technique.\n\nMachine learning has been applied in prior work to improve the efficiency of data cleaning~\\cite{yakout2013don,DBLP:journals/pvldb/YakoutENOI11,gokhale2014corleone}.\nHuman input, either for cleaning or validation of automated cleaning, is often expensive and impractical for large datasets.\nA model can learn rules from a small set of examples cleaned (or validated) by a human, and active learning is a technique to carefully select the set of examples to learn the most accurate model.\nThis model can be used to extrapolate repairs to not-yet-cleaned data, and the goal of these approaches is to provide the cleanest possible dataset--independent of the subsequent analytics or query processing.\nThese approaches, while very effective, suffer from composibility problems when placed inside cleaning and training loops.\nTo summarize, {ActiveClean\\xspace} considers data cleaning \\emph{during} model training, while these techniques consider model training \\emph{for} data cleaning.\nOne of the primary contributions of this work is an incremental model update algorithm with correctness guarantees for mixtures of data.\n\n\\subsection{Use Case: Dollars for Docs \\cite{dollarsfordocs}}\\label{s:usecase}\nProPublica collected a dataset of corporate donations to doctors to analyze conflicts of interest. \nThey reported that some doctors received over \\$500,000 in travel, meals, and consultation expenses \\cite{dollarsfordocsa}.\nProPublica laboriously curated and cleaned a dataset from the Centers for Medicare and Medicaid Services that listed nearly 250,000 research donations, and aggregated these donations by physician, drug, and pharmaceutical company.\nWe collected the raw unaggregated data and explored whether suspect donations could be predicted with a model.\nThis problem is typical of analysis scenarios based on observational data seen in finance, insurance, medicine, and investigative journalism.\nThe dataset has the following schema:\n\\begin{lstlisting}[mathescape,basicstyle={\\scriptsize}]\nContribution(pi_specialty$\\textrm{,}$ drug_name$\\textrm{,}$ device_name$\\textrm{,}$\ncorporation$\\textrm{,}$ amount$\\textrm{,}$ dispute$\\textrm{,}$ status)\n\\end{lstlisting}\n\n\\noindent\\texttt{pi\\_specialty} is a textual attribute describing the specialty of the doctor receiving the donation.\n\n\\noindent\\texttt{drug\\_name} is the branded name of the drug in the research study (null if not a drug).\n\n\\noindent\\texttt{device\\_name} is the branded name of the device in the study (null if not a device).\n\n\\noindent\\texttt{corporation} is the name of the pharmaceutical providing the donation.\n\n\\noindent\\texttt{amount} is a numerical attribute representing the donation amount.\n\n\\noindent\\texttt{dispute} is a Boolean attribute describing whether the research was disputed.\n\n\\noindent\\texttt{status} is a string label describing whether the  donation was allowed under the declared research protocol. The goal is to predict disallowed  donation. \n\n\\vspace{0.5em}\n\nHowever, this dataset is very dirty, and the systematic nature of the data corruption can result in an inaccurate model.\nOn the ProPublica website \\cite{dollarsfordocs}, they list numerous types of data problems that had to be cleaned before publishing the data (see Appendix \\ref{dfd-errors}).\nFor example, the most significant donations were made by large companies whose names were also more often inconsistently represented in the data, e.g., ``Pfizer Inc.\", ``Pfizer Incorporated\", ``Pfizer\".\nIn such scenarios, the effect of systematic error can be serious.\nDuplicate representations could artificially reduce the correlation between these entities and suspected contributions.\nThere were nearly 40,000 of the 250,000 records that had either naming inconsistencies or other inconsistencies in labeling the allowed or disallowed \\texttt{status}.\nWithout data cleaning, the detection rate using a Support Vector Machine was 66\\%.\nApplying the data cleaning to the entire dataset improved this rate to 97\\% in the clean data (Section \\ref{dfd-exp}), and the experiments describe how {ActiveClean\\xspace} can achieve an 80\\% detection rate for less than 1.6\\% of the records cleaned.\n\n\n\n\n\\iffalse\n{ActiveClean\\xspace} avoids both pitfalls, Simpson's paradox and sample size dependence.\nIn Section \\ref{model-update}, we show how we do this with iterative gradient steps (i.e., incrementally moving the line based on the clean data).\nThis takes advantage of the dirty data as well as the clean data, but still have provable properties about the intermediate results.\nThe intuition is that it smoothly and iteratively transitions the model from one population (the dirty data) to another (the clean data).\nIn Figure \\ref{sys-arch2}, we illustrate our ideal tradeoff space of sampling and data cleaning.\nAt two extremes we have no cleaning (just using the dirty data) and full cleaning.\n\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.5\\columnwidth]{figs/arch2.png}\n \\caption{{ActiveClean\\xspace} is designed to converge to an accurate model with fewer cleaned records than a uniform sampling approach (SampleClean). \\label{sys-arch2}}\\vspace{-1em}\n\\end{figure}\n\n\nWe design {ActiveClean\\xspace} to make greater progress at these small sample sizes using the dirty model as an initialization.\nDoing so is not trivial since it requires analysis of both the Machine Learning model and the data cleaning operations.\nData may look unimportant to a dirty model but when cleaned are very important.\nAlso, data cleaning and model training can happen at very different time scales, we have to carefully budget our effort to ensure that any optimizations actually address rate-determining steps in the workflow.\nFinally, in this line of work, the tradeoff space is enormous, and we have to carefully pick a design point and tailor our optimizations to this preferred regime.\n\\fi\n\n\n\n\n\n\n\n\n\\section{Problem Formalization}\\label{statements}\n\\noindent This section formalizes the problems addressed in the paper.\n\n\\subsection{Notation and Setup}\\label{notation}\nThe user provides a relation $R$, a cleaner $C(\\cdot)$, a featurizer $F(\\cdot)$, and a convex loss problem defined by the loss $\\phi(\\cdot)$.\nA total of $k$ records will be cleaned in batches of size $b$, so there will be $\\frac{k}{b}$ iterations. \nWe use the following notation to represent relevant intermediate states:\n\\begin{itemize}[noitemsep]\n\\item \\textbf{Dirty Model: } $\\theta^{(d)}$ is the model trained on $R$ (without cleaning) with the featurizer $F(\\cdot)$ and loss $\\phi(\\cdot)$. This serves as an initialization to {ActiveClean\\xspace}.\n\\item \\textbf{Dirty Records: } $R_{dirty} \\subseteq R$ is the subset of records that are still dirty. As more data are cleaned $R_{dirty} \\rightarrow \\{\\}$.\n\\item \\textbf{Clean Records: } $R_{clean} \\subseteq R$ is the subset of records that are clean, i.e., the complement of $R_{dirty}$.\n\\item \\textbf{Samples: } $S$ is a sample (possibly non-uniform but with known probabilities) of the records $R_{dirty}$. The clean sample is denoted by $S_{clean} = C(S)$.\n\\item \\textbf{Clean Model: } $\\theta^{(c)}$ is the optimal clean model, i.e., the model trained on a fully cleaned relation.\n\\item \\textbf{Current Model: } $\\theta^{(t)}$ is the current best model at iteration $t \\in \\{1,...,\\frac{k}{b}\\}$, and $\\theta^{(0)} = \\theta^{(d)}$. \n\\end{itemize}\n\nThere are two metrics that we will use to measure the performance of {ActiveClean\\xspace}:\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Model Error. } The model error is defined as $\\|\\theta^{(t)} - \\theta^{(c)}\\|$.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Testing Error. } Let $T(\\theta^{(t)})$ be the out-of-sample testing error when the current best model is applied to the clean data, and $T(\\theta^{(c)})$ be the test error when the clean model is applied to the clean data. The testing error is defined as $T(\\theta^{(t)}) - T(\\theta^{(c)})$\n\n\\subsection{Problem 1. Correct Update Problem}\\label{updp}\nGiven newly cleaned data $S_{clean}$ and the current best model $\\theta^{(t)}$, the model update problem is to calculate $\\theta^{(t+1)}$. \n$\\theta^{(t+1)}$ will have some error with respect to the true model $\\theta^{(c)}$, which we denote as:\n", "index": 7, "text": "\n\\[\nerror(\\theta^{(t+1)}) = \\| \\theta^{(t+1)} - \\theta^{(c)} \\|\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"error(\\theta^{(t+1)})=\\|\\theta^{(t+1)}-\\theta^{(c)}\\|\" display=\"block\"><mrow><mrow><mi>e</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>\u2225</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>\u2225</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIntuitively, ``reliable\" means that more cleaning should imply more accuracy.\n\n\\vspace{0.5em}\n\n\\emph{The Correct Update Problem is to reliably update the model $\\theta^{(t)}$ with a sample of cleaned data.}\n\n\\subsection{Problem 2. Efficiency Problem}\\label{optp}\nThe efficiency problem is to select $S_{clean}$ such that the expected error $\\mathbb{E}(error(\\theta^{(t)}))$ is minimized.\n{ActiveClean\\xspace} uses previously cleaned data to estimate the value of data cleaning on new records.\nThen it draws a sample of records $S \\subseteq R_{dirty}$. \nThis is a non-uniform sample where each record $r$ has a sampling probability $p(r)$ based on the estimates.\nWe derive the optimal sampling distribution for the SGD updates, and show how the theoretical optimum can be approximated.\n\n\\vspace{0.5em}\n\n\\emph{The Efficiency Problem is to select a sampling distribution $p(\\cdot)$ over all records such that the expected error w.r.t to the model if trained on fully clean data is minimized.}\n\n\\iffalse\n\\subsection{{ActiveClean\\xspace} Problem}\nThe core problem addressed by {ActiveClean\\xspace} is incremental model update while progressively cleaning data.\n\n\\begin{problem}[ActiveClean Problem]\\label{activeclean}\\sloppy\nLet $R$ be a dirty relation, $F(r) \\mapsto (x,y)$ be a featurization that maps\na record $r \\in R$ to a feature vector $x$ and label $y$, $\\phi$ be a convex regularized loss,\nand $C(r) \\mapsto r_{clean}$ be a cleaning technique that maps a record to its cleaned value. \nGiven these inputs, the {ActiveClean\\xspace} problem is to return a \\textbf{reliable} estimate $\\hat{\\theta}$ of the clean model for any limit $k$ on the number of times the data cleaning $C(\\cdot)$ can be applied.\n\n\\vspace{0.5em}\n\n\\textbf{Reliable} precisely means that the expected error in this estimate (i.e., L2 difference w.r.t a model trained on a fully cleaned dataset) is bounded above by a monotonic function in $k$ and a monotonic function of the error in the dirty model.\n\\end{problem}\n\\fi\n\n\n\\iffalse\nFrom a systems perspective, data cleaning and model training happen at very different time scales.\nWhen humans are involved, per record latencies for data cleaning are orders of magnitude larger than the CPU time needed for model training.\nWe can compare recent results in data cleaning to a model training framework like CoCoA implemented on Spark \\cite{jaggi2014communication}.\nPer record, BigDansing, a highly optimized automated Spark-based data cleaning system is 15.5x slower than CoCoA\\footnote{For CoCoA to reach a precision of 1e-3}.\nCrowd based techniques like CrowdFill \\cite{park2014crowdfill} and CrowdER \\cite{wang2012crowder} are over 100,000x slower per record. \nConsequently, all of the optimizations in {ActiveClean\\xspace} are designed to address data cleaning latency (i.e., more progress with fewer cleaned records) rather than optimizing for numerical computation (i.e., process fewer records).\n\\fi\n\n\n\n\\iffalse\nHere is an example application of {ActiveClean\\xspace} with our running example:\n\\begin{example}\nThe analyst first trains her SVM model on the dirty data ignoring the effects of the errors returning a model $\\theta^{(d)}$.\nShe decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\nShe initializes {ActiveClean\\xspace} with $\\theta^{(d)}$.\n{ActiveClean\\xspace} samples an initial batch of 10 records.\nShe manually cleans those records by merging similar drug names, making corporation names consistent, and fixing incorrect labels.\nAfter each batch, the model is updated with the most recent cleaning results $\\theta^{(t)}$.\nThe model improves after each iteration.\nAfter $t=10$ of cleaning, the analyst has an accurate model trained with 100 cleaned records but still utilizes the entire dirty data.\n\\end{example}\n\n\n\n\\subsection{Two perspectives on error}\nWhen faced with such errors there are two contrasting perspectives from the Machine Learning and the Database communities.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Existing Database Literature. } \nTraditionally, cleaning is agnostic to the queries and analysis that happens downstream. \nThis perspective breaks down when cleaning is so expensive that we can only clean a small number of records.\nIdeally, we should clean the records that are most valuable to the downstream analysis.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Existing  Machine Learning Literature. } The Machine Learning community has focused on\ndesigning models that are robust to outliers (i.e., values far away from the typical value)\nFor example, in the case of linear regression, we can change the $L_2$ norm to an $L_1$ norm to mitigate the effect of outliers:\n", "itemtype": "equation", "pos": 25629, "prevtext": "\nSince a sample of data are cleaned, it is only meaningful to talk about expected errors.\nWe call the update algorithm ``reliable\" if the expected error is upper bounded by a monotonically decreasing function $\\mu$ of the amount of cleaned data:\n", "index": 9, "text": "\n\\[\n\\mathbb{E}(error(\\theta^{new})) = O(\\mu(\\mid S_{clean} \\mid))\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(error(\\theta^{new}))=O(\\mu(\\mid S_{clean}\\mid))\" display=\"block\"><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>e</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>O</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bc</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>\u2223</mo><msub><mi>S</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThe quadratic L2 loss implies that examples that deviate far from the typical example are quadratically penalized as opposed to linearly penalized with the L1 loss.\nThere is a natural tradeoff between robustness and efficiency.\nThe more robust a technique is, the less efficient it will be (i.e., estimate variance for a fixed number of training examples).\nRobust techniques are best suited for random errors that look significantly different the rest of the examples.\nWhen errors are systematic, the Machine Learning answer has been to design features in such a way that they are robust to some systematic bias.\nFor example, in image processing, scale-invariant feature transforms (SIFT) are widely applied that allow for image models invariant to pose or scaling issues.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{The {ActiveClean\\xspace} Contribution. } We try to bring two perspectives together in this work to address the problem of expensive to clean systematic errors, namely the Database idea of data cleaning and the Machine Learning formalization of empirical risk minimization.\nSome errors require expensive cleaning procedures, increasingly using the crowd, and we joint have a time budget on cleaning and analysis.\n{ActiveClean\\xspace} prioritizes cleaning with respect to an estimated impact on the clean model.\n\n\\subsection{SampleClean Project}\n\nTraditionally, data cleaning has explored expensive, up-front cleaning of entire datasets for increased query accuracy.\nWe proposed the SampleClean problem, in which an analyst cleans a small sample of data, and then estimates the result to an aggregate query e.g., {\\ensuremath{\\texttt{sum} }\\xspace}, {\\ensuremath{\\texttt{count}}\\xspace}, or {\\ensuremath{\\texttt{avg} }\\xspace}.\nThe main insight from the SampleClean project is that highly accurate answers for aggregate queries does not require cleaning the full dataset.\nGeneralizing this insight, there is a deep relationship between the application (i.e., the query) and how an analyst should budget their effort in data cleaning.\nIn fact, {\\ensuremath{\\texttt{avg} }\\xspace} and {\\ensuremath{\\texttt{sum} }\\xspace} queries are a special case of the convex loss minimization discussed in the previous section:\n", "itemtype": "equation", "pos": 30462, "prevtext": "\nIntuitively, ``reliable\" means that more cleaning should imply more accuracy.\n\n\\vspace{0.5em}\n\n\\emph{The Correct Update Problem is to reliably update the model $\\theta^{(t)}$ with a sample of cleaned data.}\n\n\\subsection{Problem 2. Efficiency Problem}\\label{optp}\nThe efficiency problem is to select $S_{clean}$ such that the expected error $\\mathbb{E}(error(\\theta^{(t)}))$ is minimized.\n{ActiveClean\\xspace} uses previously cleaned data to estimate the value of data cleaning on new records.\nThen it draws a sample of records $S \\subseteq R_{dirty}$. \nThis is a non-uniform sample where each record $r$ has a sampling probability $p(r)$ based on the estimates.\nWe derive the optimal sampling distribution for the SGD updates, and show how the theoretical optimum can be approximated.\n\n\\vspace{0.5em}\n\n\\emph{The Efficiency Problem is to select a sampling distribution $p(\\cdot)$ over all records such that the expected error w.r.t to the model if trained on fully clean data is minimized.}\n\n\\iffalse\n\\subsection{{ActiveClean\\xspace} Problem}\nThe core problem addressed by {ActiveClean\\xspace} is incremental model update while progressively cleaning data.\n\n\\begin{problem}[ActiveClean Problem]\\label{activeclean}\\sloppy\nLet $R$ be a dirty relation, $F(r) \\mapsto (x,y)$ be a featurization that maps\na record $r \\in R$ to a feature vector $x$ and label $y$, $\\phi$ be a convex regularized loss,\nand $C(r) \\mapsto r_{clean}$ be a cleaning technique that maps a record to its cleaned value. \nGiven these inputs, the {ActiveClean\\xspace} problem is to return a \\textbf{reliable} estimate $\\hat{\\theta}$ of the clean model for any limit $k$ on the number of times the data cleaning $C(\\cdot)$ can be applied.\n\n\\vspace{0.5em}\n\n\\textbf{Reliable} precisely means that the expected error in this estimate (i.e., L2 difference w.r.t a model trained on a fully cleaned dataset) is bounded above by a monotonic function in $k$ and a monotonic function of the error in the dirty model.\n\\end{problem}\n\\fi\n\n\n\\iffalse\nFrom a systems perspective, data cleaning and model training happen at very different time scales.\nWhen humans are involved, per record latencies for data cleaning are orders of magnitude larger than the CPU time needed for model training.\nWe can compare recent results in data cleaning to a model training framework like CoCoA implemented on Spark \\cite{jaggi2014communication}.\nPer record, BigDansing, a highly optimized automated Spark-based data cleaning system is 15.5x slower than CoCoA\\footnote{For CoCoA to reach a precision of 1e-3}.\nCrowd based techniques like CrowdFill \\cite{park2014crowdfill} and CrowdER \\cite{wang2012crowder} are over 100,000x slower per record. \nConsequently, all of the optimizations in {ActiveClean\\xspace} are designed to address data cleaning latency (i.e., more progress with fewer cleaned records) rather than optimizing for numerical computation (i.e., process fewer records).\n\\fi\n\n\n\n\\iffalse\nHere is an example application of {ActiveClean\\xspace} with our running example:\n\\begin{example}\nThe analyst first trains her SVM model on the dirty data ignoring the effects of the errors returning a model $\\theta^{(d)}$.\nShe decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\nShe initializes {ActiveClean\\xspace} with $\\theta^{(d)}$.\n{ActiveClean\\xspace} samples an initial batch of 10 records.\nShe manually cleans those records by merging similar drug names, making corporation names consistent, and fixing incorrect labels.\nAfter each batch, the model is updated with the most recent cleaning results $\\theta^{(t)}$.\nThe model improves after each iteration.\nAfter $t=10$ of cleaning, the analyst has an accurate model trained with 100 cleaned records but still utilizes the entire dirty data.\n\\end{example}\n\n\n\n\\subsection{Two perspectives on error}\nWhen faced with such errors there are two contrasting perspectives from the Machine Learning and the Database communities.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Existing Database Literature. } \nTraditionally, cleaning is agnostic to the queries and analysis that happens downstream. \nThis perspective breaks down when cleaning is so expensive that we can only clean a small number of records.\nIdeally, we should clean the records that are most valuable to the downstream analysis.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Existing  Machine Learning Literature. } The Machine Learning community has focused on\ndesigning models that are robust to outliers (i.e., values far away from the typical value)\nFor example, in the case of linear regression, we can change the $L_2$ norm to an $L_1$ norm to mitigate the effect of outliers:\n", "index": 11, "text": "\n\\[\n\\phi(x_{i}^T\\theta,y_{i}) = \\|\\theta^Tx_{i} - y_i \\|_1\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\phi(x_{i}^{T}\\theta,y_{i})=\\|\\theta^{T}x_{i}-y_{i}\\|_{1}\" display=\"block\"><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><mo>\u2062</mo><mi>\u03b8</mi></mrow><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mrow><msup><mi>\u03b8</mi><mi>T</mi></msup><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>-</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><mo>\u2225</mo></mrow><mn>1</mn></msub></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\nWe then extended the SampleClean work to study cleaning Materialized Views \\cite{technicalReport}.\nSuppose base data is updated with insertions, deletions, or updates, we explored how we could efficiently propagate\nchanges to a sample of the view instead of the full view.\nSubsequent queries on the view could be answered approximate.\n\nThe SampleClean problem inspired an eponymous system that implements sampling, data cleaning, and approximate query processing on the Apache Spark stack \\cite{sampleclean}.\nAlso included in the Apache Spark stack are Machine Learning libraries including MLlib \\cite{mllib} and GraphX \\cite{graphx}.\nThe in-memory architecture of the Apache Spark stack allows for increasingly interactive analysis \\cite{AgarwalMPMMS13, armbrust2015spark}.\nAnalysts can prototype data processing workflows on samples to evaluate performance before running expensive batch processing jobs on entire datasets.\nWith data cleaning and machine learning libraries in the same software ecosystem, we see a new opportunity for joint optimization for interactive model building.\n\n\n\n\\subsection{Stochastic Gradient Descent}\nSampling is a natural part of any Machine Learning workflow, as stochastic optimization is widely used to fit model parameters.\nThe problems described in the previous subsections are often trained using a technique called Stochastic Gradient Descent (SGD) or one of its variants.\nThe basic idea of SGD is to draw a data point at random, calculate the gradient at that point, and then update a current best estimate with that gradient.\n", "itemtype": "equation", "pos": 32741, "prevtext": "\nThe quadratic L2 loss implies that examples that deviate far from the typical example are quadratically penalized as opposed to linearly penalized with the L1 loss.\nThere is a natural tradeoff between robustness and efficiency.\nThe more robust a technique is, the less efficient it will be (i.e., estimate variance for a fixed number of training examples).\nRobust techniques are best suited for random errors that look significantly different the rest of the examples.\nWhen errors are systematic, the Machine Learning answer has been to design features in such a way that they are robust to some systematic bias.\nFor example, in image processing, scale-invariant feature transforms (SIFT) are widely applied that allow for image models invariant to pose or scaling issues.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{The {ActiveClean\\xspace} Contribution. } We try to bring two perspectives together in this work to address the problem of expensive to clean systematic errors, namely the Database idea of data cleaning and the Machine Learning formalization of empirical risk minimization.\nSome errors require expensive cleaning procedures, increasingly using the crowd, and we joint have a time budget on cleaning and analysis.\n{ActiveClean\\xspace} prioritizes cleaning with respect to an estimated impact on the clean model.\n\n\\subsection{SampleClean Project}\n\nTraditionally, data cleaning has explored expensive, up-front cleaning of entire datasets for increased query accuracy.\nWe proposed the SampleClean problem, in which an analyst cleans a small sample of data, and then estimates the result to an aggregate query e.g., {\\ensuremath{\\texttt{sum} }\\xspace}, {\\ensuremath{\\texttt{count}}\\xspace}, or {\\ensuremath{\\texttt{avg} }\\xspace}.\nThe main insight from the SampleClean project is that highly accurate answers for aggregate queries does not require cleaning the full dataset.\nGeneralizing this insight, there is a deep relationship between the application (i.e., the query) and how an analyst should budget their effort in data cleaning.\nIn fact, {\\ensuremath{\\texttt{avg} }\\xspace} and {\\ensuremath{\\texttt{sum} }\\xspace} queries are a special case of the convex loss minimization discussed in the previous section:\n", "index": 13, "text": "\n\\[\n\\phi = (x_{i} - \\theta)^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\phi=(x_{i}-\\theta)^{2}\" display=\"block\"><mrow><mi>\u03d5</mi><mo>=</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n SGD can also be applied in a ``mini-batch\" mode, where we draw a subset of data $S^{(t)}$ at random and update with the average gradient.\n\n", "itemtype": "equation", "pos": 34341, "prevtext": "\n\nWe then extended the SampleClean work to study cleaning Materialized Views \\cite{technicalReport}.\nSuppose base data is updated with insertions, deletions, or updates, we explored how we could efficiently propagate\nchanges to a sample of the view instead of the full view.\nSubsequent queries on the view could be answered approximate.\n\nThe SampleClean problem inspired an eponymous system that implements sampling, data cleaning, and approximate query processing on the Apache Spark stack \\cite{sampleclean}.\nAlso included in the Apache Spark stack are Machine Learning libraries including MLlib \\cite{mllib} and GraphX \\cite{graphx}.\nThe in-memory architecture of the Apache Spark stack allows for increasingly interactive analysis \\cite{AgarwalMPMMS13, armbrust2015spark}.\nAnalysts can prototype data processing workflows on samples to evaluate performance before running expensive batch processing jobs on entire datasets.\nWith data cleaning and machine learning libraries in the same software ecosystem, we see a new opportunity for joint optimization for interactive model building.\n\n\n\n\\subsection{Stochastic Gradient Descent}\nSampling is a natural part of any Machine Learning workflow, as stochastic optimization is widely used to fit model parameters.\nThe problems described in the previous subsections are often trained using a technique called Stochastic Gradient Descent (SGD) or one of its variants.\nThe basic idea of SGD is to draw a data point at random, calculate the gradient at that point, and then update a current best estimate with that gradient.\n", "index": 15, "text": "\n\\[\n\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\gamma\\nabla\\phi(x_{i}^T\\theta,y_{i})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\gamma\\nabla\\phi(x_{i}^{T}\\theta,y_{i})\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><mo>\u2062</mo><mi>\u03b8</mi></mrow><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\nWe can use this workflow for designing an anytime data cleaning methodology.\nAs data is sampled, we can clean the samples.\nThe analyst then can stop at anytime and use the best model at that instant.\nSGD and its variants are well-studied and there are lower-bounds on the convergence rates using these techniques. \nRecently, a number of works have explored non-uniform sampling distributions for stochastic optimization \\cite{zhao2014stochastic, qu2014randomized}.\nThe main insight is that non-uniform distributions may on average estimate the gradient accurately.\nIn this work, we explore how to design such a non-uniform distribution for iterative data cleaning.\n\n\\fi\n\n\n \n\n\\section{Architecture}\\label{arch}\n\\noindent This section presents the {ActiveClean\\xspace} architecture.\n\n\\subsection{Overview}\\label{sysover}\nFigure \\ref{sys-arch} illustrates the {ActiveClean\\xspace} architecture.\nThe dotted boxes describe optional components that the user can provide to improve the efficiency of the system.  \n\n\\subsubsection{Required User Input}\\label{uinp}\n\n\n\\noindent\\textbf{Model:} The user provides a predictive model (e.g., SVM) specified as a convex loss optimization problem $\\phi(\\cdot)$ and a featurizer $F(\\cdot)$ that maps a record to its feature vector $x$ and label $y$.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Cleaning Function: } The user provides a function $C(\\cdot)$ (implemented via software or crowdsourcing) that maps dirty records to clean records as per our definition in Section \\ref{dmodel}. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Batches: } Data are cleaned in batches of size $b$ and the user can change these settings if she desires more or less frequent model updates.\nThe choice of $b$ does affect the convergence rate.\nSection~\\ref{model-update} discusses the efficiency and convergence trade-offs of different values of $b$.\nWe empirically find that a batch size of $50$ performs well across different datasets and use that as a default.\nA cleaning budget $k$ can be used as a stopping criterion once $C(\\dot)$ has been called $k$ times, and so the number of iterations of {ActiveClean\\xspace} is $T = \\frac{k}{b}$.\nAlternatively, the user can clean data until the model is of sufficient accuracy to make a decision.\n\n\\subsubsection{Basic Data Flow} \\label{df}\nThe system first trains the model $\\phi(\\cdot)$ on the dirty dataset to find an initial model $\\theta^{(d)}$ that the system will subsequently improve.\nThe {\\it sampler} selects a sample of size $b$ records from the dataset and passes\nthe sample to the {\\it cleaner}, which executes $C(\\cdot)$ for each sample record and outputs their cleaned versions.\nThe \\emph{updater} uses the cleaned sample to update the weights of the model, thus moving the model closer to the true cleaned model (in expectation).\nFinally, the system either terminates due to a stopping condition (e.g., $C(\\cdot)$ has been called a maximum number of times $k$, or training error convergence),\nor passes control to the {\\it sampler} for the next iteration.\n\n\\subsubsection{Optimizations}\nIn many cases, such as missing values, errors can be efficiently detected.\nA user provided {\\it Detector} can be used to identify such records that are more likely to be dirty, and thus improves the likelihood that the next sample will contain true dirty records.\nFurthermore, the {\\it Estimator} uses previously cleaned data to estimate the effect that cleaning a given record will have on the model.\nThese components can be used separately (if only one is supplied) or together to focus the system's cleaning efforts on records that will most improve the model.\nSection \\ref{opti} describes several instantiations of these components for different data cleaning problems.\nOur experiments show that these optimizations can improve model accuracy by up-to 2.5x (Section \\ref{comp}).\n\n\\subsection{Example}\nThe following example illustrates how a user would apply {ActiveClean\\xspace} to address the use case in Section~\\ref{s:usecase}:\n\\begin{example}\\label{archex}\nThe analyst chooses to use an SVM model, and manually cleans records by hand (the $C(\\cdot)$).  \n{ActiveClean\\xspace} initially selects a sample of $50$ records (the default)  to show the analyst.\nShe identifies a subset of 15 records that are dirty, fixes them by normalizing the drug and corporation names with the help of a search engine, and corrects the labels with typographical or incorrect values.\nThe system then uses the cleaned records to update the the current best model and select the next sample of $50$.\nThe analyst can stop at any time and use the improved model to predict donation likelihoods.\n\\end{example}\n\n\n\n\n\n\n\\iffalse\n  \\noindent To summarize in pseudocode:\n  \\begin{enumerate}[leftmargin=1em]\\scriptsize\\sloppy\n  \\item \\texttt{Init(dirty\\_data, cleaned\\_data, dirty\\_model, batch, iter)}\n  \\item For each t in $\\{1,...,T\\}$\n  \\begin{enumerate}\n    \\item \\texttt{dirty\\_sample $=$ sampler(dirty\\_data, sample\\_prob, detector, batch)}\n    \\item \\texttt{clean\\_sample $=$ Cleaner(dirty\\_sample)}\n    \\item \\texttt{current\\_model $=$ Update(current\\_model, sample\\_prob, clean\\_sample)}\n    \\item \\texttt{cleaned\\_data = cleaned\\_data + clean\\_sample}\n    \\item \\texttt{dirty\\_data = dirty\\_data - clean\\_sample}\n    \\item \\texttt{sample\\_prob $=$ Estimator(dirty\\_data, cleaned\\_data, detector)}\n    \\item \\texttt{detector $=$ DetectorUpdater(detector, cleaned\\_data)}\n  \\end{enumerate}\n  \\item \\texttt{Output: current\\_model}\n  \\end{enumerate}\n\\fi\n\n\n\\iffalse\n  \\subsection{Challenges and Formalization}\n  We highlight the important components and formalize the research questions explored in this paper. \n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Detector (Section \\ref{det}). } The first challenge in {ActiveClean\\xspace} is dirty data detection. In this step, the detector selects a candidate set of dirty records $R_{dirty} \\subseteq R$. There are two techniques to do this: (1) an \\emph{a priori} case, and (2) and an adaptive case. In the \\emph{a priori} case, the detector knows which data is dirty in advance. In the adaptive case, the detector learns classifier based on previously cleaned data to detect corruption in uncleaned data.\n\n  \\vspace{0.5em}\n\n\n\n  \\vspace{0.5em}\n\n\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Update (Section \\ref{model-update}). } This step updates the model $\\theta^{(t)}$ based on the featurized (with featurization $F(\\cdot)$) cleaned sample $F(S_{clean})$ resulting in $\\theta^{(t+1)}$. Analyzing the model update procedure as a stochastic gradient descent algorithm will help derive the sampling distribution and estimation.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Estimator (Section \\ref{sampling}): } The estimator approximates the optimal distribution derived in the Sample step. Based on the change in the featurized data $F(S_{clean})$ and $F(S_{dirty})$, it directs the next iteration of sampling to select points that will have changes most valuable to the next model update.\n\n\n  \\subsection{Optimizations}\n  There are three aspects of {ActiveClean\\xspace}, that allow us to achieve this design point: error partitioning, gradient-based model update (Section \\ref{model-update}), estimate-driven sampling (Section \\ref{sampling}).\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Partitioning Dirty and Clean Data: } In many applications, enumerating the set of corrupted records is much easier than cleaning them. For example, we may be able to select the set of rows that have missing values but actually filling those missing values is expensive. Likewise, in the constraint literature, selecting a set of rows that have a violated constraint can be done in polynomial time, however, fixing the constraints is NP-Hard.\n  In our error detection step, we partition the dirty and clean data.\n  Partitioning serves two purposes: (1) it reduces the variance of our updates because we can cheaply scan over data we know that is clean, and (2) it increases the fraction of actually dirty records in the candidate batch.\n  A good example of why we need the second objective is seen in the context of crowdsourcing.\n  If we have a crowdworker clean records, we will have to pay them for the task whether or not the record required cleaning.\n  To efficiently use this partitioning, we need a database solution indexing dirty and clean data.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Gradient-Based Updates: } In {ActiveClean\\xspace}, we start with a dirty model and then make an update using a gradient step. Here, we can draw an analogy to Materialized View maintenance, since after all, a model parametrized by $\\theta$ is just a table of floating point numbers.\n  Krishnan et al. proposed a technique called sample view cleaning, in which they take a clean sample of data and propagate the updates to a Materialized View.\n  Similarly, in this work, we take the information from a sample of cleaned data and propagate an update with the gradient.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Estimate-Driven Sampling: } Repair is the most expensive step in the workflow, so optimizing for scan cost may lead to negligible overall time improvements.\n  We can sacrifice a small overhead in pre-computation for each data point to determine its value to the model and select a sampling distribution accordingly.\n  Intuitively, while each iteration has an increased cost, it also makes more progress towards the optimum.\n\n\n  \\begin{example}\n\n  The analyst first trains an SVM model on the dirty data ignoring the effects of the errors resulting in a model $\\theta^{(d)}$.\n  She decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\n  She initializes {ActiveClean\\xspace} with $\\theta^{(d)}$.\n  {ActiveClean\\xspace} samples an initial batch of 10 records.\n  She manually cleans those records by merging similar drug names, making corporation names consistent, and fixing incorrect labels.\n  After each batch, the model is updated with the most recent cleaning results $\\theta^{(t)}$.\n  The model improves after each iteration.\n  After $t=10$ of cleaning, the analyst has an accurate model trained with 100 cleaned records but still utilizes the entire dirty data.\n  \\end{example}\n\\fi\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/arch.png}\n \\caption{{ActiveClean\\xspace} allows users to train predictive models while progressively cleaning data. The framework adaptively selects the best data to clean and can optionally (denoted with dotted lines) integrate with pre-defined detection rules and estimation algorithms for improved conference. \\label{sys-arch}}\n\\end{figure}\n\n\n\n\\section{Updates With Correctness}\\label{model-update}\nThis section describes an algorithm for reliable model updates.\nThe updater assumes that it is given a sample of data $S_{dirty}$ from $R_{dirty}$ where $i \\in S_{dirty}$ has a known sampling probability $p(i)$.\nSections \\ref{dist-samp} and \\ref{opti} show how to optimize $p(\\cdot)$ and the analysis in this section applies for any sampling distribution $p(\\cdot) > 0$.\n\n\\subsection{Geometric Derivation}\\label{geod}\nThe update algorithm intuitively follows from the convex geometry of the problem.\nConsider the problem in one dimension (i.e., the parameter $\\theta$ is a scalar value), so then the goal is to find the minimum point ($\\theta$) of a curve $l(\\theta)$.\nThe consequence of dirty data is that the wrong loss function is optimized.\nFigure \\ref{update-arch2}A illustrates the consequence of the optimization.\nThe red dotted line shows the loss function on the dirty data.\nOptimizing the loss function finds $\\theta^{(d)}$ that at the minimum point (red star).\nHowever, the true loss function (w.r.t to the clean data) is in blue, thus\nthe optimal value on the dirty data is in fact a suboptimal point on clean curve (red circle).\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/update-arch2.png}\\vspace{-1em}\n \\caption{(A) A model trained on dirty data can be thought of as a sub-optimal point w.r.t to the clean data. (B) The gradient gives us the direction to move the suboptimal model to approach the true optimum. \\label{update-arch2}}\\vspace{-1em}\n\\end{figure}\n\nThe optimal clean model $\\theta^{(c)}$ is visualized as a yellow star.\nThe first question is which direction to update $\\theta^{(d)}$ (i.e., left or right).\nFor this class of models, given a suboptimal point, the direction to \nthe global optimum is the gradient of the loss function.\nThe gradient is a $d$-dimensional vector function of the current model $\\theta^{(d)}$ and the clean data.\nTherefore, {ActiveClean\\xspace} needs to update $\\theta^{(d)}$ some distance $\\gamma$ (Figure \\ref{update-arch2}B):\n", "itemtype": "equation", "pos": 34563, "prevtext": "\n SGD can also be applied in a ``mini-batch\" mode, where we draw a subset of data $S^{(t)}$ at random and update with the average gradient.\n\n", "index": 17, "text": "\\[\n \\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\frac{\\gamma}{\\|S^{(t)}\\|}\\sum_{i\\in S^{(t)}}\\nabla\\phi(x_{i}^T\\theta,y_{i})\n \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\frac{\\gamma}{\\|S^{(t)}\\|}\\sum_{i\\in S^{(%&#10;t)}}\\nabla\\phi(x_{i}^{T}\\theta,y_{i})\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mfrac><mi>\u03b3</mi><mrow><mo>\u2225</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2225</mo></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></munder><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><mo>\u2062</mo><mi>\u03b8</mi></mrow><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nAt the optimal point, the magnitude of the gradient will be zero.\nSo intuitively, this approach iteratively moves the model downhill (transparent red circle) -- correcting the dirty model until the desired accuracy is reached.\nHowever, the gradient depends on all of the clean data which is not available and {ActiveClean\\xspace} will have to approximate the gradient from a sample of newly cleaned data.\nThe main intuition is that if the gradient steps are on average correct, the model still moves downhill albeit with a reduced convergence rate proportional to the inaccuracy of the sample-based estimate.\n\nTo derive a sample-based update rule, the most important property is that sums commute with derivatives and gradients.\nThe convex loss class of models are sums of losses, so given the current best model $\\theta$, the true gradient $g^*(\\theta)$ is:\n", "itemtype": "equation", "pos": 47446, "prevtext": "\n\nWe can use this workflow for designing an anytime data cleaning methodology.\nAs data is sampled, we can clean the samples.\nThe analyst then can stop at anytime and use the best model at that instant.\nSGD and its variants are well-studied and there are lower-bounds on the convergence rates using these techniques. \nRecently, a number of works have explored non-uniform sampling distributions for stochastic optimization \\cite{zhao2014stochastic, qu2014randomized}.\nThe main insight is that non-uniform distributions may on average estimate the gradient accurately.\nIn this work, we explore how to design such a non-uniform distribution for iterative data cleaning.\n\n\\fi\n\n\n \n\n\\section{Architecture}\\label{arch}\n\\noindent This section presents the {ActiveClean\\xspace} architecture.\n\n\\subsection{Overview}\\label{sysover}\nFigure \\ref{sys-arch} illustrates the {ActiveClean\\xspace} architecture.\nThe dotted boxes describe optional components that the user can provide to improve the efficiency of the system.  \n\n\\subsubsection{Required User Input}\\label{uinp}\n\n\n\\noindent\\textbf{Model:} The user provides a predictive model (e.g., SVM) specified as a convex loss optimization problem $\\phi(\\cdot)$ and a featurizer $F(\\cdot)$ that maps a record to its feature vector $x$ and label $y$.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Cleaning Function: } The user provides a function $C(\\cdot)$ (implemented via software or crowdsourcing) that maps dirty records to clean records as per our definition in Section \\ref{dmodel}. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Batches: } Data are cleaned in batches of size $b$ and the user can change these settings if she desires more or less frequent model updates.\nThe choice of $b$ does affect the convergence rate.\nSection~\\ref{model-update} discusses the efficiency and convergence trade-offs of different values of $b$.\nWe empirically find that a batch size of $50$ performs well across different datasets and use that as a default.\nA cleaning budget $k$ can be used as a stopping criterion once $C(\\dot)$ has been called $k$ times, and so the number of iterations of {ActiveClean\\xspace} is $T = \\frac{k}{b}$.\nAlternatively, the user can clean data until the model is of sufficient accuracy to make a decision.\n\n\\subsubsection{Basic Data Flow} \\label{df}\nThe system first trains the model $\\phi(\\cdot)$ on the dirty dataset to find an initial model $\\theta^{(d)}$ that the system will subsequently improve.\nThe {\\it sampler} selects a sample of size $b$ records from the dataset and passes\nthe sample to the {\\it cleaner}, which executes $C(\\cdot)$ for each sample record and outputs their cleaned versions.\nThe \\emph{updater} uses the cleaned sample to update the weights of the model, thus moving the model closer to the true cleaned model (in expectation).\nFinally, the system either terminates due to a stopping condition (e.g., $C(\\cdot)$ has been called a maximum number of times $k$, or training error convergence),\nor passes control to the {\\it sampler} for the next iteration.\n\n\\subsubsection{Optimizations}\nIn many cases, such as missing values, errors can be efficiently detected.\nA user provided {\\it Detector} can be used to identify such records that are more likely to be dirty, and thus improves the likelihood that the next sample will contain true dirty records.\nFurthermore, the {\\it Estimator} uses previously cleaned data to estimate the effect that cleaning a given record will have on the model.\nThese components can be used separately (if only one is supplied) or together to focus the system's cleaning efforts on records that will most improve the model.\nSection \\ref{opti} describes several instantiations of these components for different data cleaning problems.\nOur experiments show that these optimizations can improve model accuracy by up-to 2.5x (Section \\ref{comp}).\n\n\\subsection{Example}\nThe following example illustrates how a user would apply {ActiveClean\\xspace} to address the use case in Section~\\ref{s:usecase}:\n\\begin{example}\\label{archex}\nThe analyst chooses to use an SVM model, and manually cleans records by hand (the $C(\\cdot)$).  \n{ActiveClean\\xspace} initially selects a sample of $50$ records (the default)  to show the analyst.\nShe identifies a subset of 15 records that are dirty, fixes them by normalizing the drug and corporation names with the help of a search engine, and corrects the labels with typographical or incorrect values.\nThe system then uses the cleaned records to update the the current best model and select the next sample of $50$.\nThe analyst can stop at any time and use the improved model to predict donation likelihoods.\n\\end{example}\n\n\n\n\n\n\n\\iffalse\n  \\noindent To summarize in pseudocode:\n  \\begin{enumerate}[leftmargin=1em]\\scriptsize\\sloppy\n  \\item \\texttt{Init(dirty\\_data, cleaned\\_data, dirty\\_model, batch, iter)}\n  \\item For each t in $\\{1,...,T\\}$\n  \\begin{enumerate}\n    \\item \\texttt{dirty\\_sample $=$ sampler(dirty\\_data, sample\\_prob, detector, batch)}\n    \\item \\texttt{clean\\_sample $=$ Cleaner(dirty\\_sample)}\n    \\item \\texttt{current\\_model $=$ Update(current\\_model, sample\\_prob, clean\\_sample)}\n    \\item \\texttt{cleaned\\_data = cleaned\\_data + clean\\_sample}\n    \\item \\texttt{dirty\\_data = dirty\\_data - clean\\_sample}\n    \\item \\texttt{sample\\_prob $=$ Estimator(dirty\\_data, cleaned\\_data, detector)}\n    \\item \\texttt{detector $=$ DetectorUpdater(detector, cleaned\\_data)}\n  \\end{enumerate}\n  \\item \\texttt{Output: current\\_model}\n  \\end{enumerate}\n\\fi\n\n\n\\iffalse\n  \\subsection{Challenges and Formalization}\n  We highlight the important components and formalize the research questions explored in this paper. \n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Detector (Section \\ref{det}). } The first challenge in {ActiveClean\\xspace} is dirty data detection. In this step, the detector selects a candidate set of dirty records $R_{dirty} \\subseteq R$. There are two techniques to do this: (1) an \\emph{a priori} case, and (2) and an adaptive case. In the \\emph{a priori} case, the detector knows which data is dirty in advance. In the adaptive case, the detector learns classifier based on previously cleaned data to detect corruption in uncleaned data.\n\n  \\vspace{0.5em}\n\n\n\n  \\vspace{0.5em}\n\n\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Update (Section \\ref{model-update}). } This step updates the model $\\theta^{(t)}$ based on the featurized (with featurization $F(\\cdot)$) cleaned sample $F(S_{clean})$ resulting in $\\theta^{(t+1)}$. Analyzing the model update procedure as a stochastic gradient descent algorithm will help derive the sampling distribution and estimation.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Estimator (Section \\ref{sampling}): } The estimator approximates the optimal distribution derived in the Sample step. Based on the change in the featurized data $F(S_{clean})$ and $F(S_{dirty})$, it directs the next iteration of sampling to select points that will have changes most valuable to the next model update.\n\n\n  \\subsection{Optimizations}\n  There are three aspects of {ActiveClean\\xspace}, that allow us to achieve this design point: error partitioning, gradient-based model update (Section \\ref{model-update}), estimate-driven sampling (Section \\ref{sampling}).\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Partitioning Dirty and Clean Data: } In many applications, enumerating the set of corrupted records is much easier than cleaning them. For example, we may be able to select the set of rows that have missing values but actually filling those missing values is expensive. Likewise, in the constraint literature, selecting a set of rows that have a violated constraint can be done in polynomial time, however, fixing the constraints is NP-Hard.\n  In our error detection step, we partition the dirty and clean data.\n  Partitioning serves two purposes: (1) it reduces the variance of our updates because we can cheaply scan over data we know that is clean, and (2) it increases the fraction of actually dirty records in the candidate batch.\n  A good example of why we need the second objective is seen in the context of crowdsourcing.\n  If we have a crowdworker clean records, we will have to pay them for the task whether or not the record required cleaning.\n  To efficiently use this partitioning, we need a database solution indexing dirty and clean data.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Gradient-Based Updates: } In {ActiveClean\\xspace}, we start with a dirty model and then make an update using a gradient step. Here, we can draw an analogy to Materialized View maintenance, since after all, a model parametrized by $\\theta$ is just a table of floating point numbers.\n  Krishnan et al. proposed a technique called sample view cleaning, in which they take a clean sample of data and propagate the updates to a Materialized View.\n  Similarly, in this work, we take the information from a sample of cleaned data and propagate an update with the gradient.\n\n  \\vspace{0.5em}\n\n  \\noindent\\textbf{Estimate-Driven Sampling: } Repair is the most expensive step in the workflow, so optimizing for scan cost may lead to negligible overall time improvements.\n  We can sacrifice a small overhead in pre-computation for each data point to determine its value to the model and select a sampling distribution accordingly.\n  Intuitively, while each iteration has an increased cost, it also makes more progress towards the optimum.\n\n\n  \\begin{example}\n\n  The analyst first trains an SVM model on the dirty data ignoring the effects of the errors resulting in a model $\\theta^{(d)}$.\n  She decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\n  She initializes {ActiveClean\\xspace} with $\\theta^{(d)}$.\n  {ActiveClean\\xspace} samples an initial batch of 10 records.\n  She manually cleans those records by merging similar drug names, making corporation names consistent, and fixing incorrect labels.\n  After each batch, the model is updated with the most recent cleaning results $\\theta^{(t)}$.\n  The model improves after each iteration.\n  After $t=10$ of cleaning, the analyst has an accurate model trained with 100 cleaned records but still utilizes the entire dirty data.\n  \\end{example}\n\\fi\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/arch.png}\n \\caption{{ActiveClean\\xspace} allows users to train predictive models while progressively cleaning data. The framework adaptively selects the best data to clean and can optionally (denoted with dotted lines) integrate with pre-defined detection rules and estimation algorithms for improved conference. \\label{sys-arch}}\n\\end{figure}\n\n\n\n\\section{Updates With Correctness}\\label{model-update}\nThis section describes an algorithm for reliable model updates.\nThe updater assumes that it is given a sample of data $S_{dirty}$ from $R_{dirty}$ where $i \\in S_{dirty}$ has a known sampling probability $p(i)$.\nSections \\ref{dist-samp} and \\ref{opti} show how to optimize $p(\\cdot)$ and the analysis in this section applies for any sampling distribution $p(\\cdot) > 0$.\n\n\\subsection{Geometric Derivation}\\label{geod}\nThe update algorithm intuitively follows from the convex geometry of the problem.\nConsider the problem in one dimension (i.e., the parameter $\\theta$ is a scalar value), so then the goal is to find the minimum point ($\\theta$) of a curve $l(\\theta)$.\nThe consequence of dirty data is that the wrong loss function is optimized.\nFigure \\ref{update-arch2}A illustrates the consequence of the optimization.\nThe red dotted line shows the loss function on the dirty data.\nOptimizing the loss function finds $\\theta^{(d)}$ that at the minimum point (red star).\nHowever, the true loss function (w.r.t to the clean data) is in blue, thus\nthe optimal value on the dirty data is in fact a suboptimal point on clean curve (red circle).\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=\\columnwidth]{figs/update-arch2.png}\\vspace{-1em}\n \\caption{(A) A model trained on dirty data can be thought of as a sub-optimal point w.r.t to the clean data. (B) The gradient gives us the direction to move the suboptimal model to approach the true optimum. \\label{update-arch2}}\\vspace{-1em}\n\\end{figure}\n\nThe optimal clean model $\\theta^{(c)}$ is visualized as a yellow star.\nThe first question is which direction to update $\\theta^{(d)}$ (i.e., left or right).\nFor this class of models, given a suboptimal point, the direction to \nthe global optimum is the gradient of the loss function.\nThe gradient is a $d$-dimensional vector function of the current model $\\theta^{(d)}$ and the clean data.\nTherefore, {ActiveClean\\xspace} needs to update $\\theta^{(d)}$ some distance $\\gamma$ (Figure \\ref{update-arch2}B):\n", "index": 19, "text": "\n\\[\n\\theta^{new} \\leftarrow \\theta^{(d)} - \\gamma \\cdot \\nabla\\phi(\\theta^{(d)})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\theta^{new}\\leftarrow\\theta^{(d)}-\\gamma\\cdot\\nabla\\phi(\\theta^{(d)})\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mrow><mi>\u03b3</mi><mo>\u22c5</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n{ActiveClean\\xspace} needs to estimate $g^*(\\theta)$ from a sample $S$, which is drawn from the dirty data $R_{dirty}$.\n Therefore, the sum has two components the gradient on the already clean data $g_C$ which can be computed without cleaning and $g_S$ the gradient estimate from a sample of dirty data to be cleaned:\n", "itemtype": "equation", "pos": 48388, "prevtext": "\nAt the optimal point, the magnitude of the gradient will be zero.\nSo intuitively, this approach iteratively moves the model downhill (transparent red circle) -- correcting the dirty model until the desired accuracy is reached.\nHowever, the gradient depends on all of the clean data which is not available and {ActiveClean\\xspace} will have to approximate the gradient from a sample of newly cleaned data.\nThe main intuition is that if the gradient steps are on average correct, the model still moves downhill albeit with a reduced convergence rate proportional to the inaccuracy of the sample-based estimate.\n\nTo derive a sample-based update rule, the most important property is that sums commute with derivatives and gradients.\nThe convex loss class of models are sums of losses, so given the current best model $\\theta$, the true gradient $g^*(\\theta)$ is:\n", "index": 21, "text": "\n\\[\ng^*(\\theta) = \\nabla\\phi(\\theta) = \\frac{1}{N} \\sum_i^N \\nabla\\phi(x_i^{(c)},y_i^{(c)},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"g^{*}(\\theta)=\\nabla\\phi(\\theta)=\\frac{1}{N}\\sum_{i}^{N}\\nabla\\phi(x_{i}^{(c)}%&#10;,y_{i}^{(c)},\\theta)\" display=\"block\"><mrow><mrow><msup><mi>g</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi><mi>N</mi></munderover><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n$g_C$ can be calculated by applying the gradient to all of the already cleaned records:\n", "itemtype": "equation", "pos": 48807, "prevtext": "\n{ActiveClean\\xspace} needs to estimate $g^*(\\theta)$ from a sample $S$, which is drawn from the dirty data $R_{dirty}$.\n Therefore, the sum has two components the gradient on the already clean data $g_C$ which can be computed without cleaning and $g_S$ the gradient estimate from a sample of dirty data to be cleaned:\n", "index": 23, "text": "\n\\[\ng(\\theta) = \\frac{\\mid R_{clean} \\mid}{\\mid R \\mid} \\cdot g_C(\\theta) + \\frac{\\mid R_{dirty} \\mid}{\\mid R \\mid} \\cdot g_S(\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"g(\\theta)=\\frac{\\mid R_{clean}\\mid}{\\mid R\\mid}\\cdot g_{C}(\\theta)+\\frac{\\mid R%&#10;_{dirty}\\mid}{\\mid R\\mid}\\cdot g_{S}(\\theta)\" display=\"block\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>C</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>S</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n$g_S$ can be estimated from a sample by taking the gradient w.r.t each record, and re-weighting the average by their respective sampling probabilities.\nBefore taking the gradient the cleaning function $C(\\cdot)$ is applied to each sampled record.\nTherefore, let $S$ be a sample of data, where each $i \\in S$ is drawn with probability $p(i)$:\n", "itemtype": "equation", "pos": 49031, "prevtext": "\n$g_C$ can be calculated by applying the gradient to all of the already cleaned records:\n", "index": 25, "text": "\n\\[\ng_C(\\theta) = \\frac{1}{\\mid R_{clean}\\mid}\\sum_{i \\in R_{clean}}\\nabla\\phi(x_i^{(c)},y_i^{(c)},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"g_{C}(\\theta)=\\frac{1}{\\mid R_{clean}\\mid}\\sum_{i\\in R_{clean}}\\nabla\\phi(x_{i%&#10;}^{(c)},y_{i}^{(c)},\\theta)\" display=\"block\"><mrow><mrow><msub><mi>g</mi><mi>C</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub></mrow></munder><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThen, at each iteration $t$, the update becomes:\n", "itemtype": "equation", "pos": 49482, "prevtext": "\n$g_S$ can be estimated from a sample by taking the gradient w.r.t each record, and re-weighting the average by their respective sampling probabilities.\nBefore taking the gradient the cleaning function $C(\\cdot)$ is applied to each sampled record.\nTherefore, let $S$ be a sample of data, where each $i \\in S$ is drawn with probability $p(i)$:\n", "index": 27, "text": "\n\\[\ng_{S}(\\theta) = \\frac{1}{\\mid S \\mid} \\sum_{i \\in S}\\frac{1}{p(i)}\\nabla\\phi(x_i^{(c)},y_i^{(c)},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"g_{S}(\\theta)=\\frac{1}{\\mid S\\mid}\\sum_{i\\in S}\\frac{1}{p(i)}\\nabla\\phi(x_{i}^%&#10;{(c)},y_{i}^{(c)},\\theta)\" display=\"block\"><mrow><mrow><msub><mi>g</mi><mi>S</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><mi>S</mi><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><mi>S</mi></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\subsection{Model Update Algorithm}\nTo summarize, the algorithm is initialized with $\\theta^{(0)} = \\theta^{(d)}$ which is the dirty model.\nThere are three user set parameters the budget $k$, batch size $b$, and the step size $\\gamma$.\nIn the following section, we will provide references from the convex optimization literature that allow the user to appropriately select these values.\nAt each iteration $t=\\{1,...,T\\}$, the cleaning is applied to a batch of data $b$ selected from the set of candidate dirty records $R_{dirty}$.\nThen, an average gradient is estimated from the cleaned batch and the model is updated.\nIterations continue until $k = T \\cdot b$ records are cleaned.\n\n\\begin{enumerate}[noitemsep]\n\t\\item Calculate the gradient over the sample of newly clean data and call the result $g_S(\\theta^{(t)})$\n\t\\item Calculate the average gradient over all of the already clean data in $R_{clean}=R-R_{dirty}$, and call the result $g_C(\\theta^{(t)})$\n\t\\item Apply the following update rule:\n\n", "itemtype": "equation", "pos": 49642, "prevtext": "\nThen, at each iteration $t$, the update becomes:\n", "index": 29, "text": "\n\\[\n\\theta^{(t+1)} \\leftarrow \\theta^{(t)} - \\gamma \\cdot g(\\theta^{(t)})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\gamma\\cdot g(\\theta^{(t)})\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mrow><mi>\u03b3</mi><mo>\u22c5</mo><mi>g</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\\end{enumerate} \n\n\\subsection{Analysis with Stochastic Gradient Descent}\\label{sgd}\nThe update algorithm can be formalized as a class of very well studied algorithms called Stochastic Gradient Descent.\nSGD provides a theoretical framework to understand and analyze the update rule and bound the error.\nMini-batch stochastic gradient descent (SGD) is an algorithm for finding the optimal value\ngiven the convex loss and data.\nIn mini-batch SGD, random subsets of data are selected at each iteration and the average gradient is computed for every batch.\n\nOne key difference with traditional SGD models is that {ActiveClean\\xspace} applies a \\emph{full} gradient step on the already clean data and averages it with a stochastic gradient step (i.e., calculated from a sample) on the dirty data. \nTherefore, {ActiveClean\\xspace} iterations can take multiple passes over the clean data but at most a single cleaning pass of the dirty data.\nThe update algorithm can be thought of as a variant of SGD that lazily materializes the clean value.\nAs data is sampled at each iteration, data is cleaned when needed by the optimization.\nIt is well known that even for an arbitrary initialization SGD makes significant progress in less than one epoch (a pass through the entire dataset) \\cite{bottou2012stochastic}.\nIn practice, the dirty model can be much more accurate than an arbitrary initialization as corruption may only affect a few features and combined with the full gradient step on the clean data the updates converge very quickly.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ Setting the step size $\\gamma$: } There is extensive literature in machine learning for choosing the step size $\\gamma$ appropriately. $\\gamma$ can be set either to be a constant or decayed over time. Many machine learning frameworks (e.g., MLLib, Sci-kit Learn, Vowpal Wabbit) automatically set learning rates or provide different learning scheduling frameworks. \nIn the experiments, we use a technique called inverse scaling where there is a parameter $\\gamma_0=0.1$, and at each iteration it decays to $\\gamma_t = \\frac{\\gamma_0}{\\mid S \\mid t}$. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ Setting the batch size $b$: } The batch size should be set by the user to have the desired properties.\nLarger batches will take longer to clean and will make more progress towards the clean model but will have less frequent model updates.\nOn the other hand, smaller batches are cleaned faster and have more frequent model updates.\nThere are diminishing returns to increasing the batch size $O(\\frac{1}{\\sqrt{b}})$.\nIn the experiments, we use a batch size of 50 which converges fast but allows for frequent model updates.\nIf a data cleaning technique requires a larger batch size than 50, i.e., data cleaning is fast enough that the iteration overhead is significant compared to cleaning 50 records, {ActiveClean\\xspace} can apply the updates in smaller batches.\nFor example, the batch size set by the user might be $b=1000$, but the model updates after every $50$ records are cleaned.\nWe can disassociate the batching requirements of SGD and the batching requirements of the data cleaning technique.\n\n\\subsubsection{Convergence Conditions and Properties}\nConvergence properties of batch SGD formulations have been well studied \\cite{dekel2012optimal}. Essentially, if the gradient estimate is unbiased and the step size is appropriately chosen, the algorithm is guaranteed to converge. \nIn Appendix \\ref{appsgd}, we show that the gradient estimate from {ActiveClean\\xspace} is indeed unbiased and our choice of step size is one that is established to converge.\nThe convergence rates of SGD are also well analyzed \\cite{dekel2012optimal,bertsekas2011incremental,zhao2014stochastic}. \nThe analysis gives a bound on the error of intermediate models and the expected number of steps before achieving a model within a certain error. \nFor a general convex loss, a batch size $b$, and $T$ iterations, the convergence rate is bounded by $O(\\frac{\\sigma^2}{\\sqrt{bT}})$. \n$\\sigma^2$ is the variance in the estimate of the gradient at each iteration:\n", "itemtype": "equation", "pos": 50720, "prevtext": "\n\n\\subsection{Model Update Algorithm}\nTo summarize, the algorithm is initialized with $\\theta^{(0)} = \\theta^{(d)}$ which is the dirty model.\nThere are three user set parameters the budget $k$, batch size $b$, and the step size $\\gamma$.\nIn the following section, we will provide references from the convex optimization literature that allow the user to appropriately select these values.\nAt each iteration $t=\\{1,...,T\\}$, the cleaning is applied to a batch of data $b$ selected from the set of candidate dirty records $R_{dirty}$.\nThen, an average gradient is estimated from the cleaned batch and the model is updated.\nIterations continue until $k = T \\cdot b$ records are cleaned.\n\n\\begin{enumerate}[noitemsep]\n\t\\item Calculate the gradient over the sample of newly clean data and call the result $g_S(\\theta^{(t)})$\n\t\\item Calculate the average gradient over all of the already clean data in $R_{clean}=R-R_{dirty}$, and call the result $g_C(\\theta^{(t)})$\n\t\\item Apply the following update rule:\n\n", "index": 31, "text": "\\[\n\t\\theta^{(t+1)} \\leftarrow \\theta^{(t)} - \\gamma \\cdot(\\frac{\\mid R_{dirty} \\mid}{\\mid R \\mid} \\cdot g_S(\\theta^{(t)}) + \\frac{\\mid R_{clean} \\mid}{\\mid R \\mid} \\cdot  g_C(\\theta^{(t)}))\n\t\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\gamma\\cdot(\\frac{\\mid R_{dirty}\\mid}{%&#10;\\mid R\\mid}\\cdot g_{S}(\\theta^{(t)})+\\frac{\\mid R_{clean}\\mid}{\\mid R\\mid}%&#10;\\cdot g_{C}(\\theta^{(t)}))\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mi>\u03b3</mi><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>S</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>C</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nwhere $g^*$ is the gradient computed over the full data if it were fully cleaned.\nThis property of SGD allows us to bound the model error with a monotonically decreasing function of the number of records cleaned, thus satisfying the reliability condition in the problem statement.\nIf the loss in non-convex, the update procedure will converge towards a local minimum rather than the global minimum (See Appendix \\ref{non-convex}).\n\n\\subsection{Example}\nThis example describes an application of the update algorithm.\n\\begin{example}\\label{upex}\nRecall that the analyst has a dirty SVM model on the dirty data $\\theta^{(d)}$.\nShe decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\nAll of the data is initially treated as dirty with $R_{dirty} = R$ and $R_{clean} = \\emptyset$.\nThe gradient of a basic SVM is given by the following function:\n", "itemtype": "equation", "pos": 55004, "prevtext": "\n\\end{enumerate} \n\n\\subsection{Analysis with Stochastic Gradient Descent}\\label{sgd}\nThe update algorithm can be formalized as a class of very well studied algorithms called Stochastic Gradient Descent.\nSGD provides a theoretical framework to understand and analyze the update rule and bound the error.\nMini-batch stochastic gradient descent (SGD) is an algorithm for finding the optimal value\ngiven the convex loss and data.\nIn mini-batch SGD, random subsets of data are selected at each iteration and the average gradient is computed for every batch.\n\nOne key difference with traditional SGD models is that {ActiveClean\\xspace} applies a \\emph{full} gradient step on the already clean data and averages it with a stochastic gradient step (i.e., calculated from a sample) on the dirty data. \nTherefore, {ActiveClean\\xspace} iterations can take multiple passes over the clean data but at most a single cleaning pass of the dirty data.\nThe update algorithm can be thought of as a variant of SGD that lazily materializes the clean value.\nAs data is sampled at each iteration, data is cleaned when needed by the optimization.\nIt is well known that even for an arbitrary initialization SGD makes significant progress in less than one epoch (a pass through the entire dataset) \\cite{bottou2012stochastic}.\nIn practice, the dirty model can be much more accurate than an arbitrary initialization as corruption may only affect a few features and combined with the full gradient step on the clean data the updates converge very quickly.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ Setting the step size $\\gamma$: } There is extensive literature in machine learning for choosing the step size $\\gamma$ appropriately. $\\gamma$ can be set either to be a constant or decayed over time. Many machine learning frameworks (e.g., MLLib, Sci-kit Learn, Vowpal Wabbit) automatically set learning rates or provide different learning scheduling frameworks. \nIn the experiments, we use a technique called inverse scaling where there is a parameter $\\gamma_0=0.1$, and at each iteration it decays to $\\gamma_t = \\frac{\\gamma_0}{\\mid S \\mid t}$. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ Setting the batch size $b$: } The batch size should be set by the user to have the desired properties.\nLarger batches will take longer to clean and will make more progress towards the clean model but will have less frequent model updates.\nOn the other hand, smaller batches are cleaned faster and have more frequent model updates.\nThere are diminishing returns to increasing the batch size $O(\\frac{1}{\\sqrt{b}})$.\nIn the experiments, we use a batch size of 50 which converges fast but allows for frequent model updates.\nIf a data cleaning technique requires a larger batch size than 50, i.e., data cleaning is fast enough that the iteration overhead is significant compared to cleaning 50 records, {ActiveClean\\xspace} can apply the updates in smaller batches.\nFor example, the batch size set by the user might be $b=1000$, but the model updates after every $50$ records are cleaned.\nWe can disassociate the batching requirements of SGD and the batching requirements of the data cleaning technique.\n\n\\subsubsection{Convergence Conditions and Properties}\nConvergence properties of batch SGD formulations have been well studied \\cite{dekel2012optimal}. Essentially, if the gradient estimate is unbiased and the step size is appropriately chosen, the algorithm is guaranteed to converge. \nIn Appendix \\ref{appsgd}, we show that the gradient estimate from {ActiveClean\\xspace} is indeed unbiased and our choice of step size is one that is established to converge.\nThe convergence rates of SGD are also well analyzed \\cite{dekel2012optimal,bertsekas2011incremental,zhao2014stochastic}. \nThe analysis gives a bound on the error of intermediate models and the expected number of steps before achieving a model within a certain error. \nFor a general convex loss, a batch size $b$, and $T$ iterations, the convergence rate is bounded by $O(\\frac{\\sigma^2}{\\sqrt{bT}})$. \n$\\sigma^2$ is the variance in the estimate of the gradient at each iteration:\n", "index": 33, "text": "\n\\[\n\\mathbb{E}(\\|g - g^*\\|^2)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\|g-g^{*}\\|^{2})\" display=\"block\"><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mrow><mo>\u2225</mo><mrow><mi>g</mi><mo>-</mo><msup><mi>g</mi><mo>*</mo></msup></mrow><mo>\u2225</mo></mrow><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\nFor each iteration $t$, a sample of 10 records $S$ is drawn from $R_{dirty}$.\n{ActiveClean\\xspace} then applies the cleaning function to the sample:\n", "itemtype": "equation", "pos": 56033, "prevtext": "\nwhere $g^*$ is the gradient computed over the full data if it were fully cleaned.\nThis property of SGD allows us to bound the model error with a monotonically decreasing function of the number of records cleaned, thus satisfying the reliability condition in the problem statement.\nIf the loss in non-convex, the update procedure will converge towards a local minimum rather than the global minimum (See Appendix \\ref{non-convex}).\n\n\\subsection{Example}\nThis example describes an application of the update algorithm.\n\\begin{example}\\label{upex}\nRecall that the analyst has a dirty SVM model on the dirty data $\\theta^{(d)}$.\nShe decides that she has a budget of cleaning $100$ records, and decides to clean the 100 records in batches of 10 (set based on how fast she can clean the data, and how often she wants to see an updated result).\nAll of the data is initially treated as dirty with $R_{dirty} = R$ and $R_{clean} = \\emptyset$.\nThe gradient of a basic SVM is given by the following function:\n", "index": 35, "text": "\n\\[\n\\nabla\\phi(x,y,\\theta) =\n\\begin{cases}      \n-y\\cdot\\boldsymbol{x} \\text{ if } y\\cdot\\boldsymbol{x}\\cdot\\theta \\le 1 \\\\\n~~~~~~~0\\ \\text{ if } y\\ \\boldsymbol{x}\\cdot\\theta \\geq 1      \n\\end{cases}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x,y,\\theta)=\\begin{cases}-y\\cdot\\bm{x}\\text{ if }y\\cdot\\bm{x}\\cdot%&#10;\\theta\\leq 1\\\\&#10;\\leavevmode\\nobreak\\ \\leavevmode\\nobreak\\ \\leavevmode\\nobreak\\ \\leavevmode%&#10;\\nobreak\\ \\leavevmode\\nobreak\\ \\leavevmode\\nobreak\\ \\leavevmode\\nobreak\\ 0\\ %&#10;\\text{ if }y\\ \\bm{x}\\cdot\\theta\\geq 1\\end{cases}\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>-</mo><mrow><mrow><mrow><mi>y</mi><mo>\u22c5</mo><mi>\ud835\udc99</mi></mrow><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mi>y</mi></mrow><mo>\u22c5</mo><mi>\ud835\udc99</mi><mo>\u22c5</mo><mi>\u03b8</mi></mrow></mrow><mo>\u2264</mo><mn>1</mn></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mn>\u2005\u2005\u2005\u2005\u2005\u2005\u20050</mn></mpadded><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>y</mi></mpadded><mo>\u2062</mo><mi>\ud835\udc99</mi></mrow><mo>\u22c5</mo><mi>\u03b8</mi></mrow><mo>\u2265</mo><mn>1</mn></mrow></mtd><mtd/></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nUsing these values, {ActiveClean\\xspace} estimates the gradient on the newly cleaned data:\n", "itemtype": "equation", "pos": 56385, "prevtext": "\n\nFor each iteration $t$, a sample of 10 records $S$ is drawn from $R_{dirty}$.\n{ActiveClean\\xspace} then applies the cleaning function to the sample:\n", "index": 37, "text": "\n\\[\n\\{(x_i^{(c)},y_i^{(c)})\\} = \\{C(i): \\forall i \\in S\\}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\{(x_{i}^{(c)},y_{i}^{(c)})\\}=\\{C(i):\\forall i\\in S\\}\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:</mo><mrow><mrow><mo>\u2200</mo><mi>i</mi></mrow><mo>\u2208</mo><mi>S</mi></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n{ActiveClean\\xspace} also applies the gradient to the already clean data (initially non-existent):\n", "itemtype": "equation", "pos": 56536, "prevtext": "\nUsing these values, {ActiveClean\\xspace} estimates the gradient on the newly cleaned data:\n", "index": 39, "text": "\n\\[\ng_{S}(\\theta) = \\frac{1}{10} \\sum_{i \\in S}\\frac{1}{p(i)}\\nabla\\phi(x_i^{(c)},y_i^{(c)},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"g_{S}(\\theta)=\\frac{1}{10}\\sum_{i\\in S}\\frac{1}{p(i)}\\nabla\\phi(x_{i}^{(c)},y_%&#10;{i}^{(c)},\\theta)\" display=\"block\"><mrow><mrow><msub><mi>g</mi><mi>S</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mn>10</mn></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><mi>S</mi></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n$g_S$ can be estimated from a sample by taking the gradient w.r.t each record, and re-weighting the average by their respective sampling probabilities.\nBefore taking the gradient the cleaning function $C(\\cdot)$ is applied to each sampled record.\nTherefore, let $S$ be a sample of data, where each $i \\in S$ is drawn with probability $p(i)$:\n", "itemtype": "equation", "pos": 49031, "prevtext": "\n$g_C$ can be calculated by applying the gradient to all of the already cleaned records:\n", "index": 25, "text": "\n\\[\ng_C(\\theta) = \\frac{1}{\\mid R_{clean}\\mid}\\sum_{i \\in R_{clean}}\\nabla\\phi(x_i^{(c)},y_i^{(c)},\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"g_{C}(\\theta)=\\frac{1}{\\mid R_{clean}\\mid}\\sum_{i\\in R_{clean}}\\nabla\\phi(x_{i%&#10;}^{(c)},y_{i}^{(c)},\\theta)\" display=\"block\"><mrow><mrow><msub><mi>g</mi><mi>C</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2208</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub></mrow></munder><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": " \nFinally, $R_{dirty} \\leftarrow R_{dirty} - S$, $R_{clean} \\leftarrow R_{clean} + S$, and continue to the next iteration.\n\\end{example}\n\n\\section{Efficiency With Sampling}\\label{dist-samp}\nThe \\emph{updater} received a sample with probabilities $p(\\cdot)$.\nFor any distribution where  $p(\\cdot) > 0$, we can preserve correctness.\n{ActiveClean\\xspace} uses a sampling algorithm that selects the most valuable records to clean with higher probability. \n\n\\subsection{Oracle Sampling Problem}\nRecall that the convergence rate of an SGD algorithm is bounded by $\\sigma^2$ which is the variance of the gradient.\nIntuitively, the variance measures how accurately the gradient is estimated from a uniform sample.\nOther sampling distributions, while preserving the sample expected value, may have a lower variance.\nThus, the oracle sampling problem is defined as a search over sampling distributions to find the minimum variance sampling distribution.\n\n\\begin{definition}[Oracle Sampling Problem]\nGiven a set of candidate dirty data $R_{dirty}$, $\\forall r \\in R_{dirty}$ find sampling probabilities $p(r)$ such that over all samples $S$ of size $k$ it minimizes:\n", "itemtype": "equation", "pos": -1, "prevtext": "\nThen, it calculates the update rule:\n", "index": 43, "text": "\n\\[\n\t\\theta^{(t+1)} \\leftarrow \\theta^{(t)} - \\gamma \\cdot(\\frac{\\mid R_{dirty} \\mid}{\\mid R \\mid} \\cdot g_S(\\theta^{(t)}) + \\frac{\\mid R_{clean} \\mid}{\\mid R \\mid} \\cdot  g_C(\\theta^{(t)}))\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"\\theta^{(t+1)}\\leftarrow\\theta^{(t)}-\\gamma\\cdot(\\frac{\\mid R_{dirty}\\mid}{%&#10;\\mid R\\mid}\\cdot g_{S}(\\theta^{(t)})+\\frac{\\mid R_{clean}\\mid}{\\mid R\\mid}%&#10;\\cdot g_{C}(\\theta^{(t)}))\" display=\"block\"><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2190</mo><mrow><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><mi>\u03b3</mi><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>S</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><msub><mi>g</mi><mi>C</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\\end{definition}\nIt can be shown that the optimal distribution over records in $R_{dirty}$ is probabilities proportional to:\n", "itemtype": "equation", "pos": 58231, "prevtext": " \nFinally, $R_{dirty} \\leftarrow R_{dirty} - S$, $R_{clean} \\leftarrow R_{clean} + S$, and continue to the next iteration.\n\\end{example}\n\n\\section{Efficiency With Sampling}\\label{dist-samp}\nThe \\emph{updater} received a sample with probabilities $p(\\cdot)$.\nFor any distribution where  $p(\\cdot) > 0$, we can preserve correctness.\n{ActiveClean\\xspace} uses a sampling algorithm that selects the most valuable records to clean with higher probability. \n\n\\subsection{Oracle Sampling Problem}\nRecall that the convergence rate of an SGD algorithm is bounded by $\\sigma^2$ which is the variance of the gradient.\nIntuitively, the variance measures how accurately the gradient is estimated from a uniform sample.\nOther sampling distributions, while preserving the sample expected value, may have a lower variance.\nThus, the oracle sampling problem is defined as a search over sampling distributions to find the minimum variance sampling distribution.\n\n\\begin{definition}[Oracle Sampling Problem]\nGiven a set of candidate dirty data $R_{dirty}$, $\\forall r \\in R_{dirty}$ find sampling probabilities $p(r)$ such that over all samples $S$ of size $k$ it minimizes:\n", "index": 45, "text": "\n\\[\n\\mathbb{E}(\\|g_S - g^*\\|^2)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\|g_{S}-g^{*}\\|^{2})\" display=\"block\"><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mrow><mo>\u2225</mo><mrow><msub><mi>g</mi><mi>S</mi></msub><mo>-</mo><msup><mi>g</mi><mo>*</mo></msup></mrow><mo>\u2225</mo></mrow><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThis is an established result, for thoroughness, we provide a proof in the appendix (Section \\ref{impsample-deriv}), but intuitively, records with higher gradients should be sampled with higher probability as they affect the update more significantly.\nHowever, {ActiveClean\\xspace} cannot exclude records with lower gradients as that would induce a bias hurting convergence.\nThe problem is that the optimal distribution leads to a chicken-and-egg problem:\nthe optimal sampling distribution requires knowing $(x^{(c)}_i,y^{(c)}_i)$, however, cleaning is required to know those values.\n\n\\subsection{Dirty Gradient Solution}\\label{dgsample}\nSuch an oracle does not exist, and one solution is to use the gradient w.r.t to the dirty data:\n", "itemtype": "equation", "pos": 58390, "prevtext": "\n\\end{definition}\nIt can be shown that the optimal distribution over records in $R_{dirty}$ is probabilities proportional to:\n", "index": 47, "text": "\n\\[\np_i \\propto \\|\\nabla\\phi(x^{(c)}_i,y^{(c)}_i,\\theta^{(t)})\\|\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"p_{i}\\propto\\|\\nabla\\phi(x^{(c)}_{i},y^{(c)}_{i},\\theta^{(t)})\\|\" display=\"block\"><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u221d</mo><mrow><mo>\u2225</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIt turns out that the solution works reasonably well in practice on our experimental datasets and has been studied in Machine Learning as the Expected Gradient Length heuristic \\cite{settles2010active}.\nThe contribution in this work is integrating this heuristic with statistically correct updates.\nHowever, intuitively, approximating the oracle as closely as possible can result in improved prioritization.\nThe subsequent section describes two components, the detector and estimator, that can be used to improve the convergence rate.\nOur experiments suggest up-to a 2x improvement in convergence when using these optional optimizations (Section \\ref{comp}).\n\\section{Optimizations}\\label{opti}\n\n\nIn this section, we describe two approaches to optimization, the {\\it Detector} and the {\\it Estimator}, that\nimprove the efficiency of the cleaning process.  \nBoth approaches are designed to increase the likelihood that the \n{\\it Sampler} will pick dirty records that, once cleaned,\nmost move the model towards the true clean model.\nThe {\\it Detector} is intended to learn the characteristics that distinguish dirty records from clean records\nwhile the {\\it Estimator} is designed to estimate the amount that cleaning a given dirty record will move the \nmodel towards the true optimal model.\n\n\n\\input{detector}\n\\input{estimator}\n\n\n\n\n\\section{Experiments}\\label{eval}\nFirst, the experiments evaluate how various types of corrupted data benefit from data cleaning.\nNext, the experiments explore different prioritization and model update schemes for progressive data cleaning.\nFinally, {ActiveClean\\xspace} is evaluated end-to-end in a number of real-world data cleaning scenarios.\n\n\\subsection{Experimental Setup and Notation}\nThe main metric for evaluation is a relative measure of the trained model and the model if all of the data is cleaned.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Relative Model Error. } Let $\\theta$ be the model trained on the dirty data, and let $\\theta^*$ be the model trained on the same data if it was cleaned. Then the model error is defined as $\\frac{\\|\\theta - \\theta^*\\|}{\\|\\theta^*\\|}$.\n\n\\subsubsection{Scenarios}\n\n\n\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Income Classification (Adult): } In this dataset of 45,552 records, the task is to predict the income bracket (binary) from 12 numerical and categorical covariates with an SVM classifier. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Seizure Classification (EEG): } In this dataset, the task is to predict the onset of a seizure (binary) from 15 numerical covariates with a thresholded Linear Regression. There are 14980 data points in this dataset. This classification task is inherently hard with an accuracy on completely clean data of only 65\\%.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Handwriting Recognition (MNIST) \\footnote{\\scriptsize\\url{http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset}}: } In this dataset, the task is to classify 60,000 images of handwritten images into 10 categories with an one-to-all multiclass SVM classifier. The unique part of this dataset is the featurized data consists of a 784 dimensional vector which includes edge detectors and raw image patches. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Dollars For Docs: } The dataset has 240,089 records with 5 textual attributes and one numerical attribute.\nThe dataset is featurized with bag-of-words featurization model for the textual attributes which resulted in a 2021 dimensional feature vector, and a binary SVM is used to classify the status of the medical donations.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{World Bank: } The dataset has 193 records of country name, population, and various macro-economics statistics. The values are listed with the date at which they were acquired. This allowed us to determine that records from smaller and less populous countries were more likely to be out-of-date.\n\n\\subsubsection{Compared Algorithms}\n\\noindent Here are the alternative methodologies evaluated in the experiments:\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Robust Logistic Regression \\cite{feng2014robust}. } Feng et al. proposed a variant of logistic regression that is robust to outliers. We chose this algorithm because it is a robust extension of the convex regularized loss model, leading to a better apples-to-apples comparison between the techniques. (See details in Appendix \\ref{rlogit})  \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Discarding Dirty Data. } As a baseline, dirty data are discarded.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{SampleClean (SC) \\cite{wang1999sample}. } SampleClean takes a sample of data, applies data cleaning, and then trains a model to completion on the sample.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Active Learning (AL) \\cite{guillory2009active}. } To fairly evaluate Active Learning, we first apply our gradient update to ensure correctness.\nWithin each iteration, examples are prioritized by distance to the decision boundary (called Uncertainty Sampling in \\cite{settles2010active}).\nHowever, we do not include our optimizations such as detection and estimation.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ActiveClean Oracle (AC+O): } In {ActiveClean\\xspace} Oracle, instead of an estimation and detection step, the true clean value is used to evaluate the theoretical ideal performance of {ActiveClean\\xspace}.\n\n\\subsection{Does Data Cleaning Matter?}\nThe first experiment evaluates the benefits of data cleaning on two of the example datasets (EEG and Adult).\nOur goal is to understand which types of data corruption are amenable to data cleaning and which are better suited for robust statistical techniques.\nThe experiment compares four schemes: (1) full data cleaning  , (2) baseline of no cleaning, (3) discarding the dirty data, and (4) robust logistic regression,. We corrupted 5\\% of the training examples in each dataset in two different ways:\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Random Corruption: } Simulated high-magnitude random outliers. 5\\% of the examples are selected at random and a random feature is replaced with 3 times the highest feature value.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Systematic Corruption: } Simulated innocuous looking (but still incorrect) systematic corruption. The model is trained on the clean data, and the three most important features (highest weighted) are identified. The examples are sorted by each of these features and the top examples are corrupted with the mean value for that feature (5\\% corruption in all). \nIt is important to note that examples can have multiple corrupted features.\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp2.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp1.pdf}\n \\includegraphics[width=0.5\\columnwidth]{exp/legend-1.png}\\vspace{-1em}\n \\caption{(a) Robust techniques and discarding data work when corrupted data are random and look atypical. (b) Data cleaning can provide reliable performance in both the systematically corrupted setting and randomly corrupted setting.\\label{sys-rand}}\\vspace{-1.5em}\n\\end{figure}\n\nFigure \\ref{sys-rand} shows the test accuracy for models trained on both types of data with the different techniques.\nThe robust method performs well on the random high-magnitude outliers with only a 2.0\\% reduction in clean test accuracy for EEG and 2.5\\% reduction for Adult.\nIn the random setting, discarding dirty data also performs relatively well.\nHowever, the robust method falters on the systematic corruption with a 9.1\\% reduction in clean test accuracy for EEG and 10.5\\% reduction for Adult.\n\nThe problem is that without cleaning, there is no way to know if the corruption is random or systematic and when to trust a robust method.\nWhile data cleaning requires more effort, it provides benefits in both settings.\nIn the remaining experiments, unless otherwise noted, the experiments use systematic corruption.\n\n\\noindent \\emph{Summary: A 5\\% systematic corruption can introduce a 10\\% reduction in test accuracy even when using a robust method.}\n\n\\subsection{{ActiveClean\\xspace}: \\protect\\textit{\\large A Priori} Detection}\nThe next set of experiments evaluate different approaches to cleaning a sample of data compared to {ActiveClean\\xspace} using \\emph{a priori} detection.\n\\emph{A priori} detection assumes that all of the corrupted records are known in advance but their clean values are unknown. \n\n\\subsubsection{Active Learning and SampleClean}\nThe next experiment evaluates the samples-to-error tradeoff between four alternative algorithms: {ActiveClean\\xspace} (AC), SampleClean, Active Learning, and {ActiveClean\\xspace}+Oracle (AC+O).\nFigure \\ref{prio-perf} shows the model error and test accuracy as a function of the number of cleaned records.\nIn terms of model error, {ActiveClean\\xspace} gives its largest benefits for small sample sizes.\nFor 500 cleaned records of the Adult dataset, {ActiveClean\\xspace} has 6.1x less error than SampleClean and 2.1x less error than Active Learning.\nFor 500 cleaned records of the EEG dataset, {ActiveClean\\xspace} has 9.6x less error than SampleClean and 2.4x less error than Active Learning.\nBoth Active Learning and {ActiveClean\\xspace} benefit from the initialization with the dirty model as they do not retrain their models from scratch, and {ActiveClean\\xspace} improves on this performance with detection and error estimation.\nActive Learning has no notion of dirty and clean data, and therefore prioritizes with respect to the dirty data.\nThese gains in model error also correlate well to improvements in test error (defined as the test accuracy difference w.r.t cleaning all data).\nThe test error converges more quickly than model error, emphasizing the benefits of progressive data cleaning, since it is not neccessary to clean all the data to get a model with essentially the same performance as the clean model.\nFor example, to achieve a test error of 1\\% on the Adult dataset, {ActiveClean\\xspace} cleans 500 fewer records than Active Learning.\n\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} with a priori detection returns results that are more than 6x more accurate than SampleClean and 2x more accurate than Active Learning for cleaning 500 records.}\n\n\\begin{figure}[t]\n\\centering\\vspace{-1em}\n \n \\includegraphics[width=0.49\\columnwidth]{exp/exp3b.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3c.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3bb.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3cc.pdf}\n  \\includegraphics[width=0.5\\columnwidth]{exp/legend-general.png}\\vspace{-0.5em}\n \\caption{ The relative model error as a function of the number of examples cleaned. {ActiveClean\\xspace} converges with a smaller sample size to the true result in comparison to Active Learning and SampleClean. \\label{prio-perf}}\\vspace{-1em}\n\\end{figure}\n\n\\subsubsection{Source of Improvements}\\label{comp}\nThe next experiment compares the performance of {ActiveClean\\xspace} with and without various optimizations at 500 records cleaned point. \n{ActiveClean\\xspace} without detection is denoted as (AC-D) (that is at each iteration we sample from the entire dirty data), and {ActiveClean\\xspace} without detection and importance sampling is denoted as (AC-D-I).\nFigure \\ref{opts} plots the relative error of the alternatives and {ActiveClean\\xspace} with and without the optimizations.\nWithout detection (AC-D), {ActiveClean\\xspace} is still more accurate than Active Learning.\nRemoving the importance sampling, {ActiveClean\\xspace} is slightly worse than Active Learning on the Adult dataset but is comparable on the EEG dataset.\n\n\\begin{figure}[t]\\vspace{0.5em}\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp8a.png}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp8b.png}\n \\includegraphics[width=0.5\\columnwidth]{exp/legend-8.png}\\vspace{-1em}\n \\caption{ -D denotes no detection, and -D-I denotes no detection and no importance sampling. Both optimizations significantly help {ActiveClean\\xspace} outperform SampleClean and Active Learning. \\label{opts}}\\vspace{-1.5em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: Both a priori detection and non-uniform sampling significantly contribute to the gains over Active Learning.}\n\n\\iffalse\nWe evaluate Active Learning and {ActiveClean\\xspace} to better understand this relationship.\nIn Figure \\ref{albias}, we vary the biasing effect of the random corruptions.\nThat is, we start with zero mean noise and increase the mean value and variance of the noise.\nSince Active Learning uses the gradient, if there is zero mean noise, in expectation, the dirty data and clean data are the same.\nHowever, as the bias increases, the fact that Active Learning prioritizes w.r.t to the dirty data matters more and becomes increasingly erroneous w.r.t to {ActiveClean\\xspace}.\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.6\\columnwidth]{exp/exp10.pdf}\n \\caption{As we increase the biasing nature of the corruption, Active Learning is increasingly erroneous w.r.t {ActiveClean\\xspace}. \\label{albias}}\n\\end{figure}\n\\fi\n\n\\subsubsection{Mixing Dirty and Clean Data}\nTraining a model on mixed data is an unreliable methodology lacking the same guarantees as Active Learning or SampleClean even in the simplest of cases.\nFor thoroughness, the next experiments include the model error as a function of records cleaned in comparison to {ActiveClean\\xspace}.\nFigure \\ref{pc-perf} plots the same curves as the previous experiment comparing {ActiveClean\\xspace}, Active Learning, and two mixed data algorithms.\nPC randomly samples data, clean, and writes-back the cleaned data.\nPC+D randomly samples data from using the dirty data detector, cleans, and writes-back the cleaned data.\nFor these errors PC and PC+D give reasonable results (not always guaranteed), but {ActiveClean\\xspace} converges faster.\n{ActiveClean\\xspace} tunes the weighting when averaging dirty and clean data into the gradient.\n\n\\begin{figure}[ht!]\n\\centering\\vspace{-0.5em}\n \n \\includegraphics[width=0.49\\columnwidth]{exp/exp14a.pdf}\n    \\includegraphics[width=0.49\\columnwidth]{exp/exp14b.pdf}\n    \\includegraphics[width=0.49\\columnwidth]{exp/legend-14.png}\\vspace{-0.5em}\n \\caption{The relative model error as a function of the number of examples cleaned. {ActiveClean\\xspace} converges with a smaller sample size to the true result in comparison to partial cleaning (PC,PC+D).  \\label{pc-perf}}\n\\end{figure}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} converges faster than mixing dirty and clean data since it reweights data based on the fraction that is dirty and clean. Partial cleaning is not guaranteed to give sensible results.}\n\n\\vspace{1em}\n\n\\subsubsection{Corruption Rate}\nThe next experiment explores how much of the performance\nis due to the initialization with the dirty model (i.e., SampleClean trains a model from ``scratch\").\nFigure \\ref{bias} varies the systematic corruption rate and plots the number of records cleaned to achieve 1\\% relative error for SampleClean and {ActiveClean\\xspace}.\nSampleClean does not use the dirty data and thus its error is essentially governed by the Central Limit Theorem.\nSampleClean outperforms {ActiveClean\\xspace} only when corruptions are very severe (45\\% in Adult and nearly 60\\% in EEG).\nWhen the initialization with the dirty model is inaccurate, {ActiveClean\\xspace} does not perform as well. \n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp9a.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp9b.pdf}\\vspace{-1em}\n \\caption{{ActiveClean\\xspace} performs well until the corruption is so severe that the dirty model is not a good initialization. The error of SampleClean does not depend on the corruption rate so it is a vertical line.  \\label{bias}}\\vspace{-1.5em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: SampleClean is beneficial in comparison to {ActiveClean\\xspace} when corruption rates exceed 45\\%.}\n\n\\subsection{{ActiveClean\\xspace}: Adaptive Detection}\nThis experiment explores how the results of the previous experiment change when using an adaptive detector instead of the \\emph{a priori} detector.\nRecall, in the systematic corruption, 3 of the most informative features were corrupted, thus we group these problems into $9$ classes.\nWe use an all-versus-one SVM to learn the categorization.\n\n\\subsubsection{Basic Performance}\nFigure \\ref{pred-perf} overlays the convergence plots in the previous experiments with a curve (denoted by AC+C) that represents {ActiveClean\\xspace} using a classifier instead of the \\emph{a priori} detection. Initially {ActiveClean\\xspace} is comparable to Active Learning; however, as the classifier becomes more effective the detection improves the performance.\nOver both datasets, at the 500 records point on the curve, adaptive {ActiveClean\\xspace} has a 30\\% higher model error compared to \\emph{a priori} {ActiveClean\\xspace}.\nAt 1000 records point on the curve, adaptive {ActiveClean\\xspace} has about 10\\% higher error.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: For 500 records cleaned, adaptive {ActiveClean\\xspace} has a 30\\% higher model error compared to a priori {ActiveClean\\xspace}, but still outperforms Active Learning and SampleClean.}\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp11a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp11b.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/legend-11.png}\\vspace{-0.5em}\n \\caption{Even with a classifier {ActiveClean\\xspace} converges faster than Active Learning and SampleClean. \\label{pred-perf}}\\vspace{-1.0em}\n\\end{figure}\n\n\n\\subsubsection{Classifiable Errors}\nThe adaptive case depends on being able to predict corrupted records.\nFor example, random corruption not correlated with any other data features may be hard to learn.\nAs corruption becomes more random, the classifier becomes increasingly erroneous.\nThe next experiment explores making the systematic corruption more random.\nInstead of selecting the highest valued records for the most valuable features, we corrupt random records with probability $p$. \nWe compare these results to AC-D where we do not have a detector at all at one vertical slice of the previous plot (cleaning 1000 records).\nFigure \\ref{tradeoffs2}a plots the relative error reduction using a classifier.\nWhen the corruption is about 50\\% random then there is a break even point where no detection is better.\nThe classifier is imperfect and misclassifies some data points incorrectly as cleaned.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: When errors are increasingly random (50\\% random) and cannot be accurately classified, adaptive detection provides no benefit over no detection. }\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp5a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp12.pdf}\\vspace{-0.5em}\n \\caption{(a) Data corruptions that are less random are easier to classify, and lead to more significant reductions in relative model error. (b) The Taylor series approximation gives more accurate estimates when the amount of cleaned data is small. \\label{tradeoffs2}}\n\\end{figure}\n\n\\subsection{Estimation}\\label{est}\nThe next experiment compares estimation techniques: (1) ``linear regression\" trains a linear regression model that predicts the clean gradient as a function of the dirty gradient, (2) ``average gradient\" which does not use the detection to inform how to apply the estimate, (3) ``average feature change\" uses detection but no linearization, and (4) the Taylor series linear approximation.\nFigure \\ref{tradeoffs2}b measures how accurately each estimation technique estimates the gradient as a function of the number of cleaned records on the EEG dataset.\n\nEstimation error is measured using the relative L2 error with the true gradient.\nThe Taylor series approximation proposed gives more accurate for small cleaning sizes.\nLinear regression and the average feature change technique do eventually perform comparably but only after cleaning much more data.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: Linearized gradient estimates are more accurate when estimated from small samples. }\n\n\\subsection{Real World Scenarios}\nThe next set of experiments evaluate {ActiveClean\\xspace} in three real world scenarios, one demonstrating the \\emph{a priori} case and the other two for the adaptive detection case.\n\n\\subsubsection{A Priori: Constraint Cleaning}\\label{dfd-exp}\nThe first scenario explores the Dollars for Docs dataset published by ProPublica described throughout the paper.\nTo run this experiment, the entire dataset was cleaned up front, and simulated sampling from the dirty data and cleaning by looking up the value in the cleaned data (see Appendix \\ref{dfd-errors} for constraints, errors, and cleaning methodology).\nFigure \\ref{dfd}a shows that {ActiveClean\\xspace} converges faster than Active Learning and SampleClean.\nTo achieve a 4\\% relative error (i.e., a 75\\% error reduction from the dirty model), {ActiveClean\\xspace} cleans 40000 fewer records than Active Learning.\nAlso, for 10000 records cleaned, {ActiveClean\\xspace} has nearly an order of magnitude smaller error than SampleClean.\n\nFigure \\ref{dfd}b shows the detection rate (fraction of disallowed research contributions identified) of the classifier as a function of the number of records cleaned. \nOn the dirty data, we can only correctly classify 66\\% of the suspected examples (88\\% overall accuracy due to a class imbalance).\nOn the cleaned data, this classifier is nearly perfect with a 97\\% true positive rate (98\\% overall accuracy).\n{ActiveClean\\xspace} converges to the cleaned accuracy faster than the alternatives with a classifier of 92\\% true positive rate for only 10000 records cleaned.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: To achieve an 80\\% detection rate, {ActiveClean\\xspace} cleans nearly 10x less records than Active Learning. }\n\n\\begin{figure}[t]\n\\centering\\vspace{-1em}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp13a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp13b.pdf}\\vspace{-1em}\n \\caption{(a) The relative model error as a function of the number of cleaned records. (b) The true positive rate as a function of the number of cleaned records. \\label{dfd}}\n\\end{figure}\n\n\\subsubsection{Adaptive: Replacing Corrupted Data}\nThe next experiment explores the MNIST handwritten digit recognition dataset with a MATLAB image processing pipeline.\nIn this scenario, the analyst must inspect a potentially corrupted image and replace it with a higher quality one.\nThe MNIST dataset consists of 64x64 grayscale images.\nThere are two types of simulated corruptions: (1) 5x5 block removal where a random 5x5 block is removed from the image by setting its pixel values to 0, and (2) Fuzzy where a 4x4 moving average patch is applied over the entire image.\nThese corruptions are applied to a random 5\\% of the images, and mimic the random (Fuzzy) vs. systematic corruption (5x5 removal) studied in the previous experiments.\nThe adaptive detector uses a 10 class classifier (one for each digit) to detect the corruption.\n\nFigure \\ref{mnist} shows that {ActiveClean\\xspace} makes more progress towards the clean model with a smaller number of examples cleaned.\nTo achieve a 2\\% error for the block removal, {ActiveClean\\xspace} can inspect 2200 fewer images than Active Learning and 2750 fewer images than SampleClean.\nFor the fuzzy images, both Active Learning and {ActiveClean\\xspace} reach 2\\% error after cleaning fewer than 100 images, while SampleClean requires 1750.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: In the MNIST dataset, {ActiveClean\\xspace} significantly reduces (more than 2x) the number of images to clean to train a model with 2\\% error. }\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp7a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp7b.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/legend-general.png}\\vspace{-0.5em}\n \\caption{In a real adaptive detection scenario with the MNIST dataset, {ActiveClean\\xspace} outperforms Active Learning and SampleClean.  \\label{mnist}}\\vspace{-1em}\n\\end{figure}\n\n\\subsubsection{Adaptive: Regression}\nIn the prior two experiments, we explored classification problems.\nIn this experiment, we consider the case when the convex model represents a linear regression model.\nRegression models allow us to visualize what is happening when we apply {ActiveClean\\xspace}.\nIn Figure \\ref{wb}, we illustrate regression model training on a small dataset of 193 countries collected from the World Bank.\nEach country has an associated population and total dollar value of imports. \nWe are interested in examining the relationship between these variables.\nHowever, for some countries, the import values are out-of-date in the World Bank dataset. \nUp-to-date values are usually avaiable on national statistics websites and can be determined with some web searching.\nIt turns out that smaller countries were more likely to have out-of-date statistics in the World Bank dataset, and as a result, the trend line is misleading in the dirty data.\nWe applied {ActiveClean\\xspace} after verifying 30 out of the 193 countries (marked in yellow), and found that we could achieve a highly accurate approximation of the full result.\n\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/worldbank1.png}\n \\includegraphics[width=0.49\\columnwidth]{exp/worldbank2.png}\n \\caption{World Bank Data. We apply {ActiveClean\\xspace} to learn an accurate model predicting population from import values. The data has a systematic bias where small countries have out-of-date import values. \\label{wb}}\\vspace{-1em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} is accurate even in regression analytics. }\n\n\\vspace{-1em}\n\\section{Related Work}\\label{rw}\n\\noindent \\textbf{Data Cleaning: } \nWhen data cleaning is expensive, it is desirable to apply it \\textbf{progressively}, where analysts can inspect early results with only $k \\ll N$ records cleaned.\nProgressive data cleaning is a well studied problem especially in the context of entity resolution \\cite{altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.\nPrior work has focused on the problem of designing data structures and algorithms to apply data cleaning progressively. which is challenging because many data cleaning algorithms require information from the entire relation.\nOver the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning~\\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}.\n{ActiveClean\\xspace} studies the problem of prioritizing progressive cleaning by leveraging information about a user's subsequent use for the data.\nCertain records, if cleaned, may be more likely to affect the downstream analysis.\n\nThere are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning~\\cite{DBLP:journals/pvldb/YakoutENOI11,yakout2013don,gokhale2014corleone}.\nFor example, Yakout et al. train a model that evaluates the likelihood of a proposed replacement value \\cite{yakout2013don}.\nAnother application of machine learning is value imputation, where a missing value is predicted based on those records without missing values.\nMachine learning is also increasingly applied to make automated repairs more reliable with human validation \\cite{DBLP:journals/pvldb/YakoutENOI11}.\nHuman input is often expensive and impractical to apply to entire large datasets.\nMachine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data \\cite{gokhale2014corleone, DBLP:journals/pvldb/YakoutENOI11}.\nThis approach can be coupled with active learning \\cite{DBLP:journals/pvldb/MozafariSFJM14} to learn an accurate model with the fewest possible number of examples.\nWhile, in spirit, {ActiveClean\\xspace} is similar to these approaches, it addresses a very different problem of data cleaning before user-specified modeling.\nThe key new challenge in this problem is ensuring the correctness of the user's model after partial data cleaning.\n\nSampleClean~\\cite{wang1999sample} applies data cleaning to a sample of data, and estimates the results of aggregate queries.\nSampling has also been applied to estimate the number of duplicates in a relation \\cite{heise2014estimating}. \nSimilarly, Bergman et al. explore the problem of query-oriented data cleaning \\cite{DBLP:conf/sigmod/BergmanMNT15}, where given a query, they clean data relevant to that query. \nExisting work does not explore cleaning driven by the downstream machine learning ``queries\" studied in this work.\nDeshpande et al. studied data acquisition in sensor networks \\cite{deshpande2004model}. They explored value of information based prioritization of data acquisition for estimating aggregate queries of sensor readings.\nSimilarly, Jeffery et al. \\cite{DBLP:conf/pervasive/JefferyAFHW06} explored similar prioritization based on value of information.\nWe see this work as pushing prioritization further down the pipeline to the end analytics.\nFinally, incremental optimization methods like SGD have a connection to incremental materialized view maintenance as the argument for incremental maintenance over recomputation is similar (i.e., relatively sparse updates).\nKrishnan et al. explored how samples of materialized views can be maintained similar to how models are updated with a sample of clean data in this work \\cite{krishnan2015svc}.\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Stochastic Optimization and Active Learning: } Zhao and Tong recently proposed using importance sampling in conjunction with stochastic gradient descent \\cite{zhao2014stochastic}. \nThe ideas applied in {ActiveClean\\xspace} are well rooted in the Machine Learning and Optimization literature, and we apply these ideas to the data cleaning problem. \nThis line of work builds on prior results in linear algebra that show that some matrix columns are more informative than others \\cite{drineas2012fast}, and Active Learning which shows that some labels are more informative that others \\cite{settles2010active}.\nActive Learning largely studies the problem of label acquisition \\cite{settles2010active},\nand recently the links between Active Learning and Stochastic optimization have been studied \\cite{guillory2009active}. \nWe use the work in Guillory et al. to evaluate a state-of-the-art Active Learning technique against {ActiveClean\\xspace}.\n\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Transfer Learning and Bias Mitigation: }  \n{ActiveClean\\xspace} has a strong link to a field called Transfer Learning and Domain Adaptation \\cite{pan2010survey}. The basic idea of Transfer Learning is that suppose a model is trained on a dataset $D$ but tested on a dataset $D'$. \nMuch of the complexity and contribution of {ActiveClean\\xspace} comes from efficiently tuning such a process for expensive data cleaning applications -- costs not studied in Transfer Learning.\nIn robotics, Mahler et al. explored a calibration problem in which data was systematically corrupted \\cite{DBLP:conf/case/MahlerKLSMKPWFAG14} and proposed a rule-based technique for cleaning data.\nOther problems in bias mitigation (e.g., Krishnan et al. \\cite{DBLP:conf/recsys/KrishnanPFG14}) have the same structure, systematically corrupted data that is feeding into a model.\nIn this work, we try to generalize these principles given a general dirty dataset, convex model, and data cleaning procedure.\n\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Secure Learning: } {ActiveClean\\xspace} is also related to work in adversarial learning \\cite{nelson2012query}, where the goal is to make models robust to adversarial data manipulation.\nThis line of work has extensively studied methodologies for making models private to external queries and robust to malicious labels \\cite{xiaofeature}, but the data cleaning problem explores more general corruptions than just malicious labels.\nOne widely applied technique in this field is reject-on-negative impact, which essentially, discards data that reduces the loss function--which will not work when we do not have access to the true loss function (only the ``dirty loss\"). \n\n\n\n\\section{Discussion and Future Work}\nThe experimental results suggest the following conclusions about {ActiveClean\\xspace}: (1) when the data corruption rate is relatively small (e.g., 5\\%), {ActiveClean\\xspace} cleans fewer records than Active Learning or SampleClean to achieve the same model accuracy, (2) all of the optimizations in {ActiveClean\\xspace} (importance sampling, detection, and estimation) lead to significantly more accurate models at small sample sizes, (3) only when corruption rates are very severe (e.g. 50\\%) , SampleClean outperforms {ActiveClean\\xspace}, and (4) two real-world scenarios demonstrate similar accuracy improvements where {ActiveClean\\xspace} returns significantly more accurate models than SampleClean or Active Learning for the same number of records cleaned.\n\nThere are also a few additional points for discussion.\n{ActiveClean\\xspace} provides guarantees for training error on models trained with progressive data cleaning, however, there are no such guarantees on test error. \nThis work focuses on the problem where an analyst has a large amount of dirty data and would like explore data cleaning and predictive models on this dataset.\nBy providing the analyst more accurate model estimates, the value of different data cleaning techniques can be judged without having to clean the entire dataset.\nHowever, the exploratory analysis problem is distinct from the model deployment problem (i.e., serving predictions to users from the model), which we hope to explore in more detail in future work.\nIt implicitly assumes that when the model is deployed, it will be applied in a setting where the test data is also clean.\nTraining on clean data, and testing on dirty data, defeats the purpose of data cleaning and can lead to unreliable predictions.\n\nAs the experiments clearly show, {ActiveClean\\xspace} is not strictly \\emph{better} than Active Learning or SampleClean.\n{ActiveClean\\xspace} is optimized for a specific design point of sparse errors and small sample sizes, and the empirical results suggest it returns more accurate models in this setting.\nAs sample sizes and error rates increase, the benefits of {ActiveClean\\xspace} are reduced.\nAnother consideration for future work is automatically selecting alternative techniques when {ActiveClean\\xspace} is expected to perform poorly.\n\nBeyond these limitations, there are several exciting new avenues for future work.\nThe data cleaning models explored in this work can be extended to handle non-uniform costs, where different errors have a different cleaning cost.\nNext, the empirical success of Deep Learning has led to increasing industry and research adoption of non-convex losses in many tasks that were traditionally served by convex models.\nIn future work, we hope to explore how we can integrate with such frameworks.\n\n\n\\section{Conclusion}\nThe growing popularity of predictive models in data analytics adds additional challenges in managing dirty data.\nProgressive data cleaning in this setting is susceptible to errors due to mixing dirty and clean data, sensitivity to sample size, and the sparsity of errors.\nThe key insight of {ActiveClean\\xspace} is that an important class of predictive models, called convex loss models (e.g., linear regression and SVMs), can be simultaneously trained and cleaned.\nConsequently, there are provable guarantees on the convergence and error bounds of {ActiveClean\\xspace}.  \n{ActiveClean\\xspace} also includes numerous optimizations such as: using the information from the model to inform data cleaning on samples, dirty data detection to avoid sampling clean data, and batching updates.\nThe experimental results are promising as they suggest that these optimizations can significantly reduce data cleaning costs when errors are sparse and cleaning budgets are small.\nTechniques such as Active Learning and SampleClean are not optimized for the sparse low-budget setting, and {ActiveClean\\xspace} achieves models of similar accuracy for significantly less records cleaned.\n\n\n\\textbf{\\small This research is supported in part by NSF CISE Expeditions Award CCF-1139158, LBNL Award 7076018, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, C3Energy, Cisco, Cray, Cloudera, EMC2, Ericsson, Facebook, Guavus, HP, Huawei, Informatica, Intel, Microsoft, NetApp, Pivotal, Samsung, Schlumberger, Splunk, Virdata and VMware.}\n\n\n\n\\fontsize{7.5pt}{8.0pt} \\selectfont\n\\bibliographystyle{abbrv}\n\\bibliography{ref} \n\\normalsize \\selectfont\n\\appendix\n\n\\section{Set-of-Records Cleaning Model}\\label{set-of-r}\nIn paper, we formalized the analyst-specified data cleaning as follows.\nWe take the sample of the records $S_{dirty}$, and apply data cleaning $C(\\cdot)$.\n$C$ is applied to a record and produces the clean record:\n", "itemtype": "equation", "pos": 59191, "prevtext": "\nThis is an established result, for thoroughness, we provide a proof in the appendix (Section \\ref{impsample-deriv}), but intuitively, records with higher gradients should be sampled with higher probability as they affect the update more significantly.\nHowever, {ActiveClean\\xspace} cannot exclude records with lower gradients as that would induce a bias hurting convergence.\nThe problem is that the optimal distribution leads to a chicken-and-egg problem:\nthe optimal sampling distribution requires knowing $(x^{(c)}_i,y^{(c)}_i)$, however, cleaning is required to know those values.\n\n\\subsection{Dirty Gradient Solution}\\label{dgsample}\nSuch an oracle does not exist, and one solution is to use the gradient w.r.t to the dirty data:\n", "index": 49, "text": "\n\\[\np_i \\propto \\|\\nabla\\phi(x^{(d)}_i,y^{(d)}_i,\\theta^{(t)})\\|\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m1\" class=\"ltx_Math\" alttext=\"p_{i}\\propto\\|\\nabla\\phi(x^{(d)}_{i},y^{(d)}_{i},\\theta^{(t)})\\|\" display=\"block\"><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u221d</mo><mrow><mo>\u2225</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThe record-by-record cleaning model is a formalization of the costs of data cleaning where each record has the same cost to clean and this cost does not change throughout the entire cleaning session.\nThere are, however, some cases when cleaning the first record of a certain type of corruption is expensive but all subsequent records are cheaper.\n\n\\begin{example}\\label{app-ex1}\nIn most spell checking systems, when a misspelling is identified, the system gives an option to fix all instances of that misspelling.\n\\end{example}\n\n\\begin{example}\\label{app-ex2}\nWhen an inconsistent value is identified all other records with the same inconsistency can be efficiently fixed.\n\\end{example}\n\nThis model of data cleaning can fit into our framework and we formalize it as the ``Set-of-Records\" model as opposed to the ``Record-by-Record\" model. \nIn this model, the cleaning function $C(\\cdot)$ is not restricted to updating only the records in the sample.\n$C(\\cdot)$ takes the entire dirty sample as an argument (that is the cleaning is a function of the sample), the dirty data, and updates the entire dirty data:\n", "itemtype": "equation", "pos": 96348, "prevtext": "\nIt turns out that the solution works reasonably well in practice on our experimental datasets and has been studied in Machine Learning as the Expected Gradient Length heuristic \\cite{settles2010active}.\nThe contribution in this work is integrating this heuristic with statistically correct updates.\nHowever, intuitively, approximating the oracle as closely as possible can result in improved prioritization.\nThe subsequent section describes two components, the detector and estimator, that can be used to improve the convergence rate.\nOur experiments suggest up-to a 2x improvement in convergence when using these optional optimizations (Section \\ref{comp}).\n\\section{Optimizations}\\label{opti}\n\n\nIn this section, we describe two approaches to optimization, the {\\it Detector} and the {\\it Estimator}, that\nimprove the efficiency of the cleaning process.  \nBoth approaches are designed to increase the likelihood that the \n{\\it Sampler} will pick dirty records that, once cleaned,\nmost move the model towards the true clean model.\nThe {\\it Detector} is intended to learn the characteristics that distinguish dirty records from clean records\nwhile the {\\it Estimator} is designed to estimate the amount that cleaning a given dirty record will move the \nmodel towards the true optimal model.\n\n\n\\input{detector}\n\\input{estimator}\n\n\n\n\n\\section{Experiments}\\label{eval}\nFirst, the experiments evaluate how various types of corrupted data benefit from data cleaning.\nNext, the experiments explore different prioritization and model update schemes for progressive data cleaning.\nFinally, {ActiveClean\\xspace} is evaluated end-to-end in a number of real-world data cleaning scenarios.\n\n\\subsection{Experimental Setup and Notation}\nThe main metric for evaluation is a relative measure of the trained model and the model if all of the data is cleaned.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Relative Model Error. } Let $\\theta$ be the model trained on the dirty data, and let $\\theta^*$ be the model trained on the same data if it was cleaned. Then the model error is defined as $\\frac{\\|\\theta - \\theta^*\\|}{\\|\\theta^*\\|}$.\n\n\\subsubsection{Scenarios}\n\n\n\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Income Classification (Adult): } In this dataset of 45,552 records, the task is to predict the income bracket (binary) from 12 numerical and categorical covariates with an SVM classifier. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Seizure Classification (EEG): } In this dataset, the task is to predict the onset of a seizure (binary) from 15 numerical covariates with a thresholded Linear Regression. There are 14980 data points in this dataset. This classification task is inherently hard with an accuracy on completely clean data of only 65\\%.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Handwriting Recognition (MNIST) \\footnote{\\scriptsize\\url{http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset}}: } In this dataset, the task is to classify 60,000 images of handwritten images into 10 categories with an one-to-all multiclass SVM classifier. The unique part of this dataset is the featurized data consists of a 784 dimensional vector which includes edge detectors and raw image patches. \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Dollars For Docs: } The dataset has 240,089 records with 5 textual attributes and one numerical attribute.\nThe dataset is featurized with bag-of-words featurization model for the textual attributes which resulted in a 2021 dimensional feature vector, and a binary SVM is used to classify the status of the medical donations.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{World Bank: } The dataset has 193 records of country name, population, and various macro-economics statistics. The values are listed with the date at which they were acquired. This allowed us to determine that records from smaller and less populous countries were more likely to be out-of-date.\n\n\\subsubsection{Compared Algorithms}\n\\noindent Here are the alternative methodologies evaluated in the experiments:\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Robust Logistic Regression \\cite{feng2014robust}. } Feng et al. proposed a variant of logistic regression that is robust to outliers. We chose this algorithm because it is a robust extension of the convex regularized loss model, leading to a better apples-to-apples comparison between the techniques. (See details in Appendix \\ref{rlogit})  \n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Discarding Dirty Data. } As a baseline, dirty data are discarded.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{SampleClean (SC) \\cite{wang1999sample}. } SampleClean takes a sample of data, applies data cleaning, and then trains a model to completion on the sample.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{Active Learning (AL) \\cite{guillory2009active}. } To fairly evaluate Active Learning, we first apply our gradient update to ensure correctness.\nWithin each iteration, examples are prioritized by distance to the decision boundary (called Uncertainty Sampling in \\cite{settles2010active}).\nHowever, we do not include our optimizations such as detection and estimation.\n\n\\vspace{0.25em}\n\n\\noindent\\textbf{ActiveClean Oracle (AC+O): } In {ActiveClean\\xspace} Oracle, instead of an estimation and detection step, the true clean value is used to evaluate the theoretical ideal performance of {ActiveClean\\xspace}.\n\n\\subsection{Does Data Cleaning Matter?}\nThe first experiment evaluates the benefits of data cleaning on two of the example datasets (EEG and Adult).\nOur goal is to understand which types of data corruption are amenable to data cleaning and which are better suited for robust statistical techniques.\nThe experiment compares four schemes: (1) full data cleaning  , (2) baseline of no cleaning, (3) discarding the dirty data, and (4) robust logistic regression,. We corrupted 5\\% of the training examples in each dataset in two different ways:\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Random Corruption: } Simulated high-magnitude random outliers. 5\\% of the examples are selected at random and a random feature is replaced with 3 times the highest feature value.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Systematic Corruption: } Simulated innocuous looking (but still incorrect) systematic corruption. The model is trained on the clean data, and the three most important features (highest weighted) are identified. The examples are sorted by each of these features and the top examples are corrupted with the mean value for that feature (5\\% corruption in all). \nIt is important to note that examples can have multiple corrupted features.\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp2.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp1.pdf}\n \\includegraphics[width=0.5\\columnwidth]{exp/legend-1.png}\\vspace{-1em}\n \\caption{(a) Robust techniques and discarding data work when corrupted data are random and look atypical. (b) Data cleaning can provide reliable performance in both the systematically corrupted setting and randomly corrupted setting.\\label{sys-rand}}\\vspace{-1.5em}\n\\end{figure}\n\nFigure \\ref{sys-rand} shows the test accuracy for models trained on both types of data with the different techniques.\nThe robust method performs well on the random high-magnitude outliers with only a 2.0\\% reduction in clean test accuracy for EEG and 2.5\\% reduction for Adult.\nIn the random setting, discarding dirty data also performs relatively well.\nHowever, the robust method falters on the systematic corruption with a 9.1\\% reduction in clean test accuracy for EEG and 10.5\\% reduction for Adult.\n\nThe problem is that without cleaning, there is no way to know if the corruption is random or systematic and when to trust a robust method.\nWhile data cleaning requires more effort, it provides benefits in both settings.\nIn the remaining experiments, unless otherwise noted, the experiments use systematic corruption.\n\n\\noindent \\emph{Summary: A 5\\% systematic corruption can introduce a 10\\% reduction in test accuracy even when using a robust method.}\n\n\\subsection{{ActiveClean\\xspace}: \\protect\\textit{\\large A Priori} Detection}\nThe next set of experiments evaluate different approaches to cleaning a sample of data compared to {ActiveClean\\xspace} using \\emph{a priori} detection.\n\\emph{A priori} detection assumes that all of the corrupted records are known in advance but their clean values are unknown. \n\n\\subsubsection{Active Learning and SampleClean}\nThe next experiment evaluates the samples-to-error tradeoff between four alternative algorithms: {ActiveClean\\xspace} (AC), SampleClean, Active Learning, and {ActiveClean\\xspace}+Oracle (AC+O).\nFigure \\ref{prio-perf} shows the model error and test accuracy as a function of the number of cleaned records.\nIn terms of model error, {ActiveClean\\xspace} gives its largest benefits for small sample sizes.\nFor 500 cleaned records of the Adult dataset, {ActiveClean\\xspace} has 6.1x less error than SampleClean and 2.1x less error than Active Learning.\nFor 500 cleaned records of the EEG dataset, {ActiveClean\\xspace} has 9.6x less error than SampleClean and 2.4x less error than Active Learning.\nBoth Active Learning and {ActiveClean\\xspace} benefit from the initialization with the dirty model as they do not retrain their models from scratch, and {ActiveClean\\xspace} improves on this performance with detection and error estimation.\nActive Learning has no notion of dirty and clean data, and therefore prioritizes with respect to the dirty data.\nThese gains in model error also correlate well to improvements in test error (defined as the test accuracy difference w.r.t cleaning all data).\nThe test error converges more quickly than model error, emphasizing the benefits of progressive data cleaning, since it is not neccessary to clean all the data to get a model with essentially the same performance as the clean model.\nFor example, to achieve a test error of 1\\% on the Adult dataset, {ActiveClean\\xspace} cleans 500 fewer records than Active Learning.\n\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} with a priori detection returns results that are more than 6x more accurate than SampleClean and 2x more accurate than Active Learning for cleaning 500 records.}\n\n\\begin{figure}[t]\n\\centering\\vspace{-1em}\n \n \\includegraphics[width=0.49\\columnwidth]{exp/exp3b.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3c.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3bb.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp3cc.pdf}\n  \\includegraphics[width=0.5\\columnwidth]{exp/legend-general.png}\\vspace{-0.5em}\n \\caption{ The relative model error as a function of the number of examples cleaned. {ActiveClean\\xspace} converges with a smaller sample size to the true result in comparison to Active Learning and SampleClean. \\label{prio-perf}}\\vspace{-1em}\n\\end{figure}\n\n\\subsubsection{Source of Improvements}\\label{comp}\nThe next experiment compares the performance of {ActiveClean\\xspace} with and without various optimizations at 500 records cleaned point. \n{ActiveClean\\xspace} without detection is denoted as (AC-D) (that is at each iteration we sample from the entire dirty data), and {ActiveClean\\xspace} without detection and importance sampling is denoted as (AC-D-I).\nFigure \\ref{opts} plots the relative error of the alternatives and {ActiveClean\\xspace} with and without the optimizations.\nWithout detection (AC-D), {ActiveClean\\xspace} is still more accurate than Active Learning.\nRemoving the importance sampling, {ActiveClean\\xspace} is slightly worse than Active Learning on the Adult dataset but is comparable on the EEG dataset.\n\n\\begin{figure}[t]\\vspace{0.5em}\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp8a.png}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp8b.png}\n \\includegraphics[width=0.5\\columnwidth]{exp/legend-8.png}\\vspace{-1em}\n \\caption{ -D denotes no detection, and -D-I denotes no detection and no importance sampling. Both optimizations significantly help {ActiveClean\\xspace} outperform SampleClean and Active Learning. \\label{opts}}\\vspace{-1.5em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: Both a priori detection and non-uniform sampling significantly contribute to the gains over Active Learning.}\n\n\\iffalse\nWe evaluate Active Learning and {ActiveClean\\xspace} to better understand this relationship.\nIn Figure \\ref{albias}, we vary the biasing effect of the random corruptions.\nThat is, we start with zero mean noise and increase the mean value and variance of the noise.\nSince Active Learning uses the gradient, if there is zero mean noise, in expectation, the dirty data and clean data are the same.\nHowever, as the bias increases, the fact that Active Learning prioritizes w.r.t to the dirty data matters more and becomes increasingly erroneous w.r.t to {ActiveClean\\xspace}.\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.6\\columnwidth]{exp/exp10.pdf}\n \\caption{As we increase the biasing nature of the corruption, Active Learning is increasingly erroneous w.r.t {ActiveClean\\xspace}. \\label{albias}}\n\\end{figure}\n\\fi\n\n\\subsubsection{Mixing Dirty and Clean Data}\nTraining a model on mixed data is an unreliable methodology lacking the same guarantees as Active Learning or SampleClean even in the simplest of cases.\nFor thoroughness, the next experiments include the model error as a function of records cleaned in comparison to {ActiveClean\\xspace}.\nFigure \\ref{pc-perf} plots the same curves as the previous experiment comparing {ActiveClean\\xspace}, Active Learning, and two mixed data algorithms.\nPC randomly samples data, clean, and writes-back the cleaned data.\nPC+D randomly samples data from using the dirty data detector, cleans, and writes-back the cleaned data.\nFor these errors PC and PC+D give reasonable results (not always guaranteed), but {ActiveClean\\xspace} converges faster.\n{ActiveClean\\xspace} tunes the weighting when averaging dirty and clean data into the gradient.\n\n\\begin{figure}[ht!]\n\\centering\\vspace{-0.5em}\n \n \\includegraphics[width=0.49\\columnwidth]{exp/exp14a.pdf}\n    \\includegraphics[width=0.49\\columnwidth]{exp/exp14b.pdf}\n    \\includegraphics[width=0.49\\columnwidth]{exp/legend-14.png}\\vspace{-0.5em}\n \\caption{The relative model error as a function of the number of examples cleaned. {ActiveClean\\xspace} converges with a smaller sample size to the true result in comparison to partial cleaning (PC,PC+D).  \\label{pc-perf}}\n\\end{figure}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} converges faster than mixing dirty and clean data since it reweights data based on the fraction that is dirty and clean. Partial cleaning is not guaranteed to give sensible results.}\n\n\\vspace{1em}\n\n\\subsubsection{Corruption Rate}\nThe next experiment explores how much of the performance\nis due to the initialization with the dirty model (i.e., SampleClean trains a model from ``scratch\").\nFigure \\ref{bias} varies the systematic corruption rate and plots the number of records cleaned to achieve 1\\% relative error for SampleClean and {ActiveClean\\xspace}.\nSampleClean does not use the dirty data and thus its error is essentially governed by the Central Limit Theorem.\nSampleClean outperforms {ActiveClean\\xspace} only when corruptions are very severe (45\\% in Adult and nearly 60\\% in EEG).\nWhen the initialization with the dirty model is inaccurate, {ActiveClean\\xspace} does not perform as well. \n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp9a.pdf}\n  \\includegraphics[width=0.49\\columnwidth]{exp/exp9b.pdf}\\vspace{-1em}\n \\caption{{ActiveClean\\xspace} performs well until the corruption is so severe that the dirty model is not a good initialization. The error of SampleClean does not depend on the corruption rate so it is a vertical line.  \\label{bias}}\\vspace{-1.5em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: SampleClean is beneficial in comparison to {ActiveClean\\xspace} when corruption rates exceed 45\\%.}\n\n\\subsection{{ActiveClean\\xspace}: Adaptive Detection}\nThis experiment explores how the results of the previous experiment change when using an adaptive detector instead of the \\emph{a priori} detector.\nRecall, in the systematic corruption, 3 of the most informative features were corrupted, thus we group these problems into $9$ classes.\nWe use an all-versus-one SVM to learn the categorization.\n\n\\subsubsection{Basic Performance}\nFigure \\ref{pred-perf} overlays the convergence plots in the previous experiments with a curve (denoted by AC+C) that represents {ActiveClean\\xspace} using a classifier instead of the \\emph{a priori} detection. Initially {ActiveClean\\xspace} is comparable to Active Learning; however, as the classifier becomes more effective the detection improves the performance.\nOver both datasets, at the 500 records point on the curve, adaptive {ActiveClean\\xspace} has a 30\\% higher model error compared to \\emph{a priori} {ActiveClean\\xspace}.\nAt 1000 records point on the curve, adaptive {ActiveClean\\xspace} has about 10\\% higher error.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: For 500 records cleaned, adaptive {ActiveClean\\xspace} has a 30\\% higher model error compared to a priori {ActiveClean\\xspace}, but still outperforms Active Learning and SampleClean.}\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp11a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp11b.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/legend-11.png}\\vspace{-0.5em}\n \\caption{Even with a classifier {ActiveClean\\xspace} converges faster than Active Learning and SampleClean. \\label{pred-perf}}\\vspace{-1.0em}\n\\end{figure}\n\n\n\\subsubsection{Classifiable Errors}\nThe adaptive case depends on being able to predict corrupted records.\nFor example, random corruption not correlated with any other data features may be hard to learn.\nAs corruption becomes more random, the classifier becomes increasingly erroneous.\nThe next experiment explores making the systematic corruption more random.\nInstead of selecting the highest valued records for the most valuable features, we corrupt random records with probability $p$. \nWe compare these results to AC-D where we do not have a detector at all at one vertical slice of the previous plot (cleaning 1000 records).\nFigure \\ref{tradeoffs2}a plots the relative error reduction using a classifier.\nWhen the corruption is about 50\\% random then there is a break even point where no detection is better.\nThe classifier is imperfect and misclassifies some data points incorrectly as cleaned.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: When errors are increasingly random (50\\% random) and cannot be accurately classified, adaptive detection provides no benefit over no detection. }\n\n\\begin{figure}[ht!]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp5a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp12.pdf}\\vspace{-0.5em}\n \\caption{(a) Data corruptions that are less random are easier to classify, and lead to more significant reductions in relative model error. (b) The Taylor series approximation gives more accurate estimates when the amount of cleaned data is small. \\label{tradeoffs2}}\n\\end{figure}\n\n\\subsection{Estimation}\\label{est}\nThe next experiment compares estimation techniques: (1) ``linear regression\" trains a linear regression model that predicts the clean gradient as a function of the dirty gradient, (2) ``average gradient\" which does not use the detection to inform how to apply the estimate, (3) ``average feature change\" uses detection but no linearization, and (4) the Taylor series linear approximation.\nFigure \\ref{tradeoffs2}b measures how accurately each estimation technique estimates the gradient as a function of the number of cleaned records on the EEG dataset.\n\nEstimation error is measured using the relative L2 error with the true gradient.\nThe Taylor series approximation proposed gives more accurate for small cleaning sizes.\nLinear regression and the average feature change technique do eventually perform comparably but only after cleaning much more data.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: Linearized gradient estimates are more accurate when estimated from small samples. }\n\n\\subsection{Real World Scenarios}\nThe next set of experiments evaluate {ActiveClean\\xspace} in three real world scenarios, one demonstrating the \\emph{a priori} case and the other two for the adaptive detection case.\n\n\\subsubsection{A Priori: Constraint Cleaning}\\label{dfd-exp}\nThe first scenario explores the Dollars for Docs dataset published by ProPublica described throughout the paper.\nTo run this experiment, the entire dataset was cleaned up front, and simulated sampling from the dirty data and cleaning by looking up the value in the cleaned data (see Appendix \\ref{dfd-errors} for constraints, errors, and cleaning methodology).\nFigure \\ref{dfd}a shows that {ActiveClean\\xspace} converges faster than Active Learning and SampleClean.\nTo achieve a 4\\% relative error (i.e., a 75\\% error reduction from the dirty model), {ActiveClean\\xspace} cleans 40000 fewer records than Active Learning.\nAlso, for 10000 records cleaned, {ActiveClean\\xspace} has nearly an order of magnitude smaller error than SampleClean.\n\nFigure \\ref{dfd}b shows the detection rate (fraction of disallowed research contributions identified) of the classifier as a function of the number of records cleaned. \nOn the dirty data, we can only correctly classify 66\\% of the suspected examples (88\\% overall accuracy due to a class imbalance).\nOn the cleaned data, this classifier is nearly perfect with a 97\\% true positive rate (98\\% overall accuracy).\n{ActiveClean\\xspace} converges to the cleaned accuracy faster than the alternatives with a classifier of 92\\% true positive rate for only 10000 records cleaned.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: To achieve an 80\\% detection rate, {ActiveClean\\xspace} cleans nearly 10x less records than Active Learning. }\n\n\\begin{figure}[t]\n\\centering\\vspace{-1em}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp13a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp13b.pdf}\\vspace{-1em}\n \\caption{(a) The relative model error as a function of the number of cleaned records. (b) The true positive rate as a function of the number of cleaned records. \\label{dfd}}\n\\end{figure}\n\n\\subsubsection{Adaptive: Replacing Corrupted Data}\nThe next experiment explores the MNIST handwritten digit recognition dataset with a MATLAB image processing pipeline.\nIn this scenario, the analyst must inspect a potentially corrupted image and replace it with a higher quality one.\nThe MNIST dataset consists of 64x64 grayscale images.\nThere are two types of simulated corruptions: (1) 5x5 block removal where a random 5x5 block is removed from the image by setting its pixel values to 0, and (2) Fuzzy where a 4x4 moving average patch is applied over the entire image.\nThese corruptions are applied to a random 5\\% of the images, and mimic the random (Fuzzy) vs. systematic corruption (5x5 removal) studied in the previous experiments.\nThe adaptive detector uses a 10 class classifier (one for each digit) to detect the corruption.\n\nFigure \\ref{mnist} shows that {ActiveClean\\xspace} makes more progress towards the clean model with a smaller number of examples cleaned.\nTo achieve a 2\\% error for the block removal, {ActiveClean\\xspace} can inspect 2200 fewer images than Active Learning and 2750 fewer images than SampleClean.\nFor the fuzzy images, both Active Learning and {ActiveClean\\xspace} reach 2\\% error after cleaning fewer than 100 images, while SampleClean requires 1750.\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: In the MNIST dataset, {ActiveClean\\xspace} significantly reduces (more than 2x) the number of images to clean to train a model with 2\\% error. }\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/exp7a.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/exp7b.pdf}\n \\includegraphics[width=0.49\\columnwidth]{exp/legend-general.png}\\vspace{-0.5em}\n \\caption{In a real adaptive detection scenario with the MNIST dataset, {ActiveClean\\xspace} outperforms Active Learning and SampleClean.  \\label{mnist}}\\vspace{-1em}\n\\end{figure}\n\n\\subsubsection{Adaptive: Regression}\nIn the prior two experiments, we explored classification problems.\nIn this experiment, we consider the case when the convex model represents a linear regression model.\nRegression models allow us to visualize what is happening when we apply {ActiveClean\\xspace}.\nIn Figure \\ref{wb}, we illustrate regression model training on a small dataset of 193 countries collected from the World Bank.\nEach country has an associated population and total dollar value of imports. \nWe are interested in examining the relationship between these variables.\nHowever, for some countries, the import values are out-of-date in the World Bank dataset. \nUp-to-date values are usually avaiable on national statistics websites and can be determined with some web searching.\nIt turns out that smaller countries were more likely to have out-of-date statistics in the World Bank dataset, and as a result, the trend line is misleading in the dirty data.\nWe applied {ActiveClean\\xspace} after verifying 30 out of the 193 countries (marked in yellow), and found that we could achieve a highly accurate approximation of the full result.\n\n\n\\begin{figure}[t]\n\\centering\n \\includegraphics[width=0.49\\columnwidth]{exp/worldbank1.png}\n \\includegraphics[width=0.49\\columnwidth]{exp/worldbank2.png}\n \\caption{World Bank Data. We apply {ActiveClean\\xspace} to learn an accurate model predicting population from import values. The data has a systematic bias where small countries have out-of-date import values. \\label{wb}}\\vspace{-1em}\n\\end{figure}\n\n\\vspace{0.25em}\n\n\\noindent \\emph{Summary: {ActiveClean\\xspace} is accurate even in regression analytics. }\n\n\\vspace{-1em}\n\\section{Related Work}\\label{rw}\n\\noindent \\textbf{Data Cleaning: } \nWhen data cleaning is expensive, it is desirable to apply it \\textbf{progressively}, where analysts can inspect early results with only $k \\ll N$ records cleaned.\nProgressive data cleaning is a well studied problem especially in the context of entity resolution \\cite{altowim2014progressive, whang2014incremental, papenbrock2015progressive, gruenheid2014incremental}.\nPrior work has focused on the problem of designing data structures and algorithms to apply data cleaning progressively. which is challenging because many data cleaning algorithms require information from the entire relation.\nOver the last 5 years a number of new results have expanded the scope and practicality of progressive data cleaning~\\cite{mayfield2010eracer, DBLP:journals/pvldb/YakoutENOI11, yakout2013don}.\n{ActiveClean\\xspace} studies the problem of prioritizing progressive cleaning by leveraging information about a user's subsequent use for the data.\nCertain records, if cleaned, may be more likely to affect the downstream analysis.\n\nThere are a number of other works that use machine learning to improve the efficiency and/or reliability of data cleaning~\\cite{DBLP:journals/pvldb/YakoutENOI11,yakout2013don,gokhale2014corleone}.\nFor example, Yakout et al. train a model that evaluates the likelihood of a proposed replacement value \\cite{yakout2013don}.\nAnother application of machine learning is value imputation, where a missing value is predicted based on those records without missing values.\nMachine learning is also increasingly applied to make automated repairs more reliable with human validation \\cite{DBLP:journals/pvldb/YakoutENOI11}.\nHuman input is often expensive and impractical to apply to entire large datasets.\nMachine learning can extrapolate rules from a small set of examples cleaned by a human (or humans) to uncleaned data \\cite{gokhale2014corleone, DBLP:journals/pvldb/YakoutENOI11}.\nThis approach can be coupled with active learning \\cite{DBLP:journals/pvldb/MozafariSFJM14} to learn an accurate model with the fewest possible number of examples.\nWhile, in spirit, {ActiveClean\\xspace} is similar to these approaches, it addresses a very different problem of data cleaning before user-specified modeling.\nThe key new challenge in this problem is ensuring the correctness of the user's model after partial data cleaning.\n\nSampleClean~\\cite{wang1999sample} applies data cleaning to a sample of data, and estimates the results of aggregate queries.\nSampling has also been applied to estimate the number of duplicates in a relation \\cite{heise2014estimating}. \nSimilarly, Bergman et al. explore the problem of query-oriented data cleaning \\cite{DBLP:conf/sigmod/BergmanMNT15}, where given a query, they clean data relevant to that query. \nExisting work does not explore cleaning driven by the downstream machine learning ``queries\" studied in this work.\nDeshpande et al. studied data acquisition in sensor networks \\cite{deshpande2004model}. They explored value of information based prioritization of data acquisition for estimating aggregate queries of sensor readings.\nSimilarly, Jeffery et al. \\cite{DBLP:conf/pervasive/JefferyAFHW06} explored similar prioritization based on value of information.\nWe see this work as pushing prioritization further down the pipeline to the end analytics.\nFinally, incremental optimization methods like SGD have a connection to incremental materialized view maintenance as the argument for incremental maintenance over recomputation is similar (i.e., relatively sparse updates).\nKrishnan et al. explored how samples of materialized views can be maintained similar to how models are updated with a sample of clean data in this work \\cite{krishnan2015svc}.\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Stochastic Optimization and Active Learning: } Zhao and Tong recently proposed using importance sampling in conjunction with stochastic gradient descent \\cite{zhao2014stochastic}. \nThe ideas applied in {ActiveClean\\xspace} are well rooted in the Machine Learning and Optimization literature, and we apply these ideas to the data cleaning problem. \nThis line of work builds on prior results in linear algebra that show that some matrix columns are more informative than others \\cite{drineas2012fast}, and Active Learning which shows that some labels are more informative that others \\cite{settles2010active}.\nActive Learning largely studies the problem of label acquisition \\cite{settles2010active},\nand recently the links between Active Learning and Stochastic optimization have been studied \\cite{guillory2009active}. \nWe use the work in Guillory et al. to evaluate a state-of-the-art Active Learning technique against {ActiveClean\\xspace}.\n\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Transfer Learning and Bias Mitigation: }  \n{ActiveClean\\xspace} has a strong link to a field called Transfer Learning and Domain Adaptation \\cite{pan2010survey}. The basic idea of Transfer Learning is that suppose a model is trained on a dataset $D$ but tested on a dataset $D'$. \nMuch of the complexity and contribution of {ActiveClean\\xspace} comes from efficiently tuning such a process for expensive data cleaning applications -- costs not studied in Transfer Learning.\nIn robotics, Mahler et al. explored a calibration problem in which data was systematically corrupted \\cite{DBLP:conf/case/MahlerKLSMKPWFAG14} and proposed a rule-based technique for cleaning data.\nOther problems in bias mitigation (e.g., Krishnan et al. \\cite{DBLP:conf/recsys/KrishnanPFG14}) have the same structure, systematically corrupted data that is feeding into a model.\nIn this work, we try to generalize these principles given a general dirty dataset, convex model, and data cleaning procedure.\n\n\n\\vspace{0.5em}\n\n\\noindent \\textbf{Secure Learning: } {ActiveClean\\xspace} is also related to work in adversarial learning \\cite{nelson2012query}, where the goal is to make models robust to adversarial data manipulation.\nThis line of work has extensively studied methodologies for making models private to external queries and robust to malicious labels \\cite{xiaofeature}, but the data cleaning problem explores more general corruptions than just malicious labels.\nOne widely applied technique in this field is reject-on-negative impact, which essentially, discards data that reduces the loss function--which will not work when we do not have access to the true loss function (only the ``dirty loss\"). \n\n\n\n\\section{Discussion and Future Work}\nThe experimental results suggest the following conclusions about {ActiveClean\\xspace}: (1) when the data corruption rate is relatively small (e.g., 5\\%), {ActiveClean\\xspace} cleans fewer records than Active Learning or SampleClean to achieve the same model accuracy, (2) all of the optimizations in {ActiveClean\\xspace} (importance sampling, detection, and estimation) lead to significantly more accurate models at small sample sizes, (3) only when corruption rates are very severe (e.g. 50\\%) , SampleClean outperforms {ActiveClean\\xspace}, and (4) two real-world scenarios demonstrate similar accuracy improvements where {ActiveClean\\xspace} returns significantly more accurate models than SampleClean or Active Learning for the same number of records cleaned.\n\nThere are also a few additional points for discussion.\n{ActiveClean\\xspace} provides guarantees for training error on models trained with progressive data cleaning, however, there are no such guarantees on test error. \nThis work focuses on the problem where an analyst has a large amount of dirty data and would like explore data cleaning and predictive models on this dataset.\nBy providing the analyst more accurate model estimates, the value of different data cleaning techniques can be judged without having to clean the entire dataset.\nHowever, the exploratory analysis problem is distinct from the model deployment problem (i.e., serving predictions to users from the model), which we hope to explore in more detail in future work.\nIt implicitly assumes that when the model is deployed, it will be applied in a setting where the test data is also clean.\nTraining on clean data, and testing on dirty data, defeats the purpose of data cleaning and can lead to unreliable predictions.\n\nAs the experiments clearly show, {ActiveClean\\xspace} is not strictly \\emph{better} than Active Learning or SampleClean.\n{ActiveClean\\xspace} is optimized for a specific design point of sparse errors and small sample sizes, and the empirical results suggest it returns more accurate models in this setting.\nAs sample sizes and error rates increase, the benefits of {ActiveClean\\xspace} are reduced.\nAnother consideration for future work is automatically selecting alternative techniques when {ActiveClean\\xspace} is expected to perform poorly.\n\nBeyond these limitations, there are several exciting new avenues for future work.\nThe data cleaning models explored in this work can be extended to handle non-uniform costs, where different errors have a different cleaning cost.\nNext, the empirical success of Deep Learning has led to increasing industry and research adoption of non-convex losses in many tasks that were traditionally served by convex models.\nIn future work, we hope to explore how we can integrate with such frameworks.\n\n\n\\section{Conclusion}\nThe growing popularity of predictive models in data analytics adds additional challenges in managing dirty data.\nProgressive data cleaning in this setting is susceptible to errors due to mixing dirty and clean data, sensitivity to sample size, and the sparsity of errors.\nThe key insight of {ActiveClean\\xspace} is that an important class of predictive models, called convex loss models (e.g., linear regression and SVMs), can be simultaneously trained and cleaned.\nConsequently, there are provable guarantees on the convergence and error bounds of {ActiveClean\\xspace}.  \n{ActiveClean\\xspace} also includes numerous optimizations such as: using the information from the model to inform data cleaning on samples, dirty data detection to avoid sampling clean data, and batching updates.\nThe experimental results are promising as they suggest that these optimizations can significantly reduce data cleaning costs when errors are sparse and cleaning budgets are small.\nTechniques such as Active Learning and SampleClean are not optimized for the sparse low-budget setting, and {ActiveClean\\xspace} achieves models of similar accuracy for significantly less records cleaned.\n\n\n\\textbf{\\small This research is supported in part by NSF CISE Expeditions Award CCF-1139158, LBNL Award 7076018, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, C3Energy, Cisco, Cray, Cloudera, EMC2, Ericsson, Facebook, Guavus, HP, Huawei, Informatica, Intel, Microsoft, NetApp, Pivotal, Samsung, Schlumberger, Splunk, Virdata and VMware.}\n\n\n\n\\fontsize{7.5pt}{8.0pt} \\selectfont\n\\bibliographystyle{abbrv}\n\\bibliography{ref} \n\\normalsize \\selectfont\n\\appendix\n\n\\section{Set-of-Records Cleaning Model}\\label{set-of-r}\nIn paper, we formalized the analyst-specified data cleaning as follows.\nWe take the sample of the records $S_{dirty}$, and apply data cleaning $C(\\cdot)$.\n$C$ is applied to a record and produces the clean record:\n", "index": 51, "text": "\n\\[\nS_{clean} = \\{C(r) : \\forall r \\in S_{dirty}\\}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m1\" class=\"ltx_Math\" alttext=\"S_{clean}=\\{C(r):\\forall r\\in S_{dirty}\\}\" display=\"block\"><mrow><msub><mi>S</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:</mo><mrow><mrow><mo>\u2200</mo><mi>r</mi></mrow><mo>\u2208</mo><msub><mi>S</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nwe require that for every record $s \\in S_{dirty}$, that record is completely cleaned after applying $C(\\cdot)$, giving us $S_{clean}$.\nRecords outside of $S_{dirty}$ may be cleaned on a subset of dirty attributes by $C(\\cdot)$.\nAfter each iteration, we re-run the detector, and move any $r \\in R'_{dirty}$ that are clean to $R_{clean}$.\nSuch a model allows us to capture data cleaning operations such as in Example \\ref{app-ex1} and Example \\ref{app-ex2}.\n\n\\section{Stochastic Gradient Descent}\\label{appsgd}\n\nStochastic Gradient Descent converges for a suitably chosen step size if the sample gradients are unbiased estimates of the full gradient. \nThe first problem is to choose weights $\\alpha$ and $\\beta$ (to average already clean and newly cleaned data) such that the estimate of the gradient is unbiased. \n\nThe batch $S_{dirty}$ is drawn only from $R_{dirty}$.\nSince the sizes of $R_{dirty}$ and its complement are known, it follows that the gradient over the already clean data $g_C$ and the recently cleaned data $g_S$ can be combined as follows:\n", "itemtype": "equation", "pos": 97510, "prevtext": "\nThe record-by-record cleaning model is a formalization of the costs of data cleaning where each record has the same cost to clean and this cost does not change throughout the entire cleaning session.\nThere are, however, some cases when cleaning the first record of a certain type of corruption is expensive but all subsequent records are cheaper.\n\n\\begin{example}\\label{app-ex1}\nIn most spell checking systems, when a misspelling is identified, the system gives an option to fix all instances of that misspelling.\n\\end{example}\n\n\\begin{example}\\label{app-ex2}\nWhen an inconsistent value is identified all other records with the same inconsistency can be efficiently fixed.\n\\end{example}\n\nThis model of data cleaning can fit into our framework and we formalize it as the ``Set-of-Records\" model as opposed to the ``Record-by-Record\" model. \nIn this model, the cleaning function $C(\\cdot)$ is not restricted to updating only the records in the sample.\n$C(\\cdot)$ takes the entire dirty sample as an argument (that is the cleaning is a function of the sample), the dirty data, and updates the entire dirty data:\n", "index": 53, "text": "\n\\[\nR'_{dirty} = C(S_{dirty},R_{dirty})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m1\" class=\"ltx_Math\" alttext=\"R^{\\prime}_{dirty}=C(S_{dirty},R_{dirty})\" display=\"block\"><mrow><msubsup><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow><mo>\u2032</mo></msubsup><mo>=</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>S</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>,</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nTherefore,\n", "itemtype": "equation", "pos": 98609, "prevtext": "\nwe require that for every record $s \\in S_{dirty}$, that record is completely cleaned after applying $C(\\cdot)$, giving us $S_{clean}$.\nRecords outside of $S_{dirty}$ may be cleaned on a subset of dirty attributes by $C(\\cdot)$.\nAfter each iteration, we re-run the detector, and move any $r \\in R'_{dirty}$ that are clean to $R_{clean}$.\nSuch a model allows us to capture data cleaning operations such as in Example \\ref{app-ex1} and Example \\ref{app-ex2}.\n\n\\section{Stochastic Gradient Descent}\\label{appsgd}\n\nStochastic Gradient Descent converges for a suitably chosen step size if the sample gradients are unbiased estimates of the full gradient. \nThe first problem is to choose weights $\\alpha$ and $\\beta$ (to average already clean and newly cleaned data) such that the estimate of the gradient is unbiased. \n\nThe batch $S_{dirty}$ is drawn only from $R_{dirty}$.\nSince the sizes of $R_{dirty}$ and its complement are known, it follows that the gradient over the already clean data $g_C$ and the recently cleaned data $g_S$ can be combined as follows:\n", "index": 55, "text": "\n\\[\ng(\\theta^{t}) = \\frac{\\mid R_{dirty} \\mid \\cdot g_S + \\mid R_{clean} \\mid \\cdot g_C  }{\\mid R \\mid}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m1\" class=\"ltx_Math\" alttext=\"g(\\theta^{t})=\\frac{\\mid R_{dirty}\\mid\\cdot g_{S}+\\mid R_{clean}\\mid\\cdot g_{C%&#10;}}{\\mid R\\mid}\" display=\"block\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b8</mi><mi>t</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mo>\u22c5</mo><msub><mi>g</mi><mi>S</mi></msub></mrow><mo>+</mo><mrow><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mo>\u22c5</mo><msub><mi>g</mi><mi>C</mi></msub></mrow></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\begin{lemma}\nThe gradient estimate $g(\\theta)$ is unbiased if $g_S$ is an unbiased estimate of:\n", "itemtype": "equation", "pos": 98726, "prevtext": "\nTherefore,\n", "index": 57, "text": "\n\\[\n\\alpha = \\frac{\\mid R_{clean} \\mid}{\\mid R \\mid}, \\beta = \\frac{\\mid R_{dirty} \\mid}{\\mid R \\mid}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m1\" class=\"ltx_Math\" alttext=\"\\alpha=\\frac{\\mid R_{clean}\\mid}{\\mid R\\mid},\\beta=\\frac{\\mid R_{dirty}\\mid}{%&#10;\\mid R\\mid}\" display=\"block\"><mrow><mrow><mi>\u03b1</mi><mo>=</mo><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac></mrow><mo>,</mo><mrow><mi>\u03b2</mi><mo>=</mo><mfrac><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\\end{lemma}\n\\begin{proof}[Sketch]\n", "itemtype": "equation", "pos": 98928, "prevtext": "\n\n\\begin{lemma}\nThe gradient estimate $g(\\theta)$ is unbiased if $g_S$ is an unbiased estimate of:\n", "index": 59, "text": "\n\\[\n\\frac{1}{\\mid R_{dirty} \\mid} \\sum g_i(\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m1\" class=\"ltx_Math\" alttext=\"\\frac{1}{\\mid R_{dirty}\\mid}\\sum g_{i}(\\theta)\" display=\"block\"><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nBy symmetry, \n", "itemtype": "equation", "pos": 99015, "prevtext": "\n\\end{lemma}\n\\begin{proof}[Sketch]\n", "index": 61, "text": "\n\\[\n\\mathbb{E}(\\frac{1}{\\mid R_{dirty} \\mid} \\sum g_i(\\theta)) = \\frac{1}{\\mid R_{dirty} \\mid} \\cdot \\mathbb{E}(\\sum g_i(\\theta)))\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\frac{1}{\\mid R_{dirty}\\mid}\\sum g_{i}(\\theta))=\\frac{1}{\\mid R_{%&#10;dirty}\\mid}\\cdot\\mathbb{E}(\\sum g_{i}(\\theta)))\" display=\"block\"><mrow><mi>\ud835\udd3c</mi><mrow><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msub><mi>g</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u22c5</mo><mi>\ud835\udd3c</mi><mrow><mo stretchy=\"false\">(</mo><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msub><mi>g</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 99162, "prevtext": "\nBy symmetry, \n", "index": 63, "text": "\n\\[\n\\mathbb{E}(\\frac{1}{\\mid R_{dirty} \\mid} \\sum g_i(\\theta)) = g(\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex31.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\frac{1}{\\mid R_{dirty}\\mid}\\sum g_{i}(\\theta))=g(\\theta)\" display=\"block\"><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\\end{proof}\n\nThe error bound discussed in Proposition 2 can be tightened for a class of models called strongly convex (see \\cite{bertsekas2011incremental} for a defintion). \n\n\\begin{proposition}\nFor a strongly convex loss, a batch size $b$, and $T$ iterations, the convergence rate is bounded by $O(\\frac{\\sigma^2}{bT})$. \n\\end{proposition}\n\n\\section{Non-convex losses}\\label{non-convex}\nWe acknowledge that there is an increasing popularity of non-convex losses in the Neural Network and Deep Learning literature. \nHowever, even for these losses, gradient descent techniques still apply. \nInstead of converging to a global optimum they converge to a locally optimal value. \nLikewise, {ActiveClean\\xspace} will converge to the closest locally optimal value to the dirty model. \nBecause of this, it is harder to reason about the results.\nDifferent initializations will lead to different local optima, and thus, introduces a complex dependence on the initialization with the dirty model.\nThis problem is not fundemental to {ActiveClean\\xspace} and any gradient technique suffers this challenge for general non-convex losses, and we hope to explore this more in the future.\n\n\\section{Importance Sampling}\\label{impsample-deriv}\nThis lemma describes the optimal distribution over a set of scalars:\n\\begin{lemma}\\label{impsample}\nGiven a set of real numbers $A = \\{a_1,...,a_n\\}$, let $\\hat{A}$ be \na sample with replacement of $A$ of size k.\nIf $\\mu$ is the mean $\\hat{A}$, the sampling distribution that minimizes\n the variance of $\\mu$, i.e., the expected square error, is $p(a_i) \\propto a_i$.\n\\end{lemma}\nLemma \\ref{impsample} shows that when estimating a mean of numbers with sampling, the distribution with optimal variance is sampling proportionally to the values.\n\nThe variance of this estimate is given by:\n", "itemtype": "equation", "pos": 99239, "prevtext": "\n", "index": 65, "text": "\n\\[\n\\mathbb{E}(\\frac{1}{\\mid R_{dirty} \\mid} \\sum g_i(\\theta)) = \\frac{\\mid R_{dirty} \\mid \\cdot g_S + \\mid R_{clean} \\mid \\cdot g_C  }{\\mid R \\mid}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex32.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\frac{1}{\\mid R_{dirty}\\mid}\\sum g_{i}(\\theta))=\\frac{\\mid R_{dirty%&#10;}\\mid\\cdot g_{S}+\\mid R_{clean}\\mid\\cdot g_{C}}{\\mid R\\mid}\" display=\"block\"><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mfrac><mn>1</mn><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>g</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>y</mi></mrow></msub><mo>\u2223</mo></mrow><mo>\u22c5</mo><msub><mi>g</mi><mi>S</mi></msub></mrow><mo>+</mo><mrow><mrow><mo>\u2223</mo><msub><mi>R</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>\u2223</mo></mrow><mo>\u22c5</mo><msub><mi>g</mi><mi>C</mi></msub></mrow></mrow><mrow><mo>\u2223</mo><mi>R</mi><mo>\u2223</mo></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": " \nSince the estimate is unbiased, we can replace $\\mathbb{E}(\\mu)$ with the average of $A$:\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\\end{proof}\n\nThe error bound discussed in Proposition 2 can be tightened for a class of models called strongly convex (see \\cite{bertsekas2011incremental} for a defintion). \n\n\\begin{proposition}\nFor a strongly convex loss, a batch size $b$, and $T$ iterations, the convergence rate is bounded by $O(\\frac{\\sigma^2}{bT})$. \n\\end{proposition}\n\n\\section{Non-convex losses}\\label{non-convex}\nWe acknowledge that there is an increasing popularity of non-convex losses in the Neural Network and Deep Learning literature. \nHowever, even for these losses, gradient descent techniques still apply. \nInstead of converging to a global optimum they converge to a locally optimal value. \nLikewise, {ActiveClean\\xspace} will converge to the closest locally optimal value to the dirty model. \nBecause of this, it is harder to reason about the results.\nDifferent initializations will lead to different local optima, and thus, introduces a complex dependence on the initialization with the dirty model.\nThis problem is not fundemental to {ActiveClean\\xspace} and any gradient technique suffers this challenge for general non-convex losses, and we hope to explore this more in the future.\n\n\\section{Importance Sampling}\\label{impsample-deriv}\nThis lemma describes the optimal distribution over a set of scalars:\n\\begin{lemma}\\label{impsample}\nGiven a set of real numbers $A = \\{a_1,...,a_n\\}$, let $\\hat{A}$ be \na sample with replacement of $A$ of size k.\nIf $\\mu$ is the mean $\\hat{A}$, the sampling distribution that minimizes\n the variance of $\\mu$, i.e., the expected square error, is $p(a_i) \\propto a_i$.\n\\end{lemma}\nLemma \\ref{impsample} shows that when estimating a mean of numbers with sampling, the distribution with optimal variance is sampling proportionally to the values.\n\nThe variance of this estimate is given by:\n", "index": 67, "text": "\n\\[\nVar(\\mu) = \\mathbb{E}(\\mu^2)-\\mathbb{E}(\\mu)^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m1\" class=\"ltx_Math\" alttext=\"Var(\\mu)=\\mathbb{E}(\\mu^{2})-\\mathbb{E}(\\mu)^{2}\" display=\"block\"><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03bc</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nSince $\\bar{A}$ is deterministic, we can remove that term during minimization.\nFurthermore, we can write $\\mathbb{E}(\\mu^2)$ as:\n", "itemtype": "equation", "pos": 101346, "prevtext": " \nSince the estimate is unbiased, we can replace $\\mathbb{E}(\\mu)$ with the average of $A$:\n", "index": 69, "text": "\n\\[\nVar(\\mu) = \\mathbb{E}(\\mu^2)-\\bar{A}^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex34.m1\" class=\"ltx_Math\" alttext=\"Var(\\mu)=\\mathbb{E}(\\mu^{2})-\\bar{A}^{2}\" display=\"block\"><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03bc</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msup><mover accent=\"true\"><mi>A</mi><mo stretchy=\"false\">\u00af</mo></mover><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThen, we can solve the following optimization problem (removing the proportionality of $\\frac{1}{n^2}$) over the set of weights $P=\\{p(a_i)\\}$:\n", "itemtype": "equation", "pos": 101520, "prevtext": "\nSince $\\bar{A}$ is deterministic, we can remove that term during minimization.\nFurthermore, we can write $\\mathbb{E}(\\mu^2)$ as:\n", "index": 71, "text": "\n\\[\n\\mathbb{E}(\\mu^2) = \\frac{1}{n^2}\\sum_i^n \\frac{a_i^2}{p_i}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex35.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\mu^{2})=\\frac{1}{n^{2}}\\sum_{i}^{n}\\frac{a_{i}^{2}}{p_{i}}\" display=\"block\"><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03bc</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msup><mi>n</mi><mn>2</mn></msup></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi><mi>n</mi></munderover><mfrac><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup><msub><mi>p</mi><mi>i</mi></msub></mfrac></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 101730, "prevtext": "\nThen, we can solve the following optimization problem (removing the proportionality of $\\frac{1}{n^2}$) over the set of weights $P=\\{p(a_i)\\}$:\n", "index": 73, "text": "\n\\[\n\\min_{P} \\sum_i^N \\frac{a_i^2}{p_i}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex36.m1\" class=\"ltx_Math\" alttext=\"\\min_{P}\\sum_{i}^{N}\\frac{a_{i}^{2}}{p_{i}}\" display=\"block\"><mrow><munder><mi>min</mi><mi>P</mi></munder><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi><mi>N</mi></munderover><mfrac><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup><msub><mi>p</mi><mi>i</mi></msub></mfrac></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nApplying Lagrange multipliers, an equivalent unconstrained optimization problem is:\n", "itemtype": "equation", "pos": 101772, "prevtext": "\n", "index": 75, "text": "\n\\[\n\\text{subject to: } P > 0, \\sum P = 1\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex37.m1\" class=\"ltx_Math\" alttext=\"\\text{subject to: }P&gt;0,\\sum P=1\" display=\"block\"><mrow><mrow><mrow><mtext>subject to:\u00a0</mtext><mo>\u2062</mo><mi>P</mi></mrow><mo>&gt;</mo><mn>0</mn></mrow><mo>,</mo><mrow><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>P</mi></mrow><mo>=</mo><mn>1</mn></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIf, we take the derivatives with respect to $p_i$ and set them equal to zero:\n", "itemtype": "equation", "pos": 101900, "prevtext": "\nApplying Lagrange multipliers, an equivalent unconstrained optimization problem is:\n", "index": 77, "text": "\n\\[\n\\min_{P > 0,\\lambda > 0} \\sum_i^N \\frac{a_i^2}{p_i} + \\lambda \\cdot (\\sum P - 1)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex38.m1\" class=\"ltx_Math\" alttext=\"\\min_{P&gt;0,\\lambda&gt;0}\\sum_{i}^{N}\\frac{a_{i}^{2}}{p_{i}}+\\lambda\\cdot(\\sum P-1)\" display=\"block\"><mrow><mrow><munder><mi>min</mi><mrow><mrow><mi>P</mi><mo>&gt;</mo><mn>0</mn></mrow><mo>,</mo><mrow><mi>\u03bb</mi><mo>&gt;</mo><mn>0</mn></mrow></mrow></munder><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi><mi>N</mi></munderover><mfrac><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup><msub><mi>p</mi><mi>i</mi></msub></mfrac></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>P</mi></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIf, we take the derivative with respect to $\\lambda$ and set it equal to zero:\n", "itemtype": "equation", "pos": 102065, "prevtext": "\nIf, we take the derivatives with respect to $p_i$ and set them equal to zero:\n", "index": 79, "text": "\n\\[\n-\\frac{a_i^2}{2 \\cdot p_i^2} + \\lambda = 0\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex39.m1\" class=\"ltx_Math\" alttext=\"-\\frac{a_{i}^{2}}{2\\cdot p_{i}^{2}}+\\lambda=0\" display=\"block\"><mrow><mrow><mrow><mo>-</mo><mfrac><msubsup><mi>a</mi><mi>i</mi><mn>2</mn></msubsup><mrow><mn>2</mn><mo>\u22c5</mo><msubsup><mi>p</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>+</mo><mi>\u03bb</mi></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nSolving the system of equations, we get:\n", "itemtype": "equation", "pos": 102193, "prevtext": "\nIf, we take the derivative with respect to $\\lambda$ and set it equal to zero:\n", "index": 81, "text": "\n\\[\n\\sum P - 1\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex40.m1\" class=\"ltx_Math\" alttext=\"\\sum P-1\" display=\"block\"><mrow><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>P</mi></mrow><mo>-</mo><mn>1</mn></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\section{Linearization}\\label{apptaylor}\nIf $d$ is the dirty value and $c$ is the clean value, the Taylor series approximation for a function $f$ is given as follows:\n", "itemtype": "equation", "pos": 102251, "prevtext": "\nSolving the system of equations, we get:\n", "index": 83, "text": "\n\\[\np_i = \\frac{\\mid a_i \\mid }{\\sum_i \\mid a_i \\mid}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex41.m1\" class=\"ltx_Math\" alttext=\"p_{i}=\\frac{\\mid a_{i}\\mid}{\\sum_{i}\\mid a_{i}\\mid}\" display=\"block\"><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo>\u2223</mo><msub><mi>a</mi><mi>i</mi></msub><mo>\u2223</mo></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>i</mi></msub><mrow><mo>\u2223</mo><msub><mi>a</mi><mi>i</mi></msub><mo>\u2223</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIgnoring the higher order terms, the linear term $f'(d)\\cdot(d-c)$ is a linear function in each feature and label.\nWe only have to know the change in each feature to estimate the change in value.\nIn our case the function $f$ is the gradient $\\nabla\\phi$.\nSo, the resulting linearization is:\n", "itemtype": "equation", "pos": 102475, "prevtext": "\n\n\\section{Linearization}\\label{apptaylor}\nIf $d$ is the dirty value and $c$ is the clean value, the Taylor series approximation for a function $f$ is given as follows:\n", "index": 85, "text": "\n\\[\nf(c) = f(d) + f'(d)\\cdot(d-c) + ...\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex42.m1\" class=\"ltx_Math\" alttext=\"f(c)=f(d)+f^{\\prime}(d)\\cdot(d-c)+...\" display=\"block\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msup><mi>f</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>d</mi><mo>-</mo><mi>c</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi mathvariant=\"normal\">\u2026</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 102808, "prevtext": "\nIgnoring the higher order terms, the linear term $f'(d)\\cdot(d-c)$ is a linear function in each feature and label.\nWe only have to know the change in each feature to estimate the change in value.\nIn our case the function $f$ is the gradient $\\nabla\\phi$.\nSo, the resulting linearization is:\n", "index": 87, "text": "\n\\[\n\\nabla\\phi(x^{(c)}_i,y^{(c)}_i,\\theta) \\approx \\nabla\\phi(x,y,\\theta) + \\frac{\\partial}{\\partial X}\\nabla\\phi(x,y,\\theta)\\cdot (x - x^{(c)}) \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex43.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x^{(c)}_{i},y^{(c)}_{i},\\theta)\\approx\\nabla\\phi(x,y,\\theta)+\\frac{%&#10;\\partial}{\\partial X}\\nabla\\phi(x,y,\\theta)\\cdot(x-x^{(c)})\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>X</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>-</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nWhen we take the expected value:\n", "itemtype": "equation", "pos": 102955, "prevtext": "\n", "index": 89, "text": "\n\\[+ \\frac{\\partial}{\\partial Y}\\phi(x,y,\\theta)\\cdot (y - y^{(c)})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex44.m1\" class=\"ltx_Math\" alttext=\"+\\frac{\\partial}{\\partial Y}\\phi(x,y,\\theta)\\cdot(y-y^{(c)})\" display=\"block\"><mrow><mo>+</mo><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>Y</mi></mrow></mfrac><mo>\u2062</mo><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>y</mi><mo>-</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 103058, "prevtext": "\nWhen we take the expected value:\n", "index": 91, "text": "\n\\[\n\\mathbb{E}(\\nabla\\phi(x_{clean},y_{clean},\\theta)) \\approx \\nabla\\phi(x,y,\\theta) + \\frac{\\partial}{\\partial X}\\nabla\\phi(x,y,\\theta)\\cdot \\mathbb{E}(\\Delta x) \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex45.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(\\nabla\\phi(x_{clean},y_{clean},\\theta))\\approx\\nabla\\phi(x,y,\\theta%&#10;)+\\frac{\\partial}{\\partial X}\\nabla\\phi(x,y,\\theta)\\cdot\\mathbb{E}(\\Delta x)\" display=\"block\"><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>X</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mi>\ud835\udd3c</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIt follows that:\n", "itemtype": "equation", "pos": 103224, "prevtext": "\n", "index": 93, "text": "\n\\[+ \\frac{\\partial}{\\partial Y}\\nabla\\phi(x,y,\\theta)\\cdot \\mathbb{E}(\\Delta y)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex46.m1\" class=\"ltx_Math\" alttext=\"+\\frac{\\partial}{\\partial Y}\\nabla\\phi(x,y,\\theta)\\cdot\\mathbb{E}(\\Delta y)\" display=\"block\"><mrow><mo>+</mo><mrow><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>Y</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mi>\ud835\udd3c</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nwhere $M_x = \\frac{\\partial}{\\partial X}\\nabla\\phi$ and $M_y = \\frac{\\partial}{\\partial Y}\\nabla\\phi$.\nRecall that the feature space is $d$ dimensional and label space is $l$ dimensional.\nThen, $M_x$ is an $d \\times d$ matrix, and $M_y$ is a $d \\times l$ matrix.\nBoth of these matrices are computed for each record.\n$\\Delta x$ is a $d$ dimensional vector where each component represents a change in that feature and $\\Delta y$ is an $l$ dimensional vector that represents the change in each of the labels. \n\nThis linearization allows {ActiveClean\\xspace} to maintain per feature (or label) average changes and use these changes to center the optimal sampling distribution around the expected clean value.\nTo estimate $\\mathbb{E}(\\Delta x)$ and $\\mathbb{E}(\\Delta y)$, consider the following for a single feature $i$:\nIf we average all $j=\\{1,...,K\\}$ records cleaned that have an error for that feature, weighted by their sampling probability:\n", "itemtype": "equation", "pos": 103324, "prevtext": "\nIt follows that:\n", "index": 95, "text": "\n\\[\n\\approx \\nabla\\phi(x,y,\\theta) + M_x \\cdot \\mathbb{E}(\\Delta x) + M_y \\cdot \\mathbb{E}(\\Delta y)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex47.m1\" class=\"ltx_Math\" alttext=\"\\approx\\nabla\\phi(x,y,\\theta)+M_{x}\\cdot\\mathbb{E}(\\Delta x)+M_{y}\\cdot\\mathbb%&#10;{E}(\\Delta y)\" display=\"block\"><mrow><mi/><mo>\u2248</mo><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u22c5</mo><mi>\ud835\udd3c</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mi>M</mi><mi>y</mi></msub><mo>\u22c5</mo><mi>\ud835\udd3c</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nSimilarly, for a label $i$:\n", "itemtype": "equation", "pos": 104371, "prevtext": "\nwhere $M_x = \\frac{\\partial}{\\partial X}\\nabla\\phi$ and $M_y = \\frac{\\partial}{\\partial Y}\\nabla\\phi$.\nRecall that the feature space is $d$ dimensional and label space is $l$ dimensional.\nThen, $M_x$ is an $d \\times d$ matrix, and $M_y$ is a $d \\times l$ matrix.\nBoth of these matrices are computed for each record.\n$\\Delta x$ is a $d$ dimensional vector where each component represents a change in that feature and $\\Delta y$ is an $l$ dimensional vector that represents the change in each of the labels. \n\nThis linearization allows {ActiveClean\\xspace} to maintain per feature (or label) average changes and use these changes to center the optimal sampling distribution around the expected clean value.\nTo estimate $\\mathbb{E}(\\Delta x)$ and $\\mathbb{E}(\\Delta y)$, consider the following for a single feature $i$:\nIf we average all $j=\\{1,...,K\\}$ records cleaned that have an error for that feature, weighted by their sampling probability:\n", "index": 97, "text": "\n\\[\n\\bar{\\Delta}_{xi} = \\frac{1}{NK}\\sum_{j=1}^K (x^{(d)}[i]-x^{(c)}[i])\\times \\frac{1}{p(j)}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex48.m1\" class=\"ltx_Math\" alttext=\"\\bar{\\Delta}_{xi}=\\frac{1}{NK}\\sum_{j=1}^{K}(x^{(d)}[i]-x^{(c)}[i])\\times\\frac%&#10;{1}{p(j)}\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mi>x</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>N</mi><mo>\u2062</mo><mi>K</mi></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u00d7</mo><mfrac><mn>1</mn><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\nEach $\\bar{\\Delta}_{xi}$ and $\\bar{\\Delta}_{yi}$ represents an average change in a single feature.\nA single vector can represent the necessary changes to apply to a record $r$:\nFor a record $r$, the set of corrupted features is $f_r,l_r$.\nThen, each record $r$ has a d-dimensional vector $\\Delta_{rx}$ which is constructed as follows:\n", "itemtype": "equation", "pos": 104495, "prevtext": "\nSimilarly, for a label $i$:\n", "index": 99, "text": "\n\\[\n\\bar{\\Delta}_{yi} = \\frac{1}{NK}\\sum_{j=1}^K (y^{(d)}[i]-y^{(c)}[i])\\times \\frac{1}{p(j)}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex49.m1\" class=\"ltx_Math\" alttext=\"\\bar{\\Delta}_{yi}=\\frac{1}{NK}\\sum_{j=1}^{K}(y^{(d)}[i]-y^{(c)}[i])\\times\\frac%&#10;{1}{p(j)}\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mi>y</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>N</mi><mo>\u2062</mo><mi>K</mi></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u00d7</mo><mfrac><mn>1</mn><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nEach record $r$ also has an l-dimensional vector $\\Delta_{ry}$ which is constructed as follows:\n", "itemtype": "equation", "pos": 104927, "prevtext": "\n\nEach $\\bar{\\Delta}_{xi}$ and $\\bar{\\Delta}_{yi}$ represents an average change in a single feature.\nA single vector can represent the necessary changes to apply to a record $r$:\nFor a record $r$, the set of corrupted features is $f_r,l_r$.\nThen, each record $r$ has a d-dimensional vector $\\Delta_{rx}$ which is constructed as follows:\n", "index": 101, "text": "\n\\[\n \\Delta_{rx}[i] = \\begin{cases} 0 & i \\notin f_r \\\\ \n\\bar{\\Delta}_{xi} & i \\in f_r\n\\end{cases} \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex50.m1\" class=\"ltx_Math\" alttext=\"\\Delta_{rx}[i]=\\begin{cases}0&amp;i\\notin f_{r}\\\\&#10;\\bar{\\Delta}_{xi}&amp;i\\in f_{r}\\end{cases}\" display=\"block\"><mrow><mrow><msub><mi mathvariant=\"normal\">\u0394</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mi>i</mi><mo>\u2209</mo><msub><mi>f</mi><mi>r</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mi>x</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mtd><mtd columnalign=\"left\"><mrow><mi>i</mi><mo>\u2208</mo><msub><mi>f</mi><mi>r</mi></msub></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nFinally, the result is: \n", "itemtype": "equation", "pos": 105125, "prevtext": "\nEach record $r$ also has an l-dimensional vector $\\Delta_{ry}$ which is constructed as follows:\n", "index": 103, "text": "\n\\[\n \\Delta_{rx}[i] = \\begin{cases} 0 & i \\notin l_r \\\\ \n\\bar{\\Delta}_{yi} & i \\in l_r\n\\end{cases} \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex51.m1\" class=\"ltx_Math\" alttext=\"\\Delta_{rx}[i]=\\begin{cases}0&amp;i\\notin l_{r}\\\\&#10;\\bar{\\Delta}_{yi}&amp;i\\in l_{r}\\end{cases}\" display=\"block\"><mrow><mrow><msub><mi mathvariant=\"normal\">\u0394</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mi>i</mi><mo>\u2209</mo><msub><mi>l</mi><mi>r</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mi>y</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mtd><mtd columnalign=\"left\"><mrow><mi>i</mi><mo>\u2208</mo><msub><mi>l</mi><mi>r</mi></msub></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\section{Example $M_x$, $M_y$}\\label{example-deriv}\n\\noindent\\textbf{Linear Regression: }\n", "itemtype": "equation", "pos": 105252, "prevtext": "\nFinally, the result is: \n", "index": 105, "text": "\n\\[p_{r}\\propto\\|\\nabla\\phi(x,y,\\theta^{(t)}) + M_x \\cdot \\Delta_{rx} +  M_y \\cdot \\Delta_{ry}\\|\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex52.m1\" class=\"ltx_Math\" alttext=\"p_{r}\\propto\\|\\nabla\\phi(x,y,\\theta^{(t)})+M_{x}\\cdot\\Delta_{rx}+M_{y}\\cdot%&#10;\\Delta_{ry}\\|\" display=\"block\"><mrow><msub><mi>p</mi><mi>r</mi></msub><mo>\u221d</mo><mrow><mo>\u2225</mo><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><msup><mi>\u03b8</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u22c5</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></mrow><mo>+</mo><mrow><msub><mi>M</mi><mi>y</mi></msub><mo>\u22c5</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>y</mi></mrow></msub></mrow></mrow><mo>\u2225</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nFor a record, $r$, suppose we have a feature vector $x$.\nIf we take the partial derivatives with respect to x, $M_x$ is:\n", "itemtype": "equation", "pos": 105442, "prevtext": "\n\n\\section{Example $M_x$, $M_y$}\\label{example-deriv}\n\\noindent\\textbf{Linear Regression: }\n", "index": 107, "text": "\n\\[\n\\nabla\\phi(x,y,\\theta) = (\\theta^Tx - y)x\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex53.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x,y,\\theta)=(\\theta^{T}x-y)x\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mi>\u03b8</mi><mi>T</mi></msup><mo>\u2062</mo><mi>x</mi></mrow><mo>-</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 105611, "prevtext": "\nFor a record, $r$, suppose we have a feature vector $x$.\nIf we take the partial derivatives with respect to x, $M_x$ is:\n", "index": 109, "text": "\n\\[\nM_x[i,i] = 2x[i] + \\sum_{i \\ne j} \\theta[j]x[j] - y \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex54.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,i]=2x[i]+\\sum_{i\\neq j}\\theta[j]x[j]-y\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2260</mo><mi>j</mi></mrow></munder><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow><mo>-</mo><mi>y</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nSimilarly $M_y$ is:\n", "itemtype": "equation", "pos": 105670, "prevtext": "\n", "index": 111, "text": "\n\\[\nM_x[i,j] = \\theta[j]x[i]\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex55.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,j]=\\theta[j]x[i]\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Logistic Regression: } \n", "itemtype": "equation", "pos": 105721, "prevtext": "\nSimilarly $M_y$ is:\n", "index": 113, "text": "\n\\[\nM_y[i,1] = x[i] \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex56.m1\" class=\"ltx_Math\" alttext=\"M_{y}[i,1]=x[i]\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>y</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nwhere\n", "itemtype": "equation", "pos": 105802, "prevtext": "\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Logistic Regression: } \n", "index": 115, "text": "\n\\[\n\\nabla\\phi(x,y,\\theta) = (h(\\theta^Tx) - y)x\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex57.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x,y,\\theta)=(h(\\theta^{T}x)-y)x\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\u03b8</mi><mi>T</mi></msup><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nwe can rewrite this as:\n", "itemtype": "equation", "pos": 105859, "prevtext": "\nwhere\n", "index": 117, "text": "\n\\[\nh(z) = \\frac{1}{1+e^{-z}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex58.m1\" class=\"ltx_Math\" alttext=\"h(z)=\\frac{1}{1+e^{-z}}\" display=\"block\"><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 105915, "prevtext": "\nwe can rewrite this as:\n", "index": 119, "text": "\n\\[\nh_{\\theta}(x) = \\frac{1}{1+e^{\\theta^Tx}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex59.m1\" class=\"ltx_Math\" alttext=\"h_{\\theta}(x)=\\frac{1}{1+e^{\\theta^{T}x}}\" display=\"block\"><mrow><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><msup><mi>\u03b8</mi><mi>T</mi></msup><mo>\u2062</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIn component form,\n", "itemtype": "equation", "pos": 105963, "prevtext": "\n", "index": 121, "text": "\n\\[\n\\nabla\\phi(x,y,\\theta) = (h_{\\theta}(x) - y)x\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex60.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x,y,\\theta)=(h_{\\theta}(x)-y)x\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 106034, "prevtext": "\nIn component form,\n", "index": 123, "text": "\n\\[\ng = \\nabla\\phi(x,y,\\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex61.m1\" class=\"ltx_Math\" alttext=\"g=\\nabla\\phi(x,y,\\theta)\" display=\"block\"><mrow><mi>g</mi><mo>=</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nTherefore,\n", "itemtype": "equation", "pos": 106067, "prevtext": "\n", "index": 125, "text": "\n\\[\ng[i] = h_{\\theta}(x)\\cdot x[i] - yx[i]\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex62.m1\" class=\"ltx_Math\" alttext=\"g[i]=h_{\\theta}(x)\\cdot x[i]-yx[i]\" display=\"block\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mi>x</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mrow><mi>y</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 106123, "prevtext": "\nTherefore,\n", "index": 127, "text": "\n\\[\nM_x[i,i] = h_{\\theta}(x)\\cdot(1- h_{\\theta}(x))\\cdot \\theta[i] x[i] + h_{\\theta}(x) - y\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex63.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,i]=h_{\\theta}(x)\\cdot(1-h_{\\theta}(x))\\cdot\\theta[i]x[i]+h_{\\theta}(x)-y\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mrow><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mi>y</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 106217, "prevtext": "\n", "index": 129, "text": "\n\\[\nM_x[i,j] = h_{\\theta}(x)\\cdot(1- h_{\\theta}(x))\\cdot \\theta[j] x[i] + h_{\\theta}(x)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex64.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,j]=h_{\\theta}(x)\\cdot(1-h_{\\theta}(x))\\cdot\\theta[j]x[i]+h_{\\theta}(x)\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>h</mi><mi>\u03b8</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Logistic Regression: } \n", "itemtype": "equation", "pos": 105721, "prevtext": "\nSimilarly $M_y$ is:\n", "index": 113, "text": "\n\\[\nM_y[i,1] = x[i] \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex65.m1\" class=\"ltx_Math\" alttext=\"M_{y}[i,1]=x[i]\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>y</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nTherefore,\n", "itemtype": "equation", "pos": 106356, "prevtext": "\n\n\\noindent\\textbf{SVM: } \n", "index": 133, "text": "\n\\[\n\\nabla\\phi(x,y,\\theta) =\n\\begin{cases}      \n-y\\cdot\\boldsymbol{x} \\text{ if } y\\cdot\\boldsymbol{x}\\cdot\\theta \\le 1 \\\\\n0\\ \\text{ if } y\\ \\boldsymbol{x}\\cdot\\theta \\geq 1      \n\\end{cases}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex66.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi(x,y,\\theta)=\\begin{cases}-y\\cdot\\bm{x}\\text{ if }y\\cdot\\bm{x}\\cdot%&#10;\\theta\\leq 1\\\\&#10;0\\ \\text{ if }y\\ \\bm{x}\\cdot\\theta\\geq 1\\end{cases}\" display=\"block\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>-</mo><mrow><mrow><mrow><mi>y</mi><mo>\u22c5</mo><mi>\ud835\udc99</mi></mrow><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mi>y</mi></mrow><mo>\u22c5</mo><mi>\ud835\udc99</mi><mo>\u22c5</mo><mi>\u03b8</mi></mrow></mrow><mo>\u2264</mo><mn>1</mn></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mn>0</mn></mpadded><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>y</mi></mpadded><mo>\u2062</mo><mi>\ud835\udc99</mi></mrow><mo>\u22c5</mo><mi>\u03b8</mi></mrow><mo>\u2265</mo><mn>1</mn></mrow></mtd><mtd/></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 106562, "prevtext": "\nTherefore,\n", "index": 135, "text": "\n\\[\nM_x[i,i] = \\begin{cases}      \n-y[i] \\text{ if } y\\cdot\\boldsymbol{x}\\cdot\\theta \\le 1 \\\\\n0\\ \\text{ if } y\\ \\boldsymbol{x}\\cdot\\theta \\geq 1      \n\\end{cases} \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex67.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,i]=\\begin{cases}-y[i]\\text{ if }y\\cdot\\bm{x}\\cdot\\theta\\leq 1\\\\&#10;0\\ \\text{ if }y\\ \\bm{x}\\cdot\\theta\\geq 1\\end{cases}\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>-</mo><mrow><mrow><mi>y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mi>y</mi></mrow><mo>\u22c5</mo><mi>\ud835\udc99</mi><mo>\u22c5</mo><mi>\u03b8</mi></mrow></mrow><mo>\u2264</mo><mn>1</mn></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mn>0</mn></mpadded><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>y</mi></mpadded><mo>\u2062</mo><mi>\ud835\udc99</mi></mrow><mo>\u22c5</mo><mi>\u03b8</mi></mrow><mo>\u2265</mo><mn>1</mn></mrow></mtd><mtd/></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n", "itemtype": "equation", "pos": 106728, "prevtext": "\n", "index": 137, "text": "\n\\[\nM_x[i,j] = 0\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex68.m1\" class=\"ltx_Math\" alttext=\"M_{x}[i,j]=0\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{Logistic Regression: } \n", "itemtype": "equation", "pos": 105721, "prevtext": "\nSimilarly $M_y$ is:\n", "index": 113, "text": "\n\\[\nM_y[i,1] = x[i] \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex69.m1\" class=\"ltx_Math\" alttext=\"M_{y}[i,1]=x[i]\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mi>y</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>i</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\nWe then extended the SampleClean work to study cleaning Materialized Views \\cite{technicalReport}.\nSuppose base data is updated with insertions, deletions, or updates, we explored how we could efficiently propagate\nchanges to a sample of the view instead of the full view.\nSubsequent queries on the view could be answered approximate.\n\nThe SampleClean problem inspired an eponymous system that implements sampling, data cleaning, and approximate query processing on the Apache Spark stack \\cite{sampleclean}.\nAlso included in the Apache Spark stack are Machine Learning libraries including MLlib \\cite{mllib} and GraphX \\cite{graphx}.\nThe in-memory architecture of the Apache Spark stack allows for increasingly interactive analysis \\cite{AgarwalMPMMS13, armbrust2015spark}.\nAnalysts can prototype data processing workflows on samples to evaluate performance before running expensive batch processing jobs on entire datasets.\nWith data cleaning and machine learning libraries in the same software ecosystem, we see a new opportunity for joint optimization for interactive model building.\n\n\n\n\\subsection{Stochastic Gradient Descent}\nSampling is a natural part of any Machine Learning workflow, as stochastic optimization is widely used to fit model parameters.\nThe problems described in the previous subsections are often trained using a technique called Stochastic Gradient Descent (SGD) or one of its variants.\nThe basic idea of SGD is to draw a data point at random, calculate the gradient at that point, and then update a current best estimate with that gradient.\n", "itemtype": "equation", "pos": 32741, "prevtext": "\nThe quadratic L2 loss implies that examples that deviate far from the typical example are quadratically penalized as opposed to linearly penalized with the L1 loss.\nThere is a natural tradeoff between robustness and efficiency.\nThe more robust a technique is, the less efficient it will be (i.e., estimate variance for a fixed number of training examples).\nRobust techniques are best suited for random errors that look significantly different the rest of the examples.\nWhen errors are systematic, the Machine Learning answer has been to design features in such a way that they are robust to some systematic bias.\nFor example, in image processing, scale-invariant feature transforms (SIFT) are widely applied that allow for image models invariant to pose or scaling issues.\n\n\\vspace{0.5em}\n\n\\noindent\\textbf{The {ActiveClean\\xspace} Contribution. } We try to bring two perspectives together in this work to address the problem of expensive to clean systematic errors, namely the Database idea of data cleaning and the Machine Learning formalization of empirical risk minimization.\nSome errors require expensive cleaning procedures, increasingly using the crowd, and we joint have a time budget on cleaning and analysis.\n{ActiveClean\\xspace} prioritizes cleaning with respect to an estimated impact on the clean model.\n\n\\subsection{SampleClean Project}\n\nTraditionally, data cleaning has explored expensive, up-front cleaning of entire datasets for increased query accuracy.\nWe proposed the SampleClean problem, in which an analyst cleans a small sample of data, and then estimates the result to an aggregate query e.g., {\\ensuremath{\\texttt{sum} }\\xspace}, {\\ensuremath{\\texttt{count}}\\xspace}, or {\\ensuremath{\\texttt{avg} }\\xspace}.\nThe main insight from the SampleClean project is that highly accurate answers for aggregate queries does not require cleaning the full dataset.\nGeneralizing this insight, there is a deep relationship between the application (i.e., the query) and how an analyst should budget their effort in data cleaning.\nIn fact, {\\ensuremath{\\texttt{avg} }\\xspace} and {\\ensuremath{\\texttt{sum} }\\xspace} queries are a special case of the convex loss minimization discussed in the previous section:\n", "index": 13, "text": "\n\\[\n\\phi = (x_{i} - \\theta)^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex70.m1\" class=\"ltx_Math\" alttext=\"\\phi=(x_{i}-\\theta)^{2}\" display=\"block\"><mrow><mi>\u03d5</mi><mo>=</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nIt is also easy to verify that the bound on errors is $O(\\frac{\\mathbb{E}((x-\\mu)^2}{bT})$, which is essentially the CLT.\nThe importance sampling results are inutitive as well.\nApplying the linearization:\n", "itemtype": "equation", "pos": 107330, "prevtext": "\nwith the appropriate scaling it can support ${\\ensuremath{\\texttt{avg} }\\xspace}$, ${\\ensuremath{\\texttt{sum} }\\xspace}$ queries with and without predicates.\nTaking the gradient of that loss:\n", "index": 143, "text": "\n\\[\n\\nabla\\phi = 2(x_{i} - \\theta)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex71.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi=2(x_{i}-\\theta)\" display=\"block\"><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>=</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThe importance sampling prioritizes points that it expects to be far away from the mean.\n\n\\subsection{MEDIAN}\nSimilarly, we can analyze the {\\ensuremath{\\texttt{median} }\\xspace} query.\nIf we define the following loss, it is easy to verify the the optimal $\\theta$ is the median $m$:\n", "itemtype": "equation", "pos": 107572, "prevtext": "\nIt is also easy to verify that the bound on errors is $O(\\frac{\\mathbb{E}((x-\\mu)^2}{bT})$, which is essentially the CLT.\nThe importance sampling results are inutitive as well.\nApplying the linearization:\n", "index": 145, "text": "\n\\[\nM_x = 2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex72.m1\" class=\"ltx_Math\" alttext=\"M_{x}=2\" display=\"block\"><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>=</mo><mn>2</mn></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nTaking the gradient of that loss:\n", "itemtype": "equation", "pos": 107870, "prevtext": "\nThe importance sampling prioritizes points that it expects to be far away from the mean.\n\n\\subsection{MEDIAN}\nSimilarly, we can analyze the {\\ensuremath{\\texttt{median} }\\xspace} query.\nIf we define the following loss, it is easy to verify the the optimal $\\theta$ is the median $m$:\n", "index": 147, "text": "\n\\[\n\\phi = \\mid x_{i} - \\theta\\mid\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex73.m1\" class=\"ltx_Math\" alttext=\"\\phi=\\mid x_{i}-\\theta\\mid\" display=\"block\"><mrow><mi>\u03d5</mi><mo>=</mo><mrow><mo>\u2223</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>\u03b8</mi></mrow><mo>\u2223</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nApplying the linearization:\n", "itemtype": "equation", "pos": 107941, "prevtext": "\nTaking the gradient of that loss:\n", "index": 149, "text": "\n\\[\n\\nabla\\phi = \\text{1 if < m, -1 if > m}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex74.m1\" class=\"ltx_Math\" alttext=\"\\nabla\\phi=\\text{1 if &lt; m, -1 if &gt; m}\" display=\"block\"><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>\u03d5</mi></mrow><mo>=</mo><mtext>1 if \u00a1 m, -1 if \u00bf m</mtext></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\nThe intuitive result is that a robust query like a median does not need to consider estimation as the query result is robust to small changes.\n\n\\section{Experimental Comparison}\n\\subsection{Robust Logistic Regression}\\label{rlogit}\nWe use the algorithm from Feng et al. for robust logistic regression.\n\\begin{enumerate}\n\\item Input: Contaminated training samples $\\{(x_1, y_1), . . . ,(x_{n}\n, y_{n})\\}$ an upper bound on the number of outliers n, number of inliers n and sample dimension p.\n\\item Initialization: Set\n", "itemtype": "equation", "pos": 108015, "prevtext": "\nApplying the linearization:\n", "index": 151, "text": "\n\\[\nM_x = 0\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex75.m1\" class=\"ltx_Math\" alttext=\"M_{x}=0\" display=\"block\"><mrow><msub><mi>M</mi><mi>x</mi></msub><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.03797.tex", "nexttext": "\n\\item Remove samples $(xi\n, yi)$ whose magnitude satisfies $\\|x_i\\| \\ge T$.\n\\item Solve regularized logistic regression problem.\n\\end{enumerate}\n\n\\section{Dollars For Docs Setup}\\label{dfd-errors}\nThe dollars for docs dataset has the following schema:\n\\begin{lstlisting}[mathescape,basicstyle={\\scriptsize}]\nContribution(pi_speciality$\\textrm{,}$ drug_name$\\textrm{,}$ device_name$\\textrm{,}$\ncorporation$\\textrm{,}$ amount$\\textrm{,}$ dispute$\\textrm{,}$ status)\n\\end{lstlisting}\nTo flag suspect donations, we used the \\texttt{status} attribute.\nWhen the \\texttt{status} was ``covered\" that means it was an allowed contribution under the researcher's declared protocol.\nWhen the \\texttt{status} was ``non-covered\" that means it was a disallowed contribution under the researcher's declared protocol.\nThe rest of the textual attributes were featurized with a bag-of-words model, and the numerical amount and dispute attributes were treated as numbers.\n\nWe cleaned the entire Dollars for Docs dataset upfront to be able to evaluate how different budgeted data cleaning strategies compare to cleaning the full data.\nTo clean the dataset, we loaded the entire data 240089 records into Microsoft Excel. We identified four broad classes of errors:\n\\vspace{0.25em}\n\n\\noindent \\textbf{Corporations are inconsistently represented: } ``Pfizer\", ``Pfizer Inc.\", ``Pfizer Incorporated\".\n\n\\vspace{0.25em}\n\n\\noindent \\textbf{Drugs are inconsistently represented: } ``TAXOTERE  DOCETAXEL -PROSTATE CANCER\" and ``TAXOTERE\"\n\n\\vspace{0.25em}\n\n\\noindent \\textbf{Label of covered and not covered are not consistent: } ``No\", ``Yes\",``N\", ``This study is not supported\", ``None\", ``Combination\"\n\n\\vspace{0.25em} \n\n\\noindent \\textbf{Research subject must be a drug OR a medical device and not both: } ``BIO FLU QPAN H7N9AS03 Vaccine\" and ``BIO FLU QPAN H7N9AS03 Device\"\n\n\\vspace{0.5em} \n\nTo fix these errors, we sorted by each column and merged values that looked similar and removed inconsistencies as in the status labels. \nWhen there were ambiguities, we refered to the drug company's website and whitepapers.\nWhen possible, we used batch data transformations, like find and replace (i.e. the Set-of-Records model).\nIn all, 44234 records had some error and full data cleaning required about 2 days of efforts.\n\nOnce cleaned, in our experiment, we encoded the 4 problems as data quality constraints.\nTo fix the constraints, we looked up the clean value in the dataset that we cleaned up front.\n\n\\vspace{0.25em}\n\n\\noindent \\textbf{Rule 1: } Matching dependency on corporation (Weighted Jaccard Similarity $>$ 0.8).\n\n\\vspace{0.25em}\n\n\\noindent \\textbf{Rule 2: } Matching dependency on drug (Weighted Jaccard Similarity $>$ 0.8).\n\n\\vspace{0.25em}\n\n\\noindent \\textbf{Rule 3: } Label must either be ``covered\" or ``not covered\".\n\n\\vspace{0.25em} \n\n\\noindent \\textbf{Rule 4: } Either drug or medical device should be null.\n\n\\vspace{0.5em}\n\n\\section{MNIST Setup}\nWe include visualization of the errors that we generated for the MNIST experiment.\nWe generated these errors in MATLAB by taking the grayscale version of the image (a $64\\times 64$ matrix) and corrupting them by block removal and fuzzying.\n\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[scale=0.20]{exp/original.png}\n \\includegraphics[scale=0.20]{exp/5x5removal.png}\n \\includegraphics[scale=0.20]{exp/fuzzy.png}\n \\caption{We experiment with two forms of corruption in the MNIST image datasets: 5x5 block removal and making the images fuzzy. Image (a) shows an uncorrupted ``9\", image (b) shows one corrupted with block removal, and image (c) shows one that is corrupted with fuzziness. \\label{mnist-corr}}\n\\end{figure}\n\n\n", "itemtype": "equation", "pos": 108548, "prevtext": "\nThe intuitive result is that a robust query like a median does not need to consider estimation as the query result is robust to small changes.\n\n\\section{Experimental Comparison}\n\\subsection{Robust Logistic Regression}\\label{rlogit}\nWe use the algorithm from Feng et al. for robust logistic regression.\n\\begin{enumerate}\n\\item Input: Contaminated training samples $\\{(x_1, y_1), . . . ,(x_{n}\n, y_{n})\\}$ an upper bound on the number of outliers n, number of inliers n and sample dimension p.\n\\item Initialization: Set\n", "index": 153, "text": "\\[T = 4\\sqrt{\\log p/n + \\log n/n}\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex76.m1\" class=\"ltx_Math\" alttext=\"T=4\\sqrt{\\log p/n+\\log n/n}\" display=\"block\"><mrow><mi>T</mi><mo>=</mo><mrow><mn>4</mn><mo>\u2062</mo><msqrt><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mi>p</mi><mo>/</mo><mi>n</mi></mrow></mrow><mo>+</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mi>n</mi><mo>/</mo><mi>n</mi></mrow></mrow></mrow></msqrt></mrow></mrow></math>", "type": "latex"}]