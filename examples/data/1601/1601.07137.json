[{"file": "1601.07137.tex", "nexttext": "\nwhere $\\delta$ denotes the Kronecker delta function.\n\nNow let $| \\Psi_{a a^\\prime} \\rangle \\otimes | \\Psi_{b b^\\prime} \\rangle$ be the state encoding two pairs of Posner molecules $(a,a^\\prime)$ and $(b, b^\\prime)$ with $(a,b)$ in neuron 1, and $(a^\\prime, b^\\prime)$ in neuron 2, with $(a,a^\\prime)$ entangled,  as are  $(b,b^\\prime)$.  Let $r = 1$ if $a,b$ bind and  $0$ otherwise, and similarly let $r^\\prime = 1$ if $a^\\prime, b^\\prime$ bind and $0$ otherwise. Then the joint probability of a given combination $r, r^\\prime$ is given by \n\n", "itemtype": "equation", "pos": 5968, "prevtext": "\n\\author{James L. Ulrich\\thanks{Staff scientist, CyberPoint International LLC and Visiting Scholar, University of Maryland Cybersecurity Center; email: jlu5@columbia.edu.} }\n\n\n\n\n\\markboth{Posner computing: a quantum neural network model}\n{Posner computing: a quantum neural network model}\n\\renewcommand{\\sectionmark}[1]{}\n\\maketitle\n\n\\abstract{We present a model for (not necessarily universal) quantum computation given in terms of a quantum neural network, based in turn on the interactions of Posner molecules, as described in a recent article by Matthew  P. A. Fisher}.\n\n\\section{Introduction}\n A recent article by Fisher \\cite{Fisher} conjectures that the phosphate ion's half-integer spin may serve as the brain's ``qubit'' (i.e., unit of quantum storage), and that pairs of such ions form spin singlet states, which are preserved inside ``Posner molecules''. These cube-shaped molecules inherit a tri-level ``pseudo-spin'' from the six phosphate ions they contain, characterizing spin eigenstate transformations under rotations along the cube diagonal. Posner molecules may bond in pairs, collapsing onto a zero total pseudo-spin state leading to release of calcium, which in turn enhances neuronal firing. Moreover, Posner molecules in different neurons may be entangled, producing cross-neuronal firing correlations which are quantum in origin. In the following note, we sketch a model for a quantum neural network inspired by the described interactions of Posner molecules, and evaluate its ability to support a simple artificial neural network task.\n \n\\section{Related work}\nThere is a tradition of attempting to understand cognition as an artifact of quantum information processing in the brain. In his 1989 book ``The Emperor's New Mind,'' Penrose introduced the idea that consciousness is an artifact of the gravity-induced collapse of a quantum-mechanical wave-function governing brain states, referred to as ``Orchestrated Objective Reduction (Orch-Or) '' \\cite{Penrose1}. A few years later, Albert \\cite{Albert} explored the non-intuitive consequences for mental belief states of the application of the Copenhagen interpretation of quantum mechanics to human observers \\cite{Albert}, suggesting the standard interpretation is wrong, thereby supporting Penrose. In the following decade, work by Khrennikov \\cite{Khrennikov} posited that the brain is a ``quantum-like'' computer, in that one may observe interference patterns in statistical descriptions of mental states.   An updated version of the Penrose's ``Orch-Or'' hypothesis is provided in \\cite{Penrose2}, and Fisher's recent article \\cite{Fisher} might reasonably be viewed as providing an alternative physical substrate for this hypothesis, which here we attempt to describe in terms of a quantum neural network. Treatments of quantum neural networks may be found in (for example) \\cite{Ricks} and \\cite{Behrman}, and a survey may be found in \\cite{Garman}. Quantum perceptron networks are given in (for example) \\cite{Zhou} and \\cite{Zidan}. The present work attempts to construct a quantum artificial network motivated by the model of cognition presented by Fisher;  whether there is an equivalence to existing quantum artificial network models is left as a question for further research. However, we note that a distinguishing feature of the model presented here is that quantum states exist only within layers of the network; signaling across layers is purely classical.\n\n\n\\section{Posner molecule interactions}\n\nHere we provide a brief summary of the aspects of \\cite{Fisher} referenced in the present work. One first considers two phosphate ions with nuclear spin $\\frac{1}{2}$ held inside a magnesium shell in extracellular fluid, and emitted in a spin singlet state $\\frac{1}{2}(|0 \\rangle - | 1 \\rangle)$. The entangled ions are then drawn into (possibly distinct) presynaptic glutematergic neurons, where they participate in the formation of Posner molecules, each  containing six phosphorous ions. The ions, when viewed along the diagonal 3-fold symmetry axis of the molecule, form a hexagonal ring, and the associated spin Hamiltonian is given by $H = \\sum_{ij} J_{ij} \\vec{S}_i \\cdot \\vec{S}_j$ where $i,j=1,2, \\cdots, 6$ label the $6$ spins, the $\\vec{S}_l$ are the spin operators, and the $J_{ij}$ are exchange interactions. The $2^6$ energy eigenstates of $H$ can be labelled by their transformation properties under a 3-fold rotation, acquiring a phase factor  $e^{i \\sigma 2\\pi/3}$ with $\\sigma = 0, +1,-1.$ Hence the molecule can be described by pseudo-spin states $|0\\rangle, | 1 \\rangle, \\ket{-1}$, with overall molecular state of the form $| \\Psi_{Pos} \\rangle = \\sum_\\sigma c_\\sigma | \\psi_\\sigma(\\phi) \\rangle | \\sigma \\rangle$, where $\\psi_\\sigma$ encodes rotational spin state for angle $\\phi$ about the diagonal, given the state $\\ket{\\sigma}$. \\cite{Fisher2}.\n\nThe state of two Posner molecules  $(a, a^\\prime)$ occupying a neuron is given by\n\\begin{displaymath}\n| \\Psi_{a a^\\prime} \\rangle = \\sum_{\\sigma, \\sigma^\\prime} C^{a a^\\prime}_{\\sigma \\sigma^\\prime} |\\psi^a_\\sigma \\rangle | \\psi^{a^\\prime}_{\\sigma^\\prime}\\rangle |\\sigma \\sigma^\\prime\\rangle_{a a^\\prime},\\,\\,\\,  \\sum_{\\sigma, \\sigma^\\prime} |C^{a a^\\prime}_{\\sigma \\sigma^\\prime}|^2 = 1.\n \\end{displaymath}\n which is entangled unless $C^{a a^\\prime}_{\\sigma \\sigma^\\prime} =  c^a_\\sigma   c^{a^\\prime}_{\\sigma^\\prime}$, and where by $c^a_\\sigma$ (respectively, $c^{a^\\prime}_{\\sigma^\\prime})$, we mean the coefficient of the $\\sigma$ component of the pseudo-spin of molecule $a$ (respectively, $\\sigma^\\prime$ component of $a^\\prime$).\n\n Chemical bonding of the molecules is equivalent to collapse of $| \\Psi_{a a^\\prime} \\rangle$ onto a total pseudo-spin $0$ state. In this case both molecules melt, releasing calcium, which in turn stimulates further glutamate release into the synaptic cleft, impacting the firing behavior of the \\emph{post}-synaptic neuron. The probability of bonding is given by \n\n", "index": 1, "text": "\\begin{equation} \\label{eq:bond}\nP^{a a^\\prime}_{\\text{react}} = \\sum_{\\sigma, \\sigma^\\prime} |C^{a a^\\prime}_{\\sigma \\sigma^\\prime}|^2 \\delta_{\\sigma + \\sigma^\\prime, 0},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"P^{aa^{\\prime}}_{\\text{react}}=\\sum_{\\sigma,\\sigma^{\\prime}}|C^{aa^{\\prime}}_{%&#10;\\sigma\\sigma^{\\prime}}|^{2}\\delta_{\\sigma+\\sigma^{\\prime},0},\" display=\"block\"><mrow><mrow><msubsup><mi>P</mi><mtext>react</mtext><mrow><mi>a</mi><mo>\u2062</mo><msup><mi>a</mi><mo>\u2032</mo></msup></mrow></msubsup><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>\u03c3</mi><mo>,</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup></mrow></munder><mrow><msup><mrow><mo stretchy=\"false\">|</mo><msubsup><mi>C</mi><mrow><mi>\u03c3</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup></mrow><mrow><mi>a</mi><mo>\u2062</mo><msup><mi>a</mi><mo>\u2032</mo></msup></mrow></msubsup><mo stretchy=\"false\">|</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msub><mi>\u03b4</mi><mrow><mrow><mi>\u03c3</mi><mo>+</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup></mrow><mo>,</mo><mn>0</mn></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\nwhere $g_1(\\sigma, \\sigma^\\prime) = \\delta_{\\sigma + \\sigma^\\prime,0}$ and $g_0 = 1 - g_1$. \n\nOne defines an ``entanglement measure''  $\\mathcal{E} = [\\delta r \\delta r^\\prime]$ where $\\delta r := r - [r]$ and $[f_{r r^\\prime}] := \\sum{r r^\\prime}P_{r r^\\prime}f_{r r^\\prime}$.  If $\\mathcal{E} > 0$ then the two binding reactions themselves are positively correlated by virtue of quantum entanglement, and if $\\mathcal{E} < 0$ then they are anti-correlated.\n\n\\section{A quantum neural network for Posner computing}\n\nWe now define a quantum neural network motivated by the elements of the preceding section, restricted to the case that each neuron contains exactly one pair of Posner molecules. Our approach is to take a very simple artificial neural network model (the perceptron network, in which each vertex computes a linear combination of its inputs and emits a $1$ if the result exceeds a fixed threshold, and $0$ otherwise), and modify it to express the elements of Posner molecule interaction discussed in the preceding section. \n\n\\defn A \\emph{Simple Posner Network} (SPN)  is a multi-layer artificial neural network (ANN) of perceptrons \\cite{Russell}, given by a graph $G$ with vertices $v_i$,  $i = 1, \\cdots, n$, organized into $n$ layers $L_j, j = 0, \\cdots, m$, with edges $e_{i_1, i_2}$ running only between $L_j$ and $L_{j+1}$, such that:\n\\begin{enumerate}\n\\item Each non-root vertex $v_i$ is labelled with a complex vector space $V = \\mathbb{C}^3 \\otimes \\mathbb{C}^3$, and two qutrits $|a \\rangle, |b \\rangle$ with combined state $ | \\Psi^i_{a b} \\rangle \\in V$ given by:\n\n\\begin{displaymath}\n| \\Psi^i_{a b} \\rangle = \\sum_{\\sigma, \\sigma^\\prime} C^{a b}_{\\sigma \\sigma^\\prime} |\\sigma \\sigma^\\prime\\rangle_{a b} \n\\end{displaymath}\nwhere $\\sigma, \\sigma^\\prime \\in \\{ 0, \\pm 1 \\} $, and by qutrit, we mean a linear combination of pseudo-spin states $\\ket{\\sigma}$ of norm one.\n\n\\item Each edge $e_{i_1, i_2}$ is labelled with a weight $w_{i_1, i_2}$. \n\n\\item The layer $L_0$ is occupied by the root vertices, each representing a binary-valued network input which is passed to vertices in $L_1$. Each non-root vertex $v_j$ receives $k$ inputs $(\\vec{a}  = a_{i_1}, \\cdots, a_{i_k}) \\in \\mathbb{Z}_2^k$ and emits a $1$ if $g_j(\\vec{a}) > t$ for a constant $c$ and threshold $t$, where the activation function $g_j(\\vec{a}) = (\\sum_{l=1}^k w_{i_l,j} a_l) + w_0$.\n\n\\item The threshold $t$ takes a value $c_1$ with probability $P^{ab}_{react}$ (see equation \\ref{eq:bond}) and value $c_0 > c_1$ with probability $1 - P^{ab}_{react}$.\n\n\\item Let $v_{L_1}, \\cdots v_{L_k}$ be the vertices of a given level $L$. Then they define the state vector  $| \\Psi \\rangle = | \\Psi^{L_1}_{a_1 b_1} \\rangle \\otimes  \\cdots \\otimes  | \\Psi^{L_k}_{a_k b_k} \\rangle \\in V \\otimes  \\cdots \\otimes V$.  Let $b_L = ( b_{L_1}, \\cdots, b_{L_k})$ denote the outputs of the $v_{L_i}$ of $L$. Prior to evaluation of the nodes of layer $L$, a unitary transformation $U(b_{L-1})$, dependent on the input bits $b_{L-1}$, is applied to $| \\Psi \\rangle$, with the constraint that $U$ can only entangle a given qutrit with at most six other qutrits \\footnote{Since pseudo-spin entanglement is induced by singleton state entanglement of phosphate ions, we may in practice wish to model additional constraints on $U$, but these are elided here for simplicity.}. The dependence of $U$ on $b_{L-1}$ is intended to model the dependence of Posner molecule uptake on previous neuronal firing within a layer $L$, which in turn is dependent on neuronal firing of the preceding layer $L-1$.  Say  $|a \\rangle, | b \\rangle$ are the qutrits for vertex $v_1$ and $|a^\\prime \\rangle, | b^\\prime \\rangle$ are the qutrits for vertex $v_2$, and after application of $U$, $|a\\rangle, |a^\\prime \\rangle$ are entangled, as are $|b \\rangle, | b^\\prime \\rangle$. Then the probability that $v_1$ uses activation threshold $c_i$ and $v_2$ takes activation threshold $c^\\prime_j$ is given by $P_{i,j}$ (see equation \\ref{eq:entangled}).\n\n\n\\end{enumerate}\n\nIn other words, an SPN is an ordinary multi-layer artificial neural network of perceptrons, except that the threshold values for each vertex within a given layer are selected probabilistically, based on unitary evolution of a quantum state associated to the layer, followed by a projective measurement. The quantum state is expressed in terms of qutrits, motivated by the description of the pseudo-spin states of Posner molecules, in contrast to standard qubit-based quantum circuits as described in \\cite{Nielsen}. \n\n\n\nIn the next section of this paper, we explore the usefulness of this construct for a simple ANN task.\n\n\\section{Posner XOR}\n\nIt is known that a (classical) network of two perceptrons cannot learn the XOR gate (see \\cite{Russell} for a summary of circuit models, and a discussion of the XOR gate and perceptron networks). We can however construct an SPN consisting of just an input layer $L_0$ (with vertices labelled $b_0$ and $b_1$, corresponding to the input bits to the XOR gate), and a layer $L_1$ having two vertices $n_1$ and $n_2$ (corresponding respectively to the ``carry'' and ``sum'' outputs of the XOR gate). With a probability that (as we will see below) can be set arbitrarily close to one, the SPN will produce the correct outputs for each of the four possible inputs. Proceeding with our construction, we let $(a,b)$ denote the two Posner molecules for $n_1$ and $(a^\\prime, b^\\prime)$ denote the two Posner molecules for $n_2$.  Let $t_{10}$ and $t_{11} < t_{10}$ denote the possible threshold values for $n_1$, and $t_{20}$ and $t_{21} < t_{20}$ denote the possible values for $n_2$. Let $w_{ij}$ denote the weight for node $i$ for bit $j$ (with $w_{i0}$ a constant). Our strategy is to associate to $L_1$ an overall quantum state $\\ket{\\Psi}$ such we can apply to $\\ket{\\Psi}$ a unitary transformation $U(b_1, b_2)$, such that the result will define a $P_{r r^\\prime}$ (see equation \\ref{eq:entangled}) in which the thresholds that produce the correct outputs are the most likely ones. \n\nTowards this end, we define two basis vectors \n\n", "itemtype": "equation", "pos": 6697, "prevtext": "\nwhere $\\delta$ denotes the Kronecker delta function.\n\nNow let $| \\Psi_{a a^\\prime} \\rangle \\otimes | \\Psi_{b b^\\prime} \\rangle$ be the state encoding two pairs of Posner molecules $(a,a^\\prime)$ and $(b, b^\\prime)$ with $(a,b)$ in neuron 1, and $(a^\\prime, b^\\prime)$ in neuron 2, with $(a,a^\\prime)$ entangled,  as are  $(b,b^\\prime)$.  Let $r = 1$ if $a,b$ bind and  $0$ otherwise, and similarly let $r^\\prime = 1$ if $a^\\prime, b^\\prime$ bind and $0$ otherwise. Then the joint probability of a given combination $r, r^\\prime$ is given by \n\n", "index": 3, "text": "\\begin{equation}\\label{eq:entangled}\nP_{r r^\\prime} = \\sum_{\\sigma_a \\sigma_{a^\\prime} }\\sum_{\\sigma_b \\sigma_{b^\\prime}} |C^{a a^\\prime}_{\\sigma_a \\sigma_a^\\prime}|^2 |C^{b b^\\prime}_{\\sigma_b \\sigma^\\prime_b}|^2 g_r(\\sigma_a, \\sigma_b) g_{r^\\prime}(\\sigma_{a^\\prime}, \\sigma_{b^\\prime})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"P_{rr^{\\prime}}=\\sum_{\\sigma_{a}\\sigma_{a^{\\prime}}}\\sum_{\\sigma_{b}\\sigma_{b^%&#10;{\\prime}}}|C^{aa^{\\prime}}_{\\sigma_{a}\\sigma_{a}^{\\prime}}|^{2}|C^{bb^{\\prime}%&#10;}_{\\sigma_{b}\\sigma^{\\prime}_{b}}|^{2}g_{r}(\\sigma_{a},\\sigma_{b})g_{r^{\\prime%&#10;}}(\\sigma_{a^{\\prime}},\\sigma_{b^{\\prime}})\" display=\"block\"><mrow><msub><mi>P</mi><mrow><mi>r</mi><mo>\u2062</mo><msup><mi>r</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>\u03c3</mi><mi>a</mi></msub><mo>\u2062</mo><msub><mi>\u03c3</mi><msup><mi>a</mi><mo>\u2032</mo></msup></msub></mrow></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>\u03c3</mi><mi>b</mi></msub><mo>\u2062</mo><msub><mi>\u03c3</mi><msup><mi>b</mi><mo>\u2032</mo></msup></msub></mrow></munder><mrow><msup><mrow><mo stretchy=\"false\">|</mo><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>a</mi></msub><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>a</mi><mo>\u2032</mo></msubsup></mrow><mrow><mi>a</mi><mo>\u2062</mo><msup><mi>a</mi><mo>\u2032</mo></msup></mrow></msubsup><mo stretchy=\"false\">|</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">|</mo><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>b</mi></msub><mo>\u2062</mo><msubsup><mi>\u03c3</mi><mi>b</mi><mo>\u2032</mo></msubsup></mrow><mrow><mi>b</mi><mo>\u2062</mo><msup><mi>b</mi><mo>\u2032</mo></msup></mrow></msubsup><mo stretchy=\"false\">|</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msub><mi>g</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c3</mi><mi>a</mi></msub><mo>,</mo><msub><mi>\u03c3</mi><mi>b</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>g</mi><msup><mi>r</mi><mo>\u2032</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c3</mi><msup><mi>a</mi><mo>\u2032</mo></msup></msub><mo>,</mo><msub><mi>\u03c3</mi><msup><mi>b</mi><mo>\u2032</mo></msup></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\n \nThey define a two-dimensional subspace of $V \\otimes V$. If we can assign to our network a state \n\n", "itemtype": "equation", "pos": 13089, "prevtext": "\nwhere $g_1(\\sigma, \\sigma^\\prime) = \\delta_{\\sigma + \\sigma^\\prime,0}$ and $g_0 = 1 - g_1$. \n\nOne defines an ``entanglement measure''  $\\mathcal{E} = [\\delta r \\delta r^\\prime]$ where $\\delta r := r - [r]$ and $[f_{r r^\\prime}] := \\sum{r r^\\prime}P_{r r^\\prime}f_{r r^\\prime}$.  If $\\mathcal{E} > 0$ then the two binding reactions themselves are positively correlated by virtue of quantum entanglement, and if $\\mathcal{E} < 0$ then they are anti-correlated.\n\n\\section{A quantum neural network for Posner computing}\n\nWe now define a quantum neural network motivated by the elements of the preceding section, restricted to the case that each neuron contains exactly one pair of Posner molecules. Our approach is to take a very simple artificial neural network model (the perceptron network, in which each vertex computes a linear combination of its inputs and emits a $1$ if the result exceeds a fixed threshold, and $0$ otherwise), and modify it to express the elements of Posner molecule interaction discussed in the preceding section. \n\n\\defn A \\emph{Simple Posner Network} (SPN)  is a multi-layer artificial neural network (ANN) of perceptrons \\cite{Russell}, given by a graph $G$ with vertices $v_i$,  $i = 1, \\cdots, n$, organized into $n$ layers $L_j, j = 0, \\cdots, m$, with edges $e_{i_1, i_2}$ running only between $L_j$ and $L_{j+1}$, such that:\n\\begin{enumerate}\n\\item Each non-root vertex $v_i$ is labelled with a complex vector space $V = \\mathbb{C}^3 \\otimes \\mathbb{C}^3$, and two qutrits $|a \\rangle, |b \\rangle$ with combined state $ | \\Psi^i_{a b} \\rangle \\in V$ given by:\n\n\\begin{displaymath}\n| \\Psi^i_{a b} \\rangle = \\sum_{\\sigma, \\sigma^\\prime} C^{a b}_{\\sigma \\sigma^\\prime} |\\sigma \\sigma^\\prime\\rangle_{a b} \n\\end{displaymath}\nwhere $\\sigma, \\sigma^\\prime \\in \\{ 0, \\pm 1 \\} $, and by qutrit, we mean a linear combination of pseudo-spin states $\\ket{\\sigma}$ of norm one.\n\n\\item Each edge $e_{i_1, i_2}$ is labelled with a weight $w_{i_1, i_2}$. \n\n\\item The layer $L_0$ is occupied by the root vertices, each representing a binary-valued network input which is passed to vertices in $L_1$. Each non-root vertex $v_j$ receives $k$ inputs $(\\vec{a}  = a_{i_1}, \\cdots, a_{i_k}) \\in \\mathbb{Z}_2^k$ and emits a $1$ if $g_j(\\vec{a}) > t$ for a constant $c$ and threshold $t$, where the activation function $g_j(\\vec{a}) = (\\sum_{l=1}^k w_{i_l,j} a_l) + w_0$.\n\n\\item The threshold $t$ takes a value $c_1$ with probability $P^{ab}_{react}$ (see equation \\ref{eq:bond}) and value $c_0 > c_1$ with probability $1 - P^{ab}_{react}$.\n\n\\item Let $v_{L_1}, \\cdots v_{L_k}$ be the vertices of a given level $L$. Then they define the state vector  $| \\Psi \\rangle = | \\Psi^{L_1}_{a_1 b_1} \\rangle \\otimes  \\cdots \\otimes  | \\Psi^{L_k}_{a_k b_k} \\rangle \\in V \\otimes  \\cdots \\otimes V$.  Let $b_L = ( b_{L_1}, \\cdots, b_{L_k})$ denote the outputs of the $v_{L_i}$ of $L$. Prior to evaluation of the nodes of layer $L$, a unitary transformation $U(b_{L-1})$, dependent on the input bits $b_{L-1}$, is applied to $| \\Psi \\rangle$, with the constraint that $U$ can only entangle a given qutrit with at most six other qutrits \\footnote{Since pseudo-spin entanglement is induced by singleton state entanglement of phosphate ions, we may in practice wish to model additional constraints on $U$, but these are elided here for simplicity.}. The dependence of $U$ on $b_{L-1}$ is intended to model the dependence of Posner molecule uptake on previous neuronal firing within a layer $L$, which in turn is dependent on neuronal firing of the preceding layer $L-1$.  Say  $|a \\rangle, | b \\rangle$ are the qutrits for vertex $v_1$ and $|a^\\prime \\rangle, | b^\\prime \\rangle$ are the qutrits for vertex $v_2$, and after application of $U$, $|a\\rangle, |a^\\prime \\rangle$ are entangled, as are $|b \\rangle, | b^\\prime \\rangle$. Then the probability that $v_1$ uses activation threshold $c_i$ and $v_2$ takes activation threshold $c^\\prime_j$ is given by $P_{i,j}$ (see equation \\ref{eq:entangled}).\n\n\n\\end{enumerate}\n\nIn other words, an SPN is an ordinary multi-layer artificial neural network of perceptrons, except that the threshold values for each vertex within a given layer are selected probabilistically, based on unitary evolution of a quantum state associated to the layer, followed by a projective measurement. The quantum state is expressed in terms of qutrits, motivated by the description of the pseudo-spin states of Posner molecules, in contrast to standard qubit-based quantum circuits as described in \\cite{Nielsen}. \n\n\n\nIn the next section of this paper, we explore the usefulness of this construct for a simple ANN task.\n\n\\section{Posner XOR}\n\nIt is known that a (classical) network of two perceptrons cannot learn the XOR gate (see \\cite{Russell} for a summary of circuit models, and a discussion of the XOR gate and perceptron networks). We can however construct an SPN consisting of just an input layer $L_0$ (with vertices labelled $b_0$ and $b_1$, corresponding to the input bits to the XOR gate), and a layer $L_1$ having two vertices $n_1$ and $n_2$ (corresponding respectively to the ``carry'' and ``sum'' outputs of the XOR gate). With a probability that (as we will see below) can be set arbitrarily close to one, the SPN will produce the correct outputs for each of the four possible inputs. Proceeding with our construction, we let $(a,b)$ denote the two Posner molecules for $n_1$ and $(a^\\prime, b^\\prime)$ denote the two Posner molecules for $n_2$.  Let $t_{10}$ and $t_{11} < t_{10}$ denote the possible threshold values for $n_1$, and $t_{20}$ and $t_{21} < t_{20}$ denote the possible values for $n_2$. Let $w_{ij}$ denote the weight for node $i$ for bit $j$ (with $w_{i0}$ a constant). Our strategy is to associate to $L_1$ an overall quantum state $\\ket{\\Psi}$ such we can apply to $\\ket{\\Psi}$ a unitary transformation $U(b_1, b_2)$, such that the result will define a $P_{r r^\\prime}$ (see equation \\ref{eq:entangled}) in which the thresholds that produce the correct outputs are the most likely ones. \n\nTowards this end, we define two basis vectors \n\n", "index": 5, "text": "\\begin{align*}\n|u \\rangle &= \\ket{1}_a \\ket{-1}_b  | 1 \\rangle_{a^\\prime} | 1 \\rangle_{b^\\prime} \\\\\n| v \\rangle  &= |1 \\rangle_a | 1 \\rangle_b  | 1 \\rangle_{a^\\prime} \\ket{-1}_{b^\\prime}\n \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle|u\\rangle\" display=\"inline\"><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>u</mi><mo stretchy=\"false\">\u27e9</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\ket{1}_{a}\\ket{-1}_{b}|1\\rangle_{a^{\\prime}}|1\\rangle_{b^{%&#10;\\prime}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><mi>a</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mi>b</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>a</mi><mo>\u2032</mo></msup></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>b</mi><mo>\u2032</mo></msup></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle|v\\rangle\" display=\"inline\"><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>v</mi><mo stretchy=\"false\">\u27e9</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=|1\\rangle_{a}|1\\rangle_{b}|1\\rangle_{a^{\\prime}}\\ket{-1}_{b^{%&#10;\\prime}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><mi>a</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><mi>b</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>a</mi><mo>\u2032</mo></msup></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>b</mi><mo>\u2032</mo></msup></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\n then we have a state in which $P_{10} = 0.75$, meaning there is a three in four chance that vertex $n_1$ will use threshold $t_{11}$ and vertex $n_2$ will use $t_{20}$. We can transform this to a state in which $P_{01} = 0.75$ (a three in four chance that $n_2$ will use threshold $t_{21}$, and vertex $n_1$ will use $t_{10}$), by applying to $| \\Psi \\rangle$ the unitary transformation $U$ that sends $| u \\rangle \\rightarrow | v \\rangle$ and $| v \\rangle \\rightarrow | u \\rangle$ and is constant on all other basis vectors of $V \\otimes V$. Let $I$ denote the identity transformation. Of course the weights of equation \\ref{eqn:start-state} are arbitrary, and we can make the odds of bonding in $n_1$ (respectively, $n_2$) as close to certainty as we choose, by adjusting the weights accordingly.\n\nFor all cases other than $b_1 = b_2 = 1$, we apply $U$ to $| \\Psi \\rangle$, so that with probability $P_{01} = 0.75$, we have that $n_1$ uses $t_{10}$ and $n_2$ uses $t_{21}$.  \\footnote{In other words, we hold the network vertices, edges, and weights constant, and also hold constant the pair of thresholds associated to each vertex.  However, at layer $L_1$, we allow ourselves to adjust, via application of $U(b_1, b_2)$, the probability distribution over the combination of thresholds that the vertices employ. Contrast this degree of freedom with that afforded by adding a``hidden'' layer; see \\cite{Rumelhart}.} When $n_1$ uses $t_{10}$ and $n_2$ uses $t_{21}$, we obtain the desired XOR behavior provided:\n\n", "itemtype": "equation", "pos": 13390, "prevtext": "\n \nThey define a two-dimensional subspace of $V \\otimes V$. If we can assign to our network a state \n\n", "index": 7, "text": "\\begin{equation}\n| \\Psi \\rangle = \\frac{\\sqrt{3}}{2} | u \\rangle + \\frac{1}{2} | v \\rangle \\label{eqn:start-state}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"|\\Psi\\rangle=\\frac{\\sqrt{3}}{2}|u\\rangle+\\frac{1}{2}|v\\rangle\" display=\"block\"><mrow><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mrow><mfrac><msqrt><mn>3</mn></msqrt><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>u</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>+</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi>v</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\n\nFor the case $b_1 = b_2 = 1$, we apply $I$ to $| \\Psi \\rangle$, so that with $P_{10} = 0.75$,  we have that $n_1$ uses $t_{11}$ and $n_2$ uses $t_{20}$. If so, we obtain the desired XOR behavior provided:\n\n", "itemtype": "equation", "pos": 15034, "prevtext": "\n then we have a state in which $P_{10} = 0.75$, meaning there is a three in four chance that vertex $n_1$ will use threshold $t_{11}$ and vertex $n_2$ will use $t_{20}$. We can transform this to a state in which $P_{01} = 0.75$ (a three in four chance that $n_2$ will use threshold $t_{21}$, and vertex $n_1$ will use $t_{10}$), by applying to $| \\Psi \\rangle$ the unitary transformation $U$ that sends $| u \\rangle \\rightarrow | v \\rangle$ and $| v \\rangle \\rightarrow | u \\rangle$ and is constant on all other basis vectors of $V \\otimes V$. Let $I$ denote the identity transformation. Of course the weights of equation \\ref{eqn:start-state} are arbitrary, and we can make the odds of bonding in $n_1$ (respectively, $n_2$) as close to certainty as we choose, by adjusting the weights accordingly.\n\nFor all cases other than $b_1 = b_2 = 1$, we apply $U$ to $| \\Psi \\rangle$, so that with probability $P_{01} = 0.75$, we have that $n_1$ uses $t_{10}$ and $n_2$ uses $t_{21}$.  \\footnote{In other words, we hold the network vertices, edges, and weights constant, and also hold constant the pair of thresholds associated to each vertex.  However, at layer $L_1$, we allow ourselves to adjust, via application of $U(b_1, b_2)$, the probability distribution over the combination of thresholds that the vertices employ. Contrast this degree of freedom with that afforded by adding a``hidden'' layer; see \\cite{Rumelhart}.} When $n_1$ uses $t_{10}$ and $n_2$ uses $t_{21}$, we obtain the desired XOR behavior provided:\n\n", "index": 9, "text": "\\begin{align*}\nw_{10} &< t_{10} \\\\\nw_{10} + w_{11}&<t_{10}\\\\\nw_{10} + w_{12}&<t_{10}\\\\\nw_{20} &< t_{21} \\\\\nw_{21} + w_{20}&> t_{21}\\\\\nw_{22} + w_{20}&>t_{21}\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{10}\" display=\"inline\"><msub><mi>w</mi><mn>10</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;t_{10}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><msub><mi>t</mi><mn>10</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{10}+w_{11}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>10</mn></msub><mo>+</mo><msub><mi>w</mi><mn>11</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;t_{10}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><msub><mi>t</mi><mn>10</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{10}+w_{12}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>10</mn></msub><mo>+</mo><msub><mi>w</mi><mn>12</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;t_{10}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><msub><mi>t</mi><mn>10</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{20}\" display=\"inline\"><msub><mi>w</mi><mn>20</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;t_{21}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><msub><mi>t</mi><mn>21</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{21}+w_{20}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>21</mn></msub><mo>+</mo><msub><mi>w</mi><mn>20</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&gt;t_{21}\" display=\"inline\"><mrow><mi/><mo>&gt;</mo><msub><mi>t</mi><mn>21</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{22}+w_{20}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>22</mn></msub><mo>+</mo><msub><mi>w</mi><mn>20</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&gt;t_{21}\" display=\"inline\"><mrow><mi/><mo>&gt;</mo><msub><mi>t</mi><mn>21</mn></msub></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\n\nThe weights $w_{ij}$ and thresholds $t_{10}, t_{21}$ can be determined by classical learning techniques \\cite{Russell}, by excluding the $b_1 = b_2  = 1$ case. The thresholds $t_{11}$ and $t_{20}$ can then be chosen to satisfy equations \\ref{eqn-t11} and \\ref{eqn-t12}. \n\nTo produce the state given by equation \\ref{eqn:start-state}, we begin with \n\n", "itemtype": "equation", "pos": 15413, "prevtext": "\n\nFor the case $b_1 = b_2 = 1$, we apply $I$ to $| \\Psi \\rangle$, so that with $P_{10} = 0.75$,  we have that $n_1$ uses $t_{11}$ and $n_2$ uses $t_{20}$. If so, we obtain the desired XOR behavior provided:\n\n", "index": 11, "text": "\\begin{align}\n w_{10} + w_{11} + w_{12} &> t_{11}  \\label{eqn-t11}\\\\\n w_{20} + w_{21} + w_{22} &< t_{20}  \\label{eqn-t12}\n \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{10}+w_{11}+w_{12}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>10</mn></msub><mo>+</mo><msub><mi>w</mi><mn>11</mn></msub><mo>+</mo><msub><mi>w</mi><mn>12</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&gt;t_{11}\" display=\"inline\"><mrow><mi/><mo>&gt;</mo><msub><mi>t</mi><mn>11</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w_{20}+w_{21}+w_{22}\" display=\"inline\"><mrow><msub><mi>w</mi><mn>20</mn></msub><mo>+</mo><msub><mi>w</mi><mn>21</mn></msub><mo>+</mo><msub><mi>w</mi><mn>22</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle&lt;t_{20}\" display=\"inline\"><mrow><mi/><mo>&lt;</mo><msub><mi>t</mi><mn>20</mn></msub></mrow></math>", "type": "latex"}, {"file": "1601.07137.tex", "nexttext": "\nand transform it via $I \\otimes H \\otimes I \\otimes \\tilde{H} \\ket{\\Psi}_I$ where $H$ is given by:\n\\begin{displaymath}\nH = \\left( \\begin{array}{ccc}\n\\frac{\\sqrt{3}}{2} & 0 & \\frac{1}{2} \\\\\n0 & 1 & 0 \\\\\n\\frac{1}{2} & 0 & -\\frac{\\sqrt{3}}{2}  \\end{array} \\right)\n\\end{displaymath}\n\nand $\\tilde{H}$ is given by:\n\\begin{displaymath}\n\\tilde H = \\left( \\begin{array}{ccc}\n-\\frac{\\sqrt{3}}{2} & 0 & \\frac{1}{2} \\\\\n0 & 1 & 0 \\\\\n\\frac{1}{2} & 0 & \\frac{\\sqrt{3}}{2}  \\end{array} \\right)\n\\end{displaymath}\n\nwritten with respect to the basis:\n\\begin{displaymath}\n\\ket{-1} = \\left( \\begin{array}{c} 1 \\\\ 0  \\\\ 0 \\end{array} \\right), \\ket{0} = \\left( \\begin{array}{c} 0 \\\\ 1 \\\\ 0 \\end{array} \\right), \\ket{1} =  \\left( \\begin{array}{c} 0 \\\\ 0 \\\\ 1 \\end{array} \\right).\n\\end{displaymath}\n\nHence, our overall rule is: if $b_1 = b_2 = 1$, send $\\ket{\\Psi}_I \\rightarrow H \\otimes I \\otimes \\tilde{H} \\otimes I \\ket{\\Psi}_I$, and otherwise send $\\ket{\\Psi}_I \\rightarrow U\\otimes(H \\otimes I \\otimes \\tilde{H} \\otimes I \\ket{\\Psi}_I)$. The associated activation functions are then applied to the selected thresholds, to produce the appropriate outcome for each gate. (The non-zero terms of $H$ and $\\tilde{H}$ of course are determined by the weights of equation \\ref{eqn:start-state}). The probability of selecting the correct thresholds, and hence of obtaining the correct XOR behavior, is given by the magnitude squared of the larger of the two weights of equation \\ref{eqn:start-state}.  We define the ``learning'' of the XOR circuit by an SPN to be the process of classically learning the  weights $w_{ij}$ and thresholds $t_{10}, t_{21}$, coupled with the transformation rules for $\\ket{\\Psi}$.\n\n\\section{Summary and questions for further research}\nWe have presented a simple quantum neural network of perceptrons based on a model of quantum cognition via Posner molecules. We call such a network a ``Simple Posner Network'' (SPN). We have shown that such a network, consisting of two nodes,  can learn an XOR gate, a task which a classical perceptron network of two perceptrons cannot perform. \n\nOf course, there are many variants of classical artificial neural networks that \\emph{can} learn the XOR circuit \\cite{Rumelhart}. This suggests the following set of ``computational'' questions as avenues for further research:\n\\begin{enumerate}\n\\item What is a general mechanism for learning arbitrary classical circuits using SPNs?\n\\item Are there classes of classical circuits for which the computational complexity of \\emph{learning} an SPN is less than that of alternative quantum or classical artificial neural networks?\n\\item Are there classes of classical circuits for which the computational complexity of \\emph{executing} an SPN is less than that of alternative quantum or classical artificial neural networks?\n\\end{enumerate}\n\nHowever, SPNs are motivated by a particular model of quantum-based cognition in the human brain. To adhere more faithfully to that model, extensions to the SPN should be made. With respect to this, one may ask also a set of ``neurological modeling'' questions, including:\n \\begin{enumerate}\n\\item What advantages to modeling cognition would be conveyed by associating to each network vertex a mixed ensemble \\cite{Sakurai} of Posner molecules, to create a ``general'' Posner network?\n\\item It is unlikely that in the human brain, layers of neurons are associated with ``lookup tables'' of unitary transformations. Yet certainly if neurons maintain an entangled state, it is feasible that the state would be modified unitarily by presynaptic firing. What is a neurologically realistic model for this state transformation?\n\\item How does the distributions of firings of randomly constructed Posner networks compare to the distributions of firings derived from monitoring of actual brain neuronal structures of similar size, observed over randomized inputs?\n\\item What if any are the differences between the computational power of cognition that would be implied by a model based on Posner networks, as contrasted with alternative cognitive models?\n \\end{enumerate}\n\nOne hopes that in attempting to answer these set of questions, one might obtain useful information as to (1) the ability of a Posner networks to model actual brain functioning on a phenomenological level and (2) specific distributions that characterize actual brain function, expressed in terms of Posner networks.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\break\n\n\\begin{thebibliography}{10}\n\n\n\n\n\n\\bibitem{Albert} D. Z. Albert, ``Quantum Mechanics and Experience'', Harvard UP, 1992.\n\n\n\n\n\\bibitem{Behrman} E.C. Behrman, J.E. Steck, P. Kumar, and K.A. Walsh, ``Quantum algorithm design using dynamic learning'', \\emph{Quantum Information and Computation} \nvol. 8, pp. 12-29, 2008.\n\n\\bibitem{Fisher} M. Fisher, ``Quantum Cognition: The possibility of processing with nuclear spins in the brain,'' Annals of Physics, Volume 362, p. 593-602, arXiv:q-bio/1508.05929.\n\n\\bibitem{Fisher2} M. Fisher, personal communication.\n\n\\bibitem{Garman} J. Garman, ``A Heuristic Review of Quantum Neural Networks'', Master's Thesis, Imperial College London, 2011.\n\n\\bibitem{Nielsen} M. Nielsen and I. Chuang, \\emph{Quantum Computation and Quantum Information}, Cambridge UP, 2000.\n\n\\bibitem{Penrose2} S. Hameroff and R. Penrose, ``Consciousness in the universe: A review of the 'Orch OR' theory'', \\emph{Physics of Life Reviews} vol. 11, pp. 39-78, 2014.\n\n\\bibitem{Khrennikov} A. Khrennikov, ``The Brain as a Quantum-Like Computer'', arXiv:quant-ph/0205092\n\n\\bibitem{IIT} M. Oizumi, L. Albantakis, G. Tononi, ``From the Phenomology to the Mechanisms of Consciousness: Integrated Information Theory 3.0'', \\emph{PLOS Computational Biology}, Vol. 10. Issue 5, May 2014.\n\n\\bibitem{Penrose1} R. Penrose, \\emph{The Emporer's New Mind}, Oxford UP, 1989.\n\n\n\\bibitem{Ricks} B.Ricks, D. Ventura, ``Training a Quantum Neural Network'', http://papers.nips.cc/paper/2363-training-a-quantum-neural-network.pdf. \n\n\\bibitem{Rumelhart}  D. E. Rumelhart, G. E. Hinton, R. J. Williams, ``Learning internal representations by error propagation'', \\emph{Parallel distributed processing: explorations in the microstructure of cognition, vol. 1}, D.E. Rumelhart J. L. McClelland, eds., MIT Press, 1986.\n\n\\bibitem{Russell} S. Russell and P. Norvig, \\emph{Artificial Intelligence: a Modern Approach}, 3rd ed., Prentice-Hall, 2010.\n\n\\bibitem{Sakurai} J. J. Sakurai, \\emph{Modern Quantum Mechanics}, Revised edition, Addison-Wesley, 1994.\n\n\\bibitem{Vollmer} H. Vollmer, \\emph{Introduction to Circuit Complexity}, Springer, 1999.\n\n\\bibitem{Zhou} R. Zhou, L. Qin, Ling and N. Jiang, ``Quantum Perceptron Network'', \\emph{Artificial Neural Networks ICANN 2006}, Lecture Notes in Computer Science v. 4131, pp. 651-657, Spring 2006.\n\n\\bibitem{Zidan} M. Zidan, A. Sagheer, N. Metwally, ``Autonomous Perceptron Neural Network Inspired from Quantum computing'', arXiv:quant-ph/1510.00556.\n\n\n\n\n\n\n\n \n\\end{thebibliography}\n\n\n", "itemtype": "equation", "pos": 15898, "prevtext": "\n\nThe weights $w_{ij}$ and thresholds $t_{10}, t_{21}$ can be determined by classical learning techniques \\cite{Russell}, by excluding the $b_1 = b_2  = 1$ case. The thresholds $t_{11}$ and $t_{20}$ can then be chosen to satisfy equations \\ref{eqn-t11} and \\ref{eqn-t12}. \n\nTo produce the state given by equation \\ref{eqn:start-state}, we begin with \n\n", "index": 13, "text": "\\begin{equation}\n\\ket{\\Psi}_I = \\ket{\\Psi}_{ab} \\otimes \\ket{\\Psi}_{a^\\prime  b^\\prime} = \\ket{1}_a\\ket{-1}_b\\ket{1}_{a^\\prime}\\ket{1}_{b^\\prime}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\ket{\\Psi}_{I}=\\ket{\\Psi}_{ab}\\otimes\\ket{\\Psi}_{a^{\\prime}b^{\\prime}}=\\ket{1}%&#10;_{a}\\ket{-1}_{b}\\ket{1}_{a^{\\prime}}\\ket{1}_{b^{\\prime}}\" display=\"block\"><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mi>I</mi></msub><mo>=</mo><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mrow><mi>a</mi><mo>\u2062</mo><mi>b</mi></mrow></msub><mo>\u2297</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mrow><msup><mi>a</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>b</mi><mo>\u2032</mo></msup></mrow></msub></mrow><mo>=</mo><mrow><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><mi>a</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mi>b</mi></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>a</mi><mo>\u2032</mo></msup></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\" stretchy=\"false\">|</mo><mn>1</mn><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>b</mi><mo>\u2032</mo></msup></msub></mrow></mrow></math>", "type": "latex"}]