[{"file": "1601.01568.tex", "nexttext": "\nwhere $f^*: \\mathbb{R}^d \\to \\mathbb{R}^d$ is a smooth vector field and dot denotes differentiation with respect to time.\n\nWe define the flow $\\varphi_{f^*}:\\mathbb{R}^d \\times \\mathbb{R}\\rightarrow \\mathbb{R}^d$ by $\\varphi_{f^*}(\\psi,t) := x(t)$, where $x(t)$ solves \\eqref{eqn:dynsys} with $x(0)=\\psi$.\n\nWe assume that \\eqref{eqn:dynsys} has a fixed point $\\overline{x}$ that is  exponentially asymptotically stable. Define the basin of attraction as $A(\\overline{x}):=\\{\\psi\\in\\mathbb{R}^d\\mid \\lim_{t\\rightarrow\\infty}\\varphi_{f^*}(\\psi,t)=\\overline{x}\\}$. Note that $A(\\overline{x})\\ne\\emptyset$ and $A(\\overline{x})$ is open. Subsets of the basin of attraction can be determined by the use of Lyapunov functions, which are functions decreasing along solutions of \\eqref{eqn:dynsys}. We consider two types of Lyapunov functions $V$ and $T$, as described in Theorems~\\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} below. These Lyapunov functions satisfy\n\\begin{eqnarray*}\n\\langle \\nabla V(x),f^*(x)\\rangle_{\\mathbb{R}^d} &=& -p(x), \\qquad x\\in A(\\overline{x}),\\\\\n\\langle \\nabla T(x),f^*(x)\\rangle_{\\mathbb{R}^d} &=& -\\overline{c}, \\qquad x\\in A(\\overline{x})\\setminus\\{\\overline{x}\\},\n\\end{eqnarray*}\nwhere $p$ is a smooth function with $p(x)>0$ for $x\\not=\\bar x$ and $p(\\bar x)=0$, and $\\overline{c}$ is a positive constant. The scalar products on the left hand sides are called the orbital derivatives of $V$ and $T$ with respect to \\eqref{eqn:dynsys}, which are the derivatives of $V$ and $T$ along solutions of \\eqref{eqn:dynsys}. The orbital derivatives of $V$ and $T$ are negative, which implies that $V$ and $T$ are decreasing along solutions.\n\nWe assume that the function $f^*$ is unknown, but we have sampled data of the form $(x_i, y_i)$ in $X\\times \\mathbb{R}^d$, $i=1,\\dots,m$, with $y_i = f^*(x_i) + \\eta_{x_i}$. We assume that the one-dimensional random variables $\\eta_{x_i}^k \\in \\mathbb{R}^d$, where $i=1,\\dots,m$ and $k=1,\\dots,d$, are independent random variables drawn from a probability distribution with zero mean and variance $(\\sigma_{x_i}^k)^2$ bounded by $\\sigma^2$. Here $X$ is a nonempty and compact subset of $\\mathbb{R}^d$ with $C^1$ boundary.\n\nIn \\S\\ref{sec:algorithm} we provide an algorithm to approximately reconstruct the Lyapunov functions $V$ and $T$ by  functions $\\hat{V}$  and $\\hat{T}$. The following main theorem provides error estimates in a compact set $\\mathcal{D} \\subset A(\\overline{x})\\cap X$, which depend on the density of the data, measured by two key quantities: the fill distance of the data $h_\\mathbf{x}$ (see Definition \\ref{def:filldistance}) and the norm of the volume weights $\\mathbf{w}$ corresponding to the Voronoi tessellation of the data (see Definition~\\ref{def:Voronoi}).\n\n\\begin{theorem}\\label{thm:mainresult}\n Consider \\eqref{eqn:dynsys} such that $f^* \\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$ with $\\nu_1\\ge (3d + 7)/2$ if $d$ is odd, or $\\nu_1\\ge (3d + 12)/2$ if $d$ is even. Let $\\tau_1,\\tau_2\\in\\mathbb{R}$ and $k_1, k_2\\in\\mathbb{N}$ be such that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil \\tau_1 \\rceil  = \\nu_1$, and $k_2 = k_1 - (d+2)$ (if $d$ is odd) or $k_2 = k_1-(d+3)$ (if $d$ is even). Define $\\tau_2:=k_2 + (d+1)/2$.\n\n  Let $\\Omega\\subset A(\\overline{x})$ be a compact set and $\\mathcal{D}:= \\Omega \\setminus B_\\varepsilon(\\overline{x})\\subset X$, with $\\varepsilon>0$  small enough so that $\\mathcal{D}\\ne\\emptyset$. For $h_\\mathbf{x}$, $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_\\mathbf{q}$ sufficiently small, the following holds:\n\\begin{enumerate}\n\\item\nFor every $0<\\delta<1$, the reconstruction $\\hat{V}$ of the Lyapunov function $V$ defined in Theorem \\ref{thm:VLyapunovconverse} satisfies the following estimate with probability $1-\\delta$:\n\n\n\n\n\n\n\n\n\n\\begin{eqnarray}\n\\left| \\left| \\langle\\nabla \\hat{V},f^*\\rangle_{\\mathbb{R}^d} - \\langle\\nabla {V},f^*\\rangle_{\\mathbb{R}^d}    \\right| \\right|_{L^\\infty(\\mathcal{D})}  &\\le &\nC  ||V||_{W_2^{\\tau_2}(\\Omega_V)}  \\left(h_\\mathbf{q}^{k_2-\\frac{1}{2}}\\right.\\nonumber\\\\\n&&\\left.+ \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}}{\\lambda \\sqrt{\\delta}} + \\lambda^{r-\\frac{3}{2}} h_\\mathbf{x}  + \\lambda^{r-\\frac{1}{2}}\\right),\t\t\t\t\\label{eqn:mainresultV}\n\\end{eqnarray}\t\n\n\n\n\n\n\nwhere $\\Omega_V\\supset \\mathcal{D}$  is a certain compact subset of $A(\\overline{x})$, and $\\frac{1}{2} < r \\le 1$.\n\\item For every $0<\\delta<1$, the reconstruction $\\hat{T}$ of the Lyapunov function $T$ defined in Theorem \\ref{thm:TLyapunovconverse} satisfies the following estimates with probability $1-\\delta$:\n\n\n\n\n\n\n\n\n\n\\begin{eqnarray}\n\\left| \\left| \\langle\\nabla \\hat{T},f^*\\rangle_{\\mathbb{R}^d} - \\langle\\nabla {T},f^*\\rangle_{\\mathbb{R}^d}  \\right| \\right|_{L^\\infty(\\mathcal{D})} & \\le &\nC  ||T||_{W_2^{\\tau_2}(\\Omega_T)} \\left(h_\\mathbf{q}^{k_2-\\frac{1}{2}}\\right.\\nonumber\\\\\n&&\\left.+ \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}}{\\lambda \\sqrt{\\delta}}+ \\lambda^{r-\\frac{3}{2}} h_\\mathbf{x}  + \\lambda^{r-\\frac{1}{2}}\\right),\t\t\t\t\\label{eqn:mainresultT1}\\\\\n\\left| \\left| \\hat{T} - T\\right| \\right|_{L^\\infty(\\Gamma)} & \\le &C h_{\\tilde{\\mathbf{q}}}^{k_2+\\frac{1}{2}}||T||_{W_2^{\\tau_2}(\\Omega_T)},\n\\label{eqn:mainresultT2}\n\\end{eqnarray}\t\nwhere $\\Gamma$ is a non-characteristic hypersurface on which $T$ has defined values (see Definition \\ref{def:noncharhyp}),  $\\Omega_T\\supset\\mathcal{D}$ is a certain compact subset of $A(\\overline{x})$, and $\\frac{1}{2} < r \\le 1$.\\\\\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{figure}\t\t\t\n\\begin{center}\n\\begin{overpic}[width=12cm]{figure.eps}\n\\put(5,38){\\small{$X$}}\n\\put(22,41){\\footnotesize{$\\Omega_V/\\Omega_T$}}\n\\put(17,28){\\small{$\\Omega$}}\n\\put(40,36){\\small{$\\Gamma$}}\n\\put(32.4,26){\\small{$B_{\\varepsilon}(\\overline{x})$}}\n\\put(48.,29.8){\\small{$\\tilde{\\Gamma}$}}\n\\put(50.3,24.5){\\small{$\\overline{x}$}}\n\\end{overpic}\n\\end{center}\n\\caption{Domains and sets used in the statement and proof of Theorem \\ref{thm:mainresult}. The dotted lines show the boundary of the set $\\mathcal{D}=\\Omega\\setminus B_{\\varepsilon}(\\overline{x})$ where the Lyapunov functions are approximated. We also have  $\\Omega_V,\\Omega_T\\subset A(\\overline{x})$.}\t\t\\label{fig:domains}\n\\end{figure}\n\n\n\nThe main point is that the expressions on the right hand side of \\eqref{eqn:mainresultV}--\\eqref{eqn:mainresultT2} can be made arbitrarily small as the data density increases and for suitably chosen $\\lambda$ (see equation \\eqref{eqn:lambdachoice}). Therefore the orbital derivative of our Lyapunov function approximations $\\hat{V}$ and $\\hat{T}$ become arbitrarily close in the infinity norm to those of $V$ and $T$ respectively. Estimate \\eqref{eqn:mainresultV} implies that the orbital derivative of $\\hat{V}$ will be negative in $\\mathcal{D}$ (which does not contain a small neighbourhood of the equilibrium $\\overline{x}$), since $\\langle\\nabla V(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -p(x)$ where $p$ is a positive definite function (see Theorem \\ref{thm:VLyapunovconverse}). The analogous statement is true for $\\hat{T}$, since $\\langle\\nabla T(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -\\overline{c} <0$.\nIn principle the neighbourhood $B_\\varepsilon(\\overline{x})$ can shrink as the data density increases (as $h_\\mathbf{x}$ and $||\\mathbf{w}||_{\\mathbb{R}^m}$ tend to zero).\n\n\nThe above estimate contains $\\lambda >0$ as a regularisation parameter of our algorithm, and $h_\\mathbf{q}$ as the fill distance of a set of sampled points in $\\Omega_V$ (resp. $\\Omega_T$) of our choosing. Similarly, $h_{\\tilde{\\mathbf{q}}}$ is the fill distance of a set of sampled points on $\\Gamma$, which we are able to choose. The constants in the above estimates depend on $d$, $\\sigma$, the choice of function spaces for approximation and  the vector field $f^*$.\n\n\n\n\n\n\n\n\n\n\n\nThe rest of the paper is organised as follows. In \\S\\ref{sec:conversethms} we provide the converse theorems for the Lyapunov functions $V$ and $T$. In \\S\\ref{sec:background} we set out the framework for the function spaces that are used to approximate the Lyapunov functions, as well as previous results on the approximation of Lyapunov functions when the right hand side of \\eqref{eqn:dynsys} is known. The algorithms themselves that are used to compute $\\hat{V}$ and $\\hat{T}$ are detailed in \\S\\ref{sec:algorithm}. In \\S\\ref{sec:errorf} we provide an estimate for our approximation of the right hand side of \\eqref{eqn:dynsys}, which is then used in the proof of Theorem \\ref{thm:mainresult}  in \\S\\ref{sec:proofofmainthm}.\n\n\n\n\n\n\\section{Converse theorems for Lyapunov functions}\t\t\t\\label{sec:conversethms}\n\nThe concept of a Lyapunov function dates back to 1893, where Lyapunov introduced these functions for the stability analysis of an equilibrium for a given differential equation, without the explicit knowledge of the solutions \\cite{Lya07}. Many converse theorems have been proved that guarantee the existence of a Lyapunov function under certain conditions, see \\cite{Gie07:a,Hah67,Kel15} for an overview. Massera \\cite{Mas49} provided the first main converse theorem for $C^1$ vector fields where $A(\\overline{x})=\\mathbb{R}^d$, with further developments by several authors to prove the existence of smooth Lyapunov functions under weak smoothness assumptions on the right hand side (see e.g. \\cite{Hah59,LinSonWan96,Wes67}).\n\nThe existence of a Lyapunov function for system \\eqref{eqn:dynsys} with given values of the orbital derivative has been shown by Bhatia \\cite{Bha67,BhaSze70}, as stated in the following theorems (see also \\cite{Gie07:a}). We also refer to \\cite{GieHaf15} for a proof that the conditions on the function $p$ given here are sufficient to define the Lyapunov function $V$, in contrast to the conditions given in \\cite{Gie07:a}. First we make the following definition.\n\n\\begin{definition}\t\t\t\\label{def:classK}\nA continuous function $\\alpha: [0,\\infty) \\rightarrow [0,\\infty)$ is a class $\\mathcal{K}$ function if $\\alpha(0) = 0$ and $\\alpha$ is strictly monotonically increasing.\n\\end{definition}\n\n\n\n\\begin{theorem}\t\t\t\\label{thm:VLyapunovconverse}\nConsider the autonomous system of differential equations\n\n$\\dot{x}=f^*(x)$,\n\nwhere $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. We assume the system to have an\nexponentially asymptotically stable equilibrium $\\overline{x}$. Let $p\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ be a function with the following properties:\n\\begin{enumerate}\n\\item $p(x)>0$ for $x\\ne\\overline{x}$, and $p(\\overline{x}) = 0$.\n\n\n\\item There is a class $\\mathcal{K}$ function $\\alpha$ such that $p(x-\\overline{x}) \\ge \\alpha(||x-\\overline{x}||_2)$ for all $x\\in\\mathbb{R}^d$.\n\\end{enumerate}\n\nThen there exists a Lyapunov function $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ (where $A(\\overline{x})$ is the basin of attraction of $\\overline{x}$), such that\n\n", "itemtype": "equation", "pos": 3716, "prevtext": "\n\\maketitle\n\n\n\n\\begin{abstract}\nMethods have previously been developed for the approximation of Lyapunov functions using radial basis functions. However these methods assume that the evolution equations are known. We consider the problem of approximating a given Lyapunov function using radial basis functions where the evolution equations are not known, but we instead have sampled data which is contaminated with noise. We propose an algorithm in which we first approximate the underlying vector field, and use this approximation to then approximate the Lyapunov function. Our approach combines elements of machine learning/statistical learning theory with the existing theory of Lyapunov function approximation. Error estimates are provided for our algorithm.\n\\end{abstract}\n\n\n\\pagestyle{myheadings}\n\\thispagestyle{plain}\n\\markboth{P.~Giesl, B.~Hamzi, M.~Rasmussen \\& K.N.~Webster}{Approximation of Lyapunov functions from noisy data}\n\n\\section{Introduction}\t\t\t\\label{sec:introduction}\n\nOrdinary differential equations model large classes of applications such as planetary motion, chemical reactions, population dynamics or consumer behaviour. A breakthrough in the understanding of ordinary differential equations was initiated by Poincar\\'e and Lyapunov in the late 19th century, who developed an approach that embraced the use of topological and geometrical techniques for the study of dynamical systems. \nA key component of this theory is Lyapunov functions, which can be used to determine the basin of attraction of an asymptotically stable equilibrium.\n\nIn general, it is not possible to find an explicit analytical expression for a Lyapunov function associated to a nonlinear\ndifferential equation. Many methods have been proposed to numerically construct Lyapunov functions, see \\cite{GieHaf15:b} for a recent review. These methods include the SOS (sums of squares) method, which constructs a polynomial Lyapunov function by semidefinite optimization \\cite{prajna}.\nAnother method constructs\n   a continuous piecewise affine (CPA) Lyapunov function using linear optimization \\cite{Haf2007mon}. A further method is based on Zubov's equation and computes a solution of this partial differential equation  \\cite{zubov2001camilli}.\n   Lyapunov functions can also be constructed using\n set oriented\nmethods  \\cite{book2002grune}.\nThe method that is also used in this paper is based on approximating the solution of a PDE using radial basis functions \\cite{Gie07:a}.\nAll these methods to approximate Lyapunov functions rely on the knowledge of the right hand side of the\ndifferential equation.\n\n\n\n\n\n\n\n\n\n\n\n\nIn this paper, we develop a method to approximate Lyapunov functions where the right hand side is unknown, but we have sampled data of the system, which is contaminated by noise.\nWe will first approximate the right hand side of the differential equation, and then use this approximation to approximate the Lyapunov function. Our approach combines and develops previous results from  statistical learning theory \\cite{SmaZho04, SmaZho05, SmaZho07} together with existing methods using radial basis functions \\cite{Gie07:a, GieWen07}, which use the framework of reproducing kernel Hilbert spaces (RKHS).\n\nThe use of RKHS spaces to approximate important quantities in dynamical systems has previously been exploited by Smale and Zhou to approximate a hyperbolic dynamical system  \\cite{hyperbolic}. Bouvrie and Hamzi also use RKHS spaces to approximate some key quantities in control and random dynamical systems \\cite{allerton, acc2012}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Setting of the Problem and Main Result}\t\t\t\t\\label{sec:setting}\n\n\nWe consider ordinary differential equations of the form\n\n\n\n\n\n\n\n\n", "index": 1, "text": "\\begin{equation}\n  \\dot{x}  = f^*(x), \t\\label{eqn:dynsys}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\dot{x}=f^{*}(x),\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mo>=</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nholds  for all $x\\in A(\\overline{x})$. The Lyapunov function $V$ is uniquely defined up to a constant.\n\\end{theorem}\n\nWe may also choose $p(x)$ to be a positive constant in equation \\eqref{eq:Veq} to obtain a Lyapunov function $T$, defined on $A(\\overline{x})\\backslash\\{\\overline{x}\\}$, for which $\\lim_{x\\rightarrow\\overline{x}}T(x) = -\\infty$.\n\n\\begin{theorem}\t\t\t\\label{thm:TLyapunovconverse}\nConsider the autonomous system of differential equations\n\n$\\dot{x}=f^*(x)$,\n\nwhere $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. We assume the system to have an\nexponentially asymptotically stable equilibrium $\\overline{x}$. Then for all $\\overline{c}\\in\\mathbb{R}^+$, there exists a Lyapunov function $T\\in C^{\\nu_1}(A(\\overline{x})\\,\\backslash\\,\\{\\overline{x}\\},\\mathbb{R})$ such that\n\n", "itemtype": "equation", "pos": 14516, "prevtext": "\nwhere $f^*: \\mathbb{R}^d \\to \\mathbb{R}^d$ is a smooth vector field and dot denotes differentiation with respect to time.\n\nWe define the flow $\\varphi_{f^*}:\\mathbb{R}^d \\times \\mathbb{R}\\rightarrow \\mathbb{R}^d$ by $\\varphi_{f^*}(\\psi,t) := x(t)$, where $x(t)$ solves \\eqref{eqn:dynsys} with $x(0)=\\psi$.\n\nWe assume that \\eqref{eqn:dynsys} has a fixed point $\\overline{x}$ that is  exponentially asymptotically stable. Define the basin of attraction as $A(\\overline{x}):=\\{\\psi\\in\\mathbb{R}^d\\mid \\lim_{t\\rightarrow\\infty}\\varphi_{f^*}(\\psi,t)=\\overline{x}\\}$. Note that $A(\\overline{x})\\ne\\emptyset$ and $A(\\overline{x})$ is open. Subsets of the basin of attraction can be determined by the use of Lyapunov functions, which are functions decreasing along solutions of \\eqref{eqn:dynsys}. We consider two types of Lyapunov functions $V$ and $T$, as described in Theorems~\\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} below. These Lyapunov functions satisfy\n\\begin{eqnarray*}\n\\langle \\nabla V(x),f^*(x)\\rangle_{\\mathbb{R}^d} &=& -p(x), \\qquad x\\in A(\\overline{x}),\\\\\n\\langle \\nabla T(x),f^*(x)\\rangle_{\\mathbb{R}^d} &=& -\\overline{c}, \\qquad x\\in A(\\overline{x})\\setminus\\{\\overline{x}\\},\n\\end{eqnarray*}\nwhere $p$ is a smooth function with $p(x)>0$ for $x\\not=\\bar x$ and $p(\\bar x)=0$, and $\\overline{c}$ is a positive constant. The scalar products on the left hand sides are called the orbital derivatives of $V$ and $T$ with respect to \\eqref{eqn:dynsys}, which are the derivatives of $V$ and $T$ along solutions of \\eqref{eqn:dynsys}. The orbital derivatives of $V$ and $T$ are negative, which implies that $V$ and $T$ are decreasing along solutions.\n\nWe assume that the function $f^*$ is unknown, but we have sampled data of the form $(x_i, y_i)$ in $X\\times \\mathbb{R}^d$, $i=1,\\dots,m$, with $y_i = f^*(x_i) + \\eta_{x_i}$. We assume that the one-dimensional random variables $\\eta_{x_i}^k \\in \\mathbb{R}^d$, where $i=1,\\dots,m$ and $k=1,\\dots,d$, are independent random variables drawn from a probability distribution with zero mean and variance $(\\sigma_{x_i}^k)^2$ bounded by $\\sigma^2$. Here $X$ is a nonempty and compact subset of $\\mathbb{R}^d$ with $C^1$ boundary.\n\nIn \\S\\ref{sec:algorithm} we provide an algorithm to approximately reconstruct the Lyapunov functions $V$ and $T$ by  functions $\\hat{V}$  and $\\hat{T}$. The following main theorem provides error estimates in a compact set $\\mathcal{D} \\subset A(\\overline{x})\\cap X$, which depend on the density of the data, measured by two key quantities: the fill distance of the data $h_\\mathbf{x}$ (see Definition \\ref{def:filldistance}) and the norm of the volume weights $\\mathbf{w}$ corresponding to the Voronoi tessellation of the data (see Definition~\\ref{def:Voronoi}).\n\n\\begin{theorem}\\label{thm:mainresult}\n Consider \\eqref{eqn:dynsys} such that $f^* \\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$ with $\\nu_1\\ge (3d + 7)/2$ if $d$ is odd, or $\\nu_1\\ge (3d + 12)/2$ if $d$ is even. Let $\\tau_1,\\tau_2\\in\\mathbb{R}$ and $k_1, k_2\\in\\mathbb{N}$ be such that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil \\tau_1 \\rceil  = \\nu_1$, and $k_2 = k_1 - (d+2)$ (if $d$ is odd) or $k_2 = k_1-(d+3)$ (if $d$ is even). Define $\\tau_2:=k_2 + (d+1)/2$.\n\n  Let $\\Omega\\subset A(\\overline{x})$ be a compact set and $\\mathcal{D}:= \\Omega \\setminus B_\\varepsilon(\\overline{x})\\subset X$, with $\\varepsilon>0$  small enough so that $\\mathcal{D}\\ne\\emptyset$. For $h_\\mathbf{x}$, $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_\\mathbf{q}$ sufficiently small, the following holds:\n\\begin{enumerate}\n\\item\nFor every $0<\\delta<1$, the reconstruction $\\hat{V}$ of the Lyapunov function $V$ defined in Theorem \\ref{thm:VLyapunovconverse} satisfies the following estimate with probability $1-\\delta$:\n\n\n\n\n\n\n\n\n\n\\begin{eqnarray}\n\\left| \\left| \\langle\\nabla \\hat{V},f^*\\rangle_{\\mathbb{R}^d} - \\langle\\nabla {V},f^*\\rangle_{\\mathbb{R}^d}    \\right| \\right|_{L^\\infty(\\mathcal{D})}  &\\le &\nC  ||V||_{W_2^{\\tau_2}(\\Omega_V)}  \\left(h_\\mathbf{q}^{k_2-\\frac{1}{2}}\\right.\\nonumber\\\\\n&&\\left.+ \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}}{\\lambda \\sqrt{\\delta}} + \\lambda^{r-\\frac{3}{2}} h_\\mathbf{x}  + \\lambda^{r-\\frac{1}{2}}\\right),\t\t\t\t\\label{eqn:mainresultV}\n\\end{eqnarray}\t\n\n\n\n\n\n\nwhere $\\Omega_V\\supset \\mathcal{D}$  is a certain compact subset of $A(\\overline{x})$, and $\\frac{1}{2} < r \\le 1$.\n\\item For every $0<\\delta<1$, the reconstruction $\\hat{T}$ of the Lyapunov function $T$ defined in Theorem \\ref{thm:TLyapunovconverse} satisfies the following estimates with probability $1-\\delta$:\n\n\n\n\n\n\n\n\n\n\\begin{eqnarray}\n\\left| \\left| \\langle\\nabla \\hat{T},f^*\\rangle_{\\mathbb{R}^d} - \\langle\\nabla {T},f^*\\rangle_{\\mathbb{R}^d}  \\right| \\right|_{L^\\infty(\\mathcal{D})} & \\le &\nC  ||T||_{W_2^{\\tau_2}(\\Omega_T)} \\left(h_\\mathbf{q}^{k_2-\\frac{1}{2}}\\right.\\nonumber\\\\\n&&\\left.+ \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}}{\\lambda \\sqrt{\\delta}}+ \\lambda^{r-\\frac{3}{2}} h_\\mathbf{x}  + \\lambda^{r-\\frac{1}{2}}\\right),\t\t\t\t\\label{eqn:mainresultT1}\\\\\n\\left| \\left| \\hat{T} - T\\right| \\right|_{L^\\infty(\\Gamma)} & \\le &C h_{\\tilde{\\mathbf{q}}}^{k_2+\\frac{1}{2}}||T||_{W_2^{\\tau_2}(\\Omega_T)},\n\\label{eqn:mainresultT2}\n\\end{eqnarray}\t\nwhere $\\Gamma$ is a non-characteristic hypersurface on which $T$ has defined values (see Definition \\ref{def:noncharhyp}),  $\\Omega_T\\supset\\mathcal{D}$ is a certain compact subset of $A(\\overline{x})$, and $\\frac{1}{2} < r \\le 1$.\\\\\n\\end{enumerate}\n\\end{theorem}\n\n\\begin{figure}\t\t\t\n\\begin{center}\n\\begin{overpic}[width=12cm]{figure.eps}\n\\put(5,38){\\small{$X$}}\n\\put(22,41){\\footnotesize{$\\Omega_V/\\Omega_T$}}\n\\put(17,28){\\small{$\\Omega$}}\n\\put(40,36){\\small{$\\Gamma$}}\n\\put(32.4,26){\\small{$B_{\\varepsilon}(\\overline{x})$}}\n\\put(48.,29.8){\\small{$\\tilde{\\Gamma}$}}\n\\put(50.3,24.5){\\small{$\\overline{x}$}}\n\\end{overpic}\n\\end{center}\n\\caption{Domains and sets used in the statement and proof of Theorem \\ref{thm:mainresult}. The dotted lines show the boundary of the set $\\mathcal{D}=\\Omega\\setminus B_{\\varepsilon}(\\overline{x})$ where the Lyapunov functions are approximated. We also have  $\\Omega_V,\\Omega_T\\subset A(\\overline{x})$.}\t\t\\label{fig:domains}\n\\end{figure}\n\n\n\nThe main point is that the expressions on the right hand side of \\eqref{eqn:mainresultV}--\\eqref{eqn:mainresultT2} can be made arbitrarily small as the data density increases and for suitably chosen $\\lambda$ (see equation \\eqref{eqn:lambdachoice}). Therefore the orbital derivative of our Lyapunov function approximations $\\hat{V}$ and $\\hat{T}$ become arbitrarily close in the infinity norm to those of $V$ and $T$ respectively. Estimate \\eqref{eqn:mainresultV} implies that the orbital derivative of $\\hat{V}$ will be negative in $\\mathcal{D}$ (which does not contain a small neighbourhood of the equilibrium $\\overline{x}$), since $\\langle\\nabla V(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -p(x)$ where $p$ is a positive definite function (see Theorem \\ref{thm:VLyapunovconverse}). The analogous statement is true for $\\hat{T}$, since $\\langle\\nabla T(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -\\overline{c} <0$.\nIn principle the neighbourhood $B_\\varepsilon(\\overline{x})$ can shrink as the data density increases (as $h_\\mathbf{x}$ and $||\\mathbf{w}||_{\\mathbb{R}^m}$ tend to zero).\n\n\nThe above estimate contains $\\lambda >0$ as a regularisation parameter of our algorithm, and $h_\\mathbf{q}$ as the fill distance of a set of sampled points in $\\Omega_V$ (resp. $\\Omega_T$) of our choosing. Similarly, $h_{\\tilde{\\mathbf{q}}}$ is the fill distance of a set of sampled points on $\\Gamma$, which we are able to choose. The constants in the above estimates depend on $d$, $\\sigma$, the choice of function spaces for approximation and  the vector field $f^*$.\n\n\n\n\n\n\n\n\n\n\n\nThe rest of the paper is organised as follows. In \\S\\ref{sec:conversethms} we provide the converse theorems for the Lyapunov functions $V$ and $T$. In \\S\\ref{sec:background} we set out the framework for the function spaces that are used to approximate the Lyapunov functions, as well as previous results on the approximation of Lyapunov functions when the right hand side of \\eqref{eqn:dynsys} is known. The algorithms themselves that are used to compute $\\hat{V}$ and $\\hat{T}$ are detailed in \\S\\ref{sec:algorithm}. In \\S\\ref{sec:errorf} we provide an estimate for our approximation of the right hand side of \\eqref{eqn:dynsys}, which is then used in the proof of Theorem \\ref{thm:mainresult}  in \\S\\ref{sec:proofofmainthm}.\n\n\n\n\n\n\\section{Converse theorems for Lyapunov functions}\t\t\t\\label{sec:conversethms}\n\nThe concept of a Lyapunov function dates back to 1893, where Lyapunov introduced these functions for the stability analysis of an equilibrium for a given differential equation, without the explicit knowledge of the solutions \\cite{Lya07}. Many converse theorems have been proved that guarantee the existence of a Lyapunov function under certain conditions, see \\cite{Gie07:a,Hah67,Kel15} for an overview. Massera \\cite{Mas49} provided the first main converse theorem for $C^1$ vector fields where $A(\\overline{x})=\\mathbb{R}^d$, with further developments by several authors to prove the existence of smooth Lyapunov functions under weak smoothness assumptions on the right hand side (see e.g. \\cite{Hah59,LinSonWan96,Wes67}).\n\nThe existence of a Lyapunov function for system \\eqref{eqn:dynsys} with given values of the orbital derivative has been shown by Bhatia \\cite{Bha67,BhaSze70}, as stated in the following theorems (see also \\cite{Gie07:a}). We also refer to \\cite{GieHaf15} for a proof that the conditions on the function $p$ given here are sufficient to define the Lyapunov function $V$, in contrast to the conditions given in \\cite{Gie07:a}. First we make the following definition.\n\n\\begin{definition}\t\t\t\\label{def:classK}\nA continuous function $\\alpha: [0,\\infty) \\rightarrow [0,\\infty)$ is a class $\\mathcal{K}$ function if $\\alpha(0) = 0$ and $\\alpha$ is strictly monotonically increasing.\n\\end{definition}\n\n\n\n\\begin{theorem}\t\t\t\\label{thm:VLyapunovconverse}\nConsider the autonomous system of differential equations\n\n$\\dot{x}=f^*(x)$,\n\nwhere $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. We assume the system to have an\nexponentially asymptotically stable equilibrium $\\overline{x}$. Let $p\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ be a function with the following properties:\n\\begin{enumerate}\n\\item $p(x)>0$ for $x\\ne\\overline{x}$, and $p(\\overline{x}) = 0$.\n\n\n\\item There is a class $\\mathcal{K}$ function $\\alpha$ such that $p(x-\\overline{x}) \\ge \\alpha(||x-\\overline{x}||_2)$ for all $x\\in\\mathbb{R}^d$.\n\\end{enumerate}\n\nThen there exists a Lyapunov function $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ (where $A(\\overline{x})$ is the basin of attraction of $\\overline{x}$), such that\n\n", "index": 3, "text": "\\begin{equation}\t\t\t\\label{eq:Veq}\n\\langle \\nabla V(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -p(x)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\langle\\nabla V(x),f^{*}(x)\\rangle_{\\mathbb{R}^{d}}=-p(x)\" display=\"block\"><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>V</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>=</mo><mrow><mo>-</mo><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nMoreover, $\\lim_{x\\rightarrow\\overline{x}}T(x)=-\\infty$.\n\\end{theorem}\n\nThe Lyapunov function $T$ will be uniquely defined if its values  are given on a non-characteristic hypersurface $\\Gamma\\subset A(\\overline{x})$ \\cite{Gie07:a} by a function $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$; that is, $T(x) = \\xi_T(x)$ for $x\\in \\Gamma$.\n\n\\begin{definition}[Non-characteristic hypersurface]\t\t\t\\label{def:noncharhyp}\nConsider $\\dot{x}=f^*(x)$, where $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. Let $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ and recall $\\varphi_{f^*}: \\mathbb{R}^d \\times \\mathbb{R} \\rightarrow \\mathbb{R}^d$ denotes the flow mapping. The set $\\Gamma\\subset\\mathbb{R}^d$ is\ncalled a non-characteristic hypersurface if\n\\begin{enumerate}\n\\item $\\Gamma$ is compact,\n\\item $h(x) = 0$ if and only if $x\\in\\Gamma$,\n\\item $h'(x) = \\langle h(x),f^*(x)\\rangle_{\\mathbb{R}^d}<0$ holds for all $x\\in\\Gamma$, and\n\\item for each $x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\}$ there is a time $\\theta(x)\\in\\mathbb{R}$ such that $\\varphi_{f^*}(x,\\theta(x))\\in\\Gamma$.\n\\end{enumerate}\n\\end{definition}\n\nAn example of a non-characteristic hypersurface is the level set of a (local) Lyapunov function, see \\cite{Gie07:a}. In what follows we assume that we have chosen a  non-characteristic hypersurface $\\Gamma$ together with a function $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ so that $T$ is uniquely defined.\n\n\\begin{remark}\nThe Lyapunov function $V$ is smooth and defined on the entire basin of attraction $A(\\overline{x})$. However, its orbital derivative vanishes at the equilibrium $\\overline{x}$, and therefore estimates that bound the error of the orbital derivative for numerical approximations of $V$ cannot guarantee negative orbital derivative arbitrarily close to the equilibrium $\\overline{x}$. On the other hand, the Lyapunov function $T$ is not even defined at $\\overline{x}$ and is unbounded near the equilibrium. However, its definition has the advantage that it is not required that we know where the equilibrium is.\n\n\\end{remark}\n\nIn our approach to approximate Lyapunov functions directly from data, we will provide estimates for the approximation of both $V$ and $T$. The strategy is to first approximate $f^*$ from the data, and use this in turn to approximate the Lyapunov function.\n\n\n\n\n\n\n\\section{Function spaces and approximation theorems for Lyapunov functions}\t\t\t\\label{sec:background}\t\t\t\n\n\\subsection{Reproducing kernel Hilbert spaces}\t\t\\label{sec:RKHS}\n\nThe function spaces that we  use to search for our approximations to both $f^*$ and the Lyapunov functions $V$ and $T$ will be  reproducing kernel Hilbert spaces (RKHS). For a survey of the main properties of RKHS spaces mentioned in this section, we refer to \\cite{CucSma01}.\n\nIn order to define an RKHS function space we first fix a continuous, symmetric, positive definite function (a ``kernel'') $K:X\\times X\\rightarrow\\mathbb{R}$, and set $K_x:= K(\\cdot,x)$. Define the Hilbert space $\\mathcal{H}_K$ by first considering all finite linear combinations of functions $K_x$, that is $\\sum_{x_i\\in X} a_iK_{x_i}$ with finitely many $a_i\\in\\mathbb{R}$ nonzero. An inner product $\\langle \\cdot , \\cdot \\rangle_K$ on this space is defined by\n\n", "itemtype": "equation", "pos": 15438, "prevtext": "\nholds  for all $x\\in A(\\overline{x})$. The Lyapunov function $V$ is uniquely defined up to a constant.\n\\end{theorem}\n\nWe may also choose $p(x)$ to be a positive constant in equation \\eqref{eq:Veq} to obtain a Lyapunov function $T$, defined on $A(\\overline{x})\\backslash\\{\\overline{x}\\}$, for which $\\lim_{x\\rightarrow\\overline{x}}T(x) = -\\infty$.\n\n\\begin{theorem}\t\t\t\\label{thm:TLyapunovconverse}\nConsider the autonomous system of differential equations\n\n$\\dot{x}=f^*(x)$,\n\nwhere $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. We assume the system to have an\nexponentially asymptotically stable equilibrium $\\overline{x}$. Then for all $\\overline{c}\\in\\mathbb{R}^+$, there exists a Lyapunov function $T\\in C^{\\nu_1}(A(\\overline{x})\\,\\backslash\\,\\{\\overline{x}\\},\\mathbb{R})$ such that\n\n", "index": 5, "text": "\\begin{equation}\t\t\t\\label{eq:Teq}\n\\langle \\nabla T(x), f^*(x)\\rangle_{\\mathbb{R}^d} = -\\overline{c}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\langle\\nabla T(x),f^{*}(x)\\rangle_{\\mathbb{R}^{d}}=-\\overline{c}.\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>T</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>=</mo><mrow><mo>-</mo><mover accent=\"true\"><mi>c</mi><mo>\u00af</mo></mover></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nand extending linearly. One takes the completion to obtain $\\mathcal{H}_K$.\n\nAlternatively, an equivalent definition of an RKHS is as a Hilbert space of real-valued functions on $X$ for which the evaluation functional $\\delta_x(f):= f(x)$ is continuous for all $x\\in X$.\n\nFinite dimensional subspaces of $\\mathcal{H}_K$ can also be naturally defined by taking a finite number of points $\\mathbf{x}:=\\{x_1,\\ldots,x_m\\}\\subset X$ and considering the linear span\n\n", "itemtype": "equation", "pos": 18804, "prevtext": "\nMoreover, $\\lim_{x\\rightarrow\\overline{x}}T(x)=-\\infty$.\n\\end{theorem}\n\nThe Lyapunov function $T$ will be uniquely defined if its values  are given on a non-characteristic hypersurface $\\Gamma\\subset A(\\overline{x})$ \\cite{Gie07:a} by a function $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$; that is, $T(x) = \\xi_T(x)$ for $x\\in \\Gamma$.\n\n\\begin{definition}[Non-characteristic hypersurface]\t\t\t\\label{def:noncharhyp}\nConsider $\\dot{x}=f^*(x)$, where $f^*\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R}^d)$, $\\nu_1\\ge1$, $d\\in\\mathbb{N}$. Let $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ and recall $\\varphi_{f^*}: \\mathbb{R}^d \\times \\mathbb{R} \\rightarrow \\mathbb{R}^d$ denotes the flow mapping. The set $\\Gamma\\subset\\mathbb{R}^d$ is\ncalled a non-characteristic hypersurface if\n\\begin{enumerate}\n\\item $\\Gamma$ is compact,\n\\item $h(x) = 0$ if and only if $x\\in\\Gamma$,\n\\item $h'(x) = \\langle h(x),f^*(x)\\rangle_{\\mathbb{R}^d}<0$ holds for all $x\\in\\Gamma$, and\n\\item for each $x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\}$ there is a time $\\theta(x)\\in\\mathbb{R}$ such that $\\varphi_{f^*}(x,\\theta(x))\\in\\Gamma$.\n\\end{enumerate}\n\\end{definition}\n\nAn example of a non-characteristic hypersurface is the level set of a (local) Lyapunov function, see \\cite{Gie07:a}. In what follows we assume that we have chosen a  non-characteristic hypersurface $\\Gamma$ together with a function $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ so that $T$ is uniquely defined.\n\n\\begin{remark}\nThe Lyapunov function $V$ is smooth and defined on the entire basin of attraction $A(\\overline{x})$. However, its orbital derivative vanishes at the equilibrium $\\overline{x}$, and therefore estimates that bound the error of the orbital derivative for numerical approximations of $V$ cannot guarantee negative orbital derivative arbitrarily close to the equilibrium $\\overline{x}$. On the other hand, the Lyapunov function $T$ is not even defined at $\\overline{x}$ and is unbounded near the equilibrium. However, its definition has the advantage that it is not required that we know where the equilibrium is.\n\n\\end{remark}\n\nIn our approach to approximate Lyapunov functions directly from data, we will provide estimates for the approximation of both $V$ and $T$. The strategy is to first approximate $f^*$ from the data, and use this in turn to approximate the Lyapunov function.\n\n\n\n\n\n\n\\section{Function spaces and approximation theorems for Lyapunov functions}\t\t\t\\label{sec:background}\t\t\t\n\n\\subsection{Reproducing kernel Hilbert spaces}\t\t\\label{sec:RKHS}\n\nThe function spaces that we  use to search for our approximations to both $f^*$ and the Lyapunov functions $V$ and $T$ will be  reproducing kernel Hilbert spaces (RKHS). For a survey of the main properties of RKHS spaces mentioned in this section, we refer to \\cite{CucSma01}.\n\nIn order to define an RKHS function space we first fix a continuous, symmetric, positive definite function (a ``kernel'') $K:X\\times X\\rightarrow\\mathbb{R}$, and set $K_x:= K(\\cdot,x)$. Define the Hilbert space $\\mathcal{H}_K$ by first considering all finite linear combinations of functions $K_x$, that is $\\sum_{x_i\\in X} a_iK_{x_i}$ with finitely many $a_i\\in\\mathbb{R}$ nonzero. An inner product $\\langle \\cdot , \\cdot \\rangle_K$ on this space is defined by\n\n", "index": 7, "text": "\\begin{equation*}\n\\langle K_{x_i},K_{x_j} \\rangle_K := K(x_i,x_j)\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\langle K_{x_{i}},K_{x_{j}}\\rangle_{K}:=K(x_{i},x_{j})\" display=\"block\"><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>K</mi><msub><mi>x</mi><mi>i</mi></msub></msub><mo>,</mo><msub><mi>K</mi><msub><mi>x</mi><mi>j</mi></msub></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mi>K</mi></msub><mo>:=</mo><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nIn practice we will seek functions in these finite dimensional subspaces as approximations for $f^*$.\n\nWithin these Hilbert spaces the reproducing property holds:\n\n", "itemtype": "equation", "pos": 19346, "prevtext": "\nand extending linearly. One takes the completion to obtain $\\mathcal{H}_K$.\n\nAlternatively, an equivalent definition of an RKHS is as a Hilbert space of real-valued functions on $X$ for which the evaluation functional $\\delta_x(f):= f(x)$ is continuous for all $x\\in X$.\n\nFinite dimensional subspaces of $\\mathcal{H}_K$ can also be naturally defined by taking a finite number of points $\\mathbf{x}:=\\{x_1,\\ldots,x_m\\}\\subset X$ and considering the linear span\n\n", "index": 9, "text": "\\begin{equation*}\n\\mathcal{H}_{K,\\mathbf{x}} := \\textrm{sp}\\{K_x:x\\in\\mathbf{x}\\}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{H}_{K,\\mathbf{x}}:=\\textrm{sp}\\{K_{x}:x\\in\\mathbf{x}\\}.\" display=\"block\"><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mrow><mi>K</mi><mo>,</mo><mi>\ud835\udc31</mi></mrow></msub><mo>:=</mo><mrow><mtext>sp</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>K</mi><mi>x</mi></msub><mo>:</mo><mrow><mi>x</mi><mo>\u2208</mo><mi>\ud835\udc31</mi></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nIf we denote $\\kappa:=\\sqrt{\\sup_{x\\in X} K(x,x)}$, then $\\mathcal{H}_K\\subset C(X)$ and it follows that\n\n", "itemtype": "equation", "pos": 19608, "prevtext": "\nIn practice we will seek functions in these finite dimensional subspaces as approximations for $f^*$.\n\nWithin these Hilbert spaces the reproducing property holds:\n\n", "index": 11, "text": "\\begin{equation}\n\\langle K_x,f\\rangle_K = f(x), \\qquad \\forall f\\in\\mathcal{H}_K.\t\t\\label{eq:reproducing}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\langle K_{x},f\\rangle_{K}=f(x),\\qquad\\forall f\\in\\mathcal{H}_{K}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>K</mi><mi>x</mi></msub><mo>,</mo><mi>f</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mi>K</mi></msub><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mi>f</mi></mrow><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mi>K</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\n\n\n\n\nThe RKHS $\\mathcal{H}_K$ can also be defined by means of an integral operator. Let $\\rho$ be any (finite) strictly positive Borel measure on $X$ (e.g. Lebesgue measure) and ${L}^2_\\rho(X)$ be the Hilbert space of square integrable functions on $X$. Then define the linear operator $L_K:{L}^2_\\rho(X)\\rightarrow C(X)$ by\n\n", "itemtype": "equation", "pos": 19834, "prevtext": "\nIf we denote $\\kappa:=\\sqrt{\\sup_{x\\in X} K(x,x)}$, then $\\mathcal{H}_K\\subset C(X)$ and it follows that\n\n", "index": 13, "text": "\\begin{equation}\n||f||_{L^\\infty(X)} \\le \\kappa||f||_K, \\qquad \\forall f\\in\\mathcal{H}_K.\t\t\\label{eq:supnorminclusion}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"||f||_{L^{\\infty}(X)}\\leq\\kappa||f||_{K},\\qquad\\forall f\\in\\mathcal{H}_{K}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>f</mi><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>\u03ba</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mi>f</mi><mo fence=\"true\">||</mo></mrow><mi>K</mi></msub></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mi>f</mi></mrow><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mi>K</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nWhen composed with the inclusion $C(X)\\hookrightarrow L^2_\\rho(X)$ we obtain an operator from $L^2_\\rho(X)$ to $L^2_\\rho(X)$, which we also denote by $L_K$.\n $L_K$ is then a self-adjoint compact operator, and  it is also positive if the kernel $K$ is positive definite. Also the map\n\n", "itemtype": "equation", "pos": 20294, "prevtext": "\n\n\n\n\n\n\nThe RKHS $\\mathcal{H}_K$ can also be defined by means of an integral operator. Let $\\rho$ be any (finite) strictly positive Borel measure on $X$ (e.g. Lebesgue measure) and ${L}^2_\\rho(X)$ be the Hilbert space of square integrable functions on $X$. Then define the linear operator $L_K:{L}^2_\\rho(X)\\rightarrow C(X)$ by\n\n", "index": 15, "text": "\\begin{equation}\t\t\t\\label{eq:LK}\n(L_K f)(x) = \\int_X K(x,y)f(y)d\\rho(y).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"(L_{K}f)(x)=\\int_{X}K(x,y)f(y)d\\rho(y).\" display=\"block\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>L</mi><mi>K</mi></msub><mo>\u2062</mo><mi>f</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>X</mi></msub><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03c1</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\ndefines an isomorphism of Hilbert spaces. $L_K^{1/2}$ is well defined as an operator on ${L}^2_\\rho(X)$ in the sense that $L_K = L_K^{1/2}\\circ L_K^{1/2}$.\n\n\\subsection{Sobolev space RKHS}\t\t\t\\label{sec:SobolevspaceRKHS}\n\nIn this paper we will work with reproducing kernel Hilbert spaces that are Sobolev spaces. Given the open domain $\\mathcal{B}\\subset \\mathbb{R}^d$, for $k\\in \\mathbb{N}_0$, $1\\le p < \\infty$, the Sobolev space $W^k_p(\\mathcal{B})$ consists of all functions $f$ with weak derivatives $D^\\alpha f \\in L^p(\\mathcal{B})$, $|\\alpha| \\le k$. We also use the following notation to define the (semi-)norms\n\n", "itemtype": "equation", "pos": 20665, "prevtext": "\nWhen composed with the inclusion $C(X)\\hookrightarrow L^2_\\rho(X)$ we obtain an operator from $L^2_\\rho(X)$ to $L^2_\\rho(X)$, which we also denote by $L_K$.\n $L_K$ is then a self-adjoint compact operator, and  it is also positive if the kernel $K$ is positive definite. Also the map\n\n", "index": 17, "text": "\\begin{equation*}\nL_K^{1/2}:{L}^2_\\rho(X)\\rightarrow \\mathcal{H}_K\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"L_{K}^{1/2}:{L}^{2}_{\\rho}(X)\\rightarrow\\mathcal{H}_{K}\" display=\"block\"><mrow><msubsup><mi>L</mi><mi>K</mi><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msubsup><mo>:</mo><mrow><mrow><msubsup><mi>L</mi><mi>\u03c1</mi><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2192</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mi>K</mi></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nWith $p=\\infty$ the norms are defined in the natural way:\n\n", "itemtype": "equation", "pos": 21367, "prevtext": "\ndefines an isomorphism of Hilbert spaces. $L_K^{1/2}$ is well defined as an operator on ${L}^2_\\rho(X)$ in the sense that $L_K = L_K^{1/2}\\circ L_K^{1/2}$.\n\n\\subsection{Sobolev space RKHS}\t\t\t\\label{sec:SobolevspaceRKHS}\n\nIn this paper we will work with reproducing kernel Hilbert spaces that are Sobolev spaces. Given the open domain $\\mathcal{B}\\subset \\mathbb{R}^d$, for $k\\in \\mathbb{N}_0$, $1\\le p < \\infty$, the Sobolev space $W^k_p(\\mathcal{B})$ consists of all functions $f$ with weak derivatives $D^\\alpha f \\in L^p(\\mathcal{B})$, $|\\alpha| \\le k$. We also use the following notation to define the (semi-)norms\n\n", "index": 19, "text": "\\begin{equation*}\n|f|_{W^k_p(\\mathcal{B})} = \\left( \\sum_{|\\alpha | = k} || D^\\alpha f ||^p_{L^p(\\mathcal{B})} \\right)^{1/p},\\quad\n||f||_{W^k_p(\\mathcal{B})} = \\left( \\sum_{|\\alpha | \\le k} || D^\\alpha f ||^p_{L^p(\\mathcal{B})} \\right)^{1/p}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"|f|_{W^{k}_{p}(\\mathcal{B})}=\\left(\\sum_{|\\alpha|=k}||D^{\\alpha}f||^{p}_{L^{p}%&#10;(\\mathcal{B})}\\right)^{1/p},\\quad||f||_{W^{k}_{p}(\\mathcal{B})}=\\left(\\sum_{|%&#10;\\alpha|\\leq k}||D^{\\alpha}f||^{p}_{L^{p}(\\mathcal{B})}\\right)^{1/p}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mi>f</mi><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mi>p</mi><mi>k</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>=</mo><msup><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03b1</mi><mo stretchy=\"false\">|</mo></mrow><mo>=</mo><mi>k</mi></mrow></munder><msubsup><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>D</mi><mi>\u03b1</mi></msup><mo>\u2062</mo><mi>f</mi></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi>p</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></msubsup></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msup></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>f</mi><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mi>p</mi><mi>k</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>=</mo><msup><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03b1</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mi>k</mi></mrow></munder><msubsup><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>D</mi><mi>\u03b1</mi></msup><mo>\u2062</mo><mi>f</mi></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi>p</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></msubsup></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nWe will also use fractional order Sobolev spaces. For a detailed discussion see e.g. \\cite{Ada75}.\n\nThe Sobolev embedding theorem states that for $\\tau > d/2$, $W^\\tau_2(\\mathbb{R}^d)$ can be embedded into $C(\\mathbb{R}^d)$, and therefore it follows that $W^\\tau_2(\\mathbb{R}^d)$ is a RKHS, using the fact that the pointwise evaluation functional is then continuous. Several kernel functions are known to generate RKHS spaces that are norm-equivalent to Sobolev spaces \\cite{Opf06:a,Opf06:b}. We will choose to work with the Wendland functions \\cite{Wen95}. These are positive definite, compactly supported radial basis function kernels that are represented by a univariate polynomial on their support.\n\\begin{definition}[Wendland function]\nLet $l\\in\\mathbb{N}$, $k\\in\\mathbb{N}_0$. We define by recursion\n\\begin{eqnarray*}\n\\psi_{l,0}(r) &=& (1-r)^l_+\\\\\n\\textrm{and }\\psi_{l,k+1}(r) &=& \\int^1_r t\\psi_{l,k}(t)dt\n\\end{eqnarray*}\nfor $r\\in\\mathbb{R}^+_0$. Here, $x_+ = x$ for $x\\ge 0$ and $x_+ = 0$ for $x<0$.\n\\end{definition}\n\nSetting $l:=\\lfloor\\frac{d}{2}\\rfloor + k + 1$, the Wendland functions are characterised by a smoothness index $k\\in\\mathbb{N}$, and belong to $C^{2k}(\\mathbb{R}^d)$. For a domain  $D\\subset \\mathbb{R}^d$ with a Lipschitz boundary, the Wendland  function kernel is given by $K(x,y):=\\psi_{l,k}(c||x-y||_{\\mathbb{R}^d})$, $c>0$, for $x,y\\in D$. The Wendland function kernel generates an RKHS consisting of the same functions as  the Sobolev space $W^\\tau_2(D)$ with $\\tau = k + (d+1)/2$, with an equivalent norm \\cite[Corollary 10.48]{Wen05}. Therefore the generated Sobolev space is of integer order when $d$ is odd, and integer plus one half when $d$ is even.\n\nFrom now on we shall use RKHS spaces generated by Wendland function kernels. We will use two such RKHS spaces for the two parts of our algorithm: to approximate the vector field $f^*$ in \\eqref{eqn:dynsys} we use the space $\\mathcal{H}_{K^{1}}$ defined on $X$, corresponding to the Wendland function kernel $K^{1}$ with smoothness index $k_1$, such\n that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil \\tau_1 \\rceil = \\nu_1$. Then $\\mathcal{H}_{K^1}$ is norm-equivalent to $W^{\\tau_1}_2(X)$. In this case, when $d$ is odd we have that $\\lceil\\tau_1\\rceil=\\tau_1$, and the assumption that $\\nu_1 \\ge (3d+7)/2$  implies that $k_1 \\ge d+3$. When $d$ is even, $\\lceil\\tau_1\\rceil = \\tau_1 + 1/2$, and the assumption that $\\nu_1\\ge (3d+12)/2$  gives  $k_1 \\ge d+5$ (cf. Theorem \\ref{thm:mainresult}).\n\nIn the second part of our algorithm we approximate the Lyapunov function. For this, we use the RKHS space $\\mathcal{H}_{K^{2}}$ defined on $\\Omega_V$ (resp. $\\Omega_T$) corresponding to the Wendland function kernel $K^{2}$ with smoothness index $k_2$, such that $k_2 = k_1 - (d+2)$ if $d$ is odd, or $k_2 = k_1 - (d+3)\n$ if $d$ is even. Correspondingly, this implies that $k_2 \\ge 1$ when $d$ is odd, and $k_2 \\ge 2$ when $d$ is even. Here, $\\mathcal{H}_{K^2}$ is norm-equivalent to $W^{\\tau_2}_2(\\Omega_V)$ (resp.  $W^{\\tau_2}_2(\\Omega_T)$), where $\\tau_2:= k_2 + (d+1)/2$.\n\n\n\n\n\n\n\n\nThese function spaces consist of smooth functions as a consequence of the following generalised Sobolev inequality (for a proof, see e.g. \\cite[Chapter 5.7, Theorem 6]{Eva98}).\n\n\n\\begin{lemma}\t\t\t\t\t\\label{lem:genSobolev}\nLet $\\mathcal{B}\\subset\\mathbb{R}^d$ be a bounded open set with $C^1$ boundary. For $u\\in W^{m}_2(\\mathcal{B})$ where $m > d/2$, we have\n\n", "itemtype": "equation", "pos": 21684, "prevtext": "\nWith $p=\\infty$ the norms are defined in the natural way:\n\n", "index": 21, "text": "\\begin{equation*}\n|f|_{W^k_\\infty (\\mathcal{B})} = \\sup_{\\alpha = k} ||D^\\alpha f ||_{L^\\infty(\\mathcal{B})} \\quad \\text{and}\\quad ||f||_{W^k_\\infty (\\mathcal{B})} = \\sup_{\\alpha \\le k} ||D^\\alpha f ||_{L^\\infty(\\mathcal{B})}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"|f|_{W^{k}_{\\infty}(\\mathcal{B})}=\\sup_{\\alpha=k}||D^{\\alpha}f||_{L^{\\infty}(%&#10;\\mathcal{B})}\\quad\\text{and}\\quad||f||_{W^{k}_{\\infty}(\\mathcal{B})}=\\sup_{%&#10;\\alpha\\leq k}||D^{\\alpha}f||_{L^{\\infty}(\\mathcal{B})}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mi>f</mi><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mi mathvariant=\"normal\">\u221e</mi><mi>k</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>=</mo><mrow><mrow><munder><mo movablelimits=\"false\">sup</mo><mrow><mi>\u03b1</mi><mo>=</mo><mi>k</mi></mrow></munder><mo>\u2061</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>D</mi><mi>\u03b1</mi></msup><mo>\u2062</mo><mi>f</mi></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>f</mi><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mi mathvariant=\"normal\">\u221e</mi><mi>k</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>=</mo><mrow><munder><mo movablelimits=\"false\">sup</mo><mrow><mi>\u03b1</mi><mo>\u2264</mo><mi>k</mi></mrow></munder><mo>\u2061</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>D</mi><mi>\u03b1</mi></msup><mo>\u2062</mo><mi>f</mi></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $\\gamma = \\frac{1}{2}$ if $d$ is odd, and $\\gamma$ is any element in $(0,1)$ if $d$ is even.\n\\end{lemma}\n\n\\begin{corollary}\t\t\t\t\\label{cor:smoothnessK1K2}\nFor $f\\in\\mathcal{H}_{K^1}$ and $g\\in\\mathcal{H}_{K^2}$, we have\n\\begin{eqnarray}\n|| f ||_{C^{k_1}(X)} &\\le& C || f ||_{K^1},\t\\quad (\\textrm{when }d\\textrm{ is odd}),\t\\label{eqn:smoothnessK1:a}\\\\\n|| f ||_{C^{k_1-1}(X)} &\\le& C || f ||_{K^1},\t\\quad (\\textrm{when }d\\textrm{ is even}),\t\\label{eqn:smoothnessK1:b}\\\\\n|| g ||_{C^{1}(\\Omega_V/\\Omega_T)} &\\le& C || g ||_{K^2}.\t\t\\label{eqn:smoothnessK2}\n\\end{eqnarray}\n\n\\end{corollary}\n\\begin{proof}\nFollowing the arguments given in \\cite{NarWarWen04}, there exists a bounded extension operator $E$ that extends $f\\in W_2^{\\tau_1}(X)$ to $Ef\\in W_2^{\\tau_1}(\\mathbb{R}^d)$ such that $Eu = u$ on $X$. Then, from Lemma \\ref{lem:genSobolev} we have\n\\begin{eqnarray*}\n||f||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(X)} &=& ||Ef||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(X)}\n \\le  || Ef ||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(\\mathbb{R}^d)}\\\\\n& \\le & \\tilde{C} || Ef ||_{W^{\\tau_1}_2(\\mathbb{R}^d)}\n \\le  C || f ||_{W^{\\tau_1}_2(X)}.\n\\end{eqnarray*}\nThen \\eqref{eqn:smoothnessK1:a} and \\eqref{eqn:smoothnessK1:b} follow from using the norm equivalence of $\\mathcal{H}_{K^1}$  to $W^{\\tau_1}_2(X)$, and that $\\tau_1 = k_1 + (d+1)/2$. Inequality \\eqref{eqn:smoothnessK2} follows similarly, also using  $k_2 \\ge 1$ when $d$ is odd, and $k_2 \\ge 2$ when $d$ is even.\n\\end{proof}\n\n\n\n\n\n\n\n\\subsection{Generalised interpolant and approximation theorems}\n\n\nIn this section we introduce the generalised interpolant that is used to approximate the Lyapunov functions $V$ and $T$.\n\nConsider a  general interpolation setting where $\\Omega\\subset\\mathbb{R}^d$ is a bounded domain having a Lipschitz boundary. Let  $L$ be a linear differential operator and $\\mathbf{q}:=\\{q_1,\\ldots,q_M\\}\\subset\\Omega$ be a set of pairwise distinct points which do not contain any singular points of $L$. (A point $q\\in\\mathbb{R}^d$ is a singular point of $L$ if $\\delta_q\\circ L = 0$, see also \\cite{GieWen07}.) We define linear functionals\n\n", "itemtype": "equation", "pos": 25344, "prevtext": "\nWe will also use fractional order Sobolev spaces. For a detailed discussion see e.g. \\cite{Ada75}.\n\nThe Sobolev embedding theorem states that for $\\tau > d/2$, $W^\\tau_2(\\mathbb{R}^d)$ can be embedded into $C(\\mathbb{R}^d)$, and therefore it follows that $W^\\tau_2(\\mathbb{R}^d)$ is a RKHS, using the fact that the pointwise evaluation functional is then continuous. Several kernel functions are known to generate RKHS spaces that are norm-equivalent to Sobolev spaces \\cite{Opf06:a,Opf06:b}. We will choose to work with the Wendland functions \\cite{Wen95}. These are positive definite, compactly supported radial basis function kernels that are represented by a univariate polynomial on their support.\n\\begin{definition}[Wendland function]\nLet $l\\in\\mathbb{N}$, $k\\in\\mathbb{N}_0$. We define by recursion\n\\begin{eqnarray*}\n\\psi_{l,0}(r) &=& (1-r)^l_+\\\\\n\\textrm{and }\\psi_{l,k+1}(r) &=& \\int^1_r t\\psi_{l,k}(t)dt\n\\end{eqnarray*}\nfor $r\\in\\mathbb{R}^+_0$. Here, $x_+ = x$ for $x\\ge 0$ and $x_+ = 0$ for $x<0$.\n\\end{definition}\n\nSetting $l:=\\lfloor\\frac{d}{2}\\rfloor + k + 1$, the Wendland functions are characterised by a smoothness index $k\\in\\mathbb{N}$, and belong to $C^{2k}(\\mathbb{R}^d)$. For a domain  $D\\subset \\mathbb{R}^d$ with a Lipschitz boundary, the Wendland  function kernel is given by $K(x,y):=\\psi_{l,k}(c||x-y||_{\\mathbb{R}^d})$, $c>0$, for $x,y\\in D$. The Wendland function kernel generates an RKHS consisting of the same functions as  the Sobolev space $W^\\tau_2(D)$ with $\\tau = k + (d+1)/2$, with an equivalent norm \\cite[Corollary 10.48]{Wen05}. Therefore the generated Sobolev space is of integer order when $d$ is odd, and integer plus one half when $d$ is even.\n\nFrom now on we shall use RKHS spaces generated by Wendland function kernels. We will use two such RKHS spaces for the two parts of our algorithm: to approximate the vector field $f^*$ in \\eqref{eqn:dynsys} we use the space $\\mathcal{H}_{K^{1}}$ defined on $X$, corresponding to the Wendland function kernel $K^{1}$ with smoothness index $k_1$, such\n that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil \\tau_1 \\rceil = \\nu_1$. Then $\\mathcal{H}_{K^1}$ is norm-equivalent to $W^{\\tau_1}_2(X)$. In this case, when $d$ is odd we have that $\\lceil\\tau_1\\rceil=\\tau_1$, and the assumption that $\\nu_1 \\ge (3d+7)/2$  implies that $k_1 \\ge d+3$. When $d$ is even, $\\lceil\\tau_1\\rceil = \\tau_1 + 1/2$, and the assumption that $\\nu_1\\ge (3d+12)/2$  gives  $k_1 \\ge d+5$ (cf. Theorem \\ref{thm:mainresult}).\n\nIn the second part of our algorithm we approximate the Lyapunov function. For this, we use the RKHS space $\\mathcal{H}_{K^{2}}$ defined on $\\Omega_V$ (resp. $\\Omega_T$) corresponding to the Wendland function kernel $K^{2}$ with smoothness index $k_2$, such that $k_2 = k_1 - (d+2)$ if $d$ is odd, or $k_2 = k_1 - (d+3)\n$ if $d$ is even. Correspondingly, this implies that $k_2 \\ge 1$ when $d$ is odd, and $k_2 \\ge 2$ when $d$ is even. Here, $\\mathcal{H}_{K^2}$ is norm-equivalent to $W^{\\tau_2}_2(\\Omega_V)$ (resp.  $W^{\\tau_2}_2(\\Omega_T)$), where $\\tau_2:= k_2 + (d+1)/2$.\n\n\n\n\n\n\n\n\nThese function spaces consist of smooth functions as a consequence of the following generalised Sobolev inequality (for a proof, see e.g. \\cite[Chapter 5.7, Theorem 6]{Eva98}).\n\n\n\\begin{lemma}\t\t\t\t\t\\label{lem:genSobolev}\nLet $\\mathcal{B}\\subset\\mathbb{R}^d$ be a bounded open set with $C^1$ boundary. For $u\\in W^{m}_2(\\mathcal{B})$ where $m > d/2$, we have\n\n", "index": 23, "text": "\\begin{equation}\t\t\t\t\\label{eq:genSobolev}\n|| u ||_{C^{m-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(\\mathcal{B})} \\le C ||u||_{W^{m}_2(\\mathcal{B})},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"||u||_{C^{m-\\lfloor{\\frac{d}{2}}\\rfloor-1,\\gamma}(\\mathcal{B})}\\leq C||u||_{W^%&#10;{m}_{2}(\\mathcal{B})},\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>u</mi><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>C</mi><mrow><mrow><mi>m</mi><mo>-</mo><mrow><mo stretchy=\"false\">\u230a</mo><mfrac><mi>d</mi><mn>2</mn></mfrac><mo stretchy=\"false\">\u230b</mo></mrow><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mi>\u03b3</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mi>u</mi><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><mi>m</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\n\\begin{definition}[Generalized interpolant]\t\t\t\\label{def:genint}\nSuppose we have values $Lu(q_i) = \\beta_i$ for $i=1,\\ldots,M$ for a function $u:\\Omega\\rightarrow\\mathbb{R}$.\nGiven a sufficiently smooth kernel $K(\\cdot,\\cdot)$, define the generalised interpolant as\n\n", "itemtype": "equation", "pos": 27650, "prevtext": "\nwhere $\\gamma = \\frac{1}{2}$ if $d$ is odd, and $\\gamma$ is any element in $(0,1)$ if $d$ is even.\n\\end{lemma}\n\n\\begin{corollary}\t\t\t\t\\label{cor:smoothnessK1K2}\nFor $f\\in\\mathcal{H}_{K^1}$ and $g\\in\\mathcal{H}_{K^2}$, we have\n\\begin{eqnarray}\n|| f ||_{C^{k_1}(X)} &\\le& C || f ||_{K^1},\t\\quad (\\textrm{when }d\\textrm{ is odd}),\t\\label{eqn:smoothnessK1:a}\\\\\n|| f ||_{C^{k_1-1}(X)} &\\le& C || f ||_{K^1},\t\\quad (\\textrm{when }d\\textrm{ is even}),\t\\label{eqn:smoothnessK1:b}\\\\\n|| g ||_{C^{1}(\\Omega_V/\\Omega_T)} &\\le& C || g ||_{K^2}.\t\t\\label{eqn:smoothnessK2}\n\\end{eqnarray}\n\n\\end{corollary}\n\\begin{proof}\nFollowing the arguments given in \\cite{NarWarWen04}, there exists a bounded extension operator $E$ that extends $f\\in W_2^{\\tau_1}(X)$ to $Ef\\in W_2^{\\tau_1}(\\mathbb{R}^d)$ such that $Eu = u$ on $X$. Then, from Lemma \\ref{lem:genSobolev} we have\n\\begin{eqnarray*}\n||f||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(X)} &=& ||Ef||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(X)}\n \\le  || Ef ||_{C^{\\tau_1-\\lfloor{\\frac{d}{2}}\\rfloor - 1,\\gamma}(\\mathbb{R}^d)}\\\\\n& \\le & \\tilde{C} || Ef ||_{W^{\\tau_1}_2(\\mathbb{R}^d)}\n \\le  C || f ||_{W^{\\tau_1}_2(X)}.\n\\end{eqnarray*}\nThen \\eqref{eqn:smoothnessK1:a} and \\eqref{eqn:smoothnessK1:b} follow from using the norm equivalence of $\\mathcal{H}_{K^1}$  to $W^{\\tau_1}_2(X)$, and that $\\tau_1 = k_1 + (d+1)/2$. Inequality \\eqref{eqn:smoothnessK2} follows similarly, also using  $k_2 \\ge 1$ when $d$ is odd, and $k_2 \\ge 2$ when $d$ is even.\n\\end{proof}\n\n\n\n\n\n\n\n\\subsection{Generalised interpolant and approximation theorems}\n\n\nIn this section we introduce the generalised interpolant that is used to approximate the Lyapunov functions $V$ and $T$.\n\nConsider a  general interpolation setting where $\\Omega\\subset\\mathbb{R}^d$ is a bounded domain having a Lipschitz boundary. Let  $L$ be a linear differential operator and $\\mathbf{q}:=\\{q_1,\\ldots,q_M\\}\\subset\\Omega$ be a set of pairwise distinct points which do not contain any singular points of $L$. (A point $q\\in\\mathbb{R}^d$ is a singular point of $L$ if $\\delta_q\\circ L = 0$, see also \\cite{GieWen07}.) We define linear functionals\n\n", "index": 25, "text": "\\begin{equation*}\n\\lambda^j(u) := \\delta_{q_j}\\circ L(u) = Lu(q_j).\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\lambda^{j}(u):=\\delta_{q_{j}}\\circ L(u)=Lu(q_{j}).\" display=\"block\"><mrow><mrow><mrow><msup><mi>\u03bb</mi><mi>j</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><msub><mi>\u03b4</mi><msub><mi>q</mi><mi>j</mi></msub></msub><mo>\u2218</mo><mi>L</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>L</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $(\\delta_{q_j} \\circ L)^y$ is the linear function applied to one argument of the kernel. The coefficient vector $\\alpha$ is the solution of $A\\alpha = \\beta = (\\beta_i)$ with the interpolation matrix $A \\in\\mathbb{R}^{M\\times M}$  given by\n\n", "itemtype": "equation", "pos": 28002, "prevtext": "\n\n\n\\begin{definition}[Generalized interpolant]\t\t\t\\label{def:genint}\nSuppose we have values $Lu(q_i) = \\beta_i$ for $i=1,\\ldots,M$ for a function $u:\\Omega\\rightarrow\\mathbb{R}$.\nGiven a sufficiently smooth kernel $K(\\cdot,\\cdot)$, define the generalised interpolant as\n\n", "index": 27, "text": "\\begin{equation*}\ns = \\sum_{j=1}^M \\alpha_j(\\delta_{q_j} \\circ L)^yK(\\cdot,y),\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"s=\\sum_{j=1}^{M}\\alpha_{j}(\\delta_{q_{j}}\\circ L)^{y}K(\\cdot,y),\" display=\"block\"><mrow><mrow><mi>s</mi><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>j</mi></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03b4</mi><msub><mi>q</mi><mi>j</mi></msub></msub><mo>\u2218</mo><mi>L</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>y</mi></msup><mo>\u2062</mo><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\\end{definition}\n\\begin{remark}\t\t\\label{rem:sgenint}\nAccording to the above definition, we have $Ls(q_i)=\\beta_i$. In addition, it can be shown that the generalised interpolant above is the unique norm-minimal  interpolant in $\\mathcal{H}_K$, see \\cite{Gie07:a,GieWen07}. The matrix $A$ is guaranteed to be invertible due to our  choice of the Wendland function kernel $K$ \\cite[Section 3.2.2]{Gie07:a}, and since $\\mathbf{q}$ does not contain any singular points.\n\\end{remark}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe conclude this section by citing  the following theorem from \\cite{GieWen07}, which provides convergence estimates for approximating  Lyapunov functions $V_g$ (resp. $T_g$) with the generalised interpolants $s_1$ (resp. $s_2$) as above, for a known dynamical system $\\dot{x} = g(x)$.\n\\begin{theorem}\t\t\t\t\\label{thm:GieWen}\nLet $\\nu_2:= \\lceil \\tau_2 \\rceil$ with $ \\tau_2 = k_2 +  (d+1)/2$, where $k_2$ is the smoothness index of the compactly supported Wendland function. Let $k_2>1/2$ if $d$ is odd or $k_2>1$ if $d$ is even. Consider the dynamical system defined by the ordinary differential equation $\\dot{x} = g(x)$, where $g\\in C^{\\nu_2}(\\mathbb{R}^d,\\mathbb{R}^d)$. Let $\\overline{x}\\in\\mathbb{R}^d$ be an equilibrium such that the real parts of all eigenvalues of $Dg(\\overline{x})$ are negative, and suppose $g$ is bounded in $A(\\overline{x})$.\n\nLet $\\Gamma$ be a non-characteristic hypersurface as in Definition \\ref{def:noncharhyp}, with $h\\in C^{\\nu_2}(\\mathbb{R}^d,\\mathbb{R})$ and  $\\xi_T\\in C^{\\nu_2}(\\Gamma,\\mathbb{R})$. Let $V_g\\in W^{\\tau_2}_2(A(\\overline{x}),\\mathbb{R})$, $T_g\\in W_2^{\\tau_2}(A(\\overline{x}) \\backslash \\{\\overline{x}\\},\\mathbb{R})$ be the Lyapunov functions of Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} for the system  $\\dot{x} = g(x)$, with $T_g(x)=\\xi_T(x)$ for $x\\in\\Gamma$.\n\n Given pairwise distinct sets of points $\\mathbf{q}:=(q_i)_{i=1}^M$ in $A(\\overline{x})$ (not containing $\\overline{x}$) and $\\tilde{\\mathbf{q}}:=(q_i)_{i=M+1}^{M+N}$ in $\\Gamma$,\n and let $\\Omega\\subset A(\\overline{x})$ be a bounded domain with Lipschitz boundary, with $\\mathbf{q}\\subset \\Omega$.\n\n Let $s_1$ and $s_2$ be the generalised interpolants satisfying\n\\begin{eqnarray*}\n\\lambda_g^i(s_1)& := &\\langle\\nabla s_1(q_i), g(q_i)\\rangle_{\\mathbb{R}^d} = -p(q_i),\\qquad i=1,\\ldots, M,\\\\\n\\lambda_g^i(s_2)& := &\\langle\\nabla s_1(q_i), g(q_i)\\rangle_{\\mathbb{R}^d} = -\\overline{c}, \\qquad i=1,\\ldots, M,\\\\\n\\lambda^{i,0}(s_2)& := & s_2(q_i) = \\xi_T(q_i), \\qquad i=M+1,\\ldots, M+N,\n\\end{eqnarray*}\nand let the fill distance of the set of points $\\mathbf{q}$ in\n$\\Omega$\n\nand $\\tilde{\\mathbf{q}}$ in $\\Gamma$ be $h_{\\mathbf{q}}$ and $h_{\\mathbf{\\tilde{q}}}$ respectively. Then for $h_{\\mathbf{q}}, h_{\\mathbf{\\tilde{q}}}$ sufficiently small, the following estimates hold:\n\\begin{eqnarray}\n|| \\langle\\nabla s_1, g\\rangle_{\\mathbb{R}^d} - \\langle\\nabla V_g,g\\rangle_{\\mathbb{R}^d}  ||_{L^\\infty(\\Omega)} & \\le & Ch_{\\mathbf{q}}^{k-\\frac{1}{2}}||V_g||_{W_2^{\\tau_2}(\\Omega)},\\\\\n||\\langle\\nabla s_2, g\\rangle_{\\mathbb{R}^d} - \\langle\\nabla T_g,g\\rangle_{\\mathbb{R}^d} ||_{L^\\infty(\\Omega)} & \\le & Ch_{\\mathbf{q}}^{k-\\frac{1}{2}}||T_g||_{W_2^{\\tau_2}(\\Omega)},\\\\\n||s_2 - T_g||_{L^\\infty(\\Gamma)} & \\le & Ch_{\\tilde{\\mathbf{q}}}^{k+\\frac{1}{2}}||T_g||_{W_2^{\\tau_2}(\\Omega)}.\t\\label{eqn:ests2gamma}\n\\end{eqnarray}\n\\end{theorem}\n\n\n\n\n\n\\section{The Algorithm}\t\t\t\\label{sec:algorithm}\n\nHere we present the algorithm for which the estimate given in Theorem \\ref{thm:mainresult} holds. The algorithm is actually split into two parts. The first part computes $f_{\\mathbf{z},\\lambda}$ as an approximation to $f^*$ (Algorithm \\ref{alg:approxf}), and the second part computes  $\\hat{V}$ or $\\hat{T}$ as an approximation to the Lyapunov functions $V$ or $T$ respectively given in Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} (Algorithm \\ref{alg:approxV} or \\ref{alg:approxT}). As discussed in \\S\\ref{sec:SobolevspaceRKHS}, we will use two RKHS spaces $\\mathcal{H}_{K^{1}}$ and $\\mathcal{H}_{K^{2}}$ for the two parts of the algorithm, corresponding to the Wendland function kernels $K^{1}$ and $K^{2}$ with smoothness indices $k_1$ and $k_2$ respectively. We recall that the smoothness indices are chosen such that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil\\tau_1\\rceil = \\nu_1$, and $k_2 = k_1 - (d+3)/2$ if $d$ is odd, or $k_2 = k_1 - (d+4)/2$ if $d$ is even.\n\n\n\n\nRecall that our sampled data values $\\mathbf{z}:=(x_i, y_i)_{i=1}^m \\in (X\\times \\mathbb{R}^d)^m$ take the form  $y_i = f^*(x_i) + \\eta_{x_i}$, with $\\eta_x \\in \\mathbb{R}^d$ a random variable drawn from a probability distribution with zero mean  and variance $\\sigma_x^2$.\n\nOur approximation scheme for $f^*$ employs a regularised least squares algorithm (see e.g. \\cite{EvgPonPog00} and its references) to approximate each component $f^{*,k}$, $k=1,\\ldots,d$. We also introduce a weighting $\\mathbf{w}=\\{w_{x_i}\\}_{i=1}^m$ corresponding to the Voronoi tessellation associated with the points $\\{x_i\\}_{i=1}^m$ \\cite{Vor08}.\n\n\\begin{definition}[Voronoi tessellation]\t\t\t\\label{def:Voronoi}\nLet $X\\subset\\mathbb{R}^d$ be compact. For a set of pairwise distinct points $\\mathbf{x} := \\{x_i\\}_{i=1}^m \\in X^m$, the Voronoi tessellation is the collection of pairwise disjoint open sets $\\mathcal{V}_i(\\mathbf{x})$, $i=1,\\ldots,m$ defined by\n\n", "itemtype": "equation", "pos": 28343, "prevtext": "\nwhere $(\\delta_{q_j} \\circ L)^y$ is the linear function applied to one argument of the kernel. The coefficient vector $\\alpha$ is the solution of $A\\alpha = \\beta = (\\beta_i)$ with the interpolation matrix $A \\in\\mathbb{R}^{M\\times M}$  given by\n\n", "index": 29, "text": "\\begin{equation*}\n(A)_{ij} = (\\delta_{q_i}\\circ L)^x(\\delta_{q_j}\\circ L)^yK(x,y).\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"(A)_{ij}=(\\delta_{q_{i}}\\circ L)^{x}(\\delta_{q_{j}}\\circ L)^{y}K(x,y).\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03b4</mi><msub><mi>q</mi><mi>i</mi></msub></msub><mo>\u2218</mo><mi>L</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>x</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03b4</mi><msub><mi>q</mi><mi>j</mi></msub></msub><mo>\u2218</mo><mi>L</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>y</mi></msup><mo>\u2062</mo><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\\end{definition}\nThe weighting $\\mathbf{w}=\\{w_{x_i}\\}_{i=1}^m$ is then defined by $w_{x_i} = \\rho(\\mathcal{V}_i(\\mathbf{x}))$, where $\\rho$ is the strictly positive Borel measure from \\S\\ref{sec:RKHS}.\n\n\\begin{algorithm}\t\t\\label{alg:approxf}\nFix a regularisation parameter $\\lambda >0 $, and define $D_w \\in\\mathbb{R}^{m\\times m}$ as the diagonal matrix with diagonal elements $w_{x_i}$, $i=1,\\ldots,m$. The approximation $f_{\\mathbf{z},\\lambda}$ for $f^*$ is constructed component-wise. That is, for each $k = 1,\\ldots,d$, we approximate the $k$-th component $f^{*,k}$ by $f^k_{\\mathbf{z},\\lambda}\\in\\mathcal{H}_{K^1}$, defined by\n\n\n\n\n\n\n\n\n $f_{\\mathbf{z},\\lambda}^k=\\sum_{i=1}^m a_i K^1_{x_i}$, where the coefficients $a:=\\{a_i\\}_{i=1}^m$ may be calculated as the solution to the matrix equation\n\n", "itemtype": "equation", "pos": 33807, "prevtext": "\n\\end{definition}\n\\begin{remark}\t\t\\label{rem:sgenint}\nAccording to the above definition, we have $Ls(q_i)=\\beta_i$. In addition, it can be shown that the generalised interpolant above is the unique norm-minimal  interpolant in $\\mathcal{H}_K$, see \\cite{Gie07:a,GieWen07}. The matrix $A$ is guaranteed to be invertible due to our  choice of the Wendland function kernel $K$ \\cite[Section 3.2.2]{Gie07:a}, and since $\\mathbf{q}$ does not contain any singular points.\n\\end{remark}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe conclude this section by citing  the following theorem from \\cite{GieWen07}, which provides convergence estimates for approximating  Lyapunov functions $V_g$ (resp. $T_g$) with the generalised interpolants $s_1$ (resp. $s_2$) as above, for a known dynamical system $\\dot{x} = g(x)$.\n\\begin{theorem}\t\t\t\t\\label{thm:GieWen}\nLet $\\nu_2:= \\lceil \\tau_2 \\rceil$ with $ \\tau_2 = k_2 +  (d+1)/2$, where $k_2$ is the smoothness index of the compactly supported Wendland function. Let $k_2>1/2$ if $d$ is odd or $k_2>1$ if $d$ is even. Consider the dynamical system defined by the ordinary differential equation $\\dot{x} = g(x)$, where $g\\in C^{\\nu_2}(\\mathbb{R}^d,\\mathbb{R}^d)$. Let $\\overline{x}\\in\\mathbb{R}^d$ be an equilibrium such that the real parts of all eigenvalues of $Dg(\\overline{x})$ are negative, and suppose $g$ is bounded in $A(\\overline{x})$.\n\nLet $\\Gamma$ be a non-characteristic hypersurface as in Definition \\ref{def:noncharhyp}, with $h\\in C^{\\nu_2}(\\mathbb{R}^d,\\mathbb{R})$ and  $\\xi_T\\in C^{\\nu_2}(\\Gamma,\\mathbb{R})$. Let $V_g\\in W^{\\tau_2}_2(A(\\overline{x}),\\mathbb{R})$, $T_g\\in W_2^{\\tau_2}(A(\\overline{x}) \\backslash \\{\\overline{x}\\},\\mathbb{R})$ be the Lyapunov functions of Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} for the system  $\\dot{x} = g(x)$, with $T_g(x)=\\xi_T(x)$ for $x\\in\\Gamma$.\n\n Given pairwise distinct sets of points $\\mathbf{q}:=(q_i)_{i=1}^M$ in $A(\\overline{x})$ (not containing $\\overline{x}$) and $\\tilde{\\mathbf{q}}:=(q_i)_{i=M+1}^{M+N}$ in $\\Gamma$,\n and let $\\Omega\\subset A(\\overline{x})$ be a bounded domain with Lipschitz boundary, with $\\mathbf{q}\\subset \\Omega$.\n\n Let $s_1$ and $s_2$ be the generalised interpolants satisfying\n\\begin{eqnarray*}\n\\lambda_g^i(s_1)& := &\\langle\\nabla s_1(q_i), g(q_i)\\rangle_{\\mathbb{R}^d} = -p(q_i),\\qquad i=1,\\ldots, M,\\\\\n\\lambda_g^i(s_2)& := &\\langle\\nabla s_1(q_i), g(q_i)\\rangle_{\\mathbb{R}^d} = -\\overline{c}, \\qquad i=1,\\ldots, M,\\\\\n\\lambda^{i,0}(s_2)& := & s_2(q_i) = \\xi_T(q_i), \\qquad i=M+1,\\ldots, M+N,\n\\end{eqnarray*}\nand let the fill distance of the set of points $\\mathbf{q}$ in\n$\\Omega$\n\nand $\\tilde{\\mathbf{q}}$ in $\\Gamma$ be $h_{\\mathbf{q}}$ and $h_{\\mathbf{\\tilde{q}}}$ respectively. Then for $h_{\\mathbf{q}}, h_{\\mathbf{\\tilde{q}}}$ sufficiently small, the following estimates hold:\n\\begin{eqnarray}\n|| \\langle\\nabla s_1, g\\rangle_{\\mathbb{R}^d} - \\langle\\nabla V_g,g\\rangle_{\\mathbb{R}^d}  ||_{L^\\infty(\\Omega)} & \\le & Ch_{\\mathbf{q}}^{k-\\frac{1}{2}}||V_g||_{W_2^{\\tau_2}(\\Omega)},\\\\\n||\\langle\\nabla s_2, g\\rangle_{\\mathbb{R}^d} - \\langle\\nabla T_g,g\\rangle_{\\mathbb{R}^d} ||_{L^\\infty(\\Omega)} & \\le & Ch_{\\mathbf{q}}^{k-\\frac{1}{2}}||T_g||_{W_2^{\\tau_2}(\\Omega)},\\\\\n||s_2 - T_g||_{L^\\infty(\\Gamma)} & \\le & Ch_{\\tilde{\\mathbf{q}}}^{k+\\frac{1}{2}}||T_g||_{W_2^{\\tau_2}(\\Omega)}.\t\\label{eqn:ests2gamma}\n\\end{eqnarray}\n\\end{theorem}\n\n\n\n\n\n\\section{The Algorithm}\t\t\t\\label{sec:algorithm}\n\nHere we present the algorithm for which the estimate given in Theorem \\ref{thm:mainresult} holds. The algorithm is actually split into two parts. The first part computes $f_{\\mathbf{z},\\lambda}$ as an approximation to $f^*$ (Algorithm \\ref{alg:approxf}), and the second part computes  $\\hat{V}$ or $\\hat{T}$ as an approximation to the Lyapunov functions $V$ or $T$ respectively given in Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse} (Algorithm \\ref{alg:approxV} or \\ref{alg:approxT}). As discussed in \\S\\ref{sec:SobolevspaceRKHS}, we will use two RKHS spaces $\\mathcal{H}_{K^{1}}$ and $\\mathcal{H}_{K^{2}}$ for the two parts of the algorithm, corresponding to the Wendland function kernels $K^{1}$ and $K^{2}$ with smoothness indices $k_1$ and $k_2$ respectively. We recall that the smoothness indices are chosen such that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil\\tau_1\\rceil = \\nu_1$, and $k_2 = k_1 - (d+3)/2$ if $d$ is odd, or $k_2 = k_1 - (d+4)/2$ if $d$ is even.\n\n\n\n\nRecall that our sampled data values $\\mathbf{z}:=(x_i, y_i)_{i=1}^m \\in (X\\times \\mathbb{R}^d)^m$ take the form  $y_i = f^*(x_i) + \\eta_{x_i}$, with $\\eta_x \\in \\mathbb{R}^d$ a random variable drawn from a probability distribution with zero mean  and variance $\\sigma_x^2$.\n\nOur approximation scheme for $f^*$ employs a regularised least squares algorithm (see e.g. \\cite{EvgPonPog00} and its references) to approximate each component $f^{*,k}$, $k=1,\\ldots,d$. We also introduce a weighting $\\mathbf{w}=\\{w_{x_i}\\}_{i=1}^m$ corresponding to the Voronoi tessellation associated with the points $\\{x_i\\}_{i=1}^m$ \\cite{Vor08}.\n\n\\begin{definition}[Voronoi tessellation]\t\t\t\\label{def:Voronoi}\nLet $X\\subset\\mathbb{R}^d$ be compact. For a set of pairwise distinct points $\\mathbf{x} := \\{x_i\\}_{i=1}^m \\in X^m$, the Voronoi tessellation is the collection of pairwise disjoint open sets $\\mathcal{V}_i(\\mathbf{x})$, $i=1,\\ldots,m$ defined by\n\n", "index": 31, "text": "\\begin{equation*}\n\\mathcal{V}_i(\\mathbf{x}) = \\{y\\in X \\, | \\, ||x_i - y||_{\\mathbb{R}^d} < ||x_j - y||_{\\mathbb{R}^d},\\, \\text{if } i\\ne j\\}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{V}_{i}(\\mathbf{x})=\\{y\\in X\\,|\\,||x_{i}-y||_{\\mathbb{R}^{d}}&lt;||x_{j}-%&#10;y||_{\\mathbb{R}^{d}},\\,\\text{if }i\\neq j\\}.\" display=\"block\"><mrow><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>y</mi><mo>\u2208</mo><mpadded width=\"+1.7pt\"><mi>X</mi></mpadded></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">|</mo><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>y</mi></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>&lt;</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>x</mi><mi>j</mi></msub><mo>-</mo><mi>y</mi></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub></mrow><mo rspace=\"4.2pt\">,</mo><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>i</mi></mrow><mo>\u2260</mo><mi>j</mi></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nHere  $y^k = (y_i^k)_{i=1}^m$ where $y_i^k$ is simply the $k$-th component of $y_i\\in\\mathbb{R}^d$, and $A_{\\mathbf{x}} \\in \\mathbb{R}^{m\\times m}$ is a symmetric matrix defined by $(A_{\\mathbf{x}} )_{i,j} = K^1(x_i,x_j)$.\n \\end{algorithm}\n\nWe note here that due to our choice of RKHS the matrix $A_\\mathbf{x}$ is positive definite \\cite[Proposition 3.3]{GieWen07}, and therefore the matrix $(A_{\\mathbf{x}}D_w A_{\\mathbf{x}} + \\lambda A_{\\mathbf{x}})$ is invertible, as it is the sum of two positive definite matrices. The error in our approximation of $f^*$ by $f_{\\mathbf{z},\\lambda}$ is studied in \\S\\ref{sec:errorf}. We will show that this error may be bounded in the supremum norm on the domain $X$, depending on the density of the data in $X$ and the choice of regularisation parameter $\\lambda$.\n\nOnce we have our approximation $f_{\\mathbf{z},\\lambda}$, then we construct our Lyapunov function approximation with  the generalised interpolant as in  Theorem \\ref{thm:GieWen}, where we set $g = f_{\\mathbf{z},\\lambda}$. \n\nTherefore we have the following Algorithm  \\ref{alg:approxV} for $\\hat{V}$, or Algorithm \\ref{alg:approxT} for $\\hat{T}$. These algorithms involve sampling our approximation $f_{\\mathbf{z},\\lambda}$ at a discrete set of points.\n\n\\begin{subtheorem}{algorithm}\n\\begin{algorithm}[Approximation of $V$]\t\t\\label{alg:approxV}\nFirst run Algorithm \\ref{alg:approxf} on the sampled data set $(x_i,y_i)_{i=1}^m$ to compute $f_{\\mathbf{z},\\lambda}\\in(\\mathcal{H}_{K^1})^d$.\n\nDefine a set of pairwise distinct points $\\mathbf{q}:= (q_i)_{i=1}^M$, with $f_{\\mathbf{z},\\lambda}(q_i)\\ne 0$ for all $i=1,\\ldots,M$. The approximation $\\hat{V}\\in\\mathcal{H}_{K^2}$ for the Lyapunov function $V$  (see Theorem \\ref{thm:VLyapunovconverse}) is\n\n\n\n\n\n\n\ngiven by $\\hat{V}= \\sum_{i=1}^M b_i \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y} K^2(\\cdot, y)$, where $\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}$ is the linear functional $\\lambda_{f_{\\mathbf{z},\\lambda}}^i$ applied to one argument of the kernel. The coefficients $b:=\\{b_i\\}_{i=1}^M$ are given by\n\n", "itemtype": "equation", "pos": 34764, "prevtext": "\n\\end{definition}\nThe weighting $\\mathbf{w}=\\{w_{x_i}\\}_{i=1}^m$ is then defined by $w_{x_i} = \\rho(\\mathcal{V}_i(\\mathbf{x}))$, where $\\rho$ is the strictly positive Borel measure from \\S\\ref{sec:RKHS}.\n\n\\begin{algorithm}\t\t\\label{alg:approxf}\nFix a regularisation parameter $\\lambda >0 $, and define $D_w \\in\\mathbb{R}^{m\\times m}$ as the diagonal matrix with diagonal elements $w_{x_i}$, $i=1,\\ldots,m$. The approximation $f_{\\mathbf{z},\\lambda}$ for $f^*$ is constructed component-wise. That is, for each $k = 1,\\ldots,d$, we approximate the $k$-th component $f^{*,k}$ by $f^k_{\\mathbf{z},\\lambda}\\in\\mathcal{H}_{K^1}$, defined by\n\n\n\n\n\n\n\n\n $f_{\\mathbf{z},\\lambda}^k=\\sum_{i=1}^m a_i K^1_{x_i}$, where the coefficients $a:=\\{a_i\\}_{i=1}^m$ may be calculated as the solution to the matrix equation\n\n", "index": 33, "text": "\\begin{equation*}\n (A_{\\mathbf{x}}D_w A_{\\mathbf{x}} + \\lambda A_{\\mathbf{x}})a = A_{\\mathbf{x}} D_w y^k.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"(A_{\\mathbf{x}}D_{w}A_{\\mathbf{x}}+\\lambda A_{\\mathbf{x}})a=A_{\\mathbf{x}}D_{w%&#10;}y^{k}.\" display=\"block\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>A</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msub><mi>A</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>A</mi><mi>\ud835\udc31</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>a</mi></mrow><mo>=</mo><mrow><msub><mi>A</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msup><mi>y</mi><mi>k</mi></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nHere $B_\\mathbf{q} \\in \\mathbb{R}^{M\\times M}$ is a symmetric matrix defined by $(B_\\mathbf{q})_{i,j} =\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,x}\\lambda_{f_{\\mathbf{z},\\lambda}}^{j,y} K^2(x,y)$ and $p = (p(q_i))_{i=1}^M$.\n\\end{algorithm}\n\nAs before, the choice of RKHS guarantees that the matrix $B_\\mathbf{q}$ will be positive definite, provided that $f_{\\mathbf{z},\\lambda}(q_i) \\ne 0$ for all $i=1,\\ldots, M$.\n\nTo approximate $T$, we  assume that a non-characteristic hypersurface for $f^*$ has been defined as $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ according to Definition \\ref{def:noncharhyp}, for which $T(x) = \\xi_T(x)$ on $\\Gamma$, $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$.\n\n\n\\begin{algorithm}[Approximation of $T$]\t\t\\label{alg:approxT}\nFirst run Algorithm \\ref{alg:approxf} on the sampled data set $(x_i,y_i)_{i=1}^m$ to compute $f_{\\mathbf{z},\\lambda}\\in(\\mathcal{H}_{K^1})^d$.\n\nDefine a set of pairwise distinct points $\\mathbf{q}:= (q_i)_{i=1}^{M+N}$, with $f_{\\mathbf{z},\\lambda}(q_i)\\ne 0$ for all $i=1,\\ldots,M$, and $q_i\\in\\Gamma$ for $i=M+1,\\ldots,M+N$.\n\nThe approximation $\\hat{T}\\in\\mathcal{H}_{K^2}$ for the Lyapunov function $T$ (see Theorem \\ref{thm:TLyapunovconverse}) is given by $\\hat{T} = \\sum_{i=1}^M c_i\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}K^2(\\cdot,y) + \\sum_{i=M+1}^{M+N} c_i K^2(\\cdot,q_i)$, where the coefficients $c:=\\{c_i\\}_{i=1}^{M+N}$ are computed as the solution to the matrix equation\n\n", "itemtype": "equation", "pos": 36934, "prevtext": "\nHere  $y^k = (y_i^k)_{i=1}^m$ where $y_i^k$ is simply the $k$-th component of $y_i\\in\\mathbb{R}^d$, and $A_{\\mathbf{x}} \\in \\mathbb{R}^{m\\times m}$ is a symmetric matrix defined by $(A_{\\mathbf{x}} )_{i,j} = K^1(x_i,x_j)$.\n \\end{algorithm}\n\nWe note here that due to our choice of RKHS the matrix $A_\\mathbf{x}$ is positive definite \\cite[Proposition 3.3]{GieWen07}, and therefore the matrix $(A_{\\mathbf{x}}D_w A_{\\mathbf{x}} + \\lambda A_{\\mathbf{x}})$ is invertible, as it is the sum of two positive definite matrices. The error in our approximation of $f^*$ by $f_{\\mathbf{z},\\lambda}$ is studied in \\S\\ref{sec:errorf}. We will show that this error may be bounded in the supremum norm on the domain $X$, depending on the density of the data in $X$ and the choice of regularisation parameter $\\lambda$.\n\nOnce we have our approximation $f_{\\mathbf{z},\\lambda}$, then we construct our Lyapunov function approximation with  the generalised interpolant as in  Theorem \\ref{thm:GieWen}, where we set $g = f_{\\mathbf{z},\\lambda}$. \n\nTherefore we have the following Algorithm  \\ref{alg:approxV} for $\\hat{V}$, or Algorithm \\ref{alg:approxT} for $\\hat{T}$. These algorithms involve sampling our approximation $f_{\\mathbf{z},\\lambda}$ at a discrete set of points.\n\n\\begin{subtheorem}{algorithm}\n\\begin{algorithm}[Approximation of $V$]\t\t\\label{alg:approxV}\nFirst run Algorithm \\ref{alg:approxf} on the sampled data set $(x_i,y_i)_{i=1}^m$ to compute $f_{\\mathbf{z},\\lambda}\\in(\\mathcal{H}_{K^1})^d$.\n\nDefine a set of pairwise distinct points $\\mathbf{q}:= (q_i)_{i=1}^M$, with $f_{\\mathbf{z},\\lambda}(q_i)\\ne 0$ for all $i=1,\\ldots,M$. The approximation $\\hat{V}\\in\\mathcal{H}_{K^2}$ for the Lyapunov function $V$  (see Theorem \\ref{thm:VLyapunovconverse}) is\n\n\n\n\n\n\n\ngiven by $\\hat{V}= \\sum_{i=1}^M b_i \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y} K^2(\\cdot, y)$, where $\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}$ is the linear functional $\\lambda_{f_{\\mathbf{z},\\lambda}}^i$ applied to one argument of the kernel. The coefficients $b:=\\{b_i\\}_{i=1}^M$ are given by\n\n", "index": 35, "text": "\\begin{equation*}\nB_\\mathbf{q} b = - p.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"B_{\\mathbf{q}}b=-p.\" display=\"block\"><mrow><mrow><mrow><msub><mi>B</mi><mi>\ud835\udc2a</mi></msub><mo>\u2062</mo><mi>b</mi></mrow><mo>=</mo><mrow><mo>-</mo><mi>p</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nand the submatrices $C \\in\\mathbb{R}^{M\\times M}$, $D\\in \\mathbb{R}^{M\\times N}$ and $C^0\\in\\mathbb{R}^{N\\times N}$ have elements defined by $(C)_{i,j} = \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,x}\\lambda_{f_{\\mathbf{z},\\lambda}}^{j,y}K^2(x,y)$, $(D)_{i,j-N} = \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}K^2(q_j,y)$ and $(C^0)_{i-N,j-N} = K^2(q_i,q_j)$. The vector $\\beta$ is given by $\\beta_i = -\\overline{c}$, $i=1,\\ldots,M$ and $\\beta_i = \\xi_T(q_i)$, $i=M+1,\\ldots,M+N$.\n\\end{algorithm}\n\\end{subtheorem}\n\n It may again be shown that the matrix $C_{\\mathbf{q},\\tilde{\\mathbf{q}}}$ will be positive definite, providing that $f_{\\mathbf{z},\\lambda}(q_i) \\ne 0$ for all $i=1,\\ldots,M$, for details see \\cite[Section 3.2.2]{Gie07:a}.\n\n Our error in the approximations $\\hat{V}$ and $\\hat{T}$ will depend primarily on the error induced by Algorithm \\ref{alg:approxf}, which in turn depends on the density of the data, as well as the regularisation parameter. In addition, there will be an error due to the discrete sampling of $f_{\\mathbf{z},\\lambda}$ in Algorithms \\ref{alg:approxV} and \\ref{alg:approxT}. This error will depend on the density of the sample points $\\mathbf{q}$ (chosen by the user), which in principle can be entirely independent of the original set of points $\\mathbf{x}$ provided by the data. The overall error is the subject of \\S\\ref{sec:proofofmainthm}, which will prove the estimate given in Theorem \\ref{thm:mainresult}.\n\n\n \n \n  \n\n\n \\section{Error estimate for $ ||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$}\t\t\\label{sec:errorf}\n\nIn this section we estimate the error $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$ for each $k=1,\\ldots,d$.\n\nWe have sampled data of the form $(x_i, y_i)$ in $X\\times \\mathbb{R}^d$, $i=1,\\dots,m$, with $y_i = f^*(x_i) + \\eta_{x_i}$. We assume that the one-dimensional random variables $\\eta_{x_i}^k \\in \\mathbb{R}^d$, where $i=1,\\dots,m$ and $k=1,\\dots,d$, are independent random variables drawn from a probability distribution with zero mean and variance $(\\sigma_{x_i}^k)^2$ bounded by $\\sigma^2$.\n\nIn order to ease notation, and since each $f^k_{\\mathbf{z},\\lambda}$ is calculated independently for each $k$,  we shall henceforth drop the superscript $k$ and consider the data to be of the form $\\mathbf{z}:=(x_i, y_i)_{i=1}^m \\in (X\\times \\mathbb{R})^m$.\nNote that in this section we shall only be working with the RKHS $\\mathcal{H}_{K^1}$.\n\n\n\nThe following operator definition will enable convenient function representations (c.f. \\cite{SmaZho04,SmaZho05}).\n\n\\begin{definition}[Sampling Operator]\nGiven a set $\\mathbf{x}:=(x_i)_{i=1}^m$ of pairwise distinct points in $\\mathbb{R}^d$, the sampling operator $S_{\\mathbf{x}}:\\mathcal{H}_{K^1}\\rightarrow \\mathbb{R}^m$ is defined as\n\n", "itemtype": "equation", "pos": 38446, "prevtext": "\nHere $B_\\mathbf{q} \\in \\mathbb{R}^{M\\times M}$ is a symmetric matrix defined by $(B_\\mathbf{q})_{i,j} =\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,x}\\lambda_{f_{\\mathbf{z},\\lambda}}^{j,y} K^2(x,y)$ and $p = (p(q_i))_{i=1}^M$.\n\\end{algorithm}\n\nAs before, the choice of RKHS guarantees that the matrix $B_\\mathbf{q}$ will be positive definite, provided that $f_{\\mathbf{z},\\lambda}(q_i) \\ne 0$ for all $i=1,\\ldots, M$.\n\nTo approximate $T$, we  assume that a non-characteristic hypersurface for $f^*$ has been defined as $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ according to Definition \\ref{def:noncharhyp}, for which $T(x) = \\xi_T(x)$ on $\\Gamma$, $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$.\n\n\n\\begin{algorithm}[Approximation of $T$]\t\t\\label{alg:approxT}\nFirst run Algorithm \\ref{alg:approxf} on the sampled data set $(x_i,y_i)_{i=1}^m$ to compute $f_{\\mathbf{z},\\lambda}\\in(\\mathcal{H}_{K^1})^d$.\n\nDefine a set of pairwise distinct points $\\mathbf{q}:= (q_i)_{i=1}^{M+N}$, with $f_{\\mathbf{z},\\lambda}(q_i)\\ne 0$ for all $i=1,\\ldots,M$, and $q_i\\in\\Gamma$ for $i=M+1,\\ldots,M+N$.\n\nThe approximation $\\hat{T}\\in\\mathcal{H}_{K^2}$ for the Lyapunov function $T$ (see Theorem \\ref{thm:TLyapunovconverse}) is given by $\\hat{T} = \\sum_{i=1}^M c_i\\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}K^2(\\cdot,y) + \\sum_{i=M+1}^{M+N} c_i K^2(\\cdot,q_i)$, where the coefficients $c:=\\{c_i\\}_{i=1}^{M+N}$ are computed as the solution to the matrix equation\n\n", "index": 37, "text": "\\begin{equation*}\nC_{\\mathbf{q},\\tilde{\\mathbf{q}}}c = \\beta,\\quad\\text{where }C_{\\mathbf{q},\\tilde{\\mathbf{q}}}:=\n\\left(\\begin{array}{cc}\nC & D\\\\\nD^T & C^0\n\\end{array}\\right) \\in \\mathbb{R}^{(M+N)\\times(M+N)},\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"C_{\\mathbf{q},\\tilde{\\mathbf{q}}}c=\\beta,\\quad\\text{where }C_{\\mathbf{q},%&#10;\\tilde{\\mathbf{q}}}:=\\left(\\begin{array}[]{cc}C&amp;D\\\\&#10;D^{T}&amp;C^{0}\\end{array}\\right)\\in\\mathbb{R}^{(M+N)\\times(M+N)},\" display=\"block\"><mrow><mrow><mrow><mrow><msub><mi>C</mi><mrow><mi>\ud835\udc2a</mi><mo>,</mo><mover accent=\"true\"><mi>\ud835\udc2a</mi><mo stretchy=\"false\">~</mo></mover></mrow></msub><mo>\u2062</mo><mi>c</mi></mrow><mo>=</mo><mi>\u03b2</mi></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mtext>where\u00a0</mtext><mo>\u2062</mo><msub><mi>C</mi><mrow><mi>\ud835\udc2a</mi><mo>,</mo><mover accent=\"true\"><mi>\ud835\udc2a</mi><mo stretchy=\"false\">~</mo></mover></mrow></msub></mrow><mo>:=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>C</mi></mtd><mtd columnalign=\"center\"><mi>D</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>D</mi><mi>T</mi></msup></mtd><mtd columnalign=\"center\"><msup><mi>C</mi><mn>0</mn></msup></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2208</mo><msup><mi>\u211d</mi><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u00d7</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\\end{definition}\nThe adjoint operator $S_{\\mathbf{x}}^*$ can also be derived as follows. Let $c\\in \\mathbb{R}^m$, then we have\n\n", "itemtype": "equation", "pos": 41419, "prevtext": "\nand the submatrices $C \\in\\mathbb{R}^{M\\times M}$, $D\\in \\mathbb{R}^{M\\times N}$ and $C^0\\in\\mathbb{R}^{N\\times N}$ have elements defined by $(C)_{i,j} = \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,x}\\lambda_{f_{\\mathbf{z},\\lambda}}^{j,y}K^2(x,y)$, $(D)_{i,j-N} = \\lambda_{f_{\\mathbf{z},\\lambda}}^{i,y}K^2(q_j,y)$ and $(C^0)_{i-N,j-N} = K^2(q_i,q_j)$. The vector $\\beta$ is given by $\\beta_i = -\\overline{c}$, $i=1,\\ldots,M$ and $\\beta_i = \\xi_T(q_i)$, $i=M+1,\\ldots,M+N$.\n\\end{algorithm}\n\\end{subtheorem}\n\n It may again be shown that the matrix $C_{\\mathbf{q},\\tilde{\\mathbf{q}}}$ will be positive definite, providing that $f_{\\mathbf{z},\\lambda}(q_i) \\ne 0$ for all $i=1,\\ldots,M$, for details see \\cite[Section 3.2.2]{Gie07:a}.\n\n Our error in the approximations $\\hat{V}$ and $\\hat{T}$ will depend primarily on the error induced by Algorithm \\ref{alg:approxf}, which in turn depends on the density of the data, as well as the regularisation parameter. In addition, there will be an error due to the discrete sampling of $f_{\\mathbf{z},\\lambda}$ in Algorithms \\ref{alg:approxV} and \\ref{alg:approxT}. This error will depend on the density of the sample points $\\mathbf{q}$ (chosen by the user), which in principle can be entirely independent of the original set of points $\\mathbf{x}$ provided by the data. The overall error is the subject of \\S\\ref{sec:proofofmainthm}, which will prove the estimate given in Theorem \\ref{thm:mainresult}.\n\n\n \n \n  \n\n\n \\section{Error estimate for $ ||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$}\t\t\\label{sec:errorf}\n\nIn this section we estimate the error $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$ for each $k=1,\\ldots,d$.\n\nWe have sampled data of the form $(x_i, y_i)$ in $X\\times \\mathbb{R}^d$, $i=1,\\dots,m$, with $y_i = f^*(x_i) + \\eta_{x_i}$. We assume that the one-dimensional random variables $\\eta_{x_i}^k \\in \\mathbb{R}^d$, where $i=1,\\dots,m$ and $k=1,\\dots,d$, are independent random variables drawn from a probability distribution with zero mean and variance $(\\sigma_{x_i}^k)^2$ bounded by $\\sigma^2$.\n\nIn order to ease notation, and since each $f^k_{\\mathbf{z},\\lambda}$ is calculated independently for each $k$,  we shall henceforth drop the superscript $k$ and consider the data to be of the form $\\mathbf{z}:=(x_i, y_i)_{i=1}^m \\in (X\\times \\mathbb{R})^m$.\nNote that in this section we shall only be working with the RKHS $\\mathcal{H}_{K^1}$.\n\n\n\nThe following operator definition will enable convenient function representations (c.f. \\cite{SmaZho04,SmaZho05}).\n\n\\begin{definition}[Sampling Operator]\nGiven a set $\\mathbf{x}:=(x_i)_{i=1}^m$ of pairwise distinct points in $\\mathbb{R}^d$, the sampling operator $S_{\\mathbf{x}}:\\mathcal{H}_{K^1}\\rightarrow \\mathbb{R}^m$ is defined as\n\n", "index": 39, "text": "\\begin{equation*}\nS_{\\mathbf{x}}(f) = (f(x_i))_{i=1}^m.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"S_{\\mathbf{x}}(f)=(f(x_{i}))_{i=1}^{m}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>S</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msubsup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nThe final equality follows from the reproducing property \\eqref{eq:reproducing}. So then $S^*_{\\mathbf{x}} c = \\sum_{i=1}^m c_iK^1_{x_i}$ for all $c\\in \\mathbb{R}^m$.\n\nThe following Lemma shows that the function $f_{\\mathbf{z},\\lambda}$ calculated in Algorithm \\ref{alg:approxf} is the minimiser of a regularised cost function. We omit the proof, which is similar to that contained in \\cite[Theorem 1]{SmaZho05}, except for the introduction of the weights $w$. \n\n\\begin{lemma}\t\t\\label{lem:fzlambda}\nLet\n\n", "itemtype": "equation", "pos": 41618, "prevtext": "\n\\end{definition}\nThe adjoint operator $S_{\\mathbf{x}}^*$ can also be derived as follows. Let $c\\in \\mathbb{R}^m$, then we have\n\n", "index": 41, "text": "\\begin{equation*}\n\\left\\langle f,S^*_{\\mathbf{x}}c\\right\\rangle_{K^1} = \\left\\langle S_{\\mathbf{x}} f,c\\right\\rangle_{\\mathbb{R}^m} = \\sum_{i=1}^m c_if(x_i) = \\left\\langle f, \\sum_{i=1}^m c_i K^1_{x_i}\\right\\rangle_{K^1},\\quad \\forall f\\in\\mathcal{H}_{K^1}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\left\\langle f,S^{*}_{\\mathbf{x}}c\\right\\rangle_{K^{1}}=\\left\\langle S_{%&#10;\\mathbf{x}}f,c\\right\\rangle_{\\mathbb{R}^{m}}=\\sum_{i=1}^{m}c_{i}f(x_{i})=\\left%&#10;\\langle f,\\sum_{i=1}^{m}c_{i}K^{1}_{x_{i}}\\right\\rangle_{K^{1}},\\quad\\forall f%&#10;\\in\\mathcal{H}_{K^{1}}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo>\u27e8</mo><mi>f</mi><mo>,</mo><mrow><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><mi>c</mi></mrow><mo>\u27e9</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub><mo>=</mo><msub><mrow><mo>\u27e8</mo><mrow><msub><mi>S</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><mi>f</mi></mrow><mo>,</mo><mi>c</mi><mo>\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><msub><mrow><mo>\u27e8</mo><mi>f</mi><mo>,</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>\u2062</mo><msubsup><mi>K</mi><msub><mi>x</mi><mi>i</mi></msub><mn>1</mn></msubsup></mrow></mrow><mo>\u27e9</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mi>f</mi></mrow><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><msup><mi>K</mi><mn>1</mn></msup></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\nLet $D_w \\in \\mathbb{R}^{m\\times m}$ be the diagonal matrix with entries $\\{w_{x_i}\\}_{i=1}^m$, and let $\\mathbf{y}:=\\{y_i\\}_{i=1}^m$. If $S_{\\mathbf{x}}^* D_w S_{\\mathbf{x}} + \\lambda I$ is invertible, then $f_{\\mathbf{z},\\lambda}$ exists and is given by\n\n", "itemtype": "equation", "pos": 42395, "prevtext": "\nThe final equality follows from the reproducing property \\eqref{eq:reproducing}. So then $S^*_{\\mathbf{x}} c = \\sum_{i=1}^m c_iK^1_{x_i}$ for all $c\\in \\mathbb{R}^m$.\n\nThe following Lemma shows that the function $f_{\\mathbf{z},\\lambda}$ calculated in Algorithm \\ref{alg:approxf} is the minimiser of a regularised cost function. We omit the proof, which is similar to that contained in \\cite[Theorem 1]{SmaZho05}, except for the introduction of the weights $w$. \n\n\\begin{lemma}\t\t\\label{lem:fzlambda}\nLet\n\n", "index": 43, "text": "\\begin{equation}\t\t\t\\label{eq:fzlambda}\nf_{\\mathbf{z},\\lambda}:=\\underset{f\\in\\mathcal{H}_{K^1}}{\\arg\\min}\\left\\{ \\sum_{i=1}^m w_{x_i}(f(x_i)-y_i)^2 + \\lambda||f||^2_{{K^1}}\\right\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"f_{\\mathbf{z},\\lambda}:=\\underset{f\\in\\mathcal{H}_{K^{1}}}{\\arg\\min}\\left\\{%&#10;\\sum_{i=1}^{m}w_{x_{i}}(f(x_{i})-y_{i})^{2}+\\lambda||f||^{2}_{{K^{1}}}\\right\\}.\" display=\"block\"><mrow><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>:=</mo><mrow><munder accentunder=\"true\"><mrow><mi>arg</mi><mo>\u2061</mo><mi>min</mi></mrow><mrow><mi>f</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><msup><mi>K</mi><mn>1</mn></msup></msub></mrow></munder><mo>\u2062</mo><mrow><mo>{</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>w</mi><msub><mi>x</mi><mi>i</mi></msub></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msub><mi>y</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">||</mo><mi>f</mi><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nFurthermore, if $f_{\\mathbf{z},\\lambda}=\\sum_{i=1}^m a_i {K^1}_{x_i}$, then the coefficients $a:=\\{a_i\\}_{i=1}^m$ may be calculated as\n\n", "itemtype": "equation", "pos": 42849, "prevtext": "\n\nLet $D_w \\in \\mathbb{R}^{m\\times m}$ be the diagonal matrix with entries $\\{w_{x_i}\\}_{i=1}^m$, and let $\\mathbf{y}:=\\{y_i\\}_{i=1}^m$. If $S_{\\mathbf{x}}^* D_w S_{\\mathbf{x}} + \\lambda I$ is invertible, then $f_{\\mathbf{z},\\lambda}$ exists and is given by\n\n", "index": 45, "text": "\\begin{equation}\nf_{\\mathbf{z},\\lambda} = J  \\mathbf{y},\\quad J:=(S_{\\mathbf{x}}^* D_w S_{\\mathbf{x}} + \\lambda I)^{-1}S_{\\mathbf{x}}^* D_w.\t\\label{eqn:Ldef}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"f_{\\mathbf{z},\\lambda}=J\\mathbf{y},\\quad J:=(S_{\\mathbf{x}}^{*}D_{w}S_{\\mathbf%&#10;{x}}+\\lambda I)^{-1}S_{\\mathbf{x}}^{*}D_{w}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>=</mo><mrow><mi>J</mi><mo>\u2062</mo><mi>\ud835\udc32</mi></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>J</mi><mo>:=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msub><mi>S</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mi>I</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $A_{\\mathbf{x}} \\in \\mathbb{R}^{m\\times m}$ is the symmetric matrix defined by $(A_{\\mathbf{x}} )_{i,j} = {K^1}(x_i,x_j)$.\n\\end{lemma}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur strategy to prove convergence of the estimate $f_{\\mathbf{z},\\lambda}$ to $f^*$ combines and adapts results contained in \\cite{SmaZho04,SmaZho05,SmaZho07}. The main difference in our case to the standard assumptions in learning theory is that the data $\\mathbf{z} = (x_i,y_i)_{i=1}^m$ is not necessarily generated from an underlying probability distribution. Instead, our data is generated by the underlying dynamical system \\eqref{eqn:dynsys}, and the data sites may be situated arbitrarily. They could potentially be chosen deterministically, or indeed may be generated randomly.   The assumptions made in \\cite{SmaZho05} correspond to this setting, but we would like to provide estimates in terms of the density of the data. This is why we have introduced the weights $(w_{x_i})_{i=1}^m$ corresponding to the $\\rho$-volume Voronoi tessellation (c.f. also \\cite{SmaZho04}, where a weighting scheme is introduced in a  different setting).\n\n\\begin{definition}[Fill distance]\t\t\t\\label{def:filldistance}\nLet $\\mathcal{C}\\subset\\mathbb{R}^d$ be a compact set and  $\\mathbf{x}:=\\{x_1,\\ldots,x_m\\}$ be a grid, where $\\mathbf{x}\\subset \\mathcal{C}$. We denote the \\emph{fill distance} of $\\mathbf{x}$ in $\\mathcal{C}$ as\n\n", "itemtype": "equation", "pos": 43157, "prevtext": "\nFurthermore, if $f_{\\mathbf{z},\\lambda}=\\sum_{i=1}^m a_i {K^1}_{x_i}$, then the coefficients $a:=\\{a_i\\}_{i=1}^m$ may be calculated as\n\n", "index": 47, "text": "\\begin{equation}\na = (A_{\\mathbf{x}}D_w A_{\\mathbf{x}} + \\lambda A_{\\mathbf{x}})^{-1} A_{\\mathbf{x}} D_w \\mathbf{y},\t\t\t\\label{eqn:coeffsa}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"a=(A_{\\mathbf{x}}D_{w}A_{\\mathbf{x}}+\\lambda A_{\\mathbf{x}})^{-1}A_{\\mathbf{x}%&#10;}D_{w}\\mathbf{y},\" display=\"block\"><mrow><mrow><mi>a</mi><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>A</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msub><mi>A</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>A</mi><mi>\ud835\udc31</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mi>A</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><mi>\ud835\udc32</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nIn particular, for all $y\\in \\mathcal{C}$ there is a grid point $x_i \\in \\mathbf{x}$ such that $||y - x_i|| \\le h_{\\mathbf{x}}$.\n\\end{definition}\n\nIn order to provide an estimate for   $||f_{\\mathbf{z},\\lambda} - f^*||_{K^1}$, we first define $f_{\\mathbf{x},\\lambda}, f_\\lambda\\in\\mathcal{H}_{K^1}$ by\n\\begin{eqnarray}\nf_{\\mathbf{x},\\lambda}& := & J(S_{\\mathbf{x}}f^*)\t\t\\label{eq:fxlambda}\\\\\n\\text{and}\\qquad f_\\lambda & := & \\underset{f\\in\\mathcal{H_{K^1}}}{\\arg\\min} \\left\\{ ||f - f^*||^2_\\rho + \\lambda ||f||^2_{K^1}\\right\\}\t\\label{eq:flambda}\n\\end{eqnarray}\nwhere $||f||^2_\\rho =  \\int_X |f(x)|^2d\\rho(x)$. Recall from Section \\ref{sec:RKHS} that $\\rho$ is a finite strictly positive Borel measure on $X$.\n\nThe function $f_{\\mathbf{x},\\lambda}$  may be seen as a `noise-free' version of $f_{\\mathbf{z},\\lambda}$, such that in the case of no noise, i.e. $\\eta_x = 0$ for all $x\\in X$, then we would have $f_{\\mathbf{z},\\lambda} = f_{\\mathbf{x},\\lambda}$. Correspondingly, the function $f_\\lambda$ can be seen as a `data-free' limit of $f_{\\mathbf{x},\\lambda}$, or the limiting function as the data sites $\\mathbf{x}$ become arbitrarily dense in $X$. Finally, if $f^*\\in\\mathcal{H}_{K^1}$, then $f^*$ is the `regularisation-free' version of $f_\\lambda$ -- the limit of $f_\\lambda$ as $\\lambda\\rightarrow 0$.\n\nThe strategy is to break down the estimate of $||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)}$ according to\n\\begin{eqnarray*}\n||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)} & = & ||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda} + f_{\\mathbf{x},\\lambda} - f_\\lambda + f_\\lambda - f^*||_{L^\\infty(X)}\\\\\n& \\le &  ||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{L^\\infty(X)} + ||f_{\\mathbf{x},\\lambda} - f_\\lambda||_{L^\\infty(X)} + ||f_\\lambda - f^*||_{L^\\infty(X)}\n\\end{eqnarray*}\nand estimate each of the three terms in the inequality. These three terms correspond to errors incurred by the noise (sample error), the finite set of data sites (integration error) and the regularisation parameter $\\lambda$ (regularisation error).\n\n\\subsection{Sample error}\n\nAn estimate for $||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||^2_{K^1}$ for an unweighted approximation scheme is given in Theorem 2 of \\cite{SmaZho05}. A similar result is given in the following lemma, that incorporates the weights of our  scheme. The proof follows that of \\cite{SmaZho05}, and here we will just sketch the main adaptations. Importantly, our estimate provides convergence of $f_{\\mathbf{z},\\lambda}$ to $f_{\\mathbf{x},\\lambda}$ as the data sites $\\mathbf{x}$ become more dense, or as the quantity $||\\mathbf{w}||_{\\mathbb{R}^m}$ tends to zero.\n\n\\begin{lemma}\t\t\t\\label{lem:sampleerror}\nFor $\\lambda > 0$,  for every $0 < \\delta < 1$, with probability $1 - \\delta$, we have\n\n", "itemtype": "equation", "pos": 44691, "prevtext": "\nwhere $A_{\\mathbf{x}} \\in \\mathbb{R}^{m\\times m}$ is the symmetric matrix defined by $(A_{\\mathbf{x}} )_{i,j} = {K^1}(x_i,x_j)$.\n\\end{lemma}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur strategy to prove convergence of the estimate $f_{\\mathbf{z},\\lambda}$ to $f^*$ combines and adapts results contained in \\cite{SmaZho04,SmaZho05,SmaZho07}. The main difference in our case to the standard assumptions in learning theory is that the data $\\mathbf{z} = (x_i,y_i)_{i=1}^m$ is not necessarily generated from an underlying probability distribution. Instead, our data is generated by the underlying dynamical system \\eqref{eqn:dynsys}, and the data sites may be situated arbitrarily. They could potentially be chosen deterministically, or indeed may be generated randomly.   The assumptions made in \\cite{SmaZho05} correspond to this setting, but we would like to provide estimates in terms of the density of the data. This is why we have introduced the weights $(w_{x_i})_{i=1}^m$ corresponding to the $\\rho$-volume Voronoi tessellation (c.f. also \\cite{SmaZho04}, where a weighting scheme is introduced in a  different setting).\n\n\\begin{definition}[Fill distance]\t\t\t\\label{def:filldistance}\nLet $\\mathcal{C}\\subset\\mathbb{R}^d$ be a compact set and  $\\mathbf{x}:=\\{x_1,\\ldots,x_m\\}$ be a grid, where $\\mathbf{x}\\subset \\mathcal{C}$. We denote the \\emph{fill distance} of $\\mathbf{x}$ in $\\mathcal{C}$ as\n\n", "index": 49, "text": "\\begin{equation*}\nh_{\\mathbf{x}} = \\max_{y\\in \\mathcal{C}} \\min_{x_i \\in \\mathbf{x}} ||x_i - y||.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"h_{\\mathbf{x}}=\\max_{y\\in\\mathcal{C}}\\min_{x_{i}\\in\\mathbf{x}}||x_{i}-y||.\" display=\"block\"><mrow><mrow><msub><mi>h</mi><mi>\ud835\udc31</mi></msub><mo>=</mo><mrow><munder><mi>max</mi><mrow><mi>y</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></munder><mo>\u2061</mo><mrow><munder><mi>min</mi><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>\u2208</mo><mi>\ud835\udc31</mi></mrow></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mo stretchy=\"false\">|</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mi>y</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $\\sigma^2:={\\sup_{x\\in X}\\sigma^2_{x}}$ and $\\kappa^2:={\\sup_{x\\in X} {K^1}(x,x)}$.\n\\end{lemma}\n\\begin{proof} First note that if $\\lambda >0$ then $(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)$ is invertible. This follows since it is the sum of a positive and a strictly positive operator on $\\mathcal{H}_{K^1}$. Similar to \\cite[Theorem 2]{SmaZho05}, we have\n\\begin{eqnarray*}\n\n\n\n\n||S^*_{\\mathbf{x}} D_w (y - S_{\\mathbf{x}}f^*)||^2_{K^1} \n& = &  \\sum_{i,j=1}^m  w_{x_i}w_{x_j}\\eta_{x_i}\\eta_{x_j}{K^1}(x_i,x_j).\n\\end{eqnarray*}\nSince we have assumed that the $\\eta_x$ random variables are independent with zero mean, we have that\n\n", "itemtype": "equation", "pos": 47573, "prevtext": "\nIn particular, for all $y\\in \\mathcal{C}$ there is a grid point $x_i \\in \\mathbf{x}$ such that $||y - x_i|| \\le h_{\\mathbf{x}}$.\n\\end{definition}\n\nIn order to provide an estimate for   $||f_{\\mathbf{z},\\lambda} - f^*||_{K^1}$, we first define $f_{\\mathbf{x},\\lambda}, f_\\lambda\\in\\mathcal{H}_{K^1}$ by\n\\begin{eqnarray}\nf_{\\mathbf{x},\\lambda}& := & J(S_{\\mathbf{x}}f^*)\t\t\\label{eq:fxlambda}\\\\\n\\text{and}\\qquad f_\\lambda & := & \\underset{f\\in\\mathcal{H_{K^1}}}{\\arg\\min} \\left\\{ ||f - f^*||^2_\\rho + \\lambda ||f||^2_{K^1}\\right\\}\t\\label{eq:flambda}\n\\end{eqnarray}\nwhere $||f||^2_\\rho =  \\int_X |f(x)|^2d\\rho(x)$. Recall from Section \\ref{sec:RKHS} that $\\rho$ is a finite strictly positive Borel measure on $X$.\n\nThe function $f_{\\mathbf{x},\\lambda}$  may be seen as a `noise-free' version of $f_{\\mathbf{z},\\lambda}$, such that in the case of no noise, i.e. $\\eta_x = 0$ for all $x\\in X$, then we would have $f_{\\mathbf{z},\\lambda} = f_{\\mathbf{x},\\lambda}$. Correspondingly, the function $f_\\lambda$ can be seen as a `data-free' limit of $f_{\\mathbf{x},\\lambda}$, or the limiting function as the data sites $\\mathbf{x}$ become arbitrarily dense in $X$. Finally, if $f^*\\in\\mathcal{H}_{K^1}$, then $f^*$ is the `regularisation-free' version of $f_\\lambda$ -- the limit of $f_\\lambda$ as $\\lambda\\rightarrow 0$.\n\nThe strategy is to break down the estimate of $||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)}$ according to\n\\begin{eqnarray*}\n||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)} & = & ||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda} + f_{\\mathbf{x},\\lambda} - f_\\lambda + f_\\lambda - f^*||_{L^\\infty(X)}\\\\\n& \\le &  ||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{L^\\infty(X)} + ||f_{\\mathbf{x},\\lambda} - f_\\lambda||_{L^\\infty(X)} + ||f_\\lambda - f^*||_{L^\\infty(X)}\n\\end{eqnarray*}\nand estimate each of the three terms in the inequality. These three terms correspond to errors incurred by the noise (sample error), the finite set of data sites (integration error) and the regularisation parameter $\\lambda$ (regularisation error).\n\n\\subsection{Sample error}\n\nAn estimate for $||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||^2_{K^1}$ for an unweighted approximation scheme is given in Theorem 2 of \\cite{SmaZho05}. A similar result is given in the following lemma, that incorporates the weights of our  scheme. The proof follows that of \\cite{SmaZho05}, and here we will just sketch the main adaptations. Importantly, our estimate provides convergence of $f_{\\mathbf{z},\\lambda}$ to $f_{\\mathbf{x},\\lambda}$ as the data sites $\\mathbf{x}$ become more dense, or as the quantity $||\\mathbf{w}||_{\\mathbb{R}^m}$ tends to zero.\n\n\\begin{lemma}\t\t\t\\label{lem:sampleerror}\nFor $\\lambda > 0$,  for every $0 < \\delta < 1$, with probability $1 - \\delta$, we have\n\n", "index": 51, "text": "\\begin{equation}\n||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{L^\\infty(X)} \\le \\kappa ||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{K^1} \\le \\frac{||\\mathbf{w}||_{\\mathbb{R}^m} \\sigma \\kappa^2}{\\lambda\\sqrt{\\delta}}\t\\label{eq:sampleerror}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"||f_{\\mathbf{z},\\lambda}-f_{\\mathbf{x},\\lambda}||_{L^{\\infty}(X)}\\leq\\kappa||f%&#10;_{\\mathbf{z},\\lambda}-f_{\\mathbf{x},\\lambda}||_{K^{1}}\\leq\\frac{||\\mathbf{w}||%&#10;_{\\mathbb{R}^{m}}\\sigma\\kappa^{2}}{\\lambda\\sqrt{\\delta}}\" display=\"block\"><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>\u03ba</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mrow><mo>\u2264</mo><mfrac><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>\u2062</mo><mi>\u03c3</mi><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup></mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><msqrt><mi>\u03b4</mi></msqrt></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere the inequality follows from our assumption that  $\\sigma^2:=\\sup_{x\\in X}\\sigma_{x_i}^2 < \\infty$. Then it follows that\n\n", "itemtype": "equation", "pos": 48484, "prevtext": "\nwhere $\\sigma^2:={\\sup_{x\\in X}\\sigma^2_{x}}$ and $\\kappa^2:={\\sup_{x\\in X} {K^1}(x,x)}$.\n\\end{lemma}\n\\begin{proof} First note that if $\\lambda >0$ then $(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)$ is invertible. This follows since it is the sum of a positive and a strictly positive operator on $\\mathcal{H}_{K^1}$. Similar to \\cite[Theorem 2]{SmaZho05}, we have\n\\begin{eqnarray*}\n\n\n\n\n||S^*_{\\mathbf{x}} D_w (y - S_{\\mathbf{x}}f^*)||^2_{K^1} \n& = &  \\sum_{i,j=1}^m  w_{x_i}w_{x_j}\\eta_{x_i}\\eta_{x_j}{K^1}(x_i,x_j).\n\\end{eqnarray*}\nSince we have assumed that the $\\eta_x$ random variables are independent with zero mean, we have that\n\n", "index": 53, "text": "\\begin{equation*}\n\\mathbb{E}(||S^*_{\\mathbf{x}} D_w (y - S_{\\mathbf{x}}f^*)||^2_{K^1})  =  \\sum_{i=1}^m w_{x_i}^2 \\sigma_{x_i}^2 {K^1}(x_i,x_i)\n \\le  \\sigma^2\\kappa^2 \\sum_{i=1}^m w^2_{x_i} = \\sigma^2\\kappa^2 ||\\mathbf{w}||^2,\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(||S^{*}_{\\mathbf{x}}D_{w}(y-S_{\\mathbf{x}}f^{*})||^{2}_{K^{1}})=%&#10;\\sum_{i=1}^{m}w_{x_{i}}^{2}\\sigma_{x_{i}}^{2}{K^{1}}(x_{i},x_{i})\\leq\\sigma^{2%&#10;}\\kappa^{2}\\sum_{i=1}^{m}w^{2}_{x_{i}}=\\sigma^{2}\\kappa^{2}||\\mathbf{w}||^{2},\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>y</mi><mo>-</mo><mrow><msub><mi>S</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><msup><mi>f</mi><mo>*</mo></msup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msubsup><mi>w</mi><msub><mi>x</mi><mi>i</mi></msub><mn>2</mn></msubsup><mo>\u2062</mo><msubsup><mi>\u03c3</mi><msub><mi>x</mi><mi>i</mi></msub><mn>2</mn></msubsup><mo>\u2062</mo><msup><mi>K</mi><mn>1</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2264</mo><mrow><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msubsup><mi>w</mi><msub><mi>x</mi><mi>i</mi></msub><mn>2</mn></msubsup></mrow></mrow><mo>=</mo><mrow><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nThe operator $(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}$ is estimated analagously to \\cite[Proposition 1]{SmaZho05} to obtain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 48853, "prevtext": "\nwhere the inequality follows from our assumption that  $\\sigma^2:=\\sup_{x\\in X}\\sigma_{x_i}^2 < \\infty$. Then it follows that\n\n", "index": 55, "text": "\\begin{equation*}\n\\mathbb{E}(||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{K^1}^2) \\le ||(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}||^2||\\mathbf{w}||^2\\sigma^2\\kappa^2.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(||f_{\\mathbf{z},\\lambda}-f_{\\mathbf{x},\\lambda}||_{K^{1}}^{2})\\leq|%&#10;|(S^{*}_{\\mathbf{x}}D_{w}S_{\\mathbf{x}}+\\lambda I)^{-1}||^{2}||\\mathbf{w}||^{2%&#10;}\\sigma^{2}\\kappa^{2}.\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><msup><mrow><mo fence=\"true\">||</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msub><mi>S</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mi>I</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msup><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nThen we have\n\n", "itemtype": "equation", "pos": 49210, "prevtext": "\nThe operator $(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}$ is estimated analagously to \\cite[Proposition 1]{SmaZho05} to obtain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "index": 57, "text": "\\begin{equation}\t\t\t\\label{eq:SDS}\n||(S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}|| \\le \\frac{1}{\\lambda}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"||(S^{*}_{\\mathbf{x}}D_{w}S_{\\mathbf{x}}+\\lambda I)^{-1}||\\leq\\frac{1}{\\lambda}.\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\">||</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>S</mi><mi>\ud835\udc31</mi><mo>*</mo></msubsup><mo>\u2062</mo><msub><mi>D</mi><mi>w</mi></msub><mo>\u2062</mo><msub><mi>S</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mi>I</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo fence=\"true\">||</mo></mrow><mo>\u2264</mo><mfrac><mn>1</mn><mi>\u03bb</mi></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nFinally, for $0 < \\delta < 1$,  application of the Markov inequality to the random variable $||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||^2_{K^1}$ gives\n\n", "itemtype": "equation", "pos": 49354, "prevtext": "\nThen we have\n\n", "index": 59, "text": "\\begin{equation*}\n\\mathbb{E}(||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||_{K^1}^2) \\le \\frac{||\\mathbf{w}||^2\\sigma^2\\kappa^2}{\\lambda^2}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}(||f_{\\mathbf{z},\\lambda}-f_{\\mathbf{x},\\lambda}||_{K^{1}}^{2})\\leq%&#10;\\frac{||\\mathbf{w}||^{2}\\sigma^{2}\\kappa^{2}}{\\lambda^{2}}.\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mfrac><mrow><msup><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup></mrow><msup><mi>\u03bb</mi><mn>2</mn></msup></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nCombining the above together with \\eqref{eq:supnorminclusion} proves the lemma.\n\\qquad\\end{proof}\n\n\\subsection{Integration error}\n\nTo establish our estimate for the integration error we need to make additional assumptions on the choice of Borel measure $\\rho$. Namely, we will require that  it is strongly continuous (c.f. \\cite{Pag97}):\n\n\\begin{definition}\nA Borel measure $\\rho$ is strongly continuous if for all hyperplanes $H\\subset\\mathbb{R}^d$, we have $\\rho(H)=0$.\n\\end{definition}\n\nNote that this requirement implies that the boundaries of the Voronoi tessellation have $\\rho$-measure zero. Lebesgue measure is still an example measure that satisfies all of our assumptions, recall Section \\ref{sec:RKHS}.\nAn estimate for the integration error $||f_{\\mathbf{x},\\lambda} - f_\\lambda||_{L^\\infty(X)}$ is given in the following lemma.\n\n\\begin{lemma} \t\t\t\\label{lem:integrationerror}\nLet $\\rho$ be a (finite) strictly positive, strongly continuous Borel measure on $X$.\n\nFor $\\lambda > 0$, we have\n\n", "itemtype": "equation", "pos": 49676, "prevtext": "\nFinally, for $0 < \\delta < 1$,  application of the Markov inequality to the random variable $||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||^2_{K^1}$ gives\n\n", "index": 61, "text": "\\begin{equation*}\n\\mathbb{P}\\left(||f_{\\mathbf{z},\\lambda} - f_{\\mathbf{x},\\lambda}||^2_{K^1} \\ge  \\frac{||\\mathbf{w}||^2\\sigma^2\\kappa^2}{\\lambda^2\\delta}\\right) \\le \\delta.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{P}\\left(||f_{\\mathbf{z},\\lambda}-f_{\\mathbf{x},\\lambda}||^{2}_{K^{1}}%&#10;\\geq\\frac{||\\mathbf{w}||^{2}\\sigma^{2}\\kappa^{2}}{\\lambda^{2}\\delta}\\right)%&#10;\\leq\\delta.\" display=\"block\"><mrow><mi>\u2119</mi><mrow><mo>(</mo><mo stretchy=\"false\">|</mo><mo stretchy=\"false\">|</mo><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo stretchy=\"false\">|</mo><msubsup><mo stretchy=\"false\">|</mo><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup><mo>\u2265</mo><mfrac><mrow><msup><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup></mrow><mrow><msup><mi>\u03bb</mi><mn>2</mn></msup><mo>\u2062</mo><mi>\u03b4</mi></mrow></mfrac><mo>)</mo></mrow><mo>\u2264</mo><mi>\u03b4</mi><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\\end{lemma}\n\\begin{proof}\n It is shown in \\cite{CucSma02} that the solution to \\eqref{eq:flambda} for $\\lambda > 0$ is given by\n\n", "itemtype": "equation", "pos": 50868, "prevtext": "\nCombining the above together with \\eqref{eq:supnorminclusion} proves the lemma.\n\\qquad\\end{proof}\n\n\\subsection{Integration error}\n\nTo establish our estimate for the integration error we need to make additional assumptions on the choice of Borel measure $\\rho$. Namely, we will require that  it is strongly continuous (c.f. \\cite{Pag97}):\n\n\\begin{definition}\nA Borel measure $\\rho$ is strongly continuous if for all hyperplanes $H\\subset\\mathbb{R}^d$, we have $\\rho(H)=0$.\n\\end{definition}\n\nNote that this requirement implies that the boundaries of the Voronoi tessellation have $\\rho$-measure zero. Lebesgue measure is still an example measure that satisfies all of our assumptions, recall Section \\ref{sec:RKHS}.\nAn estimate for the integration error $||f_{\\mathbf{x},\\lambda} - f_\\lambda||_{L^\\infty(X)}$ is given in the following lemma.\n\n\\begin{lemma} \t\t\t\\label{lem:integrationerror}\nLet $\\rho$ be a (finite) strictly positive, strongly continuous Borel measure on $X$.\n\nFor $\\lambda > 0$, we have\n\n", "index": 63, "text": "\\begin{equation}\n||f_{\\mathbf{x},\\lambda} - f_\\lambda||_{L^\\infty(X)} \\le \\frac{C}{\\lambda}\\kappa ||f^* - f_\\lambda||_{K^1} \\, h_\\mathbf{x} \\rho(X).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"||f_{\\mathbf{x},\\lambda}-f_{\\lambda}||_{L^{\\infty}(X)}\\leq\\frac{C}{\\lambda}%&#10;\\kappa||f^{*}-f_{\\lambda}||_{K^{1}}\\,h_{\\mathbf{x}}\\rho(X).\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mi>\u03bb</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mfrac><mi>C</mi><mi>\u03bb</mi></mfrac><mo>\u2062</mo><mi>\u03ba</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msub><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>-</mo><msub><mi>f</mi><mi>\u03bb</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mpadded><mo>\u2062</mo><msub><mi>h</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><mi>\u03c1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $L_{K^1}$ was defined in equation \\eqref{eq:LK}.\n\nNow we have\n\\begin{eqnarray*}\nf_{\\mathbf{x},\\lambda} - f_\\lambda & = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1} S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} f^* -  f_\\lambda\\\\\n\n& = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}\\left\\{ S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} (f^* -  f_\\lambda) - (L_{K^1} f^* - L_{K^1} f_\\lambda)\\right\\}\\\\\n& = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}\\left\\{ \\sum_{i=1}^m w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - L_{K^1} (f^* -  f_\\lambda)\\right\\}\n\\end{eqnarray*}\nwhere the second equality follows from \\eqref{eq:flambdasol} and the final equality follows from the definition of $S_{\\mathbf{x}}$ and its adjoint.\n\nRecall that we have chosen the weighting $\\mathbf{w}$ to be equal to the $\\rho$-volume of the Voronoi tessellation associated to the data sites $\\mathbf{x}$ -- that is, $w_{x_i} = \\rho(V_i(\\mathbf{x}))$. Also, since $\\rho$ is strongly continuous it holds that\n\n", "itemtype": "equation", "pos": 51161, "prevtext": "\n\n\\end{lemma}\n\\begin{proof}\n It is shown in \\cite{CucSma02} that the solution to \\eqref{eq:flambda} for $\\lambda > 0$ is given by\n\n", "index": 65, "text": "\\begin{equation}\nf_\\lambda = (L_{K^1} + \\lambda I)^{-1} L_{K^1} f^*,\t\\label{eq:flambdasol}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"f_{\\lambda}=(L_{K^{1}}+\\lambda I)^{-1}L_{K^{1}}f^{*},\" display=\"block\"><mrow><mrow><msub><mi>f</mi><mi>\u03bb</mi></msub><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>L</mi><msup><mi>K</mi><mn>1</mn></msup></msub><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mi>I</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mi>L</mi><msup><mi>K</mi><mn>1</mn></msup></msub><mo>\u2062</mo><msup><mi>f</mi><mo>*</mo></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nand so\n\\begin{eqnarray*}\n\\left|\\left|\\sum_{i=1}^m w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - L_{K^1} (f^* -  f_\\lambda)\\right|\\right|_{L^\\infty(X)}\t\\hspace{-7.3cm}\\\\\n& = & \\left|\\left|\\sum_{i=1}^m \\left\\{ w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - \\int_{V_i(\\mathbf{x})}{K_y^1} (f^*(y) - f_\\lambda(y))d\\rho(y)\\right\\}\\right|\\right|_{L^\\infty(X)}\\\\\n& \\le & \\sum_{i=1}^m \\int_{V_i(\\mathbf{x})} \\left|\\left|(f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - (f^*(y) - f_\\lambda(y)) {K_y^1}\\right|\\right|_{L^\\infty(X)} d\\rho(y)\\\\\n& \\le & C\\kappa ||f^* - f_\\lambda||_{K^1} \\sum_{i=1}^m \\int_{V_i(\\mathbf{x})} |x_i - y | d\\rho(y)\n\\,\\le\\,  C\\kappa ||f^* - f_\\lambda||_{K^1} \\, h_\\mathbf{x} \\rho(X)\n\\end{eqnarray*}\n\nThe second equality follows from the fact that $(f^*-f_\\lambda)$ and $K_x$ belong to $\\mathcal{H}_{K^1}$, and are therefore bounded and Lipschitz on $X$ (cf. Corollary \\ref{cor:smoothnessK1K2}).\nThis, together with \\eqref{eq:SDS} proves the lemma.\n\\qquad\\end{proof}\n\n\\subsection{Regularisation error}\n\nFor the regularisation error we  recall the following result from \\cite[Lemma 3]{SmaZho07} (c.f. also \\cite[Theorem 4]{SmaZho05}):\n\n\\begin{lemma}\t\t\t\\label{lem:regularisationerror}\nSuppose that  $L_{K^1}^{-r} f^* \\in {L}^2_\\rho(X)$ for some  $\\frac{1}{2} < r \\le 1$. Then we have\n\n\n\n\n\n", "itemtype": "equation", "pos": 52264, "prevtext": "\nwhere $L_{K^1}$ was defined in equation \\eqref{eq:LK}.\n\nNow we have\n\\begin{eqnarray*}\nf_{\\mathbf{x},\\lambda} - f_\\lambda & = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1} S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} f^* -  f_\\lambda\\\\\n\n& = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}\\left\\{ S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} (f^* -  f_\\lambda) - (L_{K^1} f^* - L_{K^1} f_\\lambda)\\right\\}\\\\\n& = & (S^*_{\\mathbf{x}} D_w S_{\\mathbf{x}} + \\lambda I)^{-1}\\left\\{ \\sum_{i=1}^m w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - L_{K^1} (f^* -  f_\\lambda)\\right\\}\n\\end{eqnarray*}\nwhere the second equality follows from \\eqref{eq:flambdasol} and the final equality follows from the definition of $S_{\\mathbf{x}}$ and its adjoint.\n\nRecall that we have chosen the weighting $\\mathbf{w}$ to be equal to the $\\rho$-volume of the Voronoi tessellation associated to the data sites $\\mathbf{x}$ -- that is, $w_{x_i} = \\rho(V_i(\\mathbf{x}))$. Also, since $\\rho$ is strongly continuous it holds that\n\n", "index": 67, "text": "\\begin{equation*}\nL_{K^1}(f^* - f_\\lambda) \n=\\sum_{i=1}^m \\int_{V_i(\\mathbf{x})} {K^1}(x,y)(f^*(y) - f_\\lambda(y))d\\rho(y)\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"L_{K^{1}}(f^{*}-f_{\\lambda})=\\sum_{i=1}^{m}\\int_{V_{i}(\\mathbf{x})}{K^{1}}(x,y%&#10;)(f^{*}(y)-f_{\\lambda}(y))d\\rho(y)\" display=\"block\"><mrow><mrow><msub><mi>L</mi><msup><mi>K</mi><mn>1</mn></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>-</mo><msub><mi>f</mi><mi>\u03bb</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msub><mi>V</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mrow><msup><mi>K</mi><mn>1</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>f</mi><mi>\u03bb</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03c1</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\n\n\n\\end{lemma}\n\n\\subsection{Estimate for $||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)}$}\n\nAltogether, from lemmas \\ref{lem:sampleerror}, \\ref{lem:integrationerror} and \\ref{lem:regularisationerror} and equation \\eqref{eq:supnorminclusion} we have with probability $1-\\delta$\n\n", "itemtype": "equation", "pos": 53695, "prevtext": "\nand so\n\\begin{eqnarray*}\n\\left|\\left|\\sum_{i=1}^m w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - L_{K^1} (f^* -  f_\\lambda)\\right|\\right|_{L^\\infty(X)}\t\\hspace{-7.3cm}\\\\\n& = & \\left|\\left|\\sum_{i=1}^m \\left\\{ w_{x_i} (f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - \\int_{V_i(\\mathbf{x})}{K_y^1} (f^*(y) - f_\\lambda(y))d\\rho(y)\\right\\}\\right|\\right|_{L^\\infty(X)}\\\\\n& \\le & \\sum_{i=1}^m \\int_{V_i(\\mathbf{x})} \\left|\\left|(f^*(x_i) -  f_\\lambda(x_i))K^1_{x_i} - (f^*(y) - f_\\lambda(y)) {K_y^1}\\right|\\right|_{L^\\infty(X)} d\\rho(y)\\\\\n& \\le & C\\kappa ||f^* - f_\\lambda||_{K^1} \\sum_{i=1}^m \\int_{V_i(\\mathbf{x})} |x_i - y | d\\rho(y)\n\\,\\le\\,  C\\kappa ||f^* - f_\\lambda||_{K^1} \\, h_\\mathbf{x} \\rho(X)\n\\end{eqnarray*}\n\nThe second equality follows from the fact that $(f^*-f_\\lambda)$ and $K_x$ belong to $\\mathcal{H}_{K^1}$, and are therefore bounded and Lipschitz on $X$ (cf. Corollary \\ref{cor:smoothnessK1K2}).\nThis, together with \\eqref{eq:SDS} proves the lemma.\n\\qquad\\end{proof}\n\n\\subsection{Regularisation error}\n\nFor the regularisation error we  recall the following result from \\cite[Lemma 3]{SmaZho07} (c.f. also \\cite[Theorem 4]{SmaZho05}):\n\n\\begin{lemma}\t\t\t\\label{lem:regularisationerror}\nSuppose that  $L_{K^1}^{-r} f^* \\in {L}^2_\\rho(X)$ for some  $\\frac{1}{2} < r \\le 1$. Then we have\n\n\n\n\n\n", "index": 69, "text": "\\begin{equation}\t\t\t\t\\label{eqn:estflambdafstar}\n||f_\\lambda - f^*||_{K^1} \\le \\lambda^{r-\\frac{1}{2}} ||L_{K^1}^{-r} f^*||_{{L}^2_\\rho(X)},\\qquad \\frac{1}{2} < r \\le 1.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"||f_{\\lambda}-f^{*}||_{K^{1}}\\leq\\lambda^{r-\\frac{1}{2}}||L_{K^{1}}^{-r}f^{*}|%&#10;|_{{L}^{2}_{\\rho}(X)},\\qquad\\frac{1}{2}&lt;r\\leq 1.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mi>\u03bb</mi></msub><mo>-</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub><mo>\u2264</mo><mrow><msup><mi>\u03bb</mi><mrow><mi>r</mi><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>L</mi><msup><mi>K</mi><mn>1</mn></msup><mrow><mo>-</mo><mi>r</mi></mrow></msubsup><mo>\u2062</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>L</mi><mi>\u03c1</mi><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>&lt;</mo><mi>r</mi><mo>\u2264</mo><mn>1</mn></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nApplying equation \\eqref{eqn:estflambdafstar} again yields\n\n\n", "itemtype": "equation", "pos": 54157, "prevtext": "\n\n\n\n\n\\end{lemma}\n\n\\subsection{Estimate for $||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)}$}\n\nAltogether, from lemmas \\ref{lem:sampleerror}, \\ref{lem:integrationerror} and \\ref{lem:regularisationerror} and equation \\eqref{eq:supnorminclusion} we have with probability $1-\\delta$\n\n", "index": 71, "text": "\\begin{equation}\t\t\n||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)} \\le\n\\frac{||\\mathbf{w}||_{\\mathbb{R}^m}\\sigma\\kappa^2}{\\lambda \\sqrt{\\delta}} +  \\frac{C\\kappa ||f^* - f_\\lambda||_{K^1} \\, h_\\mathbf{x} \\rho(X)}{\\lambda}     + \\kappa\\lambda^{r-\\frac{1}{2}}||L_{K^1}^{-r}f^*||_{{L}^2_\\rho(X)}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"||f_{\\mathbf{z},\\lambda}-f^{*}||_{L^{\\infty}(X)}\\leq\\frac{||\\mathbf{w}||_{%&#10;\\mathbb{R}^{m}}\\sigma\\kappa^{2}}{\\lambda\\sqrt{\\delta}}+\\frac{C\\kappa||f^{*}-f_%&#10;{\\lambda}||_{K^{1}}\\,h_{\\mathbf{x}}\\rho(X)}{\\lambda}+\\kappa\\lambda^{r-\\frac{1}%&#10;{2}}||L_{K^{1}}^{-r}f^{*}||_{{L}^{2}_{\\rho}(X)}\" display=\"block\"><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mfrac><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>\u2062</mo><mi>\u03c3</mi><mo>\u2062</mo><msup><mi>\u03ba</mi><mn>2</mn></msup></mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><msqrt><mi>\u03b4</mi></msqrt></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>C</mi><mo>\u2062</mo><mi>\u03ba</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msub><mrow><mo fence=\"true\">||</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>-</mo><msub><mi>f</mi><mi>\u03bb</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mpadded><mo>\u2062</mo><msub><mi>h</mi><mi>\ud835\udc31</mi></msub><mo>\u2062</mo><mi>\u03c1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>\u03bb</mi></mfrac><mo>+</mo><mrow><mi>\u03ba</mi><mo>\u2062</mo><msup><mi>\u03bb</mi><mrow><mi>r</mi><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>L</mi><msup><mi>K</mi><mn>1</mn></msup><mrow><mo>-</mo><mi>r</mi></mrow></msubsup><mo>\u2062</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>L</mi><mi>\u03c1</mi><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere the constant $C$ depends on $f^*$,  $d$, $\\sigma$ and the choice of RKHS $\\mathcal{H}_{K^1}$. Now it is clear that the above bound can be made arbitrarily small as $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ tend to zero, if $\\lambda$ also tends to zero at an appropriate rate.\nWith the choice of regularisation parameter\n\n", "itemtype": "equation", "pos": 54524, "prevtext": "\nApplying equation \\eqref{eqn:estflambdafstar} again yields\n\n\n", "index": 73, "text": "\\begin{equation}\n||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)} \\le C \\left(\n\\frac{||\\mathbf{w}||_{\\mathbb{R}^m}}{\\lambda \\sqrt{\\delta}} + \\lambda^{r-\\frac{3}{2}} h_\\mathbf{x}+ \\lambda^{r-\\frac{1}{2}} \\right),\n\\label{eqn:festimate}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"||f_{\\mathbf{z},\\lambda}-f^{*}||_{L^{\\infty}(X)}\\leq C\\left(\\frac{||\\mathbf{w}%&#10;||_{\\mathbb{R}^{m}}}{\\lambda\\sqrt{\\delta}}+\\lambda^{r-\\frac{3}{2}}h_{\\mathbf{x%&#10;}}+\\lambda^{r-\\frac{1}{2}}\\right),\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mfrac><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mrow><mi>\u03bb</mi><mo>\u2062</mo><msqrt><mi>\u03b4</mi></msqrt></mrow></mfrac><mo>+</mo><mrow><msup><mi>\u03bb</mi><mrow><mi>r</mi><mo>-</mo><mfrac><mn>3</mn><mn>2</mn></mfrac></mrow></msup><mo>\u2062</mo><msub><mi>h</mi><mi>\ud835\udc31</mi></msub></mrow><mo>+</mo><msup><mi>\u03bb</mi><mrow><mi>r</mi><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwith probability $1-\\delta$, we obtain the  estimate\n\n", "itemtype": "equation", "pos": 55108, "prevtext": "\nwhere the constant $C$ depends on $f^*$,  $d$, $\\sigma$ and the choice of RKHS $\\mathcal{H}_{K^1}$. Now it is clear that the above bound can be made arbitrarily small as $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ tend to zero, if $\\lambda$ also tends to zero at an appropriate rate.\nWith the choice of regularisation parameter\n\n", "index": 75, "text": "\\begin{equation}\t\t\t\t\t\\label{eqn:lambdachoice}\n\\lambda = \\left(\\max\\left\\{||\\mathbf{w}||_{\\mathbb{R}^m}, h_{\\mathbf{x}}^{\\frac{2}{3-2r}}\\right\\}\\right)^{\\frac{2}{2r+1}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\lambda=\\left(\\max\\left\\{||\\mathbf{w}||_{\\mathbb{R}^{m}},h_{\\mathbf{x}}^{\\frac%&#10;{2}{3-2r}}\\right\\}\\right)^{\\frac{2}{2r+1}},\" display=\"block\"><mrow><mrow><mi>\u03bb</mi><mo>=</mo><msup><mrow><mo>(</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>,</mo><msubsup><mi>h</mi><mi>\ud835\udc31</mi><mfrac><mn>2</mn><mrow><mn>3</mn><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow></mrow></mfrac></msubsup><mo>}</mo></mrow></mrow><mo>)</mo></mrow><mfrac><mn>2</mn><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow><mo>+</mo><mn>1</mn></mrow></mfrac></msup></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \\section{Proof of  Theorem \\ref{thm:mainresult}}\t\t\\label{sec:proofofmainthm}\n\nLet $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ and $T\\in C^{\\nu_1}(A(\\overline{x})\\,\\backslash\\,\\{\\overline{x}\\},\\mathbb{R})$ be the Lyapunov functions for $f^*$ as defined in Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse}. Then we have\n\n", "itemtype": "equation", "pos": 55345, "prevtext": "\nwith probability $1-\\delta$, we obtain the  estimate\n\n", "index": 77, "text": "\\begin{equation}\t\t\t\t\\label{eqn:fzlambdaestnolambda}\n||f_{\\mathbf{z},\\lambda} - f^*||_{L^\\infty(X)} \\le C \\left(\\max\\left\\{||\\mathbf{w}||_{\\mathbb{R}^m}/\\sqrt{\\delta}, h_{\\mathbf{x}}\\right\\}\\right)^{\\frac{2r-1}{2r+1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"||f_{\\mathbf{z},\\lambda}-f^{*}||_{L^{\\infty}(X)}\\leq C\\left(\\max\\left\\{||%&#10;\\mathbf{w}||_{\\mathbb{R}^{m}}/\\sqrt{\\delta},h_{\\mathbf{x}}\\right\\}\\right)^{%&#10;\\frac{2r-1}{2r+1}}.\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub><mo>-</mo><msup><mi>f</mi><mo>*</mo></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>/</mo><msqrt><mi>\u03b4</mi></msqrt></mrow><mo>,</mo><msub><mi>h</mi><mi>\ud835\udc31</mi></msub><mo>}</mo></mrow></mrow><mo>)</mo></mrow><mfrac><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow><mo>-</mo><mn>1</mn></mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow><mo>+</mo><mn>1</mn></mrow></mfrac></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwith $p(x)$ also defined in Theorem \\ref{thm:VLyapunovconverse}. Similarly,\n\\begin{eqnarray}\nL_{f^*}T(x) &=& -\\overline{c}\\qquad \\text{for all }x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\},\\\\\nT(x) & = & \\xi_T(x), \\qquad x\\in\\Gamma.\t\t\t\\label{eq:TxiT}\n\\end{eqnarray}\nfor $c>0$, where $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ is a non-characteristic hypersurface according to Definition \\ref{def:noncharhyp} (with $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$), and $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$.\n\nAs stated in Theorem \\ref{thm:VLyapunovconverse}, the Lyapunov function $V$ is uniquely defined up to a constant.\nWe will fix $V$ by setting $V(\\overline{x})=0$. The Lyapunov function $T$ is uniquely defined according to the above properties.\n\n\n\nThe following Lemma provides an alternative characterisation of the Lyapunov function $V$, which will be useful later in the section.\n\\begin{lemma}\t\t\t\t\t\t\\label{lem:VxiV}\nLet $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ be the uniquely defined Lyapunov function as above, and $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ ($h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$) is a non-characteristic hypersurface according to Definition \\ref{def:noncharhyp}. Define $\\xi_V \\in C^{\\nu_1}(\\Gamma, \\mathbb{R})$ by\n$\\xi_V(x) := V(x)$ for $x\\in\\Gamma$. Also recall $\\varphi_{f^*}(t,\\cdot)$ denotes the flow operator of \\eqref{eqn:dynsys}, and define the function $\\theta_{f^*}\\in C^{\\nu_1}(A(\\overline{x})\\backslash\\{\\overline{x}\\},\\mathbb{R})$ by $\\varphi_{f^*}(t,x)\\in\\Gamma \\Leftrightarrow t = \\theta_{f^*}(x)$.\nThen\n\n", "itemtype": "equation", "pos": 55933, "prevtext": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \\section{Proof of  Theorem \\ref{thm:mainresult}}\t\t\\label{sec:proofofmainthm}\n\nLet $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ and $T\\in C^{\\nu_1}(A(\\overline{x})\\,\\backslash\\,\\{\\overline{x}\\},\\mathbb{R})$ be the Lyapunov functions for $f^*$ as defined in Theorems \\ref{thm:VLyapunovconverse} and \\ref{thm:TLyapunovconverse}. Then we have\n\n", "index": 79, "text": "\\begin{equation}\nL_{f^*}V(x) := \\langle \\nabla V(x), f^*(x) \\rangle_{\\mathbb{R}^d} = -p(x),\\qquad \\text{for all }x\\in A(\\overline{x}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"L_{f^{*}}V(x):=\\langle\\nabla V(x),f^{*}(x)\\rangle_{\\mathbb{R}^{d}}=-p(x),%&#10;\\qquad\\text{for all }x\\in A(\\overline{x}),\" display=\"block\"><mrow><mrow><mrow><mrow><msub><mi>L</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi>V</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>=</mo><mrow><mo>-</mo><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><mtext>for all\u00a0</mtext><mo>\u2062</mo><mi>x</mi></mrow><mo>\u2208</mo><mrow><mi>A</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\\end{lemma}\n\\begin{proof}\nIt is shown in \\cite[Theorem 2.38]{Gie07:a} that the function $\\theta_{f^*}$ is well-defined and belongs to $C^{\\nu_1}(A(\\overline{x})\\backslash\\{\\overline{x}\\},\\mathbb{R})$. Also in \\cite[Theorem 2.46]{Gie07:a} it is shown that\n\n", "itemtype": "equation", "pos": 57701, "prevtext": "\nwith $p(x)$ also defined in Theorem \\ref{thm:VLyapunovconverse}. Similarly,\n\\begin{eqnarray}\nL_{f^*}T(x) &=& -\\overline{c}\\qquad \\text{for all }x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\},\\\\\nT(x) & = & \\xi_T(x), \\qquad x\\in\\Gamma.\t\t\t\\label{eq:TxiT}\n\\end{eqnarray}\nfor $c>0$, where $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ is a non-characteristic hypersurface according to Definition \\ref{def:noncharhyp} (with $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$), and $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$.\n\nAs stated in Theorem \\ref{thm:VLyapunovconverse}, the Lyapunov function $V$ is uniquely defined up to a constant.\nWe will fix $V$ by setting $V(\\overline{x})=0$. The Lyapunov function $T$ is uniquely defined according to the above properties.\n\n\n\nThe following Lemma provides an alternative characterisation of the Lyapunov function $V$, which will be useful later in the section.\n\\begin{lemma}\t\t\t\t\t\t\\label{lem:VxiV}\nLet $V\\in C^{\\nu_1}(A(\\overline{x}),\\mathbb{R})$ be the uniquely defined Lyapunov function as above, and $\\Gamma = \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid h(x) = 0\\}$ ($h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$) is a non-characteristic hypersurface according to Definition \\ref{def:noncharhyp}. Define $\\xi_V \\in C^{\\nu_1}(\\Gamma, \\mathbb{R})$ by\n$\\xi_V(x) := V(x)$ for $x\\in\\Gamma$. Also recall $\\varphi_{f^*}(t,\\cdot)$ denotes the flow operator of \\eqref{eqn:dynsys}, and define the function $\\theta_{f^*}\\in C^{\\nu_1}(A(\\overline{x})\\backslash\\{\\overline{x}\\},\\mathbb{R})$ by $\\varphi_{f^*}(t,x)\\in\\Gamma \\Leftrightarrow t = \\theta_{f^*}(x)$.\nThen\n\n", "index": 81, "text": "\\begin{equation*}\nV(x) = \\xi_V(\\varphi_{f^*}(\\theta_{f^*}(x),x)) + \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau ,x))d\\tau,\\qquad x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"V(x)=\\xi_{V}(\\varphi_{f^{*}}(\\theta_{f^{*}}(x),x))+\\int_{0}^{\\theta_{f^{*}}(x)%&#10;}p(\\varphi_{f^{*}}(\\tau,x))d\\tau,\\qquad x\\in A(\\overline{x})\\backslash\\{%&#10;\\overline{x}\\}.\" display=\"block\"><mrow><mrow><mrow><mrow><mi>V</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03be</mi><mi>V</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03c6</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03b8</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mrow><msub><mi>\u03b8</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03c6</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03c4</mi></mrow></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>x</mi><mo>\u2208</mo><mrow><mrow><mi>A</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\\</mo><mrow><mo stretchy=\"false\">{</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nLet $y = \\varphi_{f^*}(\\theta_{f^*}(x),x) \\in \\Gamma$. Then, for $x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\}$,\n\\begin{eqnarray*}\nV(x) & = &  \\int_{\\theta_{f^*}(x)}^\\infty p(\\varphi_{f^*}(\\tau,x))d\\tau + \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau\\\\\n\n& = & \\int_{0}^\\infty p(\\varphi_{f^*}(\\overline\\tau ,y))d\\overline\\tau + \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau \\qquad\\text{(using $\\overline{\\tau} = \\tau - \\theta_{f^*}(x)$)}\\\\\n& = & \\xi_V(y) +  \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau\n\\end{eqnarray*}\nwhich proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\\begin{remark}\t\t\t\t\t\t\\label{rem:xiT}\nSimilarly, the Lyapunov function $T$ has the representation\n\n", "itemtype": "equation", "pos": 58150, "prevtext": "\n\\end{lemma}\n\\begin{proof}\nIt is shown in \\cite[Theorem 2.38]{Gie07:a} that the function $\\theta_{f^*}$ is well-defined and belongs to $C^{\\nu_1}(A(\\overline{x})\\backslash\\{\\overline{x}\\},\\mathbb{R})$. Also in \\cite[Theorem 2.46]{Gie07:a} it is shown that\n\n", "index": 83, "text": "\\begin{equation*}\nV(x) = \\int_0^\\infty p(\\varphi_{f^*}(\\tau,x))d\\tau\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"V(x)=\\int_{0}^{\\infty}p(\\varphi_{f^{*}}(\\tau,x))d\\tau\" display=\"block\"><mrow><mrow><mi>V</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi mathvariant=\"normal\">\u221e</mi></msubsup><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03c6</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03c4</mi></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwith $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ as above.\n\\end{remark}\n\nWe  aim to approximate the Lyapunov functions $V$ and $T$ in a compact subset of the basin of attraction $A(\\overline{x})$. This subset is given by $\\mathcal{D}:=\\Omega\\setminus B_\\varepsilon(\\overline{x})$ for a given $\\varepsilon >0$, where  $\\Omega$ is compact, cf. Theorem \\ref{thm:mainresult}. See Figure \\ref{fig:domains} for a sketch of these domains.\n\nFor the approximation of $V$, we define $\\tilde\\Omega_V := \\{x\\in A(\\overline{x}) \\mid V(x) \\le R\\}$  with $R>0$ large enough so that $\\Omega \\subset\\tilde\\Omega_V$. Similarly for $T$, we choose $\\tilde\\Omega_T := \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid T(x) \\le R\\}$ with $R>0$ large enough so that $\\Omega \\subset\\tilde\\Omega_T$.\n\nRecall that $\\Gamma$ is a non-characteristic hypersurface for $f^*$ (and thus also for $f_{\\mathbf{z},\\lambda}$, if $f_{\\mathbf{z},\\lambda}$ and $f^*$ are sufficiently close in supremum norm). Additionally, we may define $\\tilde\\Gamma:= \\varphi_{f^*}(T,\\Gamma)$ with $T>0$ sufficiently large so that $\\tilde\\Gamma\\subset B_\\varepsilon(\\overline{x})$.\n\n Note that $\\tilde\\Gamma$ is  a non-characteristic hypersurface for $f^*$ (also for $f_{\\mathbf{z},\\lambda}$), defined by some $\\tilde{h}\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$. Then we define the Lipschitz domains ${\\Omega}_V:=\\tilde\\Omega_V\\cap\\{x\\in A(\\overline{x})\\mid \\tilde{h}(x)\\ge 0\\}$ and ${\\Omega}_T:=\\tilde\\Omega_T\\cap\\{x\\in A(\\overline{x})\\mid \\tilde{h}(x)\\ge 0\\}$ (cf. Theorem \\ref{thm:GieWen}), and note that $\\mathcal{D}\\subset\\Omega_V$ and $\\mathcal{D}\\subset\\Omega_T$. Also note that all orbits (for $f^*$ and $f_{\\mathbf{z},\\lambda}$) enter and exit ${\\Omega}_V$ (and ${\\Omega}_T$) only once.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur algorithm detailed in \\S\\ref{sec:algorithm} computes the generalised interpolant approximations $\\hat{V}$ and $\\hat{T}$ corresponding to the vector field approximation $f_{\\mathbf{z},\\lambda}$ (as in Theorem \\ref{thm:GieWen} with $g = f_{\\mathbf{z},\\lambda}$).\n\n\n\n\n\nNote that for    $\\max_k\\left(||f^k_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^\\infty(X)}\\right)$ sufficiently small (recall the superscript $k$ denotes the $k$-th component), $f_{\\mathbf{z},\\lambda}$ does not have any equilibria in $\\Omega_V$ (resp. $\\Omega_T$). Similarly,  $\\Gamma, \\tilde{\\Gamma}$ are both non-characteristic hypersurfaces for $f_{\\mathbf{z},\\lambda}$, and  all trajectories in  $\\Omega_V$ (resp. $\\Omega_T$) eventually enter (and stay in) the region defined by $\\{x\\in A(\\overline{x}) \\mid \\tilde{h}(x) <0\\}$.\n\n\nIn fact, for $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, $f_{\\mathbf{z},\\lambda}$ and $f^*$ are even close in a $C^{\\nu_2}$ sense, as we will show in the following Lemmas \\ref{lem:fzlambdafstarbounded} and \\ref{lem:fzlambdafstarepsilon}.\n\n\n\n\\begin{lemma}\t\t\t\\label{lem:fzlambdafstarbounded}\nFor $\\lambda >0$, for every $0<\\delta<1$, with probability $1-\\delta$, we have\n\n", "itemtype": "equation", "pos": 58926, "prevtext": "\nLet $y = \\varphi_{f^*}(\\theta_{f^*}(x),x) \\in \\Gamma$. Then, for $x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\}$,\n\\begin{eqnarray*}\nV(x) & = &  \\int_{\\theta_{f^*}(x)}^\\infty p(\\varphi_{f^*}(\\tau,x))d\\tau + \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau\\\\\n\n& = & \\int_{0}^\\infty p(\\varphi_{f^*}(\\overline\\tau ,y))d\\overline\\tau + \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau \\qquad\\text{(using $\\overline{\\tau} = \\tau - \\theta_{f^*}(x)$)}\\\\\n& = & \\xi_V(y) +  \\int_0^{\\theta_{f^*}(x)} p(\\varphi_{f^*}(\\tau,x))d\\tau\n\\end{eqnarray*}\nwhich proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\\begin{remark}\t\t\t\t\t\t\\label{rem:xiT}\nSimilarly, the Lyapunov function $T$ has the representation\n\n", "index": 85, "text": "\\begin{equation*}\nT(x) = \\xi_T(\\varphi_{f^*}(\\theta_{f^*}(x),x)) + \\overline{c}\\,\\theta_{f^*}(x),\\qquad x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\},\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"T(x)=\\xi_{T}(\\varphi_{f^{*}}(\\theta_{f^{*}}(x),x))+\\overline{c}\\,\\theta_{f^{*}%&#10;}(x),\\qquad x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\},\" display=\"block\"><mrow><mrow><mrow><mrow><mi>T</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03be</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03c6</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03b8</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>c</mi><mo>\u00af</mo></mover></mpadded><mo>\u2062</mo><msub><mi>\u03b8</mi><msup><mi>f</mi><mo>*</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>x</mi><mo>\u2208</mo><mrow><mrow><mi>A</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\\</mo><mrow><mo stretchy=\"false\">{</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\\end{lemma}\n\\begin{proof}\nFrom Lemma \\ref{lem:fzlambda} and equation \\eqref{eq:fxlambda}, we see that for each $k=1,\\ldots,d$:\n\n", "itemtype": "equation", "pos": 62047, "prevtext": "\nwith $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ as above.\n\\end{remark}\n\nWe  aim to approximate the Lyapunov functions $V$ and $T$ in a compact subset of the basin of attraction $A(\\overline{x})$. This subset is given by $\\mathcal{D}:=\\Omega\\setminus B_\\varepsilon(\\overline{x})$ for a given $\\varepsilon >0$, where  $\\Omega$ is compact, cf. Theorem \\ref{thm:mainresult}. See Figure \\ref{fig:domains} for a sketch of these domains.\n\nFor the approximation of $V$, we define $\\tilde\\Omega_V := \\{x\\in A(\\overline{x}) \\mid V(x) \\le R\\}$  with $R>0$ large enough so that $\\Omega \\subset\\tilde\\Omega_V$. Similarly for $T$, we choose $\\tilde\\Omega_T := \\{x\\in A(\\overline{x})\\backslash\\{\\overline{x}\\} \\mid T(x) \\le R\\}$ with $R>0$ large enough so that $\\Omega \\subset\\tilde\\Omega_T$.\n\nRecall that $\\Gamma$ is a non-characteristic hypersurface for $f^*$ (and thus also for $f_{\\mathbf{z},\\lambda}$, if $f_{\\mathbf{z},\\lambda}$ and $f^*$ are sufficiently close in supremum norm). Additionally, we may define $\\tilde\\Gamma:= \\varphi_{f^*}(T,\\Gamma)$ with $T>0$ sufficiently large so that $\\tilde\\Gamma\\subset B_\\varepsilon(\\overline{x})$.\n\n Note that $\\tilde\\Gamma$ is  a non-characteristic hypersurface for $f^*$ (also for $f_{\\mathbf{z},\\lambda}$), defined by some $\\tilde{h}\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$. Then we define the Lipschitz domains ${\\Omega}_V:=\\tilde\\Omega_V\\cap\\{x\\in A(\\overline{x})\\mid \\tilde{h}(x)\\ge 0\\}$ and ${\\Omega}_T:=\\tilde\\Omega_T\\cap\\{x\\in A(\\overline{x})\\mid \\tilde{h}(x)\\ge 0\\}$ (cf. Theorem \\ref{thm:GieWen}), and note that $\\mathcal{D}\\subset\\Omega_V$ and $\\mathcal{D}\\subset\\Omega_T$. Also note that all orbits (for $f^*$ and $f_{\\mathbf{z},\\lambda}$) enter and exit ${\\Omega}_V$ (and ${\\Omega}_T$) only once.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur algorithm detailed in \\S\\ref{sec:algorithm} computes the generalised interpolant approximations $\\hat{V}$ and $\\hat{T}$ corresponding to the vector field approximation $f_{\\mathbf{z},\\lambda}$ (as in Theorem \\ref{thm:GieWen} with $g = f_{\\mathbf{z},\\lambda}$).\n\n\n\n\n\nNote that for    $\\max_k\\left(||f^k_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^\\infty(X)}\\right)$ sufficiently small (recall the superscript $k$ denotes the $k$-th component), $f_{\\mathbf{z},\\lambda}$ does not have any equilibria in $\\Omega_V$ (resp. $\\Omega_T$). Similarly,  $\\Gamma, \\tilde{\\Gamma}$ are both non-characteristic hypersurfaces for $f_{\\mathbf{z},\\lambda}$, and  all trajectories in  $\\Omega_V$ (resp. $\\Omega_T$) eventually enter (and stay in) the region defined by $\\{x\\in A(\\overline{x}) \\mid \\tilde{h}(x) <0\\}$.\n\n\nIn fact, for $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, $f_{\\mathbf{z},\\lambda}$ and $f^*$ are even close in a $C^{\\nu_2}$ sense, as we will show in the following Lemmas \\ref{lem:fzlambdafstarbounded} and \\ref{lem:fzlambdafstarepsilon}.\n\n\n\n\\begin{lemma}\t\t\t\\label{lem:fzlambdafstarbounded}\nFor $\\lambda >0$, for every $0<\\delta<1$, with probability $1-\\delta$, we have\n\n", "index": 87, "text": "\\begin{equation}\t\t\\label{eq:fzlambdafstarbounded}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{K^1} \\le \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}\\sigma\\kappa}{\\lambda\\sqrt{\\delta}} + 2 ||f^{*,k}||_{K^1},\\qquad k=1,\\ldots,d.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"||f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}||_{K^{1}}\\leq\\frac{||\\mathbf{w}||_{%&#10;\\mathbb{R}^{m}}\\sigma\\kappa}{\\lambda\\sqrt{\\delta}}+2||f^{*,k}||_{K^{1}},\\qquad&#10;k%&#10;=1,\\ldots,d.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub><mo>\u2264</mo><mrow><mfrac><mrow><msub><mrow><mo fence=\"true\">||</mo><mi>\ud835\udc30</mi><mo fence=\"true\">||</mo></mrow><msup><mi>\u211d</mi><mi>m</mi></msup></msub><mo>\u2062</mo><mi>\u03c3</mi><mo>\u2062</mo><mi>\u03ba</mi></mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><msqrt><mi>\u03b4</mi></msqrt></mrow></mfrac><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>k</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>d</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nWe will show that $||f^k_{\\mathbf{x},\\lambda}||_{K^1}$ is bounded independently of $(\\mathbf{x},\\lambda)$. To see this, first note that due to the choice of the positive definite Wendland function kernel $K^1$, that it is always possible to find a norm-minimal function $g^k_0\\in\\mathcal{H}_{K^1}$ that interpolates the data. That is, $g^k_0$ is the solution to the problem\n\n", "itemtype": "equation", "pos": 62403, "prevtext": "\n\n\\end{lemma}\n\\begin{proof}\nFrom Lemma \\ref{lem:fzlambda} and equation \\eqref{eq:fxlambda}, we see that for each $k=1,\\ldots,d$:\n\n", "index": 89, "text": "\\begin{equation}\t\t\t\\label{eq:fkxlambda}\nf^k_{\\mathbf{x},\\lambda}=\\arg\\min_{g\\in\\mathcal{H}_{K^1}}\\left\\{ \\sum_{i=1}^m w_{x_i}(g(x_i)-f^{*,k}(x_i))^2 + \\lambda||g||^2_{K^1}\\right\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"f^{k}_{\\mathbf{x},\\lambda}=\\arg\\min_{g\\in\\mathcal{H}_{K^{1}}}\\left\\{\\sum_{i=1}%&#10;^{m}w_{x_{i}}(g(x_{i})-f^{*,k}(x_{i}))^{2}+\\lambda||g||^{2}_{K^{1}}\\right\\}.\" display=\"block\"><mrow><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc31</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>=</mo><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mrow><mi>g</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><msup><mi>K</mi><mn>1</mn></msup></msub></mrow></munder><mo>\u2061</mo><mrow><mo>{</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><msub><mi>w</mi><msub><mi>x</mi><mi>i</mi></msub></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">||</mo><mi>g</mi><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup><mn>2</mn></msubsup></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nTherefore we have that $||g^k_0||_{K^1} \\le ||f^{*,k}||_{K^1}$. Now from \\eqref{eq:fkxlambda} we have the following:\n\\begin{eqnarray*}\n\\lambda || f^k_{\\mathbf{x},\\lambda} ||^2_{K^1} & \\le & \\sum_{i=1}^m w_{x_i}( f^k_{\\mathbf{x},\\lambda}(x_i)-f^{*,k}(x_i))^2 + \\lambda|| f^k_{\\mathbf{x},\\lambda}||^2_{K^1}\\\\\n& \\le & \\sum_{i=1}^m w_{x_i}(g^k_0(x_i)-f^{*,k}(x_i))^2 + \\lambda||g^k_0||^2_{K^1}\\\\\n& = & \\lambda ||g^k_0||^2_{K^1}\\\\\n& \\le & \\lambda ||f^{*,k}||_{K^1}^2\n\\end{eqnarray*}\nSo then $|| f^k_{\\mathbf{x},\\lambda} - f^{*,k} ||_{K^1} \\le || f^k_{\\mathbf{x},\\lambda}||_{K^1} + ||f^{*,k}||_{K^1} \\le 2 ||f^{*,k}||_{K^1}$.\n\nIn Lemma \\ref{lem:sampleerror} we have provided a bound for $|| f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1}$ for a given probability $1 - \\delta$. Then together we find with probability $1 - \\delta$,\n\\begin{eqnarray*}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{K^1} & \\le & ||f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1} + ||f^k_{\\mathbf{x},\\lambda} - f^{*,k}||_{K^1} \\\\\n& \\le & \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}\\sigma\\kappa}{\\lambda\\sqrt{\\delta}} + 2 ||f^{*,k}||_{K^1}\n\\end{eqnarray*}\nwhich proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nWe will need the following convergence result in Lemma \\ref{lem:fzlambdafstarepsilon}.\n\n\\begin{theorem}[\\cite{WenRie05}]\t\t\\label{thm:WenRie}\nSuppose $X\\subseteq\\mathbb{R}^d$ is bounded and satisfies an interior cone condition with radius $r$ and angle $\\theta$. Let $\\tilde\\tau$ be a positive integer, $0< s \\le 1$, $1\\le p < \\infty$, $1 \\le q \\le \\infty$ and let $m\\in\\mathbb{N}_0$ satisfy $\\tilde\\tau > m+d/p$, or, if $p=1$, $\\tilde\\tau\\ge m+d$. Then there exists a constant $C>0$ depending only on $\\tilde\\tau,d,p,q,m,\\theta$  such that every discrete set $\\Pi\\subseteq\\Omega$ with mesh norm $h_{\\Pi}$ sufficiently small, and every $u\\in W_p^{\\tilde\\tau+s}(X)$ the estimate\n\n", "itemtype": "equation", "pos": 62973, "prevtext": "\nWe will show that $||f^k_{\\mathbf{x},\\lambda}||_{K^1}$ is bounded independently of $(\\mathbf{x},\\lambda)$. To see this, first note that due to the choice of the positive definite Wendland function kernel $K^1$, that it is always possible to find a norm-minimal function $g^k_0\\in\\mathcal{H}_{K^1}$ that interpolates the data. That is, $g^k_0$ is the solution to the problem\n\n", "index": 91, "text": "\\begin{equation*}\n\\min_{g\\in\\mathcal{H}_{K^1}}\\left\\{||g||_{K^1}~:~ g(x_i) = f^{*,k}(x_i),~i=1,\\ldots,m\\right\\}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m1\" class=\"ltx_Math\" alttext=\"\\min_{g\\in\\mathcal{H}_{K^{1}}}\\left\\{||g||_{K^{1}}~{}:~{}g(x_{i})=f^{*,k}(x_{i%&#10;}),~{}i=1,\\ldots,m\\right\\}.\" display=\"block\"><mrow><mrow><munder><mi>min</mi><mrow><mi>g</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><msup><mi>K</mi><mn>1</mn></msup></msub></mrow></munder><mo>\u2061</mo><mrow><mo>{</mo><mrow><mpadded width=\"+3.3pt\"><msub><mrow><mo fence=\"true\">||</mo><mi>g</mi><mo fence=\"true\">||</mo></mrow><msup><mi>K</mi><mn>1</mn></msup></msub></mpadded><mo rspace=\"5.8pt\">:</mo><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"5.8pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>m</mi></mrow></mrow></mrow></mrow><mo>}</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nis satisfied. Here, $(x)_+ = \\max\\{x,0\\}$, and we use the notation $u|\\Pi$ to denote the restriction of $u$ to the set $\\Pi$.\n\n\n\n\n\n\n\n\n\\end{theorem}\n\n\n\n\\begin{lemma} \t\t\t\\label{lem:fzlambdafstarepsilon}\nLet $\\varepsilon >0$ be arbitrarily small. For every $0 < \\delta < 1$, there exists $\\iota >0$ such that when\n$||\\mathbf{w}||_{\\mathbb{R}^m}, h_{\\mathbf{x}} <\\iota$, and $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}, the following estimate holds with probability $1-\\delta$:\n\\begin{eqnarray*}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{C^{\\nu_2}(X)}& <& \\varepsilon,\\qquad k=1,\\ldots,d,\n\\end{eqnarray*}\nwhere $\\nu_2:= \\lceil\\tau_2\\rceil = k_1-(d+3)/2$  ($d$  odd), and $\\nu_2:= \\lceil\\tau_2\\rceil = k_1-(d+4)/2$ ($d$ even).\n \\end{lemma}\n\\begin{proof}\nNote that since $X$ has a $C^1$ boundary, it satisfies the interior cone condition from Theorem~\\ref{thm:WenRie} (see \\cite[Definition 3.6]{Wen05}).\nLet $j\\in\\mathbb{N}_0$ be such that $j\\le k_1 - 1$.\nRecall that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil\\tau_1\\rceil = \\nu_1$. Then when $d$ is odd, we have $j < \\tau_1 - 1 - d/2$. When $d$ is even, we have $\\lfloor\\tau_1\\rfloor - d/2 = k_1$ and so $j < \\lfloor\\tau_1\\rfloor - d/2$.\n\n\n\nUsing Theorem \\ref{thm:WenRie}, and the fact that $\\mathcal{H}_{K^1}$ and $W_2^{\\tau_1}$ are norm-equivalent, we have the following estimate:\n\n", "itemtype": "equation", "pos": 65041, "prevtext": "\nTherefore we have that $||g^k_0||_{K^1} \\le ||f^{*,k}||_{K^1}$. Now from \\eqref{eq:fkxlambda} we have the following:\n\\begin{eqnarray*}\n\\lambda || f^k_{\\mathbf{x},\\lambda} ||^2_{K^1} & \\le & \\sum_{i=1}^m w_{x_i}( f^k_{\\mathbf{x},\\lambda}(x_i)-f^{*,k}(x_i))^2 + \\lambda|| f^k_{\\mathbf{x},\\lambda}||^2_{K^1}\\\\\n& \\le & \\sum_{i=1}^m w_{x_i}(g^k_0(x_i)-f^{*,k}(x_i))^2 + \\lambda||g^k_0||^2_{K^1}\\\\\n& = & \\lambda ||g^k_0||^2_{K^1}\\\\\n& \\le & \\lambda ||f^{*,k}||_{K^1}^2\n\\end{eqnarray*}\nSo then $|| f^k_{\\mathbf{x},\\lambda} - f^{*,k} ||_{K^1} \\le || f^k_{\\mathbf{x},\\lambda}||_{K^1} + ||f^{*,k}||_{K^1} \\le 2 ||f^{*,k}||_{K^1}$.\n\nIn Lemma \\ref{lem:sampleerror} we have provided a bound for $|| f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1}$ for a given probability $1 - \\delta$. Then together we find with probability $1 - \\delta$,\n\\begin{eqnarray*}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{K^1} & \\le & ||f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1} + ||f^k_{\\mathbf{x},\\lambda} - f^{*,k}||_{K^1} \\\\\n& \\le & \\frac{||\\mathbf{w}||_{\\mathbb{R}^m}\\sigma\\kappa}{\\lambda\\sqrt{\\delta}} + 2 ||f^{*,k}||_{K^1}\n\\end{eqnarray*}\nwhich proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\nWe will need the following convergence result in Lemma \\ref{lem:fzlambdafstarepsilon}.\n\n\\begin{theorem}[\\cite{WenRie05}]\t\t\\label{thm:WenRie}\nSuppose $X\\subseteq\\mathbb{R}^d$ is bounded and satisfies an interior cone condition with radius $r$ and angle $\\theta$. Let $\\tilde\\tau$ be a positive integer, $0< s \\le 1$, $1\\le p < \\infty$, $1 \\le q \\le \\infty$ and let $m\\in\\mathbb{N}_0$ satisfy $\\tilde\\tau > m+d/p$, or, if $p=1$, $\\tilde\\tau\\ge m+d$. Then there exists a constant $C>0$ depending only on $\\tilde\\tau,d,p,q,m,\\theta$  such that every discrete set $\\Pi\\subseteq\\Omega$ with mesh norm $h_{\\Pi}$ sufficiently small, and every $u\\in W_p^{\\tilde\\tau+s}(X)$ the estimate\n\n", "index": 93, "text": "\\begin{equation}\n|u|_{W_q^m(X)} \\le C\\left( h_\\Pi^{\\tilde\\tau+s-m-d(1/p - 1/q)_+} |u|_{W_p^{\\tilde\\tau+s}(X)} + h_{\\Pi}^{-m}||u|\\Pi||_{l^\\infty(\\Pi)}\\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"|u|_{W_{q}^{m}(X)}\\leq C\\left(h_{\\Pi}^{\\tilde{\\tau}+s-m-d(1/p-1/q)_{+}}|u|_{W_%&#10;{p}^{\\tilde{\\tau}+s}(X)}+h_{\\Pi}^{-m}||u|\\Pi||_{l^{\\infty}(\\Pi)}\\right)\" display=\"block\"><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mi>u</mi><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mi>q</mi><mi>m</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msubsup><mi>h</mi><mi mathvariant=\"normal\">\u03a0</mi><mrow><mrow><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">~</mo></mover><mo>+</mo><mi>s</mi></mrow><mo>-</mo><mi>m</mi><mo>-</mo><mrow><mi>d</mi><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mi>q</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo></msub></mrow></mrow></msubsup><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">|</mo><mi>u</mi><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mi>p</mi><mrow><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">~</mo></mover><mo>+</mo><mi>s</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>+</mo><msub><mrow><mrow><msubsup><mi>h</mi><mi mathvariant=\"normal\">\u03a0</mi><mrow><mo>-</mo><mi>m</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mi>u</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u03a0</mi></mrow><mo stretchy=\"false\">|</mo></mrow></mrow><mo fence=\"true\" stretchy=\"false\">|</mo></mrow><mrow><msup><mi>l</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a0</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nNote that we have replaced $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}|\\Pi||_{l^\\infty(\\Pi)}$ in Theorem \\ref{thm:WenRie} with $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$. Then the discrete set $\\Pi$ from Theorem \\ref{thm:WenRie} may be taken to be any discrete set in $X$, and so the fill distance $h_{\\Pi}$ in the above can be taken to be arbitrarily small.\n\nNow, from \\eqref{eqn:fzlambdaestnolambda} we see that $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$\n\n\n\n\n\n\n can be made arbitrarily small for small $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$, and suitably chosen $\\lambda>0$ as in \\eqref{eqn:lambdachoice}. The estimate \\eqref{eqn:fzlambdaestnolambda}  holds with probability $1-\\delta$ (for $0<\\delta<1$), where $\\delta$ here is the same as in Lemma \\ref{lem:fzlambdafstarbounded}, as the estimate depends on the same probabilistic inequality for $||f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1}$ (cf. \\eqref{eq:sampleerror}).\nThen we have from \\eqref{eq:fzlambdafstarbounded} (and using again the norm-equivalance of $\\mathcal{H}_{K^1}$ and $W_2^{\\tau_1}$), that $ |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^{\\tau_1}(X)}$ is bounded, say $ |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^{\\tau_1}(X)} \\le \\tilde{C}/k_1$.\n\nNow, given $\\tilde\\varepsilon>0$, setting\n\n", "itemtype": "equation", "pos": 66547, "prevtext": "\nis satisfied. Here, $(x)_+ = \\max\\{x,0\\}$, and we use the notation $u|\\Pi$ to denote the restriction of $u$ to the set $\\Pi$.\n\n\n\n\n\n\n\n\n\\end{theorem}\n\n\n\n\\begin{lemma} \t\t\t\\label{lem:fzlambdafstarepsilon}\nLet $\\varepsilon >0$ be arbitrarily small. For every $0 < \\delta < 1$, there exists $\\iota >0$ such that when\n$||\\mathbf{w}||_{\\mathbb{R}^m}, h_{\\mathbf{x}} <\\iota$, and $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}, the following estimate holds with probability $1-\\delta$:\n\\begin{eqnarray*}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{C^{\\nu_2}(X)}& <& \\varepsilon,\\qquad k=1,\\ldots,d,\n\\end{eqnarray*}\nwhere $\\nu_2:= \\lceil\\tau_2\\rceil = k_1-(d+3)/2$  ($d$  odd), and $\\nu_2:= \\lceil\\tau_2\\rceil = k_1-(d+4)/2$ ($d$ even).\n \\end{lemma}\n\\begin{proof}\nNote that since $X$ has a $C^1$ boundary, it satisfies the interior cone condition from Theorem~\\ref{thm:WenRie} (see \\cite[Definition 3.6]{Wen05}).\nLet $j\\in\\mathbb{N}_0$ be such that $j\\le k_1 - 1$.\nRecall that $\\tau_1 = k_1 + (d+1)/2$ with $\\lceil\\tau_1\\rceil = \\nu_1$. Then when $d$ is odd, we have $j < \\tau_1 - 1 - d/2$. When $d$ is even, we have $\\lfloor\\tau_1\\rfloor - d/2 = k_1$ and so $j < \\lfloor\\tau_1\\rfloor - d/2$.\n\n\n\nUsing Theorem \\ref{thm:WenRie}, and the fact that $\\mathcal{H}_{K^1}$ and $W_2^{\\tau_1}$ are norm-equivalent, we have the following estimate:\n\n", "index": 95, "text": "\\begin{equation*}\n|f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^j(X)} \\le C\\left( h_{\\Pi}^{\\tau_1-j} |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^{\\tau_1}(X)} + h_{\\Pi}^{-j}||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}\\right).\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m1\" class=\"ltx_Math\" alttext=\"|f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}|_{W_{2}^{j}(X)}\\leq C\\left(h_{\\Pi}^{\\tau_{%&#10;1}-j}|f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}|_{W_{2}^{\\tau_{1}}(X)}+h_{\\Pi}^{-j}||%&#10;f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^{\\infty}(X)}\\right).\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><mi>j</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msubsup><mi>h</mi><mi mathvariant=\"normal\">\u03a0</mi><mrow><msub><mi>\u03c4</mi><mn>1</mn></msub><mo>-</mo><mi>j</mi></mrow></msubsup><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">|</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><msub><mi>\u03c4</mi><mn>1</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>+</mo><mrow><msubsup><mi>h</mi><mi mathvariant=\"normal\">\u03a0</mi><mrow><mo>-</mo><mi>j</mi></mrow></msubsup><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwe have that\n\n\n\n\n\n", "itemtype": "equation", "pos": 68096, "prevtext": "\nNote that we have replaced $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}|\\Pi||_{l^\\infty(\\Pi)}$ in Theorem \\ref{thm:WenRie} with $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$. Then the discrete set $\\Pi$ from Theorem \\ref{thm:WenRie} may be taken to be any discrete set in $X$, and so the fill distance $h_{\\Pi}$ in the above can be taken to be arbitrarily small.\n\nNow, from \\eqref{eqn:fzlambdaestnolambda} we see that $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$\n\n\n\n\n\n\n can be made arbitrarily small for small $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$, and suitably chosen $\\lambda>0$ as in \\eqref{eqn:lambdachoice}. The estimate \\eqref{eqn:fzlambdaestnolambda}  holds with probability $1-\\delta$ (for $0<\\delta<1$), where $\\delta$ here is the same as in Lemma \\ref{lem:fzlambdafstarbounded}, as the estimate depends on the same probabilistic inequality for $||f^k_{\\mathbf{z},\\lambda} - f^k_{\\mathbf{x},\\lambda}||_{K^1}$ (cf. \\eqref{eq:sampleerror}).\nThen we have from \\eqref{eq:fzlambdafstarbounded} (and using again the norm-equivalance of $\\mathcal{H}_{K^1}$ and $W_2^{\\tau_1}$), that $ |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^{\\tau_1}(X)}$ is bounded, say $ |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^{\\tau_1}(X)} \\le \\tilde{C}/k_1$.\n\nNow, given $\\tilde\\varepsilon>0$, setting\n\n", "index": 97, "text": "\\begin{equation*}\n||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}  <  \\frac{\\tilde{C}}{k_1}\\left(\\frac{\\tilde\\varepsilon}{2C\\tilde{C}}\\right)^{\\frac{\\tau_1}{\\tau_1 - j}}\n\\qquad\\text{and}\\qquad h_{\\Pi}  <  \\left(\\frac{\\tilde\\varepsilon}{2 C \\tilde{C}}\\right)^{\\frac{1}{\\tau_1 - j}},\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m1\" class=\"ltx_Math\" alttext=\"||f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^{\\infty}(X)}&lt;\\frac{\\tilde{C}}{k_{1}}%&#10;\\left(\\frac{\\tilde{\\varepsilon}}{2C\\tilde{C}}\\right)^{\\frac{\\tau_{1}}{\\tau_{1}%&#10;-j}}\\qquad\\text{and}\\qquad h_{\\Pi}&lt;\\left(\\frac{\\tilde{\\varepsilon}}{2C\\tilde{C%&#10;}}\\right)^{\\frac{1}{\\tau_{1}-j}},\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>&lt;</mo><mrow><mrow><mfrac><mover accent=\"true\"><mi>C</mi><mo stretchy=\"false\">~</mo></mover><msub><mi>k</mi><mn>1</mn></msub></mfrac><mo>\u2062</mo><msup><mrow><mo>(</mo><mfrac><mover accent=\"true\"><mi>\u03b5</mi><mo stretchy=\"false\">~</mo></mover><mrow><mn>2</mn><mo>\u2062</mo><mi>C</mi><mo>\u2062</mo><mover accent=\"true\"><mi>C</mi><mo stretchy=\"false\">~</mo></mover></mrow></mfrac><mo>)</mo></mrow><mfrac><msub><mi>\u03c4</mi><mn>1</mn></msub><mrow><msub><mi>\u03c4</mi><mn>1</mn></msub><mo>-</mo><mi>j</mi></mrow></mfrac></msup></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><msub><mi>h</mi><mi mathvariant=\"normal\">\u03a0</mi></msub><mo>&lt;</mo><msup><mrow><mo>(</mo><mfrac><mover accent=\"true\"><mi>\u03b5</mi><mo stretchy=\"false\">~</mo></mover><mrow><mn>2</mn><mo>\u2062</mo><mi>C</mi><mo>\u2062</mo><mover accent=\"true\"><mi>C</mi><mo stretchy=\"false\">~</mo></mover></mrow></mfrac><mo>)</mo></mrow><mfrac><mn>1</mn><mrow><msub><mi>\u03c4</mi><mn>1</mn></msub><mo>-</mo><mi>j</mi></mrow></mfrac></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nNow using $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)} = \\sum_{j=0}^{k_1-1} |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^j(X)}$ gives the bound $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)} \\allowbreak  \\le \\tilde\\varepsilon.$\nThen by Lemma \\ref{lem:genSobolev} (also using arguments similar to  Corollary \\ref{cor:smoothnessK1K2} since $X$ is closed), we have that  $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{C^{\\nu_2}(X)} \\le C ||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)}$ and setting $\\varepsilon = C\\tilde\\varepsilon$ proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt follows that for sufficiently small $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$, that (with probability $1-\\delta$) $f_{\\mathbf{z},\\lambda}$ will have an equilibrium close to $\\overline{x}$ which is also exponentially asymptotically stable. In addition, the non-characteristic hypersurfaces $\\Gamma$ and $\\tilde{\\Gamma}$ for $f^*$ will also be non-characteristic hypersurfaces for $f_{\\mathbf{z},\\lambda}$ (as will the level sets $\\{x\\in A(\\overline{x})\\mid V(x)=R\\}$, resp. $\\{x\\in A(\\overline{x})\\mid T(x)=R\\}$). In this case we can define the following `Lyapunov-type' functions for $f_{\\mathbf{z},\\lambda}$.\n\n\n\n\n\n\n\\begin{definition}\t\t\t\t\\label{def:VzlambdaTzlambda}\nLet $\\varphi_{\\mathbf{z},\\lambda}(t,\\cdot)$ denote the flow operator for the system $\\dot{x} = f_{\\mathbf{z},\\lambda}(x)$. For $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}, and $0<\\delta<1$,  $\\Gamma$ will be a non-characteristic hypersurface for $f_{\\mathbf{z},\\lambda}$ with probability $1-\\delta$.\nThen the function $\\theta_{{\\mathbf{z},\\lambda}}:\\Omega_V\\rightarrow \\mathbb{R}$\ngiven by $\\varphi_{\n{\\mathbf{z},\\lambda}}(t,x) \\in \\Gamma \\Leftrightarrow t = \\theta_{{\\mathbf{z},\\lambda}}(x)$ is well-defined. By a slight abuse of notation we will also similarly define $\\theta_{{\\mathbf{z},\\lambda}}: \\Omega_T\\rightarrow\\mathbb{R}$.\n\nWe define the functions $V_{\\mathbf{z},\\lambda}: \\Omega_V\\rightarrow\\mathbb{R}$ and $T_{\\mathbf{z},\\lambda}: \\Omega_T\\rightarrow\\mathbb{R}$\n\nby\n\\begin{eqnarray}\nV_{\\mathbf{z},\\lambda}(x) & = & \\xi_V(\\varphi_{{\\mathbf{z},\\lambda}}(\\theta_{{\\mathbf{z},\\lambda}}(x),x)) + \\int_0^{\\theta_{{\\mathbf{z},\\lambda}}(x)} p(\\varphi_{{\\mathbf{z},\\lambda}}(\\tau ,x))d\\tau,\\qquad x\\in \\Omega_V,\\label{eqn:Vzlambda}\\\\\nT_{\\mathbf{z},\\lambda}(x) & = & \\xi_T(\\varphi_{{\\mathbf{z},\\lambda}}(\\theta_{{\\mathbf{z},\\lambda}}(x),x)) + \\overline{c}\\, \\theta_{{\\mathbf{z},\\lambda}}(x),\\qquad x\\in \\Omega_T,\t\t\t\\label{eqn:Tzlambda}\n\\end{eqnarray}\nwhere $\\xi_V\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ and $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ are as in Lemma \\ref{lem:VxiV} and equation \\eqref{eq:TxiT} respectively.\n\n\\end{definition}\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the proof of the following Lemma we show that in fact $\\theta_{\\mathbf{z},\\lambda}  \\in C^{\\nu_2}(\\Omega_V\\cup\\Omega_T,\\mathbb{R})$, $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$ and $T_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_T,\\mathbb{R})$ .\n\\begin{lemma}\t\t\t\t\t\\label{lem:Vzlambdabounded}\nFor every $\\varepsilon_1 >0$, and every $0 < \\delta < 1$, there is  $\\varepsilon_2 >0$ such that if $\\max\\left\\{||\\mathbf{w}||_{\\mathbb{R}^m}, h_{\\mathbf{x}}\\right\\} < \\varepsilon_2$ and  $\\lambda>0$ is chosen according to \\eqref{eqn:lambdachoice}, then we have with probability $1 - \\delta$:\n\\begin{eqnarray*}\n||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}(\\Omega_V)} < \\varepsilon_1,\\\\\n||T_{\\mathbf{z},\\lambda} - T ||_{C^{\\nu_2}(\\Omega_T)} < \\varepsilon_1.\n\\end{eqnarray*}\n\\end{lemma}\n\\begin{proof} We will prove the result for $V_{\\mathbf{z},\\lambda}$, as the proof for $T_{\\mathbf{z},\\lambda}$ is similar.\nWe will show that $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$, and $||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}(\\Omega_V)}$ can be made arbitrarily small as $||f_{\\mathbf{z},\\lambda} - f^* ||_{C^{\\nu_2}(\\Omega_V)}\\rightarrow 0$. Then the result will follow from Lemma \\ref{lem:fzlambdafstarepsilon}. The proof follows the ideas contained in \\cite[Theorem 2.38]{Gie07:a}.\n\nWe consider a one-parameter family of vector fields ${f}(\\cdot,\\mu)$, $\\mu\\in\\mathbb{R}$, in the $C^{\\nu_2}$ topology such that ${f}(\\cdot,0) = f^*$. Let $\\varphi(t,\\cdot,\\mu)$ denote the corresponding one-parameter family of flow operators and note that $\\varphi$ is $C^{\\nu_2}$ in each of its arguments. For $\\varepsilon>0$ sufficiently small, $|\\mu|<\\varepsilon$,  $\\Gamma$ is a non-characteristic hypersurface for each $f(\\cdot,\\mu)$, and  all orbits of $f(\\cdot,\\mu)$ in $\\Omega_V$ enter and exit $\\Omega_V$ precisely once. Then we define the one-parameter family of functions $\\theta(\\cdot,\\mu) :\\Omega_V\\rightarrow\\mathbb{R}$ by $\\varphi(t,x,\\mu) \\in \\Gamma \\Leftrightarrow t = \\theta(x,\\mu)$. We show that $\\theta\\in C^{\\nu_2}(\\Omega_V\\times[-\\varepsilon,\\varepsilon],\\mathbb{R})$ by the implicit function theorem. Note that $\\theta$ is the solution $t$ to\n\n", "itemtype": "equation", "pos": 68416, "prevtext": "\nwe have that\n\n\n\n\n\n", "index": 99, "text": "\\begin{equation*}\n|f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^j(X)}  \\le \\frac{\\tilde\\varepsilon}{k_1}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m1\" class=\"ltx_Math\" alttext=\"|f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}|_{W_{2}^{j}(X)}\\leq\\frac{\\tilde{%&#10;\\varepsilon}}{k_{1}}.\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><mi>j</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mfrac><mover accent=\"true\"><mi>\u03b5</mi><mo stretchy=\"false\">~</mo></mover><msub><mi>k</mi><mn>1</mn></msub></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nwhere $h$ is as in Definition \\ref{def:noncharhyp}. Let $(t^*,x^*,\\mu^*)$ be a solution to \\eqref{eq:implicittheta}. Then we have $ \\frac{d}{dt}F(t^*,x^*,\\mu^*) <0$\nby Definition \\ref{def:noncharhyp}. But since $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ and $\\varphi$ is a $C^{\\nu_2}$ function in $(x,t,\\mu)$, we have that $\\theta\\in C^{\\nu_2}(\\Omega_V\\times[-\\varepsilon,\\varepsilon],\\mathbb{R})$ by the implicit function theorem.\n\nFor each $\\mu$, define\n\n", "itemtype": "equation", "pos": 73519, "prevtext": "\nNow using $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)} = \\sum_{j=0}^{k_1-1} |f^k_{\\mathbf{z},\\lambda} - f^{*,k}|_{W_2^j(X)}$ gives the bound $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)} \\allowbreak  \\le \\tilde\\varepsilon.$\nThen by Lemma \\ref{lem:genSobolev} (also using arguments similar to  Corollary \\ref{cor:smoothnessK1K2} since $X$ is closed), we have that  $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{C^{\\nu_2}(X)} \\le C ||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{W_2^{k_1-1}(X)}$ and setting $\\varepsilon = C\\tilde\\varepsilon$ proves the Lemma.\n\\qquad\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt follows that for sufficiently small $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$, that (with probability $1-\\delta$) $f_{\\mathbf{z},\\lambda}$ will have an equilibrium close to $\\overline{x}$ which is also exponentially asymptotically stable. In addition, the non-characteristic hypersurfaces $\\Gamma$ and $\\tilde{\\Gamma}$ for $f^*$ will also be non-characteristic hypersurfaces for $f_{\\mathbf{z},\\lambda}$ (as will the level sets $\\{x\\in A(\\overline{x})\\mid V(x)=R\\}$, resp. $\\{x\\in A(\\overline{x})\\mid T(x)=R\\}$). In this case we can define the following `Lyapunov-type' functions for $f_{\\mathbf{z},\\lambda}$.\n\n\n\n\n\n\n\\begin{definition}\t\t\t\t\\label{def:VzlambdaTzlambda}\nLet $\\varphi_{\\mathbf{z},\\lambda}(t,\\cdot)$ denote the flow operator for the system $\\dot{x} = f_{\\mathbf{z},\\lambda}(x)$. For $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}, and $0<\\delta<1$,  $\\Gamma$ will be a non-characteristic hypersurface for $f_{\\mathbf{z},\\lambda}$ with probability $1-\\delta$.\nThen the function $\\theta_{{\\mathbf{z},\\lambda}}:\\Omega_V\\rightarrow \\mathbb{R}$\ngiven by $\\varphi_{\n{\\mathbf{z},\\lambda}}(t,x) \\in \\Gamma \\Leftrightarrow t = \\theta_{{\\mathbf{z},\\lambda}}(x)$ is well-defined. By a slight abuse of notation we will also similarly define $\\theta_{{\\mathbf{z},\\lambda}}: \\Omega_T\\rightarrow\\mathbb{R}$.\n\nWe define the functions $V_{\\mathbf{z},\\lambda}: \\Omega_V\\rightarrow\\mathbb{R}$ and $T_{\\mathbf{z},\\lambda}: \\Omega_T\\rightarrow\\mathbb{R}$\n\nby\n\\begin{eqnarray}\nV_{\\mathbf{z},\\lambda}(x) & = & \\xi_V(\\varphi_{{\\mathbf{z},\\lambda}}(\\theta_{{\\mathbf{z},\\lambda}}(x),x)) + \\int_0^{\\theta_{{\\mathbf{z},\\lambda}}(x)} p(\\varphi_{{\\mathbf{z},\\lambda}}(\\tau ,x))d\\tau,\\qquad x\\in \\Omega_V,\\label{eqn:Vzlambda}\\\\\nT_{\\mathbf{z},\\lambda}(x) & = & \\xi_T(\\varphi_{{\\mathbf{z},\\lambda}}(\\theta_{{\\mathbf{z},\\lambda}}(x),x)) + \\overline{c}\\, \\theta_{{\\mathbf{z},\\lambda}}(x),\\qquad x\\in \\Omega_T,\t\t\t\\label{eqn:Tzlambda}\n\\end{eqnarray}\nwhere $\\xi_V\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ and $\\xi_T\\in C^{\\nu_1}(\\Gamma,\\mathbb{R})$ are as in Lemma \\ref{lem:VxiV} and equation \\eqref{eq:TxiT} respectively.\n\n\\end{definition}\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the proof of the following Lemma we show that in fact $\\theta_{\\mathbf{z},\\lambda}  \\in C^{\\nu_2}(\\Omega_V\\cup\\Omega_T,\\mathbb{R})$, $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$ and $T_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_T,\\mathbb{R})$ .\n\\begin{lemma}\t\t\t\t\t\\label{lem:Vzlambdabounded}\nFor every $\\varepsilon_1 >0$, and every $0 < \\delta < 1$, there is  $\\varepsilon_2 >0$ such that if $\\max\\left\\{||\\mathbf{w}||_{\\mathbb{R}^m}, h_{\\mathbf{x}}\\right\\} < \\varepsilon_2$ and  $\\lambda>0$ is chosen according to \\eqref{eqn:lambdachoice}, then we have with probability $1 - \\delta$:\n\\begin{eqnarray*}\n||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}(\\Omega_V)} < \\varepsilon_1,\\\\\n||T_{\\mathbf{z},\\lambda} - T ||_{C^{\\nu_2}(\\Omega_T)} < \\varepsilon_1.\n\\end{eqnarray*}\n\\end{lemma}\n\\begin{proof} We will prove the result for $V_{\\mathbf{z},\\lambda}$, as the proof for $T_{\\mathbf{z},\\lambda}$ is similar.\nWe will show that $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$, and $||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}(\\Omega_V)}$ can be made arbitrarily small as $||f_{\\mathbf{z},\\lambda} - f^* ||_{C^{\\nu_2}(\\Omega_V)}\\rightarrow 0$. Then the result will follow from Lemma \\ref{lem:fzlambdafstarepsilon}. The proof follows the ideas contained in \\cite[Theorem 2.38]{Gie07:a}.\n\nWe consider a one-parameter family of vector fields ${f}(\\cdot,\\mu)$, $\\mu\\in\\mathbb{R}$, in the $C^{\\nu_2}$ topology such that ${f}(\\cdot,0) = f^*$. Let $\\varphi(t,\\cdot,\\mu)$ denote the corresponding one-parameter family of flow operators and note that $\\varphi$ is $C^{\\nu_2}$ in each of its arguments. For $\\varepsilon>0$ sufficiently small, $|\\mu|<\\varepsilon$,  $\\Gamma$ is a non-characteristic hypersurface for each $f(\\cdot,\\mu)$, and  all orbits of $f(\\cdot,\\mu)$ in $\\Omega_V$ enter and exit $\\Omega_V$ precisely once. Then we define the one-parameter family of functions $\\theta(\\cdot,\\mu) :\\Omega_V\\rightarrow\\mathbb{R}$ by $\\varphi(t,x,\\mu) \\in \\Gamma \\Leftrightarrow t = \\theta(x,\\mu)$. We show that $\\theta\\in C^{\\nu_2}(\\Omega_V\\times[-\\varepsilon,\\varepsilon],\\mathbb{R})$ by the implicit function theorem. Note that $\\theta$ is the solution $t$ to\n\n", "index": 101, "text": "\\begin{equation}\nF(x,t,\\mu) := h(\\varphi(t,x,\\mu))\t=0\t\t\\label{eq:implicittheta}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"F(x,t,\\mu):=h(\\varphi(t,x,\\mu))=0\" display=\"block\"><mrow><mrow><mi>F</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nThen it follows that $\\tilde{V}\\in C^{\\nu_2}(\\Omega_V\\times [-\\varepsilon,\\varepsilon],\\mathbb{R})$. It may also readily be verified that\n\n", "itemtype": "equation", "pos": 74069, "prevtext": "\nwhere $h$ is as in Definition \\ref{def:noncharhyp}. Let $(t^*,x^*,\\mu^*)$ be a solution to \\eqref{eq:implicittheta}. Then we have $ \\frac{d}{dt}F(t^*,x^*,\\mu^*) <0$\nby Definition \\ref{def:noncharhyp}. But since $h\\in C^{\\nu_1}(\\mathbb{R}^d,\\mathbb{R})$ and $\\varphi$ is a $C^{\\nu_2}$ function in $(x,t,\\mu)$, we have that $\\theta\\in C^{\\nu_2}(\\Omega_V\\times[-\\varepsilon,\\varepsilon],\\mathbb{R})$ by the implicit function theorem.\n\nFor each $\\mu$, define\n\n", "index": 103, "text": "\\begin{equation}\t\t\t\t\t\\label{eqn:Vtilde}\n\\tilde{V}(x,\\mu)  =  \\xi_V(\\varphi(\\theta(x,\\mu),x,\\mu)) + \\int_0^{\\theta(x,\\mu)} p(\\varphi(\\tau ,x,\\mu))d\\tau,\\qquad x\\in \\Omega_V.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\tilde{V}(x,\\mu)=\\xi_{V}(\\varphi(\\theta(x,\\mu),x,\\mu))+\\int_{0}^{\\theta(x,\\mu)%&#10;}p(\\varphi(\\tau,x,\\mu))d\\tau,\\qquad x\\in\\Omega_{V}.\" display=\"block\"><mrow><mrow><mrow><mrow><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03be</mi><mi>V</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03c4</mi></mrow></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>x</mi><mo>\u2208</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nNote that $\\tilde{V}(x,0) = V(x)$ by Lemma \\ref{lem:VxiV}. Now it is clear by \\eqref{eqn:Vtilde} that $||\\tilde{V}(\\cdot,\\mu) - V ||_{C^{\\nu_2}}\\rightarrow 0$ as $\\mu\\rightarrow 0$. But since $f(\\cdot,\\mu)$ is any one parameter family in the $C^{\\nu_2}$ topology with $f(\\cdot,0) = f^*$, we use Lemma  \\ref{lem:fzlambdafstarepsilon} (and $\\Omega_V\\subset X$) to deduce that $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$, and $||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}}\\rightarrow 0$ as $||f_{\\mathbf{z},\\lambda} - f^* ||_{C^{\\nu_2}}\\rightarrow 0$ for $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, and $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}.\n\\qquad\\end{proof}\n\n\\begin{remark}\t\t\t\t\\label{rem:orbderVTzlambda}\nIt follows from the proof of Lemma \\ref{lem:Vzlambdabounded} and from \\eqref{eqn:Vzlambda} and \\eqref{eqn:Tzlambda} that provided $\\theta_{\\mathbf{z},\\lambda}$ is well defined (which is guaranteed with probability $1-\\delta$), we have:\n\\begin{eqnarray}\n\\langle \\nabla V_{\\mathbf{z},\\lambda}(x),f_{\\mathbf{z},\\lambda}(x)\\rangle_{\\mathbb{R}^d}& =& -p(x),\\qquad x\\in\\Omega_V,\t\\label{eqn:Vzlambdaorbder}\\\\\n\\langle \\nabla T_{\\mathbf{z},\\lambda}(x),f_{\\mathbf{z},\\lambda}(x)\\rangle_{\\mathbb{R}^d}& = &-\\overline{c},\\qquad x\\in\\Omega_T.\t\\label{eqn:Tzlambdaorbder}\n\\end{eqnarray}\n\\end{remark}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now define a pairwise distinct, discrete set of points $\\mathbf{q}:=(q_i)_{i=1}^M \\subset \\Omega_V$ (resp. $\\Omega_T$). Note that these points need not be the same as $\\mathbf{x}$. Let $h_{\\mathbf{q}}$ be the fill distance of $\\mathbf{q}$ in $\\Omega_V$ (resp. $\\Omega_T$). We compute our approximations $\\hat{V}$ and $\\hat{T}$ according to our algorithm given in \\S\\ref{sec:algorithm}.\n\n\nWe have (for $\\hat{V}$, the arguments for $\\hat{T}$ are similar)\n\\begin{eqnarray*}\n\\langle \\nabla\\hat{V}, f^*\\rangle_{\\mathbb{R}^d} & = &  \\langle \\nabla\\hat{V}, f_{\\mathbf{z},\\lambda}  -f_{\\mathbf{z},\\lambda} +f^*\\rangle_{\\mathbb{R}^d}\\\\\n\\Rightarrow\\langle \\nabla\\hat{V}, f^*\\rangle_{\\mathbb{R}^d} + p(\\cdot) & = &  \\langle \\nabla\\hat{V}, f_{\\mathbf{z},\\lambda}\\rangle_{\\mathbb{R}^d}  - \\langle\\nabla\\hat{V},f_{\\mathbf{z},\\lambda} -f^*\\rangle_{\\mathbb{R}^d} + p(\\cdot).\n\\end{eqnarray*}\nThen we have, for $x\\in\\mathcal{D}$,\n\\begin{eqnarray*}\n\\langle \\nabla\\hat{V}(x), f^*(x)\\rangle_{\\mathbb{R}^d} + p(x) & \\le & \\langle \\nabla\\hat{V}(x), f_{\\mathbf{z},\\lambda} (x)\\rangle_{\\mathbb{R}^d} + p(x)\\nonumber\\\\\n&&  + \\tilde{C}_2\\max_k\\left(||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(\\mathcal{D})} . ||(\\nabla \\hat{V})^k||_{L^\\infty(\\mathcal{D})}\\right)  \\nonumber\\\\\n& \\le & \\tilde{C}_1 h_{\\mathbf{q}}^{k_2-\\frac{1}{2}} ||{V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_2(\\Omega_V)} \\nonumber\\\\\n& &  +\\tilde{C}_2\\max_k\\left(||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)} . ||(\\nabla \\hat{V})^k||_{L^\\infty(\\Omega_V)}\\right),\n\\end{eqnarray*}\nwhere recall that $\\tau_2 := k_2 + (d+1)/2$ is the degree of the Sobolev RKHS $\\mathcal{H}_{K^2}$. The last inequality above follows from Remark \\ref{rem:orbderVTzlambda}, Theorem \\ref{thm:GieWen}\n\nand $\\mathcal{D}\\subset\\Omega_V \\subset X$.  Recall the superscript $k$ denotes the $k$-th component of a $d$-dimensional vector.\n\nNow we use an estimate similar to (3.16) from \\cite[Lemma 3.9]{GieHaf15}: recall that $\\hat{V}\\in W^{\\tau_2}_2(\\Omega_V)$. Then from Corollary \\ref{cor:smoothnessK1K2} we have\n\n", "itemtype": "equation", "pos": 74395, "prevtext": "\nThen it follows that $\\tilde{V}\\in C^{\\nu_2}(\\Omega_V\\times [-\\varepsilon,\\varepsilon],\\mathbb{R})$. It may also readily be verified that\n\n", "index": 105, "text": "\\begin{equation*}\n\\langle \\nabla \\tilde{V}(x,\\mu),f(x,\\mu)\\rangle_{\\mathbb{R}^d} = -p(x),\\qquad x\\in\\Omega_V.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m1\" class=\"ltx_Math\" alttext=\"\\langle\\nabla\\tilde{V}(x,\\mu),f(x,\\mu)\\rangle_{\\mathbb{R}^{d}}=-p(x),\\qquad x%&#10;\\in\\Omega_{V}.\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>=</mo><mrow><mo>-</mo><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>x</mi><mo>\u2208</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nRecall that $\\hat{V}$ is the norm-minimal generalised interpolant to $V_{\\mathbf{z},\\lambda}$ in $\\mathcal{H}_{K^2}$ (since $V_{\\mathbf{z},\\lambda}$ satisfies \\eqref{eqn:Vzlambdaorbder}), and  $\\mathcal{H}_{K^2}$ is norm-equivalent to $W^{\\tau_2}_2(\\Omega_V)$. Then $||\\hat{V}||_{W^{\\tau_2}_2(\\Omega_V)} \\le C ||{V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_2(\\Omega_V)}$.\n\nIn addition, Lemma \\ref{lem:Vzlambdabounded} shows that\n\n", "itemtype": "equation", "pos": 77923, "prevtext": "\nNote that $\\tilde{V}(x,0) = V(x)$ by Lemma \\ref{lem:VxiV}. Now it is clear by \\eqref{eqn:Vtilde} that $||\\tilde{V}(\\cdot,\\mu) - V ||_{C^{\\nu_2}}\\rightarrow 0$ as $\\mu\\rightarrow 0$. But since $f(\\cdot,\\mu)$ is any one parameter family in the $C^{\\nu_2}$ topology with $f(\\cdot,0) = f^*$, we use Lemma  \\ref{lem:fzlambdafstarepsilon} (and $\\Omega_V\\subset X$) to deduce that $V_{\\mathbf{z},\\lambda}\\in C^{\\nu_2}(\\Omega_V,\\mathbb{R})$, and $||V_{\\mathbf{z},\\lambda} - V ||_{C^{\\nu_2}}\\rightarrow 0$ as $||f_{\\mathbf{z},\\lambda} - f^* ||_{C^{\\nu_2}}\\rightarrow 0$ for $||\\mathbf{w}||_{\\mathbb{R}^m}$ and $h_{\\mathbf{x}}$ sufficiently small, and $\\lambda>0$ chosen according to \\eqref{eqn:lambdachoice}.\n\\qquad\\end{proof}\n\n\\begin{remark}\t\t\t\t\\label{rem:orbderVTzlambda}\nIt follows from the proof of Lemma \\ref{lem:Vzlambdabounded} and from \\eqref{eqn:Vzlambda} and \\eqref{eqn:Tzlambda} that provided $\\theta_{\\mathbf{z},\\lambda}$ is well defined (which is guaranteed with probability $1-\\delta$), we have:\n\\begin{eqnarray}\n\\langle \\nabla V_{\\mathbf{z},\\lambda}(x),f_{\\mathbf{z},\\lambda}(x)\\rangle_{\\mathbb{R}^d}& =& -p(x),\\qquad x\\in\\Omega_V,\t\\label{eqn:Vzlambdaorbder}\\\\\n\\langle \\nabla T_{\\mathbf{z},\\lambda}(x),f_{\\mathbf{z},\\lambda}(x)\\rangle_{\\mathbb{R}^d}& = &-\\overline{c},\\qquad x\\in\\Omega_T.\t\\label{eqn:Tzlambdaorbder}\n\\end{eqnarray}\n\\end{remark}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now define a pairwise distinct, discrete set of points $\\mathbf{q}:=(q_i)_{i=1}^M \\subset \\Omega_V$ (resp. $\\Omega_T$). Note that these points need not be the same as $\\mathbf{x}$. Let $h_{\\mathbf{q}}$ be the fill distance of $\\mathbf{q}$ in $\\Omega_V$ (resp. $\\Omega_T$). We compute our approximations $\\hat{V}$ and $\\hat{T}$ according to our algorithm given in \\S\\ref{sec:algorithm}.\n\n\nWe have (for $\\hat{V}$, the arguments for $\\hat{T}$ are similar)\n\\begin{eqnarray*}\n\\langle \\nabla\\hat{V}, f^*\\rangle_{\\mathbb{R}^d} & = &  \\langle \\nabla\\hat{V}, f_{\\mathbf{z},\\lambda}  -f_{\\mathbf{z},\\lambda} +f^*\\rangle_{\\mathbb{R}^d}\\\\\n\\Rightarrow\\langle \\nabla\\hat{V}, f^*\\rangle_{\\mathbb{R}^d} + p(\\cdot) & = &  \\langle \\nabla\\hat{V}, f_{\\mathbf{z},\\lambda}\\rangle_{\\mathbb{R}^d}  - \\langle\\nabla\\hat{V},f_{\\mathbf{z},\\lambda} -f^*\\rangle_{\\mathbb{R}^d} + p(\\cdot).\n\\end{eqnarray*}\nThen we have, for $x\\in\\mathcal{D}$,\n\\begin{eqnarray*}\n\\langle \\nabla\\hat{V}(x), f^*(x)\\rangle_{\\mathbb{R}^d} + p(x) & \\le & \\langle \\nabla\\hat{V}(x), f_{\\mathbf{z},\\lambda} (x)\\rangle_{\\mathbb{R}^d} + p(x)\\nonumber\\\\\n&&  + \\tilde{C}_2\\max_k\\left(||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(\\mathcal{D})} . ||(\\nabla \\hat{V})^k||_{L^\\infty(\\mathcal{D})}\\right)  \\nonumber\\\\\n& \\le & \\tilde{C}_1 h_{\\mathbf{q}}^{k_2-\\frac{1}{2}} ||{V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_2(\\Omega_V)} \\nonumber\\\\\n& &  +\\tilde{C}_2\\max_k\\left(||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)} . ||(\\nabla \\hat{V})^k||_{L^\\infty(\\Omega_V)}\\right),\n\\end{eqnarray*}\nwhere recall that $\\tau_2 := k_2 + (d+1)/2$ is the degree of the Sobolev RKHS $\\mathcal{H}_{K^2}$. The last inequality above follows from Remark \\ref{rem:orbderVTzlambda}, Theorem \\ref{thm:GieWen}\n\nand $\\mathcal{D}\\subset\\Omega_V \\subset X$.  Recall the superscript $k$ denotes the $k$-th component of a $d$-dimensional vector.\n\nNow we use an estimate similar to (3.16) from \\cite[Lemma 3.9]{GieHaf15}: recall that $\\hat{V}\\in W^{\\tau_2}_2(\\Omega_V)$. Then from Corollary \\ref{cor:smoothnessK1K2} we have\n\n", "index": 107, "text": "\\begin{equation*}\n||(\\nabla \\hat{V})^k||_{L^\\infty(\\Omega_V)} \\le ||\\hat{V}||_{C^1(\\Omega_V)} \\le C||\\hat{V}||_{\\mathcal{H}_{K^2}}.\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m1\" class=\"ltx_Math\" alttext=\"||(\\nabla\\hat{V})^{k}||_{L^{\\infty}(\\Omega_{V})}\\leq||\\hat{V}||_{C^{1}(\\Omega_%&#10;{V})}\\leq C||\\hat{V}||_{\\mathcal{H}_{K^{2}}}.\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mo>\u2207</mo><mo>\u2061</mo><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mi>k</mi></msup><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><msub><mrow><mo fence=\"true\">||</mo><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">^</mo></mover><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>C</mi><mn>1</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">^</mo></mover><mo fence=\"true\">||</mo></mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><msup><mi>K</mi><mn>2</mn></msup></msub></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nand so\n $ ||V_{\\mathbf{z},\\lambda} ||_{W^{\\tau_2}_2(\\Omega_V)} \\le C ||  V ||_{W^{\\tau_2}_2(\\Omega_V)}$ for sufficiently small $||\\mathbf{w}||_{\\mathbb{R}^m}$, $h_{\\mathbf{x}}$ with probability $1-\\delta$.\nThen it follows that\n\n\n\n\n\n", "itemtype": "equation", "pos": 78494, "prevtext": "\nRecall that $\\hat{V}$ is the norm-minimal generalised interpolant to $V_{\\mathbf{z},\\lambda}$ in $\\mathcal{H}_{K^2}$ (since $V_{\\mathbf{z},\\lambda}$ satisfies \\eqref{eqn:Vzlambdaorbder}), and  $\\mathcal{H}_{K^2}$ is norm-equivalent to $W^{\\tau_2}_2(\\Omega_V)$. Then $||\\hat{V}||_{W^{\\tau_2}_2(\\Omega_V)} \\le C ||{V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_2(\\Omega_V)}$.\n\nIn addition, Lemma \\ref{lem:Vzlambdabounded} shows that\n\n", "index": 109, "text": "\\begin{equation*}\n||{V} - {V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_2(\\Omega_V)}  \\le\nC||{V} - {V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_2}_\\infty(\\Omega_V)}\n\\le  C||{V} - {V}_{\\mathbf{z},\\lambda}||_{C^{\\nu_2}(\\Omega_V)} \\le C\\varepsilon,\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m1\" class=\"ltx_Math\" alttext=\"||{V}-{V}_{\\mathbf{z},\\lambda}||_{W^{\\tau_{2}}_{2}(\\Omega_{V})}\\leq C||{V}-{V}%&#10;_{\\mathbf{z},\\lambda}||_{W^{\\tau_{2}}_{\\infty}(\\Omega_{V})}\\leq C||{V}-{V}_{%&#10;\\mathbf{z},\\lambda}||_{C^{\\nu_{2}}(\\Omega_{V})}\\leq C\\varepsilon,\" display=\"block\"><mrow><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><mi>V</mi><mo>-</mo><msub><mi>V</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><msub><mi>\u03c4</mi><mn>2</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><mi>V</mi><mo>-</mo><msub><mi>V</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mi mathvariant=\"normal\">\u221e</mi><msub><mi>\u03c4</mi><mn>2</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><mi>V</mi><mo>-</mo><msub><mi>V</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>C</mi><msub><mi>\u03bd</mi><mn>2</mn></msub></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><mi>\u03b5</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\nWe may similarly show\n\n", "itemtype": "equation", "pos": 78971, "prevtext": "\nand so\n $ ||V_{\\mathbf{z},\\lambda} ||_{W^{\\tau_2}_2(\\Omega_V)} \\le C ||  V ||_{W^{\\tau_2}_2(\\Omega_V)}$ for sufficiently small $||\\mathbf{w}||_{\\mathbb{R}^m}$, $h_{\\mathbf{x}}$ with probability $1-\\delta$.\nThen it follows that\n\n\n\n\n\n", "index": 111, "text": "\\begin{equation}\t\t\t\t\t\\label{eqn:Vestimate}\n\\langle \\nabla\\hat{V}(x), f^*(x)\\rangle_{\\mathbb{R}^d} + p(x)  \\le  C_1||{V}||_{W^{\\tau_2}_2(\\Omega_V)} \\left(\nh_{\\mathbf{q}}^{k_2-\\frac{1}{2}}\n + \\max_k||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)} ||  \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"\\langle\\nabla\\hat{V}(x),f^{*}(x)\\rangle_{\\mathbb{R}^{d}}+p(x)\\leq C_{1}||{V}||%&#10;_{W^{\\tau_{2}}_{2}(\\Omega_{V})}\\left(h_{\\mathbf{q}}^{k_{2}-\\frac{1}{2}}+\\max_{%&#10;k}||f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^{\\infty}(X)}||\\right).\" display=\"block\"><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mo>\u2207</mo><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><msup><mi>f</mi><mo>*</mo></msup><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>+</mo><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><msub><mi>C</mi><mn>1</mn></msub><mo stretchy=\"false\">|</mo><mo stretchy=\"false\">|</mo><mi>V</mi><mo stretchy=\"false\">|</mo><msub><mo stretchy=\"false\">|</mo><mrow><msubsup><mi>W</mi><mn>2</mn><msub><mi>\u03c4</mi><mn>2</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>V</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mrow><mo>(</mo><msubsup><mi>h</mi><mi>\ud835\udc2a</mi><mrow><msub><mi>k</mi><mn>2</mn></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup><mo>+</mo><munder><mi>max</mi><mi>k</mi></munder><mo stretchy=\"false\">|</mo><mo stretchy=\"false\">|</mo><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup><mo stretchy=\"false\">|</mo><msub><mo stretchy=\"false\">|</mo><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo stretchy=\"false\">|</mo><mo stretchy=\"false\">|</mo><mo>)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\nFurthermore, we can directly apply \\eqref{eqn:ests2gamma} from Theorem \\ref{thm:GieWen} to obtain\n\n", "itemtype": "equation", "pos": 79270, "prevtext": "\nWe may similarly show\n\n", "index": 113, "text": "\\begin{equation}\n\\langle \\nabla\\hat{T}(x), f^*(x)\\rangle_{\\mathbb{R}^d} + c  \\le   C_1 ||{T}||_{W^{\\tau_2}_2(\\Omega_T)}\n\\left(h_{\\mathbf{q}}^{k_2-\\frac{1}{2}}\n + \\max_k||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}\n\\right).\t\\label{eqn:Testimate1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\langle\\nabla\\hat{T}(x),f^{*}(x)\\rangle_{\\mathbb{R}^{d}}+c\\leq C_{1}||{T}||_{W%&#10;^{\\tau_{2}}_{2}(\\Omega_{T})}\\left(h_{\\mathbf{q}}^{k_{2}-\\frac{1}{2}}+\\max_{k}|%&#10;|f^{k}_{\\mathbf{z},\\lambda}-f^{*,k}||_{L^{\\infty}(X)}\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mover accent=\"true\"><mi>T</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msup><mi>f</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><msup><mi>\u211d</mi><mi>d</mi></msup></msub><mo>+</mo><mi>c</mi></mrow><mo>\u2264</mo><mrow><msub><mi>C</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mi>T</mi><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><msub><mi>\u03c4</mi><mn>2</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>T</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><msubsup><mi>h</mi><mi>\ud835\udc2a</mi><mrow><msub><mi>k</mi><mn>2</mn></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup><mo>+</mo><mrow><munder><mi>max</mi><mi>k</mi></munder><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mrow><msubsup><mi>f</mi><mrow><mi>\ud835\udc33</mi><mo>,</mo><mi>\u03bb</mi></mrow><mi>k</mi></msubsup><mo>-</mo><msup><mi>f</mi><mrow><mo>*</mo><mo>,</mo><mi>k</mi></mrow></msup></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01568.tex", "nexttext": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombining \\eqref{eqn:festimate} with \\eqref{eqn:Vestimate}--\\eqref{eqn:Testimate2} proves Theorem \\ref{thm:mainresult}.\\qquad$\\square$\n\n\n\n\n\n\\begin{remark}\nFurthermore, as $||f^k_{\\mathbf{z},\\lambda} - f^{*,k}||_{L^\\infty(X)}$ converges to zero, we can shrink the ball $B_\\varepsilon(\\overline{x})$ (and therefore also $\\tilde\\Gamma$) towards $\\overline{x}$. The domains $\\Omega_V$ and $\\Omega_T$ will converge towards $\\tilde\\Omega_V$ and $\\tilde\\Omega_T$ respectively, and therefore $V_{\\mathbf{z},\\lambda}$ and $T_{\\mathbf{z},\\lambda}$ will converge to $V$ and $T$ respectively. However, we do not give estimates for how fast $h_{\\mathbf{x}}$ and $\\mathbf{w}$ would need to converge to zero relative to $\\varepsilon$.\n\\end{remark}\n\n\n\n\n\n\n\\section{Acknowledgements}\n\nB. Hamzi was supported by a Marie Curie Fellowship Grant Number 112C006. M. Rasmussen was supported by an EPSRC Career Acceleration Fellowship EP/I004165/1 and K.N. Webster was supported by the EPSRC Grant EP/L00187X/1 and\na Marie Sk\\l odowska-Curie Individual Fellowship Grant Number 660616.\n\nWe would also like to thank Holger Wendland for drawing our attention to the reference for Theorem \\ref{thm:WenRie}.\n\n\n\n\\begin{thebibliography}{99}\n\\bibitem{Ada75} R.~A.~Adams, \\textsl{Sobolev Spaces}, Adademic Press, New York, 1975.\n\n\n\n\\bibitem{Bha67} N.~Bhatia, \\textsl{On asymptotic stability in dynamical systems}, Math. Systems Theory \\textbf{1} (1967), 113--128.\n\n\\bibitem{BhaSze70} N.~Bhatia and G.~Szeg\\\"{o}, \\textsl{Stability Theory of Dynamical Systems}, Grundlehren der mathematischen Wissenschaften \\textbf{161}, Springer, Berlin, 1970.\n \n \\bibitem{allerton} J.~Bouvrie,  and B.~Hamzi, Balanced Reduction of Nonlinear Control Systems in\nReproducing Kernel Hilbert Space, in {\\it Proc. 48th Annual Allerton Conference on Communication, Control, and Computing}  (2010), 294--301,\n \\url{http://arxiv.org/abs/1011.2952}.\n\n\\bibitem{acc2012} J.~Bouvrie  and B.~Hamzi, Empirical Estimators for the Controllability Energy and\nInvariant Measure of Stochastically Forced Nonlinear Systems,in {\\it Proc. of the 2012 American Control Conference}  (2012), (long version at\n \\url{http://arxiv.org/abs/1204.0563}).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem{zubov2001camilli} \n F.~Camilli, L.~Gr{\\\"u}ne and F.~Wirth,\n\\textsl{A generalization of {Z}ubov's method to perturbed systems},\nSIAM J. Control Optim. \\textbf{40} (2001), 496--515.\n\n\\bibitem{CucSma01} F.~Cucker and S.~Smale, \\textsl{On The Mathematical Foundations of Learning}, Bull. Amer. Math. Soc. \\textbf{39} Number 1 (2001), 1--49.\n\n\\bibitem{CucSma02} F.~Cucker and S.~Smale, \\textsl{Best choices for regularisation parameters in learning theory}, Found. Comput. Math. \\textbf{2} (2002), 413--428.\n\n\n\n\\bibitem{Eva98} L.~Evans, \\textsl{Partial Differential Equations}, vol. 19 of \\textsl{Graduate Studies in Mathematics}, AMS, Providence, Rhode Island, 1998.\n\n\\bibitem{EvgPonPog00} T.~Evgeniou, M.~Pontil and T.~Poggio, \\textsl{Regularization networks and support vector machines}, Adv. Comput. Math. \\textbf{13} (2000), 1--50.\n\n\\bibitem{Gie07:a} P.~Giesl, \\textsl{Construction of Global Lyapunov Functions Using Radial Basis Functions}, Lecture Notes in Mathematics. Springer Berlin Heidelberg, 2007.\n\n\n\n\\bibitem{GieHaf15} P.~Giesl and S.~Hafstein, \\textsl{Computation and verification of Lyapunov functions}, SIAM J. Appl. Dyn. Syst. \\textbf{14} No. 4 (2015), 1663--1698.\n\n\\bibitem{GieHaf15:b} P.~Giesl and S.~Hafstein, \\textsl{Review on computational methods for Lyapunov functions}, Discrete and Continuous Dynamical Systems Series B \\textbf{20} No. 8 (2015), 2291--2331.\n\n\\bibitem{GieWen07} P.~Giesl and H.~Wendland, \\textsl{Meshless collocation: error estimates with application to dynamical systems}, SIAM J. Num. Anal. \\textbf{45} No. 4 (2007), 1723--1741.\n\n\n\\bibitem{book2002grune} \n L.~Gr{\\\"u}ne,\n\\textsl{Asymptotic Behavior of Dynamical and Control Systems Under Perturbation and Discretization},\nLecture Notes in Mathematics. Springer-Verlag, Berlin, 2002.\n\n\n\\bibitem{Haf2007mon}\nS.~Hafstein,\n\\textsl{An algorithm for constructing {L}yapunov functions},\nMonograph. Electron. J. Diff. Eqns., 2007.\n\n\n\n\n\\bibitem{Hah59} W.~Hahn, \\textsl{Theorie und Anwendung der direkten Methode von Ljapunov}, Ergebnisse der Mathematik und ihrer Grenzgebiete \\textbf{22}, Springer, Berlin, 1959.\n\n\\bibitem{Hah67} W.~Hahn, \\textsl{Stability of Motion}, Springer, New York, 1967.\n\n\n\n\n \n\n\n\\bibitem{Lya07} A.M.~Lyapunov, \\textsl{Probl\\`eme g\\'en\\'eral de la stabilit\\'e du mouvement}, Ann. Fac. Sci. Toulouse \\textbf{9} (1907), 203--474. Translation of the Russian version, published 1893 in Comm. Soc. math. Kharkow. Newly printed: Ann. of math. Stud. \\textbf{17}, Princeton, 1949.\n\n\\bibitem{LinSonWan96} Y.~Lin, E.~D.~Sontag and Y.~Wang, \\textsl{A smooth converse Lyapunov theorem for robust stability}, SIAM J. Control Optim. \\textbf{34} (1996), 124--160.\n\n\\bibitem{Kel15} C.~Kellett, \\textsl{Classical converse theorems in Lyapunov's second method}, Discrete Contin. Dyn. Syst. Ser. B, \\textbf{8} (2015), 2333--2360.\n\n\\bibitem{Mas49} J.~L.~Massera, \\textsl{On Liapounoff's conditions of stability}, Ann. of Math. \\textbf{50} Number 3 (1949), 705--721.\n\n\n\n\\bibitem{NarWarWen04} F.J.~Narcowich, J.D.~Ward,  and H.~Wendland, \\textsl{Sobolev bounds on functions with scattered zeros, with applications to radial basis function surface fitting}, Mathematics of Computation, \\textbf{74} (2004), 743--763.\n\n\\bibitem{Opf06:a} R.~Opfer, \\textsl{Multiscale kernels}, Adv. Comput. Math., \\textbf{25} (2006), 357--380.\n\n\\bibitem{Opf06:b} R.~Opfer, \\textsl{Tight frame expansions of multiscale reproducing kernels in Sobolev spaces}, Appl. Comput. Harmon. Anal., \\textbf{20} (2006), 357--374.\n\n\\bibitem{prajna} A.~Papachristodoulou and  S.~Prajna, On the construction of Lyapunov functions using the sum of squares decomposition, Proceedings of the 41st IEEE Conference on Decision and Control, 2002.\n\n\\bibitem{Pag97} G.~Pag\\`{e}s, \\textsl{A space quantization method for numerical integration}, J. Comp. Appl. Math. \\textbf{89} (1997), 1--38.\n\n\n\n\n\n\\bibitem{SmaZho04} S.~Smale and D.-X.~Zhou, \\textsl{Shannon Sampling and Function Reconstruction from Point Values}, Bull. Amer. Math. Soc. \\textbf{41} (2004), 279--305.\n\n\\bibitem{SmaZho05} S.~Smale and D.-X.~Zhou, \\textsl{Shannon Sampling II: Connections to Learning Theory}, Appl. Comput. Harmon. Anal. \\textbf{19} (2005), 285--302.\n\n\\bibitem{SmaZho07} S.~Smale and D.-X.~Zhou, \\textsl{Learning Theory Estimates via their Integral operators and their Approximations}, Constr. Approx. \\textbf{26} Issue 2 (2007), 153--172.\n\n\\bibitem{hyperbolic} S.~Smale and D.-X.~Zhou, \\textsl{Online Learning with Markov Sampling}, Anal. Appl., \\textbf{7} (2009), 87--113.\n\n\n\n\n\n\\bibitem{Vor08} G.~Voronoi, \\textsl{Recherches sur les parallelodres primitives}, J. Reine Angew. Math. \\textbf{134} (1908), 198--287.\n\n\\bibitem{Wes67} F.~Wesley Wilson, Jr., \\textsl{Smoothing derivatives of functions and applications}, Trans. Amer. Math. Soc. \\textbf{139} (1969), 413--428.\n\n\\bibitem{Wen95} H.~Wendland, \\textsl{Piecewise polynomial, positive definite and compactly supported radial functions of minimal degree}, Adv. Comput. Math., \\textbf{4} (1995), 3489--396.\n\n\n\n\\bibitem{Wen05} H.~Wendland, \\textsl{Scattered Data Approximation}, Cambridge Monogr. Appl. Comput. Math., Cambridge University Press, Cambridge, UK, 2005.\n\n\\bibitem{WenRie05} H.~Wendland and C.~Rieger, \\textsl{Approximate interpolation with applications to selecting smoothing parameters}, Numer. Math. \\textbf{101} (2005), 729--748.\n\n\n\n\n\n\n\n\n\n\n\\end{thebibliography}\n\n", "itemtype": "equation", "pos": 79637, "prevtext": "\n\nFurthermore, we can directly apply \\eqref{eqn:ests2gamma} from Theorem \\ref{thm:GieWen} to obtain\n\n", "index": 115, "text": "\\begin{equation}\t\t\t\t\\label{eqn:Testimate2}\n||\\hat{T} - T||_{L^\\infty(\\Gamma)}  \\le  Ch_{\\tilde{\\mathbf{q}}}^{k_2+\\frac{1}{2}}||T||_{W_2^{\\tau_2}(\\Omega_T)}\t\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"||\\hat{T}-T||_{L^{\\infty}(\\Gamma)}\\leq Ch_{\\tilde{\\mathbf{q}}}^{k_{2}+\\frac{1}%&#10;{2}}||T||_{W_{2}^{\\tau_{2}}(\\Omega_{T})}\" display=\"block\"><mrow><msub><mrow><mo fence=\"true\">||</mo><mrow><mover accent=\"true\"><mi>T</mi><mo stretchy=\"false\">^</mo></mover><mo>-</mo><mi>T</mi></mrow><mo fence=\"true\">||</mo></mrow><mrow><msup><mi>L</mi><mi mathvariant=\"normal\">\u221e</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0393</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2264</mo><mrow><mi>C</mi><mo>\u2062</mo><msubsup><mi>h</mi><mover accent=\"true\"><mi>\ud835\udc2a</mi><mo stretchy=\"false\">~</mo></mover><mrow><msub><mi>k</mi><mn>2</mn></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup><mo>\u2062</mo><msub><mrow><mo fence=\"true\">||</mo><mi>T</mi><mo fence=\"true\">||</mo></mrow><mrow><msubsup><mi>W</mi><mn>2</mn><msub><mi>\u03c4</mi><mn>2</mn></msub></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a9</mi><mi>T</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow></mrow></math>", "type": "latex"}]