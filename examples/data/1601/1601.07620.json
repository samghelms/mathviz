[{"file": "1601.07620.tex", "nexttext": "\nThe two time constants determine the decay times of these slow and fast synaptic currents, and we set $\\tau_{{\\mbox{\\scriptsize s}}} = 100$ ms and  $\\tau_{{\\mbox{\\scriptsize f}}} = 2$ ms.  The synapses that are modified by training are all of the slow type, while the random synapses are fast.  For example, the output of the network is the product of~${ {\\bm s}(t) }$ and the output weight matrix~${\\bm W}$, ${\\bm W} { {\\bm s}(t) }$ (Figure~\\ref{fig:Figure1}a). \n\nThe membrane potentials of the model neurons, collected together into a $N$-component vector ${\\bm V}$, obey the equation  \n\n", "itemtype": "equation", "pos": 8108, "prevtext": "\n\n\n\\thispagestyle{empty}\n\\vspace*{0.5in}\n\\begin{center}\n\\begin{Large}\n{\\bf\nUsing Firing-Rate Dynamics to Train\\\\ \n\\vspace*{0.05in}\nRecurrent Networks of Spiking Model Neurons\\\\\n}\n\\end{Large}\n\\vspace*{0.2in}   \n{\\bf Brian DePasquale, Mark M. Churchland$^{1}$, L.F. Abbott$^{1,2}$}\\\\\n\\vspace*{0.1in}\nDepartment of Neuroscience\\\\\n$^1$Grossman Center for the Statistics of Mind\\\\\n$^2$Department of Physiology and Cellular Biophysics\\\\\nColumbia University College of Physicians and Surgeons\\\\\nNew York NY 10032-2695 USA\\\\\n\n\\vspace*{0.5in}\n{\\bf Abstract}\n\\end{center}\n\nRecurrent neural networks are powerful tools for understanding and modeling computation and representation by populations of neurons. Continuous-variable or ``rate\" model networks have been analyzed and applied extensively for these purposes.  However, neurons fire action potentials, and the discrete nature of spiking is an important feature of neural circuit dynamics.\nDespite significant advances, training recurrently connected spiking neural networks remains a challenge.  We present a procedure for training recurrently connected spiking networks to generate dynamical patterns autonomously, to produce complex temporal outputs based on integrating network input, and to model physiological data. Our procedure makes use of a continuous-variable network to identify targets for training the inputs to the spiking model neurons. Surprisingly, we are able to construct spiking networks that duplicate tasks performed by continuous-variable networks with only a relatively minor expansion in the number of neurons. Our approach provides a novel view of the significance and appropriate use of ``firing rate\" models, and it is a useful approach for building model spiking networks that can be used to address important questions about representation and computation in neural systems.\n  \n\\newpage\n{\\vspace{0.05in}\\noindent{{\\large\\bf{{Introduction}}}} \\addtocounter{section}{1}\\setcounter{subsection}{0} }\n\nA fundamental riddle of nervous system function is the disparity between our continuous and comparatively slow sensory percepts and motor actions and the neural representation of those percepts and actions by brief, discrete and spatially distributed actions potentials. A related puzzle is the reliability with which these signals are represented despite the variability of neural spiking across nominally identical performances of a behavior.  A useful approach to addressing these issues is to build spiking model networks that perform relevant tasks, but this has proven difficult to do.  Here we develop a method for constructing functioning networks of spiking model neurons that perform a variety of tasks while embodying the variable character of neuronal activity.  In this context, ``task\" refers to a computation performed by a biological neural circuit.\n\nThere have been previous successes constructing spiking networks that perform specific tasks (see for example \\citet{Seung, Wang, MachensBrody, Hennequin}).  In addition, more general procedures have been developed (reviewed in \\citet{Abbottetal}) that construct spiking networks that duplicate systems of linear \\citep{Eliasmith, BoerlinDeneve, BoerlinMachensDeneve} and nonlinear \\citep{Eliasmith, Thalmeieretal} equations.  However, most tasks of interest to neuroscientists, such as action choices based on presented stimuli, are not expressed in terms of systems of differential equations.  \n\nOur work  uses continuous-variable network models \\citep{Sompolinsky}, typically called ``rate\" networks, as an intermediary between conventional task descriptions in terms of stimuli and responses, and spiking network construction.  This results in a general procedure for constructing spiking networks that perform a wide variety of tasks of interest to neuroscience (see also \\citet{Thalmeieretal, Abbottetal}).  We apply this procedure to example tasks and show how constraints on the sparseness and sign (Dale's law) of network connectivity can be imposed.  We also build a spiking network model that matches multiple features of data recorded from neurons in motor cortex and from arm muscles during a reaching task.\n\n{\\vspace{0.05in}\\noindent{{\\large\\bf{{Results}}}} \\addtocounter{section}{1}\\setcounter{subsection}{0} }\n\nThe focus of our work is the development of a procedure for constructing recurrently connected networks of spiking model.  We begin by describing the model-building procedure and then present examples of its use. \n\n{\\vspace{0.05in} \\noindent{\\bf{{Network architecture and network training}}}\\addtocounter{subsection}{1} } \\label{ssec:Network architecture}\n\nThe general architecture we consider is a recurrently connected network of~$N$ leaky integrate-and-fire  (LIF) model neurons that receives task-specific input~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and, following training, produces an approximation of a specified ``target\" output signal~${F_{{\\mbox{\\scriptsize out}}}(t)}$ (Figure \\ref{fig:Figure1}a). ${F_{{\\mbox{\\scriptsize in}}}(t)}$ can be thought of as external sensory input or as input from another neural network, and ${F_{{\\mbox{\\scriptsize out}}}(t)}$ as the input current into a downstream neuron or as a more abstractly defined network output (for example a motor output signal or a decision variable). The neurons in the network are connected to each other by synapses with strengths denoted by the $N\\times N$ matrix~${\\bm J}$.  Connections between the network and to the output have strengths given by an $N\\times N_{{\\mbox{\\scriptsize out}}}$ matrix~${\\bm W}$, where $N_{{\\mbox{\\scriptsize out}}}$ is the number of outputs (either 1 or 2 in the examples we provide). During network training both~${\\bm J}$ and~${\\bm W}$ are modified. In addition to the trained connections described by ${\\bm J}$, we also include random connections defined by another $N\\times N$ matrix, ${\\bm J}^{{\\mbox{\\scriptsize f}}}$.  The elements of this matrix are chosen randomly from a Gaussian distribution with mean $\\mu/N$ and variance $g_{{\\mbox{\\scriptsize f}}}^2/N$ and are not modified during training. The values of $\\mu$ and $g_{{\\mbox{\\scriptsize f}}}$ are given below for the different examples we present. This random connectivity produces chaotic spiking in the network~\\citep{VanVreeswijkSompolinsky, Brunel}, which we use as a source of spiking irregularity and trial-to-trial variability.  We use the parameter $g_{{\\mbox{\\scriptsize f}}}$ to control the level of this variability.\n\n\\begin{figure} \n\\centerline{ \\includegraphics[width = 2in]{Fig1.pdf}}\n\\caption{ Network architectures. {\\bf a)} Spiking network.  A network of~$N$ recurrently connected leaky integrate-and-fire neurons (green circles) receives an input ${F_{{\\mbox{\\scriptsize in}}}(t)}$ (grey circle) through synapses~${\\bm U}$, and generates an output ${F_{{\\mbox{\\scriptsize out}}}(t)}$ (red circle) through synapses~${\\bm W}$. Connections marked in red (recurrent connections ${\\bm J}$ and output connections ${\\bm W}$) are modified by training, and black connections are random and remain fixed, including a second set of recurrent connections with strengths~${\\bm J}^{{\\mbox{\\scriptsize f}}}$. {\\bf b)} Continuous-variable network. A network of~$\\tilde N$ recurrently connected ``rate\" units (blue circles) receive inputs ${F_{{\\mbox{\\scriptsize in}}}(t)}$ and ${F_{{\\mbox{\\scriptsize out}}}(t)}$ through synapses~${\\bm{\\tilde U}}$ and ${\\bm{\\tilde u}}$, respectively.  All connections are random and held fixed. The sum of ${\\bm{\\tilde U}}{F_{{\\mbox{\\scriptsize out}}}(t)}$ and the recurrent input determined by ${\\bm{\\tilde J}}$  defines the auxiliary targets ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ for the spiking network.}\t\n\\label{fig:Figure1}\n\\end{figure}\n\nWhen a neuron in the network fires an action potential, it contributes both fast and slow synaptic currents to other network neurons.  These currents are described by the two $N$-dimensional vectors, ${ {\\bm s}(t) }$ and ${ {\\bm f}(t) }$.  When neuron $i$ in the network fires an action potential, component $i$ of both ${ {\\bm s}(t) }$ and ${ {\\bm f}(t) }$ is incremented by 1, otherwise\n\n", "index": 1, "text": "\\begin{equation}\n\\tau_{{\\mbox{\\scriptsize s}}}\\frac{d{ {\\bm s}(t) }}{dt} = -{ {\\bm s}(t) } \\quad\\mbox{and}\\quad \\tau_{{\\mbox{\\scriptsize f}}}\\frac{d{ {\\bm f}(t) }}{dt} = -{ {\\bm f}(t) } \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\tau_{{\\mbox{\\scriptsize s}}}\\frac{d{{\\bm{s}}(t)}}{dt}=-{{\\bm{s}}(t)}\\quad%&#10;\\mbox{and}\\quad\\tau_{{\\mbox{\\scriptsize f}}}\\frac{d{{\\bm{f}}(t)}}{dt}=-{{\\bm{f%&#10;}}(t)}\\,.\" display=\"block\"><mrow><mrow><mrow><mrow><msub><mi>\u03c4</mi><mtext>s</mtext></msub><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mi>\ud835\udc94</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mrow><mo>=</mo><mrow><mrow><mo>-</mo><mrow><mi>\ud835\udc94</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><msub><mi>\u03c4</mi><mtext>f</mtext></msub><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mi>\ud835\udc87</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mi>\ud835\udc87</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07620.tex", "nexttext": "\nwith $\\tau_{{\\mbox{\\scriptsize m}}} = 20$ ms.  For a case with $N_{{\\mbox{\\scriptsize in}}}$ inputs, ${\\bm U}$ is an $N\\times N_{{\\mbox{\\scriptsize in}}}$ matrix (we consider $N_{{\\mbox{\\scriptsize in}}} = 1$ and 2) with elements drawn independently from a uniform distribution between -1 and 1\\@.  $I$ is a bias current set equal to 10 mV\\@.  It is increased between trials in the examples of Figures~\\ref{fig:Figure3} and~\\ref{fig:Figure4}, representing a ``holding\" input.  Each neuron fires an action potential when its membrane potential reaches a threshold $V_{{\\mbox{\\scriptsize th}}} = -55$ mV and is then reset to $V_{{\\mbox{\\scriptsize reset}}} = V_{{\\mbox{\\scriptsize rest}}} = -65$ mV\\@.  Following an action potential, the membrane potential is held at the reset potential for a refractory period of 2 ms unless stated otherwise.  The parameter $g$ controls the strength of the inputs to each neuron, and we provide its value for the different examples below.\n\nWe can now specify the goal and associated challenges of network training. The goal is to modify the entries of~${\\bm J}$ and~${\\bm W}$ so that the network performs the task specified by~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and~${F_{{\\mbox{\\scriptsize out}}}(t)}$, meaning that\n\n", "itemtype": "equation", "pos": 8903, "prevtext": "\nThe two time constants determine the decay times of these slow and fast synaptic currents, and we set $\\tau_{{\\mbox{\\scriptsize s}}} = 100$ ms and  $\\tau_{{\\mbox{\\scriptsize f}}} = 2$ ms.  The synapses that are modified by training are all of the slow type, while the random synapses are fast.  For example, the output of the network is the product of~${ {\\bm s}(t) }$ and the output weight matrix~${\\bm W}$, ${\\bm W} { {\\bm s}(t) }$ (Figure~\\ref{fig:Figure1}a). \n\nThe membrane potentials of the model neurons, collected together into a $N$-component vector ${\\bm V}$, obey the equation  \n\n", "index": 3, "text": "\\begin{equation}\n\\tau_{{\\mbox{\\scriptsize m}}}\\frac{d{\\bm V}}{dt} =  V_{{\\mbox{\\scriptsize rest}}} - {\\bm V} + g\\Big({\\bm J}{ {\\bm s}(t) } + {\\bm J}^{{\\mbox{\\scriptsize f}}}{ {\\bm f}(t) } + {\\bm U}{F_{{\\mbox{\\scriptsize in}}}(t)}\\Big ) + I\\, ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\tau_{{\\mbox{\\scriptsize m}}}\\frac{d{\\bm{V}}}{dt}=V_{{\\mbox{\\scriptsize rest}}%&#10;}-{\\bm{V}}+g\\Big{(}{\\bm{J}}{{\\bm{s}}(t)}+{\\bm{J}}^{{\\mbox{\\scriptsize f}}}{{%&#10;\\bm{f}}(t)}+{\\bm{U}}{F_{{\\mbox{\\scriptsize in}}}(t)}\\Big{)}+I\\,,\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c4</mi><mtext>m</mtext></msub><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mi>\ud835\udc7d</mi></mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mrow><mo>=</mo><mrow><mrow><msub><mi>V</mi><mtext>rest</mtext></msub><mo>-</mo><mi>\ud835\udc7d</mi></mrow><mo>+</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mi>\ud835\udc71</mi><mo>\u2062</mo><mi>\ud835\udc94</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>\ud835\udc71</mi><mtext>f</mtext></msup><mo>\u2062</mo><mi>\ud835\udc87</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>\ud835\udc7c</mi><mo>\u2062</mo><msub><mi>F</mi><mtext>in</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow></mrow><mo>+</mo><mpadded width=\"+1.7pt\"><mi>I</mi></mpadded></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07620.tex", "nexttext": "\nwhen the network responds to~${F_{{\\mbox{\\scriptsize in}}}(t)}$ (with the approximation being as accurate as possible). \\hyperref[eq:ZWsFout]{Equation~\\ref{eq:ZWsFout}} stipulates that ${ {\\bm s}(t) }$ must provide a basis for the function~${F_{{\\mbox{\\scriptsize out}}}(t)}$.  If it does, it is straightforward to compute the optimal ${\\bm W}$ by minimizing the squared difference between the two sides of equation~\\ref{eq:ZWsFout}, averaged over time.  This can be done either recursively \\citep{Haykin} or using a standard batch least-squares approach.\n\nDetermining the optimal ${\\bm J}$ is significantly more challenging because of the recurrent nature of the network.  ${\\bm J}$ must be chosen so that the input to the network neurons, ${\\bm J}{ {\\bm s}(t) }$, generates a pattern of spiking that produces ${ {\\bm s}(t) }$.  The circularity of this constraint is what makes recurrent network learning difficult.  The difference between the easy problem of computing ${\\bm W}$ and the difficult problem of computing ${\\bm J}$ is that, in the case of ${\\bm W}$, we have the target ${F_{{\\mbox{\\scriptsize out}}}(t)}$ in equation~\\ref{eq:ZWsFout} that specifies what signal ${\\bm W}$ should produce.  For ${\\bm J}$, it is not obvious what the input it generates should be.  \n\nSuppose that we \\emph{did} have targets analogous to ${F_{{\\mbox{\\scriptsize out}}}(t)}$ but for computing ${\\bm J}$ (we call them auxiliary target functions and denote them by the~$N$-component vector~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$).  Then, ${\\bm J}$, like ${\\bm W}$, could be determined by a least-squares procedure, that is, by minimizing the time-averaged squared differences between the two sides of\n\n", "itemtype": "equation", "pos": 10412, "prevtext": "\nwith $\\tau_{{\\mbox{\\scriptsize m}}} = 20$ ms.  For a case with $N_{{\\mbox{\\scriptsize in}}}$ inputs, ${\\bm U}$ is an $N\\times N_{{\\mbox{\\scriptsize in}}}$ matrix (we consider $N_{{\\mbox{\\scriptsize in}}} = 1$ and 2) with elements drawn independently from a uniform distribution between -1 and 1\\@.  $I$ is a bias current set equal to 10 mV\\@.  It is increased between trials in the examples of Figures~\\ref{fig:Figure3} and~\\ref{fig:Figure4}, representing a ``holding\" input.  Each neuron fires an action potential when its membrane potential reaches a threshold $V_{{\\mbox{\\scriptsize th}}} = -55$ mV and is then reset to $V_{{\\mbox{\\scriptsize reset}}} = V_{{\\mbox{\\scriptsize rest}}} = -65$ mV\\@.  Following an action potential, the membrane potential is held at the reset potential for a refractory period of 2 ms unless stated otherwise.  The parameter $g$ controls the strength of the inputs to each neuron, and we provide its value for the different examples below.\n\nWe can now specify the goal and associated challenges of network training. The goal is to modify the entries of~${\\bm J}$ and~${\\bm W}$ so that the network performs the task specified by~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and~${F_{{\\mbox{\\scriptsize out}}}(t)}$, meaning that\n\n", "index": 5, "text": "\\begin{equation}\n\t\\label{eq:ZWsFout}\n\t{\\bm W} { {\\bm s}(t) } \\approx {F_{{\\mbox{\\scriptsize out}}}(t)} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"{\\bm{W}}{{\\bm{s}}(t)}\\approx{F_{{\\mbox{\\scriptsize out}}}(t)}\" display=\"block\"><mrow><mrow><mi>\ud835\udc7e</mi><mo>\u2062</mo><mi>\ud835\udc94</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><msub><mi>F</mi><mtext>out</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07620.tex", "nexttext": "\nThere are stability issues associated with this procedure, that we discuss below, however the main challenge in this approach is to determine the appropriate auxiliary target functions. Our solution to this problem is to obtain them from a continuous-variable model.  More generally, if we can train or otherwise identify another model that implements a solution to a task, we can use signals generated from that model to train our spiking network.\n\n{\\vspace{0.05in} \\noindent{\\bf{{Using continuous variable models to determine auxiliary target functions}}}\\addtocounter{subsection}{1} }\n\nEquations~\\ref{eq:zJsf} and~\\ref{eq:ZWsFout}, respectively, summarize two key features of the vector of functions ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$: 1) They should correspond to the inputs of a recurrently connected dynamic system, and 2) They should provide a basis for the network output ${F_{{\\mbox{\\scriptsize out}}}(t)}$.  To satisfy the first of these requirements, we identify ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ with the inputs of a recurrently connected continuous-variable ``rate\" network. These networks have been studied intensely~\\citep{Sompolinsky, RajanAbbottSompolinsky} and have been trained to perform a variety of tasks \\citep{Jaeger, SussilloAbbott, Buonomano, SussilloRev}.  To satisfy the second condition, we use the desired spiking network output, ${F_{{\\mbox{\\scriptsize out}}}(t)}$, as an \\emph{input} to the rate network.  This allows us to obtain the auxiliary target functions without having to train the continuous variable network. \n\nThe continuous-variable model we use is a randomly connected network of~$\\tilde N$ firing-rate units (throughout we use tildes to denote quantities associated with the continuous-variable network).  Like the spiking networks, these units receive the input~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and, as mentioned above, they also receive ${F_{{\\mbox{\\scriptsize out}}}(t)}$ as an input. The continuous-variable model is described by an $\\tilde N$-component vector ${ {\\bm x}(t) }$ that satisfies the equation\n\n", "itemtype": "equation", "pos": 12227, "prevtext": "\nwhen the network responds to~${F_{{\\mbox{\\scriptsize in}}}(t)}$ (with the approximation being as accurate as possible). \\hyperref[eq:ZWsFout]{Equation~\\ref{eq:ZWsFout}} stipulates that ${ {\\bm s}(t) }$ must provide a basis for the function~${F_{{\\mbox{\\scriptsize out}}}(t)}$.  If it does, it is straightforward to compute the optimal ${\\bm W}$ by minimizing the squared difference between the two sides of equation~\\ref{eq:ZWsFout}, averaged over time.  This can be done either recursively \\citep{Haykin} or using a standard batch least-squares approach.\n\nDetermining the optimal ${\\bm J}$ is significantly more challenging because of the recurrent nature of the network.  ${\\bm J}$ must be chosen so that the input to the network neurons, ${\\bm J}{ {\\bm s}(t) }$, generates a pattern of spiking that produces ${ {\\bm s}(t) }$.  The circularity of this constraint is what makes recurrent network learning difficult.  The difference between the easy problem of computing ${\\bm W}$ and the difficult problem of computing ${\\bm J}$ is that, in the case of ${\\bm W}$, we have the target ${F_{{\\mbox{\\scriptsize out}}}(t)}$ in equation~\\ref{eq:ZWsFout} that specifies what signal ${\\bm W}$ should produce.  For ${\\bm J}$, it is not obvious what the input it generates should be.  \n\nSuppose that we \\emph{did} have targets analogous to ${F_{{\\mbox{\\scriptsize out}}}(t)}$ but for computing ${\\bm J}$ (we call them auxiliary target functions and denote them by the~$N$-component vector~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$).  Then, ${\\bm J}$, like ${\\bm W}$, could be determined by a least-squares procedure, that is, by minimizing the time-averaged squared differences between the two sides of\n\n", "index": 7, "text": "\\begin{equation}\n\t\\label{eq:zJsf}\n\t{\\bm J} { {\\bm s}(t) } \\approx {{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)} \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"{\\bm{J}}{{\\bm{s}}(t)}\\approx{{\\bm{F}}_{{\\mbox{\\scriptsize\\sc J}}}(t)}\\,.\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc71</mi><mo>\u2062</mo><mi>\ud835\udc94</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><msub><mi>\ud835\udc6d</mi><mtext class=\"ltx_font_smallcaps\" mathvariant=\"normal\">J</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07620.tex", "nexttext": "\nwhere $\\tau_x = 10$ ms, $H$ is a nonlinear function (we use $H(\\cdot) = \\tanh(\\cdot)$), and $\\tilde J$, ${\\bm{\\tilde u}}$, and ${\\bm{\\tilde U}}$ are matrices of dimension $\\tilde N\\times\\tilde N$, $\\tilde N\\times N_{{\\mbox{\\scriptsize out}}}$ and  $\\tilde N\\times N_{{\\mbox{\\scriptsize in}}}$, respectively.  The elements of these matrices are chosen independently from a Gaussian distribution of zero mean and variance $1/N$ for $J$, and a uniform distribution between -1 and 1 for ${\\bm{\\tilde u}}$ and ${\\bm{\\tilde U}}$ unless stated otherwise.  We set $\\tilde g = 1.2$ except where identified otherwise.\n\nTo be sure that signals from this driven network are appropriate for training the spiking model, the continuous-variable network, driven by the target output, should be capable of producing a good approximation of ${F_{{\\mbox{\\scriptsize out}}}(t)}$.  To check this, we can test whether an $N_{{\\mbox{\\scriptsize out}}}\\times \\tilde N$ matrix can be found (by least squares) that satisfies ${\\bm{\\tilde W}} H({ {\\bm x}(t) }) \\approx {F_{{\\mbox{\\scriptsize out}}}(t)}$ to a sufficient degree of accuracy. Provided~${\\bm{\\tilde J}}$ and~${\\bm{\\tilde u}}$ are appropriately scaled, this can be done for a wide range of tasks \\citep{SussilloRev}. \n\nThe auxiliary target functions~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ that we seek are generated from the inputs to the neurons in the continuous-variable network.  There is often, however, a mismatch between the dimensions of~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$, which is $N$, and of the inputs to the continuous-variable model, which is $\\tilde N$.  To deal with this, we introduce an $N\\times\\tilde N$ matrix ${\\bm u}$, with elements drawn independently from a uniform distribution over the range $\\pm\\sqrt{3/\\tilde N}$, and write\n\n", "itemtype": "equation", "pos": 14432, "prevtext": "\nThere are stability issues associated with this procedure, that we discuss below, however the main challenge in this approach is to determine the appropriate auxiliary target functions. Our solution to this problem is to obtain them from a continuous-variable model.  More generally, if we can train or otherwise identify another model that implements a solution to a task, we can use signals generated from that model to train our spiking network.\n\n{\\vspace{0.05in} \\noindent{\\bf{{Using continuous variable models to determine auxiliary target functions}}}\\addtocounter{subsection}{1} }\n\nEquations~\\ref{eq:zJsf} and~\\ref{eq:ZWsFout}, respectively, summarize two key features of the vector of functions ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$: 1) They should correspond to the inputs of a recurrently connected dynamic system, and 2) They should provide a basis for the network output ${F_{{\\mbox{\\scriptsize out}}}(t)}$.  To satisfy the first of these requirements, we identify ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ with the inputs of a recurrently connected continuous-variable ``rate\" network. These networks have been studied intensely~\\citep{Sompolinsky, RajanAbbottSompolinsky} and have been trained to perform a variety of tasks \\citep{Jaeger, SussilloAbbott, Buonomano, SussilloRev}.  To satisfy the second condition, we use the desired spiking network output, ${F_{{\\mbox{\\scriptsize out}}}(t)}$, as an \\emph{input} to the rate network.  This allows us to obtain the auxiliary target functions without having to train the continuous variable network. \n\nThe continuous-variable model we use is a randomly connected network of~$\\tilde N$ firing-rate units (throughout we use tildes to denote quantities associated with the continuous-variable network).  Like the spiking networks, these units receive the input~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and, as mentioned above, they also receive ${F_{{\\mbox{\\scriptsize out}}}(t)}$ as an input. The continuous-variable model is described by an $\\tilde N$-component vector ${ {\\bm x}(t) }$ that satisfies the equation\n\n", "index": 9, "text": "\\begin{equation}\n\\tau_x\\frac{d{ {\\bm x}(t) }}{dt} = -{ {\\bm x}(t) } + \\tilde g{\\bm{\\tilde J}} H({ {\\bm x}(t) }) + {\\bm{\\tilde u}}{F_{{\\mbox{\\scriptsize out}}}(t)} + {\\bm{\\tilde U}}{F_{{\\mbox{\\scriptsize in}}}(t)} \\, ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\tau_{x}\\frac{d{{\\bm{x}}(t)}}{dt}=-{{\\bm{x}}(t)}+\\tilde{g}{\\bm{\\tilde{J}}}H({{%&#10;\\bm{x}}(t)})+{\\bm{\\tilde{u}}}{F_{{\\mbox{\\scriptsize out}}}(t)}+{\\bm{\\tilde{U}}%&#10;}{F_{{\\mbox{\\scriptsize in}}}(t)}\\,,\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c4</mi><mi>x</mi></msub><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mi>\ud835\udc99</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mrow><mo>=</mo><mrow><mrow><mo>-</mo><mrow><mi>\ud835\udc99</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mover accent=\"true\"><mi>g</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc71</mi><mo mathvariant=\"bold\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc99</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mover accent=\"true\"><mi>\ud835\udc96</mi><mo mathvariant=\"bold\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msub><mi>F</mi><mtext>out</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mover accent=\"true\"><mi>\ud835\udc7c</mi><mo mathvariant=\"bold\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msub><mi>F</mi><mtext>in</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07620.tex", "nexttext": "\nWe leave out the input term proportion to ${F_{{\\mbox{\\scriptsize in}}}(t)}$ in this expression because the spiking network receives the input ${F_{{\\mbox{\\scriptsize in}}}(t)}$ directly.  This set of target functions satisfies both of the requirements listed at the beginning of this section and, as we show in the following examples, they allow functional spiking networks to be constructed by finding connections ${\\bm J}$ that satisfy equation~\\ref{eq:zJsf}.  We do this initially by a recursive least squares algorithm \\citep{Haykin}, but later we discuss solving this problem by batch least squares instead.\n\n{\\vspace{0.05in} \\noindent{\\bf{{Examples of trained networks}}}\\addtocounter{subsection}{1} }\n\nThe procedure described above can be used to construct networks that perform a variety of tasks. We present three examples that range from tasks inspired by problems of relevance to neuroscience to modeling experimental data. \n\nOur first example is an autonomous oscillation task that requires the network to generate a self-sustained, temporally complex output~(\\hyperref[fig:Figure2]{Figure \\ref*{fig:Figure2}}). \n\\begin{figure}\n\\centerline{\\includegraphics[width=2in]{Fig2_alt.pdf}}\n\t\\caption{Network activity before and after training for an autonomous oscillation task. {\\bf (a)} Membrane voltage and spiking activity of two example neurons. {\\bf (b)} Raster plot of 200 neurons. {\\bf (c)} Random recurrent input~${\\bm J}^{{\\mbox{\\scriptsize f}}}{ {\\bm f}(t) }$ for two example neurons.  {\\bf (d)} Auxiliary target function~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ (black) and learned recurrent input~${\\bm J}{ {\\bm s}(t) }$ (red) for two example neurons. {\\bf (e)} Target output~${F_{{\\mbox{\\scriptsize out}}}(t)}$ (black) and the generated output~${\\bm W}{ {\\bm s}(t) }$ (red) over one period.  Parameter for this example: $N = 3000$, $g = 7$ mV, $\\mu = -57$, $g_{{\\mbox{\\scriptsize f}}} = 17$, and $\\tilde N = 1000$.}\n\\label{fig:Figure2}\t\n\\end{figure}\n${F_{{\\mbox{\\scriptsize out}}}(t)}$ for this task is a periodic function created by summing sine functions with frequencies of 1, 2, 3, and 5 Hz.  We require that the network generates this output autonomously, therefore~${F_{{\\mbox{\\scriptsize in}}}(t)} = 0$ for this example. Complex, autonomous oscillatory dynamics are a feature of neural circuits involved in repetitive motor acts such locomotion \\citep{Marder}.\n\nInitially ${\\bm J} = 0$, so the activity of the network is determined by the random synaptic input prodvide by~${\\bm J}^{{\\mbox{\\scriptsize f}}}$, and the neurons exhibit irregular spiking~(\\hyperref[fig:Figure2]{Figure \\ref*{fig:Figure2}a-c}).  In this initial configuration, the average Fano factor, computed using 100 ms bins, is 0.5, and the average firing rate across the network is 5 Hz. Following the training procedure,  the learned postsynaptic currents ${\\bm J}{ {\\bm s}(t) }$ closely match their respective auxiliary target functions~(\\hyperref[fig:Figure2]{Figure \\ref*{fig:Figure2}d}), and the network output similarly matches the target~${F_{{\\mbox{\\scriptsize out}}}(t)}$~(\\hyperref[fig:Figure2]{Figure \\ref*{fig:Figure2}e}). Residual chaotic spiking due to~${\\bm J}^{{\\mbox{\\scriptsize f}}}$~(\\hyperref[fig:Figure2]{Figure \\ref*{fig:Figure2}c}) and the fact that we are approximating a continuous function by a sum of discontinuous functions cause unavoidable deviations. Nevertheless, a network of 3,000 LIF neurons firing at an average rate of 6.5 Hz with an average Fano factor of 0.25 performs this task with normalized post-training error of 5\\% (this error is the variance of the difference between ${\\bm W}{ {\\bm s}(t) }$ and ${F_{{\\mbox{\\scriptsize out}}}(t)}$ divided by the variance of ${F_{{\\mbox{\\scriptsize out}}}(t)}$).\n\nBecause the output for this first task can be produced by a linear dynamical system, previous methods could also have been used to construct a functioning spiking network \\citep{Eliasmith, BoerlinMachensDeneve}. However, this is no longer true for the following examples.  In addition, it is worth noting that the network we have constructed generates its output as an isolated periodic attractor of a nonlinear dynamical system. The other procedures, in particular that of \\citet{BoerlinMachensDeneve}, create networks that reproduce the linear dynamics that generates ${F_{{\\mbox{\\scriptsize out}}}(t)}$.  This results in a system that can produce not only ${\\bm W}{ {\\bm s}(t) }\\approx{F_{{\\mbox{\\scriptsize out}}}(t)}$, but also ${\\bm W}{ {\\bm s}(t) }\\approx\\alpha {F_{{\\mbox{\\scriptsize out}}}(t)}$ over a continuous range of $\\alpha$ values.  This often results in a slow drift in the amplitude of ${\\bm W}{ {\\bm s}(t) }$ over time.  The point here is that our procedure solves a different problem than previous procedures, despite the fact that it generates the same output.  The previous procedures were designed to duplicate the linear dynamics that produce ${F_{{\\mbox{\\scriptsize out}}}(t)}$, whereas our procedure duplicates ${F_{{\\mbox{\\scriptsize out}}}(t)}$ uniquely.\n\nThe second task we present is a temporal XOR task that requires the network to categorize the input it receives on a given trial and report this decision through its output.  Each trial for this task consists of a sequence of two pulses appearing as the network input~${F_{{\\mbox{\\scriptsize in}}}(t)}$~(\\hyperref[fig:Figure3]{Figure \\ref*{fig:Figure3}}).\n\\begin{figure}\n\\centerline{\\includegraphics[width=3in]{Fig3_new2.pdf}}\n\\caption{Temporal XOR task.  The input ${F_{{\\mbox{\\scriptsize in}}}(t)}$ (black) consists of two pulses that are either short or long in duration. The output~${\\bm W}{ {\\bm s}(t) }$ (red) should report an XOR function of the combination of pulses.  Membrane potentials of 10 example neurons (blue) are shown for the 4 different task conditions. Parameters for this example: $N = 3000$, $g = 10$ mV, $\\mu = -40$, $g_{{\\mbox{\\scriptsize f}}} = 12$ and $\\tilde N = 1000$.}\n\\label{fig:Figure3}\t\n\\end{figure}\nEach pulse has an amplitude of 0.3, and its duration can be either short (100 ms) or long (300 ms).  The two pulses are separated by 300 ms, and after an additional 300 ms delay the network must respond with either a positive or a negative pulse (with a shape given by 1/2 cycle of a 1 Hz sinewave).  The rule for choosing a positive or negative output is an exclusive OR function of the input sequence (short-short $\\rightarrow -$, short-long $\\rightarrow +$, long-short $\\rightarrow +$, long-long $\\rightarrow -$).  The time between trials and the input sequence on each trial are chosen randomly.\n \nA network of 3,000 LIF neurons with an average firing rate of~7 Hz can perform this task correctly on 95\\% of trials.  As in the autonomous oscillation task, individual neuron spiking activity varies from trial-to-trial due to the effect of~${\\bm J}^{{\\mbox{\\scriptsize f}}}$. The Fano factor computed across all neurons, all analysis times, and all task conditions is 0.26\\@.  This task requires integration of each input pulse, storage of a memory of the first pulse at least until the time of the second pulse, memory of the decision during the delay period before the output is produced, and classification according to the XOR rule.\n\n{\\vspace{0.05in} \\noindent{\\bf{{Generating EMG activity during reaching}}}\\addtocounter{subsection}{1} } \n\nWe now turn to an example based on data from an experimental study, with the spiking network generating outputs that match electromyograms (EMGs) recorded in 2 arm muscles of a non-human primate performing a reaching task~\\citep{ChurchlandCunningham}.  In this task, a trial begins with the appearance of a target cue at one of eight possible reach directions (task conditions). After a short delay, during which the arm position must be held fixed, a ``go'' cue appears, instructing a reach to  the target. The time between trials and the sequence of reach directions are varied randomly.  \n\n\\begin{figure}\n\\centerline{\\includegraphics[width=3.5in]{Fig4_CORRECT.pdf}}\n\\caption{Producing EMG during reaching. {\\bf (a)} Task design. A two-dimensional input (left) is applied to the network for~500 ms to specify a reach direction after which the network must produce output matching the corresponding EMG activity patterns recorded from two arm muscles (right). Each color represents the activity for a specific direction. {\\bf (b)} Raster plot showing the activity of a single neuron across all trials (each row) for all conditions (different colors). The Fano factor for this neuron is 1.2. {\\bf (c)} Firing rate of the neuron shown in (b). Each color represents the trial-averaged firing rate for a single condition. {\\bf (d)} The Fano factor as a function of time computed across all neurons and conditions. {\\bf (e)} ${\\bm W}{ {\\bm s}(t) }$ for both outputs and all conditions (different colors) on a single trial. {\\bf (f)} Firing rates for four network neurons. Some neurons are tuned during input or output periods exclusively (bottom two plots), while most are tuned during both periods (top two plots). {\\bf (g)} Trial-averaged firing rate autocorrelation, averaged across all neurons and all conditions.  By the time of movement, the autocorrelation function is near zero, indicating that the tuning between input and movement periods is, on average, uncorrelated.  The time bar in all panels represents 200 ms, and the dot denotes movement onset. Parameters for this example: $N = 5000$, $\\mu = -112$, $g_{{\\mbox{\\scriptsize f}}} = 33$, $g = 7.2$ mV, $\\tilde N = 1000$, $\\tilde g = 1.4$.  Also, in this example, the elements of ${\\bm{\\tilde u}}$ were chosen randomly and uniformly over the range $\\pm 0.76$, and the range for ${\\bm{\\tilde U}}$ was $\\pm 0.25$. The refractory period was set to zero in this example. EMGs were filtered with a 4 ms Gaussian window.}\n\\label{fig:Figure4}\t\n\\end{figure}\n\nTo convey information about target location to the model, we use two network inputs denoted by a two-component vector~${F_{{\\mbox{\\scriptsize in}}}(t)}$ and with amplitudes $2\\cos(\\theta)$ and $2\\sin(\\theta)$ where the angle $\\theta$ specifies the reach direction~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}a left}). The input is applied for~500 ms and, when it terminates, the network is required to generate two outputs (thus ${F_{{\\mbox{\\scriptsize out}}}(t)}$ is also two-dimensional) that match trial-averaged and smoothed EMG recordings from the anterior and posterior deltoid muscles during reaches to the specified target~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}a right \\& e}). \n\nA network of 5,000 neurons with an average firing rate of~6 Hz performs this task with a normalized post-training error of 7\\%~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}e}), consistent with another modeling study that used a firing-rate network~\\citep{SussilloChurchland}.  The activity of the trained network exhibits several features consistent with recordings from neurons in motor cortex. Individual neurons show a large amount of spiking irregularity that is variable across trials and conditions~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}b}). The Fano factor computed across all neurons and all task conditions drops during task execution~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}d}), consistent with observations across a wide range of cortical areas~\\citep{Churchlandetal}. This network shows that EMGs can be generated by a network with a realistic degree of spiking variability.\n\nAnother interesting feature of the network activity is the variety of different neural responses. Individual neurons display tuning during the input period, the output period, or across multiple epochs with different tunings~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}f}). As in recordings from motor cortex, consistently tuned neurons represent a minority of the network; most neurons change their tuning during the task~(\\hyperref[fig:Figure4]{Figure \\ref*{fig:Figure4}g}).  \n\n\\begin{figure}\n\\centerline{\\includegraphics[width=4in]{Fig5_alt.pdf}}\n\\caption{Population level analyses of EMG task activity. {\\bf (a)} Temporal PCs 3,4 and 7 computed on a single-trial using data from all neurons and all conditions. Results from three different trials are shown in different colors. {\\bf (b)} Same as (a) except displaying temporal PCs 50,51 and 52.  {\\bf (c)} Fraction of the total variance captured in successive temporal PCs for single-trial PCA analysis (blue), and fraction of the EMG variance accounted for when regressing against increasing numbers of PCs (red traces corresponding to multiple trials).}\n\\label{fig:Figure5}\t\n\\end{figure}\n\nTo examine the population dynamics of this model, we performed PCA on filtered (4 ms Gaussian filter) single-trial spike trains from a~$T\\times NC$ data matrix, where~$T$ is the number of times sampled during a trial (2900),~$N$ is the number of neurons (5000), and~$C$ is the number of reach conditions (8).  We computed the eigenvectors of the~$T \\times T$ covariance matrix obtained from these ``data\", generating temporal PCs~(\\hyperref[fig:Figure5]{Figure \\ref*{fig:Figure5}a \\& b}).  Each temporal PC represents a temporal function that is strongly represented across the population and across all reach conditions, albeit in different ways across the population on a single trial for each condition.  Two important features emerge from this analysis. First, more prominent single-trial PCs~(\\hyperref[fig:Figure5]{Figure \\ref*{fig:Figure5}a}) are relatively consistent from trial-to-trial, while less prominent PCs~(\\hyperref[fig:Figure5]{Figure \\ref*{fig:Figure5}b}) vary more. Second, the prominent PCs fluctuate on a slower time scale than the less prominent PCs. These two features indicate that the more prominent PCs form the basis of the network output on a single trial, while the less prominent PCs reflect network noise. This can be verified by reconstructing the network output using increasing numbers of temporal PCs and calculating the fraction of the output variance captured~(\\hyperref[fig:Figure5]{Figure \\ref*{fig:Figure5}c red}).  A small number of the leading PCs account for most of the network output variance despite the fact that they account for only a fraction of the full activity variance on a single trial~(\\hyperref[fig:Figure5]{Figure \\ref*{fig:Figure5}c blue}).\n\n{\\vspace{0.05in} \\noindent{\\bf{{Learning constrained connectivities}}}\\addtocounter{subsection}{1} } \n\nThe examples we have presented up to now involve a fully connected ${\\bm J}$ matrix with no sign constraints.  In other words, no elements were constrained to be zero, and the training procedure could make the sign of any element either positive or negative.  Biological networks tend to be sparse (many elements of ${\\bm J}$ are fixed at zero) and obey Dale's law, corresponding to excitatory and inhibitory cell types.  This implies that the columns of ${\\bm J}$ should be labelled either excitatory or inhibitory and constrained to have the appropriate sign ($+$ for excitatory and $-$ for inhibitory). Here we outline a procedure for training a network to solve a task while abiding by these constraints.\n\nIn the previous examples, we used a  recursive least squares (RLS) procedure to compute ${\\bm J}$ because of stability issues that we now explain.  Satisfying equation~\\ref{eq:zJsf} accurately assures that ${ {\\bm s}(t) }$ can be generated self-consistently, but it does not guarantee that the resulting network state will be stable, and if it is unstable the least-squares solution is useless.  We find that the use of RLS resolves this problem.  As explained previously \\citep{SussilloAbbott}, RLS provides stability because the fluctuations produced by the network when it is doing the task are sampled during the recursive procedure, allowing adjustments to be made that quench instabilities.  However, when sparseness and especially sign constraints are impossed, use of RLS becomes impractical.  Instead we must resort to a batch least-squares (BLS) algorithm.  \n\nThe BLS algorithm computes ${\\bm J}$ on the basis of samples of ${ {\\bm s}(t) }$ that must be provided.  To assure a stable solution, these samples should not only characterize the activity of a network doing the task, they should include the typical fluctuations that arise during network operation.  To obtain such samples, we perform the network training in two steps.  First, we train a fully connected and sign-unconstrained network using the RLS procedure, just as in the previous examples.  We sample ${ {\\bm s}(t) }$ from this network during the training process, and use these samples to solve the BLS problem while enforcing the desired constraints. \n\n\\begin{figure}\n\\centerline{\\includegraphics[width=4in]{Fig6_alt.pdf}}\n\\caption{Performing the autonomous oscillation task (Figure~\\ref{fig:Figure2}) with constrained connectivity.  {\\bf (a)} ${F_{{\\mbox{\\scriptsize out}}}(t)}$ (dashed black) and ${\\bm W}{ {\\bm s}(t) }$ (magenta) from a network with 50\\% sparse connectivity. {\\bf (b)} ${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ (dashed black) and ${\\bm J}{ {\\bm s}(t) }$ (magenta) for one neuron during training. Residual fluctuations can be seen, critical for stability after learning.  {\\bf (c)} Entries of~${\\bm J}$ for 100 neurons. {\\bf (d)} Same as (a) except residuals from RLS solutions were shuffled before BLS was performed.  {\\bf (e)} Same as (b), except showing shuffled residuals. {\\bf (f)} Cumulative variance of successive PCs of the spatial covariance matrix of the RLS residuals (magenta) and the shuffled residuals (cyan). {\\bf (g)} ${F_{{\\mbox{\\scriptsize out}}}(t)}$ (dashed black) and ${\\bm W}{ {\\bm s}(t) }$ (red) from a network with 50\\% sparseness satisfying Dale's Law (with 50\\% excitatory and $50\\%$ inhibitory neurons). {\\bf (h)} Entries of~${\\bm J}$ for (g) for 100 neurons. {\\bf (i)} Histogram of the entries of~${\\bm J}$ for (g). Network parameters: $N = 1000$, $\\mu = g_{{\\mbox{\\scriptsize f}}} = 0$, $g =  15$ mV\\@.}\n\\label{fig:Figure6}\t\n\\end{figure}\n\nApplying this two-step procedure, we can construct networks that perform the autonomous oscillation task of Figure~\\ref{fig:Figure2} with 50\\% sparseness, either without~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}a-c}) or with~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}g-i}) a Dale's law constraint. The normalized post-training error for both networks on this task is 5\\%, although to obtain this level we had to allow an average firing rate of~22 Hz.  In addition, the random connectivity represented by ${\\bm J}^{{\\mbox{\\scriptsize f}}}$ was not included in this case because, for the number of neurons we used (1000), these networks are somewhat fragile to chaotic fluctuations.  This fragility could be reduced by using more neurons, but even with BLS the computations, especially for the sign-constrained case, are quite lengthy.\n\nWe argued that the two-step training procedure was needed to sample network fluctuations properly.  Could we have simply added white noise to samples of ${ {\\bm s}(t) }$ that did not contain the actual fluctuations produced by an operating network~\\citep{Jaeger, Eliasmith}?  PCA on the covariance matrix of the network fluctuations obtained during RLS training shows that most of their variance is captured by a small number of PCs~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}f magenta}), indicating significant spatial correlations.  The temporal autocorrelation function for residual errors also showed significant correlation (not shown).  To understand the role of these correlations, we created a  dataset of ${ {\\bm s}(t) }$ with the actual network fluctuations replaced by shuffled fluctuations.  Although the shuffled synaptic input~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}e}) is very similar to the unshuffled input~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}b}), use of the shuffled data set resulted in poor performance of the trained network~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}d}).  This is because the shuffled data fail to capture the correlations present in the actual network fluctuations~(\\hyperref[fig:Figure6]{Figure \\ref*{fig:Figure6}f cyan}). These results reaffirm the conclusion that the RLS algorithm is effective for sampling network instabilities, and that the fluctuations obtained in this way can  be used effectively to obtain constrained BLS values for ${\\bm J}$.\n\n{\\vspace{0.05in}\\noindent{{\\large\\bf{{Discussion}}}} \\addtocounter{section}{1}\\setcounter{subsection}{0} }\n\nWe have developed a framework for constructing recurrent spiking neural networks that perform the types of tasks solved by biological neural circuits and that can be made compatible with biophysical constraints on connectivity.  In this approach, the first step in producing a spiking system that implements a task is to identify a continuous-variable dynamical system that can, at least in principle, perform the task. Previous approaches to building models that perform tasks also resorted to identifying continuous analog systems.  A key distinction, however, is that by exploiting the rich dynamics of externally driven, randomly connected, continuous-variable models, we can apply our approach to cases where a dynamic description of the task is not readily apparent.  In general, any continuous variable network that can implement a task should generate useful auxiliary targets for training a spiking model.  An intriguing future direction would be to use continuous-variable networks trained with back-propagation \\citep{MartensSutskever, SussilloChurchland, SussilloRev} for this purpose.  Another recent proposal for training spiking networks also makes use of continuous-variable network dynamics, but in this interesting approach, a spiking network is constructed to duplicate the dynamics of a continuous-variable model, and then it is trained essentially as if it were the continuous model \\citep{Thalmeieretal}.\n\nOur work involves a more complex map from the continuous variables of a ``rate\" model to the action potentials of a spiking model.  The simplest map of this type assigns a population of spiking neurons to each unit of the continuous-variable model such that their collective activity represents the continuous ``firing-rate\".  If we had followed this path, our spiking networks would have likely involved hundreds of thousands to millions of model neurons.  In our approach, only a few times as many spiking neurons as continuous variable units are needed.  Performing PCA on the activity of a continuous-variable network reveals that relatively small number of PCs capture a large fraction of the variance \\citep{RajanAbbottSompolinsky, SussilloAbbott}.  Thus, the unit activity in these networks is redundant, and matching every unit with a different population of spiking neurons is wasteful because this amounts to representing the same PCs over and over again.  Our approach avoids this problem by distributing continuous signals from the entire continuous-variable network to overlapping pools of spiking neurons. \n \nOur work also involves a novel interpretation of continuous variable models and the outputs of their units. These models are typically considered to be approximations of spiking models \\citep{Ermentrout, Gerstner, Shriki, Ostojic}.  We do not interpret the ``firing rates\" of units in continuous-variable networks as measures of the spiking rates of any neuron or collection of neurons in our spiking networks (in fact, these ``firing rates\" can be negative, which is why we avoid the term firing-rate network).  Instead, the continuous-variable networks are generators of the principle components upon which the dynamics of both networks are based. PCA applied to ${ {\\bm s}(t) }$ of the spiking network and to  $H({\\bm{x}})$ of the continuous-variable network yield very similar results, at least for the predominant PCs.  For example, the leading 10 temporal PCs account for more than 90\\% of the total variance for both networks, and the median of the principle angles between the subspaces defined by these two sets of 10 vectors is 5 degrees.  This indicates that the temporal signals that dominate the dynamics and output of these two different types of networks are extremely similar. \n\nWe extracted a new set of auxiliary targets by projecting the original set onto a relatively small number of PCs of the continuous-variable network, and this did not have a detrimental impact on network training.  We did this for the autonomous oscillator task using just 12 PCs, and the normalized error for the resulting network was similar to the error for the network shown in Figure~\\ref{fig:Figure2}. This confirms that the key information being passed from the continuous-variable network to the spiking network is carried by the leading PCs.  The continuous-variable network is used in our procedure as a way of computing the PCs relevant to a task.  If these can be obtained in another way, the spiking network could be trained directly from the PCs.  One way of doing this is to extract the PCs directly from data, as has been done in other studies \\citep{Fisheretal, RajanHarveyTank}. \n\nFinally, our approach strongly supports the use of continuous-variable models to analyze and understand neural circuits.  However, it is important to appreciate that the connection between spiking and continuous-variable networks is subtle.  In our procedure, the connectivity and nonlinearity in the continuous network bear no relation to the corresponding features of the spiking model, and the continuous network is not unique.  Furthermore, the signals that allow a task to be performed are only apparent at the population level.  In addition, since our spiking networks are not constructed by a rational design process, it may not be immediately apparent how they work.  Nevertheless, the underlying continuous-variable model, and especially its leading PCs, capture the essence of how the spiking network operates and tools exist for understanding this operation in detail \\citep{SussilloBarak}.  These models and methods should do the same for experimental data. \n\n\\newpage\n{\\vspace{0.05in}\\noindent{{\\large\\bf{{Acknowledgments}}}} \\addtocounter{section}{1}\\setcounter{subsection}{0} }\n\nWe are grateful to Antonio Lara for providing the EMG data.  Research supported by NIH grant MH093338 and by the Simons Collaboration for the Global Brain, the Gatsby Charitable Foundation, the Swartz Foundation, the Mathers Foundation and the Kavli Institute for Brain Science at Columbia University.  B.D. was supported by a National Science Foundation Graduate Research Fellowship. \n\n\\begin{thebibliography}{99}\n\n\t\\bibitem[Abbott, DePasquale \\& Memmesheimer(2016)]{Abbottetal}\n\tAbbott, L.F., DePasquale, B., Memmesheimer, R.-M. (2016) Building functional networks of spiking model neurons. {\\emph Nat. Neurosci.}, (to be published).\n\t\n\t\\bibitem[Boerlin \\& Den\\`{e}ve(2011)]{BoerlinDeneve}\n\tBoerlin, M., Den\\`eve, S. (2011) Spike-based population coding and working memory. \\emph{PLoS Comput. Biol.} 7:e1001080.\n\n\t\\bibitem[Boerlin, Machens \\& Den\\`{e}ve(2013)]{BoerlinMachensDeneve}\n\tBoerlin, M., Machens, C.K., Den\\`{e}ve S. (2013). Predictive coding of dynamical variables in balanced spiking networks. \\emph{PLoS Comp Biol}, 9(11): e1003258.\n\t\n\t\\bibitem[Brunel(2000)]{Brunel}\n\tBrunel, N. (2000). Dynamics of networks of randomly connected excitatory and inhibitory spiking neurons. \\emph{J. Physiol. (Paris)} 94, 445\u00d0463.\n\n\t\\bibitem[Churchland, Lara \\& Cunningham(2016)]{ChurchlandCunningham}\n\tChurchland, M.M., Lara, A.H., Cunningham, J.P. (2016).  The motor cortex and supplementary motor area exhibit different population-level dynamics. COSYNE annual meeting abstract.\n\t\t\n\t\\bibitem[Churchland {\\it et. al.}(2010)]{Churchlandetal}\n\tChurchland, M.M., Yu, B.M., {\\it et. al.} (2010). Stimulus onset quenches neural variability: a widespread cortical phenomenon. \\emph{Nat Neurosci}, 13(3):369-378.\n\t\n\t\\bibitem[Eliasmith(2005)]{Eliasmith}\n\tEliasmith, C. (2005). A unified approach to building and controlling spiking attractor networks. \\emph{Neural Computation}, 17:1276-1314.\n\t\n\t\\bibitem[Ermentrout(1994)]{Ermentrout}\n\tErmentrout, B. (1994) Reduction of conductance-based models with slow synapses to neural nets. {\\emph Neural Comput.}, 6: 679\u00d0695.\n\t\n\t\\bibitem[Fisher {\\it et. al.}(2013)]{Fisheretal}\n\tFisher, D., Olasagasti, I., Tank, D. W., Aksay, E. R. F., Goldman, M. S. (2013) A modeling framework for deriving the structural and functional architecture of a short-term memory microcircuit. {\\emph Neuron}, 79:987\u00d01000.\n\t\n\t\\bibitem[Gerstner(1995)]{Gerstner}\n\tGerstner, W. (1995) Time structure of the activity in neural network models. {\\emph Phys. Rev. E}, 51: 738\u00d0758.\n\t\n\t\\bibitem[Haykin(2002)]{Haykin}\n\tHaykin, S. (2002) Adaptive Filter Theory (Upper Saddle River, NJ: Prentice Hall).\n\t\n\t\\bibitem[Hennequin {\\it et. al.}(2014)]{Hennequin}\n\tHennequin, G., Vogels, T.P., Gerstner, W. (2014). Optimal Control of Transient Dynamics in Balanced Networks Supports Generation of Complex Movements. \\emph{Neuron}, 82:1394-1406.\n\t\n\t\\bibitem[Jaeger \\& Haas(2004)]{Jaeger}\n\tJaeger, H. \\& Haas, H. (2004). Harnessing nonlinearity: predicing chaotic systems and saving energy in wireless communication. \\emph{Science}, 304:78-80.\n\t\n\t\\bibitem[Laje \\& Buonomano(2013)]{Buonomano}\n\tLaje, R., Buonomano, D.V. (2013) Robust timing and motor patterns by taming chaos in recurrent neural networks. \\emph{Nat. Neurosci.}, 16:925\u00d0933.\n\t\n\t\\bibitem[Machens, Romo \\& Brody (2005)]{MachensBrody}\n\tMachens, C.K., Romo, R., Brody, C.D. (2005). Flexible control of mutual inhibition: a neural model of two-interval discrimination. \\emph{Science}, 307:1121-1124.\n\t\n\t\\bibitem[Marder(2000)]{Marder}\n\tMarder, E. (2000) Motor pattern generation. {\\emph Curr. Opin. Neurobiol.}, 10: 691-698.\n\t\n\t\\bibitem[Martens \\& Sutskever(2011)]{MartensSutskever}\n\tMartens, J. and Sutskever, I. (2011). Learning recurrent neural networks with Hessian-free optimization. \\emph{Proc. 28$^{th}$ Int. Conf. on Machine Learning, (Bellevue, WA)}.\n\t\n\t\\bibitem[Ostojic \\& Brunel(2011)]{Ostojic}\n\tOstojic, S., Brunel, N. (2011) From spiking neuron models to linear-nonlinear models. {\\emph PLoS Comput. Biol.}, 7: e1001056.\n\t\n\t\\bibitem[Rajan, Abbott \\& Sompolinsky(2010)]{RajanAbbottSompolinsky}\n\tRajan, K, Abbott, L.F., Sompolinsky, H. (2010). Stimulus-dependent suppression of chaos in recurrent neural networks. \\emph{Physical Review E}, 82:011903.\n\t\n\t\\bibitem[Rajan, Harvey \\& Tank(2016)]{RajanHarveyTank}\n\tRajan, K., Harvey, C., Tank, D. Recurrent network models of sequence generation and memory. {\\emph Neuron} (to be published).\n\t\n\t\\bibitem[Seung {\\it et. al.}(2000)]{Seung}\n\tSeung, H.S., Lee, D.D., Reis, B.Y., Tank, D.W. (2000). Stability of the memory of eye position in a recurrent network of conductance-based model neurons. \\emph{Neuron}, 26:259-271.\n\t\n\t\\bibitem[Shriki, Hansel \\& Sompolinsky(2003)]{Shriki}\t\n\tShriki, O., Hansel, D., Sompolinsky, H. (2003) Rate models for conductance-based cortical neuronal networks. {\\emph Neural Comput.},15: 1809\u00d01841.\n\t\n\t\\bibitem[Sompolinsky, Crisanti \\& Sommers(1988)]{Sompolinsky}\n\tSompolinsky, H., Crissanti, A., and Sommers, H.J. (1988). Chaos in Random Neural Networks. \\emph{Cerebral Phys. Rev. Lett.}, 61:259-262.\n\t\n\t\\bibitem[Sussillo(2014)]{SussilloRev}\n\tSussillo, D. (2014) Neural circuits as computational dynamical systems. {\\emph Curr. Opin. Neuro- biol.}, 25:156\u00d0163.\n\t\n\t\\bibitem[Sussillo \\& Abbott(2009)]{SussilloAbbott}\n\tSussillo, D. and Abbott, L.F. (2009). Generating coherent patterns of activity from chaotic neural networks. \\emph{Neuron}, 63(4):544-557.\n\t\n\t\\bibitem[Sussillo \\& Barak(2013)]{SussilloBarak}\n\tSussillo, D., Barak, O. (2013)\n\tOpening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks. \\emph{Neural Comput.}, 25:626-649.\n\t\n\t\\bibitem[Sussillo {\\it et. al.}(2015)]{SussilloChurchland}\n\tSussillo, D., Churchland, M.M., Kaufman, M.T. \\& Shenoy, K.V. (2015). A neural network that finds a naturalistic solution for the production of muscle activity. \\emph{Nat Neurosci}, 18:1025-1033.\n\t\n\t\\bibitem[Thalmeier {\\it et. al.}(2015)]{Thalmeieretal}\n\tThalmeier, D., Uhlmann, M., Kappen, H. J., Memmesheimer, R.-M. (2015) Learning universal computations with spikes. arXiv:1505.07866.\n\t\t\n\t\\bibitem[van Vreeswijk \\& Sompolinsky(1998)]{VanVreeswijkSompolinsky}\n\tvan Vreeswijk, C. \\& Sompolinsky, H. (1998). Chaotic balanced state in a model of cortical circuits. \\emph{Neural Computation}, 10:1321-1371.\n\t\n\t\\bibitem[Wang(2002)]{Wang}\n\tWang, X.J. (2002). Probabilistic decision making by slow reverberation in cortical circuits. \\emph{Neuron}, 36:955-968.\n\t\n\\end{thebibliography}\n\n\n", "itemtype": "equation", "pos": 16466, "prevtext": "\nwhere $\\tau_x = 10$ ms, $H$ is a nonlinear function (we use $H(\\cdot) = \\tanh(\\cdot)$), and $\\tilde J$, ${\\bm{\\tilde u}}$, and ${\\bm{\\tilde U}}$ are matrices of dimension $\\tilde N\\times\\tilde N$, $\\tilde N\\times N_{{\\mbox{\\scriptsize out}}}$ and  $\\tilde N\\times N_{{\\mbox{\\scriptsize in}}}$, respectively.  The elements of these matrices are chosen independently from a Gaussian distribution of zero mean and variance $1/N$ for $J$, and a uniform distribution between -1 and 1 for ${\\bm{\\tilde u}}$ and ${\\bm{\\tilde U}}$ unless stated otherwise.  We set $\\tilde g = 1.2$ except where identified otherwise.\n\nTo be sure that signals from this driven network are appropriate for training the spiking model, the continuous-variable network, driven by the target output, should be capable of producing a good approximation of ${F_{{\\mbox{\\scriptsize out}}}(t)}$.  To check this, we can test whether an $N_{{\\mbox{\\scriptsize out}}}\\times \\tilde N$ matrix can be found (by least squares) that satisfies ${\\bm{\\tilde W}} H({ {\\bm x}(t) }) \\approx {F_{{\\mbox{\\scriptsize out}}}(t)}$ to a sufficient degree of accuracy. Provided~${\\bm{\\tilde J}}$ and~${\\bm{\\tilde u}}$ are appropriately scaled, this can be done for a wide range of tasks \\citep{SussilloRev}. \n\nThe auxiliary target functions~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$ that we seek are generated from the inputs to the neurons in the continuous-variable network.  There is often, however, a mismatch between the dimensions of~${{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)}$, which is $N$, and of the inputs to the continuous-variable model, which is $\\tilde N$.  To deal with this, we introduce an $N\\times\\tilde N$ matrix ${\\bm u}$, with elements drawn independently from a uniform distribution over the range $\\pm\\sqrt{3/\\tilde N}$, and write\n\n", "index": 11, "text": "\\begin{equation}\n\t\\label{eq:Jsu}\n\t{{\\bm F}_{{\\mbox{\\scriptsize \\sc J}}}(t)} = {\\bm u}\\Big(\\tilde g{\\bm{\\tilde J}} H({ {\\bm x}(t) }) + {\\bm{\\tilde u}} {F_{{\\mbox{\\scriptsize out}}}(t)}\\Big) \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"{{\\bm{F}}_{{\\mbox{\\scriptsize\\sc J}}}(t)}={\\bm{u}}\\Big{(}\\tilde{g}{\\bm{\\tilde{%&#10;J}}}H({{\\bm{x}}(t)})+{\\bm{\\tilde{u}}}{F_{{\\mbox{\\scriptsize out}}}(t)}\\Big{)}\\,.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\ud835\udc6d</mi><mtext class=\"ltx_font_smallcaps\" mathvariant=\"normal\">J</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\ud835\udc96</mi><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mover accent=\"true\"><mi>g</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc71</mi><mo mathvariant=\"bold\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc99</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mover accent=\"true\"><mi>\ud835\udc96</mi><mo mathvariant=\"bold\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msub><mi>F</mi><mtext>out</mtext></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\" rspace=\"4.2pt\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]