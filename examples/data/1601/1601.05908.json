[{"file": "1601.05908.tex", "nexttext": "\nwhere, $gap_{total}$ exemplifies the amount of decrease in the $cwnd$ which caused by the loss event. In other words, $gap_{total}$ represents the released amount from the bandwidth after loss. $gap_{total}$ is calculated as the distance between the maximum recorded limit of the bandwidth ($cwnd_{loss}$) and the $cwnd_{degraded}$ as in Equation \\eqref{eq2}.\n\n", "itemtype": "equation", "pos": 12580, "prevtext": "\n\n\\begin{frontmatter}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\title{Agile-SD: A Linux-based TCP Congestion Control Algorithm for Supporting High-speed and Short-distance Networks}\n\n\n\n\n\n\n\n\n\\author[lable1]{Mohamed A. Alrshah$^{1,}$}\n\\author[lable1]{Mohamed Othman$^{2,}$}\n\\author[lable2]{Borhanuddin Ali}\n\\author[lable1]{Zurina Mohd Hanapi}\n\\address[lable1]{Department of Communication Technology and Network, Universiti Putra Malaysia, 43400 UPM, Serdang, Selangor D.E., Malaysia}\n\\address[lable2]{Department of Computer and Communication Systems Engineering, Universiti Putra Malaysia, 43400 UPM, Serdang, Selangor D.E, Malaysia.}\n\n\\begin{abstract}\nRecently, high-speed and short-distance networks are widely deployed and their necessity is rapidly increasing everyday. This type of networks is used in several network applications; such as Local Area Networks (LAN) and Data Center Networks (DCN). In LANs and DCNs, high-speed and short-distance networks are commonly deployed to connect between computing and storage elements in order to provide rapid services. Indeed, the overall performance of such networks is significantly influenced by the Congestion Control Algorithm (CCA) which suffers from the problem of bandwidth under-utilization, especially if the applied buffer regime is very small. In this paper, a novel loss-based CCA tailored for high-speed and Short-Distance (SD) networks, namely Agile-SD, has been proposed. The main contribution of the proposed CCA is to implement the mechanism of agility factor. Further, intensive simulation experiments have been carried out to evaluate the performance of Agile-SD compared to Compound and Cubic which are the default CCAs of the most commonly used operating systems. The results of the simulation experiments show that the proposed CCA outperforms the compared CCAs in terms of average throughput, loss ratio and fairness, especially when a small buffer is applied. Moreover, Agile-SD shows lower sensitivity to the buffer size change and packet error rate variation which increases its efficiency.\n\n\\end{abstract}\n\n\\begin{keyword}\n\n\n\nAgile\\sep\nCCA\\sep\nTCP\\sep\nLinux\\sep\nHigh-speed\\sep\nShort-distance\\sep\nBandwidth Utilization\\sep\nFairness\\sep\nSmall Buffer.\n\\end{keyword}\n\n\\end{frontmatter}\n\n\\footnotetext[1]{Corresponding authors: \n\\\\E-mail addresses: mohamed.asnd@gmail.com (Mohamed Alrshah),\\\\mothman@upm.edu.my (Mohamed Othman).}\n\n\\footnotetext[2]{The author is also an associate researcher at the Computational \\mbox{Science} and Mathematical Physics Lab, Institute of Mathematical \\mbox{Science}, Universiti Putra Malaysia.}\n\n\n\n\n\n\n\n\n\\section{Introduction}\n\\label{Intro}\nIn the last decades, the necessity of high-speed and short-distance networks is rapidly increasing everyday due to their wide deployment. Several network applications, such as Local Area Networks (LAN) and Data Center Networks (DCN), are implementing this type of networks \\citep{Buyya2008, Armbrust2010}. These LANs and DCNs serve a very wide range of network-based applications; such as web hosting, searching engines, social media, multimedia broadcasting and storage drives. In the environment of LANs, as shown in Figure \\ref{fig:lantopology}, and DCNs, as shown in Figure \\ref{fig:dctopology} \\citep{Alfares2010, Wu2012, Yoo2012, prakash2012}, high-speed and short-distance networks are commonly deployed to connect computing and storage elements to each other in order to provide rapid services.These networks have certain characteristics which are widely different from other types of networks; for instance, link delay is very small which can be a few milliseconds or even hundreds of microseconds and the Bandwidth-Delay-Product (BDP) of the link is very small compared to its equivalent in high-speed and long-distance networks \\citep{Tahiliani2012, Vasudevan2009}.\n\nThese attributes could negatively affect the performance of the Transmission Control Protocol (TCP) by making it either more aggressive or more conservative based on the applied approach. In fact, the Congestion Control Algorithm (CCA) is one of the main parts of TCP. It significantly affects the overall performance of such networks, because it is still suffering from the problem of bandwidth under-utilization, especially if the applied buffer regime is very small. This under-utilization of bandwidth is caused by the variation of the aforementioned characteristics of the networks which results either a slow growth of $cwnd$ or an over-injection of data into the network \\citep{Afanasyev2010, Scharf2011, Callegari2012b, Callegari2014, Lar2013, acharya2012, alrshah2014}.\n\nIn order to solve the problem of bandwidth under-utilization over high-speed and Short-Distance (SD) networks, a new loss-based CCA, namely Agile-SD, has been proposed. The main contribution of the proposed CCA is to implement the mechanism of agility factor. Further, intensive simulation experiments have been carried out to evaluate the performance of Agile-SD compared to Compound (the default CCA of MS Windows since Windows Vista) and Cubic (the default CCA of Linux since Kernel 2.6.16) which are the default CCAs of the most commonly used operating systems \\citep{Afanasyev2010, alrshah2014}.\n\nThe rest of this paper is organized as follows: the related work is presented in Section \\ref{RW} while Section \\ref{Agile-SD} presents the proposed algorithm \\textquotedblleft Agile-SD\\textquotedblright. Section \\ref{PE} explains the used approach of performance evaluation which is contains the experiments' setup, network topology, performance metrics, results and discussion. Finally, Section \\ref{Conc} presents the conclusion and the future work.\n\n\\section{Related Work}\n\\label{RW}\n\nIn order to solve the problem of bandwidth under-utilization, Cubic \\citep{Ha2008}, Scalable TCP \\citep{Kelly2003}, HS-TCP \\citep{Floyd2003}, BIC \\citep{xu2004}, HCC \\citep{xu2011}, H-TCP \\citep{Leith2004}, TCP Africa \\citep{King2005}, TCP Compound \\citep{Tan2006}, Fusion \\citep{Kaneko2007}, TCP illinois \\citep{Liu2008} and YeAH \\citep{Baiocchi2007} have been developed and implemented in the real operating systems. All of these TCP variants are still unable to fully utilize the available bandwidths of high-speed networks, especially if the used buffer size is less than the BDP of the link \\citep{Afanasyev2010, Scharf2011, Callegari2012b, Callegari2014, Lar2013, acharya2012, alrshah2014}. \n\nFurther, some researchers tried to solve the aforementioned problem by proposing a set of CCAs or TCP variants; such as DCTCP \\citep{Alizadeh2010}, ICTCP \\citep{Haitao2013}, IA-TCP \\citep{Jaehyun2012} and D$^2$TCP \\citep{Vamanan2012} which designed for data center networks. All of these TCP variants are still suffering from some critical problems, such as the problem of TCP outcast which has not been solved yet \\citep{Tahiliani2012}.\n\nFurthermore, some researchers tried to improve the performance of TCP by using parallel approaches; such as AppTCP \\citep{Wang2013}, GridFTP \\citep{allcock2005}, pTCP \\citep{hsieh2002}, BBCP \\citep{hanushevsky2001}, PSockets \\citep{sivakumar2000}, MulTCP \\citep{crowcroft1998}, DPSS \\citep{Tierney1994} and Parallel-TCP \\citep{alrshah2009, alrshah2013}. Most of parallel schemes have achieved high bandwidth utilization, but unfortunately they have another issues which limited their deployments. One of these issues is that all of the parallel schemes have a very high aggressiveness level compared to the existing single-based TCP variants. This aggressive behavior negatively affects the fairness \\citep{Fu2005, fu2007}.\n\n\\begin{figure} [t]\n\\centering\n\\includegraphics[width=1\\linewidth]{lantopology.pdf}\n\\caption{A Network Topology for LAN.}\n\\label{fig:lantopology}\n\\end{figure}\n\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=1\\linewidth]{dctopology.pdf}\n\\caption{Multi-rooted Hierarchical Topology of Data Centers.}\n\\label{fig:dctopology}\n\\end{figure}\n\nHowever, the widely deployed CCAs; such as Compound and Cubic which have been set as the default CCAs in MS Windows and Linux operating systems, respectively; are playing the important role in the real networks. Thus, Compound and Cubic should be used as a benchmark, to confirm the performance of any newly proposed CCA or TCP variant. For this reason, these two CCAs are going to be briefly explained in the next subsections.\n\n\\subsection{Compound TCP (C-TCP)}\nThe widely deployed TCP variant namely C-TCP \\citep{Tan2006} is the default CCA of MS Windows since Windows Vista. C-TCP combines HS-TCP \\citep{Floyd2003} and NewReno \\citep{floyd1999} to be used as fast and slow modes, respectively. C-TCP is a loss-delay-based approach relies on multi-modes switching to increase the bandwidth utilization over high-speed networks. Generally, it improves the performance of TCP to some extent but it introduces another problem which is the RTT mis-estimation. This problem has been inherited from Vegas \\citep{brak1995} and it can negatively affect the overall performance of the protocol \\citep{Afanasyev2010, alrshah2014}.\n\n\\subsection{CUBIC TCP (Cubic)}\nCubic \\citep{Ha2008} is the default CCA of Linux operating systems since its implementation in Kernel 2.6.16. Cubic enhances the bandwidth utilization over high-speed networks by increasing the $cwnd$ in the congestion avoidance phase by a $cubic$ function of the elapsed time since last loss. In addition, Cubic forces its $cwnd$ not to be less than the pre-calculated $cwnd$ of NewReno. Despite of all, Cubic is still suffering from the under-utilization of high-speed bandwidth specifically when the used buffer size is small \\citep{Afanasyev2010, alrshah2014, Ha2008}.\n\n\\subsection{The Latest Issues}\nRecent studies have revealed that all of the current TCP variants have different levels of inability on fully utilizing the bandwidths over the new generation of high-speed networks, especially if a \\emph{near-zero} buffer is applied. Thus, it becomes very necessary to design a new CCA to increase the bandwidth utilization over such networks \\citep{Afanasyev2010, alrshah2014}.\n\n\n\n\n\n\\section{Agile-SD: The Proposed Algorithm}\n\\label{Agile-SD}\n\nAlgorithm \\ref{algo01} explains the Agile-SD mechanism which is geared to work on high-speed and short-distance networks to enhance the overall performance and bandwidth utilization while preserving the fairness. Moreover, Figure \\ref{fig:TCP} shows the flow control diagram of Agile-SD and the following subsections explain the proposed algorithm in more details.\n\n\n\\SetKwProg{Function}{Function}{ }{end}\n\\SetKwProg{Event}{Event}{ do}{end}\n\n\\begin{algorithm}[t!]\n\\caption{Agile-SD Congestion Avoidance.}\\label{algo01}\n\n\\textbf{Initialization:}\\\\\n\n\t\\hspace{0.5cm}$\\lambda_{min} \\leftarrow 1, \\lambda_{max} \\leftarrow 3,$\\\\\n\t\\hspace{0.5cm}$\\beta_1 \\leftarrow 0.90, \\beta_2 \\leftarrow 0.95,$\\\\\n\t\\hspace{0.5cm}$cwnd \\leftarrow 2$\n\n\\Event{On ACK Receiption}\n{\n\tcalculate $gap_{current}$ as in Equation (\\ref{eq3})\\\\\n\t\n\tcalculate $gap_{total}$ as in Equation (\\ref{eq2})\\\\\n\n\tcalculate $\\lambda$ as in Equation (\\ref{eq1})\\\\\n\n\t$\\alpha = \\frac{\\lambda}{cwnd}$\n\t\n\t\n\t$cwnd \\leftarrow cwnd + \\alpha$\\\\\n}\n\n\n\\Event{On Loss Detection of 3-duplicated ACKs}\n{\n\t$cwnd_{loss} \t\\leftarrow cwnd$\\\\\n\t\n\t\\uIf {$tcp\\_status = SlowStart$}\n\t{\t\n\t\t$cwnd \\leftarrow cwnd \\times \\beta_1$ \\label{L13}\\\\\n\t}\n\t\\Else\n\t{\n\t\t$cwnd \\leftarrow cwnd \\times \\beta_2$ \\label{L17}\\\\\n\t}\n\t\n\t$ssthresh \t\\leftarrow cwnd - 1$\\\\\n\t$cwnd_{degraded} \\leftarrow cwnd$\\\\\n}\n\\end{algorithm} \\DecMargin{1em}\n\n\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[width=0.7\\linewidth]{TCP.pdf}\n\\caption{The flow control diagram of Agile-SD.}\n\\label{fig:TCP}\n\\end{figure}\n\n\\subsection{The Agility Factor Mechanism}\nAs known, \\citet{RFC6928} increases the initial value of TCP $cwnd$ to 10 packets, but Agile-SD initializes its $cwnd$ by 2 packets in order to focus on the impact of CA on bandwidth utilization. However, in the future implementations the initial $cwnd$ should be set to 10 to gain better bandwidth utilization.\n\nClearly, Agile-SD increases its $cwnd$ in the stage of congestion avoidance by fraction similarly as the existing CCAs. But, Agile-SD increases its $cwnd$ by $\\frac{\\lambda}{cwnd}$ to show a convex curve unlike the standard TCP which increases its $cwnd$ linearly by $\\frac{1}{cwnd}$. The main contribution of Agile-SD is the unique $cwnd$ growth function which relies on the agility factor mechanism which symbolized by $\\lambda$, as shown in Equation \\eqref{eq1}.\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=\\linewidth]{epoch.pdf}\n\\caption{The $cwnd$ evolution of Agile-SD and the standard TCP.}\n\\label{fig:epoch}\n\\end{figure}\n\n", "index": 1, "text": "\\begin{align}\n&\\lambda = max\\left( \\frac{\\lambda_{max} \\times gap_{current}}{gap_{total}}, \\lambda_{min}\\right)\t\\label{eq1}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda=max\\left(\\frac{\\lambda_{max}\\times gap_{current}}{gap_{%&#10;total}},\\lambda_{min}\\right)\" display=\"inline\"><mrow><mi>\u03bb</mi><mo>=</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>\u00d7</mo><mi>g</mi></mrow><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow></mfrac></mstyle><mo>,</mo><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\n\nWhile, $gap_{current}$ is calculated as the difference between the maximum recorded limit of the bandwidth ($cwnd_{loss}$) and the current $cwnd$, as in Equation \\eqref{eq3}.\n\n", "itemtype": "equation", "pos": 13076, "prevtext": "\nwhere, $gap_{total}$ exemplifies the amount of decrease in the $cwnd$ which caused by the loss event. In other words, $gap_{total}$ represents the released amount from the bandwidth after loss. $gap_{total}$ is calculated as the distance between the maximum recorded limit of the bandwidth ($cwnd_{loss}$) and the $cwnd_{degraded}$ as in Equation \\eqref{eq2}.\n\n", "index": 3, "text": "\\begin{align}\ngap_{total} = max\\left((cwnd_{loss} - cwnd_{degraded}), 1\\right)\t\t\t\t\t\t\t\\label{eq2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle gap_{total}=max\\left((cwnd_{loss}-cwnd_{degraded}),1\\right)\" display=\"inline\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow><mo>=</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><msub><mi>d</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>s</mi></mrow></msub></mrow><mo>-</mo><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><msub><mi>d</mi><mrow><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>d</mi></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mn>1</mn><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\n\nSimply, $\\lambda$ is used to mitigate the impact of loss degradation on the overall performance of TCP. Specifically, $\\lambda$ shortens the time of epoch which is needed by CCA to move its $cwnd$ from $cwnd_{degraded}$ to $cwnd_{loss}$ or to the maximum allowed $cwnd$, as shown in Figure \\ref{fig:epoch}. In order to increase the bandwidth utilization, $\\lambda$ speeds up the growth of $cwnd$ when the current $cwnd$ is far away from the last $cwnd_{loss}$. While, it conservatively slows down the growth of $cwnd$ when the current $cwnd$ nearing to the last $cwnd_{loss}$.\n\nMore specifically, to ensure that the performance of Agile-SD is not less than the standard TCP, $\\lambda_{min}$ must be always set to 1 while $\\lambda_{max}$ must be always set to a value $\\geq 1$. However, if $\\lambda_{max}$ is set to 1, Agile-SD will behave exactly similar to NewReno. But, if it was set to a value $> 1$, such as 2, 3 or 4, it would clearly improve the overall performance. \n\n\\begin{figure} [t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{factor.pdf}\n\\caption{The concept of agility factor mechanism $\\lambda$.}\n\\label{fig:factor}\n\\end{figure}\n\n\\begin{figure} [t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{fraction.pdf}\n\\caption{Relation between $\\alpha, \\lambda$ and the bandwidth utilization.}\n\\label{fig:fraction}\n\\end{figure}\n\n\nAfter loss detection by receiving three duplicate ACKs, Agile-SD initiates its agility factor by $\\lambda_{max}$, then reduces it every cycle towards $\\lambda_{min}$. Nevertheless, it restarts by $\\lambda_{max}$ again if another three duplicate ACKs are received as shown in Figure \\ref{fig:factor}. Consequently, it is very clear that $\\alpha$ is directly proportional to $\\lambda$, and $\\lambda$ is reversely proportional to the current size of $cwnd$, as shown in Figure \\ref{fig:fraction}. In other words, the aggressiveness of the proposed algorithm increases whenever the difference between $cwnd$ and $cwnd_{loss}$ increases, as in Equation \\eqref{eq4}. \n\n\n", "itemtype": "equation", "pos": 13361, "prevtext": "\n\nWhile, $gap_{current}$ is calculated as the difference between the maximum recorded limit of the bandwidth ($cwnd_{loss}$) and the current $cwnd$, as in Equation \\eqref{eq3}.\n\n", "index": 5, "text": "\\begin{align}\ngap_{current} = max\\left((cwnd_{loss} - cwnd), 1\\right)\t\t\t\t\t\t\t\t\t\t\\label{eq3}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle gap_{current}=max\\left((cwnd_{loss}-cwnd),1\\right)\" display=\"inline\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo>=</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><msub><mi>d</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>s</mi></mrow></msub></mrow><mo>-</mo><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>d</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mn>1</mn><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\n\nContrarily, it decreases its aggressiveness whenever the utilization is around to touch the maximum available bandwidth, as in Equation \\eqref{eq5}. \n\n", "itemtype": "equation", "pos": 15471, "prevtext": "\n\nSimply, $\\lambda$ is used to mitigate the impact of loss degradation on the overall performance of TCP. Specifically, $\\lambda$ shortens the time of epoch which is needed by CCA to move its $cwnd$ from $cwnd_{degraded}$ to $cwnd_{loss}$ or to the maximum allowed $cwnd$, as shown in Figure \\ref{fig:epoch}. In order to increase the bandwidth utilization, $\\lambda$ speeds up the growth of $cwnd$ when the current $cwnd$ is far away from the last $cwnd_{loss}$. While, it conservatively slows down the growth of $cwnd$ when the current $cwnd$ nearing to the last $cwnd_{loss}$.\n\nMore specifically, to ensure that the performance of Agile-SD is not less than the standard TCP, $\\lambda_{min}$ must be always set to 1 while $\\lambda_{max}$ must be always set to a value $\\geq 1$. However, if $\\lambda_{max}$ is set to 1, Agile-SD will behave exactly similar to NewReno. But, if it was set to a value $> 1$, such as 2, 3 or 4, it would clearly improve the overall performance. \n\n\\begin{figure} [t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{factor.pdf}\n\\caption{The concept of agility factor mechanism $\\lambda$.}\n\\label{fig:factor}\n\\end{figure}\n\n\\begin{figure} [t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{fraction.pdf}\n\\caption{Relation between $\\alpha, \\lambda$ and the bandwidth utilization.}\n\\label{fig:fraction}\n\\end{figure}\n\n\nAfter loss detection by receiving three duplicate ACKs, Agile-SD initiates its agility factor by $\\lambda_{max}$, then reduces it every cycle towards $\\lambda_{min}$. Nevertheless, it restarts by $\\lambda_{max}$ again if another three duplicate ACKs are received as shown in Figure \\ref{fig:factor}. Consequently, it is very clear that $\\alpha$ is directly proportional to $\\lambda$, and $\\lambda$ is reversely proportional to the current size of $cwnd$, as shown in Figure \\ref{fig:fraction}. In other words, the aggressiveness of the proposed algorithm increases whenever the difference between $cwnd$ and $cwnd_{loss}$ increases, as in Equation \\eqref{eq4}. \n\n\n", "index": 7, "text": "\\begin{align}\n\\alpha_{max} &= \\lim_{gap_{current} \\to gap_{total}}  \\dfrac{max\\left( \\frac{\\lambda_{max} \\times gap_{current}}{gap_{total}}, \\lambda_{min}\\right)} {cwnd}\\label{eq4}\\\\\n&= \\frac{\\lambda_{max}}{cwnd} \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{max}\" display=\"inline\"><msub><mi>\u03b1</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lim_{gap_{current}\\to gap_{total}}\\dfrac{max\\left(\\frac{\\lambda%&#10;_{max}\\times gap_{current}}{gap_{total}},\\lambda_{min}\\right)}{cwnd}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo>\u2192</mo><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mrow><mrow><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>\u00d7</mo><mi>g</mi></mrow><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow></mfrac><mo>,</mo><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>)</mo></mrow></mrow><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>d</mi></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{\\lambda_{max}}{cwnd}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>d</mi></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\n\nIn general, Agile-SD reduces the cycle time which by its role reduces the epoch time to overcome the problem of slow evolution of $cwnd$ provided by the standard TCP, as shown early in Figure \\ref{fig:epoch}. On one hand, this behavior guarantees the performance of Agile-SD not to be lower than the standard TCP. Thus, it increases the bandwidth utilization by improving the ability of Agile-SD to expose the condition of the underlying network as shown in Figure \\ref{fig:fraction}. On the other hand, it reduces the sensitivity of Agile-SD to the loss rate.\n\n\\subsection{The Decrement of cwnd}\n\nThe standard TCP applies the \\textit{Multiplicative} \\textit{Decrease} mechanism which halves the $cwnd$ after any loss detection, by receiving three duplicate ACKs, regardless of which stage the loss is detected in. Unlikely, Agile-SD decreases its $cwnd$ after any loss detection by two ways based on the stage which the loss is coming from. First, if the loss is detected in the slow start stage, Agile-SD reduces its $cwnd$ to $\\beta_1\\%$ of the latest $cwnd$ as shown at Line \\ref{L13} in Algorithm \\ref{algo01}. Second, if the loss is detected in the congestion avoidance stage, Agile-SD reduces its $cwnd$ to $\\beta_2\\%$ of the latest $cwnd$  as shown at Line \\ref{L17} in Algorithm \\ref{algo01}. Moreover, Agile-SD sets the $ssthresh$ to $cwnd - 1$, after any degradation, in order to avoid slipping into an undesirable slow start.\n\nSince, the loss which happens in the slow start stage is more severe than which happens in the congestion avoidance stage. Therefore, the value of $\\beta_1$ should be always less than $\\beta_2$. In other words, the reduction which follows a slow start loss should be greater than the reduction which follows a congestion avoidance loss. Also, $\\beta_1$ and $\\beta_2$ must be reversely proportional to their relative $\\lambda_{max}$ but the relation among them is still under investigation to be revealed in the future work. Thus, whenever the values of $\\beta_1$ and $\\beta_2$ is increased, the value of $\\lambda_{max}$ should be adaptively decreased and vice versa. For instance, if $\\beta_1$ and $\\beta_2$ are set to 0.9 and 0.95, respectively, where these values are compatible with $\\lambda_{max} = 3$. Then, if $\\beta_1$ and $\\beta_2$ are reduced to 0.85 and 0.9, respectively, the value of $\\lambda_{max}$ should be increased to a value, such as 4 or 5, and so on.\n\n\\subsection{Agile-SD Overall Behavior}\n\nSimilar to standard TCP, Agile-SD starts by slow start to show an exponential increase until the detection of first loss; by receiving three duplicate ACKs. This reduces its $cwnd$ to $\\beta_1\\%$ and triggers the congestion avoidance function. In this stage, Agile-SD increases its $cwnd$ by $\\alpha$ to show a convex curve. But, if the $cwnd$ becomes closer to the bandwidth limit which is set as $cwnd_{loss}$, it starts a linear increase until detecting another packet loss. If the event of packet loss is detected, Agile-SD reduces its $cwnd$ to $\\beta_2\\%$ then repeats the same stages which follows the slow start stage. However, if timeout is detected at any stage, Agile-SD resets its $cwnd$ to the initial value, as shown in Figure \\ref{fig:TCP}.\n\nFor more understanding, assume that there is a TCP link with $cwnd_{loss} = 12, cwnd_{degraded} = 9$ and a constant $RTT$ equal to 20 ms, and the congestion avoidance stage is just started after the loss directly. Thus, the number of $cycles$ needed by any CCA to reach $cwnd_{loss}$ is 4 cycles which is equal to $(cwnd_{loss} - cwnd_{degraded} + 1)$. Consequently, the epoch time needed by the standard TCP, which is $\"RTT-dependent\"$, is the number of needed $cycles$ times $RTT$, so it will be equal to 80 ms. \n\nInstead, Agile-SD increases its $cwnd$ independently from the $RTT$. Thus, every $cycle$ consumes a time of $\\frac{RTT}{\\lambda}$ to send a number of $\\frac{cwnd}{\\lambda}$ packets during that cycle, then it increases its $cwnd$ by 1. Consequently, the epoch time needed by Agile-SD will be equal to what shown in Equation \\eqref{eq6}.\n\n", "itemtype": "equation", "pos": 15857, "prevtext": "\n\nContrarily, it decreases its aggressiveness whenever the utilization is around to touch the maximum available bandwidth, as in Equation \\eqref{eq5}. \n\n", "index": 9, "text": "\\begin{align}\n\\alpha_{min} &= \\lim_{gap_{current} \\to zero}  \\dfrac{max\\left( \\frac{\\lambda_{max} \\times gap_{current}}{gap_{total}}, \\lambda_{min}\\right)} {cwnd}\\label{eq5}\\\\\n&= \\frac{\\lambda_{min}}{cwnd} \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{min}\" display=\"inline\"><msub><mi>\u03b1</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lim_{gap_{current}\\to zero}\\dfrac{max\\left(\\frac{\\lambda_{max}%&#10;\\times gap_{current}}{gap_{total}},\\lambda_{min}\\right)}{cwnd}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mo>\u2192</mo><mrow><mi>z</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi></mrow></mrow></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mrow><mrow><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>\u00d7</mo><mi>g</mi></mrow><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></mrow><mrow><mi>g</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow></mfrac><mo>,</mo><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>)</mo></mrow></mrow><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>d</mi></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{\\lambda_{min}}{cwnd}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03bb</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mrow><mi>c</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>d</mi></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\nwhere $k$ is the number of needed cycles. \n\nSuppose $\\lambda_{min}$ and $\\lambda_{max}$ are set to 1 and 4, respectively. So, $\\lambda_i$ will take the value of [4, 3, 2, 1] sequentially, which will result in an epoch time equal to 41.66 ms. Thus, the epoch time of Agile-SD will be shrunk by around 48\\% from the epoch time of the standard TCP on the same network link. This behavior helps Agile-SD to increase its $cwnd$ more quickly than the other compared CCAs and consequently improves the bandwidth utilization. In other words, the faster $cwnd$ growth is the higher bandwidth utilization and vice versa. \n\n\\section{Performance Evaluation of Agile-SD}\n\\label{PE}\nThe goal of this work is, to develop a new CCA, namely Agile-SD, which has the ability of increasing the bandwidth utilization over high-speed and short-distance networks while maintaining fairness. \\mbox{Agile-SD} CCA has been implemented as a pluggable Linux CCA module which can be plugged into any Linux Kernel. As well as, this module has the ability to be plugged into NS-2 network simulator, as a Linux TCP, in order to evaluate its performance compared to some of the widely deployed CCAs.\n\n\\subsection{The Experiments Setup}\nIn this work, intensive simulation experiments have been conducted using the well-known network simulator NS-2 version 2.35, to evaluate the proposed CCA by comparing its performance with C-TCP and \\mbox{Cubic}. The conducted experiments have been divided into three main scenarios: single-flow, sequentially established/terminated multiple-flows, and synchronously established/terminated multiple-flows. Table \\ref{params} shows the setting of the experiments' parameters as used in this work.\n\\begin{table}[h!]\n\t\\caption{Experiment Parameters.}\n\t\\begin{center}\n\t\\begin{tabular}{p{0.15cm}p{2.24cm}p{4.16cm}} \n\t\\hline\n\tNo.& Parameter\t\t\t&\tValue\t\t\t\t\t\t\t\t\t\\\\ \\hline\n\t1. & CCAs\t\t\t\t&\tAgile-SD, Cubic, C-TCP\t\t\t\t\t\\\\ \n\t2. & Link capacity\t\t&\t1 Gbps for all\t\t\t\t\t\t\t\\\\ \n\t3. & Link delay\t\t\t&\t1ms (node to router)\t\t\t\t\t\t\\\\ \n\t   & \t\t\t\t\t&\t4ms (router to router)\t\t\t\t\t\\\\ \n\t4. & BDP\t\t\t\t&\t750KB (As in \\citep{RFC1072})\t\t\t\\\\ \n\t5. & PER\t\t\t\t&   $zero, 10^{-5}, 10^{-4}$\t\t\t\t\\\\%\n\t6. & Buffer size\t\t&\tfrom 5 to 500 packets\t\t\t\t\t\\\\ \n\t7. & Packet size\t\t&\t1000 bytes\t\t\t\t\t\t\t\t\\\\ \n\t8. & Queuing Algo\t \t&\tDrop-Tail\t\t\t\t\t\t\t\t\\\\ \n\t9. & Traffic type\t\t&\tFTP\t\t\t\t\t\t\t\t\t\t\\\\ \n\t10. & SACK, FACK\t\t&\tDisabled\t\t\t\t\t\t\t\t\\\\ \n\t11. & Simulation time\t&\t100 seconds\t\t\t\t\t\t\t\t\\\\ \\hline\n\t\\end{tabular}\n\t\\label{params}\n\t\\end{center}\n\\end{table}\n\nIn the first scenario of single-flow, there is only one pair of sender and receiver, as shown in Figure \\ref{fig:topology-ideal}, which presents an ideal case with no congestion to show the ability of the evaluated CCAs on achieving full bandwidth utilization. As for the second and third scenarios of multiple flows, there are $n$ pairs of sender and receiver, as shown in Figure \\ref{fig:topology}, which have been used to simulate the network congestion and to show its impact on the performance measurements of the evaluated CCAs. In the second scenario, the flows are sequentially established and terminated as shown in Figure \\ref{fig:multi-flows-sequence}(a). While in the third scenario, the flows are synchronously established and terminated as shown in Figure \\ref{fig:multi-flows-sequence}(b).\n\nIn all of these experiments, a standard single dumbbell topology has been used, as shown in figures \\ref{fig:topology-ideal} and \\ref{fig:topology}, where $n$ is the competing senders ($S1$, $S2$, $S3$, ..., $Sn$) which send data simultaneously to $n$ receivers ($D1$, $D2$, $D3$, ..., $Dn$) through the shared single bottleneck. All source and destination nodes are connected to the bottleneck routers over LAN with $1Gbps$ speed and $1ms$ propagation delay. While the bottleneck link is $1Gbps$ speed with a propagation delay of $4ms$ \\citep{Wang2013}. These experiments have been repeated for each CCA separately with variable buffer size and variable packet error rate (PER). The buffer size varies from $5$ to $500$ packets while the PERs which have been used are $10^{-4}$, $10^{-5}$ and $zero$ PER. \n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics[width=\\linewidth]{topologyideal.pdf}\n\\caption{Non-congested Network topology.}\n\\label{fig:topology-ideal}\n\\end{figure}\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics[width=\\linewidth]{topology.pdf}\n\\caption{Network topology with standard dumbbell bottleneck.}\n\\label{fig:topology}\n\\end{figure}\n\n\\begin{figure} [t!]\n\t\\centering\n\t\\begin{center}\n\t\t\\subfigure[Sequentially established/terminated flows scenario.] \n\t\t{\n\t\t\t\\includegraphics[width=0.9\\linewidth]{multiflowssequence1.pdf}\n\t\t\t\\label{fig:multi-flows-sequence1}\n\t\t}\n\t\t\\subfigure[Synchronously established/terminated flows scenario.] \n\t\t{\n\t\t\t\\includegraphics[width=0.9\\linewidth]{multiflowssequence2.pdf}\n\t\t\t\\label{fig:multi-flows-sequence2}\n\t\t}\n\t\\end{center}\n\t\\caption{The sequence of establishments and terminations of the multiple flows scenarios.}\n\t\\label{fig:multi-flows-sequence}\n\\end{figure}\n\nMoreover, the performance metrics evaluated in this paper are the average throughput, loss ratio, inter-fairness, intra-fairness and RTT-fairness. Average throughput and loss ratio are evaluated to reflect the ability of the TCP variant on utilizing the bandwidth. While, measuring inter-fairness, intra-fairness and RTT-fairness is to show the quality of sharing the link between the competing TCP flows based on Jain's fairness index (JFI) \\citep{jain1984}, as shown in Equation \\eqref{fair}.\n\n\n", "itemtype": "equation", "pos": 20146, "prevtext": "\n\nIn general, Agile-SD reduces the cycle time which by its role reduces the epoch time to overcome the problem of slow evolution of $cwnd$ provided by the standard TCP, as shown early in Figure \\ref{fig:epoch}. On one hand, this behavior guarantees the performance of Agile-SD not to be lower than the standard TCP. Thus, it increases the bandwidth utilization by improving the ability of Agile-SD to expose the condition of the underlying network as shown in Figure \\ref{fig:fraction}. On the other hand, it reduces the sensitivity of Agile-SD to the loss rate.\n\n\\subsection{The Decrement of cwnd}\n\nThe standard TCP applies the \\textit{Multiplicative} \\textit{Decrease} mechanism which halves the $cwnd$ after any loss detection, by receiving three duplicate ACKs, regardless of which stage the loss is detected in. Unlikely, Agile-SD decreases its $cwnd$ after any loss detection by two ways based on the stage which the loss is coming from. First, if the loss is detected in the slow start stage, Agile-SD reduces its $cwnd$ to $\\beta_1\\%$ of the latest $cwnd$ as shown at Line \\ref{L13} in Algorithm \\ref{algo01}. Second, if the loss is detected in the congestion avoidance stage, Agile-SD reduces its $cwnd$ to $\\beta_2\\%$ of the latest $cwnd$  as shown at Line \\ref{L17} in Algorithm \\ref{algo01}. Moreover, Agile-SD sets the $ssthresh$ to $cwnd - 1$, after any degradation, in order to avoid slipping into an undesirable slow start.\n\nSince, the loss which happens in the slow start stage is more severe than which happens in the congestion avoidance stage. Therefore, the value of $\\beta_1$ should be always less than $\\beta_2$. In other words, the reduction which follows a slow start loss should be greater than the reduction which follows a congestion avoidance loss. Also, $\\beta_1$ and $\\beta_2$ must be reversely proportional to their relative $\\lambda_{max}$ but the relation among them is still under investigation to be revealed in the future work. Thus, whenever the values of $\\beta_1$ and $\\beta_2$ is increased, the value of $\\lambda_{max}$ should be adaptively decreased and vice versa. For instance, if $\\beta_1$ and $\\beta_2$ are set to 0.9 and 0.95, respectively, where these values are compatible with $\\lambda_{max} = 3$. Then, if $\\beta_1$ and $\\beta_2$ are reduced to 0.85 and 0.9, respectively, the value of $\\lambda_{max}$ should be increased to a value, such as 4 or 5, and so on.\n\n\\subsection{Agile-SD Overall Behavior}\n\nSimilar to standard TCP, Agile-SD starts by slow start to show an exponential increase until the detection of first loss; by receiving three duplicate ACKs. This reduces its $cwnd$ to $\\beta_1\\%$ and triggers the congestion avoidance function. In this stage, Agile-SD increases its $cwnd$ by $\\alpha$ to show a convex curve. But, if the $cwnd$ becomes closer to the bandwidth limit which is set as $cwnd_{loss}$, it starts a linear increase until detecting another packet loss. If the event of packet loss is detected, Agile-SD reduces its $cwnd$ to $\\beta_2\\%$ then repeats the same stages which follows the slow start stage. However, if timeout is detected at any stage, Agile-SD resets its $cwnd$ to the initial value, as shown in Figure \\ref{fig:TCP}.\n\nFor more understanding, assume that there is a TCP link with $cwnd_{loss} = 12, cwnd_{degraded} = 9$ and a constant $RTT$ equal to 20 ms, and the congestion avoidance stage is just started after the loss directly. Thus, the number of $cycles$ needed by any CCA to reach $cwnd_{loss}$ is 4 cycles which is equal to $(cwnd_{loss} - cwnd_{degraded} + 1)$. Consequently, the epoch time needed by the standard TCP, which is $\"RTT-dependent\"$, is the number of needed $cycles$ times $RTT$, so it will be equal to 80 ms. \n\nInstead, Agile-SD increases its $cwnd$ independently from the $RTT$. Thus, every $cycle$ consumes a time of $\\frac{RTT}{\\lambda}$ to send a number of $\\frac{cwnd}{\\lambda}$ packets during that cycle, then it increases its $cwnd$ by 1. Consequently, the epoch time needed by Agile-SD will be equal to what shown in Equation \\eqref{eq6}.\n\n", "index": 11, "text": "\\begin{align}\n&Epoch Time = \\sum_{i=1}^{k}\\dfrac{RTT}{\\lambda_i}  \\label{eq6}\n\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle EpochTime=\\sum_{i=1}^{k}\\dfrac{RTT}{\\lambda_{i}}\\par&#10;\" display=\"inline\"><mrow><mrow><mi>E</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>T</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>e</mi></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mi>R</mi><mo>\u2062</mo><mi>T</mi><mo>\u2062</mo><mi>T</mi></mrow><msub><mi>\u03bb</mi><mi>i</mi></msub></mfrac></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05908.tex", "nexttext": "\n\nSubstantially, these experiments show the impact of bottleneck congestion, buffer size and PER on the performance of the examined CCAs and also show the performance changes when a smaller buffer size is applied. Moreover, the simulation time used in all experiments has been set to 100 seconds which is enough for TCP to show its steady state.\n\n\\subsection{Results and Discussion}\n\nThis subsection presents an analytical discussion of the behavior exhibited by the proposed CCA and the compared CCAs. As well as, it presents the results of the performance evaluation and shows the measurements of the average throughput, loss ratio, inter-fairness, intra-fairness and RTT-fairness.\n\n\\subsubsection{The $cwnd$ evolution}\nFundamentally, the target of CCAs is: to maximize the throughput while minimizing the loss ratio and maintaining the fairness. Figure \\ref{fig:CWND} shows the $cwnd$ evolution of the studied CCAs based on the buffer size change. Due to the mechanism of agility factor, Agile-SD expectedly shows the faster $cwnd$ growth followed by Cubic and C-TCP. This fast or slow evolution of $cwnd$ is the core of any CCA which would directly affect the other performance metrics, such as throughput, loss ratio and it may affect the fairness as well.\n\nIn Figure \\ref{fig:CWND:1}, it is very clear that Agile-SD reaches the maximum $cwnd$, which is about 1500 packets, in around 17 second then starts oscillating to show very short epochs, while, Cubic reaches the maximum $cwnd$ in about 60 seconds then starts oscillating to draw very long epochs. As for C-TCP, it fails to reach the maximum $cwnd$ and touches only the edge of 110 packets then exhibits very short epochs. Indeed, the larger the $cwnd$, the higher the throughput and vice versa.\n\nInterestingly, when the buffer size increases, the behavior of the studied CCAs relatively improves. The figures from \\ref{fig:CWND:3} to \\ref{fig:CWND:7} show that Agile-SD and Cubic reduce their time of reaching the maximum $cwnd$ whenever the buffer size increases. Besides, Agile-SD keeps showing short epochs while Cubic remains drawing long epochs. Unlikely, C-TCP heightens its $cwnd$ towards the maximum limit whenever the buffer size increases. In fact, the wider oscillating and/or the longer epochs is the lower bandwidth utilization and vice versa. Thus, the higher bandwidth utilization among the studied CCAs would be provided by Agile-SD followed by Cubic then C-TCP.\n\n\\begin{figure*} [t!]\n\t\\centering\n\t\\begin{center}\n\t\t\\subfigure [Buffer Size = 5 Packets.]\t{\n\t\t\t\\includegraphics[scale=0.39]{agile1.pdf}\t\t\n\t\t\t\\includegraphics[scale=0.39]{compound1.pdf}\n\t\t\t\\includegraphics[scale=0.39]{cubic1.pdf}\n\t\t\t\\label{fig:CWND:1}\n\t\t}\t\n\n\n\n\n\n\n\t\t\\subfigure [Buffer Size = 25 Packets.]\t{\n\t\t\t\\includegraphics[scale=0.39]{agile3.pdf}\t\t\n\t\t\t\\includegraphics[scale=0.39]{compound3.pdf}\n\t\t\t\\includegraphics[scale=0.39]{cubic3.pdf}\n\t\t\t\\label{fig:CWND:3}\n\t\t}\t\n\n\n\n\n\n\n\t\t\\subfigure [Buffer Size = 100 Packets.]\t{\n\t\t\t\\includegraphics[scale=0.39]{agile5.pdf}\t\t\n\t\t\t\\includegraphics[scale=0.39]{compound5.pdf}\n\t\t\t\\includegraphics[scale=0.39]{cubic5.pdf}\n\t\t\t\\label{fig:CWND:5}\n\t\t}\n\n\n\n\n\n\t\t\\subfigure [Buffer Size = 250 Packets.]\t{\n\t\t\t\\includegraphics[scale=0.39]{agile6.pdf}\t\t\n\t\t\t\\includegraphics[scale=0.39]{compound6.pdf}\n\t\t\t\\includegraphics[scale=0.39]{cubic6.pdf}\n\t\t\t\\label{fig:CWND:6}\n\t\t}\t\n\t\t\\subfigure [Buffer Size = 500 Packets.]\t{\n\t\t\t\\includegraphics[scale=0.39]{agile7.pdf}\t\t\n\t\t\t\\includegraphics[scale=0.39]{compound7.pdf}\n\t\t\t\\includegraphics[scale=0.39]{cubic7.pdf}\n\t\t\t\\label{fig:CWND:7}\n\t\t}\n\t\\end{center}\n\t\\caption{TCP Congestion Window Evolution.}\n\t\\label{fig:CWND}\n\\end{figure*}\n\n\\subsubsection{The average throughput}\nIn the first scenario, as shown in Figure \\ref{fig:single-0per-throughput}, Agile-SD has overcome the other CCAs in terms of average throughput due to its fast growth of $cwnd$ resulted by the mechanism of agility factor. Moreover, Agile-SD presents lower sensitivity to PER than the others, whereas, Cubic and C-TCP are highly affected by PER and they present a poor performance when the PER is increased. However, in the cases of $10^{-4} and 10^{-5}$ PER as shown in figures \\ref{fig:single-2per-throughput} and \\ref{fig:single-3per-throughput}, C-TCP presents better performance than Cubic in most cases. In general, Agile-SD achieves better throughput than the others in most cases even in the lossy environments. Clearly, it improves the bandwidth utilization up to 55\\% in some cases of this scenario.\n\nFor the second scenario, the figures \\ref{fig:seq-0per-throughput}, \\ref{fig:seq-2per-throughput} and \\ref{fig:seq-3per-throughput} show that Agile-SD has overcome the other CCAs, in term of average throughput, at most cases even when the buffer size is small and the PER is high. Furthermore, it improves the bandwidth utilization from 10\\% to 40\\% in the cases of 5 packets buffer size. While in the third scenario, Agile-SD has outperformed the other CCAs in all cases especially when a \\emph{near-zero} buffer is applied as shown in figures \\ref{fig:sync-0per-throughput}, \\ref{fig:sync-2per-throughput} and \\ref{fig:sync-3per-throughput}. Moreover, Agile-SD significantly improves the bandwidth utilization even when the PER is high. Thus, it provides up to 40\\% of improvement in some cases.\n\n\\begin{figure*}[t!]\n\t\\begin{center}\n\t\t\\subfigure[The First Scenario: $Zero$ PER.] \n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{single0perthroughput.pdf}\n\t\t\t\\label{fig:single-0per-throughput}\n\t\t}\n\n\n\n\n\n\t\t\\subfigure[The First Scenario: $10^{-5}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{single2perthroughput.pdf}\n\t\t\t\\label{fig:single-2per-throughput}\n\t\t}\n\t\t\\subfigure[The First Scenario: $10^{-4}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{single3perthroughput.pdf}\n\t\t\t\\label{fig:single-3per-throughput}\n\t\t}\n\n\t\t\\subfigure[The Second Scenario: $Zero$ PER.] \n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{seq0perthroughput.pdf}\n\t\t\t\\label{fig:seq-0per-throughput}\n\t\t}\n\n\n\n\n\n\t\t\\subfigure[The Second Scenario: $10^{-5}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{seq2perthroughput.pdf}\n\t\t\t\\label{fig:seq-2per-throughput}\n\t\t}\n\t\t\\subfigure[The Second Scenario: $10^{-4}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{seq3perthroughput.pdf}\n\t\t\t\\label{fig:seq-3per-throughput}\n\t\t}\n\n\t\t\\subfigure[The Third Scenario: $Zero$ PER.] \n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{sync0perthroughput.pdf}\n\t\t\t\\label{fig:sync-0per-throughput}\n\t\t}\n\n\n\n\n\n\t\t\\subfigure[The Third Scenario: $10^{-5}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{sync2perthroughput.pdf}\n\t\t\t\\label{fig:sync-2per-throughput}\n\t\t}\n\t\t\\subfigure[The Third Scenario: $10^{-4}$ PER.]\n\t\t{\n\t\t\t\\includegraphics[scale=0.39]{sync3perthroughput.pdf}\n\t\t\t\\label{fig:sync-3per-throughput}\n\t\t}\n\t\\end{center}\n\t\\caption{The Average Throughput vs. Buffer Size.}\n\t\\label{fig:throughput}\n\\end{figure*}\n\n\\subsubsection{The loss ratio}\nAs regarding to all scenarios, the studied CCAs have presented a loss ratio lower than 0.5\\% which is considered as a negligible loss ratio. Thus, Figure \\ref{fig:single3perloss} has been selected here as a sample of the loss ratio results of all scenarios to save the space of this paper and because the rest of the figures have no much difference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{The fairness}\nAs for intra-fairness and RTT-fairness, all the studied CCAs are interchangeably close to each other. However, in some cases Agile-SD seems more fair, especially when the applied buffer size is small. Since the difference among the graphs of the results is very trivial, the figures \\ref{fig:seq0perintra} and \\ref{fig:sync0perrtt} have been chosen as samples of intra-fairness and RTT-fairness, respectively.\n\nMoreover, a separated experiment has been carried out to evaluate the inter-fairness among the studied CCAs and the standard NewReno, using the same topology as shown in Figure \\ref{fig:topology}, where the result is shown in Figure \\ref{fig:interfairness}. For inter-fairness to NewReno, Agile-SD and C-TCP achieve around 0.76 while Cubic achieves about 0.79 inter-fairness index. As for the inter-fairness to Cubic, Agile-SD scores the highest index which is almost 0.99 and C-TCP scores around 0.96 while NewReno achieves only 0.79 inter-fairness index. As for the inter-fairness to C-TCP, Cubic scores the highest index which is around 0.96 while Agile-SD and NewReno achieve about 0.76 inter-fairness index.\n\n\\section{Conclusion}\n\\label{Conc}\n\nIn this paper, a new CCA, namely Agile-SD, has been proposed and evaluated. The main contribution of the proposed CCA is to implement the mechanism of agility factor. The need of the proposed CCA has been arisen by the inability of the existing high-speed CCAs in achieving a full bandwidth utilization over high-speed networks, especially when a small buffer regime is applied. Further, a new CCA module has been implemented and plugged into the Linux kernel version 3.19.0. As well as, this module has been plugged into the Network Simulator NS-2 version 2.35, as a Linux TCP, in order to evaluate it by comparing its performance to the other CCAs. \n\nSubsequently, intensive simulation experiments have been conducted to evaluate the proposed CCA by comparing its performance to C-TCP and Cubic, which are the current default TCP algorithms of MS Windows and Linux, respectively. The results show that the proposed algorithm achieves higher bandwidth utilization than the existing CCAs while maintaining fairness. Due to the use of agility factor, Agile-SD shows lower sensitivity to the changes of buffer size and PER.\n\nImportantly, Agile-SD presents higher performance than the compared CCAs and it provides a significant improvement which is: up to 55\\% in the case of single flow, up to 40\\% in the case of sequentially established/terminated multi-flows and up to 40\\% in the case of synchronously established/terminated multi-flows.\n\nMore importantly, the second scenario presents the real case of network, in which all TCP flows are not established or terminated synchronously. In this scenario, Agile-SD has achieved up to 95\\% bandwidth utilization while the others did not exceed it in the case of large buffer. As for the case of small buffer, Agile-SD achieves around 92\\% bandwidth utilization while the other TCP variants achieve from 32\\% to 85\\% bandwidth utilization.\n\nEventually, Agile-SD is a sender-side TCP module which does not change anything at receiver-side. It uses the standard slow start and provides a new congestion avoidance algorithm featured by the mechanism of agility factor. Currently, we have already implemented Agile-SD into the latest Linux kernel 3.19.0 and a real dumbbell topology has been built using Dummynet over PC-BSD version 10 to evaluate the proposed CCA based on real test-bed in the nearest future. Also, there is a strong intention to evaluate Agile-SD with SACK and/or FACK features to show their impacts on the throughput. As well as, Agile-SD should have the ability to consider the delayed acknowledgments which needs some modification at the receiver-side.\n\n\\section*{Acknowledgments}\nThis work has been partially supported by the Malaysian Ministry of Education under the Fundamental Research Grant FRGS/02/01/12/1143/FR for financial support.\\\\\n\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[width=1\\linewidth]{single3perloss.pdf}\n\\caption{1st Scenario ($10^{-4}$ PER): Loss Ratio vs. Buffer Size.}\n\\label{fig:single3perloss}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[width=\\linewidth]{seq0perintra.pdf}\n\\caption{2nd Scenario ($Zero$ PER): Intra-Fairness vs. Buffer Size.}\n\\label{fig:seq0perintra}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[width=\\linewidth]{sync0perrtt.pdf}\n\\caption{3rd Scenario ($Zero$ PER): RTT-Fairness vs. Buffer Size.}\n\\label{fig:sync0perrtt}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[angle=-90,width=0.9\\linewidth]{interfairness.pdf}\n\\caption{The inter-fairness among the studied CCAs.}\n\\label{fig:interfairness}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{thebibliography}{46}\n\\expandafter\\ifx\\csname natexlab\\endcsname\\relax\\def\\natexlab#1{#1}\\fi\n\\expandafter\\ifx\\csname url\\endcsname\\relax\n  \\def\\url#1{\\texttt{#1}}\\fi\n\\expandafter\\ifx\\csname urlprefix\\endcsname\\relax\\def\\urlprefix{URL }\\fi\n\n\\bibitem[{Acharya(2012)}]{acharya2012}\nAcharya, S., 2012. Study and analysis of tcp/ip congestion control techniques:\n  A review. Illinois Journalism Education Association, .\n\n\\bibitem[{Afanasyev et~al.(2010)Afanasyev, Tilley, Reiher, and\n  Kleinrock}]{Afanasyev2010}\nAfanasyev, A., Tilley, N., Reiher, P., Kleinrock, L., 2010. {Host-to-Host\n  Congestion Control for TCP}. IEEE Communications Surveys and Tutorials\n  12~(3), 304--342.\n\n\\bibitem[{Al-Fares et~al.(2010)Al-Fares, Radhakrishnan, Raghavan, Huang, and\n  Vahdat}]{Alfares2010}\nAl-Fares, M., Radhakrishnan, S., Raghavan, B., Huang, N., Vahdat, A., 2010.\n  Hedera: Dynamic flow scheduling for data center networks. In: NSDI. Vol.~10.\n  pp. 19--19.\n\n\\bibitem[{Alizadeh et~al.(2010)Alizadeh, Greenberg, Maltz, Padhye, Patel,\n  Prabhakar, Sengupta, and Sridharan}]{Alizadeh2010}\nAlizadeh, M., Greenberg, A., Maltz, D.~A., Padhye, J., Patel, P., Prabhakar,\n  B., Sengupta, S., Sridharan, M., 2010. Data center tcp (dctcp). In:\n  Proceedings of the ACM SIGCOMM 2010 Conference. SIGCOMM '10. ACM, New York,\n  NY, USA, pp. 63--74.\n\n\\bibitem[{Allcock et~al.(2005)Allcock, Bresnahan, Kettimuthu, Link, Dumitrescu,\n  Raicu, and Foster}]{allcock2005}\nAllcock, W., Bresnahan, J., Kettimuthu, R., Link, M., Dumitrescu, C., Raicu,\n  I., Foster, I., 2005. The globus striped gridftp framework and server. In:\n  Proceedings of the 2005 ACM/IEEE conference on Supercomputing. Vol.~1. IEEE\n  Computer Society, pp. 1--11.\n\n\\bibitem[{Armbrust et~al.(2010)Armbrust, Fox, Griffith, Joseph, Katz,\n  Konwinski, Lee, Patterson, Rabkin, Stoica, and Zaharia}]{Armbrust2010}\nArmbrust, M., Fox, A., Griffith, R., Joseph, A.~D., Katz, R., Konwinski, A.,\n  Lee, G., Patterson, D., Rabkin, A., Stoica, I., Zaharia, M., Apr. 2010. View\n  of cloud computing. Comm. ACM 53~(4), 50--58.\n\n\\bibitem[{Baiocchi et~al.(2007)Baiocchi, Castellani, and\n  Vacirca}]{Baiocchi2007}\nBaiocchi, A., Castellani, A.~P., Vacirca, F., 2007. {YeAH-TCP:Yet Another\n  Highspeed TCP}. In: Proc. PFLDnet. Roma, Italy, pp. 37--42.\n\n\\bibitem[{Brakmo and Peterson(1995)}]{brak1995}\nBrakmo, L.~S., Peterson, L.~L., 1995. Tcp vegas: End to end congestion\n  avoidance on a global internet. Selected Areas in Communications, IEEE\n  Journal on 13~(8), 1465--1480.\n\n\\bibitem[{Buyya et~al.(2008)Buyya, Yeo, and Venugopal}]{Buyya2008}\nBuyya, R., Yeo, C.~S., Venugopal, S., Sept 2008. Market-oriented cloud\n  computing: Vision, hype, and reality for delivering it services as computing\n  utilities. In: 10th IEEE International Conference on High Performance\n  Computing and Communications, 2008. pp. 5--13.\n\n\\bibitem[{Callegari et~al.(2012)Callegari, Giordano, Pagano, and\n  Pepe}]{Callegari2012b}\nCallegari, C., Giordano, S., Pagano, M., Pepe, T., 2012. {Behavior analysis of\n  TCP Linux variants}. Computer Networks 56~(1), 462--476.\n\n\\bibitem[{Callegari et~al.(2014)Callegari, Giordano, Pagano, and\n  Pepe}]{Callegari2014}\nCallegari, C., Giordano, S., Pagano, M., Pepe, T., 2014. A survey of congestion\n  control mechanisms in linux tcp. In: Distributed Computer and Communication\n  Networks. Vol. 279 of Communications in Computer and Information Science.\n  Springer, pp. 28--42.\n\n\\bibitem[{Chu et~al.(2013)Chu, Cheng, Dukkipati, and Mathis}]{RFC6928}\nChu, J., Cheng, Y., Dukkipati, N., Mathis, M., April 2013. Increasing tcp's\n  initial window. RFC 6928, IETF Network Working Group, .\n\n\\bibitem[{Crowcroft and Oechslin(1998)}]{crowcroft1998}\nCrowcroft, J., Oechslin, P., 1998. Differentiated end-to-end internet services\n  using a weighted proportional fair sharing tcp. ACM SIGCOMM Computer\n  Communication Review 28~(3), 53--69.\n\n\\bibitem[{{D. Leith}(2004)}]{Leith2004}\n{D. Leith}, R.~S., 2004. H-tcp: Tcp for high-speed and long distance networks.\n  In: Proceedings of PFLDnet. pp. 95--101.\n\n\\bibitem[{Floyd(2003)}]{Floyd2003}\nFloyd, S., April 2003. {HighSpeed TCP for Large Congestion Windows}. RFC 3649,\n  IETF Network Working Group, .\n\n\\bibitem[{Floyd and Henderson(1999)}]{floyd1999}\nFloyd, S., Henderson, T., April 1999. The newreno modification to tcp\u00e2\u0080\u0099s fast\n  recovery algorithm. RFC 2582, IETF Network Group, .\n\n\\bibitem[{Fu and Indulska(2005)}]{Fu2005}\nFu, Q., Indulska, J., 2005. Features of parallel tcp with emphasis on\n  congestion avoidance in heterogeneous networks. In: Wysocki, T., Dadej, A.,\n  Wysocki, B. (Eds.), Advanced Wired and Wireless Networks. Vol.~26 of\n  Multimedia Systems and Applications Series. Springer US, pp. 207--230.\n\n\\bibitem[{Fu et~al.(2007)Fu, Indulska, Perreau, and Zhang}]{fu2007}\nFu, Q., Indulska, J., Perreau, S., Zhang, L., 2007. Exploring tcp\n  parallelisation for performance improvement in heterogeneous networks.\n  Computer Communications 30~(17), 3321--3334.\n\n\\bibitem[{Ha and Rhee(2008)}]{Ha2008}\nHa, S., Rhee, I., 2008. {CUBIC: A New TCP-Friendly High-Speed TCP Variant}.\n  SIGOPS Operating Systems Review 42~(5), 64--74.\n\n\\bibitem[{Hanushevsky et~al.(2001)Hanushevsky, Trunov, and\n  Cottrell}]{hanushevsky2001}\nHanushevsky, A., Trunov, A., Cottrell, L., 2001. Peer-to-peer computing for\n  secure high performance data copying. In: In Proc. of the 2001 Int. Conf. on\n  Computing in High Energy and Nuclear Physics (CHEP 2001), Beijng. Vol. 2001.\n  Citeseer.\n\n\\bibitem[{Hsieh and Sivakumar(2002)}]{hsieh2002}\nHsieh, H.-Y., Sivakumar, R., 2002. ptcp: An end-to-end transport layer protocol\n  for striped connections. In: 10th IEEE International Conference on Network\n  Protocols Proceedings. Vol. 2002. IEEE, pp. 24--33.\n\n\\bibitem[{Hwang et~al.(2012)Hwang, Yoo, and Choi}]{Jaehyun2012}\nHwang, J., Yoo, J., Choi, N., June 2012. Ia-tcp:a rate based incast-avoidance\n  algorithm for tcp in data center networks. In: IEEE International Conference\n  on Communications (ICC). pp. 1292--1296.\n\n\\bibitem[{Jacobson and Braden(1988)}]{RFC1072}\nJacobson, V., Braden, R., October 1988. Tcp extensions for long-delay paths.\n  RFC 1072, IETF Network Working Group, .\n\n\\bibitem[{Jain et~al.(1984)Jain, Chiu, and Hawe}]{jain1984}\nJain, R., Chiu, D.-M., Hawe, W.~R., 1984. A quantitative measure of fairness\n  and discrimination for resource allocation in shared computer system. Eastern\n  Research Laboratory, Digital Equipment Corporation.\n\n\\bibitem[{Kaneko et~al.(2007)Kaneko, Fujikawa, Su, and Katto}]{Kaneko2007}\nKaneko, K., Fujikawa, T., Su, Z., Katto, J., 2007. {TCP-Fusion : A Hybrid\n  Congestion Control Algorithm for High-speed Networks}. In: Proc. PFLDnet,\n  ISI, Marina Del Rey, California. pp. 31--36.\n\n\\bibitem[{Kelly(2003)}]{Kelly2003}\nKelly, T., 2003. {Scalable TCP : Improving Performance in Highspeed Wide Area\n  Networks}. ACM SIGCOMM Computer Communications Review 33~(2), 83--91.\n\n\\bibitem[{King et~al.(2005)King, Baraniuk, and Riedi}]{King2005}\nKing, R., Baraniuk, R., Riedi, R., 2005. {TCP-Africa: An adaptive and fair\n  rapid increase rule for scalable TCP}. In: INFOCOM 2005. 24th Annual Joint\n  Conference of the IEEE Computer and Communications Societies. Proceedings\n  IEEE. pp. 1--11.\n\n\\bibitem[{Lar and Liao(2013)}]{Lar2013}\nLar, S.-u., Liao, X., 2013. An initiative for a classified bibliography on\n  tcp/ip congestion control. Journal of Network and Computer Applications\n  36~(1), 126--133.\n\n\\bibitem[{Liu et~al.(2008)Liu, Ba{\\c{s}}ar, and Srikant}]{Liu2008}\nLiu, S., Ba{\\c{s}}ar, T., Srikant, R., 2008. Tcp-illinois: A loss-and\n  delay-based congestion control algorithm for high-speed networks. Performance\n  Evaluation 65~(6), 417--440.\n\n\\bibitem[{{Mohamed A. Alrshah} and {Mohamed Othman}(2009)}]{alrshah2009}\n{Mohamed A. Alrshah}, {Mohamed Othman}, Nov 2009. Test-bed based comparison of\n  single and parallel tcp and the impact of parallelism on throughput and\n  fairness in heterogenous networks. In: ICCTD '09. International Conference on\n  Computer Technology and Development, 2009. Vol.~1. pp. 332--335.\n\n\\bibitem[{{Mohamed A. Alrshah} et~al.(2014){Mohamed A. Alrshah}, {Mohamed\n  Othman}, {Borhanuddin Ali}, and {Zurina Mohd Hanapi}}]{alrshah2014}\n{Mohamed A. Alrshah}, {Mohamed Othman}, {Borhanuddin Ali}, {Zurina Mohd\n  Hanapi}, 2014. Comparative study of high-speed linux tcp variants over\n  high-{BDP} networks. Journal of Network and Computer Applications 43, 66--75.\n\n\\bibitem[{{Mohamed A. Alrshah and Mohamed Othman}(2013)}]{alrshah2013}\n{Mohamed A. Alrshah and Mohamed Othman}, Nov 2013. Performance evaluation of\n  parallel {TCP}, and its impact on bandwidth utilization and fairness in\n  {High-BDP} networks based on test-bed. In: 2013 IEEE Malaysia International\n  Conference on Communications (MICC). pp. 23--28.\n\n\\bibitem[{Prakash et~al.(2012)Prakash, Dixit, Hu, and Kompella}]{prakash2012}\nPrakash, P., Dixit, A., Hu, Y.~C., Kompella, R., 2012. The tcp outcast problem:\n  Exposing unfairness in data center networks. In: Proceedings of the 9th\n  USENIX conference on Networked Systems Design and Implementation, San Jose,\n  CA. p.~.\n\n\\bibitem[{Scharf(2011)}]{Scharf2011}\nScharf, M., 2011. {Comparison of end-to-end and network-supported fast startup\n  congestion control schemes}. Computer Networks 55~(8), 1921--1940.\n\n\\bibitem[{Sivakumar et~al.(2000)Sivakumar, Bailey, and\n  Grossman}]{sivakumar2000}\nSivakumar, H., Bailey, S., Grossman, R.~L., 2000. Psockets: The case for\n  application-level network striping for data intensive applications using high\n  speed wide area networks. In: Proceedings of the 2000 ACM/IEEE conference on\n  Supercomputing. Vol. 2000. IEEE Computer Society, pp. 1--7.\n\n\\bibitem[{Tahiliani et~al.(2012)Tahiliani, Tahiliani, and\n  Sekaran}]{Tahiliani2012}\nTahiliani, R., Tahiliani, M., Sekaran, K., Dec 2012. Tcp variants for data\n  center networks: A comparative study. In: International Symposium on Cloud\n  and Services Computing (ISCOS). pp. 57--62.\n\n\\bibitem[{Tan and Song(2006)}]{Tan2006}\nTan, K., Song, J., 2006. Compound tcp: A scalable and tcp-friendly congestion\n  control for high-speed networks. In: in 4th International workshop on\n  Protocols for Fast Long-Distance Networks (PFLDNet), 2006. pp. 80--83.\n\n\\bibitem[{Tierney et~al.(1994)Tierney, Lee, Chen, Herzog, Hoo, Jin, and\n  Johnston}]{Tierney1994}\nTierney, B., Lee, J., Chen, L.~T., Herzog, H., Hoo, G., Jin, G., Johnston,\n  W.~E., 1994. Distributed parallel data storage systems: a scalable approach\n  to high speed image servers. In: Proceedings of the second ACM international\n  conference on Multimedia. Vol. 1994 of MULTIMEDIA '94. ACM, pp. 399--405.\n\n\\bibitem[{Vamanan et~al.(2012)Vamanan, Hasan, and Vijaykumar}]{Vamanan2012}\nVamanan, B., Hasan, J., Vijaykumar, T., 2012. Deadline-aware datacenter tcp\n  (d2tcp). In: Proceedings of the ACM SIGCOMM 2012 Conference on Applications,\n  Technologies, Architectures, and Protocols for Computer Communication.\n  SIGCOMM '12. ACM, New York, NY, USA, pp. 115--126.\n\n\\bibitem[{Vasudevan et~al.(2009)Vasudevan, Phanishayee, Shah, Krevat, Andersen,\n  Ganger, Gibson, and Mueller}]{Vasudevan2009}\nVasudevan, V., Phanishayee, A., Shah, H., Krevat, E., Andersen, D.~G., Ganger,\n  G.~R., Gibson, G.~A., Mueller, B., Aug. 2009. Safe and effective fine-grained\n  tcp retransmissions for datacenter communication. SIGCOMM Comput. Commun.\n  Rev. 39~(4), 303--314.\n\n\\bibitem[{Wang et~al.(2014)Wang, Wu, Dou, Ren, and Li}]{Wang2013}\nWang, G., Wu, Y., Dou, K., Ren, Y., Li, J., 2014. Apptcp: The design and\n  evaluation of application-based tcp for e-vlbi in fast long distance\n  networks. Future Generation Computer Systems 39, 67--74.\n\n\\bibitem[{Wu et~al.(2013)Wu, Feng, Guo, and Zhang}]{Haitao2013}\nWu, H., Feng, Z., Guo, C., Zhang, Y., April 2013. Ictcp: Incast congestion\n  control for tcp in data-center networks. Networking, IEEE/ACM Transactions on\n  21~(2), 345--358.\n\n\\bibitem[{Wu and Yang(2012)}]{Wu2012}\nWu, X., Yang, X., June 2012. Dard: Distributed adaptive routing for datacenter\n  networks. In: 2012 IEEE 32nd International Conference on Distributed\n  Computing Systems (ICDCS). pp. 32--41.\n\n\\bibitem[{Xu et~al.(2004)Xu, Harfoush, and Rhee}]{xu2004}\nXu, L., Harfoush, K., Rhee, I., 2004. Binary increase congestion control (bic)\n  for fast long-distance networks. In: INFOCOM 2004. Twenty-third Annual Joint\n  Conference of the IEEE Computer and Communications Societies. Vol.~4. pp.\n  2514--2524.\n\n\\bibitem[{Xu et~al.(2011)Xu, Zhou, Pham, Ji, Yang, and Liu}]{xu2011}\nXu, W., Zhou, Z., Pham, D., Ji, C., Yang, M., Liu, Q., 2011. Hybrid congestion\n  control for high-speed networks. Journal of Network and Computer Applications\n  34~(4), 1416--1428.\n\n\\bibitem[{Yoo et~al.(2012)Yoo, Yin, and Wen}]{Yoo2012}\nYoo, S. J.~B., Yin, Y., Wen, K., April 2012. Intra and inter datacenter\n  networking: The role of optical packet switching and flexible bandwidth\n  optical networking. In: Optical Network Design and Modeling, 2012 16th\n  International Conference on. pp. 1--6.\n\n\\end{thebibliography}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 25736, "prevtext": "\nwhere $k$ is the number of needed cycles. \n\nSuppose $\\lambda_{min}$ and $\\lambda_{max}$ are set to 1 and 4, respectively. So, $\\lambda_i$ will take the value of [4, 3, 2, 1] sequentially, which will result in an epoch time equal to 41.66 ms. Thus, the epoch time of Agile-SD will be shrunk by around 48\\% from the epoch time of the standard TCP on the same network link. This behavior helps Agile-SD to increase its $cwnd$ more quickly than the other compared CCAs and consequently improves the bandwidth utilization. In other words, the faster $cwnd$ growth is the higher bandwidth utilization and vice versa. \n\n\\section{Performance Evaluation of Agile-SD}\n\\label{PE}\nThe goal of this work is, to develop a new CCA, namely Agile-SD, which has the ability of increasing the bandwidth utilization over high-speed and short-distance networks while maintaining fairness. \\mbox{Agile-SD} CCA has been implemented as a pluggable Linux CCA module which can be plugged into any Linux Kernel. As well as, this module has the ability to be plugged into NS-2 network simulator, as a Linux TCP, in order to evaluate its performance compared to some of the widely deployed CCAs.\n\n\\subsection{The Experiments Setup}\nIn this work, intensive simulation experiments have been conducted using the well-known network simulator NS-2 version 2.35, to evaluate the proposed CCA by comparing its performance with C-TCP and \\mbox{Cubic}. The conducted experiments have been divided into three main scenarios: single-flow, sequentially established/terminated multiple-flows, and synchronously established/terminated multiple-flows. Table \\ref{params} shows the setting of the experiments' parameters as used in this work.\n\\begin{table}[h!]\n\t\\caption{Experiment Parameters.}\n\t\\begin{center}\n\t\\begin{tabular}{p{0.15cm}p{2.24cm}p{4.16cm}} \n\t\\hline\n\tNo.& Parameter\t\t\t&\tValue\t\t\t\t\t\t\t\t\t\\\\ \\hline\n\t1. & CCAs\t\t\t\t&\tAgile-SD, Cubic, C-TCP\t\t\t\t\t\\\\ \n\t2. & Link capacity\t\t&\t1 Gbps for all\t\t\t\t\t\t\t\\\\ \n\t3. & Link delay\t\t\t&\t1ms (node to router)\t\t\t\t\t\t\\\\ \n\t   & \t\t\t\t\t&\t4ms (router to router)\t\t\t\t\t\\\\ \n\t4. & BDP\t\t\t\t&\t750KB (As in \\citep{RFC1072})\t\t\t\\\\ \n\t5. & PER\t\t\t\t&   $zero, 10^{-5}, 10^{-4}$\t\t\t\t\\\\%\n\t6. & Buffer size\t\t&\tfrom 5 to 500 packets\t\t\t\t\t\\\\ \n\t7. & Packet size\t\t&\t1000 bytes\t\t\t\t\t\t\t\t\\\\ \n\t8. & Queuing Algo\t \t&\tDrop-Tail\t\t\t\t\t\t\t\t\\\\ \n\t9. & Traffic type\t\t&\tFTP\t\t\t\t\t\t\t\t\t\t\\\\ \n\t10. & SACK, FACK\t\t&\tDisabled\t\t\t\t\t\t\t\t\\\\ \n\t11. & Simulation time\t&\t100 seconds\t\t\t\t\t\t\t\t\\\\ \\hline\n\t\\end{tabular}\n\t\\label{params}\n\t\\end{center}\n\\end{table}\n\nIn the first scenario of single-flow, there is only one pair of sender and receiver, as shown in Figure \\ref{fig:topology-ideal}, which presents an ideal case with no congestion to show the ability of the evaluated CCAs on achieving full bandwidth utilization. As for the second and third scenarios of multiple flows, there are $n$ pairs of sender and receiver, as shown in Figure \\ref{fig:topology}, which have been used to simulate the network congestion and to show its impact on the performance measurements of the evaluated CCAs. In the second scenario, the flows are sequentially established and terminated as shown in Figure \\ref{fig:multi-flows-sequence}(a). While in the third scenario, the flows are synchronously established and terminated as shown in Figure \\ref{fig:multi-flows-sequence}(b).\n\nIn all of these experiments, a standard single dumbbell topology has been used, as shown in figures \\ref{fig:topology-ideal} and \\ref{fig:topology}, where $n$ is the competing senders ($S1$, $S2$, $S3$, ..., $Sn$) which send data simultaneously to $n$ receivers ($D1$, $D2$, $D3$, ..., $Dn$) through the shared single bottleneck. All source and destination nodes are connected to the bottleneck routers over LAN with $1Gbps$ speed and $1ms$ propagation delay. While the bottleneck link is $1Gbps$ speed with a propagation delay of $4ms$ \\citep{Wang2013}. These experiments have been repeated for each CCA separately with variable buffer size and variable packet error rate (PER). The buffer size varies from $5$ to $500$ packets while the PERs which have been used are $10^{-4}$, $10^{-5}$ and $zero$ PER. \n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics[width=\\linewidth]{topologyideal.pdf}\n\\caption{Non-congested Network topology.}\n\\label{fig:topology-ideal}\n\\end{figure}\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics[width=\\linewidth]{topology.pdf}\n\\caption{Network topology with standard dumbbell bottleneck.}\n\\label{fig:topology}\n\\end{figure}\n\n\\begin{figure} [t!]\n\t\\centering\n\t\\begin{center}\n\t\t\\subfigure[Sequentially established/terminated flows scenario.] \n\t\t{\n\t\t\t\\includegraphics[width=0.9\\linewidth]{multiflowssequence1.pdf}\n\t\t\t\\label{fig:multi-flows-sequence1}\n\t\t}\n\t\t\\subfigure[Synchronously established/terminated flows scenario.] \n\t\t{\n\t\t\t\\includegraphics[width=0.9\\linewidth]{multiflowssequence2.pdf}\n\t\t\t\\label{fig:multi-flows-sequence2}\n\t\t}\n\t\\end{center}\n\t\\caption{The sequence of establishments and terminations of the multiple flows scenarios.}\n\t\\label{fig:multi-flows-sequence}\n\\end{figure}\n\nMoreover, the performance metrics evaluated in this paper are the average throughput, loss ratio, inter-fairness, intra-fairness and RTT-fairness. Average throughput and loss ratio are evaluated to reflect the ability of the TCP variant on utilizing the bandwidth. While, measuring inter-fairness, intra-fairness and RTT-fairness is to show the quality of sharing the link between the competing TCP flows based on Jain's fairness index (JFI) \\citep{jain1984}, as shown in Equation \\eqref{fair}.\n\n\n", "index": 13, "text": "\\begin{align}\nJFI(x_1, x_2, ..., x_n) = \\dfrac{(\\sum_{i=1}^{n} x_i)^2}{n \\cdot \\sum_{i=1}^{n} x_i^2} \t\t\t\t\t\t\t\t\\label{fair}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle JFI(x_{1},x_{2},...,x_{n})=\\dfrac{(\\sum_{i=1}^{n}x_{i})^{2}}{n%&#10;\\cdot\\sum_{i=1}^{n}x_{i}^{2}}\" display=\"inline\"><mrow><mrow><mi>J</mi><mo>\u2062</mo><mi>F</mi><mo>\u2062</mo><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>x</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mrow><mi>n</mi><mo>\u22c5</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}]