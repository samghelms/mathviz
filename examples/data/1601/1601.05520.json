[{"file": "1601.05520.tex", "nexttext": "\nThis function has a cumbersome additional return value just so that the linear\nargument is not discarded. Further, the type above does not express the fact that the\ninput buffer and output buffer are identical --- this would need to be established by additional proof.  To address this problem, we include a type operator~$\\BangF{\\cdot}$, in the style\nof Wadler's $!$ operator, which changes all writable modes in a type to read-only ones. The full definition of $\\BangF{\\cdot}$ is in \\autoref{fig:kinding}.\nWe can therefore write the type of our function as:\n\n", "itemtype": "equation", "pos": 32214, "prevtext": "\n\n\\newtheorem{lemma}{Lemma}\n\\newtheorem{definition}{Definition}\n\\newtheorem{assumption}{Assumption}\n\n\n\n\n\n\n\n\n\n\n\\newtheorem{theorem}{Theorem}\n\n\n\n\n\\floatstyle{boxed}\n\\restylefloat{table}\n\\restylefloat{figure}\n\n\n\n\n\\normalem\n\n  \n  \n\n  \\makeatletter\n  \\newsavebox{\\@brx}\n  \\newcommand{\\llangle}[1][]{\\savebox{\\@brx}{\\(\\m@th{#1\\langle}\\)}     \\mathopen{\\copy\\@brx\\mkern2mu\\kern-0.9\\wd\\@brx\\usebox{\\@brx}}}\n  \\newcommand{\\rrangle}[1][]{\\savebox{\\@brx}{\\(\\m@th{#1\\rangle}\\)}     \\mathclose{\\copy\\@brx\\mkern2mu\\kern-0.9\\wd\\@brx\\usebox{\\@brx}}}\n  \\makeatother\n\n  \n  \n  \\title{{\\textsc{Cogent}\\xspace}: Certified Compilation for a Functional Systems Language}\n  \n  \n\n\n\n\n\n\n\n\\authorinfo{\nLiam~O'Connor,\nChristine~Rizkallah,\nZilin~Chen,\nSidney~Amani,\nJapheth~Lim,\nYutaka~Nagashima,\nThomas~Sewell,\nAlex~Hixon,\nGabriele~Keller,\nToby~Murray,\nGerwin~Klein}\n  {NICTA, Sydney, Australia \\\\\n            University of New South Wales, Australia}\n  {\\href{mailto:christine.rizkallah@nicta.com.au}{first.last@nicta.com.au}\n    \\ifDraft Draft of \\today \\pageref{p:lastpage} pages (of 12 total excl. bib). \\fi}\n\n\n  \\maketitle\n\n\n  \\urlstyle{sf}\n  \\thispagestyle{empty}\n  \\begin{abstract}\n\n\n    We present a self-certifying compiler for the {\\textsc{Cogent}\\xspace} systems language.\n    {\\textsc{Cogent}\\xspace} is a restricted, polymorphic, higher-order, and purely functional\n    language with linear types and without the need for a trusted runtime or\n    garbage collector. It compiles to efficient C code that is designed to\n    interoperate with existing C functions.\n    \n    The language is suited for layered systems code with minimal sharing such\n    as file systems or network protocol control code.\n     \n    For a well-typed {\\textsc{Cogent}\\xspace} program, the compiler produces C code, a\n    high-level shallow embedding of its semantics in Isabelle/HOL, and a\n    proof that the C code correctly implements this embedding. The aim is\n    for proof engineers to reason about the full semantics of\n    real-world systems code productively and equationally,\n    while retaining the interoperability and leanness of C.\n    \n    We describe the formal verification stages of the compiler, which include\n    automated formal refinement calculi, a switch from imperative update\n    semantics to functional value semantics formally justified by the linear\n    type system, and a number of standard compiler phases such as type\n    checking and monomorphisation. The compiler certificate is a series of\n    language-level meta proofs and per-program translation validation phases,\n    combined into one coherent top-level theorem in Isabelle/HOL.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \\end{abstract}\n\n \\ifFinal\n  \\pagestyle{empty}\n\\fi\n\n\n\\category{F.3.2}{Logics and Meanings of Programs}{Semantics of Programming Languages}\n\\ifFinal\n\\category{D.3.2}{Programming Languages}{Language Clas\\-si\\-fication}[Applicative (functional) languages]\n\\category{D.2.4}{Software Engineering}{Software / Program Verification}[For\\-mal methods]\n\\fi\n\n\\keywords verification, semantics, linear types\n\\ifFinal, domain-specific languages, file systems, Isabelle/HOL\\fi\n\n\\section{Introduction}\\label{s:intro}\n\nImagine writing low-level systems code in a purely functional language and then\nreasoning about this code equationally and productively in an interactive\ntheorem prover. Imagine doing this without the need for a trusted compiler,\nruntime or\ngarbage collector and letting this code interoperate with native C parts of\nthe system, including your own efficiently implemented and formally verified\nadditional data types and operations.\n\n{\\textsc{Cogent}\\xspace} achieves this goal by certified compilation from a high-level, pure,\npolymorphic, functional language with linear types, specifically designed for\ncertain classes of systems code. For a given well-typed {\\textsc{Cogent}\\xspace} program, the\ncompiler will produce a high-level shallow embedding of the program's\nsemantics in Isabelle/HOL~\\citep{Nipkow_Klein:Isabelle}, and a theorem that\nconnects this shallow embedding to the C code that the compiler produces:~any \nproperty proved of the shallow embedding is guaranteed\nto hold for the generated C.\n\nThe compilation target is C, because C is the language most existing \nsystems code is written in, and because with the advent of tools like\nCompCert~\\citep{Leroy_06,Leroy_09} and gcc translation\nvalidation~\\citep{Sewell_MK_13}, C is now a language with well understood\nsemantics and existing formal verification infrastructure.\n\nIf C is so great, why not verify C systems code directly? After all, there is\nan ever growing list of successes\n\\citep{Klein_EHACDEEKNSTW_09,Klein_AEMSKH_14,Gu_KRSWWZG_15,Beringer_PYA_15}\nin this space. The reason is simple: verification of manually written C\nprograms remains expensive. Just as high-level languages increase\nprogrammer productivity, they should also increase verification productivity.\nCertifying compilation of a language with verification-friendly semantics is\na key step in achieving this goal for {\\textsc{Cogent}\\xspace}.\n\nThe state of the art for certified compilation of a full featured\nfunctional language is\nCakeML~\\citep{Kumar_MNO_14}, which covers an entire ML dialect. {\\textsc{Cogent}\\xspace} is\ntargeted at a substantially different point in the design space. CakeML includes a verified runtime and garbage collector,\nwhile {\\textsc{Cogent}\\xspace}\nworks hard to avoid these so it can be applicable to low-level embedded\nsystems code. CakeML covers full turing-complete ML with complex semantics\nthat works well for code written in theorem provers.\n{\\textsc{Cogent}\\xspace} is a restricted language of total functions with intentionally simple\nsemantics that are easy to reason about equationally.\nCakeML is great for application code; {\\textsc{Cogent}\\xspace} is great for systems code,\nespecially layered systems code with minimal sharing such as the control\ncode of file systems or network protocol stacks. {\\textsc{Cogent}\\xspace} is not designed for\nsystems code with closely-coupled, cross-cutting sharing, such as\nmicrokernels.\n\n{\\textsc{Cogent}\\xspace}'s main restrictions are the (purposeful) lack of recursion and\niteration and its linear type system. The former ensures totality,\nwhich is important for both systems code correctness as well as for a simple\nshallow representation in higher-order logic. The latter is important for\nmemory management and for making the transition from imperative C semantics\nto functional value semantics. Even in the restricted target domains of\n{\\textsc{Cogent}\\xspace}, real programs will of course contain some amount of iteration. \nThis is\nwhere {\\textsc{Cogent}\\xspace}'s integrated foreign function interface comes in: the engineer \nprovides her own verified data types and\niterator interfaces in C and uses them seamlessly in {\\textsc{Cogent}\\xspace}, including in\nformal reasoning.\n\n{\\textsc{Cogent}\\xspace} is restricted, but it is not a toy language. We have used it to\nimplement two efficient full-scale Linux file systems --- a custom Flash file system\nand an implementation of standard Linux ext2. We plan to report on the experience with these implementations in\nseparate work. The focus of this paper is what can be learned \nfrom {\\textsc{Cogent}\\xspace} about the formal verification of certifying compilation.\n\nIn particular, this paper discusses in detail the following contributions:\n\\begin{inparaenum}[a)]\n\\item the self-certifying {\\textsc{Cogent}\\xspace} compiler and language;\n\\item the formal semantics of the {\\textsc{Cogent}\\xspace} language and the switch from\nimperative update semantics to functional value semantics formally justified\nby the linear type system (\\autoref{s:lang});\n\\item the top-level compiler certificate (\\autoref{s:toplevel}), which is a series of language-level\nmeta proofs and per-program translation validation phases;\n\\item the verification stages that make up the correctness theorem (\\autoref{s:verification}), including\nautomated refinement calculi, formally verified type checking, A-normalisation, and monomorphisation; and\n\\item the lessons learned in this project on functional language formalisation and\ncompiler correctness proofs (\\autoref{s:lessons}).\n\\end{inparaenum}\n\n\n\\section{Overview}\\label{s:overview}\n\nOur aim in this paper is to build a self-certifying compiler from {\\textsc{Cogent}\\xspace} to\nefficient C code, such that a proof engineer can reason equationally about\nits semantics in Isabelle/HOL and apply the compiler theorem to derive\nproperties about the generated C code. Formally, the certificate theorem is a\nrefinement statement between the shallow embedding and the C code. This\ngenerated C code can be compiled by CompCert. It also falls into the subset\nof the gcc translation validation tool by \\citet{Sewell_MK_13}, whose theorem\nwould compose directly with our compiler certificate.\\footnote{At the time of writing, {\\textsc{Cogent}\\xspace}'s occasionally larger stack frames lead to gcc emitting\n\\texttt{memcpy()} calls that, while conceptually straightforward to handle,\nthe translation validator does not yet cover.}\n\n\n\n\nShallow embeddings are nice for the human user, but they do not provide much\nsyntactic structure for constructing the compiler theorem.\nTherefore, the compiler also generates a deep embedding for each {\\textsc{Cogent}\\xspace}\nprogram to use in the internal proof chain.\n\n\n\n\nThere are two semantics for this deep embedding.\n\\begin{inparaenum}[(1)]\n\\item a formal functional \\emph{value semantics} where programs evaluate to values and \n\\item a formal imperative \\emph{update semantics} where programs manipulate references to mutable global state.\n\\end{inparaenum}\n\n\\floatstyle{plain} \\restylefloat{figure}\n\\begin{figure}[tbh]\n    \\begin{center}\n      \\includegraphics[width=\\columnwidth]{detailed-overview.pdf}\n    \\end{center}\n    \\caption{A detailed overview of the verification chain.}\n        \n        \n        \n    \\label{fig:refinement}\n  \\end{figure}\n\\floatstyle{boxed}\n\\restylefloat{figure}\n\n\\noindent \n\\autoref{fig:refinement} shows an overview of the program representations\ngenerated by the compiler and the break-down of the automatic refinement\nproof that makes up the compiler certificate. The program representations\nare, from the bottom of \\autoref{fig:refinement}: the C code, the semantics\nof the C code expressed in Isabelle/Simpl~\\citep{schirmer:phd}, the same\nexpressed as a monadic functional\nprogram~\\citep{Greenaway_AK_12,Greenaway_LAK_14}, a monomorphic A-normal deep\nembedding of the {\\textsc{Cogent}\\xspace} program, a polymorphic A-normal deep embedding of the\nsame, an A-normal shallow embedding, and finally a `neat' shallow embedding\nof the {\\textsc{Cogent}\\xspace} program that is syntactically close to the {\\textsc{Cogent}\\xspace} input of the\ncompiler. Most of the theorems assume that the {\\textsc{Cogent}\\xspace} program is well-typed,\nwhich is discharged automatically in Isabelle with type inference\ninformation from the compiler.\n\nThe solid arrows on the right-hand side of the figure represent refinement\nproofs and the labels on these arrows correspond to the numbers in the\nfollowing description. The only arrow that is not formally verified is the\none crossing from C code into Isabelle/HOL at the bottom of\n\\autoref{fig:refinement} --- this is the C-to-Isabelle parser~\\citep{Tuch_KN_07},\nwhich is a mature verification tool used in a number of large-scale\nverifications. As mentioned, it could additionally be checked by translation\nvalidation. We briefly describe each intermediate theorem, starting with the\nSimpl code at the bottom of the figure. For well-typed {\\textsc{Cogent}\\xspace} programs, we\nautomatically prove:\n\n\\begin{enumerate}\n  \\item Theorem: The Simpl code produced by the C parser corresponds to a\n    monadic representation of the C code. \n    The proof is generated using an adjusted version of the AutoCorres tool.\n \\item Theorem: The monadic program terminates and is a refinement of the monomorphic {\\textsc{Cogent}\\xspace} deep embedding \n    under the update semantics.\n \\item Theorem: If a {\\textsc{Cogent}\\xspace} deep embedding evaluates in the update\nsemantics then it evaluates to the same result in the value semantics.\nThis is a known consequence of linear type systems~\\citep{Hofmann_00}, but to our knowledge\nit is the first mechanised proof of such a property, esp.\\ for a full-scale language.\n \\item Theorem: If a monomorphic {\\textsc{Cogent}\\xspace} deep embedding evaluates in the value semantics \n     then the polymorphic deep embedding evaluates equivalently in the value semantics.\n \\item Theorem: If the polymorphic {\\textsc{Cogent}\\xspace} deep embedding evaluates in the value semantics then \n     the {\\textsc{Cogent}\\xspace} shallow embedding evaluates to a corresponding shallow Isabelle/HOL value.\n \\item Theorem: The A-normal shallow embedding is (extensionally) equal in\nIsabelle/HOL to a syntactically neater shallow embedding, which is more\nconvenient for human reasoning. This human-friendly shallow embedding\ncorresponds to the {\\textsc{Cogent}\\xspace} code before the compiler's A-normalisation phase.\n\n\n\\end{enumerate}\n\n\\noindent\nArrow 7 indicates verification of user-supplied abstract data types\n(ADTs) implemented in C and further manual high-level proofs on top of the\nhuman-friendly shallow embedding. These are enabled by the previous steps,\nbut are not part of this paper.\n\nIn \\autoref{s:verification} we define in more detail the relations that\nformally link the values (and states, when applicable) that these programs\nevaluate to. Steps (3) and (4) are general properties about the language and\nwe therefore prove them manually once and for all. Steps (1), (2), (5), and\n(6) are generated by the compiler for every program. The proof for step (1)\nis generated by AutoCorres. For steps (2) and (5) we define compositional\nrefinement calculi that ease the automation of these proofs. Step (6), the\ncorrectness of A-normalisation, is straightforward to prove via rewriting\nbecause at this stage we can already use equational reasoning.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Language}\\label{s:lang}\n\nIn this section we formally define {\\textsc{Cogent}\\xspace}, including its linear type system,\nits two dynamic semantics --- update and value --- mentioned earlier in\n\\autoref{s:overview}, and the refinement theorem between them. We begin the section by walking through an example\n{\\textsc{Cogent}\\xspace} programs.\n\n\\subsection{Example}\n\n\\autoref{fig:cdsl-snippet} shows an excerpt of our {\\textsc{Cogent}\\xspace} ext2 implementation.\nThe example uses not all, but many features of the language.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure}[th]\n\\begin{lstlisting}[language=CDSL]\ntype ExSt\ntype UArray a\ntype Opt a = <None () | Some a>\ntype Node = #{mbuf:Opt Buf, ptr:U32, fr:U32, to:U32}\ntype Acc = (ExSt, FsSt, VfsInode)\ntype Cnt = (UArray Node, \n  (U32, Node, Acc, U32, UArray Node) -> (Node, Acc))\n\nuarray_create: all (a :< E). (ExSt, U32) \n  -> <Success (ExSt, UArray a) | Err ExSt>\n\next2_free_branch: (U32, Node, Acc, U32) \n  -> (Node, Acc, <Expd Cnt | Iter ()>\next2_free_branch (depth,nd,(ex,fs,inode),mdep) =\n  if depth + 1 < mdep \n    then\n      uarray_create[Node] (ex,nd.to-nd.fr) !nd\n      | Success (ex, children) =>\n        let nd_t { mbuf } = nd\n        and (children, (ex, inode, _, mbuf)) = \n          uarray_map_no_break #{\n            arr  = children,\n            f    = ext2_free_branch_entry,\n            acc  = (ex, inode, node_t.fr, mbuf),\n            ... } !nd_t\n        and nd = nd_t { mbuf }\n        in (nd, (ex, fs, inode), \n          Expd (children, ext2_free_branch_cleanup))\n      | Err ex -> (nd, (ex,fs,inode), Iter ())\n    else ...\n\\end{lstlisting}\n\\caption{{\\textsc{Cogent}\\xspace} example}\\label{fig:cdsl-snippet}\n\\end{figure}\n\n\n\n\\noindent\nThe first line in \\autoref{fig:cdsl-snippet} shows the {\\textsc{Cogent}\\xspace} side of the\nforeign function interface. It declares an abstract {\\textsc{Cogent}\\xspace} data\ntype~{\\texttt{\\textcolor{typecol}{{ExSt}}}\\xspace}, implemented in C. Line 2 shows a parametric abstract\ntype, and line 9 shows a corresponding abstract\nfunction~{\\texttt{\\textcolor{funccol}{{uarray\\_create}}()}\\xspace}, also implemented in C. Note that this\nabstract function is polymorphic, with a kind constraint~$\\Escapable$ (see\n\\autoref{s:kinding}) on type argument {\\texttt{{a}}\\xspace}.\n\nThe integration of such foreign functions is seamless on the {\\textsc{Cogent}\\xspace} side, but\nnaturally has requirements on the corresponding C code. The C side must\nrespect the {\\textsc{Cogent}\\xspace} type system, and, for example, keep all shared state\ninternal to the abstract type to comply with linearity constraints. It must\nalso be terminating and implement the user-supplied semantics that appear in\nthe corresponding shallow embedding of the {\\textsc{Cogent}\\xspace} program in Isabelle/HOL ---\nideally the user should provide a formal proof to discharge the corresponding\nassumption of the compiler certificate theorem.\n\nAbstract functions can be higher-order and provide the\niteration constructs that are intentionally left out from core {\\textsc{Cogent}\\xspace}.\nE.g.\\ line 21, {\\texttt{\\textcolor{funccol}{{uarray\\_map\\_no\\_break}}()}\\xspace} implements a map iterator\nfor arrays. In our\nfile system applications we have found it sufficient to provide a small\nlibrary of iterators for types such as arrays. We also interfaced to an\nexisting mature red-black tree implementation.\n\nReturning to the example in \\autoref{fig:cdsl-snippet}, lines 3--7 show basic\ntype constructors and declarations of \nvariants, records and tuples\nusing type variables and the primitive type {\\texttt{\\textcolor{typecol}{{U32}}}\\xspace}. For instance, type\n{\\texttt{\\textcolor{typecol}{{Cnt}}}\\xspace} is defined as a pair of {\\texttt{\\textcolor{typecol}{{UArray Node}}}\\xspace} and a function\ntype. Types in {\\textsc{Cogent}\\xspace} are structural~\\citep{Pierce_02}, i.e.\\ two types with\nthe same structure but different names are intensionally equal.\n\nMoreover, line 17 calls the abstract polymorphic function   \n{\\texttt{\\textcolor{funccol}{{uarray\\_create}}()}\\xspace}, instantiated with type argument {\\texttt{\\textcolor{typecol}{{Node}}}\\xspace}.\nThe {\\texttt{{!nd}}} notation temporarily turns a linear object of type\n{\\texttt{\\textcolor{typecol}{{Node}}}\\xspace} into a read-only one (see \\autoref{s:letbang}). The two\nbasic, non-linear fields {\\texttt{{to}}} and {\\texttt{{fr}}} in type {\\texttt{\\textcolor{typecol}{{Node}}}\\xspace} can\ndirectly be accessed read-only using projection functions.\nLine 18 and 29 are pattern matches on the result of the function invocation.\nLine 19 shows surface syntax for {\\textsc{Cogent}\\xspace}'s linear \\textbf{take} construct (see\n\\autoref{sec:records}), accessing and binding the {\\texttt{{mbuf}}} field of\n{\\texttt{{nd}}} to the name~{\\texttt{{mbuf}}} (punning as in Haskell), as well as\nbinding the rest of the record to the name {\\texttt{{nd\\_t}}}.\n\n\nThe linear type system tracks that the field {\\texttt{{mbuf}}} is logically absent\nin {\\texttt{{nd\\_t}}}. It also tracks that {\\texttt{{nd}}} on line 19 has been used,\nso cannot be accessed again. Thus the programmer is safe to bind a new object\nto the same name {\\texttt{{nd}}} (on line 26) without worrying about name\nshadowing. Line 26 shows surface syntax for $\\PUT$, the dual to $\\TAKE$,\nwhich re-establishes the {\\texttt{{mbuf}}} fields in the example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Types and Kinding}\\label{s:kinding}\n\n\\citet{Wadler_90} first noted that linear types can be used as a way to safely\nmodel mutable state and similar effects while maintaining a purely functional\nsemantics.  \\citet{Hofmann_00} later proved Wadler's intuition by\nshowing that, for a linear language, imperative C code can implement a simple\nset-theoretic semantics. We use linear types for two reasons: to ensure safe handling of heap-allocated objects, without the need for runtime \nsupport, and to allow us to assign to {\\textsc{Cogent}\\xspace} programs a simple, equational, purely functional semantics implemented via mutable state and imperative effects.\n\n\n\\begin{figure}\n\\begin{grammar}\n\\text{prim. types}     & t              & \\Coloneqq & \\PrimType{U8} \\alt \\PrimType{U16} \\alt \\PrimType{U32} \\alt \\PrimType{U64} \\alt \\PrimType{Bool} \\\\\n\\text{types}           & \\tau, \\rho     & \\Coloneqq & \\alpha \\alt \\Observed{\\alpha} \\alt \\Unit \\\\\n                       &                & \\alt      & t \\alt \\AbsTy{T}{\\many{\\tau}}{m} \\alt \\FunTy{\\tau}{\\rho} \\\\\n                       &                & \\alt      & \\VariantTy{\\many{\\Cons{C}{\\tau}}} \\alt \\RecordTy{\\many{\\FieldTy{f}{\\perhaps{\\tau}}}}{m} \\\\\n\\text{field types}     & \\perhaps{\\tau} & \\Coloneqq & \\tau \\alt \\taken{\\tau}\\\\\n\\text{permissions}     & \\mathcal{P}    & =         & \\{ \\Discardable, \\Shareable, \\Escapable \\}\\\\\n\\text{kinds}           & \\kappa         & \\subseteq & \\mathcal{P} \\\\\n\\text{polytypes}       & \\pi            & ::=       & \\PolyTy{\\many{\\OfKind{\\alpha}{\\kappa}}}{\\tau}\\\\\n\\text{modes}           & m              & \\Coloneqq & \\ReadOnly \\alt \\Writable \\alt \\Unboxed \\\\\n\\text{type variables}  &                & \\ni       & \\alpha, \\beta \\\\\n\\text{abs. type names} &                & \\ni       & \\AbsN{T}, \\AbsN{U} \\\\\n\\text{kind context}    & \\Delta         & \\Coloneqq & \\many{\\ofKind{\\alpha}{\\kappa}} \\\\\n\\text{type context}    & \\Gamma         & \\Coloneqq & \\many{\\ofType{x}{\\tau}}\n\\end{grammar} \\[-1em]\n\\begin{tabular}{p{0.24\\columnwidth}p{0.7\\columnwidth}}\n\\boxlabel{$\\Weakening{\\Delta}{\\Gamma_1}{\\Gamma_2}$} &\n\\begin{displaymath}\n  \\inferrule{\\text{for each $i$:}\\ \\Kinding{\\Delta}{\\tau_i}{\\{\\Discardable\\}}}\n            {\\Weakening{\\Delta}{\\many{\\ofType{x_i}{\\tau_i}},\\Gamma}{\\Gamma}}\n\\end{displaymath} \\[-1.3em]\n\\boxlabel{$\\Contraction{\\Delta}{\\Gamma_1}{\\Gamma_2}{\\Gamma_3}$} &\n\\begin{displaymath}\n  \\inferrule{\\text{for each $i$:}\\ \\Kinding{\\Delta}{\\tau_i}{\\{\\Shareable\\}}}\n            {\\Contraction{\\Delta}{\\many{\\ofType{x_i}{\\tau_i}},\\Gamma_1,\\Gamma_2}{\\many{\\ofType{x_i}{\\tau_i}},\\Gamma_1}{\\many{\\ofType{x_i}{\\tau_i}},\\Gamma_2}}\n\\end{displaymath}\\end{tabular}\n\\vspace{-0.7em}\n\\begin{center}\n  ($\\many{\\text{overbar}}$ indicates lists, i.e. zero or more)\n\\end{center}\n\\vspace{-0.5em}\n\\caption{Type Structure of {\\textsc{Cogent}\\xspace} \\& structural context operations}\n\\label{fig:typestruct}\n\\end{figure}\n\nThe type structure and associated syntax of {\\textsc{Cogent}\\xspace} is presented in \\autoref{fig:typestruct}. Our type system is loosely based on the polymorphic\n$\\lambda_{\\text{URAL}}$ of \\citet{Ahmed_FM_05}. We restrict this polymorphism to be rank-1 and predicative, in the style of ML, to permit easy implementation\nby specialisation with minimal performance penalty. \n\nTo ease implementation, and to eliminate any direct dependency on a heap allocator, we require that all functions be defined on the top-level. \nThis eliminates the need for linear function types: any top-level function can be shared freely because they cannot capture \\emph{any} local variables, \nlet alone linear ones.\n\nWe include a set of primitive integer types ($\\PrimType{U8}$, $\\PrimType{U16}$\netc.). Records $\\RecordTy{\\many{\\FieldTy{f}{\\perhaps{\\tau}}}}{m}$ comprise\n(1)~a sequence of fields $f :: \\perhaps{\\tau}$, where $\\taken{\\tau}$ is the type on\nan inaccessible field, and (2)~a mode $m$ (see\n \\mbox{\\autoref{sec:records}} and \\autoref{s:kindrec} for a more detailed description). We also have polymorphic variants\n$\\VariantTy{\\many{\\Cons{C}{\\tau}}}$, a generalised sum type in the style of\nOCaml, the mechanics of which are briefly described in\n\\autoref{s:variants}. Abstract types $\\AbsTy{T}{\\many{\\tau}}{m}$ are also\nparametrised by modes.\nWe omit product types from this presentation; \nthey are desugared into unboxed records.\n\nThe most obvious similarity to $\\lambda_{\\text{URAL}}$ is our use of \\emph{kinds} to determine if a type may be freely shared or discarded, as \nopposed to earlier linear type systems, such as that of~\\citet{Wadler_90}, where a type's linearity is encoded directly into its syntactic structure. Kinds \nin {\\textsc{Cogent}\\xspace} are sets of \\emph{permissions}, denoting whether a variable of that type may be discarded without being used ($\\Discardable$), shared freely and used \nmultiple times ($\\Shareable$), or safely bound in a $\\LET!$ expression ($\\Escapable$). A \\emph{linear} type, values of which must be used exactly once, \nhas a kind\nthat excludes~$\\Discardable$ and~$\\Shareable$, and so forbids it being discarded or shared.\nWe discuss $\\LET!$ expressions in \\autoref{sec:kindletb}. \n\nAnother similarity to $\\lambda_{\\text{URAL}}$ is that we explicitly represent the context operations of weakening and contraction, normally relegated to structural rules, \nas explicit judgements: $\\Weakening{\\Delta}{\\Gamma}{\\Gamma'}$ for weakening (discarding assumptions) and $\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2}$ for contraction (duplicating them). \nThe rules for these judgements are presented in \\autoref{fig:typestruct}. For a typing assumption to be discarded (respectively duplicated),\nthe type must have kind $\\{\\Discardable\\}$ (resp. $\\{\\Shareable\\}$).\n\n\n\\begin{figure}\n\\begin{inductive}{\\Kinding{\\Delta}{\\tau}{\\kappa}}\n  \\inferrule{ }{\\Kinding{\\Delta}{\\Unit}{\\kappa}}{\\rulename{KUnit}} \\quad\n  \\inferrule{ }{\\Kinding{\\Delta}{t}{\\kappa}}{\\rulename{KPrim}} \\quad\n  \\inferrule{ }{\\Kinding{\\Delta}{\\FunTy{\\tau}{\\rho}}{\\kappa}}{\\rulename{KFun}} \\\\\n  \\inferrule{(\\ofKind{\\alpha}{\\kappa'}) \\in \\Delta \\quad \\kappa \\subseteq \\kappa'}\n            {\\Kinding{\\Delta}{\\alpha}{\\kappa}}{\\rulename{KVar}} \\quad\n  \\inferrule{(\\ofKind{\\alpha}{\\kappa'}) \\in \\Delta \\quad \\kappa \\subseteq \\BangF{\\kappa'}}\n            {\\Kinding{\\Delta}{\\alpha!}{\\kappa}}{\\rulename{KVar}!} \\\\\n  \n  \n  \\inferrule{ \\text{for each $i$:}\\ \\Kinding{\\Delta}{\\tau_i}{\\kappa} }\n            {\\Kinding{\\Delta}{\\VariantTy{\\many{\\Cons{C_\\mathit{i}}{\\tau_i}}}}{\\kappa}}{\\rulename{KVariant}} \\\\\n  \\inferrule{ \\ofKind{m}{\\kappa'} \\\\ \\kappa \\subseteq \\kappa' \\\\\\\\ \\text{for each $i$:}\\ \\Kinding{\\Delta}{\\tau_i}{\\kappa} }\n            {\\Kinding{\\Delta}{\\AbsTy{T}{\\many{\\tau_i}}{m}}{\\kappa}}{\\rulename{KAbs}} \\quad\\!\\!\\!\n  \\inferrule{ \\ofKind{m}{\\kappa'} \\\\ \\kappa \\subseteq \\kappa' \\\\\\\\ \\text{for each $\\tau_i$ not taken:}\\ \\Kinding{\\Delta}{\\tau_i}{\\kappa} }\n            {\\Kinding{\\Delta}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}}{\\kappa}}{\\rulename{KRec}} \\\\\n\\end{inductive}\n\\vspace{-2.5em}\n\\begin{inductive}{\\ofKind{m}{\\kappa}}\n  \\inferrule{}{\\ofKind{\\ReadOnly}{\\{\\Discardable, \\Shareable\\}}} \\quad\n  \\inferrule{}{\\ofKind{\\Writable}{\\{\\Escapable\\}}} \\quad\n  \\inferrule{}{\\ofKind{\\Unboxed}{\\{\\Discardable, \\Shareable, \\Escapable\\}}} \n\\end{inductive}\n\\vspace{-1em}\n  \\boxlabel{$\\BangF{\\cdot} : \\tau \\rightarrow \\tau$}\n  \\begin{displaymath}\n    \\begin{array}{lcl}\n      \\BangF{\\alpha}                                       & = & \\Observed{\\alpha} \\\\\n      \\BangF{\\Observed{\\alpha}}                            & = & \\Observed{\\alpha} \\\\\n      \\BangF{\\Unit}                                        & = & \\Unit \\\\\n      \\BangF{t}                                            & = & t \\\\\n      \\BangF{\\AbsTy{T}{\\many{\\tau_i}}{m}}                  & = & \\AbsTy{T}{\\many{\\BangF{\\tau_i}}}{\\BangF{m}} \\\\\n      \\BangF{\\FunTy{\\tau}{\\rho}}                           & = & \\FunTy{\\tau}{\\rho} \\\\\n\n      \\BangF{\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}}        & = & \\VariantTy{\\many{\\Cons{C_i}{\\BangF{\\tau_i}}}} \\\\\n      \\BangF{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}} & = & \\RecordTy{\\many{\\FieldTy{f$_i$}{\\BangF{\\perhaps{\\tau_i}}}}}{\\BangF{m}} \\\\\n    \\end{array}\n  \\end{displaymath}\n  \\boxlabel{$\\BangF{\\cdot} : \\kappa \\rightarrow \\kappa$}\n  \\begin{displaymath}\n     \\BangF{\\kappa} \\quad = \\quad \\begin{cases}\n                                     \\kappa                        & \\text{if}\\ \\{\\Discardable, \\Shareable\\} \\subseteq \\kappa \\\\\n                                     \\{\\Discardable, \\Shareable\\}  & \\text{otherwise}\n                                  \\end{cases}\n  \\end{displaymath}\n  \\boxlabel{$\\BangF{\\cdot} : m \\rightarrow m$}\n  \\begin{displaymath}\n    \\begin{array}{lcl}\n      \\BangF{\\ReadOnly}                                       & = & \\ReadOnly\\\\\n      \\BangF{\\Writable}                                       & = & \\ReadOnly\\\\\n      \\BangF{\\Unboxed}                                        & = & \\Unboxed \\\\\n    \\end{array}\n  \\end{displaymath}\n\\caption{Kinding rules for {\\textsc{Cogent}\\xspace} types and the $\\BangF{\\cdot}$ operator}\n\\label{fig:kinding}\n\\end{figure}\n\nThe full kinding rules for the types of {\\textsc{Cogent}\\xspace} are given in \\autoref{fig:kinding}. Basic types such as $\\Unit$ or $\\PrimType{U8}$, as well as functions,\nare simply passed by value and do not contain any heap references, so they may be given any kind. Kinding for structures and abstract functions is discussed\nshortly in \\autoref{s:kindrec}.\n\n\nA type may have multiple kinds, as a nonlinear type assumption may be used linearly, never being shared and being used exactly once. Therefore, a type with a\npermissive kind, such as $\\{\\Discardable, \\Shareable\\}$, would be an acceptable instantiation of a type variable of kind $\\emptyset$, as we are free to \n\\emph{waive} permissions that are included in a kind. We can prove formally by straightforward rule induction:\n\\begin{lemma}[Waiving rights] If $\\Kinding{\\Delta}{\\tau}{\\kappa}$ and $\\kappa' \\subseteq \\kappa$, then $\\Kinding{\\Delta}{\\tau}{\\kappa'}$.\n\\end{lemma}\n\\noindent This result allows for a simple kind-checking algorithm, not immediately apparent from the rules. For example, the maximal kind of an unboxed\nstructure with two fields of type $\\tau_1$ and $\\tau_2$ respectively can be computed by taking the intersection of the computed maximal kinds of $\\tau_1$ and $\\tau_2$. This result ensures\nthat this intersection is also a valid kind for $\\tau_1$ and $\\tau_2$.\n\n\\subsubsection{Kinding for Records and Abstract Types}\\label{s:kindrec}\n\nRecall that {\\textsc{Cogent}\\xspace} may be extended with \\emph{abstract types}, implemented in\nC, which we write as\n$\\AbsTy{T}{\\many{\\tau_i}}{m}$ in our formalisation. We allow abstract types\nto take any number of \\emph{type parameters} ${\\tau_i}$, where each specific\ninstance corresponds to a distinct C type. For example, a $\\mathtt{List}$ abstract type,\nparameterised by its element type, would correspond to a family of C $\\mathtt{List}$ types,\neach one specialised to a particular concrete element type. Because the implementations of these\ntypes are user supplied, the user is free to specialise implementations based on these type parameters,\nfor example representing an array of boolean values as a bitstring, so long as they can show \nthat every different operation implementation is a refinement of the same user-supplied CDSL \nsemantics for that operation.\n\nValues of abstract types may be represented by references to heap data structures. \nSpecifically, an abstract type or structure is stored on the heap when its associated\n\\emph{storage mode}~$m$ is not ``\\Unboxed''. For boxed records and abstract\ntypes, the storage mode distinguishes between those that are ``\\Writable'' vs.\n``\\ReadOnly''. The same is true for record types, written $\\RecordTy{\\many{\\FieldTy{f}{\\perhaps{\\tau}}}}{m}$,\nwhich are discussed in more detail in \\autoref{sec:records}.\n\n\nThe storage mode $m$ affects the maximal kind that can be assigned\nto the type. For example, an unboxed structure with two components of type $\\PrimType{U8}$ is freely shareable, but if the structure is\ninstead stored on the heap, then a writable reference to that structure must be linear. Thus, the type given to such references has the ``$\\Writable$'' mode,\nwhose kind is $\\{\\Escapable\\}$, thereby preventing such a reference from being assigned a nonlinear kind such as $\\{\\Discardable,\\Shareable\\}$.\n\n\n\n\n\n\n\n\n\n\\subsubsection{Kinding and $\\textbf{bang}$}\n\\label{sec:kindletb}\n\nLike \\citet{Wadler_90}, we allow linear values to be shared read-only in a limited scope. This is useful for practical programming\nin a language with linear types, as it makes our types more informative. For example, to write a function to determine the size of a (linear) buffer object, \na naive approach would be to write a function:\n\n", "index": 1, "text": "$$\\mathsf{size} : \\mathtt{Buf} \\rightarrow \\mathtt{U32} \\times \\mathtt{Buf}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mathsf{size}:\\mathtt{Buf}\\rightarrow\\mathtt{U32}\\times\\mathtt{Buf}\" display=\"block\"><mrow><mi>\ud835\uddcc\ud835\uddc2\ud835\uddd3\ud835\uddbe</mi><mo>:</mo><mrow><mi>\ud835\ude71\ud835\ude9e\ud835\ude8f</mi><mo>\u2192</mo><mrow><mi>\ud835\ude84\ud835\udff9\ud835\udff8</mi><mo>\u00d7</mo><mi>\ud835\ude71\ud835\ude9e\ud835\ude8f</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\nFor any valid type $\\tau$, the kind of $\\BangF{\\tau}$ will be\nnonlinear, which means that our $\\mathsf{size}$ function no longer needs to be encumbered by the \nextra return value. This kinding result is formally stated as:\n\n\\begin{lemma}[Kinding for $\\BangF{\\cdot}$] For any type $\\tau$, if $\\Kinding{\\Delta}{\\tau}{\\kappa}$ then $\\Kinding{\\Delta}{\\BangF{\\tau}}{\\BangF{\\kappa}}$.\n\\end{lemma}\n\n\\noindent To integrate this type operator with parametric polymorphism, we borrow a trick from Odersky's Observer types~\\citep{Odersky_92}, and tag type variables that\nhave been made read only, using the syntax $\\alpha!$. Whenever a variable $\\alpha$ is instantiated to some concrete type $\\tau$, we also replace \n$\\alpha!$ with $\\BangF{\\tau}$. The lemma above ensures that our kinding rule for such tagged variables is sound, and enables us to prove the following:\n\n\\begin{lemma}[Type instantiation preserves kinds] For any type $\\tau$, $\\Kinding{\\many{\\ofKind{\\alpha_i}{\\kappa_i}}}{\\tau}{\\kappa}$\n      implies $\\Kinding{\\Delta}{\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{\\kappa}$ when, for each $i$, $\\Kinding{\\Delta}{\\rho_i}{\\kappa_i}$.\n\\end{lemma}\n\n\\subsection{Expressions and Typing}\n\\begin{figure}\n\\begin{grammar}\n\\text{primops}         & o              & \\in       & \\{\\texttt{+}, \\texttt{*}, \\texttt{/}, \\texttt{<=}, \\texttt{==}, \\texttt{||}, \\texttt{{<}<}, \\dots\\} \\\\\n\\text{literals}        & \\ell           & \\in       & \\{123, \\mathtt{True}, \\texttt{'a'}, \\dots\\} \\\\\n\\text{expressions}     & e              & \\Coloneqq & \\VarN{x} \\alt \\Unit \\alt \\TyApp{f}{\\many{\\tau}} \\alt \\GenPrimOp{o}{\\many{e}} \\alt \\App{e_1}{e_2} \\\\\n                       &                & \\alt      & \\Let{x}{e_1}{e_2} \\\\\n                       &                & \\alt      & \\LetBang{\\many{y}}{x}{e_1}{e_2} \\\\\n\n                       &                & \\alt      & \\If{e_1}{e_2}{e_3} \\\\\n                       &                & \\alt      & \\ell \\alt \\Cast{t}{e} \\alt \\Promote{\\many{\\Cons{C}{\\tau}}}{e} \\\\\n                       &                & \\alt      & \\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3} \\\\\n                       &                & \\alt      & \\Esac{e} \\alt \\Cons{C}{e} \\\\\n                       &                & \\alt      & \\StructInit{\\many{\\FieldEq{f}{e}}} \\alt \\Member{e}{f} \\alt \\Put{e_1}{f}{e_2} \\\\\n                       &                & \\alt      & \\Take{x}{f}{y}{e_1}{e_2} \\\\\n\\text{function def.}   & d              & \\Coloneqq & \\FunDef{f}{\\pi}{x}{e} \\alt \\AbsFunDef{f}{\\pi} \\\\\n\\text{programs}        & P              & \\Coloneqq & \\many{d}\\\\\n\\text{function names}  &                & \\ni       & \\FunN{f}, \\FunN{g} \\\\\n\\text{variables}       &                & \\ni       & \\VarN{x}, \\VarN{y} \\\\\n\\text{constructors}    &                & \\ni       & \\ConsN{A},\\ConsN{B},\\ConsN{C} \\\\\n\\text{record fields}   &                & \\ni       & \\FieldN{f}, \\FieldN{g} \\\\\n\\end{grammar}\n\\begin{displaymath}\n  \\begin{array}{lclr}\n    \\PrimOpType{\\cdot} & : & o \\rightarrow \\many{t} \\times t & \\text{(primop types)} \\\\\n    \\FunDefn{\\cdot} &  : & f \\rightarrow d  & \\text{(definition environment)}\\\\\n    |\\cdot| & : & t \\rightarrow \\mathbb{N} & \\text{(maximum value)}  \\\\\n  \\end{array}\n\\end{displaymath}\n\\caption{Syntax of {\\textsc{Cogent}\\xspace} programs (after desugaring)}\n\\label{fig:syntax}\n\\end{figure}\n\\noindent \nWhile {\\textsc{Cogent}\\xspace} features a rich surface syntax, due to space constraints, we only document the (full) core language in \\autoref{fig:syntax} to which the surface syntax is desugared.\n\n\\begin{figure*}\n  \\begin{inductive}{\\Typing{\\Delta}{\\Gamma}{e}{\\tau}}\n    \\inferrule{\\Weakening{\\Delta}{\\Gamma}{\\ofType{x}{\\tau}}}{\\Typing{\\Delta}{\\Gamma}{x}{\\tau}}{\\rulename{Var}} \\quad\n    \\inferrule{ }{\\Typing{\\Delta}{\\Gamma}{\\Unit}{\\Unit}}{\\rulename{Unit}} \\quad\n    \\inferrule{ \\ell < |t|}{\\Typing{\\Delta}{\\Gamma}{\\ell}{t}}{\\rulename{Literal}} \\quad\n    \\inferrule{ \\TypingS{\\Delta}{\\Gamma}{\\many{e_i}}{\\many{t_i}} \\\\\\\\\n               \\PrimOpType{o} = (\\many{t_i}, t) }\n              {\\Typing{\\Delta}{\\Gamma}{\\GenPrimOp{o}{\\many{e_i}}}{t}}{\\rulename{PrimOp}}\\quad\n    \\inferrule{ \\Typing{\\Delta}{\\Gamma}{e}{t'} \\\\ |t'| \\le |t| }{\\Typing{\\Delta}{\\Gamma}{\\Cast{t}{e}}{t}}{\\rulename{Cast}} \\\\\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\rho \\rightarrow \\tau} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho} }\n              {\\Typing{\\Delta}{\\Gamma}{\\App{e_1}{e_2}}{\\tau}}{\\rulename{App}} \\quad\\!\\!\n    \\inferrule{\\FunTyEnv{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}}\\\\\\\\\n               \\text{for each $i$:}\\ \\Kinding{\\Delta}{\\rho_i}{\\kappa_i}}\n              {\\Typing{\\Delta}{\\Gamma}{\\TyApp{f}{\\many{\\rho_i}}}{\\Subst{(\\tau \\rightarrow \\tau')}{\\many{\\alpha_i}}{\\many{\\rho_i}}}}{\\rulename{Fun}} \\quad\\!\\!\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\VariantTy{\\Cons{A}{\\rho} \\alt \\many{\\Cons{C_i}{\\tau_i}}}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\rho}, \\Gamma_2}{e_2}{\\tau} \\\\\n               \\Typing{\\Delta}{\\ofType{y}{\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}}, \\Gamma_2}{e_3}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Case{e_1}{\\Cons{A}{\\VarN{x}}}{e_2}{y}{e_3}}{\\tau}}{\\rulename{Case}}    \n    \n    \n    \n    \n    \n  \\\\\n  \\end{inductive}\n  \\begin{center}\n    \\begin{tabular}{p{0.625\\textwidth}|p{0.25\\textwidth}}\n      \\begin{inductive0}\n    \\begin{tabular}{c}\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Cons{C}{e}}{\\VariantTy{\\Cons{C}{\\tau}}}}{\\rulename{Cons}} \\quad\\!\\!\\!\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\VariantTy{\\many{\\Cons{B}{\\rho}}}} \\\\\n               \\many{\\Cons{B}{\\rho}} \\subseteq \\many{\\Cons{C}{\\tau}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Promote{\\many{\\Cons{C}{\\tau}}}{e}}{\\VariantTy{\\many{\\Cons{C}{\\tau}}}}}{\\rulename{Prom}} \\quad\\!\\!\\!\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\VariantTy{\\Cons{C}{\\tau}}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Esac{e}}{\\tau}}\n              {\\rulename{Esac}} \\quad\\!\\!\\!\n\\\\\\\\\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n                   \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\rho} \\\\\n                   \\Typing{\\Delta}{\\ofType{x}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n                  {\\Typing{\\Delta}{\\Gamma}{\\Let{x}{e_1}{e_2}}{\\tau}}{\\rulename{Let}} \\quad\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n                   \\Kinding{\\Delta}{\\rho}{\\{\\Escapable\\}}\\\\\\\\\n                   \\Typing{\\Delta}{\\many{\\ofType{v_i}{\\BangF{\\tau_i}}}, \\Gamma_1}{e_1}{\\rho} \\\\\\\\\n                   \\Typing{\\Delta}{\\many{\\ofType{v_i}{\\tau_i}}, \\ofType{x}{\\rho},\\Gamma_2}{e_2}{\\tau}}\n                  {\\Typing{\\Delta}{\\many{\\ofType{v_i}{\\tau_i}}, \\Gamma}{\\LetBang{\\many{v_i}}{x}{e_1}{e_2}}{\\tau}}{\\rulename{Let}!} \\\\\n        \n        \n        \n        \n        \n        \n        \n        \n        \\end{tabular}\n      \\end{inductive0}\n      &\\vspace{-2ex}\n      \\begin{inductive}{\\TypingS{\\Delta}{\\Gamma}{\\many{e}}{\\many{\\tau}}}\n        \\inferrule{\\Weakening{\\Delta}{\\Gamma}{\\emptyset} }\n                  {\\TypingS{\\Delta}{\\Gamma}{\\varepsilon}{\\varepsilon}}{\\rulename{L}_\\varepsilon} \\\\\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n                   \\Typing{\\Delta}{\\Gamma_1}{e}{\\tau} \\\\\n                   \\TypingS{\\Delta}{\\Gamma_2}{\\many{e_i}}{\\many{\\tau_i}}}\n                  {\\TypingS{\\Delta}{\\Gamma}{e\\ \\many{e_i}}{ \\tau\\ \\many{\\tau_i} }}{\\rulename{L}_C}\n      \\end{inductive}\n    \\end{tabular}\n  \\end{center}\\vspace{1.5ex}\n  \\begin{inductive0}\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau_i}}}, \\FieldTy{f}{\\rho} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau_j}}}}{m}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau_i}}}, \\FieldTy{f}{\\taken{\\rho}} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau_j}}}}{m}}, \\ofType{y}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Take{x}{f}{y}{e_1}{e_2}}{\\tau}}{\\rulename{Take}_1} \\quad\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               \\Kinding{\\Delta}{\\rho}{\\{\\Shareable\\}} \\\\\\\\\n               m \\neq \\ReadOnly \\\\ \\perhaps{\\tau_k} = \\rho \\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}}, \\ofType{y}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\tau}}\n              {\\rulename{Take}_2} \\\\\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau}_i}}, \\FieldTy{f}{\\taken{\\rho}} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau}_j}}}{m}} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Put{e_1}{f}{e_2}}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau}_i}}, \\FieldTy{f}{\\rho} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau}_j}}}{m}}}{\\rulename{Put}_1} \\quad\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\ \\perhaps{\\tau}_k = \\rho\\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau}_i}}}{m}} \\\\\n               \\Kinding{\\Delta}{\\rho}{\\{\\Discardable\\}} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Put{e_1}{f$_k$}{e_2}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau}_i}}}{m}}}{\\rulename{Put}_2} \\\\\n    \\inferrule{\\Kinding{\\Delta}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\rho}_i}}, \\FieldTy{f}{\\tau} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\rho}_j}}}{m}}{\\{\\Shareable\\}} \\\\\\\\\n              \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\rho}_i}}, \\FieldTy{f}{\\tau} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\rho}_j}}}{m}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Member{e}{f}}{\\tau}}{\\rulename{Member}} \\quad\n    \\inferrule{\\TypingS{\\Delta}{\\Gamma}{\\many{e_i}}{\\many{\\tau_i}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Unboxed}}}\n              {\\rulename{Struct}}\n  \\end{inductive0}\n  \\caption{Typing rules for {\\textsc{Cogent}\\xspace}}\n  \\label{fig:typing}\n\\end{figure*}\n\n\\autoref{fig:typing} shows the typing rules for {\\textsc{Cogent}\\xspace} expressions.\nMany of these are standard for any linear type system. We will\ndiscuss here the rules for $\\LET!$, where we have taken a slightly different approach to established literature, and the rules for the \nextensions we have made to the type system, such as variants and record types.\n\n\\subsubsection{Typing for $\\LET!$}\\label{s:letbang}\n\nOn the expression level, the programmer can use $\\LET!$ expressions, in the style of \\citet{Wadler_90}, to temporarily convert variables of linear types to their\nread-only equivalents, allowing them to be freely shared. In this example, we wish to copy a buffer $b_2$ onto a buffer $b_1$ only when $b_2$ will fit inside\n$b_1$. \n\n", "itemtype": "equation", "pos": 32852, "prevtext": "\nThis function has a cumbersome additional return value just so that the linear\nargument is not discarded. Further, the type above does not express the fact that the\ninput buffer and output buffer are identical --- this would need to be established by additional proof.  To address this problem, we include a type operator~$\\BangF{\\cdot}$, in the style\nof Wadler's $!$ operator, which changes all writable modes in a type to read-only ones. The full definition of $\\BangF{\\cdot}$ is in \\autoref{fig:kinding}.\nWe can therefore write the type of our function as:\n\n", "index": 3, "text": "$$\\mathsf{size} : \\BangF{\\mathtt{Buf}} \\rightarrow \\mathtt{U32}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\mathsf{size}:\\BangF{\\mathtt{Buf}}\\rightarrow\\mathtt{U32}\" display=\"block\"><mrow><mi>\ud835\uddcc\ud835\uddc2\ud835\uddd3\ud835\uddbe</mi><mo>:</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\BangF</mtext></merror><mo>\u2062</mo><mi>\ud835\ude71\ud835\ude9e\ud835\ude8f</mi></mrow><mo>\u2192</mo><mi>\ud835\ude84\ud835\udff9\ud835\udff8</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": " \nNote that even though $b_1$ and $b_2$ are used multiple times, they are only used once in a linear context. Inside the $\\LET!$ binding, they have been made\ntemporarily nonlinear. Our kind system ensures these read-only, shareable references inside $\\LET!$ bindings cannot ``escape'' into\nthe outside context. For example, the expression $\\LetBang{b}{b'}{b}{\\mathsf{copy}(b, b')}$ would violate the invariants of the linear type system, and ruin the purely\nfunctional abstraction that linear types allow, as both $b$ and $b'$ would refer to the same object, and a destructive update to $b$ would change the shareable $b'$. \n\nWe are able to use the existing kind system to handle these safety checks with\nthe inclusion of the $\\Escapable$ permission, for\n$\\Escapable$scapable, which indicates that the type may be safely returned\nfrom within a $\\LET!$. We ensure, via the typing rules of\n\\autoref{fig:typing}, that the left hand side of the binding ($\\mathit{ok}$ in the example) has the\n$\\Escapable$ permission, which excludes temporarily nonlinear references via\n$\\BangF{\\cdot}$ (see \\autoref{fig:kinding}). Our solution is as powerful as\nOdersky's, but we encode the restrictions in the kind system directly, not as \nside-condition constraints that recursively descend into the structure of\nthe binding's type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Typing for Variants}\\label{s:variants}\nA variant type $\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}$ is a generalised sum type, where each alternative is distinguished by a unique \\emph{data constructor}~$\\ConsN{C_i}$. The order in which the constructors appear in the type is not important.\nOne can create a variant type with a single alternative simply by invoking a constructor, e.g. $\\Cons{Some}{255}$ might be given the type\n$\\VariantTy{\\Cons{Some}{\\PrimType{U8}}}$. The original value of $255$ can be retrieved using the $\\ESAC$ construct. The set of alternatives is enlarged \nby using $\\PROMOTE$ expressions that are automatically inserted by the type-checker of the surface language, which uses subtyping to infer the type of a given\nvariant. A similar trick is used for numeric literals and $\\CAST$. \n\nIn order to pattern match on a variant, we provide a $\\CASE$ construct that attempts to match against one constructor. If the constructor does not match, \nit is \\emph{removed} from the type and the reduced type is provided to the $\\ELSE$ branch. In this way, a traditional multi-way pattern match can be desugared\nby nesting:\n\\begin{displaymath}\n\\begin{array}{@{}lcl@{}}\n \\begin{array}{l}\n   \\CASE\\ x\\ \\OF \\\\\n  \\quad \\Cons{A}{a} \\rightarrow e_a \\\\\n  \\quad \\Cons{B}{b} \\rightarrow e_b \\\\\n  \\quad \\Cons{C}{c} \\rightarrow e_c \n \\end{array}  & \\text{becomes} & \\begin{array}{l}\n   \\CASE\\ x\\ \\OF \\\\\n   \\quad \\Cons{A}{a} \\rightarrow {e_a} \\\\\n   \\quad \\ELSE\\ x' \\rightarrow \\CASE\\ x'\\ \\OF \\\\\n   \\quad\\quad \\Cons{B}{b} \\rightarrow e_b \\\\\n   \\quad\\quad \\ELSE\\ x'' \\rightarrow \\LET\\ c = \\Esac{x''}\\ \\IN\\ e_c\n \\end{array} \n\\end{array}\n\\end{displaymath}\nNote that because the typing rule for $\\ESAC$ only applies when only one alternative remains, our pattern matching is necessarily total.\n\n\\subsubsection{Typing for Records}\n\\label{sec:records}\n\n\n\n\n\n\n\n\nSome care is needed to reconcile record types and linear types.\nAssume that $\\mathtt{Object}$ is a type synonym for an (unboxed) record type containing an integer and two (linear) buffers.\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nFor any valid type $\\tau$, the kind of $\\BangF{\\tau}$ will be\nnonlinear, which means that our $\\mathsf{size}$ function no longer needs to be encumbered by the \nextra return value. This kinding result is formally stated as:\n\n\\begin{lemma}[Kinding for $\\BangF{\\cdot}$] For any type $\\tau$, if $\\Kinding{\\Delta}{\\tau}{\\kappa}$ then $\\Kinding{\\Delta}{\\BangF{\\tau}}{\\BangF{\\kappa}}$.\n\\end{lemma}\n\n\\noindent To integrate this type operator with parametric polymorphism, we borrow a trick from Odersky's Observer types~\\citep{Odersky_92}, and tag type variables that\nhave been made read only, using the syntax $\\alpha!$. Whenever a variable $\\alpha$ is instantiated to some concrete type $\\tau$, we also replace \n$\\alpha!$ with $\\BangF{\\tau}$. The lemma above ensures that our kinding rule for such tagged variables is sound, and enables us to prove the following:\n\n\\begin{lemma}[Type instantiation preserves kinds] For any type $\\tau$, $\\Kinding{\\many{\\ofKind{\\alpha_i}{\\kappa_i}}}{\\tau}{\\kappa}$\n      implies $\\Kinding{\\Delta}{\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{\\kappa}$ when, for each $i$, $\\Kinding{\\Delta}{\\rho_i}{\\kappa_i}$.\n\\end{lemma}\n\n\\subsection{Expressions and Typing}\n\\begin{figure}\n\\begin{grammar}\n\\text{primops}         & o              & \\in       & \\{\\texttt{+}, \\texttt{*}, \\texttt{/}, \\texttt{<=}, \\texttt{==}, \\texttt{||}, \\texttt{{<}<}, \\dots\\} \\\\\n\\text{literals}        & \\ell           & \\in       & \\{123, \\mathtt{True}, \\texttt{'a'}, \\dots\\} \\\\\n\\text{expressions}     & e              & \\Coloneqq & \\VarN{x} \\alt \\Unit \\alt \\TyApp{f}{\\many{\\tau}} \\alt \\GenPrimOp{o}{\\many{e}} \\alt \\App{e_1}{e_2} \\\\\n                       &                & \\alt      & \\Let{x}{e_1}{e_2} \\\\\n                       &                & \\alt      & \\LetBang{\\many{y}}{x}{e_1}{e_2} \\\\\n\n                       &                & \\alt      & \\If{e_1}{e_2}{e_3} \\\\\n                       &                & \\alt      & \\ell \\alt \\Cast{t}{e} \\alt \\Promote{\\many{\\Cons{C}{\\tau}}}{e} \\\\\n                       &                & \\alt      & \\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3} \\\\\n                       &                & \\alt      & \\Esac{e} \\alt \\Cons{C}{e} \\\\\n                       &                & \\alt      & \\StructInit{\\many{\\FieldEq{f}{e}}} \\alt \\Member{e}{f} \\alt \\Put{e_1}{f}{e_2} \\\\\n                       &                & \\alt      & \\Take{x}{f}{y}{e_1}{e_2} \\\\\n\\text{function def.}   & d              & \\Coloneqq & \\FunDef{f}{\\pi}{x}{e} \\alt \\AbsFunDef{f}{\\pi} \\\\\n\\text{programs}        & P              & \\Coloneqq & \\many{d}\\\\\n\\text{function names}  &                & \\ni       & \\FunN{f}, \\FunN{g} \\\\\n\\text{variables}       &                & \\ni       & \\VarN{x}, \\VarN{y} \\\\\n\\text{constructors}    &                & \\ni       & \\ConsN{A},\\ConsN{B},\\ConsN{C} \\\\\n\\text{record fields}   &                & \\ni       & \\FieldN{f}, \\FieldN{g} \\\\\n\\end{grammar}\n\\begin{displaymath}\n  \\begin{array}{lclr}\n    \\PrimOpType{\\cdot} & : & o \\rightarrow \\many{t} \\times t & \\text{(primop types)} \\\\\n    \\FunDefn{\\cdot} &  : & f \\rightarrow d  & \\text{(definition environment)}\\\\\n    |\\cdot| & : & t \\rightarrow \\mathbb{N} & \\text{(maximum value)}  \\\\\n  \\end{array}\n\\end{displaymath}\n\\caption{Syntax of {\\textsc{Cogent}\\xspace} programs (after desugaring)}\n\\label{fig:syntax}\n\\end{figure}\n\\noindent \nWhile {\\textsc{Cogent}\\xspace} features a rich surface syntax, due to space constraints, we only document the (full) core language in \\autoref{fig:syntax} to which the surface syntax is desugared.\n\n\\begin{figure*}\n  \\begin{inductive}{\\Typing{\\Delta}{\\Gamma}{e}{\\tau}}\n    \\inferrule{\\Weakening{\\Delta}{\\Gamma}{\\ofType{x}{\\tau}}}{\\Typing{\\Delta}{\\Gamma}{x}{\\tau}}{\\rulename{Var}} \\quad\n    \\inferrule{ }{\\Typing{\\Delta}{\\Gamma}{\\Unit}{\\Unit}}{\\rulename{Unit}} \\quad\n    \\inferrule{ \\ell < |t|}{\\Typing{\\Delta}{\\Gamma}{\\ell}{t}}{\\rulename{Literal}} \\quad\n    \\inferrule{ \\TypingS{\\Delta}{\\Gamma}{\\many{e_i}}{\\many{t_i}} \\\\\\\\\n               \\PrimOpType{o} = (\\many{t_i}, t) }\n              {\\Typing{\\Delta}{\\Gamma}{\\GenPrimOp{o}{\\many{e_i}}}{t}}{\\rulename{PrimOp}}\\quad\n    \\inferrule{ \\Typing{\\Delta}{\\Gamma}{e}{t'} \\\\ |t'| \\le |t| }{\\Typing{\\Delta}{\\Gamma}{\\Cast{t}{e}}{t}}{\\rulename{Cast}} \\\\\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\rho \\rightarrow \\tau} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho} }\n              {\\Typing{\\Delta}{\\Gamma}{\\App{e_1}{e_2}}{\\tau}}{\\rulename{App}} \\quad\\!\\!\n    \\inferrule{\\FunTyEnv{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}}\\\\\\\\\n               \\text{for each $i$:}\\ \\Kinding{\\Delta}{\\rho_i}{\\kappa_i}}\n              {\\Typing{\\Delta}{\\Gamma}{\\TyApp{f}{\\many{\\rho_i}}}{\\Subst{(\\tau \\rightarrow \\tau')}{\\many{\\alpha_i}}{\\many{\\rho_i}}}}{\\rulename{Fun}} \\quad\\!\\!\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\VariantTy{\\Cons{A}{\\rho} \\alt \\many{\\Cons{C_i}{\\tau_i}}}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\rho}, \\Gamma_2}{e_2}{\\tau} \\\\\n               \\Typing{\\Delta}{\\ofType{y}{\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}}, \\Gamma_2}{e_3}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Case{e_1}{\\Cons{A}{\\VarN{x}}}{e_2}{y}{e_3}}{\\tau}}{\\rulename{Case}}    \n    \n    \n    \n    \n    \n  \\\\\n  \\end{inductive}\n  \\begin{center}\n    \\begin{tabular}{p{0.625\\textwidth}|p{0.25\\textwidth}}\n      \\begin{inductive0}\n    \\begin{tabular}{c}\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Cons{C}{e}}{\\VariantTy{\\Cons{C}{\\tau}}}}{\\rulename{Cons}} \\quad\\!\\!\\!\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\VariantTy{\\many{\\Cons{B}{\\rho}}}} \\\\\n               \\many{\\Cons{B}{\\rho}} \\subseteq \\many{\\Cons{C}{\\tau}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Promote{\\many{\\Cons{C}{\\tau}}}{e}}{\\VariantTy{\\many{\\Cons{C}{\\tau}}}}}{\\rulename{Prom}} \\quad\\!\\!\\!\n    \\inferrule{\\Typing{\\Delta}{\\Gamma}{e}{\\VariantTy{\\Cons{C}{\\tau}}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Esac{e}}{\\tau}}\n              {\\rulename{Esac}} \\quad\\!\\!\\!\n\\\\\\\\\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n                   \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\rho} \\\\\n                   \\Typing{\\Delta}{\\ofType{x}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n                  {\\Typing{\\Delta}{\\Gamma}{\\Let{x}{e_1}{e_2}}{\\tau}}{\\rulename{Let}} \\quad\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n                   \\Kinding{\\Delta}{\\rho}{\\{\\Escapable\\}}\\\\\\\\\n                   \\Typing{\\Delta}{\\many{\\ofType{v_i}{\\BangF{\\tau_i}}}, \\Gamma_1}{e_1}{\\rho} \\\\\\\\\n                   \\Typing{\\Delta}{\\many{\\ofType{v_i}{\\tau_i}}, \\ofType{x}{\\rho},\\Gamma_2}{e_2}{\\tau}}\n                  {\\Typing{\\Delta}{\\many{\\ofType{v_i}{\\tau_i}}, \\Gamma}{\\LetBang{\\many{v_i}}{x}{e_1}{e_2}}{\\tau}}{\\rulename{Let}!} \\\\\n        \n        \n        \n        \n        \n        \n        \n        \n        \\end{tabular}\n      \\end{inductive0}\n      &\\vspace{-2ex}\n      \\begin{inductive}{\\TypingS{\\Delta}{\\Gamma}{\\many{e}}{\\many{\\tau}}}\n        \\inferrule{\\Weakening{\\Delta}{\\Gamma}{\\emptyset} }\n                  {\\TypingS{\\Delta}{\\Gamma}{\\varepsilon}{\\varepsilon}}{\\rulename{L}_\\varepsilon} \\\\\n        \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\\\\\n                   \\Typing{\\Delta}{\\Gamma_1}{e}{\\tau} \\\\\n                   \\TypingS{\\Delta}{\\Gamma_2}{\\many{e_i}}{\\many{\\tau_i}}}\n                  {\\TypingS{\\Delta}{\\Gamma}{e\\ \\many{e_i}}{ \\tau\\ \\many{\\tau_i} }}{\\rulename{L}_C}\n      \\end{inductive}\n    \\end{tabular}\n  \\end{center}\\vspace{1.5ex}\n  \\begin{inductive0}\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau_i}}}, \\FieldTy{f}{\\rho} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau_j}}}}{m}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau_i}}}, \\FieldTy{f}{\\taken{\\rho}} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau_j}}}}{m}}, \\ofType{y}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Take{x}{f}{y}{e_1}{e_2}}{\\tau}}{\\rulename{Take}_1} \\quad\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               \\Kinding{\\Delta}{\\rho}{\\{\\Shareable\\}} \\\\\\\\\n               m \\neq \\ReadOnly \\\\ \\perhaps{\\tau_k} = \\rho \\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}} \\\\\\\\\n               \\Typing{\\Delta}{\\ofType{x}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau_i}}}}{m}}, \\ofType{y}{\\rho}, \\Gamma_2}{e_2}{\\tau}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\tau}}\n              {\\rulename{Take}_2} \\\\\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau}_i}}, \\FieldTy{f}{\\taken{\\rho}} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau}_j}}}{m}} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Put{e_1}{f}{e_2}}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\tau}_i}}, \\FieldTy{f}{\\rho} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\tau}_j}}}{m}}}{\\rulename{Put}_1} \\quad\n    \\inferrule{\\Contraction{\\Delta}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\\\\n               m \\neq \\ReadOnly \\\\ \\perhaps{\\tau}_k = \\rho\\\\\\\\\n               \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau}_i}}}{m}} \\\\\n               \\Kinding{\\Delta}{\\rho}{\\{\\Discardable\\}} \\\\\n               \\Typing{\\Delta}{\\Gamma_2}{e_2}{\\rho}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Put{e_1}{f$_k$}{e_2}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\perhaps{\\tau}_i}}}{m}}}{\\rulename{Put}_2} \\\\\n    \\inferrule{\\Kinding{\\Delta}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\rho}_i}}, \\FieldTy{f}{\\tau} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\rho}_j}}}{m}}{\\{\\Shareable\\}} \\\\\\\\\n              \\Typing{\\Delta}{\\Gamma_1}{e_1}{\\RecordTy{\\many{\\FieldTy{g$_i$}{\\perhaps{\\rho}_i}}, \\FieldTy{f}{\\tau} ,\\many{\\FieldTy{g$_j$}{\\perhaps{\\rho}_j}}}{m}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\Member{e}{f}}{\\tau}}{\\rulename{Member}} \\quad\n    \\inferrule{\\TypingS{\\Delta}{\\Gamma}{\\many{e_i}}{\\many{\\tau_i}}}\n              {\\Typing{\\Delta}{\\Gamma}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Unboxed}}}\n              {\\rulename{Struct}}\n  \\end{inductive0}\n  \\caption{Typing rules for {\\textsc{Cogent}\\xspace}}\n  \\label{fig:typing}\n\\end{figure*}\n\n\\autoref{fig:typing} shows the typing rules for {\\textsc{Cogent}\\xspace} expressions.\nMany of these are standard for any linear type system. We will\ndiscuss here the rules for $\\LET!$, where we have taken a slightly different approach to established literature, and the rules for the \nextensions we have made to the type system, such as variants and record types.\n\n\\subsubsection{Typing for $\\LET!$}\\label{s:letbang}\n\nOn the expression level, the programmer can use $\\LET!$ expressions, in the style of \\citet{Wadler_90}, to temporarily convert variables of linear types to their\nread-only equivalents, allowing them to be freely shared. In this example, we wish to copy a buffer $b_2$ onto a buffer $b_1$ only when $b_2$ will fit inside\n$b_1$. \n\n", "index": 5, "text": "$$\\begin{array}{l}\n  \\LetBang{ b_1, b_2 }{\\mathit{ok}}{(\\mathsf{size}(b_2) < \\mathsf{size}(b_1))}{ } \\\\\n  \\quad\\If{\\mathit{ok}}{\\mathsf{copy}(b_1, b_2)}{\\ldots}\n  \\end{array}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{l}\\LetBang{b_{1},b_{2}}{\\mathit{ok}}{(\\mathsf{size}(b_{2})&lt;%&#10;\\mathsf{size}(b_{1}))}\\\\&#10;\\quad\\If{\\mathit{ok}}{\\mathsf{copy}(b_{1},b_{2})}{\\ldots}\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\LetBang</mtext></merror><msub><mi>b</mi><mn>1</mn></msub><mo>,</mo><msub><mi>b</mi><mn>2</mn></msub><mi>\ud835\udc5c\ud835\udc58</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\uddcc\ud835\uddc2\ud835\uddd3\ud835\uddbe</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>&lt;</mo><mi>\ud835\uddcc\ud835\uddc2\ud835\uddd3\ud835\uddbe</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\If</mtext></merror><mo>\u2062</mo><mi>\ud835\udc5c\ud835\udc58</mi><mo>\u2062</mo><mi>\ud835\uddbc\ud835\uddc8\ud835\uddc9\ud835\uddd2</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>b</mi><mn>1</mn></msub><mo>,</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\nLet us say we want to extract the field $\\text{b}_1$ from an $\\mathtt{Object}$. If we extract just a single $\\mathtt{Buf}$, we have implicitly discarded the other buffer $\\text{b}_2$.\nBut, we can't return the entire $\\mathtt{Object}$ along with the $\\mathtt{Buf}$, as this would introduce aliasing. Our solution is to return along with the $\\mathtt{Buf}$\n an $\\mathtt{Object}$ where the field $\\text{b}_1$ cannot be extracted again, and reflect this in the field's type, written as $\\text{b}_1 :: \\taken{\\mathtt{Buf}}$. \nThis field extractor, whose general form is $\\Take{x}{f}{y}{e_1}{e_2}$, operates as follows: given a record~$e_1$, it binds the field $f$ of $e_1$ \nto the variable\n$y$, and the new record to the variable $x$ in $e_2$. Unless the type of the field $f$ has kind $\\{\\Shareable\\}$, that field will be marked as unavailable, or \\emph{taken}, in the type of the new record $x$.\n\nConversely, we also introduce a $\\PUT$ operation, which, given a record with a taken field, allows a new value to be supplied in its place. The expression $\\Put{e_1}{f}{e_2}$ returns the\nrecord in $e_1$ where the field $f$ has been replaced with the result of $e_2$. Unless the type of the field $f$ has kind $\\{\\Discardable\\}$, that field must already be taken, to avoid\naccidentally destroying our only reference to a linear resource.\n\nUnboxed records can be created using a simple struct literal $\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}$. We also allow records to be stored on the heap to minimise unnecessary copying,\nas unboxed records are passed by value.  These boxed records are created by invoking an externally-defined C allocator function.\n\nFor these allocation functions, it is often convenient to allocate a record with all fields already taken, to indicate that they are uninitialised. Thus a function for allocating\n\\texttt{Object}-like records might return values of type: $ \\{ \\text{size} :: \\taken{\\mathtt{U32}}, \\text{b}_1 :: \\taken{\\mathtt{Buf}}, \\text{b}_2 :: \\taken{\\mathtt{Buf}} \\}\\ \\Writable$.\n\n\n\nFor any nonlinear record (that is, (1)~read-only boxed records, which cannot have linear fields, as well as~(2)~unboxed records without linear fields)\n we also allow traditional member syntax $\\Member{e}{f}$ for field access. The typing rules for all of these expressions are given in \\autoref{fig:typing}. \n\n\\subsubsection{Type Specialisation} \n\\label{sec:typing:poly}\nAs mentioned earlier, we implement parametric polymorphism by specialising code to avoid paying the performance penalties of other approaches such as\nboxing. This means that polymorphism in our language is restricted to predicative rank-1 quantifiers.\n\nThis allows us to specify dynamic objects, such as our value typing relations (see \\autoref{sec:updvalrel}) and our dynamic semantics (see \\autoref{sec:dynsem}), in\nterms of simple monomorphic types, without type variables. Thus, in order to evaluate a polymorphic program, each type variable must first be instantiated\nto a monomorphic type. We show that typing of the instantiated program follows from the typing of the polymorphic program, if the type instantiation used matches\nthe kinds of the type variables.\n\n\\begin{lemma}[Type specialisation]\n\\label{lemma:spec} \n$\\Typing{\\many{\\ofKind{\\alpha_i}{\\kappa_i}}}{\\Gamma}{e}{\\tau}$\n      implies $\\Typing{\\Delta}\n                      {\\Subst{\\Gamma}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      {\\Subst{e}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      {\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      $ when, for each $i$, $\\Kinding{\\Delta}{\\rho_i}{\\kappa_i}$.\n\\end{lemma}\n\\noindent The above lemma is sufficient to show the monomorphic instantiation case, by setting $\\Delta = \\varepsilon$ (the empty context). This lemma is a\nkey ingredient for the refinement link between polymorphic and monomorphic deep embeddings (See \\autoref{s:mono-correctness}).\n\n\\subsection{Dynamic Semantics}\n\\label{sec:dynsem}\n\\begin{figure}\n  \\boxlabel{Value Semantics}\n  \\begin{grammar}\n    \\text{values} & v & \\Coloneqq & \\ell \\alt \\Unit \\\\ \n                  &   & \\alt      & \\FunVal{x}{e}                     & \\text{(function values)} \\\\\n                  &   & \\alt      & \\AbsFunVal{f}{\\many{\\tau}}        & \\text{(abstract functions)} \\\\\n                  &   & \\alt      & \\Cons{C}{v}                       & \\text{(variant values)} \\\\\n\n                  &   & \\alt      & \\RecordVal{\\many{\\FieldEq{f}{v}}} & \\text{(records)} \\\\\n                  &   & \\alt      & a_v                               & \\text{(abstract values)} \\\\\n    \\text{environments} & V & \\Coloneqq & \\many{\\EnvBind{x}{v}} \\\\\n    \\text{abstract values} & a_v \n  \\end{grammar}\n  \\begin{displaymath}\n   \\begin{array}{lclr}\n    \\AValSem{\\cdot} & : & f \\rightarrow (v \\rightarrow v) & \\text{(abstract function semantics)}\n   \\end{array}\n  \\end{displaymath}\n  \\boxlabel{Update Semantics}\n  \\begin{grammar}\n    \\text{u. sem. values} & u & \\Coloneqq & \\ell \\alt \\Unit \\\\ \n                            &   & \\alt      & \\FunVal{x}{e}                     & \\text{(function values)} \\\\\n                            &   & \\alt      & \\AbsFunVal{f}{\\many{\\tau}}        & \\text{(abstract functions)} \\\\\n                            &   & \\alt      & \\Cons{C}{u}                       & \\text{(variant values)} \\\\\n\n                            &   & \\alt      & \\RecordVal{\\many{\\FieldEq{f}{u}}} & \\text{(records)} \\\\\n                            &   & \\alt      & a_u                               & \\text{(abstract values)} \\\\\n                            &   & \\alt      & p                                 & \\text{(pointers)} \\\\\n    \\text{environments}     & U & \\Coloneqq & \\many{\\EnvBind{x}{u}}\\\\\n    \\text{pointers}         & p & & \\multicolumn{2}{l}{$\\text{sets of pointers}$\\ \\hspace{5ex} $r, w$} \\\\\n    \\text{abstract values}  & a_u & & \n    \\multicolumn{2}{l}{\\text{stores}\\ \\hspace{13ex} \\ensuremath{\\mu : p \\nrightarrow u}}\\\\\n  \\end{grammar}\n  \\begin{displaymath}\n   \\begin{array}{lclr}\n    \\AUpdSem{\\cdot} & : & f \\rightarrow (u \\times \\mu \\rightarrow u \\times \\mu) & \\text{(abstract function semantics)}\n   \\end{array}\n  \\end{displaymath}\n  \\caption{Definitions for Value and Update Semantics}\n  \\label{fig:semdef}\n\\end{figure}\n\\autoref{fig:updvalsem} defines the big-step evaluation rules for the \n\\emph{value} semantics of {\\textsc{Cogent}\\xspace}. The relation\n\\mbox{$\\ValSem{V}{e}{v}$} states that under\nenvironment $V$, the expression $e$ evaluates to a resultant value\n$v$. These values are documented in \\autoref{fig:semdef}. In many\nways, the semantics is entirely typical of a purely functional\nlanguage, albeit with some care to handle abstract function calls\nappropriately. This is intentional, since our goal is to automatically\nproduce a purely functional shallow embedding from this semantics.\n\nAs functions must be defined on the top level, our function values\n$\\FunVal{x}{e}$ consist only of an unevaluated expression, which is\nevaluated when the function is applied. Abstract function values,\nwritten $\\AbsFunVal{f}{\\many{\\tau}}$, are instead passed more\nindirectly, as a pair of the function name and a list of the types\nused to instantiate any type variables.  When an abstract function\nvalue $\\AbsFunVal{f}{\\many{\\tau}}$ is applied, the user-supplied\nsemantics $\\AValSem{f}$ are invoked, which is simply a function from\ninput value to output value.\n\nThe \\emph{update} semantics, by contrast, is much more imperative. The\nsemantic rules can also be found in \\autoref{fig:updvalsem}, with associated\ndefinitions in\n\\autoref{fig:semdef}. This semantics is also an evaluation\nsemantics, written $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$ in the style \nof~\\citet{Pierce_02}. Values in the update semantics may now be \n\\emph{pointers}, written $p$, to values in a mutable store or \\emph{heap} $\\mu$.  \nThis mutable store is modelled as a partial function from a pointer to \nan update semantics value. \n\n\n\n\n\n\nMost of the rules in \\autoref{fig:updvalsem} only differ from the value\nsemantics in that they thread the store~$\\mu$ through the\nevaluation of the program. However, the key differences arise in the\ntreatment of records and of abstract types, which may now be\nrepresented as \\emph{boxed} structures, stored on the heap. In\nparticular, note that the rule $\\rulename{UPut}_2$ destructively\nupdates the heap, instead of creating a new record value, and the\nsemantics of abstract functions $\\AUpdSem{\\cdot}$ may also modify the\nheap.\n\n\\begin{figure*}[t]\n\\small\n  \\begin{inductive}{\\ValSem{V}{e}{v}}\n    \\inferrule{(\\EnvBind{x}{v}) \\in V}{\\ValSem{V}{x}{v}}{{\\textsc{\\scriptsize {VVar}}}} \\quad\\!\n    \\inferrule{ }{\\ValSem{V}{\\Unit}{\\Unit}}{{\\textsc{\\scriptsize {V()}}}} \\quad\\!\n    \\inferrule{\\FunDefn{f} = \\FunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}{x}{e}}\n              {\\ValSem{V}{\\TyApp{f}{\\many{\\tau_i}}}{\\FunVal{x}{\\Subst{e}{\\many{\\alpha_i}}{\\many{\\tau_i}}}}}\n              {{\\textsc{\\scriptsize {VFun}}}_C}\\quad\\!\n    \\inferrule{\\FunDefn{f} = \\AbsFunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}}\n              {\\ValSem{V}{\\TyApp{f}{\\many{\\tau_i}}}{\\AbsFunVal{f}{\\many{\\tau_i}}}}\n              {{\\textsc{\\scriptsize {VFun}}}_A}\\\\\n    \\inferrule{ }{\\ValSem{V}{\\ell}{\\ell}}{{\\textsc{\\scriptsize {VLit}}}} \\quad\\!\\!\\!\\!\n    \\inferrule{ \\ValSem{V}{e}{\\ell}}{\\ValSem{V}{\\Cast{t}{e}}{\\ell}}{{\\textsc{\\scriptsize {VCast}}}} \\quad\\!\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\FunVal{x}{e}} \\\\\\\\ \\ValSem{V}{e_2}{v'} \\quad\\!\\! \\ValSem{(\\EnvBind{x}{v'})}{e}{v}}\n              {\\ValSem{V}{\\App{e_1}{e_2}}{v}}\n              {{\\textsc{\\scriptsize {VApp}}}_C}\\quad\\!\\!\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\AbsFunVal{f}{\\many{\\tau}}} \\\\\\\\ \\ValSem{V}{e_2}{v'} \\quad\\!\\! \\AbsValSem{f}{v'}{v}}\n              {\\ValSem{V}{\\App{e_1}{e_2}}{v} }{{\\textsc{\\scriptsize {VApp}}}_A} \\quad\\!\\!\\!\\!\\!\n    \n    \\inferrule{\\text{for each $i$:}\\ \\ValSem{V}{e_i}{\\ell_i}}{\\ValSem{V}{\\GenPrimOp{o}{\\many{e_i}}}{\\GenPrimOp{o}{\\many{\\ell_i}}}}{{\\textsc{\\scriptsize {VPrimOp}}}}\\\\\n    \\inferrule{\\ValSem{V}{e_1}{v'} \\\\\\\\ \\ValSem{\\EnvBind{x}{v'},V}{e_2}{v}}{\\ValSem{V}{\\Let{x}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VLet}}}}\\quad\n    \\inferrule{\\ValSem{V}{e_1}{v'} \\\\\\\\ \\ValSem{\\EnvBind{x}{v'},V}{e_2}{v}}{\\ValSem{V}{\\LetBang{\\many{y}}{x}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VLet}}}!}\\quad\n    \n    \n    \n    \\inferrule{\\ValSem{V}{e}{v}}{\\ValSem{V}{\\Cons{C}{e}}{\\Cons{C}{v}}}{{\\textsc{\\scriptsize {VCons}}}} \\quad\n    \\inferrule{\\ValSem{V}{e}{\\Cons{C_k}{v}}}{\\ValSem{V}{\\Promote{\\many{\\Cons{C_i}{\\tau_i}}}{e}}{\\Cons{C_k}{v}}}{\\textsc{\\scriptsize {VProm}}}\\\\\n    \\inferrule{\\ValSem{V}{e_1}{\\Cons{C}{v'}} \\\\ \\ValSem{\\EnvBind{x}{v'}, V}{e_2}{v}}{\\ValSem{V}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{v}}{{\\textsc{\\scriptsize {VCase}}}_1} \\quad\n    \\inferrule{\\ValSem{V}{e_1}{\\Cons{B}{v'}} \\\\ \\ConsN{B} \\neq \\ConsN{C} \\\\ \\ValSem{\\EnvBind{x}{(\\Cons{B}{v'})}, V}{e_3}{v}}\n              {\\ValSem{V}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{v}}{{\\textsc{\\scriptsize {VCase}}}_2} \\quad\n    \\inferrule{\\ValSem{V}{e}{\\Cons{C}{v}}}{\\ValSem{V}{\\Esac{e}}{v}}{{\\textsc{\\scriptsize {VEsac}}}} \\\\\n    \\inferrule{\\text{for each $i$:}\\ \\ValSem{V}{e_i}{v_i}}\n              {\\ValSem{V}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}}\n              {{\\textsc{\\scriptsize {VStr}}}} \\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}}\n              {\\ValSem{V}{\\Member{e}{f$_k$}}{v_k}}\n              {{\\textsc{\\scriptsize {VMem}}}} \\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}} \n              \\\\\\\\ \\ValSem{\\EnvBind{x}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}, \\EnvBind{y}{v_k}, V}{e_2}{v} }\n              {\\ValSem{V}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VTake}}}}\\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}} \n              \\quad \\ValSem{V}{e_2}{v'_k}\n              \\\\\\\\ \\text{for each $i \\neq k$:}\\ v'_i = v_i}\n              {\\ValSem{V}{\\Put{e_1}{f$_k$}{e_2}}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v'_i}}}}}{{\\textsc{\\scriptsize {VPut}}}}\n  \\end{inductive}\n\n\\vspace{0.5ex}\n\n  \\begin{inductive}{\\UpdSem{U}{e}{\\mu}{u}{\\mu'}}\n\n    \\inferrule{\\FunDefn{f} = \\FunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}{x}{e}}\n              {\\UpdSem{U}{\\TyApp{f}{\\many{\\tau_i}}}{\\mu}{\\FunVal{x}{\\Subst{e}{\\many{\\alpha_i}}{\\many{\\tau_i}}}}{\\mu}}\n              {{\\textsc{\\scriptsize {UFun}}}_C}\\quad\\!\n    \\inferrule{\\FunDefn{f} = \\AbsFunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}}\n              {\\UpdSem{U}{\\TyApp{f}{\\many{\\tau_i}}}{\\mu}{\\AbsFunVal{f}{\\many{\\tau_i}}}{\\mu}}\n              {{\\textsc{\\scriptsize {UFun}}}_A} \\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{u'}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'},U}{\\mu_1}{e_2}{u}{\\mu_2}}{\\UpdSem{U}{\\Let{x}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {ULet}}}}\\\\\n\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\FunVal{x}{e}}{\\mu_1} \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'}{\\mu_2} \\quad\\!\\! \\UpdSem{(\\EnvBind{x}{u'})}{e}{\\mu_2}{u}{\\mu_3}}\n              {\\UpdSem{U}{\\App{e_1}{e_2}}{\\mu}{u}{\\mu_3}}\n              {{\\textsc{\\scriptsize {UApp}}}_C}\\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\AbsFunVal{f}{\\many{\\tau_i}}}{\\mu_1} \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'}{\\mu_2} \\quad\\!\\! \\AbsUpdSem{f}{u'}{\\mu_2}{u}{\\mu_3}}\n              {\\UpdSem{U}{\\App{e_1}{e_2}}{\\mu}{u}{\\mu_3} }{{\\textsc{\\scriptsize {UApp}}}_A} \\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{u'}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'},U}{\\mu_1}{e_2}{u}{\\mu_2}}{\\UpdSem{U}{\\LetBang{\\many{y}}{x}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {ULet!}}}}\\\\ \n\n\n  \n \n \n\n\n\n   \n  \n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\Cons{C_k}{u}}{\\mu'}}{\\UpdSem{U}{\\Promote{\\many{\\Cons{C_i}{\\tau_i}}}{e}}{\\mu}{\\Cons{C_k}{u}}{\\mu'}}{\\textsc{\\scriptsize {UProm}}}\\quad\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\Cons{C}{u}}{\\mu'}}{\\UpdSem{U}{\\Esac{e}}{\\mu}{u}{\\mu'}}{{\\textsc{\\scriptsize {UEsac}}}} \\quad\\!\\!\n    \\inferrule{\\UpdSemA{U}{\\many{e_i}}{\\mu}{\\many{u_i}}{\\mu'}}\n              {\\UpdSem{U}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu'}}\n              {{\\textsc{\\scriptsize {UStr}}}} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu'}}\n              {\\UpdSem{U}{\\Member{e}{f$_k$}}{\\mu}{u_k}{\\mu'}}\n              {{\\textsc{\\scriptsize {UMem}}}_1} \n              \\\\\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\Cons{C}{u'}}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'}, U}{\\mu_1}{e_2}{u}{\\mu_2}}\n              {\\UpdSem{U}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UCase}}}_1} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\Cons{B}{u'}}{\\mu_1} \\\\ \\ConsN{B} \\neq \\ConsN{C} \\\\\\\\ \\UpdSem{\\EnvBind{x}{(\\Cons{B}{u'})}, U}{e_3}{\\mu_1}{u}{\\mu_2}}\n              {\\UpdSem{U}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UCase}}}_2} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{p}{\\mu'} \\\\\\\\ \\mu'(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}}\n              {\\UpdSem{U}{\\Member{e}{f$_k$}}{\\mu}{u_k}{\\mu'}}\n              {{\\textsc{\\scriptsize {UMem}}}_2}\n    \\end{inductive}\n    \\begin{center}\n\n\n\n\n\n\n\n\n        \\begin{inductive0}\n    \\inferrule{(\\EnvBind{x}{u}) \\in U}{\\UpdSem{U}{x}{\\mu}{u}{\\mu}}{{\\textsc{\\scriptsize {UVar}}}} \\quad\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu_1} \n                \\\\\\\\ \\UpdSem{\\EnvBind{x}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}, \\EnvBind{y}{u_k}, U}{e_2}{\\mu_1}{u}{\\mu_2} }\n                    {\\UpdSem{U}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UTake}}}_1}\\quad\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu_1} \n                \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'_k}{\\mu_2}\n                \\quad \\text{for each $i \\neq k$:}\\ u'_i = u_i}\n                    {\\UpdSem{U}{\\Put{e_1}{f$_k$}{e_2}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u'_i}}}}{\\mu_2}}{{\\textsc{\\scriptsize {UPut}}}_1} \\[1.5em]\n    \\inferrule{ \\UpdSem{U}{e}{\\mu}{\\ell}{\\mu'}}{\\UpdSem{U}{\\Cast{t}{e}}{\\mu}{\\ell}{\\mu'}}{{\\textsc{\\scriptsize {UCast}}}} \\quad\\!\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{p}{\\mu_1} \n                \\\\   \\mu_1(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}\n                \\\\\\\\ \\UpdSem{\\EnvBind{x}{p}, \\EnvBind{y}{u_k}, U}{e_2}{\\mu_1}{u}{\\mu_2} }\n                    {\\UpdSem{U}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UTake}}}_2}\\quad\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{p}{\\mu_1}\n               \\quad \\UpdSem{U}{e_2}{\\mu_1}{u'_k}{\\mu_2}\n               \\\\\\\\  \\mu_2(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}\n               \\\\    \\text{for each $i \\neq k$:}\\ u'_i = u_i}\n                    {\\UpdSem{U}{\\Put{e_1}{f$_k$}{e_2}}{\\mu}{p}{\\mu_2(p \\coloneqq \\RecordVal{\\many{\\FieldEq{f$_i$}{u'_i}}} )}}{{\\textsc{\\scriptsize {UPut}}}_2}\n        \\end{inductive0}\n\n    \\end{center}\n  \\caption{{\\textsc{Cogent}\\xspace} Value and Update Semantics (some straightforward rules omitted for brevity)}\n  \\label{fig:updvalsem}\n\\end{figure*}\n\n\n\\subsubsection{Update-Value Refinement and Type Preservation}\n\\label{sec:updvalrel}\nIn order to show that the update semantics is a refinement of the value semantics, we must exploit the information given to us by {\\textsc{Cogent}\\xspace}'s linear type system. \nA typical refinement approach to relate the two semantics would be to define a correspondence relation between update semantics states and value semantics values, \nand show that an update semantics evaluation implies a corresponding value semantics evaluation. However, such a statement is not true if aliasing exists, as a destructive\nupdate (from, say, $\\PUT$) would result in multiple values being changed in the update semantics but not necessarily in the value semantics. As our type system forbids\naliasing of writable references, we must include this information in our correspondence relation. Written as $u\\ |\\ \\mu : v : \\tau\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w]$, this relation\nstates that the update semantics value $u$ with store $\\mu$ corresponds to the value semantics value $v$, which both have the type $\\tau$. The sets $r$ and $w$ contain\nall pointers accessible from the value $u$ that are read-only and writable respectively. We use this to encode the uniqueness property ensured by linear types as explicit\nnon-aliasing constraints in the rules for the correspondence relation, which are given in \\autoref{fig:valtypref}. Read-only pointers may alias other read-only pointers, but\nwritable pointers do not alias any other pointer, whether read-only or writable. \n\nBecause our correspondence relation includes types, it naturally implies a value typing relation for both value semantics (written $v : \\tau$) and update semantics (written\n$u\\ |\\ \\mu : \\tau\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w]$ ). In fact, the rules for both relations can be derived from the rules in \\autoref{fig:valtypref} simply by\nerasing either the value semantics parts (highlighted like \\HiPurple{this}) or the update semantics parts (highlighted like \\HiBlue{\\text{this}}). \n\nAs we ultimately prove preservation for this correspondence relation across evaluation, this same erasure strategy can be applied to our proofs to produce a type preservation\nproof for either semantics.  \n\n\\paragraph{Formalising uniqueness}\nWith this correspondence relation, we can prove our intuitions about linear types. For example, the following lemma, which shows that we do not discard any unique\nwritable reference via weakening, makes use of the fact that a value is only given a discardable type when it contains no writable pointers.\n\\begin{lemma}[Weakening respects environment typing]$\\ $ \n\n\\noindent If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\Weakening{}{\\Gamma}{\\Gamma'}$ then there exists \\HiBlue{r' \\subseteq r} such that \n$\\VTR{U}{\\mu}{V}{\\Gamma'}{r'}{w}$. \n\\end{lemma}\n\n\\noindent We also prove a similar lemma about our context splitting judgement, which uses the fact that a value is only given a shareable type when it contains no writable pointers to conclude that the two output contexts give access to non-aliasing sets of writable pointers.\n\\begin{lemma}[Splitting respects environment typing]$\\ $\n\n\\noindent If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\Contraction{}{\\Gamma}{\\Gamma_1}{\\Gamma_2}$ then there exists \\HiBlue{r_1, r_2} and \\HiBlue{w_1, w_2} where \\HiBlue{r = r_1 \\cup r_2} and \\HiBlue{w = w_1 \\cup w_2}, such that $\\VTR{U}{\\mu}{V}{\\Gamma_1}{r_1}{w_1}$ and $\\VTR{U}{\\mu}{V}{\\Gamma_2}{r_2}{w_2}$ and \\HiBlue{w_1 \\cap w_2 = \\emptyset}.\n\\end{lemma}\n\n\\noindent In addition, we prove our main intuition about $\\BangF{\\cdot}$, necessary for showing refinement for $\\LET!$ expressions.\n\\begin{lemma}[$\\BangF{\\cdot}$ makes writable read-only]$\\ $\n\n\\noindent If $\\VTR{u}{\\mu}{v}{\\tau}{r}{w}$ then $\\VTR{u}{\\mu}{v}{\\BangF{\\tau}}{r \\cup w}{\\emptyset}$\n\\end{lemma}\n\n\\paragraph{Dealing with mutable state} We define a \\emph{framing} relation which specifies exactly how evaluation may affect the mutable store $\\mu$. Given an input\nset of writable pointers $w_i$, an input store $\\mu_i$, an output set of pointers $w_o$ and an output store $\\mu_o$, the relation, written ${{w_i}\\ |\\ {\\mu_i}\\ \\textbf{frame}\\ {w_o}\\ |\\ {\\mu_o}}$, \nensures three properties for any pointer $p$:\n\\begin{description}\n  \\item[Inertia] If $p \\notin w_i \\cup w_o$, then $\\mu_i(p) = \\mu_o(p)$.\n  \\item[Leak freedom] If $p \\in w_i$ and $p \\notin w_o$, then $\\mu_o(p) = \\bot$.\n  \\item[Fresh allocation] If $p \\notin w_i$ and $p \\in w_o$, then $\\mu_i(p) = \\bot$.\n\\end{description}\nFraming implies that our correspondence relation, for both values and environments, is unaffected by unrelated store updates:\n\n\\begin{lemma}[Unrelated updates] Assume two unrelated pointer sets \\HiBlue{w \\cap w_1 = \\emptyset} and that \\HiBlue{{{w_1}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w_2}\\ |\\ {\\mu'}}}, then\n\n\\begin{itemize}\n\\item If $\\VTR{u}{\\mu}{v}{\\tau}{r}{w}$  \nthen $\\VTR{u}{\\mu'}{v}{\\tau}{r}{w}$ and \\HiBlue{w \\cap w_2 = \\emptyset}.\n\\item If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ \nthen $\\VTR{U}{\\mu'}{V}{\\Gamma}{r}{w}$ and \\HiBlue{w \\cap w_2 = \\emptyset}.\n\\end{itemize}\n\\end{lemma}\n\n\\paragraph{Refinement and preservation}\nWith the above lemmas and definitions, we are able to prove refinement between the value and the update semantics. This of course requires us to assume the same for\nthe semantics given to abstract functions, $\\AValSem{\\cdot}$ and $\\AUpdSem{\\cdot}$.\n\n\\begin{assumption} Let $f$ be an abstract function with type signature $f :: \\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}$, and $\\many{\\rho_i}$ be an\ninstantiation of the type variables $\\many{\\alpha_i}$ such that for each $i$, $\\Kinding{}{\\rho_i}{\\kappa_i}$. Let $\\HiBlue{u}$ and $\\HiPurple{v}$ be update- and value-semantics values such that $\\VTR{u}{\\mu}{v}{\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{r}{w}$. The user-supplied meaning of $f$ in each semantics gives $\\HiPurple{\\AbsValSem{f}{v}{v'}}$ and $\\HiBlue{\\AbsUpdSem{f}{u}{\\mu}{u'}{\\mu'}}$. \nThen, there exists \\HiBlue{r' \\subseteq r} and \\HiBlue{w'} such that $\\VTR{u'}{\\mu'}{v'}{\\Subst{\\tau'}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{r}{w}$ and \\HiBlue{{{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}}.\n\\end{assumption}\n\n\\noindent We first prove that the correspondence relation is preserved when both semantics evaluate from corresponding environments. By erasing one semantics, this becomes\na type preservation theorem for the other. Due to space constraints, we omit the details of the proof in this paper, but the full proof is available in our Isabelle/HOL\nformalisation.\n\\begin{theorem}[Preservation of types and correspondence]$\\ $\n\\label{thm:preservation}\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\HiPurple{\\ValSem{V}{e}{v}}$ and $\\HiBlue{\\UpdSem{U}{e}{\\mu}{u}{\\mu'}}$, \nthen there exists \\HiBlue{r' \\subseteq r} and \\HiBlue{w'} such that $\\VTR{u}{\\mu'}{v}{\\tau}{r'}{w'}$ and \\HiBlue{{{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}}.\n\\end{theorem}\n\n\\noindent In order to prove refinement, we must show that every evaluation on the concrete update semantics has a corresponding evaluation in the abstract value semantics. While \\autoref{thm:preservation} already gets us most of the way there, we still need to prove that the value semantics can evaluate whenever the update semantics does.\n\\begin{lemma}[Upward-propagation of evaluation]$\\ $\n\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$, then there exists a $v$ such that $\\ValSem{V}{e}{v}$\n\\end{lemma}\n\n\\noindent Composing this lemma and \\autoref{thm:preservation}, we can now easily prove our desired refinement statement.\n\\begin{theorem}[Value $\\Rightarrow$ Update refinement]\n\\label{thm:updvalrefinement}\n\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$, then there exists a value $v$ and pointer sets $r' \\subseteq r$ and  $w'$ such that $\\ValSem{V}{e}{v}$, and $\\VTRN{u}{\\mu'}{v}{\\tau}{r'}{w'}$ and ${{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}$.\n\\end{theorem}\n\\begin{figure*}\n  \\small\n  \\begin{inductive}{\\VTR{u}{\\mu}{v}{\\tau}{r}{w}}\n  \\inferrule{ \\ell < |t|}\n            {\\VTR{\\ell}{\\mu}{\\ell}{t}{\\emptyset}{\\emptyset}}\n            {{\\textsc{\\scriptsize {RLit}}}}\\quad\n  \\inferrule{ }{\\VTR{\\Unit}{\\mu}{\\Unit}{\\Unit}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RUnit}}}}\\quad\n  \\inferrule{ \\VTR{u}{\\mu}{v}{\\tau}{r}{w} \\\\ \n              \\Cons{C}{\\tau} \\in \\many{\\Cons{C_i}{\\tau_i}}\n             }{\\VTR{\\Cons{C}{u}}{\\mu}{\\Cons{C}{v}}{\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}}{r}{w}}{{\\textsc{\\scriptsize {RVariant}}}}\\\\\n  \\inferrule{\\Typing{\\emptyset}{\\ofType{x}{\\tau}}{e}{\\rho}}\n            {\\VTR{\\FunVal{x}{e}}{\\mu}{\\FunVal{x}{e}}{\\FunTy{\\tau}{\\rho}}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RFun}}}_C}\\quad\n  \\inferrule{\\AbsFunTyEnv{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}}}\n            {\\VTR{\\AbsFunVal{f}{\\many{\\rho_i}}}{\\mu}{\\AbsFunVal{f}{\\many{\\rho_i}}}{\\Subst{(\\FunTy{\\tau}{\\tau'})}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RFun}}}_A}\\\\\n\n\n\n\n\n  \\inferrule{\\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{w}}\n            {\\VTR{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Unboxed}}{r}{w}}{{\\textsc{\\scriptsize {RRec}}}_U}\\quad\n  \\inferrule{\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Unboxed}}{r}{w}}{\\VTR{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Unboxed}}{r}{w}}{{\\textsc{\\scriptsize {RA}}}_U} \\\\\n  \\inferrule{\\HiBlue{\\mu(p) = \\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}} \\\\\n             \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{w} }\n            {\\VTR{p}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Writable}}{r}{\\{p\\} \\cup w}}{{\\textsc{\\scriptsize {RRec}}}_W}\\quad\n  \\inferrule{\\HiBlue{\\mu(p) = a_u}\\\\\\\\\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Writable}}{r}{w}} \n            {\\VTR{p}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Writable}}{r}{\\{p\\} \\cup w}}{{\\textsc{\\scriptsize {RA}}}_W} \\\\\n  \\inferrule{\\HiBlue{\\mu(p) = \\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}} \\\\\n             \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{\\emptyset} }\n            {\\VTR{p}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\ReadOnly}}{\\{p\\} \\cup r}{\\emptyset}}{{\\textsc{\\scriptsize {RRec}}}_R} \\quad\n  \\inferrule{\\HiBlue{\\mu(p) = a_u}\\\\\\\\\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\ReadOnly}}{r}{\\emptyset}} \n            {\\VTR{p}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\ReadOnly}}{\\{p\\} \\cup r}{\\emptyset}}{{\\textsc{\\scriptsize {RA}}}_R} \n  \\end{inductive}\n  \\begin{sidebyside}\n  \\begin{inductive}{\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{m}}{r}{w}}\n    \\text{(rules for abstract types are user provided)}\n  \\end{inductive}\n  \\begin{inductive}{\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}}\n  \\inferrule{\\text{for each $ \\ofType{x_i}{\\tau_i} \\in \\Gamma$}: \\\\\\\\\n              \\HiBlue{(\\EnvBind{x_i}{u_i}) \\in U} \\\\ \\HiPurple{(\\EnvBind{x_i}{v_i}) \\in V} \\\\\\\\\n              \\VTR{u_i}{\\mu}{v_i}{\\tau_i}{r_i}{w_i} \\\\\\\\\n             \\text{for each $j, k$ where $j \\neq k$:}\\ \n             \\HiBlue{w_j \\cap (r_k \\cup w_k) = \\emptyset}}\n             {\\VTR{U}{\\mu}{V}{\\Gamma}{\\textstyle{\\bigcup}_i r_i}{\\textstyle{\\bigcup}_i w_i}}{{\\textsc{\\scriptsize {REnv}}}}\n  \\end{inductive}\n  & \n  \\vspace{-1em}\n  \\begin{inductive}{\\VTRA{\\many{u}}{\\mu}{\\many{v}}{\\many{\\perhaps{\\tau}}}{r}{w}}\n    \\inferrule{ }{\\VTRA{\\varepsilon}{\\mu}{\\varepsilon}{\\varepsilon}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RL}}}_1} \\[0.4em]\n    \\inferrule{ \\VTR{u}{\\mu}{v}{\\tau}{r}{w}\n            \\\\  \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\perhaps{\\tau_i}}}{r'}{w'}\n            \\\\\\\\ \\HiBlue{w \\cap (r' \\cup w') = \\emptyset} \\\\\n               \\HiBlue{w' \\cap (r \\cup w) = \\emptyset}}\n              {\\VTRA{u\\ \\many{u_i}}{\\mu}{v\\ \\many{v_i}}{\\tau\\ \\many{\\perhaps{\\tau_i}}}{r \\cup r'}{w \\cup w'}}{{\\textsc{\\scriptsize {RL}}}_2} \\[0.4em]\n    \\inferrule{\\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\perhaps{\\tau_i}}}{r'}{w'}}\n              {\\VTRA{u\\ \\many{u_i}}{\\mu}{v\\ \\many{v_i}}{\\taken{\\tau}\\ \\many{\\perhaps{\\tau_i}}}{r'}{w'}}{{\\textsc{\\scriptsize {RL}}}_3} \n  \\end{inductive} \n  \\end{sidebyside}\n\\caption{Value Typing and Refinement.  For value typing rules, erase \\HiBlue{\\text{this}} text for value semantics, and \\HiPurple{this} text for update semantics.}\n\\label{fig:valtypref}\n\\end{figure*}\n\n\n\\section{Verification}\\label{s:verification}\nWith the formal semantics of {\\textsc{Cogent}\\xspace} available, this section describes each of\nthe proof steps that make up the compiler certificate, depicted in\n\\autoref{fig:refinement} in \\autoref{s:overview}.\n\n\\subsection{Top-Level Theorem}\\label{s:toplevel}\nWe start by describing the top-level theorem that forms the program certificate, emitted by the compiler. Recall that for a well-typed\n{\\textsc{Cogent}\\xspace} program, the compiler produces C code, a shallow\nembedding in Isabelle/HOL, and a refinement proof between them.\n\nWe say a C program correctly implements its {\\textsc{Cogent}\\xspace} shallow embedding if the following holds:\n\\begin{inparaenum}[(i)]\n\\item the C program terminates with defined execution; and \n\\item if the initial C state and {\\textsc{Cogent}\\xspace} store are related, and the input values of the\nprograms are related, then their output values are related.\n\\end{inparaenum}\n\nThis means, the compiler correctness theorem states that a \\emph{value\nrelation} is preserved. This relation is concrete and can be inspected.\nIn~\\autoref{sec:updvalrel}, we introduced a value typing relation between\nupdate semantics and value semantics. At each other refinement stage in the\nfollowing sections, we will introduce a further relation between values of\nthe two respective programs. By composing these value relations, we get the\nvalue relation $\\mathcal{V}$ between the result $v_m$ of the C program $p_m$\nand the shallow embedding $s$ by going through the intermediate update\nsemantics value $u$ and value semantics result $v$. Note that the relation\nin~\\autoref{sec:updvalrel} also depends on a {\\textsc{Cogent}\\xspace} store $\\mu$. The C state\nand {\\textsc{Cogent}\\xspace} store are related using the \\emph{state relation} \\srel, defined in\ndetail in \\autoref{s:c-to-deep}.\n\n\nLet $\\lambda e. \\ \\monoexpr \\ \\rename \\ e$ and \n  $\\lambda v. \\ \\monoval \\ \\rename \\ v$ (defined in~\\autoref{s:mono})\n  be two functions\n   that monomorphise expressions and (function) values, respectively,\n   using a rename function \\rename provided by the compiler.\nFurther, let \n   $R$ be a state relation, \n   $s$ a shallow embedding, \n   $e$ a monomorphic deep embedding, \n   $p_m$  a C program, $\\mu$ a {\\textsc{Cogent}\\xspace} store and $\\sigma$ a  C state. \n    Then we define \n$\\correspond$  as follows: \\\\\n     If ($\\exists r\\;w.\\;\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w})$ and $(\\mu, \\sigma) \\in R$, \n     then $p_m$ successfully terminates starting at $\\sigma$; and \n     after executing $p_m$, for any resulting value $v_m$ and state $\\sigma^\\prime$, there exist $\\mu^\\prime$, $u$, and $v$ such that:\n\n", "itemtype": "equation", "pos": 47750, "prevtext": " \nNote that even though $b_1$ and $b_2$ are used multiple times, they are only used once in a linear context. Inside the $\\LET!$ binding, they have been made\ntemporarily nonlinear. Our kind system ensures these read-only, shareable references inside $\\LET!$ bindings cannot ``escape'' into\nthe outside context. For example, the expression $\\LetBang{b}{b'}{b}{\\mathsf{copy}(b, b')}$ would violate the invariants of the linear type system, and ruin the purely\nfunctional abstraction that linear types allow, as both $b$ and $b'$ would refer to the same object, and a destructive update to $b$ would change the shareable $b'$. \n\nWe are able to use the existing kind system to handle these safety checks with\nthe inclusion of the $\\Escapable$ permission, for\n$\\Escapable$scapable, which indicates that the type may be safely returned\nfrom within a $\\LET!$. We ensure, via the typing rules of\n\\autoref{fig:typing}, that the left hand side of the binding ($\\mathit{ok}$ in the example) has the\n$\\Escapable$ permission, which excludes temporarily nonlinear references via\n$\\BangF{\\cdot}$ (see \\autoref{fig:kinding}). Our solution is as powerful as\nOdersky's, but we encode the restrictions in the kind system directly, not as \nside-condition constraints that recursively descend into the structure of\nthe binding's type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Typing for Variants}\\label{s:variants}\nA variant type $\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}$ is a generalised sum type, where each alternative is distinguished by a unique \\emph{data constructor}~$\\ConsN{C_i}$. The order in which the constructors appear in the type is not important.\nOne can create a variant type with a single alternative simply by invoking a constructor, e.g. $\\Cons{Some}{255}$ might be given the type\n$\\VariantTy{\\Cons{Some}{\\PrimType{U8}}}$. The original value of $255$ can be retrieved using the $\\ESAC$ construct. The set of alternatives is enlarged \nby using $\\PROMOTE$ expressions that are automatically inserted by the type-checker of the surface language, which uses subtyping to infer the type of a given\nvariant. A similar trick is used for numeric literals and $\\CAST$. \n\nIn order to pattern match on a variant, we provide a $\\CASE$ construct that attempts to match against one constructor. If the constructor does not match, \nit is \\emph{removed} from the type and the reduced type is provided to the $\\ELSE$ branch. In this way, a traditional multi-way pattern match can be desugared\nby nesting:\n\\begin{displaymath}\n\\begin{array}{@{}lcl@{}}\n \\begin{array}{l}\n   \\CASE\\ x\\ \\OF \\\\\n  \\quad \\Cons{A}{a} \\rightarrow e_a \\\\\n  \\quad \\Cons{B}{b} \\rightarrow e_b \\\\\n  \\quad \\Cons{C}{c} \\rightarrow e_c \n \\end{array}  & \\text{becomes} & \\begin{array}{l}\n   \\CASE\\ x\\ \\OF \\\\\n   \\quad \\Cons{A}{a} \\rightarrow {e_a} \\\\\n   \\quad \\ELSE\\ x' \\rightarrow \\CASE\\ x'\\ \\OF \\\\\n   \\quad\\quad \\Cons{B}{b} \\rightarrow e_b \\\\\n   \\quad\\quad \\ELSE\\ x'' \\rightarrow \\LET\\ c = \\Esac{x''}\\ \\IN\\ e_c\n \\end{array} \n\\end{array}\n\\end{displaymath}\nNote that because the typing rule for $\\ESAC$ only applies when only one alternative remains, our pattern matching is necessarily total.\n\n\\subsubsection{Typing for Records}\n\\label{sec:records}\n\n\n\n\n\n\n\n\nSome care is needed to reconcile record types and linear types.\nAssume that $\\mathtt{Object}$ is a type synonym for an (unboxed) record type containing an integer and two (linear) buffers.\n\n", "index": 7, "text": "$$ \\mathtt{Object} = \\{ \\text{size} :: \\mathtt{U32}, \\text{b}_1 :: \\mathtt{Buf}, \\text{b}_2 :: \\mathtt{Buf} \\}\\ \\Unboxed$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\mathtt{Object}=\\{\\text{size}::\\mathtt{U32},\\text{b}_{1}::\\mathtt{Buf},\\text{b%&#10;}_{2}::\\mathtt{Buf}\\}\\ \\Unboxed\" display=\"block\"><mrow><mi>\ud835\ude7e\ud835\ude8b\ud835\ude93\ud835\ude8e\ud835\ude8c\ud835\ude9d</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mtext>size</mtext><mo>:</mo><mo>:</mo><mi>\ud835\ude84\ud835\udff9\ud835\udff8</mi><mo>,</mo><msub><mtext>b</mtext><mn>1</mn></msub><mo>:</mo><mo>:</mo><mi>\ud835\ude71\ud835\ude9e\ud835\ude8f</mi><mo>,</mo><msub><mtext>b</mtext><mn>2</mn></msub><mo>:</mo><mo>:</mo><mi>\ud835\ude71\ud835\ude9e\ud835\ude8f</mi><mo rspace=\"7.5pt\" stretchy=\"false\">}</mo></mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\Unboxed</mtext></merror></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\n\n\n\n\\begin{theorem}\nGiven a {\\textsc{Cogent}\\xspace} function~$f$ that takes $x$ of type $\\tau$ as input, \nlet~$p_m$ be its generated C code, \n$s$ its shallow embedding, and \n$e$ its deep embedding. \nLet~$v_m$ be an argument of~$p_m$, and~$u$ and $v$ be the update and value semantics arguments, of appropriate type, for~$f$. If $r$ is injective, then\n", "itemtype": "equation", "pos": 80157, "prevtext": "\nLet us say we want to extract the field $\\text{b}_1$ from an $\\mathtt{Object}$. If we extract just a single $\\mathtt{Buf}$, we have implicitly discarded the other buffer $\\text{b}_2$.\nBut, we can't return the entire $\\mathtt{Object}$ along with the $\\mathtt{Buf}$, as this would introduce aliasing. Our solution is to return along with the $\\mathtt{Buf}$\n an $\\mathtt{Object}$ where the field $\\text{b}_1$ cannot be extracted again, and reflect this in the field's type, written as $\\text{b}_1 :: \\taken{\\mathtt{Buf}}$. \nThis field extractor, whose general form is $\\Take{x}{f}{y}{e_1}{e_2}$, operates as follows: given a record~$e_1$, it binds the field $f$ of $e_1$ \nto the variable\n$y$, and the new record to the variable $x$ in $e_2$. Unless the type of the field $f$ has kind $\\{\\Shareable\\}$, that field will be marked as unavailable, or \\emph{taken}, in the type of the new record $x$.\n\nConversely, we also introduce a $\\PUT$ operation, which, given a record with a taken field, allows a new value to be supplied in its place. The expression $\\Put{e_1}{f}{e_2}$ returns the\nrecord in $e_1$ where the field $f$ has been replaced with the result of $e_2$. Unless the type of the field $f$ has kind $\\{\\Discardable\\}$, that field must already be taken, to avoid\naccidentally destroying our only reference to a linear resource.\n\nUnboxed records can be created using a simple struct literal $\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}$. We also allow records to be stored on the heap to minimise unnecessary copying,\nas unboxed records are passed by value.  These boxed records are created by invoking an externally-defined C allocator function.\n\nFor these allocation functions, it is often convenient to allocate a record with all fields already taken, to indicate that they are uninitialised. Thus a function for allocating\n\\texttt{Object}-like records might return values of type: $ \\{ \\text{size} :: \\taken{\\mathtt{U32}}, \\text{b}_1 :: \\taken{\\mathtt{Buf}}, \\text{b}_2 :: \\taken{\\mathtt{Buf}} \\}\\ \\Writable$.\n\n\n\nFor any nonlinear record (that is, (1)~read-only boxed records, which cannot have linear fields, as well as~(2)~unboxed records without linear fields)\n we also allow traditional member syntax $\\Member{e}{f}$ for field access. The typing rules for all of these expressions are given in \\autoref{fig:typing}. \n\n\\subsubsection{Type Specialisation} \n\\label{sec:typing:poly}\nAs mentioned earlier, we implement parametric polymorphism by specialising code to avoid paying the performance penalties of other approaches such as\nboxing. This means that polymorphism in our language is restricted to predicative rank-1 quantifiers.\n\nThis allows us to specify dynamic objects, such as our value typing relations (see \\autoref{sec:updvalrel}) and our dynamic semantics (see \\autoref{sec:dynsem}), in\nterms of simple monomorphic types, without type variables. Thus, in order to evaluate a polymorphic program, each type variable must first be instantiated\nto a monomorphic type. We show that typing of the instantiated program follows from the typing of the polymorphic program, if the type instantiation used matches\nthe kinds of the type variables.\n\n\\begin{lemma}[Type specialisation]\n\\label{lemma:spec} \n$\\Typing{\\many{\\ofKind{\\alpha_i}{\\kappa_i}}}{\\Gamma}{e}{\\tau}$\n      implies $\\Typing{\\Delta}\n                      {\\Subst{\\Gamma}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      {\\Subst{e}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      {\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}\n                      $ when, for each $i$, $\\Kinding{\\Delta}{\\rho_i}{\\kappa_i}$.\n\\end{lemma}\n\\noindent The above lemma is sufficient to show the monomorphic instantiation case, by setting $\\Delta = \\varepsilon$ (the empty context). This lemma is a\nkey ingredient for the refinement link between polymorphic and monomorphic deep embeddings (See \\autoref{s:mono-correctness}).\n\n\\subsection{Dynamic Semantics}\n\\label{sec:dynsem}\n\\begin{figure}\n  \\boxlabel{Value Semantics}\n  \\begin{grammar}\n    \\text{values} & v & \\Coloneqq & \\ell \\alt \\Unit \\\\ \n                  &   & \\alt      & \\FunVal{x}{e}                     & \\text{(function values)} \\\\\n                  &   & \\alt      & \\AbsFunVal{f}{\\many{\\tau}}        & \\text{(abstract functions)} \\\\\n                  &   & \\alt      & \\Cons{C}{v}                       & \\text{(variant values)} \\\\\n\n                  &   & \\alt      & \\RecordVal{\\many{\\FieldEq{f}{v}}} & \\text{(records)} \\\\\n                  &   & \\alt      & a_v                               & \\text{(abstract values)} \\\\\n    \\text{environments} & V & \\Coloneqq & \\many{\\EnvBind{x}{v}} \\\\\n    \\text{abstract values} & a_v \n  \\end{grammar}\n  \\begin{displaymath}\n   \\begin{array}{lclr}\n    \\AValSem{\\cdot} & : & f \\rightarrow (v \\rightarrow v) & \\text{(abstract function semantics)}\n   \\end{array}\n  \\end{displaymath}\n  \\boxlabel{Update Semantics}\n  \\begin{grammar}\n    \\text{u. sem. values} & u & \\Coloneqq & \\ell \\alt \\Unit \\\\ \n                            &   & \\alt      & \\FunVal{x}{e}                     & \\text{(function values)} \\\\\n                            &   & \\alt      & \\AbsFunVal{f}{\\many{\\tau}}        & \\text{(abstract functions)} \\\\\n                            &   & \\alt      & \\Cons{C}{u}                       & \\text{(variant values)} \\\\\n\n                            &   & \\alt      & \\RecordVal{\\many{\\FieldEq{f}{u}}} & \\text{(records)} \\\\\n                            &   & \\alt      & a_u                               & \\text{(abstract values)} \\\\\n                            &   & \\alt      & p                                 & \\text{(pointers)} \\\\\n    \\text{environments}     & U & \\Coloneqq & \\many{\\EnvBind{x}{u}}\\\\\n    \\text{pointers}         & p & & \\multicolumn{2}{l}{$\\text{sets of pointers}$\\ \\hspace{5ex} $r, w$} \\\\\n    \\text{abstract values}  & a_u & & \n    \\multicolumn{2}{l}{\\text{stores}\\ \\hspace{13ex} \\ensuremath{\\mu : p \\nrightarrow u}}\\\\\n  \\end{grammar}\n  \\begin{displaymath}\n   \\begin{array}{lclr}\n    \\AUpdSem{\\cdot} & : & f \\rightarrow (u \\times \\mu \\rightarrow u \\times \\mu) & \\text{(abstract function semantics)}\n   \\end{array}\n  \\end{displaymath}\n  \\caption{Definitions for Value and Update Semantics}\n  \\label{fig:semdef}\n\\end{figure}\n\\autoref{fig:updvalsem} defines the big-step evaluation rules for the \n\\emph{value} semantics of {\\textsc{Cogent}\\xspace}. The relation\n\\mbox{$\\ValSem{V}{e}{v}$} states that under\nenvironment $V$, the expression $e$ evaluates to a resultant value\n$v$. These values are documented in \\autoref{fig:semdef}. In many\nways, the semantics is entirely typical of a purely functional\nlanguage, albeit with some care to handle abstract function calls\nappropriately. This is intentional, since our goal is to automatically\nproduce a purely functional shallow embedding from this semantics.\n\nAs functions must be defined on the top level, our function values\n$\\FunVal{x}{e}$ consist only of an unevaluated expression, which is\nevaluated when the function is applied. Abstract function values,\nwritten $\\AbsFunVal{f}{\\many{\\tau}}$, are instead passed more\nindirectly, as a pair of the function name and a list of the types\nused to instantiate any type variables.  When an abstract function\nvalue $\\AbsFunVal{f}{\\many{\\tau}}$ is applied, the user-supplied\nsemantics $\\AValSem{f}$ are invoked, which is simply a function from\ninput value to output value.\n\nThe \\emph{update} semantics, by contrast, is much more imperative. The\nsemantic rules can also be found in \\autoref{fig:updvalsem}, with associated\ndefinitions in\n\\autoref{fig:semdef}. This semantics is also an evaluation\nsemantics, written $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$ in the style \nof~\\citet{Pierce_02}. Values in the update semantics may now be \n\\emph{pointers}, written $p$, to values in a mutable store or \\emph{heap} $\\mu$.  \nThis mutable store is modelled as a partial function from a pointer to \nan update semantics value. \n\n\n\n\n\n\nMost of the rules in \\autoref{fig:updvalsem} only differ from the value\nsemantics in that they thread the store~$\\mu$ through the\nevaluation of the program. However, the key differences arise in the\ntreatment of records and of abstract types, which may now be\nrepresented as \\emph{boxed} structures, stored on the heap. In\nparticular, note that the rule $\\rulename{UPut}_2$ destructively\nupdates the heap, instead of creating a new record value, and the\nsemantics of abstract functions $\\AUpdSem{\\cdot}$ may also modify the\nheap.\n\n\\begin{figure*}[t]\n\\small\n  \\begin{inductive}{\\ValSem{V}{e}{v}}\n    \\inferrule{(\\EnvBind{x}{v}) \\in V}{\\ValSem{V}{x}{v}}{{\\textsc{\\scriptsize {VVar}}}} \\quad\\!\n    \\inferrule{ }{\\ValSem{V}{\\Unit}{\\Unit}}{{\\textsc{\\scriptsize {V()}}}} \\quad\\!\n    \\inferrule{\\FunDefn{f} = \\FunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}{x}{e}}\n              {\\ValSem{V}{\\TyApp{f}{\\many{\\tau_i}}}{\\FunVal{x}{\\Subst{e}{\\many{\\alpha_i}}{\\many{\\tau_i}}}}}\n              {{\\textsc{\\scriptsize {VFun}}}_C}\\quad\\!\n    \\inferrule{\\FunDefn{f} = \\AbsFunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}}\n              {\\ValSem{V}{\\TyApp{f}{\\many{\\tau_i}}}{\\AbsFunVal{f}{\\many{\\tau_i}}}}\n              {{\\textsc{\\scriptsize {VFun}}}_A}\\\\\n    \\inferrule{ }{\\ValSem{V}{\\ell}{\\ell}}{{\\textsc{\\scriptsize {VLit}}}} \\quad\\!\\!\\!\\!\n    \\inferrule{ \\ValSem{V}{e}{\\ell}}{\\ValSem{V}{\\Cast{t}{e}}{\\ell}}{{\\textsc{\\scriptsize {VCast}}}} \\quad\\!\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\FunVal{x}{e}} \\\\\\\\ \\ValSem{V}{e_2}{v'} \\quad\\!\\! \\ValSem{(\\EnvBind{x}{v'})}{e}{v}}\n              {\\ValSem{V}{\\App{e_1}{e_2}}{v}}\n              {{\\textsc{\\scriptsize {VApp}}}_C}\\quad\\!\\!\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\AbsFunVal{f}{\\many{\\tau}}} \\\\\\\\ \\ValSem{V}{e_2}{v'} \\quad\\!\\! \\AbsValSem{f}{v'}{v}}\n              {\\ValSem{V}{\\App{e_1}{e_2}}{v} }{{\\textsc{\\scriptsize {VApp}}}_A} \\quad\\!\\!\\!\\!\\!\n    \n    \\inferrule{\\text{for each $i$:}\\ \\ValSem{V}{e_i}{\\ell_i}}{\\ValSem{V}{\\GenPrimOp{o}{\\many{e_i}}}{\\GenPrimOp{o}{\\many{\\ell_i}}}}{{\\textsc{\\scriptsize {VPrimOp}}}}\\\\\n    \\inferrule{\\ValSem{V}{e_1}{v'} \\\\\\\\ \\ValSem{\\EnvBind{x}{v'},V}{e_2}{v}}{\\ValSem{V}{\\Let{x}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VLet}}}}\\quad\n    \\inferrule{\\ValSem{V}{e_1}{v'} \\\\\\\\ \\ValSem{\\EnvBind{x}{v'},V}{e_2}{v}}{\\ValSem{V}{\\LetBang{\\many{y}}{x}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VLet}}}!}\\quad\n    \n    \n    \n    \\inferrule{\\ValSem{V}{e}{v}}{\\ValSem{V}{\\Cons{C}{e}}{\\Cons{C}{v}}}{{\\textsc{\\scriptsize {VCons}}}} \\quad\n    \\inferrule{\\ValSem{V}{e}{\\Cons{C_k}{v}}}{\\ValSem{V}{\\Promote{\\many{\\Cons{C_i}{\\tau_i}}}{e}}{\\Cons{C_k}{v}}}{\\textsc{\\scriptsize {VProm}}}\\\\\n    \\inferrule{\\ValSem{V}{e_1}{\\Cons{C}{v'}} \\\\ \\ValSem{\\EnvBind{x}{v'}, V}{e_2}{v}}{\\ValSem{V}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{v}}{{\\textsc{\\scriptsize {VCase}}}_1} \\quad\n    \\inferrule{\\ValSem{V}{e_1}{\\Cons{B}{v'}} \\\\ \\ConsN{B} \\neq \\ConsN{C} \\\\ \\ValSem{\\EnvBind{x}{(\\Cons{B}{v'})}, V}{e_3}{v}}\n              {\\ValSem{V}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{v}}{{\\textsc{\\scriptsize {VCase}}}_2} \\quad\n    \\inferrule{\\ValSem{V}{e}{\\Cons{C}{v}}}{\\ValSem{V}{\\Esac{e}}{v}}{{\\textsc{\\scriptsize {VEsac}}}} \\\\\n    \\inferrule{\\text{for each $i$:}\\ \\ValSem{V}{e_i}{v_i}}\n              {\\ValSem{V}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}}\n              {{\\textsc{\\scriptsize {VStr}}}} \\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}}\n              {\\ValSem{V}{\\Member{e}{f$_k$}}{v_k}}\n              {{\\textsc{\\scriptsize {VMem}}}} \\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}} \n              \\\\\\\\ \\ValSem{\\EnvBind{x}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}, \\EnvBind{y}{v_k}, V}{e_2}{v} }\n              {\\ValSem{V}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{v}}{{\\textsc{\\scriptsize {VTake}}}}\\quad\\!\\!\\!\n    \\inferrule{\\ValSem{V}{e_1}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}} \n              \\quad \\ValSem{V}{e_2}{v'_k}\n              \\\\\\\\ \\text{for each $i \\neq k$:}\\ v'_i = v_i}\n              {\\ValSem{V}{\\Put{e_1}{f$_k$}{e_2}}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v'_i}}}}}{{\\textsc{\\scriptsize {VPut}}}}\n  \\end{inductive}\n\n\\vspace{0.5ex}\n\n  \\begin{inductive}{\\UpdSem{U}{e}{\\mu}{u}{\\mu'}}\n\n    \\inferrule{\\FunDefn{f} = \\FunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}{x}{e}}\n              {\\UpdSem{U}{\\TyApp{f}{\\many{\\tau_i}}}{\\mu}{\\FunVal{x}{\\Subst{e}{\\many{\\alpha_i}}{\\many{\\tau_i}}}}{\\mu}}\n              {{\\textsc{\\scriptsize {UFun}}}_C}\\quad\\!\n    \\inferrule{\\FunDefn{f} = \\AbsFunDef{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\FunTy{\\tau}{\\rho}}}}\n              {\\UpdSem{U}{\\TyApp{f}{\\many{\\tau_i}}}{\\mu}{\\AbsFunVal{f}{\\many{\\tau_i}}}{\\mu}}\n              {{\\textsc{\\scriptsize {UFun}}}_A} \\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{u'}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'},U}{\\mu_1}{e_2}{u}{\\mu_2}}{\\UpdSem{U}{\\Let{x}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {ULet}}}}\\\\\n\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\FunVal{x}{e}}{\\mu_1} \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'}{\\mu_2} \\quad\\!\\! \\UpdSem{(\\EnvBind{x}{u'})}{e}{\\mu_2}{u}{\\mu_3}}\n              {\\UpdSem{U}{\\App{e_1}{e_2}}{\\mu}{u}{\\mu_3}}\n              {{\\textsc{\\scriptsize {UApp}}}_C}\\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\AbsFunVal{f}{\\many{\\tau_i}}}{\\mu_1} \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'}{\\mu_2} \\quad\\!\\! \\AbsUpdSem{f}{u'}{\\mu_2}{u}{\\mu_3}}\n              {\\UpdSem{U}{\\App{e_1}{e_2}}{\\mu}{u}{\\mu_3} }{{\\textsc{\\scriptsize {UApp}}}_A} \\quad\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{u'}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'},U}{\\mu_1}{e_2}{u}{\\mu_2}}{\\UpdSem{U}{\\LetBang{\\many{y}}{x}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {ULet!}}}}\\\\ \n\n\n  \n \n \n\n\n\n   \n  \n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\Cons{C_k}{u}}{\\mu'}}{\\UpdSem{U}{\\Promote{\\many{\\Cons{C_i}{\\tau_i}}}{e}}{\\mu}{\\Cons{C_k}{u}}{\\mu'}}{\\textsc{\\scriptsize {UProm}}}\\quad\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\Cons{C}{u}}{\\mu'}}{\\UpdSem{U}{\\Esac{e}}{\\mu}{u}{\\mu'}}{{\\textsc{\\scriptsize {UEsac}}}} \\quad\\!\\!\n    \\inferrule{\\UpdSemA{U}{\\many{e_i}}{\\mu}{\\many{u_i}}{\\mu'}}\n              {\\UpdSem{U}{\\StructInit{\\many{\\FieldEq{f$_i$}{e_i}}}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu'}}\n              {{\\textsc{\\scriptsize {UStr}}}} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu'}}\n              {\\UpdSem{U}{\\Member{e}{f$_k$}}{\\mu}{u_k}{\\mu'}}\n              {{\\textsc{\\scriptsize {UMem}}}_1} \n              \\\\\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\Cons{C}{u'}}{\\mu_1} \\\\\\\\ \\UpdSem{\\EnvBind{x}{u'}, U}{\\mu_1}{e_2}{u}{\\mu_2}}\n              {\\UpdSem{U}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UCase}}}_1} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\Cons{B}{u'}}{\\mu_1} \\\\ \\ConsN{B} \\neq \\ConsN{C} \\\\\\\\ \\UpdSem{\\EnvBind{x}{(\\Cons{B}{u'})}, U}{e_3}{\\mu_1}{u}{\\mu_2}}\n              {\\UpdSem{U}{\\Case{e_1}{\\Cons{C}{\\VarN{x}}}{e_2}{y}{e_3}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UCase}}}_2} \\quad\\!\\!\\!\n    \\inferrule{\\UpdSem{U}{e}{\\mu}{p}{\\mu'} \\\\\\\\ \\mu'(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}}\n              {\\UpdSem{U}{\\Member{e}{f$_k$}}{\\mu}{u_k}{\\mu'}}\n              {{\\textsc{\\scriptsize {UMem}}}_2}\n    \\end{inductive}\n    \\begin{center}\n\n\n\n\n\n\n\n\n        \\begin{inductive0}\n    \\inferrule{(\\EnvBind{x}{u}) \\in U}{\\UpdSem{U}{x}{\\mu}{u}{\\mu}}{{\\textsc{\\scriptsize {UVar}}}} \\quad\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu_1} \n                \\\\\\\\ \\UpdSem{\\EnvBind{x}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}, \\EnvBind{y}{u_k}, U}{e_2}{\\mu_1}{u}{\\mu_2} }\n                    {\\UpdSem{U}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UTake}}}_1}\\quad\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu_1} \n                \\\\\\\\ \\UpdSem{U}{e_2}{\\mu_1}{u'_k}{\\mu_2}\n                \\quad \\text{for each $i \\neq k$:}\\ u'_i = u_i}\n                    {\\UpdSem{U}{\\Put{e_1}{f$_k$}{e_2}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{u'_i}}}}{\\mu_2}}{{\\textsc{\\scriptsize {UPut}}}_1} \\[1.5em]\n    \\inferrule{ \\UpdSem{U}{e}{\\mu}{\\ell}{\\mu'}}{\\UpdSem{U}{\\Cast{t}{e}}{\\mu}{\\ell}{\\mu'}}{{\\textsc{\\scriptsize {UCast}}}} \\quad\\!\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{p}{\\mu_1} \n                \\\\   \\mu_1(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}\n                \\\\\\\\ \\UpdSem{\\EnvBind{x}{p}, \\EnvBind{y}{u_k}, U}{e_2}{\\mu_1}{u}{\\mu_2} }\n                    {\\UpdSem{U}{\\Take{x}{f$_k$}{y}{e_1}{e_2}}{\\mu}{u}{\\mu_2}}{{\\textsc{\\scriptsize {UTake}}}_2}\\quad\\!\\!\\!\n          \\inferrule{\\UpdSem{U}{e_1}{\\mu}{p}{\\mu_1}\n               \\quad \\UpdSem{U}{e_2}{\\mu_1}{u'_k}{\\mu_2}\n               \\\\\\\\  \\mu_2(p) = {\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}\n               \\\\    \\text{for each $i \\neq k$:}\\ u'_i = u_i}\n                    {\\UpdSem{U}{\\Put{e_1}{f$_k$}{e_2}}{\\mu}{p}{\\mu_2(p \\coloneqq \\RecordVal{\\many{\\FieldEq{f$_i$}{u'_i}}} )}}{{\\textsc{\\scriptsize {UPut}}}_2}\n        \\end{inductive0}\n\n    \\end{center}\n  \\caption{{\\textsc{Cogent}\\xspace} Value and Update Semantics (some straightforward rules omitted for brevity)}\n  \\label{fig:updvalsem}\n\\end{figure*}\n\n\n\\subsubsection{Update-Value Refinement and Type Preservation}\n\\label{sec:updvalrel}\nIn order to show that the update semantics is a refinement of the value semantics, we must exploit the information given to us by {\\textsc{Cogent}\\xspace}'s linear type system. \nA typical refinement approach to relate the two semantics would be to define a correspondence relation between update semantics states and value semantics values, \nand show that an update semantics evaluation implies a corresponding value semantics evaluation. However, such a statement is not true if aliasing exists, as a destructive\nupdate (from, say, $\\PUT$) would result in multiple values being changed in the update semantics but not necessarily in the value semantics. As our type system forbids\naliasing of writable references, we must include this information in our correspondence relation. Written as $u\\ |\\ \\mu : v : \\tau\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w]$, this relation\nstates that the update semantics value $u$ with store $\\mu$ corresponds to the value semantics value $v$, which both have the type $\\tau$. The sets $r$ and $w$ contain\nall pointers accessible from the value $u$ that are read-only and writable respectively. We use this to encode the uniqueness property ensured by linear types as explicit\nnon-aliasing constraints in the rules for the correspondence relation, which are given in \\autoref{fig:valtypref}. Read-only pointers may alias other read-only pointers, but\nwritable pointers do not alias any other pointer, whether read-only or writable. \n\nBecause our correspondence relation includes types, it naturally implies a value typing relation for both value semantics (written $v : \\tau$) and update semantics (written\n$u\\ |\\ \\mu : \\tau\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w]$ ). In fact, the rules for both relations can be derived from the rules in \\autoref{fig:valtypref} simply by\nerasing either the value semantics parts (highlighted like \\HiPurple{this}) or the update semantics parts (highlighted like \\HiBlue{\\text{this}}). \n\nAs we ultimately prove preservation for this correspondence relation across evaluation, this same erasure strategy can be applied to our proofs to produce a type preservation\nproof for either semantics.  \n\n\\paragraph{Formalising uniqueness}\nWith this correspondence relation, we can prove our intuitions about linear types. For example, the following lemma, which shows that we do not discard any unique\nwritable reference via weakening, makes use of the fact that a value is only given a discardable type when it contains no writable pointers.\n\\begin{lemma}[Weakening respects environment typing]$\\ $ \n\n\\noindent If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\Weakening{}{\\Gamma}{\\Gamma'}$ then there exists \\HiBlue{r' \\subseteq r} such that \n$\\VTR{U}{\\mu}{V}{\\Gamma'}{r'}{w}$. \n\\end{lemma}\n\n\\noindent We also prove a similar lemma about our context splitting judgement, which uses the fact that a value is only given a shareable type when it contains no writable pointers to conclude that the two output contexts give access to non-aliasing sets of writable pointers.\n\\begin{lemma}[Splitting respects environment typing]$\\ $\n\n\\noindent If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\Contraction{}{\\Gamma}{\\Gamma_1}{\\Gamma_2}$ then there exists \\HiBlue{r_1, r_2} and \\HiBlue{w_1, w_2} where \\HiBlue{r = r_1 \\cup r_2} and \\HiBlue{w = w_1 \\cup w_2}, such that $\\VTR{U}{\\mu}{V}{\\Gamma_1}{r_1}{w_1}$ and $\\VTR{U}{\\mu}{V}{\\Gamma_2}{r_2}{w_2}$ and \\HiBlue{w_1 \\cap w_2 = \\emptyset}.\n\\end{lemma}\n\n\\noindent In addition, we prove our main intuition about $\\BangF{\\cdot}$, necessary for showing refinement for $\\LET!$ expressions.\n\\begin{lemma}[$\\BangF{\\cdot}$ makes writable read-only]$\\ $\n\n\\noindent If $\\VTR{u}{\\mu}{v}{\\tau}{r}{w}$ then $\\VTR{u}{\\mu}{v}{\\BangF{\\tau}}{r \\cup w}{\\emptyset}$\n\\end{lemma}\n\n\\paragraph{Dealing with mutable state} We define a \\emph{framing} relation which specifies exactly how evaluation may affect the mutable store $\\mu$. Given an input\nset of writable pointers $w_i$, an input store $\\mu_i$, an output set of pointers $w_o$ and an output store $\\mu_o$, the relation, written ${{w_i}\\ |\\ {\\mu_i}\\ \\textbf{frame}\\ {w_o}\\ |\\ {\\mu_o}}$, \nensures three properties for any pointer $p$:\n\\begin{description}\n  \\item[Inertia] If $p \\notin w_i \\cup w_o$, then $\\mu_i(p) = \\mu_o(p)$.\n  \\item[Leak freedom] If $p \\in w_i$ and $p \\notin w_o$, then $\\mu_o(p) = \\bot$.\n  \\item[Fresh allocation] If $p \\notin w_i$ and $p \\in w_o$, then $\\mu_i(p) = \\bot$.\n\\end{description}\nFraming implies that our correspondence relation, for both values and environments, is unaffected by unrelated store updates:\n\n\\begin{lemma}[Unrelated updates] Assume two unrelated pointer sets \\HiBlue{w \\cap w_1 = \\emptyset} and that \\HiBlue{{{w_1}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w_2}\\ |\\ {\\mu'}}}, then\n\n\\begin{itemize}\n\\item If $\\VTR{u}{\\mu}{v}{\\tau}{r}{w}$  \nthen $\\VTR{u}{\\mu'}{v}{\\tau}{r}{w}$ and \\HiBlue{w \\cap w_2 = \\emptyset}.\n\\item If $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ \nthen $\\VTR{U}{\\mu'}{V}{\\Gamma}{r}{w}$ and \\HiBlue{w \\cap w_2 = \\emptyset}.\n\\end{itemize}\n\\end{lemma}\n\n\\paragraph{Refinement and preservation}\nWith the above lemmas and definitions, we are able to prove refinement between the value and the update semantics. This of course requires us to assume the same for\nthe semantics given to abstract functions, $\\AValSem{\\cdot}$ and $\\AUpdSem{\\cdot}$.\n\n\\begin{assumption} Let $f$ be an abstract function with type signature $f :: \\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}$, and $\\many{\\rho_i}$ be an\ninstantiation of the type variables $\\many{\\alpha_i}$ such that for each $i$, $\\Kinding{}{\\rho_i}{\\kappa_i}$. Let $\\HiBlue{u}$ and $\\HiPurple{v}$ be update- and value-semantics values such that $\\VTR{u}{\\mu}{v}{\\Subst{\\tau}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{r}{w}$. The user-supplied meaning of $f$ in each semantics gives $\\HiPurple{\\AbsValSem{f}{v}{v'}}$ and $\\HiBlue{\\AbsUpdSem{f}{u}{\\mu}{u'}{\\mu'}}$. \nThen, there exists \\HiBlue{r' \\subseteq r} and \\HiBlue{w'} such that $\\VTR{u'}{\\mu'}{v'}{\\Subst{\\tau'}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{r}{w}$ and \\HiBlue{{{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}}.\n\\end{assumption}\n\n\\noindent We first prove that the correspondence relation is preserved when both semantics evaluate from corresponding environments. By erasing one semantics, this becomes\na type preservation theorem for the other. Due to space constraints, we omit the details of the proof in this paper, but the full proof is available in our Isabelle/HOL\nformalisation.\n\\begin{theorem}[Preservation of types and correspondence]$\\ $\n\\label{thm:preservation}\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\HiPurple{\\ValSem{V}{e}{v}}$ and $\\HiBlue{\\UpdSem{U}{e}{\\mu}{u}{\\mu'}}$, \nthen there exists \\HiBlue{r' \\subseteq r} and \\HiBlue{w'} such that $\\VTR{u}{\\mu'}{v}{\\tau}{r'}{w'}$ and \\HiBlue{{{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}}.\n\\end{theorem}\n\n\\noindent In order to prove refinement, we must show that every evaluation on the concrete update semantics has a corresponding evaluation in the abstract value semantics. While \\autoref{thm:preservation} already gets us most of the way there, we still need to prove that the value semantics can evaluate whenever the update semantics does.\n\\begin{lemma}[Upward-propagation of evaluation]$\\ $\n\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$, then there exists a $v$ such that $\\ValSem{V}{e}{v}$\n\\end{lemma}\n\n\\noindent Composing this lemma and \\autoref{thm:preservation}, we can now easily prove our desired refinement statement.\n\\begin{theorem}[Value $\\Rightarrow$ Update refinement]\n\\label{thm:updvalrefinement}\n\n\\noindent If $\\Typing{\\varepsilon}{\\Gamma}{e}{\\tau}$ and $\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w}$ and $\\UpdSem{U}{e}{\\mu}{u}{\\mu'}$, then there exists a value $v$ and pointer sets $r' \\subseteq r$ and  $w'$ such that $\\ValSem{V}{e}{v}$, and $\\VTRN{u}{\\mu'}{v}{\\tau}{r'}{w'}$ and ${{w}\\ |\\ {\\mu}\\ \\textbf{frame}\\ {w'}\\ |\\ {\\mu'}}$.\n\\end{theorem}\n\\begin{figure*}\n  \\small\n  \\begin{inductive}{\\VTR{u}{\\mu}{v}{\\tau}{r}{w}}\n  \\inferrule{ \\ell < |t|}\n            {\\VTR{\\ell}{\\mu}{\\ell}{t}{\\emptyset}{\\emptyset}}\n            {{\\textsc{\\scriptsize {RLit}}}}\\quad\n  \\inferrule{ }{\\VTR{\\Unit}{\\mu}{\\Unit}{\\Unit}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RUnit}}}}\\quad\n  \\inferrule{ \\VTR{u}{\\mu}{v}{\\tau}{r}{w} \\\\ \n              \\Cons{C}{\\tau} \\in \\many{\\Cons{C_i}{\\tau_i}}\n             }{\\VTR{\\Cons{C}{u}}{\\mu}{\\Cons{C}{v}}{\\VariantTy{\\many{\\Cons{C_i}{\\tau_i}}}}{r}{w}}{{\\textsc{\\scriptsize {RVariant}}}}\\\\\n  \\inferrule{\\Typing{\\emptyset}{\\ofType{x}{\\tau}}{e}{\\rho}}\n            {\\VTR{\\FunVal{x}{e}}{\\mu}{\\FunVal{x}{e}}{\\FunTy{\\tau}{\\rho}}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RFun}}}_C}\\quad\n  \\inferrule{\\AbsFunTyEnv{f}{\\PolyTy{\\many{\\OfKind{\\alpha_i}{\\kappa_i}}}{\\tau \\rightarrow \\tau'}}}\n            {\\VTR{\\AbsFunVal{f}{\\many{\\rho_i}}}{\\mu}{\\AbsFunVal{f}{\\many{\\rho_i}}}{\\Subst{(\\FunTy{\\tau}{\\tau'})}{\\many{\\alpha_i}}{\\many{\\rho_i}}}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RFun}}}_A}\\\\\n\n\n\n\n\n  \\inferrule{\\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{w}}\n            {\\VTR{\\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Unboxed}}{r}{w}}{{\\textsc{\\scriptsize {RRec}}}_U}\\quad\n  \\inferrule{\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Unboxed}}{r}{w}}{\\VTR{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Unboxed}}{r}{w}}{{\\textsc{\\scriptsize {RA}}}_U} \\\\\n  \\inferrule{\\HiBlue{\\mu(p) = \\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}} \\\\\n             \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{w} }\n            {\\VTR{p}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\Writable}}{r}{\\{p\\} \\cup w}}{{\\textsc{\\scriptsize {RRec}}}_W}\\quad\n  \\inferrule{\\HiBlue{\\mu(p) = a_u}\\\\\\\\\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Writable}}{r}{w}} \n            {\\VTR{p}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\Writable}}{r}{\\{p\\} \\cup w}}{{\\textsc{\\scriptsize {RA}}}_W} \\\\\n  \\inferrule{\\HiBlue{\\mu(p) = \\RecordVal{\\many{\\FieldEq{f$_i$}{u_i}}}} \\\\\n             \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\tau_i}}{r}{\\emptyset} }\n            {\\VTR{p}{\\mu}{\\RecordVal{\\many{\\FieldEq{f$_i$}{v_i}}}}{\\RecordTy{\\many{\\FieldTy{f$_i$}{\\tau_i}}}{\\ReadOnly}}{\\{p\\} \\cup r}{\\emptyset}}{{\\textsc{\\scriptsize {RRec}}}_R} \\quad\n  \\inferrule{\\HiBlue{\\mu(p) = a_u}\\\\\\\\\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\ReadOnly}}{r}{\\emptyset}} \n            {\\VTR{p}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{\\ReadOnly}}{\\{p\\} \\cup r}{\\emptyset}}{{\\textsc{\\scriptsize {RA}}}_R} \n  \\end{inductive}\n  \\begin{sidebyside}\n  \\begin{inductive}{\\VTRAbs{a_u}{\\mu}{a_v}{\\AbsTy{T}{\\many{\\tau}}{m}}{r}{w}}\n    \\text{(rules for abstract types are user provided)}\n  \\end{inductive}\n  \\begin{inductive}{\\VTR{U}{\\mu}{V}{\\Gamma}{r}{w}}\n  \\inferrule{\\text{for each $ \\ofType{x_i}{\\tau_i} \\in \\Gamma$}: \\\\\\\\\n              \\HiBlue{(\\EnvBind{x_i}{u_i}) \\in U} \\\\ \\HiPurple{(\\EnvBind{x_i}{v_i}) \\in V} \\\\\\\\\n              \\VTR{u_i}{\\mu}{v_i}{\\tau_i}{r_i}{w_i} \\\\\\\\\n             \\text{for each $j, k$ where $j \\neq k$:}\\ \n             \\HiBlue{w_j \\cap (r_k \\cup w_k) = \\emptyset}}\n             {\\VTR{U}{\\mu}{V}{\\Gamma}{\\textstyle{\\bigcup}_i r_i}{\\textstyle{\\bigcup}_i w_i}}{{\\textsc{\\scriptsize {REnv}}}}\n  \\end{inductive}\n  & \n  \\vspace{-1em}\n  \\begin{inductive}{\\VTRA{\\many{u}}{\\mu}{\\many{v}}{\\many{\\perhaps{\\tau}}}{r}{w}}\n    \\inferrule{ }{\\VTRA{\\varepsilon}{\\mu}{\\varepsilon}{\\varepsilon}{\\emptyset}{\\emptyset}}{{\\textsc{\\scriptsize {RL}}}_1} \\[0.4em]\n    \\inferrule{ \\VTR{u}{\\mu}{v}{\\tau}{r}{w}\n            \\\\  \\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\perhaps{\\tau_i}}}{r'}{w'}\n            \\\\\\\\ \\HiBlue{w \\cap (r' \\cup w') = \\emptyset} \\\\\n               \\HiBlue{w' \\cap (r \\cup w) = \\emptyset}}\n              {\\VTRA{u\\ \\many{u_i}}{\\mu}{v\\ \\many{v_i}}{\\tau\\ \\many{\\perhaps{\\tau_i}}}{r \\cup r'}{w \\cup w'}}{{\\textsc{\\scriptsize {RL}}}_2} \\[0.4em]\n    \\inferrule{\\VTRA{\\many{u_i}}{\\mu}{\\many{v_i}}{\\many{\\perhaps{\\tau_i}}}{r'}{w'}}\n              {\\VTRA{u\\ \\many{u_i}}{\\mu}{v\\ \\many{v_i}}{\\taken{\\tau}\\ \\many{\\perhaps{\\tau_i}}}{r'}{w'}}{{\\textsc{\\scriptsize {RL}}}_3} \n  \\end{inductive} \n  \\end{sidebyside}\n\\caption{Value Typing and Refinement.  For value typing rules, erase \\HiBlue{\\text{this}} text for value semantics, and \\HiPurple{this} text for update semantics.}\n\\label{fig:valtypref}\n\\end{figure*}\n\n\n\\section{Verification}\\label{s:verification}\nWith the formal semantics of {\\textsc{Cogent}\\xspace} available, this section describes each of\nthe proof steps that make up the compiler certificate, depicted in\n\\autoref{fig:refinement} in \\autoref{s:overview}.\n\n\\subsection{Top-Level Theorem}\\label{s:toplevel}\nWe start by describing the top-level theorem that forms the program certificate, emitted by the compiler. Recall that for a well-typed\n{\\textsc{Cogent}\\xspace} program, the compiler produces C code, a shallow\nembedding in Isabelle/HOL, and a refinement proof between them.\n\nWe say a C program correctly implements its {\\textsc{Cogent}\\xspace} shallow embedding if the following holds:\n\\begin{inparaenum}[(i)]\n\\item the C program terminates with defined execution; and \n\\item if the initial C state and {\\textsc{Cogent}\\xspace} store are related, and the input values of the\nprograms are related, then their output values are related.\n\\end{inparaenum}\n\nThis means, the compiler correctness theorem states that a \\emph{value\nrelation} is preserved. This relation is concrete and can be inspected.\nIn~\\autoref{sec:updvalrel}, we introduced a value typing relation between\nupdate semantics and value semantics. At each other refinement stage in the\nfollowing sections, we will introduce a further relation between values of\nthe two respective programs. By composing these value relations, we get the\nvalue relation $\\mathcal{V}$ between the result $v_m$ of the C program $p_m$\nand the shallow embedding $s$ by going through the intermediate update\nsemantics value $u$ and value semantics result $v$. Note that the relation\nin~\\autoref{sec:updvalrel} also depends on a {\\textsc{Cogent}\\xspace} store $\\mu$. The C state\nand {\\textsc{Cogent}\\xspace} store are related using the \\emph{state relation} \\srel, defined in\ndetail in \\autoref{s:c-to-deep}.\n\n\nLet $\\lambda e. \\ \\monoexpr \\ \\rename \\ e$ and \n  $\\lambda v. \\ \\monoval \\ \\rename \\ v$ (defined in~\\autoref{s:mono})\n  be two functions\n   that monomorphise expressions and (function) values, respectively,\n   using a rename function \\rename provided by the compiler.\nFurther, let \n   $R$ be a state relation, \n   $s$ a shallow embedding, \n   $e$ a monomorphic deep embedding, \n   $p_m$  a C program, $\\mu$ a {\\textsc{Cogent}\\xspace} store and $\\sigma$ a  C state. \n    Then we define \n$\\correspond$  as follows: \\\\\n     If ($\\exists r\\;w.\\;\\VTRN{U}{\\mu}{V}{\\Gamma}{r}{w})$ and $(\\mu, \\sigma) \\in R$, \n     then $p_m$ successfully terminates starting at $\\sigma$; and \n     after executing $p_m$, for any resulting value $v_m$ and state $\\sigma^\\prime$, there exist $\\mu^\\prime$, $u$, and $v$ such that:\n\n", "index": 9, "text": "$$(\\mu^\\prime, \\sigma^\\prime) \\in \\srel \\ \\wedge \n    \\UpdSem{U}{e}{\\mu}{u}{\\mu^\\prime}\\wedge \\\n    \\ValSem{V}{e}{\\monoval \\ \\rename \\ v} \\wedge \\\n       \\mathcal{V} \\  r \\ \\mu^\\prime \\ v_m\\ u\\ v \\ s $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"(\\mu^{\\prime},\\sigma^{\\prime})\\in\\srel\\ \\wedge\\UpdSem{U}{e}{\\mu}{u}{\\mu^{%&#10;\\prime}}\\wedge\\ \\ValSem{V}{e}{\\monoval\\ \\rename\\ v}\\wedge\\ \\mathcal{V}\\ r\\ \\mu%&#10;^{\\prime}\\ v_{m}\\ u\\ v\\ s\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03bc</mi><mo>\u2032</mo></msup><mo>,</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\srel</mtext></merror><mo>\u2227</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\UpdSem</mtext></merror><mo>\u2062</mo><mi>U</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>\u03bc</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><msup><mi>\u03bc</mi><mo>\u2032</mo></msup></mrow><mo>\u2227</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\ValSem</mtext></merror><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\monoval</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mo>\u2062</mo><mi>v</mi></mrow><mo>\u2227</mo><mrow><mpadded width=\"+5pt\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb1</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msup><mi>\u03bc</mi><mo>\u2032</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>v</mi><mi>m</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>u</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>v</mi></mpadded><mo>\u2062</mo><mi>s</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\text {where  $U = (x \\mapsto u)$, $V= (x \\mapsto \\ v)$, and $\\Gamma = (x \\mapsto \\tau)$.}\n\\end{theorem}\n\n\\noindent\nThis top-level refinement theorem additionally assumes that abstract functions\nin the program adhere to their specification and that their behaviour\nremains the same when they are monomorphised.\n\nIntuitively, this theorem states that for related input values, all programs in the refinement chain evaluate to related output values. This can of course be used to deduce that there exist intermediate programs through which the C code and its shallow embedding are directly related. The proof engineer does not need to care what those intermediate programs are. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Well-typedness}\\label{s:typetree}\n\nBefore we present each refinement step, we briefly describe the well-typing\ntheorems that are used in these steps.\n\nThe {\\textsc{Cogent}\\xspace} compiler proves, via an automated Isabelle/HOL tactic, that the\nmonomorphic deep embedding of the input program is well-typed. Specifically,\nthe compiler defines $\\FunDefn{\\cdot}$ in Isabelle/HOL and proves that each\n{\\textsc{Cogent}\\xspace} function~$f\\ \\VarN{x} = e$ is well-typed in accordance with its type as\ngiven by $\\FunDefn{\\cdot}$. Polymorphic well-typing is derived generically in\nthe monomorphisation proof in \\autoref{s:mono-correctness}.\n\n\\begin{theorem}[Typing]\nLet~$f$ be a (monomorphic) {\\textsc{Cogent}\\xspace} function, where \\mbox{$\\FunDefn{f} = \\FunDef{f}{\\FunTy{\\tau}{\\tau'}}{x}{e}$}.\nThen $\\Typing{\\varepsilon}{x : \\tau}{e}{\\tau'}$.\n\\end{theorem}\n\n\\noindent Because, as we will see in \\autoref{s:c-to-deep}, proving\nrefinement requires access to the typing judgements for program\nsub-expressions and not just for the top level, the {\\textsc{Cogent}\\xspace} compiler also\ninstructs Isabelle to store all of the intermediate typing judgements\nestablished during type checking. These theorems are stored in a tree\nstructure, isomorphic to the type derivation tree for the {\\textsc{Cogent}\\xspace} program. Each\nnode is a typing theorem for a sub-expression of the program.\n\n\\subsection{From C to {\\textsc{Cogent}\\xspace} Monomorphic Deep Embedding}\\label{s:c-to-deep}\n\nThis section describes the first three transformations from\n\\autoref{fig:refinement} in \\autoref{s:overview}. In the first step, the C\ncode is converted to Simpl~\\citep{schirmer:phd} by the C-to-Isabelle\nparser~\\citep{Tuch_KN_07}, used in the seL4\nproject~\\citep{Klein_EHACDEEKNSTW_09}. This step is kept as simple as\npossible and makes no effort to abstract from the details of C.\n\n\n\n\n\nThe second step in \\autoref{fig:refinement}, which is the first link in the formal refinement chain, applies a modified version of the AutoCorres tool to produce a \\emph{monadic} shallow embedding of the C code\nsemantics, and additionally proves that the Simpl C semantics is\na refinement of the monadic shallow embedding. We modify AutoCorres to make\nits output more predictable by switching off its control-flow\nsimplification and forcing it to always output the shallow embedding in\nthe \\emph{nondeterministic state monad} of~\\citet{Cock_KS_08}.\nIn this monad, computation is represented by functions of type\n${\\mathit{state}} \\Rightarrow (\\alpha \\mathrel{\\times} {\\mathit{state}}) \\;\\set \\mathrel{\\times} \\bool$. Here\n${\\mathit{state}}$ is the global state of the C program, including\nglobal variables, while $\\alpha$ is the return-type of the computation.\nA computation takes as input the global state and returns a set, \\results, of pairs with new state and result value. Additionally the computation\nreturns a boolean, \\failed, indicating whether it failed (e.g. whether there was undefined behaviour). \n\nWhile AutoCorres was designed to facilitate manual reasoning about C code,\nhere we use it as the foundation for automatically proving correspondence to\nthe {\\textsc{Cogent}\\xspace} input program. One of the main benefits AutoCorres gives us is a\n\\emph{typed} memory model. Specifically, the ${\\mathit{state}}$ of the AutoCorres monadic\nrepresentation contains a set of \\emph{typed heaps}, each of type~$\\mathsf{32}\\  {\\mathsf{word}} \\Rightarrow \\alpha$, \none for each type~$\\alpha$ used on the heap in the C input program. \n\nProving that the\nAutoCorres-generated monadic embedding never fails implies that the C\ncode is type- and memory-safe, and is free of undefined behaviour~\\citep{Greenaway_LAK_14}. We prove\nnon-failure as a side-condition of the refinement statement from the\nAutoCorres shallow embedding to the {\\textsc{Cogent}\\xspace} monomorphic deep embedding in its\nupdate semantics, essentially using {\\textsc{Cogent}\\xspace}'s type system to guarantee C memory\nsafety during execution.\n\n\n\n\nThis refinement proof is the third step in \\autoref{fig:refinement}.\nTo phrase the refinement statement we first define how deeply-embedded \n{\\textsc{Cogent}\\xspace} values and types relate to their corresponding monadic shallowly-embedded C values.\nThe value-mapping is captured by\nthe \\emph{value relation}~$\\valrel$, defined in Isabelle/HOL automatically\nby the\n{\\textsc{Cogent}\\xspace} compiler using ad hoc\noverloading. $\\valrel$ is defined separately for each {\\textsc{Cogent}\\xspace} program because the\ntypes used in the shallow C embedding depend on those used in\nthe C program as, e.g., C structs are represented directly as\nIsabelle/HOL records. \n\n\n\n\n\n\n\nThe type relation $\\typerel$ is used to determine, for a {\\textsc{Cogent}\\xspace} value~$v$ of\ntype $\\tau$, which typed heap in the state of the monadic shallow \nembedding~$v$ should appear in. As with $\\valrel$ it is defined automatically\nfor each {\\textsc{Cogent}\\xspace} program.\n\nGiven $\\valrel$ and~$\\typerel$ for a particular {\\textsc{Cogent}\\xspace} program, the\n\\emph{state relation}~$\\srel$ defines the correspondence between the store~$\\mu$\nover which the {\\textsc{Cogent}\\xspace} update semantics operates, \nand the state~$\\sigma$ of the monadic shallow embedding. \n\n\\begin{definition}[Monad-to-Update State Relation]\n$(\\mu,\\sigma) \\in \\srel$ if and only if: for all pointers~$p$\nin the domain of $\\mu$, there exists a\nvalue~$v$ in the appropriate heap of~$\\sigma$ (as defined by $\\typerel$) at\nlocation~$p$, such that $\\valrel\\  \\mu(p)\\  v$ holds.\n\\end{definition}\n\n\\noindent \nWith $\\srel$ and $\\valrel$,\nwe define refinement generically between \na monadic computation~$p_m$\nand a {\\textsc{Cogent}\\xspace} expression~$e$, evaluated under the update semantics. \nWe denote the \nrefinement predicate \\corres.\nBecause $\\srel$ changes for each {\\textsc{Cogent}\\xspace} program, we parameterise\n\\corres by an arbitrary state relation~$R$. It is parameterised also by \nthe typing context~$\\Gamma$ and the environment~$U$, \nas well as by the initial update semantics store~$\\mu$ and monadic shallow embedding\nstate~$\\sigma$.\n\n\\begin{definition}{Monad-to-Update Correspondence}\n", "itemtype": "equation", "pos": 80711, "prevtext": "\n\n\n\n\n\\begin{theorem}\nGiven a {\\textsc{Cogent}\\xspace} function~$f$ that takes $x$ of type $\\tau$ as input, \nlet~$p_m$ be its generated C code, \n$s$ its shallow embedding, and \n$e$ its deep embedding. \nLet~$v_m$ be an argument of~$p_m$, and~$u$ and $v$ be the update and value semantics arguments, of appropriate type, for~$f$. If $r$ is injective, then\n", "index": 11, "text": "\n\\[\n\\begin{array}{l}\n    \\forall \\mu\\ \\sigma.\\ \\mathcal{V} \\ \\rename \\ \\mu  \\ v_m\\ u\\ v \\ s \\  \\longrightarrow \\\\\n   \\quad\\quad\\correspond \\ \\rename \\ \\srel\n     \\  (s \\; v_s) \\ (\\monoexpr \\ \\rename \\ e) \\ (p_m v_m)\\ \n       U\\  V\\  \\Gamma \\ \\mu \\ \\sigma\n\\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{l}\\forall\\mu\\ \\sigma.\\ \\mathcal{V}\\ \\rename\\ \\mu\\ v_{m}\\ u\\ v%&#10;\\ s\\ \\longrightarrow\\\\&#10;\\quad\\quad\\correspond\\ \\rename\\ \\srel\\ (s\\;v_{s})\\ (\\monoexpr\\ \\rename\\ e)\\ (p%&#10;_{m}v_{m})\\ U\\ V\\ \\Gamma\\ \\mu\\ \\sigma\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>\u2200</mo><mrow><mpadded width=\"+5pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mi>\u03c3</mi></mrow></mrow><mo rspace=\"7.5pt\">.</mo><mrow><mrow><mpadded width=\"+5pt\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb1</mi></mpadded><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>v</mi><mi>m</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>u</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>v</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>s</mi></mpadded></mrow><mo>\u27f6</mo><mi/></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\correspond</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\srel</mtext></merror><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mpadded width=\"+2.8pt\"><mi>s</mi></mpadded><mo>\u2062</mo><msub><mi>v</mi><mi>s</mi></msub></mrow><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\monoexpr</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mo>\u2062</mo><mi>e</mi></mrow><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>p</mi><mi>m</mi></msub><mo>\u2062</mo><msub><mi>v</mi><mi>m</mi></msub></mrow><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>U</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>V</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi mathvariant=\"normal\">\u0393</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mi>\u03c3</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\end{definition}\n\n\\noindent\n\n\n\nThe definition states that if the state relation~$R$ holds initially,\nthen the monadic computation~$p_m$ cannot fail and, moreover,\nfor all executions of~$p_m$ there must exist\na corresponding execution under the update semantics of the expression~$e$\nsuch that the final states are related by~$R$ and $\\valrel$ holds between\ntheir results.\nAutoCorres proves automatically that: $\\neg \\ \\failed \\ (p_m\\  \\sigma) \\longrightarrow \\results \\ (p_m\\ \\sigma) \\neq \\emptyset$.\n\n\\paragraph{Refinement Proof}\nThe refinement proof is automatic in Isabelle, driven by a set of syntax-directed\n\\corres rules, one for each {\\textsc{Cogent}\\xspace} construct. The proof procedure makes use\nof the fact that the {\\textsc{Cogent}\\xspace} term is in A-normal form to reduce the number of\ncases that need to be considered and to simplify the higher-order unification\nproblems that some of the proof rules pose to Isabelle. \n\nThis refinement theorem does not need an explicit formal assumption of\nwell-typedness of the {\\textsc{Cogent}\\xspace} program. The proof tactic will simply fail for\nprograms that are not well-typed.\n\n\\autoref{fig:corres-rules} depicts two \\corres rules, one for expressions~$x$\nthat are variables and the other for~$\\Let{x}{a}{b}$.\nThese correspond respectively to the two basic monadic operations~\\mreturn,\nwhich yields values, and $>>=$, for sequencing computations.\n\n\n\nObserve that the rule \\textsc{Corres-Let} is \\emph{compositional}: to prove\nthat $\\Let{x}{a}{b}$ corresponds to $a' >>= b'$ the rule involves proving\nthat (1)~$a$ corresponds to $a'$ and (2)~that~$b$ corresponds to~$b'$ when each are\nexecuted over corresponding results~$v_u$ and~$v_m$ (e.g. as yielded by\n$a$ and $a'$ respectively). This compositionality significantly simplifies the automation of the correspondence proof.\nThe typing assumptions of \\textsc{Corres-Let} are discharged by appealing to the type theorem tree generated by the compiler (see \\autoref{s:typetree}). \n\n \\begin{figure} \n  \\begin{tabular}{c} \n  \\inferrule{ (\\EnvBind{x}{u}) \\in U  \\\\ \\valrel\\ u \\ v_m}\n            {\\corresargs{x}{(\\mreturn \\  v_m)}}\\; {\\textsc{\\scriptsize {Corres-Var}}}\\\\ \\\\ \n\n  \\inferrule{\\Contraction{}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\quad \n             \\Typing{\\varepsilon}{\\Gamma_1}{a}{\\tau} \\quad\n             \\corresargsE{a}{a'}{U}{\\Gamma_1} \\\\\n             (\\forall v_u \\ v_m\\ \\mu^\\prime\\ \\sigma^\\prime.\\ \\valrel\\ v_u v_m \n              \\longrightarrow \\\\ \n              \\quad\\quad \\corres \\ R \\ {b}\\ (b' \\; v_m)\\\n                                 (x \\mapsto v_u,U) \\ \n                                 (x : \\tau,\\Gamma_2) \\ {\\mu^\\prime}\n                                 \\sigma^\\prime\n             )} \n            {\\corresargs{(\\Let{x}{a}{b})}{(a' >>= b')}} \\!{\\textsc{\\scriptsize {Corres-Let}}} \\\\ \n  \\end{tabular} \\caption{Two example \\corres rules}\n  \\label{fig:corres-rules}\n\\end{figure}\n\nThe rules for some of the other constructs, such as $\\TAKE$, $\\PUT$, and $\\mathbf{case}$, \ncontain non-trivial assumptions about \\srel and about the types used \nin the program. Once a  program and its \\srel are fixed, \na set of simpler \nrules is automatically generated by \\emph{specialising} the generic \\corres\nrules for each of these constructs to the particular \\srel and types used in the\ninput program. This in effect discharges the non-trivial assumptions of these\nrules once-and-for-all, allowing the automated proof of correspondence to \nproceed efficiently.\n\nConceptually, the refinement proof proceeds bottom-up, starting with the leaf functions of\nthe program and ending with the top-level entry points;  \\corres results\nproved earlier are used to discharge \\corres assumptions for callees.\nThe \\corres proof tactic thus follows\nthe call-graph of the input program. Currently, the tactic is limited to\ncomputing call graphs correctly only for programs containing up to second-order\nfunctions. We did not need higher orders in our applications yet, but\nthe tactic can certainly be extended if needed.\n\nThe resulting refinement theorem at this stage assumes that \\corres holds for \nall the abstract functions used in the \n program.\n\\begin{theorem}\nLet~$f$ be a (monomorphic) {\\textsc{Cogent}\\xspace} function, such that $\\FunDefn{f} = \\FunDef{f}{\\tau \\rightarrow \\tau'}{x}{e}$. Let~$p_m$ be its monadic shallow embedding, as\nderived from its generated C code. Let~$u$ and $v_m$ be arguments of\nappropriate type for~$f$ and $p_m$ respectively. Then:\n", "itemtype": "equation", "pos": 87805, "prevtext": "\n\\text {where  $U = (x \\mapsto u)$, $V= (x \\mapsto \\ v)$, and $\\Gamma = (x \\mapsto \\tau)$.}\n\\end{theorem}\n\n\\noindent\nThis top-level refinement theorem additionally assumes that abstract functions\nin the program adhere to their specification and that their behaviour\nremains the same when they are monomorphised.\n\nIntuitively, this theorem states that for related input values, all programs in the refinement chain evaluate to related output values. This can of course be used to deduce that there exist intermediate programs through which the C code and its shallow embedding are directly related. The proof engineer does not need to care what those intermediate programs are. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Well-typedness}\\label{s:typetree}\n\nBefore we present each refinement step, we briefly describe the well-typing\ntheorems that are used in these steps.\n\nThe {\\textsc{Cogent}\\xspace} compiler proves, via an automated Isabelle/HOL tactic, that the\nmonomorphic deep embedding of the input program is well-typed. Specifically,\nthe compiler defines $\\FunDefn{\\cdot}$ in Isabelle/HOL and proves that each\n{\\textsc{Cogent}\\xspace} function~$f\\ \\VarN{x} = e$ is well-typed in accordance with its type as\ngiven by $\\FunDefn{\\cdot}$. Polymorphic well-typing is derived generically in\nthe monomorphisation proof in \\autoref{s:mono-correctness}.\n\n\\begin{theorem}[Typing]\nLet~$f$ be a (monomorphic) {\\textsc{Cogent}\\xspace} function, where \\mbox{$\\FunDefn{f} = \\FunDef{f}{\\FunTy{\\tau}{\\tau'}}{x}{e}$}.\nThen $\\Typing{\\varepsilon}{x : \\tau}{e}{\\tau'}$.\n\\end{theorem}\n\n\\noindent Because, as we will see in \\autoref{s:c-to-deep}, proving\nrefinement requires access to the typing judgements for program\nsub-expressions and not just for the top level, the {\\textsc{Cogent}\\xspace} compiler also\ninstructs Isabelle to store all of the intermediate typing judgements\nestablished during type checking. These theorems are stored in a tree\nstructure, isomorphic to the type derivation tree for the {\\textsc{Cogent}\\xspace} program. Each\nnode is a typing theorem for a sub-expression of the program.\n\n\\subsection{From C to {\\textsc{Cogent}\\xspace} Monomorphic Deep Embedding}\\label{s:c-to-deep}\n\nThis section describes the first three transformations from\n\\autoref{fig:refinement} in \\autoref{s:overview}. In the first step, the C\ncode is converted to Simpl~\\citep{schirmer:phd} by the C-to-Isabelle\nparser~\\citep{Tuch_KN_07}, used in the seL4\nproject~\\citep{Klein_EHACDEEKNSTW_09}. This step is kept as simple as\npossible and makes no effort to abstract from the details of C.\n\n\n\n\n\nThe second step in \\autoref{fig:refinement}, which is the first link in the formal refinement chain, applies a modified version of the AutoCorres tool to produce a \\emph{monadic} shallow embedding of the C code\nsemantics, and additionally proves that the Simpl C semantics is\na refinement of the monadic shallow embedding. We modify AutoCorres to make\nits output more predictable by switching off its control-flow\nsimplification and forcing it to always output the shallow embedding in\nthe \\emph{nondeterministic state monad} of~\\citet{Cock_KS_08}.\nIn this monad, computation is represented by functions of type\n${\\mathit{state}} \\Rightarrow (\\alpha \\mathrel{\\times} {\\mathit{state}}) \\;\\set \\mathrel{\\times} \\bool$. Here\n${\\mathit{state}}$ is the global state of the C program, including\nglobal variables, while $\\alpha$ is the return-type of the computation.\nA computation takes as input the global state and returns a set, \\results, of pairs with new state and result value. Additionally the computation\nreturns a boolean, \\failed, indicating whether it failed (e.g. whether there was undefined behaviour). \n\nWhile AutoCorres was designed to facilitate manual reasoning about C code,\nhere we use it as the foundation for automatically proving correspondence to\nthe {\\textsc{Cogent}\\xspace} input program. One of the main benefits AutoCorres gives us is a\n\\emph{typed} memory model. Specifically, the ${\\mathit{state}}$ of the AutoCorres monadic\nrepresentation contains a set of \\emph{typed heaps}, each of type~$\\mathsf{32}\\  {\\mathsf{word}} \\Rightarrow \\alpha$, \none for each type~$\\alpha$ used on the heap in the C input program. \n\nProving that the\nAutoCorres-generated monadic embedding never fails implies that the C\ncode is type- and memory-safe, and is free of undefined behaviour~\\citep{Greenaway_LAK_14}. We prove\nnon-failure as a side-condition of the refinement statement from the\nAutoCorres shallow embedding to the {\\textsc{Cogent}\\xspace} monomorphic deep embedding in its\nupdate semantics, essentially using {\\textsc{Cogent}\\xspace}'s type system to guarantee C memory\nsafety during execution.\n\n\n\n\nThis refinement proof is the third step in \\autoref{fig:refinement}.\nTo phrase the refinement statement we first define how deeply-embedded \n{\\textsc{Cogent}\\xspace} values and types relate to their corresponding monadic shallowly-embedded C values.\nThe value-mapping is captured by\nthe \\emph{value relation}~$\\valrel$, defined in Isabelle/HOL automatically\nby the\n{\\textsc{Cogent}\\xspace} compiler using ad hoc\noverloading. $\\valrel$ is defined separately for each {\\textsc{Cogent}\\xspace} program because the\ntypes used in the shallow C embedding depend on those used in\nthe C program as, e.g., C structs are represented directly as\nIsabelle/HOL records. \n\n\n\n\n\n\n\nThe type relation $\\typerel$ is used to determine, for a {\\textsc{Cogent}\\xspace} value~$v$ of\ntype $\\tau$, which typed heap in the state of the monadic shallow \nembedding~$v$ should appear in. As with $\\valrel$ it is defined automatically\nfor each {\\textsc{Cogent}\\xspace} program.\n\nGiven $\\valrel$ and~$\\typerel$ for a particular {\\textsc{Cogent}\\xspace} program, the\n\\emph{state relation}~$\\srel$ defines the correspondence between the store~$\\mu$\nover which the {\\textsc{Cogent}\\xspace} update semantics operates, \nand the state~$\\sigma$ of the monadic shallow embedding. \n\n\\begin{definition}[Monad-to-Update State Relation]\n$(\\mu,\\sigma) \\in \\srel$ if and only if: for all pointers~$p$\nin the domain of $\\mu$, there exists a\nvalue~$v$ in the appropriate heap of~$\\sigma$ (as defined by $\\typerel$) at\nlocation~$p$, such that $\\valrel\\  \\mu(p)\\  v$ holds.\n\\end{definition}\n\n\\noindent \nWith $\\srel$ and $\\valrel$,\nwe define refinement generically between \na monadic computation~$p_m$\nand a {\\textsc{Cogent}\\xspace} expression~$e$, evaluated under the update semantics. \nWe denote the \nrefinement predicate \\corres.\nBecause $\\srel$ changes for each {\\textsc{Cogent}\\xspace} program, we parameterise\n\\corres by an arbitrary state relation~$R$. It is parameterised also by \nthe typing context~$\\Gamma$ and the environment~$U$, \nas well as by the initial update semantics store~$\\mu$ and monadic shallow embedding\nstate~$\\sigma$.\n\n\\begin{definition}{Monad-to-Update Correspondence}\n", "index": 13, "text": "\n\\[\n\\begin{array}{l}\n\\corres \\;R\\; e\\; p_m\\;U\\; \\Gamma\\; \\mu\\; \\sigma = \\\\\n\\quad (\\exists r \\; w.\\; U\\ |\\ \\mu : \\Gamma\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w])\\longrightarrow \\\\\n\\quad \\;\\;     (\\mu,\\sigma) \\in R \\longrightarrow \\\\\n\\quad\\quad   \\;(\\neg\\ \\failed \\ (p_m \\ \\sigma)\\; \\wedge \\\\\n\\quad\\quad   \\;(\\forall v_m \\;\\sigma^\\prime. \\ (v_m,\\sigma^\\prime) \\in \\results\\ (p_m\\;\\sigma) \\longrightarrow \\\\\n\\quad\\quad\\quad    (\\exists \\mu^\\prime \\ u. \\ \\UpdSem{U}{e}{\\mu}{u}{\\mu^\\prime} \\wedge \n      (\\mu^\\prime,\\sigma^\\prime) \\in R \\wedge \\valrel\\ u\\ v_m)))\n\\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{l}\\corres\\;R\\;e\\;p_{m}\\;U\\;\\Gamma\\;\\mu\\;\\sigma=\\\\&#10;\\quad(\\exists r\\;w.\\;U\\ |\\ \\mu:\\Gamma\\ [\\textbf{ro:}\\ r\\ \\textbf{rw:}\\ w])%&#10;\\longrightarrow\\\\&#10;\\quad\\;\\;(\\mu,\\sigma)\\in R\\longrightarrow\\\\&#10;\\quad\\quad\\;(\\neg\\ \\failed\\ (p_{m}\\ \\sigma)\\;\\wedge\\\\&#10;\\quad\\quad\\;(\\forall v_{m}\\;\\sigma^{\\prime}.\\ (v_{m},\\sigma^{\\prime})\\in%&#10;\\results\\ (p_{m}\\;\\sigma)\\longrightarrow\\\\&#10;\\quad\\quad\\quad(\\exists\\mu^{\\prime}\\ u.\\ \\UpdSem{U}{e}{\\mu}{u}{\\mu^{\\prime}}%&#10;\\wedge(\\mu^{\\prime},\\sigma^{\\prime})\\in R\\wedge\\valrel\\ u\\ v_{m})))\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\corres</mtext></merror><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>R</mi></mpadded><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mpadded width=\"+2.8pt\"><msub><mi>p</mi><mi>m</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>U</mi></mpadded><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi mathvariant=\"normal\">\u0393</mi></mpadded><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mi>\u03c3</mi></mrow><mo>=</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo lspace=\"12.5pt\" stretchy=\"false\">(</mo><mo>\u2203</mo><mpadded width=\"+2.8pt\"><mi>r</mi></mpadded><mi>w</mi><mo rspace=\"5.3pt\">.</mo><mpadded width=\"+5pt\"><mi>U</mi></mpadded><mo rspace=\"7.5pt\" stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>:</mo><mpadded width=\"+5pt\"><mi mathvariant=\"normal\">\u0393</mi></mpadded><mrow><mo stretchy=\"false\">[</mo><mpadded width=\"+5pt\"><mtext mathvariant=\"bold\">ro:</mtext></mpadded><mpadded width=\"+5pt\"><mi>r</mi></mpadded><mpadded width=\"+5pt\"><mtext mathvariant=\"bold\">rw:</mtext></mpadded><mi>w</mi><mo stretchy=\"false\">]</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u27f6</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo lspace=\"18.1pt\" stretchy=\"false\">(</mo><mi>\u03bc</mi><mo>,</mo><mi>\u03c3</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><mi>R</mi><mo>\u27f6</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mo lspace=\"25.3pt\" stretchy=\"false\">(</mo><mpadded width=\"+5pt\"><mi mathvariant=\"normal\">\u00ac</mi></mpadded><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\failed</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mpadded width=\"+5pt\"><msub><mi>p</mi><mi>m</mi></msub></mpadded><mi>\u03c3</mi><mo rspace=\"5.3pt\" stretchy=\"false\">)</mo></mrow><mo>\u2227</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mo lspace=\"25.3pt\" stretchy=\"false\">(</mo><mo>\u2200</mo><mpadded width=\"+2.8pt\"><msub><mi>v</mi><mi>m</mi></msub></mpadded><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo rspace=\"7.5pt\">.</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>v</mi><mi>m</mi></msub><mo>,</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\results</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mpadded width=\"+2.8pt\"><msub><mi>p</mi><mi>m</mi></msub></mpadded><mi>\u03c3</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u27f6</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mo lspace=\"32.5pt\" stretchy=\"false\">(</mo><mo>\u2203</mo><mpadded width=\"+5pt\"><msup><mi>\u03bc</mi><mo>\u2032</mo></msup></mpadded><mi>u</mi><mo rspace=\"7.5pt\">.</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\UpdSem</mtext></merror><mi>U</mi><mi>e</mi><mi>\u03bc</mi><mi>u</mi><msup><mi>\u03bc</mi><mo>\u2032</mo></msup><mo>\u2227</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03bc</mi><mo>\u2032</mo></msup><mo>,</mo><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><mi>R</mi><mo>\u2227</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\valrel</mtext></merror><mpadded width=\"+5pt\"><mi>u</mi></mpadded><msub><mi>v</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\end{theorem}\n\n\\subsection{From Update to Value Semantics}\n\nTo complete this step, the compiler simply applies \n\\autoref{thm:updvalrefinement}.\n\n\\subsection{From Monomorphic to Polymorphic Deep Embedding}\\label{s:mono-correctness}\n\\label{s:mono}\nHaving made the transition to the value semantics, the proof now establishes\nthe correctness of the compiler's monomorphisation pass, moving upwards\nin \\autoref{fig:refinement} from\na monomorphic to a polymorphic deep embedding of the input program.\n\nIn this pass, the compiler generates an injective renaming function \\rename that, for a polymorphic function \nname $f_p$ and types $\\many{\\tau}$, yields the specialised \nmonomorphic function name $f_m$, mapping names downwards, from \nthe polymorphic to the monomorphic level.\nJust as we assume abstract functions are correctly implemented in C, we\nalso assume that their behaviour\nremains consistent under\n\\rename. \n\nTo establish correctness of monomorphisation, we essentially have an Isabelle\nfunction that repeats the monomorphisation process on behalf of the {\\textsc{Cogent}\\xspace} compiler, \nand prove that (1)~the monomorphised\nprogram it produced is identical to that produced by the compiler, and\n(2)~that the monomorphised program is a correct refinement of the polymorphic\none.\nWe define two Isabelle/HOL functions, both parameterised by~$\\rename$: \none for monomorphising expressions,\ncalled $\\monoexpr$, and the other for monomorphising (function) values,\ncalled \\monoval. \nThe functions specialise function calls and use \n\\rename to monomorphise \nall function calls in expressions and values, respectively.  \nThe functions are defined compositionally for all other {\\textsc{Cogent}\\xspace} constructs. \n\nStep~(1) is proved by straightforward rewriting, and is automated on a per-program basis. \nStep~(2) is embodied in the following refinement theorem,\nwhich we prove, once and for all,  by rule induction over the value semantics. \nThe specialisation Lemma~\\autoref{lemma:spec} of \\autoref{sec:typing:poly}, \nis a key ingredient of this proof.\n\n\n\\begin{theorem}[Monomorphisation]\nLet $f$ be a (polymorphic) {\\textsc{Cogent}\\xspace} function whose definition given by\n$\\FunDefn{\\cdot}$ is $f\\ \\VarN{x} = e$. Let~$v$ be an appropriately-typed\nargument for~$f$. Let~$\\rename$ be an injective renaming function. Then:\n", "itemtype": "equation", "pos": 92830, "prevtext": "\n\\end{definition}\n\n\\noindent\n\n\n\nThe definition states that if the state relation~$R$ holds initially,\nthen the monadic computation~$p_m$ cannot fail and, moreover,\nfor all executions of~$p_m$ there must exist\na corresponding execution under the update semantics of the expression~$e$\nsuch that the final states are related by~$R$ and $\\valrel$ holds between\ntheir results.\nAutoCorres proves automatically that: $\\neg \\ \\failed \\ (p_m\\  \\sigma) \\longrightarrow \\results \\ (p_m\\ \\sigma) \\neq \\emptyset$.\n\n\\paragraph{Refinement Proof}\nThe refinement proof is automatic in Isabelle, driven by a set of syntax-directed\n\\corres rules, one for each {\\textsc{Cogent}\\xspace} construct. The proof procedure makes use\nof the fact that the {\\textsc{Cogent}\\xspace} term is in A-normal form to reduce the number of\ncases that need to be considered and to simplify the higher-order unification\nproblems that some of the proof rules pose to Isabelle. \n\nThis refinement theorem does not need an explicit formal assumption of\nwell-typedness of the {\\textsc{Cogent}\\xspace} program. The proof tactic will simply fail for\nprograms that are not well-typed.\n\n\\autoref{fig:corres-rules} depicts two \\corres rules, one for expressions~$x$\nthat are variables and the other for~$\\Let{x}{a}{b}$.\nThese correspond respectively to the two basic monadic operations~\\mreturn,\nwhich yields values, and $>>=$, for sequencing computations.\n\n\n\nObserve that the rule \\textsc{Corres-Let} is \\emph{compositional}: to prove\nthat $\\Let{x}{a}{b}$ corresponds to $a' >>= b'$ the rule involves proving\nthat (1)~$a$ corresponds to $a'$ and (2)~that~$b$ corresponds to~$b'$ when each are\nexecuted over corresponding results~$v_u$ and~$v_m$ (e.g. as yielded by\n$a$ and $a'$ respectively). This compositionality significantly simplifies the automation of the correspondence proof.\nThe typing assumptions of \\textsc{Corres-Let} are discharged by appealing to the type theorem tree generated by the compiler (see \\autoref{s:typetree}). \n\n \\begin{figure} \n  \\begin{tabular}{c} \n  \\inferrule{ (\\EnvBind{x}{u}) \\in U  \\\\ \\valrel\\ u \\ v_m}\n            {\\corresargs{x}{(\\mreturn \\  v_m)}}\\; {\\textsc{\\scriptsize {Corres-Var}}}\\\\ \\\\ \n\n  \\inferrule{\\Contraction{}{\\Gamma}{\\Gamma_1}{\\Gamma_2} \\quad \n             \\Typing{\\varepsilon}{\\Gamma_1}{a}{\\tau} \\quad\n             \\corresargsE{a}{a'}{U}{\\Gamma_1} \\\\\n             (\\forall v_u \\ v_m\\ \\mu^\\prime\\ \\sigma^\\prime.\\ \\valrel\\ v_u v_m \n              \\longrightarrow \\\\ \n              \\quad\\quad \\corres \\ R \\ {b}\\ (b' \\; v_m)\\\n                                 (x \\mapsto v_u,U) \\ \n                                 (x : \\tau,\\Gamma_2) \\ {\\mu^\\prime}\n                                 \\sigma^\\prime\n             )} \n            {\\corresargs{(\\Let{x}{a}{b})}{(a' >>= b')}} \\!{\\textsc{\\scriptsize {Corres-Let}}} \\\\ \n  \\end{tabular} \\caption{Two example \\corres rules}\n  \\label{fig:corres-rules}\n\\end{figure}\n\nThe rules for some of the other constructs, such as $\\TAKE$, $\\PUT$, and $\\mathbf{case}$, \ncontain non-trivial assumptions about \\srel and about the types used \nin the program. Once a  program and its \\srel are fixed, \na set of simpler \nrules is automatically generated by \\emph{specialising} the generic \\corres\nrules for each of these constructs to the particular \\srel and types used in the\ninput program. This in effect discharges the non-trivial assumptions of these\nrules once-and-for-all, allowing the automated proof of correspondence to \nproceed efficiently.\n\nConceptually, the refinement proof proceeds bottom-up, starting with the leaf functions of\nthe program and ending with the top-level entry points;  \\corres results\nproved earlier are used to discharge \\corres assumptions for callees.\nThe \\corres proof tactic thus follows\nthe call-graph of the input program. Currently, the tactic is limited to\ncomputing call graphs correctly only for programs containing up to second-order\nfunctions. We did not need higher orders in our applications yet, but\nthe tactic can certainly be extended if needed.\n\nThe resulting refinement theorem at this stage assumes that \\corres holds for \nall the abstract functions used in the \n program.\n\\begin{theorem}\nLet~$f$ be a (monomorphic) {\\textsc{Cogent}\\xspace} function, such that $\\FunDefn{f} = \\FunDef{f}{\\tau \\rightarrow \\tau'}{x}{e}$. Let~$p_m$ be its monadic shallow embedding, as\nderived from its generated C code. Let~$u$ and $v_m$ be arguments of\nappropriate type for~$f$ and $p_m$ respectively. Then:\n", "index": 15, "text": "\n\\[\n\\begin{array}{l}\n\\forall \\mu\\ \\sigma. \\;\\valrel\\ u \\ v_m \\longrightarrow \\corres\\ \\srel\\ e\\ (p_m\\ v_m)\\ (x \\mapsto u)\\ (x : \\tau)\\ \\mu \\ \\sigma\n\\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{l}\\forall\\mu\\ \\sigma.\\;\\valrel\\ u\\ v_{m}\\longrightarrow\\corres%&#10;\\ \\srel\\ e\\ (p_{m}\\ v_{m})\\ (x\\mapsto u)\\ (x:\\tau)\\ \\mu\\ \\sigma\\end{array}\" display=\"block\"><mtable displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><mo>\u2200</mo><mpadded width=\"+5pt\"><mi>\u03bc</mi></mpadded><mi>\u03c3</mi><mo rspace=\"5.3pt\">.</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\valrel</mtext></merror><mpadded width=\"+5pt\"><mi>u</mi></mpadded><msub><mi>v</mi><mi>m</mi></msub><mo>\u27f6</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\corres</mtext></merror><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\srel</mtext></merror><mpadded width=\"+5pt\"><mi>e</mi></mpadded><mrow><mo stretchy=\"false\">(</mo><mpadded width=\"+5pt\"><msub><mi>p</mi><mi>m</mi></msub></mpadded><msub><mi>v</mi><mi>m</mi></msub><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>\u21a6</mo><mi>u</mi><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>:</mo><mi>\u03c4</mi><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mpadded width=\"+5pt\"><mi>\u03bc</mi></mpadded><mi>\u03c3</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\end{theorem}\n\n\\noindent Note that on the left-hand-side of the implication, the computation\nruns under the value semantics where the renaming is applied across\nthe $\\FunDefn{\\cdot}$ of the right-hand side.\n\nThe compiler generates a well-typedness proof for the monomorphic deeply\nembedded program (\\autoref{s:typetree}). We use the top-level theorem's injectivity assumption on\n\\rename to infer well-typedness of the polymorphic deeply embedded program.\n\n\\subsection{From Deep to Shallow Embedding}\n\n\nIn this section, the proof makes the transition from deep to shallow\nembedding, where the shallow embedding is a pure function in Isabelle/HOL. \nThis shallow embedding is still in A-normal form and is produced\nby the compiler as a separate Isabelle/HOL theory file. There is a second,\nneater shallow embedding, explained in the following section, that is closer\nto the {\\textsc{Cogent}\\xspace} input program.\n\nFor each {\\textsc{Cogent}\\xspace} type, the compiler generates a corresponding Isabelle/HOL type\ndefinition, and for each {\\textsc{Cogent}\\xspace} function, a corresponding Isabelle/HOL\nconstant definition. We can drop the linear types at this stage and remain in\nIsabelle's simple types, because we have already made use of them: we are in\nthe value semantics.\n\n\n\n\n\nIn addition to these definitions, the compiler produces a theorem that the\ndeeply embedded polymorphic {\\textsc{Cogent}\\xspace} term under the value semantics correctly\nrefines this Isabelle/HOL function. Refinement is formally defined here\nby the predicate $\\scorres$ that defines when a shallowly embedded\nexpression~$s$ is refined by a deeply embedded one~$e$ when evaluated\nunder the environment~$V$.\n\n\\begin{definition}[Deep to Shallow Correspondence]\n\n", "itemtype": "equation", "pos": 95319, "prevtext": "\n\\end{theorem}\n\n\\subsection{From Update to Value Semantics}\n\nTo complete this step, the compiler simply applies \n\\autoref{thm:updvalrefinement}.\n\n\\subsection{From Monomorphic to Polymorphic Deep Embedding}\\label{s:mono-correctness}\n\\label{s:mono}\nHaving made the transition to the value semantics, the proof now establishes\nthe correctness of the compiler's monomorphisation pass, moving upwards\nin \\autoref{fig:refinement} from\na monomorphic to a polymorphic deep embedding of the input program.\n\nIn this pass, the compiler generates an injective renaming function \\rename that, for a polymorphic function \nname $f_p$ and types $\\many{\\tau}$, yields the specialised \nmonomorphic function name $f_m$, mapping names downwards, from \nthe polymorphic to the monomorphic level.\nJust as we assume abstract functions are correctly implemented in C, we\nalso assume that their behaviour\nremains consistent under\n\\rename. \n\nTo establish correctness of monomorphisation, we essentially have an Isabelle\nfunction that repeats the monomorphisation process on behalf of the {\\textsc{Cogent}\\xspace} compiler, \nand prove that (1)~the monomorphised\nprogram it produced is identical to that produced by the compiler, and\n(2)~that the monomorphised program is a correct refinement of the polymorphic\none.\nWe define two Isabelle/HOL functions, both parameterised by~$\\rename$: \none for monomorphising expressions,\ncalled $\\monoexpr$, and the other for monomorphising (function) values,\ncalled \\monoval. \nThe functions specialise function calls and use \n\\rename to monomorphise \nall function calls in expressions and values, respectively.  \nThe functions are defined compositionally for all other {\\textsc{Cogent}\\xspace} constructs. \n\nStep~(1) is proved by straightforward rewriting, and is automated on a per-program basis. \nStep~(2) is embodied in the following refinement theorem,\nwhich we prove, once and for all,  by rule induction over the value semantics. \nThe specialisation Lemma~\\autoref{lemma:spec} of \\autoref{sec:typing:poly}, \nis a key ingredient of this proof.\n\n\n\\begin{theorem}[Monomorphisation]\nLet $f$ be a (polymorphic) {\\textsc{Cogent}\\xspace} function whose definition given by\n$\\FunDefn{\\cdot}$ is $f\\ \\VarN{x} = e$. Let~$v$ be an appropriately-typed\nargument for~$f$. Let~$\\rename$ be an injective renaming function. Then:\n", "index": 17, "text": "\n\\[\n\\begin{array}{l}\n\\forall v'.\\  \\ValSem{(x \\mapsto \\monoval \\ \\rename \\ v)}{\\monoexpr\\  \\rename \\ e}{\\monoval\\ \\rename\\ v'}\n\\longrightarrow \\ValSem{(x \\mapsto v)}{e}{v'}\n\\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{l}\\forall v^{\\prime}.\\ \\ValSem{(x\\mapsto\\monoval\\ \\rename\\ v)}%&#10;{\\monoexpr\\ \\rename\\ e}{\\monoval\\ \\rename\\ v^{\\prime}}\\longrightarrow\\ValSem{(%&#10;x\\mapsto v)}{e}{v^{\\prime}}\\end{array}\" display=\"block\"><mtable displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><mo>\u2200</mo><msup><mi>v</mi><mo>\u2032</mo></msup><mo rspace=\"7.5pt\">.</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\ValSem</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>\u21a6</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\monoval</mtext></merror><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\monoexpr</mtext></merror><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><mi>e</mi><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\monoval</mtext></merror><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\rename</mtext></merror><msup><mi>v</mi><mo>\u2032</mo></msup><mo>\u27f6</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\ValSem</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>\u21a6</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><mi>e</mi><msup><mi>v</mi><mo>\u2032</mo></msup></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\end{definition}\n\n\\noindent That is, $s$ corresponds to $e$ under variable bindings $V$ if whenever $e$\nevaluates to an $r$ under $V$, then $s$ and $v$ are in the value relation\n${\\mathrm{valRel}}$. Similarly to the proof from monadic C to update semantics, the\nvalue relation here is one polymorphic constant in Isabelle/HOL, defined\nincrementally via ad-hoc overloading.\n\nThe program-specific refinement theorem produced is:\n\\begin{theorem}[Deep to Shallow Refinement]\nLet $f$ be an A-normal {\\textsc{Cogent}\\xspace} function such that\n$\\FunDefn{f} = \\FunDef{f}{\\pi}{x}{e}$, and\nlet~$s$ be $f$'s shallow embedding. Then\n\n", "itemtype": "equation", "pos": 97243, "prevtext": "\n\\end{theorem}\n\n\\noindent Note that on the left-hand-side of the implication, the computation\nruns under the value semantics where the renaming is applied across\nthe $\\FunDefn{\\cdot}$ of the right-hand side.\n\nThe compiler generates a well-typedness proof for the monomorphic deeply\nembedded program (\\autoref{s:typetree}). We use the top-level theorem's injectivity assumption on\n\\rename to infer well-typedness of the polymorphic deeply embedded program.\n\n\\subsection{From Deep to Shallow Embedding}\n\n\nIn this section, the proof makes the transition from deep to shallow\nembedding, where the shallow embedding is a pure function in Isabelle/HOL. \nThis shallow embedding is still in A-normal form and is produced\nby the compiler as a separate Isabelle/HOL theory file. There is a second,\nneater shallow embedding, explained in the following section, that is closer\nto the {\\textsc{Cogent}\\xspace} input program.\n\nFor each {\\textsc{Cogent}\\xspace} type, the compiler generates a corresponding Isabelle/HOL type\ndefinition, and for each {\\textsc{Cogent}\\xspace} function, a corresponding Isabelle/HOL\nconstant definition. We can drop the linear types at this stage and remain in\nIsabelle's simple types, because we have already made use of them: we are in\nthe value semantics.\n\n\n\n\n\nIn addition to these definitions, the compiler produces a theorem that the\ndeeply embedded polymorphic {\\textsc{Cogent}\\xspace} term under the value semantics correctly\nrefines this Isabelle/HOL function. Refinement is formally defined here\nby the predicate $\\scorres$ that defines when a shallowly embedded\nexpression~$s$ is refined by a deeply embedded one~$e$ when evaluated\nunder the environment~$V$.\n\n\\begin{definition}[Deep to Shallow Correspondence]\n\n", "index": 19, "text": "$$\\scorres\\ s\\ e\\ V\\ \\equiv\\ \\forall r.\\ \\ValSem{V}{e}{r} \\longrightarrow {\\mathrm{valRel}}\\ s\\ r$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\scorres\\ s\\ e\\ V\\ \\equiv\\ \\forall r.\\ \\ValSem{V}{e}{r}\\longrightarrow{\\mathrm%&#10;{valRel}}\\ s\\ r\" display=\"block\"><mrow><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\scorres</mtext></merror><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>V</mi></mpadded></mrow><mo rspace=\"7.5pt\">\u2261</mo><mrow><mo>\u2200</mo><mi>r</mi></mrow></mrow><mo rspace=\"7.5pt\">.</mo><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\ValSem</mtext></merror><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>r</mi></mrow><mo>\u27f6</mo><mrow><mpadded width=\"+5pt\"><mi>valRel</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>r</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\n\\end{theorem}\n\n\\noindent\nNote that ${\\mathrm{valRel}}\\ v_s\\ v$ ensures that $v_s$ and $v$ are of matching type,\nand that the shallow expression $s\\ v_s$ ensures in Isabelle's type system\nthat it is the appropriate one. Like the C refinement proof in\n\\autoref{s:c-to-deep}, this proof is automatic and driven by a set of\nsyntax-directed \\scorres rules, specialised to {\\textsc{Cogent}\\xspace} A-normal form.\n\n\n\\subsection{From Shallow Embedding to Neat Shallow Embedding}\n\n\\autoref{fig:shallow} depicts the final top-level shallow embedding, only mildly polished for\npresentation, for the {\\textsc{Cogent}\\xspace} example of \\autoref{fig:cdsl-snippet}.\n\n\\begin{figure}[ht]\n\\begin{lstlisting}[style=isa]\next2_free_branch (Cnt.mk depth nd (Acc.mk ex fs inode) mdep) \\<equiv>\nif depth + 1 < mdep then \ncase uarray_create (RR.mk ex (to\\<^sub>f nd - fr\\<^sub>f nd)) of\n  R\\<^sub>1\\<^sub>1.Success ds\\<^sub>1\\<^sub>0 \\<Rightarrow>\n    let (ex, ds\\<^sub>1\\<^sub>2) = take ds\\<^sub>1\\<^sub>0 RR.p1\\<^sub>f;\n        (children, ds\\<^sub>1\\<^sub>3) = take ds\\<^sub>1\\<^sub>2 RR.p2\\<^sub>f;\n        (mbuf, nd_t) = take nd mbuf\\<^sub>f;\n        (children, ds\\<^sub>1\\<^sub>6) = take\n          (uarray_map_no_break\n            (ArrayMapP.mk children (fr\\<^sub>f nd_t)\n              (to\\<^sub>f nd_t) ext2_free_branch_entry\n              (Cnt.mk ex inode (fr\\<^sub>f nd_t) mbuf) ()))\n          RR.p1\\<^sub>f;\n  ...    \n\\end{lstlisting}\n\\caption{Shallow embedding for the example from \\autoref{s:overview}.}\n\\label{fig:shallow}\n\\end{figure}\n\n\\noindent As \\autoref{fig:shallow} shows, the Isabelle definitions use the same names\nas the {\\textsc{Cogent}\\xspace} input program and they have the same structure as the input\nprogram. In this example, it remains visible that the compiler replaces\ntuples from the surface syntax with records in the core language, e.g.\\\n{\\texttt{{Cnt.mk}}} is the Isabelle record constructor for the type {\\texttt{{Cnt}}}, and\ninstead of tuple pattern matching, the compiler generates a sequence of\n{\\texttt{{take}}} expressions. In practice, these disappear by rewriting when \nreasoning about the function. Tuple syntax could be reconstructed\nin an additional small proof pass if so desired.\n\nThe correctness statement for this phase is simple: it is pure Isabelle/HOL\nequality between the A-normal and neat shallow embedding for each function.\nFor instance:\n\n", "itemtype": "equation", "pos": 97965, "prevtext": "\n\\end{definition}\n\n\\noindent That is, $s$ corresponds to $e$ under variable bindings $V$ if whenever $e$\nevaluates to an $r$ under $V$, then $s$ and $v$ are in the value relation\n${\\mathrm{valRel}}$. Similarly to the proof from monadic C to update semantics, the\nvalue relation here is one polymorphic constant in Isabelle/HOL, defined\nincrementally via ad-hoc overloading.\n\nThe program-specific refinement theorem produced is:\n\\begin{theorem}[Deep to Shallow Refinement]\nLet $f$ be an A-normal {\\textsc{Cogent}\\xspace} function such that\n$\\FunDefn{f} = \\FunDef{f}{\\pi}{x}{e}$, and\nlet~$s$ be $f$'s shallow embedding. Then\n\n", "index": 21, "text": "$$\\forall v_s\\ v.\\ {\\mathrm{valRel}}\\ v_s\\ v \\longrightarrow \\scorres\\ (s\\ v_s)\\ e\\ (x \\mapsto v)$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\forall v_{s}\\ v.\\ {\\mathrm{valRel}}\\ v_{s}\\ v\\longrightarrow\\scorres\\ (s\\ v_{%&#10;s})\\ e\\ (x\\mapsto v)\" display=\"block\"><mrow><mo>\u2200</mo><mpadded width=\"+5pt\"><msub><mi>v</mi><mi>s</mi></msub></mpadded><mi>v</mi><mo rspace=\"7.5pt\">.</mo><mpadded width=\"+5pt\"><mi>valRel</mi></mpadded><mpadded width=\"+5pt\"><msub><mi>v</mi><mi>s</mi></msub></mpadded><mi>v</mi><mo>\u27f6</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\scorres</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mpadded width=\"+5pt\"><mi>s</mi></mpadded><msub><mi>v</mi><mi>s</mi></msub><mo rspace=\"7.5pt\" stretchy=\"false\">)</mo></mrow><mpadded width=\"+5pt\"><mi>e</mi></mpadded><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>\u21a6</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05520.tex", "nexttext": "\nThe proof is simple as well. Since we can now use equational reasoning with\nIsabelle's powerful rewriter, we just unfold both sides, apply extensionality\nand the proof is automatic given the right congruence rules and equality\ntheorems for functions lower in the call graph. This proof stage was the\neasiest and fastest of the stages to construct; it took about 1 person day.\n\nThis is a strong indication that this representation of the program is well\nsuited for further reasoning on top.\n\n\\section{Discussion and Lessons Learned}\\label{s:lessons}\n\n\n\n\\paragraph{Language Restrictions: Totality}\nThe current version of {\\textsc{Cogent}\\xspace} purposefully omits primitive constructs for\niteration and recursion, because we wanted to ensure that the language was\ntotal for a neat shallow embedding in HOL (which is total). However, since\nour language meta-level proofs do not require totality, we only require that\n\\emph{each program} is terminating. We are therefore contemplating to relax\nthis restriction and allow {\\textsc{Cogent}\\xspace} iterator constructs where termination is\nobvious enough for Isabelle to prove automatically.\n\n\\paragraph{Formal Language Semantics}\nThe {\\textsc{Cogent}\\xspace} semantics in Isabelle departs slightly from that presented in\n\\autoref{s:lang}. In particular, we enriched the update semantics to carry\nenough value type information to infer their corresponding C types, and\nadjusted the typing rules accordingly. While not needed for any of the\nproofs of \\autoref{s:lang}, this information is used in the automatic\nC-correspondence proof.\nIn addition, we found ourselves repeating parts of the (linear) type\npreservation proof in rule inductions on the semantics that make use of\ntyping assumptions. This means, while type erasure is an important\nproperty for languages to enjoy (and \\emph{is} enjoyed by {\\textsc{Cogent}\\xspace}), dynamic\nsemantics with type information are helpful for mechanised\nreasoning. Ideally, there should be an erased and a typed dynamic\nsemantics, with type safety implying their equivalence.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\paragraph{Optimisation}\n\nThe current {\\textsc{Cogent}\\xspace} compiler performs little optimisation when generating C\ncode and leaves low-level optimisation to gcc or CompCert. Clever\noptimisations in the {\\textsc{Cogent}\\xspace}-to-C stage would complicate our current\nsyntax-directed correspondence approach. {\\textsc{Cogent}\\xspace}-to-{\\textsc{Cogent}\\xspace} optimisations,\nhowever, are different. The ease by which we prove the correctness of the\nA-normalisation over the shallow embedding via rewriting, suggests fruitful\nground for optimisation. We leave exploring this idea for future work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\paragraph{Effort and Size} {\\textsc{Cogent}\\xspace} has been\nunder development for over 2 years and has continually evolved\nas we have scaled the language to ever larger applications.\nAll up, the combined language development\nand certifying compiler took {$\\approx 5$ person-years\\xspace}. Engineering the\n{\\textsc{Cogent}\\xspace} compiler, excluding {$\\approx 33.5$ person-months\\xspace} spent on\nproof automation and proof framework development,\nconsumed {$\\approx 10$ person-months\\xspace}. The remaining {$\\approx 18$ person-months\\xspace} was for the\ndesign, formalisation and proof of {\\textsc{Cogent}\\xspace} and its properties (e.g. the\ntheorems of \\autoref{s:lang}), a small amount of which was also spent on\nearly compiler development.\nThe total size of the development in\nthe Isabelle theorem prover is {$\\approx 17,000$ lines of code (including comments and whitespace)\\xspace}, which includes the\nonce-and-for-all language proofs plus automated proof tactics to perform\nthe translation validation steps, given appropriate hints from the {\\textsc{Cogent}\\xspace}\ncompiler. The {\\textsc{Cogent}\\xspace} compiler, written in Haskell, is {$\\approx 9,500$ source lines of code (excluding comments and whitespace)\\xspace}.\nFor {6,454\\xspace} lines of etx2 {\\textsc{Cogent}\\xspace} code we generate {76,759\\xspace} lines of Isabelle/HOL proofs\nand embeddings.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Related Work}\\label{s:related}\n\n\nLike us, the High-Assurance Systems Programming~\\citet{Habit:lang} pro\\-ject \nseeks to improve systems software by combining formal \nmethods and programming language research. Like {\\textsc{Cogent}\\xspace}, \nHASP's systems\nlanguage, Habit, is a domain specific functional language. \n\\citet{McCreight_CT_10} show the correctness of a garbage collector in this project; however, to the best \nof our knowledge, there exist no full formal language semantics yet. \n\nIvory~\\citep{Pike_HBEDL_14} is a domain specific language embedded in Haskell\nalso for implementing correct systems software. It generates well-defined,\nmemory safe C code; however, unlike {\\textsc{Cogent}\\xspace} it does not \\emph{prove} correctness\nof the generated code.\n\n\nLinear types have been used in several general purpose imperative languages\nto ensure memory safety without depending on a runtime, such as in Vault~\\citep{Fahndrich_DeLine_02} and \\citet{Rust:lang}.\nPacLang \\citep{Ennals_SM_04} is an imperative domain-specific language which uses linear\ntypes to guide optimisation of packet processing applications on network\nprocessors. Similar substructural type systems, namely uniqueness types, have been\nintegrated into functional programming languages such as\nClean~\\citep{Barendsen_Smeters_93}. However, the type system there is only\nused as a way to provide a purely functional abstraction over effects, \nand thus Clean still depends on a run-time garbage collector.\n\n\n\n\n\n\n\nTo the best of our knowledge, \\citet{Hofmann_00} is the only work which proves the equivalence of the functional and imperative interpretation of a language with a linear type\nsystem. The proof is by pen and paper, from a first order functional language with linear types to its translation in C. {\\textsc{Cogent}\\xspace} in comparison is higher order and its compiler\nproduces a machine checked proof linking a purely functional shallow embedding\nto its C implementation.\n\n\n\n\n\n\n\n\n\n\n\n\nExamples for verified compilers for high-level languages are\nCakeML~\\citep{Kumar_MNO_14}, discussed in more detail in \\autoref{s:intro}, which compiles a full ML dialect, including verified runtime and garbage\ncollection. In contrast, \\citep{Neis_HKMDV_15} focuses on a compositional approach to\ncompiler verification for a relatively simple functional language, Pilsner,\nto an idealised assembly language.\n\n\\citet{Chargueraud_10, Chargueraud_11} also generate a shallow\nembedding representation of a program to facilitate proofs about\nproperties via a proof assistant, as we do. However, they do not address the\nverification of the code generated by the compiler.\n\n\\section{Conclusions}\\label{s:concl}\n\nWe have presented the {\\textsc{Cogent}\\xspace} language, its self-certifying compiler, their\nformal definitions and top-level compiler certificate theorem,\nand the correctness theorems for each compiler stage. The\nlanguage targets systems code where data sharing is minimal or can be abstracted,\nperformance and small memory footprint are requirements, and formal\nverification is the aim.\n\n{\\textsc{Cogent}\\xspace} is a pure, total functional language to enable productive equational\nreasoning in an interactive theorem prover. It is higher-order and\npolymorphic to increase conciseness. It uses linear types to make memory\nmanagement bugs compile time errors, and to enable efficient destructive\nin-place update. It avoids garbage collection and a trusted runtime to reduce\nfootprint. It supports a formally modelled foreign-function interface to\ninteroperate with C code and to implement additional data types, iterators\nand operations.\n\nIt does all of these with full formal proof of compilation correctness\nand type-safety in Isabelle/HOL.\n\n{\\textsc{Cogent}\\xspace} sets a new benchmark for trustworthy systems languages, and\ndemonstrates, through the careful application of language design\nwith verified compilation in mind, that writing systems code that\nsupports purely functional equational reasoning is possible.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\balance\n{\n  \\Finalfalse\n\n  \\ifAlpha\n    \\bibliographystyle{alpha}\n  \\else\n    \\bibliographystyle{plainnat}\n  \\fi\n  \\ifFinal\n    \\errmessage{Replace this by the content of your .bbl file!}\n  \\else\n    \\bibliography{references}\n  \\fi\n}\n\n", "itemtype": "equation", "pos": 100435, "prevtext": "\n\\end{theorem}\n\n\\noindent\nNote that ${\\mathrm{valRel}}\\ v_s\\ v$ ensures that $v_s$ and $v$ are of matching type,\nand that the shallow expression $s\\ v_s$ ensures in Isabelle's type system\nthat it is the appropriate one. Like the C refinement proof in\n\\autoref{s:c-to-deep}, this proof is automatic and driven by a set of\nsyntax-directed \\scorres rules, specialised to {\\textsc{Cogent}\\xspace} A-normal form.\n\n\n\\subsection{From Shallow Embedding to Neat Shallow Embedding}\n\n\\autoref{fig:shallow} depicts the final top-level shallow embedding, only mildly polished for\npresentation, for the {\\textsc{Cogent}\\xspace} example of \\autoref{fig:cdsl-snippet}.\n\n\\begin{figure}[ht]\n\\begin{lstlisting}[style=isa]\next2_free_branch (Cnt.mk depth nd (Acc.mk ex fs inode) mdep) \\<equiv>\nif depth + 1 < mdep then \ncase uarray_create (RR.mk ex (to\\<^sub>f nd - fr\\<^sub>f nd)) of\n  R\\<^sub>1\\<^sub>1.Success ds\\<^sub>1\\<^sub>0 \\<Rightarrow>\n    let (ex, ds\\<^sub>1\\<^sub>2) = take ds\\<^sub>1\\<^sub>0 RR.p1\\<^sub>f;\n        (children, ds\\<^sub>1\\<^sub>3) = take ds\\<^sub>1\\<^sub>2 RR.p2\\<^sub>f;\n        (mbuf, nd_t) = take nd mbuf\\<^sub>f;\n        (children, ds\\<^sub>1\\<^sub>6) = take\n          (uarray_map_no_break\n            (ArrayMapP.mk children (fr\\<^sub>f nd_t)\n              (to\\<^sub>f nd_t) ext2_free_branch_entry\n              (Cnt.mk ex inode (fr\\<^sub>f nd_t) mbuf) ()))\n          RR.p1\\<^sub>f;\n  ...    \n\\end{lstlisting}\n\\caption{Shallow embedding for the example from \\autoref{s:overview}.}\n\\label{fig:shallow}\n\\end{figure}\n\n\\noindent As \\autoref{fig:shallow} shows, the Isabelle definitions use the same names\nas the {\\textsc{Cogent}\\xspace} input program and they have the same structure as the input\nprogram. In this example, it remains visible that the compiler replaces\ntuples from the surface syntax with records in the core language, e.g.\\\n{\\texttt{{Cnt.mk}}} is the Isabelle record constructor for the type {\\texttt{{Cnt}}}, and\ninstead of tuple pattern matching, the compiler generates a sequence of\n{\\texttt{{take}}} expressions. In practice, these disappear by rewriting when \nreasoning about the function. Tuple syntax could be reconstructed\nin an additional small proof pass if so desired.\n\nThe correctness statement for this phase is simple: it is pure Isabelle/HOL\nequality between the A-normal and neat shallow embedding for each function.\nFor instance:\n\n", "index": 23, "text": "$$\\mathrm{Shallow.}{\\mathrm{ext2\\_free\\_branch}} = \\mathrm{Neat.}{\\mathrm{ext2\\_free\\_branch}}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\mathrm{Shallow.}{\\mathrm{ext2\\_free\\_branch}}=\\mathrm{Neat.}{\\mathrm{ext2\\_%&#10;free\\_branch}}\" display=\"block\"><mrow><mi>Shallow</mi><mo>.</mo><mrow><mrow><mi>ext2</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>free</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>branch</mi></mrow><mo>=</mo><mi>Neat</mi></mrow><mo>.</mo><mrow><mi>ext2</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>free</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>branch</mi></mrow></mrow></math>", "type": "latex"}]