[{"file": "1601.03094.tex", "nexttext": "\nwhere $A$ and $B$ on the right hand side are\nthe vector representation of the trajectories $A$ and $B$.\n\n{\\bf Scenario 2:} In Fig. \\ref{fig:simple_examples_about_metric}-(b) the sets $A$ and $B$\nstill only have one trajectory but now the trajectories have ``holes''. To define $\\mathcal{D}$ for this scenario we can reduce it to Scenario $1$ by \ncomputing the total distance\nbetween each of the components of the vectors $[-1.0$, *, $-0.2$, $0.2$, $0.6$, $*]$\nand $[*$, $-0.54$, $-0.18$, $0.18$,$0.54$, $*]$ and using the\nrule that $|x - *| = M > 0$ if $x \\in \\mathbb{R}$ and that $| * - *| = 0$.\nFor example, if $M = 0.1$ we get $\\mathcal{D}(A,B) = 0.3$.\nWe can interpret the symbol * as total \nuncertainty in a tracker $A$\nregarding the position of an object $B$ at a particular point in time, in which case we penalize its performance by a fixed amount. If tracker $A$ outputs * because the object $B$ does not exist in that time instant (e.g. it is outside the tracker's range) we do not penalize its performance, hence\n$|* - * | = 0$.\n\nMore generally, let $A^+ = [...,A^+(t),...]$ and $B^+ = [...,B^+(t),...]$ be the vector representation of the single trajectories in $A$ and $B$, now with each point living in $\\mathbb{R}^p$, and padded with the symbol $*$ and let \n$d^+:\\mathbb{R}^p\\cup\\{*\\} \\times \\mathbb{R}^p\\cup\\{*\\} \\mapsto \\mathbb{R}$ be\nan extension of some point-wise\nmetric $d:\\mathbb{R}^p \\times \\mathbb{R}^p \\mapsto \\mathbb{R}$\nsuch that for every\n$x,y \\in \\mathbb{R}$ we have $d^+(x,y) = \\min\\{2M,d(x,y)\\}$, \n$d^+(x,*)= d^+(*,x)= M > 0$ and $d^+(*,*) = 0$. \nOne can show that $d^+$ is a metric (c.f. Lemma \\ref{th:extdismetric} in Appendix \\ref{app:proof_of_th_d_nat_is_metric}) and hence so is\n\n", "itemtype": "equation", "pos": 8217, "prevtext": "\n\\title{A metric for sets of trajectories that is\\\\\npractical and mathematically consistent}\n\n\\author{\n\\IEEEauthorblockN{Jos\\'e Bento}\n\\IEEEauthorblockA{\nEmail: jose.bento@bc.edu}\n}\n\n\\maketitle\n\n\n\n\n\\begin{abstract}\nMetrics on the space of sets of trajectories are important for scientists in the field of computer vision, machine learning, robotics and general artificial intelligence.\n\nYet existing notions of closeness are either\nmathematically inconsistent or of limited practical use.\n\nIn this paper we outline the limitations in the existing \nmathematically-consistent metrics, which are based\non \\cite{schuhmacher2008consistent}, and the inconsistencies\nin the heuristic notions of closeness used in practice, whose\nmain ideas are common to the CLEAR MOT measures\n\\cite{keni2008evaluating} widely used in computer vision.\n\nIn two steps we then propose a new intuitive metric\nbetween sets of trajectories and address these problems. \nFirst we explain a natural solution that \nleads to a metric that is hard to compute. Then we modify this\nformulation to obtain a metric that is easy to compute and\nkeeps all the good properties of the previous metric.\nIn particular, our notion of closeness\nis the first that has the following three properties: it can be quickly computed, it incorporates confusion of trajectories' dentity in an\noptimal way and it is a metric in the mathematical sense.\n\\end{abstract}\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\n\n\\section{Introduction} \\label{sec:intro}\n\n\n\n\nConsider two sets $A$ and $B$ each with multiple\ntrajectories. We denote the set of all trajectories as $\\mathcal{T}$ and\nthe set of all finite sets of trajectories as $\\mathcal{S}$.\n\nFor concreteness, we assume that\n$A = \\{A_1,...,A_k\\}\\in \\mathcal{S}$ and $B = \\{B_1,...,B_l\\}\\in \\mathcal{S}$ where\neach trajectory, say $A_1$, is a set of state-time pairs\n$\\{(t_1,x_1),...,(t_n,x_n)\\}\\in \\mathcal{T}$ with $t_i \\in \\mathbb{N}$ and\n$x_i \\in \\mathbb{R}^p$, which we can also represent as $x_i = A_1(t_i)$.\n\nIn this paper we propose a new\ndistance measure $\\mathcal{D}(A,B)$ for $A,B \\in \\mathcal{S}$.\n\nMeasures of distance between sets of trajectories\nare common, for example, in the field of computer vision\ntracking. In this case $A$ contains the trajectories of several\nobjects and $B$ is the set of approximate\ntrajectories that a tracking algorithm reproduces from video-data.\nA state-time pair $(t,x)$ can be,\nfor example, the position and velocity of an object at time $t$.\n$\\mathcal{D}(A,B)$ is important to evaluate the performance of\nmulti-object tracking algorithms and to distinguish a good tracker, $\\mathcal{D}(A,B) =$ ``small'', from a bad, tracker $\\mathcal{D}(A,B) =$ ``large''.\n\nMachine learning is another example where a measure of closeness\nbetween sets of trajectories is important. Imagine that each datapoint\nin a data set is a set of the trajectories followed by all players in a team\nduring a football play. Now consider the following three tasks:\nthe unsupervised task of clustering football\nplays, the supervised task of building a classifier for the different plays and \nthe information retrieval task of finding plays similar to a reference play.\nWe can solve these tasks using algorithms that only require\na measure of distance on the sets of trajectories, e.g.  \\cite{ganti1999clustering,kleinberg2002approximation, yianilos1993data} respectively.\n\nOur goal is that $\\mathcal{D}(A,B)$ is both mathematically consistent\nand useful in practice. A common mathematical inconsistency\nof similarity measures used in practical applications involving trajectories is that they are not a mathematical\nmetric. In Section \\ref{sec:limitations_MOT} we show this is the\ncase with the CLEAR MOT measures \\cite{keni2008evaluating}, widely used in computer vision, and hence also with many other distance measures\nthat use heuristics similar to the CLEAR MOT. On the contrary, the measure we introduce satisfies the properties of a metric: for every $A,B,C \\in \\mathcal{S}$ we have (i) {\\bf (non-negativity)} $\\mathcal{D}(A,B) \\geq 0$, (ii) {\\bf (coincidence)} $\\mathcal{D}(A,B) = 0$ iff $A = B$, (iii) {\\bf (symmetry)} $\\mathcal{D}(A,B) = \\mathcal{D}(B,A)$ and (iv) {\\bf (sub-additivity)} $\\mathcal{D}(A,C) \\leq \\mathcal{D}(A,B) + \\mathcal{D}(B,C)$.\n\nIn the context of tracking, it is easy to see why not dealing with a mathematical\nmetric can lead to inconsistencies. Imagine that under a certain distance $\\mathcal{D}$ both tracker1's output, $O_1$, and tracker2's output, $O_2$, are close to the ground truth, $GT$. In this setting, one intuitively expects that $O_1$ and $O_2$ are also close to each other. This expectation is related to the sub-additivity property $\\mathcal{D}(O_1,O_2) \\leq \\mathcal{D}(O_1,GT) + \\mathcal{D}(O_2,GT)$ and we \nconsider its violation an inconsistency. The need for symmetry, non-negativity and the coincidence property is intuitive. Note that the\nmachine learning\nalgorithms mentioned above, namely\\cite{ganti1999clustering,kleinberg2002approximation, yianilos1993data},  also\nrequire $\\mathcal{D}$ to be a metric.\n\nIn addition to seeking mathematical consistency, our goal is also to define a useful measure. In the examples that follow we again focus on vision tracking because in this context it is clear why the existing mathematically consistent measures, which are based on \\cite{schuhmacher2008consistent}, are not useful in practice.\n\nWe obviously\nwant $\\mathcal{D}(A,B)$ to have a computation\ntime that scales well with the number and length of the trajectories in $A$\nand $B$. We show our metric is fast to compute in Section \\ref{sec:num_res_run_time}. In addition, to be useful,\n$\\mathcal{D}(A,B)$ must behave as expected in scenarios with \nintuitive answers as, for example, in the scenarios we now explain. These help us understand how a consistent and practical $\\mathcal{D}$\nshould look like, help us introduce relevant previous work, some notation, and also help understanding why our task is not easy.\n\n\n\n\\begin{figure}[htbp]\n\\begin{center}\n\\includegraphics[height=2.9cm]{./figures/simple_example_1.eps}\n\n\\put(-53,65){\\tiny \\bf (a)}\n\\put(-53,-0){{\\tiny Time}}\n\\put(-100,35){{\\tiny \\rotatebox{90}{Space}}}\n\n\\includegraphics[height=2.9cm]{./figures/simple_example_2.eps}\n\n\\put(-53,65){\\tiny \\bf (b)}\n\\put(-53,-0){{\\tiny Time}}\n\\put(-100,35){{\\tiny \\rotatebox{90}{Space}}}\n\\\\\n\n\\includegraphics[height=2.9cm]{./figures/simple_example_3.eps}\n\n\\put(-53,65){\\tiny \\bf (c)}\n\\put(-53,18){{\\color{blue} \\tiny $A_1$}}\n\\put(-73,38){{\\color{blue} \\tiny $A_2$}}\n\\put(-53,28){{\\color{red} \\tiny $B_2$}}\n\\put(-53,38){{\\color{red} \\tiny $B_1$}}\n\\put(-53,-0){{\\tiny Time}}\n\\put(-100,35){{\\tiny \\rotatebox{90}{Space}}}\n\n\\includegraphics[height=2.9cm]{./figures/simple_example_4.eps}\n\n\\put(-53,65){\\tiny \\bf (d)}\n\\put(-53,-0){{\\tiny Time}}\n\\put(-80,60){{\\color{blue} \\tiny $A_1$}}\n\\put(-80,27){{\\color{blue} \\tiny $A_2$}}\n\\put(-53,52){{\\color{red} \\tiny $B_1$}}\n\\put(-53,30){{\\color{red} \\tiny $B_2$}}\n\\put(-23,46){{\\color{green} \\tiny $C_1$}}\n\\put(-23,36){{\\color{green} \\tiny $C_2$}}\n\\put(-100,35){{\\tiny \\rotatebox{90}{Space}}}\n\n\\vspace{-0.2cm}\n\\caption{Scenarios where defining $\\mathcal{D}(A,B)$ is intuitive. The red cross markers {\\color{red} $\\times$} are the trajectories from $B$, the blue circle markers {\\color{blue} $\\circ$} are the trajectories from $A$ and\nthe green square markers {\\color{green} $\\Box$} from $C$.}\n\\vspace{-0.6cm}\n\\label{fig:simple_examples_about_metric}\n\\end{center}\n\\end{figure}\n\n\n\n{\\bf Scenario 1:} In Fig. \\ref{fig:simple_examples_about_metric}-(a) the set $A$ has only\none trajectory $\\{(1,-1.0)$, $(2,-0.6)$, $(3,-0.2)$,\n$(4,0.2)$, $(5,0.6)$, $(6,1.0)\\}$\nand the set $B$ has only one trajectory $\\{(1,-0.9)$, $(2,-0.54)$, $(3,-0.18)$,\n$(4,0.18)$, $(5,0.54)$, $(6,0.9)\\}$.\nOne intuitive way to define \n$\\mathcal{D}(A,B)$ in this case is to form the vectors $[-1.0$, $-0.6$, $-0.2$, $0.2$, $0.6$, $1.0]$\nand $[-0.9$, $-0.54$, $-0.18$, $0.18$,$0.54$, $0.9]$ and compute the sum of the distances between each of their components. This gives\n$\\mathcal{D}(A,B) = 0.36$.\nMore generally, we can use any vector norm between these two vectors\nand, as long as both $A$ and $B$ only have one trajectory of equal length, this procedure defines a metric, \n", "index": 1, "text": "$$\\mathcal{D}(A,B)  = \\|A-B\\|,$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{D}(A,B)=\\|A-B\\|,\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>\u2225</mo><mrow><mi>A</mi><mo>-</mo><mi>B</mi></mrow><mo>\u2225</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\n{\\bf Scenario 3:} For Fig. \\ref{fig:simple_examples_about_metric}-(c) we cannot define $\\mathcal{D}(A,B)$ as easily as in Scenario 1 and 2 because $A$ and $B$ have multiple trajectories. We can try the same approach and reduce $\\mathcal{D}$ to a norm in a vector space by (a) writing $A$ as \nthe concatenation of \n$A_1 = [-0.90,-0.78,-0.66,-0.54,-0.42,-0.30]$ and $A_2 = [-0.7, -0.42, -0.14, 0.14, 0.42, 0.70]$ and (b) writing\n$B$ as the concatenation of $B_1 = [-1.00, -0.64, -0.28, 0.08, 0.44, 0.80]$ and $B_2 = [-0.60,-0.56, -0.52, -0.48, -0.44,-0.40]$ and (c) computing the total distance between the components of the vectors $A$ and $B$ thus formed. However, this procedure\nis not well defined because if we\nconcatenate $[A_1,A_2]$ and $[B_1,B_2]$ we get $\\mathcal{D}(A,B) = 6.40$ and if we concatenate\n$[A_2,A_1]$ and $[B_1,B_2]$\nwe get $\\mathcal{D}(A,B) = 1.68$.\n\nEffectively we have defined $\\mathcal{D}(A,B)$ by\ncomparing each trajectory in $A$ against one trajectory in $B$ but since $A$ and $B$ are unordered sets we do not know if we should compare $A_1$ with $B_1$ or with $B_2$.\n\nOne way to resolve this ambiguity is to choose the smallest\nof the values computed, $1.68$ in our example. That is,\nwe choose the most favorable comparison between trajectories.\nThe authors in\n\\cite{ristic2011metric} show that\nthis procedure\nresults in a metric. In this paper we call this metric\nOSPA because it is basically an extension of the OSPA\nmetric of \\cite{schuhmacher2008consistent}\nfrom $A$ and $B$ being sets of points to $A$ and $B$ being sets of trajectories.\n\nTo write a general expression for OSPA we first extend $A$ and $B$ such that each have $m$ trajectories of length $T$. First we make all trajectories have the same length $T$ by padding them with state-time pairs $(*,t)$.\nPadded trajectories are represented by $A^+_i$ and $B^+_i$. Afterwards, if $A$ has $k$ trajectories and $B$ has $l$ trajectories we extend $A$ to\n$A^+ = \\{A^+_1,...,A^+_k,A^+_{k+1},...,A^+_m \\}$\nand we extend $B$ to $B^+ = \\{B^+_1,...,B^+_l,B^+_{l+1},...,B^+_m\\}$ where $m = k + l$ and \nwhere the extra trajectories $A^+_i$, $i > k$, and $B^+_i$, $i > l$, are all of the\nkind $\\{(1,*),...,(T,*)\\}$. We write the set of all extended trajectories as $\\mathcal{T}^+$. Let $\\Pi$ be the set of all\npermutations of $[m] \\equiv \\{1,...,m\\}$.\nWe represent any $\\sigma \\in \\Pi$ as an ordered set\n$(\\sigma_1,...,\\sigma_{m})$ where $\\sigma_i \\in [m]$. \n\n\\begin{definition}\nThe OSPA metric is defined as\n\n", "itemtype": "equation", "pos": 9965, "prevtext": "\nwhere $A$ and $B$ on the right hand side are\nthe vector representation of the trajectories $A$ and $B$.\n\n{\\bf Scenario 2:} In Fig. \\ref{fig:simple_examples_about_metric}-(b) the sets $A$ and $B$\nstill only have one trajectory but now the trajectories have ``holes''. To define $\\mathcal{D}$ for this scenario we can reduce it to Scenario $1$ by \ncomputing the total distance\nbetween each of the components of the vectors $[-1.0$, *, $-0.2$, $0.2$, $0.6$, $*]$\nand $[*$, $-0.54$, $-0.18$, $0.18$,$0.54$, $*]$ and using the\nrule that $|x - *| = M > 0$ if $x \\in \\mathbb{R}$ and that $| * - *| = 0$.\nFor example, if $M = 0.1$ we get $\\mathcal{D}(A,B) = 0.3$.\nWe can interpret the symbol * as total \nuncertainty in a tracker $A$\nregarding the position of an object $B$ at a particular point in time, in which case we penalize its performance by a fixed amount. If tracker $A$ outputs * because the object $B$ does not exist in that time instant (e.g. it is outside the tracker's range) we do not penalize its performance, hence\n$|* - * | = 0$.\n\nMore generally, let $A^+ = [...,A^+(t),...]$ and $B^+ = [...,B^+(t),...]$ be the vector representation of the single trajectories in $A$ and $B$, now with each point living in $\\mathbb{R}^p$, and padded with the symbol $*$ and let \n$d^+:\\mathbb{R}^p\\cup\\{*\\} \\times \\mathbb{R}^p\\cup\\{*\\} \\mapsto \\mathbb{R}$ be\nan extension of some point-wise\nmetric $d:\\mathbb{R}^p \\times \\mathbb{R}^p \\mapsto \\mathbb{R}$\nsuch that for every\n$x,y \\in \\mathbb{R}$ we have $d^+(x,y) = \\min\\{2M,d(x,y)\\}$, \n$d^+(x,*)= d^+(*,x)= M > 0$ and $d^+(*,*) = 0$. \nOne can show that $d^+$ is a metric (c.f. Lemma \\ref{th:extdismetric} in Appendix \\ref{app:proof_of_th_d_nat_is_metric}) and hence so is\n\n", "index": 3, "text": "$$\\mathcal{D}(A,B) = \\sum_t d^+(A^+(t),B^+(t)).$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{D}(A,B)=\\sum_{t}d^{+}(A^{+}(t),B^{+}(t)).\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>t</mi></munder><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>A</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msup><mi>B</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\\end{definition}\n\n\nThis metric requires\na procedure to match trajectories in $A$ with trajectories in $B$ for comparison and matching (parts of) trajectories is also a central theme in our paper. Indeed, early on researchers identified finding such a match as a central task in defining a metric for sets of trajectories \\cite{fridling1991performance, drummond1992ambiguities}.\n\nIn the context of computer vision tracking it is important that $A$ and $B$ are extended to have have $m = l+k$ trajectories each. Let $A$ be the ground-truth trajectories and $B$ be the tracker's reconstructed trajectories. We can match any of the $k$ original trajectories in $A$ to a trajectory $B^+_i = \\{(1,*),...,(T,*)\\}$, $i > l$, to represent that the tracker missed a trajectory completely and we can match any of the $l$ original trajectories in $B$ to a trajectory $A^+_i = \\{(1,*),...,(T,*)\\}$, $i > k$, to represent the tracker producing a spurious trajectory.\n\nThe next scenario shows why OSPA-based metrics can be uninformative\nin practice.\n\n\n\n{\\bf Scenario 4:} For the scenario in Fig. \\ref{fig:simple_examples_about_metric}-(d), we cannot use an OSPA-based metric to obtain a $\\mathcal{D}(A,B)$ that is practical in applications such as performance evaluation in computer vision tracking. Indeed, if we use a procedure that matches full-trajectories to full-trajectories as described in Scenario 3, and after we \ncompute the sum of the absolute values of the difference between components of the matched trajectories, we obtain a value of $\\mathcal{D}(A,B) = 7.2$. We obtain this value regardless of whether\nwe compare $A_1= \\{(1,1.00)$, $(2, 0.60)$, $(3, 0.20)$, $(4, -0.20)$,\n$(5, -0.60)$, $(6, -1.00)\\}$  with $B_1= \\{(1,1.00)$, $(2, 0.60)$, $(3, 0.20)$, $(4, 0.20)$, $(5, 0.60)$ and\n$A_2 = \\{(1,-1.00)$, $(2, -0.60)$, $(3, -0.20)$,\n$(4, 0.20)$, $(5, 0.60)$, $(6, 1.00)\\}$ with $B_2 = \\{(1,-1.00)$, $(2, -0.60)$, $(3, -0.20)$, $(4, -0.20)$,\n$(5, -0.60)$, $(6, -1.00)\\}$, or we compare $A_1$ with $B_2$ and\n$A_2$ with $B_1$. Note however that if we compute\n$\\mathcal{D}(A,C)$ or $\\mathcal{D}(B,C)$, where $C$ is\nan object that is stopped at position $0$, we also get $7.2$.\n\nIf we interpret\n$A$ as the trajectories of two objects and $B$ and $C$ as the output\nof two different trackers, the OSPA-based metric is saying that the trackers\nare equally good, yet, most people would probably resist equating both\nbecause the tracker that outputs $B$ is actually doing a good job at\nestimating positions but simply makes one confusion of identity of the objects $A_1$ and $A_2$ as they pass by\neach while the other tracker miss estimates the objects' positions \nall the time.\n\nOSPA-based metrics tend to over penalize the quality of a tracker in\nall situations like in Fig. \\ref{fig:simple_examples_about_metric}-(d) where one trajectory in $A$ follows closely one trajectory in $B$ but later follows another trajectory in$B$. When this happens we say we have an \\emph{\\bf identity switch} and the fact\nthat OSPA-based metrics cannot deal\nwith identity switches makes then\nuseless in many important applications.\n\nFor example, imagine that we are tracking hundreds of bats, just like the authors\n\\cite{betke2007tracking,betke2008thermal,wu2009tracking} did, and we use a tracker that has the impressive ability to simultaneously track all the bats flying around a cave very accurately for many minutes. Only once in a while the tracker confuses the identity of two bats that pass by very close to each other. According to OSPA, the performance of this tracker is very poor. However, probably most people agree that its performance is above that of most existing trackers.\n\nIt is because of examples as the above that the computer vision\ntracking community mostly uses\nmeasures of closeness like\nthe CLEAR MOT to assess\ntracking performance. The CLEAR\nMOT are in fact two measure of closeness, MOTP and MOTA. Although they are not a metric, they do allow to distinguish good trackers from the bad trackers in realistic scenarios. In particular, they allow the user to control how much\nidentity switches should penalize the value of\n$\\mathcal{D}(A,B)$.\n\nThe main idea behind the CLEAR MOT is to use a simple heuristic to\nmatch \\emph{parts} of trajectories in $A$ \\emph{to parts} of trajectories in $B$ instead of matching full\ntrajectories in $A$ to full trajectories in $B$ like in the OSPA-base metrics.\nLet $\\Pi^T$ be the set of all  sequences of length $T$ of permutations of $[m]$ objects. In other words, if $\\Sigma \\in \\Pi^T$ then\n$\\Sigma = (\\sigma(1),\\sigma(2),...,\\sigma(T))$ where $\\sigma(t) \\in \\Pi, \\forall t$. The CLEAR MOT heuristic\nsequentially builds a sequence $\\Sigma_{\\text{MOT}} = (\\sigma_{{\\text{MOT}}}(1),\\sigma_{{\\text{MOT}}}(2),...,\\sigma_{{\\text{MOT}}}(T)) \\in \\Pi^T$\nin such a way that $\\mathcal{D}(A,B)$, as defined in Definition \\ref{def:MOT_metric}, is small and at the same time the number of times $\\sigma(t)$ is different from $\\sigma(t+1)$ is also small.\n\n\\begin{definition}\\label{def:MOT_metric}\nThe CLEAR MOT's distance measure for evaluating tracking precision is called MOTP and is defined as \n\n", "itemtype": "equation", "pos": 12501, "prevtext": "\n\n{\\bf Scenario 3:} For Fig. \\ref{fig:simple_examples_about_metric}-(c) we cannot define $\\mathcal{D}(A,B)$ as easily as in Scenario 1 and 2 because $A$ and $B$ have multiple trajectories. We can try the same approach and reduce $\\mathcal{D}$ to a norm in a vector space by (a) writing $A$ as \nthe concatenation of \n$A_1 = [-0.90,-0.78,-0.66,-0.54,-0.42,-0.30]$ and $A_2 = [-0.7, -0.42, -0.14, 0.14, 0.42, 0.70]$ and (b) writing\n$B$ as the concatenation of $B_1 = [-1.00, -0.64, -0.28, 0.08, 0.44, 0.80]$ and $B_2 = [-0.60,-0.56, -0.52, -0.48, -0.44,-0.40]$ and (c) computing the total distance between the components of the vectors $A$ and $B$ thus formed. However, this procedure\nis not well defined because if we\nconcatenate $[A_1,A_2]$ and $[B_1,B_2]$ we get $\\mathcal{D}(A,B) = 6.40$ and if we concatenate\n$[A_2,A_1]$ and $[B_1,B_2]$\nwe get $\\mathcal{D}(A,B) = 1.68$.\n\nEffectively we have defined $\\mathcal{D}(A,B)$ by\ncomparing each trajectory in $A$ against one trajectory in $B$ but since $A$ and $B$ are unordered sets we do not know if we should compare $A_1$ with $B_1$ or with $B_2$.\n\nOne way to resolve this ambiguity is to choose the smallest\nof the values computed, $1.68$ in our example. That is,\nwe choose the most favorable comparison between trajectories.\nThe authors in\n\\cite{ristic2011metric} show that\nthis procedure\nresults in a metric. In this paper we call this metric\nOSPA because it is basically an extension of the OSPA\nmetric of \\cite{schuhmacher2008consistent}\nfrom $A$ and $B$ being sets of points to $A$ and $B$ being sets of trajectories.\n\nTo write a general expression for OSPA we first extend $A$ and $B$ such that each have $m$ trajectories of length $T$. First we make all trajectories have the same length $T$ by padding them with state-time pairs $(*,t)$.\nPadded trajectories are represented by $A^+_i$ and $B^+_i$. Afterwards, if $A$ has $k$ trajectories and $B$ has $l$ trajectories we extend $A$ to\n$A^+ = \\{A^+_1,...,A^+_k,A^+_{k+1},...,A^+_m \\}$\nand we extend $B$ to $B^+ = \\{B^+_1,...,B^+_l,B^+_{l+1},...,B^+_m\\}$ where $m = k + l$ and \nwhere the extra trajectories $A^+_i$, $i > k$, and $B^+_i$, $i > l$, are all of the\nkind $\\{(1,*),...,(T,*)\\}$. We write the set of all extended trajectories as $\\mathcal{T}^+$. Let $\\Pi$ be the set of all\npermutations of $[m] \\equiv \\{1,...,m\\}$.\nWe represent any $\\sigma \\in \\Pi$ as an ordered set\n$(\\sigma_1,...,\\sigma_{m})$ where $\\sigma_i \\in [m]$. \n\n\\begin{definition}\nThe OSPA metric is defined as\n\n", "index": 5, "text": "$$\\mathcal{D}(A,B) = \\min_{\\sigma \\in \\Pi} \\sum_{i,t} d^+(A^+_i(t),B^+_{\\sigma_i}(t)).$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{D}(A,B)=\\min_{\\sigma\\in\\Pi}\\sum_{i,t}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma%&#10;_{i}}(t)).\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mi>min</mi><mrow><mi>\u03c3</mi><mo>\u2208</mo><mi mathvariant=\"normal\">\u03a0</mi></mrow></munder><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></munder><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\\end{definition}\n\nThe heuristic focuses on simplicity\nto guarantee that we can\ncompute $\\mathcal{D}(A,B)$ fast.\n\nUnfortunately, at the expense of being computable,\nit inherits serious limitations as we explain in Section \n\\ref{sec:limitations_MOT}.\n\nIt also depends on a user-defined parameter $thr$\nthat controls how easily $\\sigma_{\\text{MOT}}(t)$ changes  from one time instant to the other. Intuitively, $thr$ allows the user to say\nhow close two objects must be for MOTP to have confidence that they should be compared.\n\n\\begin{definition}\\label{def:MOT_association}\nThe CLEAR MOT matching heuristic defines $\\Sigma_{\\text{MOT}}$ sequentially as follows.\n\n\\begin{enumerate}\n\\item Initialize $\\sigma_{\\text{MOT}}(1)$ such that\n$\\sum_{i} d^+(A^+_i(1),B^+_{\\sigma_{\\text{MOT}_i}(1)}(1))$\nis minimal;\n\\item For each $t>1$ do: for all $i,j\\in[m]$ such that\n$\\sigma_{\\text{MOT}_i}(t-1)=j$ and\n$d^+(A^+_i(t),B^+_{j}(t)) < thr$ fix\n$\\sigma_{\\text{MOT}_i}(t)=j$. We call such matches as \\emph{\\bf anchored}. Define\nthe non-fixed components of $\\sigma_{\\text{MOT}}(t)$ such that\n$\\sum_{i} d^+(A^+_i(t),B^+_{\\sigma_{\\text{MOT}_i}(t)}(t))$ is\nminimal.\n\\end{enumerate}\n\n\\end{definition}\n\n\nWhat is the value of MOTP for an example like in Fig. \\ref{fig:simple_examples_about_metric}-(d) if $thr = 0.19$? First we need to compute $\\Sigma_{\\text{MOT}}$. Let us focus on the pair $A$ and $B$. For $t=1$ we minimize distance by matching $A_1$ to $B_1$ and $A_2$ to $B_2$. This is mathematically equivalent to setting $\\sigma_{\\text{MOT}}(1) = (1,2)$. For $t=2$ the previous association is anchored because $d^+(A^+_1(1),B^+_{\\sigma_{\\text{MOT}_1}(1)}(1)) = d^+(A^+_2(1),B^+_{\\sigma_{\\text{MOT}_2}(1)}(1)) = 0 < thr$\nand so $\\sigma_{\\text{MOT}}(2) = (1,2)$. The same happens for $t=3$. For $t=4$ the previous association cannot be anchored because that would lead to distances larger than $thr$ so we need to re-minimize the distance. This leads to $\\sigma_{\\text{MOT}}(4) = (2,1)$. For $t=5$ and $t=6$ this association is anchored. In short, we get $\\Sigma_{\\text{MOT}} = ((1,2),(1,2),(1,2),(2,1),(2,1),(2,1))$. Using this value we compute $\\mathcal{D}(A,B) = 0$. We also get $\\mathcal{D}(A,C) = \\mathcal{D}(B,C) = 7.2$. In other words, MOTP says that, apart from an identity switch, tracker $B$ is better than tracker $C$, which is the intuitive answer we expect.\n\n\nRecall that, as we said before, although MOTP\ndefines a measure of closeness between sets of trajectories that is\nuseful, it is mathematically inconsistent. In other words, there\nis still no measure that\nis both mathematically consistent\nand useful in measuring the distance\nbetween sets of multiple trajectories.\nOur main contribution is to show how to capture all the good properties of\nall the definitions above, and none of their limitations, by using a definition of the form\n\n\n", "itemtype": "equation", "pos": 17711, "prevtext": "\n\\end{definition}\n\n\nThis metric requires\na procedure to match trajectories in $A$ with trajectories in $B$ for comparison and matching (parts of) trajectories is also a central theme in our paper. Indeed, early on researchers identified finding such a match as a central task in defining a metric for sets of trajectories \\cite{fridling1991performance, drummond1992ambiguities}.\n\nIn the context of computer vision tracking it is important that $A$ and $B$ are extended to have have $m = l+k$ trajectories each. Let $A$ be the ground-truth trajectories and $B$ be the tracker's reconstructed trajectories. We can match any of the $k$ original trajectories in $A$ to a trajectory $B^+_i = \\{(1,*),...,(T,*)\\}$, $i > l$, to represent that the tracker missed a trajectory completely and we can match any of the $l$ original trajectories in $B$ to a trajectory $A^+_i = \\{(1,*),...,(T,*)\\}$, $i > k$, to represent the tracker producing a spurious trajectory.\n\nThe next scenario shows why OSPA-based metrics can be uninformative\nin practice.\n\n\n\n{\\bf Scenario 4:} For the scenario in Fig. \\ref{fig:simple_examples_about_metric}-(d), we cannot use an OSPA-based metric to obtain a $\\mathcal{D}(A,B)$ that is practical in applications such as performance evaluation in computer vision tracking. Indeed, if we use a procedure that matches full-trajectories to full-trajectories as described in Scenario 3, and after we \ncompute the sum of the absolute values of the difference between components of the matched trajectories, we obtain a value of $\\mathcal{D}(A,B) = 7.2$. We obtain this value regardless of whether\nwe compare $A_1= \\{(1,1.00)$, $(2, 0.60)$, $(3, 0.20)$, $(4, -0.20)$,\n$(5, -0.60)$, $(6, -1.00)\\}$  with $B_1= \\{(1,1.00)$, $(2, 0.60)$, $(3, 0.20)$, $(4, 0.20)$, $(5, 0.60)$ and\n$A_2 = \\{(1,-1.00)$, $(2, -0.60)$, $(3, -0.20)$,\n$(4, 0.20)$, $(5, 0.60)$, $(6, 1.00)\\}$ with $B_2 = \\{(1,-1.00)$, $(2, -0.60)$, $(3, -0.20)$, $(4, -0.20)$,\n$(5, -0.60)$, $(6, -1.00)\\}$, or we compare $A_1$ with $B_2$ and\n$A_2$ with $B_1$. Note however that if we compute\n$\\mathcal{D}(A,C)$ or $\\mathcal{D}(B,C)$, where $C$ is\nan object that is stopped at position $0$, we also get $7.2$.\n\nIf we interpret\n$A$ as the trajectories of two objects and $B$ and $C$ as the output\nof two different trackers, the OSPA-based metric is saying that the trackers\nare equally good, yet, most people would probably resist equating both\nbecause the tracker that outputs $B$ is actually doing a good job at\nestimating positions but simply makes one confusion of identity of the objects $A_1$ and $A_2$ as they pass by\neach while the other tracker miss estimates the objects' positions \nall the time.\n\nOSPA-based metrics tend to over penalize the quality of a tracker in\nall situations like in Fig. \\ref{fig:simple_examples_about_metric}-(d) where one trajectory in $A$ follows closely one trajectory in $B$ but later follows another trajectory in$B$. When this happens we say we have an \\emph{\\bf identity switch} and the fact\nthat OSPA-based metrics cannot deal\nwith identity switches makes then\nuseless in many important applications.\n\nFor example, imagine that we are tracking hundreds of bats, just like the authors\n\\cite{betke2007tracking,betke2008thermal,wu2009tracking} did, and we use a tracker that has the impressive ability to simultaneously track all the bats flying around a cave very accurately for many minutes. Only once in a while the tracker confuses the identity of two bats that pass by very close to each other. According to OSPA, the performance of this tracker is very poor. However, probably most people agree that its performance is above that of most existing trackers.\n\nIt is because of examples as the above that the computer vision\ntracking community mostly uses\nmeasures of closeness like\nthe CLEAR MOT to assess\ntracking performance. The CLEAR\nMOT are in fact two measure of closeness, MOTP and MOTA. Although they are not a metric, they do allow to distinguish good trackers from the bad trackers in realistic scenarios. In particular, they allow the user to control how much\nidentity switches should penalize the value of\n$\\mathcal{D}(A,B)$.\n\nThe main idea behind the CLEAR MOT is to use a simple heuristic to\nmatch \\emph{parts} of trajectories in $A$ \\emph{to parts} of trajectories in $B$ instead of matching full\ntrajectories in $A$ to full trajectories in $B$ like in the OSPA-base metrics.\nLet $\\Pi^T$ be the set of all  sequences of length $T$ of permutations of $[m]$ objects. In other words, if $\\Sigma \\in \\Pi^T$ then\n$\\Sigma = (\\sigma(1),\\sigma(2),...,\\sigma(T))$ where $\\sigma(t) \\in \\Pi, \\forall t$. The CLEAR MOT heuristic\nsequentially builds a sequence $\\Sigma_{\\text{MOT}} = (\\sigma_{{\\text{MOT}}}(1),\\sigma_{{\\text{MOT}}}(2),...,\\sigma_{{\\text{MOT}}}(T)) \\in \\Pi^T$\nin such a way that $\\mathcal{D}(A,B)$, as defined in Definition \\ref{def:MOT_metric}, is small and at the same time the number of times $\\sigma(t)$ is different from $\\sigma(t+1)$ is also small.\n\n\\begin{definition}\\label{def:MOT_metric}\nThe CLEAR MOT's distance measure for evaluating tracking precision is called MOTP and is defined as \n\n", "index": 7, "text": "$$\\mathcal{D}(A,B) = \\sum_{i,t} d^+(A^+_i(t),B^+_{\\sigma_{\\text{MOT}_i}(t)}(t)).$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{D}(A,B)=\\sum_{i,t}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma_{\\text{MOT}_{i}}(t%&#10;)}(t)).\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></munder><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msub><mi>\u03c3</mi><msub><mtext>MOT</mtext><mi>i</mi></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nwhere $\\mathcal{K}: \\Pi^T \\mapsto \\mathbb{R}$ is a function that\npenalizes $\\sigma(t)$ changing with time. With this we fill an important gap in the literature,\n\nMore comprehensively, our contribution is the following:\n\n\\begin{enumerate}\n\\item We show that the CLEAR MOT association heuristic can be unintuitive;\n\\item We show that MOTP does not define a mathematical metric;\n\\item We use \\eqref{eq:slopydefDnat}\nto define a similarity measure that we prove is a metric and that deals with identity switches optimally;\n\\item We modify \\eqref{eq:slopydefDnat} to define the first similarity measure that is fast to compute, is a metric, and is useful in practice;\n\\end{enumerate}\n \n\nWe now present each of our contributions in order. We start\nhowever with an extensive literature\nreview  to clearly delineate the gap we will fill.\n\nNote that in this paper we repeatedly make reference to the CLEAR MOT measures and OSPA-based metrics. Not because there are no other metrics beside these two but because\nthey are excellent representatives of the two categories\nin which most the work done in this area falls: similarity\nmeasures that are practical (although even these have problems) but are\nnot a metric and similarity measures that are a metric but are not practical.\n\n\n\n\n\n\\vspace{-0.4cm}\n\\section{Related work} \\label{sec:relwork}\n\nIn this section we review existing work on metrics for sets of trajectories.\nAmong all the work we review we find no similarity measure between\ntwo sets of trajectories $A$ and $B$ that is mathematically consistent (a metric) and, at the same time, is useful and can deal with identity switches (it looks for similarities between parts of trajectories of $A$\nand parts of trajectories of $B$). As we argue in the introduction,\nthese are two desired characteristic that we are the first\nto incorporate and we focus our discussion around them.\n\nSeveral other ideas in the work we review can\nbe easily incorporated into our work and define new metrics\nthat compete with past work beyond these two characteristics.\nThe discussion of these variant metrics is beyond the scope of this paper.\n\nOur work is related to the problem of defining a distance\nbetween two sets $A$ and $B$, a topic too vast to review in this paper.\nIn \\cite{deza2009encyclopedia} the reader can find many of these\ndistances. In this paper, the sets $A$ and $B$ are sets of trajectories, and this limits the scope of our discussion.\nIn the simplest case, when trajectories have only one point/vector,\ntypical definitions involve computing an average of the distance between\nall pairs of elements from $A$ and $B$, e.g. \\cite{fujita2013metrics}, or\nthe sum of distance\nbetween a few pairs of elements from $A$ and $B$ obtained by some\nprocedure that matches elements of $A$ with elements of $B$, e.g.\n\\cite{schuhmacher2008consistent,gardner2014measuring}.\n\nIn general however, each trajectory is composed by a set of vectors indexed\nby time, which limits our discussion even more.\nTo the best of our knowledge the most rigorous works on metrics\nfor sets of trajectories are based on the ideas proposed in  \\cite{schuhmacher2008consistent}.\n\nIn \\cite{schuhmacher2008consistent} the authors propose\na distance between sets of vectors, the optimal sub-pattern\nassignment metric (OSPA), and explain its advantages for evaluating the performance of multi-object filters compared to other distances between sets.\nIn particular, the OSPA metric has better sensitivity to cardinality\ndifferences between sets than the Hausdorff metric and does not lead to complicated interpretations as the optimal mass transfer metric (OMAT)\nthat \\cite{hoffman2004multitarget} propose to address\nthe limitations of the Hausdorff metric. The OSPA metric between\ntwo sets of vectors\nis well defined for any metric between vectors.\n\nAll the spin-offs of \\cite{schuhmacher2008consistent} focus on defining\na metric between two sets of trajectories $A$ and $B$\nfor the purpose of evaluating the\nperformance of tracking algorithms. We recall however\nthat many applications in machine learning and AI apart from tracking\nbenefit if we work with a metric, for example like the ones we define in this paper, rather than a\nsimilarity measure that is not a metric. It is crucial to note that all the\nspin-offs of \\cite{schuhmacher2008consistent} only compare full\ntrajectories in $A$ to full trajectories in $B$ and hence suffer from the\nsame limitations that we describe in Example 4 in the Introduction.\n\n\nThe authors in \\cite{ristic2011metric} define\nthe OSPA-T metric in two steps. In the first step they solve an optimization\nproblem that optimally matches\nfull tracks in $A$ to full tracks in $B$ while taking into account that\ntracks have different lengths and might be incomplete. In the second step,\nthey assign labels to each track based on this match, they compute\nthe OSPA metric for each time instant using a new metric between pair of\nvectors that considers both the vectors' components as well as their labels\nand they sum all the OSPA values across all time instants.\n\nAlthough\nthe optimization problem of the first step defines a\nmetric, \\cite{vu2014new} point out that the full two-step procedure\nthat defines OSPA-T can violate the triangle inequality.\n\n\nThe authors in \\cite{vu2014new} define the OSPAMT\nto be a metric and to be more reliable than OSPA-T\nwhen we evaluate the performance of multi-target tracking algorithms.\nThe OSPAMT metric also computes an optimal match between\nfull trajectories in $A$ and full trajectories in $B$ but\nunlike OSPA-T allows to match one full trajectory in $A$ to \nmultiple full trajectories in $B$ (and vice-versa).\nThe authors make this design choice not to penalize a tracker\nwhen it outputs only one track for two objects that\nmove closely together.\n\n\nSome extensions to OSPA incorporate the uncertainty in the measurements.\nThe Q-OSPA metric defined in \\cite{QOSPA2013}\nincorporates uncertainty by weighting the distance between pairs\nof points by the product of their certainty and by adding a new term\nthat is proportional to the product of the uncertainties. The H-OSPA\nmetric defined in \\cite{nagappa2011incorporating} incorporates\nuncertainty by using OSAP with distributions as elements of\n$A$ and $B$ instead of vectors and using the Hellinger distance between\ndistributions instead of the Euclidean distance between vectors.\n\nThe authors of both works focus only on the simpler case where\nthe sets $A$ and $B$ contain vectors/points and not trajectories.\nHowever, combining their work with that of \\cite{ristic2011metric}\nor \\cite{vu2014new} to obtain a metric between sets of trajectories\nis immediate.\n\n\nThe papers above are fairly recent and\nthe search for similarity measures between sets of trajectories\nthat are a metric is not older. However, researchers in the field of\ncomputer vision have been interested in defining similarly measures\nfor sets of trajectories to evaluate the performance of tracking\nalgorithms much prior to these works. It is impossible to review all\nwork done in this area. Specially because the \nevaluation of the performance of trackers has many challenges other than\nthe problem of defining a similarity measure. See \n\\cite{ellis2002performance,milan2013challenges} for some\nexamples of these other challenges. Nonetheless,\nwe mention a few works and point out ideas\nin them that relate to our problem. We emphasize that\nnone of the following works defines\na metric mathematically.\n\nMost of our paper is about solving the problem of forming a good\nmatch between elements in $A$ and $B$.\nIn \\cite{fridling1991performance}, which is expanded\nin a subsequent paper \\cite{drummond1992ambiguities}, the authors are one of the first\nto identify this as the central problem in defining a similarity measure,\nalthough some of their ideas draw from the much earlier Ph.D. thesis\nof one of the authors \\cite{Drummond75}. They propose a one-to-one\nassociation between the different points of $A$ and $B$ but\nthis association is optimally computed independently every instant and there is no discussion about the number of changes in matching that this might create.\n\nOne of the reasons why the CLEAR MOT metrics are widely\nused is because they create a simple association between\n$A$ and $B$, i.e., the association between $A$ and $B$ does\nnot change often in time. It appears that \\cite{colegrove1996performance}\nis one of the first works that describes how to control the number of association changes when computing a similarity measure. The authors do not\nassociate $A$ and $B$ independently every time instant but rather\nuse a sequential matching procedure that tries to keep the \nassociation from the previous time instant if possible. \nThis is similar to the procedure used in the much more\nrecent CLEAR MOT measures that we discuss in the Introduction.\n\n\nThe association that \\cite{colegrove1996performance} use at every\npoint in time is not one-to-one optimal like in \\cite{fridling1991performance}\nor in the CLEAR MOT, rather the authors use a simple thresholding rule to\nassociate neighboring elements of $A$ and $B$. The idea of using a simple\nthreshold rule to compare $A$ and $B$\nseems to have survived until relatively recent. For example, in \n\\cite{yin2007performance} the authors match a full trajectory in $A$ to\na full trajectory in $B$ if they are close in space for a sufficiently long\ntime interval. The authors in \\cite{bashir2006performance} use a similar\nthresholding method to match $A$ and $B$.\n\n\nShortly after the papers \\cite{fridling1991performance,drummond1992ambiguities}\nsome of the same authors discuss again the problem of associating $A$ and $B$.\nIn \\cite{drummond1999methodologies} they propose four different\nmethods to solve this problem.\nIn the first method, $A$ and $B$ are optimally\nmatched independently at each time instant,\npossibly generating different associations every time instant.\nIn the second method, the association between $A$ and $B$ cannot change with\ntime. This is similar to what happens in the OSPA-based metrics. It creates\nsimple associations but can also\nlead to problems as we discuss in the Introduction. In the third method, the\nauthors allow the association between $A$ and $B$ to change in time\nbut only in special circumstances. Unfortunately, as they point out, this leads\nto a NP-hard problem. Finally, in the fourth method, the authors discuss some ad-hoc ideas to try to minimize the number of changes in association. Some of these ideas resemble the idea used in the CLEAR MOT of keeping the association from the previous time period if possible.\n\n\nNot all challenges in defining a measure of performance for trackers\nare related to defining a similarity measure between trajectories. In addition,\nnot all challenges in defining a similarity measure between trajectories are\nrelated to defining a way to compare and associate the trajectories in $A$ with\nthe trajectories in $B$. Even if we assume $A$ and $B$ are already matched, there is the question of computing some quantity from this\nmatch.\nA typical quantity researchers compute is\nthe sum of the distances\nbetween the different points of matched trajectories, averaged over\nall pairs of matched trajectories. As explained later,\nour metric is a combination of this\nquantity with the number of confusion of identities in the match between\n$A$ and $B$.\n\n\nApart from other distance-related quantities,\nresearchers also compute many quantities that evaluate the quality\nof the match itself. For example, the number of trajectories in $A$ that\ndo not match to any trajectory in $B$ or the number of times in which\nthe match between $A$ and $B$ changes.\n\\cite{rothrock2000performance,gorji2011performance} list many quantities that can be computed to measure the\nsimilarity between $A$ and $B$ and some of these quantities might\nbe useful to define similarity measures for applications outside tracking.\n\n\nIt is worth mentioning a few works that differ from the main stream in this\naspect. One of them is \\cite{pingali1996performance}, where the authors\ndefine a similarity measure based on comparing the occurrence of\nspecial discrete events in $A$ and $B$, and another is \n\\cite{edward2009information}, where the\nauthors propose an information theoretic measure of\nsimilarity between sets of trajectories. Finally, in \\cite{porikli2004trajectory} the authors propose a similarity\nmeasured based on hidden Markov models that does not\nassume that the temporal sampling rates of the trajectories\nare equal.\n\n\n\n\n\\vspace{-0.2cm}\n\\section{The limitations of the CLEAR MOT} \\label{sec:limitations_MOT}\n\nThe CLEAR MOT similarity measures are one of the most commonly\nused measures that are able to associate parts of\ntrajectories of $A$ with parts of trajectories in $B$ such that the sum of the distance between associated points is small and at the same time the association is simple, i.e. does not change often in time. The CLEAR MOT achieve this using the heuristic procedure in Definition \\ref{def:MOT_association}. In Theorem \\ref{th:MOT_inconsistent} we show that this heuristic can be unintuitive and in Theorem \\ref{th:MOPT_no_metric} we show that MOTP is mathematically inconsistent.\n\n\\begin{theorem}\\label{th:MOT_inconsistent}\nFor any $\\Sigma \\in \\Pi^T$ and any $A,B \\in \\mathcal{S}$ without holes and with $m$ trajectories each let $swi(\\Sigma) = \\frac{1}{T-1}\\sum^{T-1}_{t=1} \\mathbb{I}(\\sigma(t) \\neq \\sigma(t+1))$ and $dist(\\Sigma,A,B) = \\frac{1}{T}\\sum^T_{t=1} \\sum^m_{i=1} \\|A_i(t) - B_{\\sigma_i(t)}(t)\\|$.\n\nFor any CLEAR MOT threshold $thr > 0$, there exists $A$, $B$ and $\\Sigma$ such that \n$dist(\\Sigma,A,B) < \\mathcal{O}(1/T)$, $swi(\\Sigma) =0$ and  $dist(\\Sigma_{\\text{MOTP}},A,B) > m\\,thr - \\mathcal{O}(1/T))$.\n\\end{theorem}\n\nIn the context of computer vision tracking the theorem above shows that there are situations in which the average tracking performance gets arbitrarily close to optimal with time while the CLEAR MOT association $\\Sigma_{\\text{MOT}}$ says that it does not. In other words, the CLEAR MOT can be unintuitive.\n\nThe following theorem show that, for any $thr > 0$,\nthe MOTP is mathematically inconsistent.\n\n\\begin{theorem}\\label{th:MOPT_no_metric}\nMOTP is not a metric.\n\\end{theorem}\n\nThe proofs of these two theorems are in Appendix\n\\ref{app:proof_of_th_mota_bad_association}.\n\n\n\n\n\\vspace{-0.2cm}\n\\section{A natural metric for sets of trajectories} \\label{sec:naturalslowmetric}\n\nDespite the large volumes of research about similarity measures\nfor sets of trajectories, largely motivated, at least initially, by the need to\nassess the performance of tracking systems, our work is the first to propose a measure that is both mathematically consistent and practical.\n\nTo build towards our final metric, in this section we define a metric that \\emph{captures the best match\nbetween the parts of trajectories in $A$ and parts of trajectories in $B$\nwhile tacking into account that simple matches are preferred to complex\nones}. As the four scenarios in the introduction suggest, this is a desirable characteristic for a measure of distance and is only partially present in the OSPA and the CLEAR MOT which are representatives of the two currently segregated camps of (a) the consistent metrics and of (b) the practical metrics. Unfortunately the metric we now  define is hard to compute and we need an extra section to modify it and reduce computational complexity.\n\n\nBefore we introduce our metric we introduce some new notation.\n\nWe denote the identity permutation by $I = (1,2,...,m)$. We also define $\\Pi^T$ as all {sequence of permutations} of length $T$. In particular if $\\Sigma \\in \\Pi^T$ then $\\Sigma = (\\sigma(1),\\sigma(2),...,\\sigma(T))$ where\n$\\sigma(t) \\in \\Pi, \\forall t$. Given $\\Sigma \\in \\Pi^T$, we define $\\Sigma^{-1} \\in \\Pi^T$ as $ \\Sigma^{-1} \\equiv (\\sigma(1)^{-1},\\sigma(2)^{-1},...,\\sigma(T)^{-1})$ where $\\sigma(t)^{-1}$ is the inverse permutation of $\\sigma(t)$. In addition, if $\\Sigma' =  (\\sigma'(1),\\sigma'(2),...,\\sigma'(T))\\in \\Pi^T$ is another sequence\nof permutations we define $\\Sigma \\circ \\Sigma'  \\in \\Pi^T$ as $\\Sigma \\circ \\Sigma' \\equiv (\\sigma(1) \\circ \\sigma'(1),...,\\sigma(T) \\circ \\sigma'(T))$\nwhere the symbol $\\circ$ denotes composition of permutations.\n\nWe now introduce a another new definition.\n\n\\begin{definition}\\label{th:property_of_Sigma}\n$\\mathcal{K}: \\Pi^T \\mapsto \\mathbb{R}^+_0$ is a map \nthat satisfies the following three properties\n(i) $\\mathcal{K}(\\Sigma) = 0$ if and only if $\\Sigma$ is\nconstant $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$ for some $\\sigma \\in \\Pi$, (ii) $\\mathcal{K}(\\Sigma^{-1}) = \\mathcal{K}(\\Sigma)$ and (iii) $\\mathcal{K}(\\Sigma \\circ \\Sigma') \\leq \\mathcal{K}(\\Sigma) + \\mathcal{K}(\\Sigma')$.\n\\end{definition}\n\nWe now define a new distance measure.\n\n\\begin{definition}\nThe {\\bf natural distance} between two sets of trajectories\nis a map $\\mathcal{D}_{nat}: \\mathcal{S}\\times\\mathcal{S}\\mapsto\\mathbb{R}^+_0$ such that for any $A,B \\in \\mathcal{S}$\n{\\small\n\n", "itemtype": "equation", "pos": 20630, "prevtext": "\n\\end{definition}\n\nThe heuristic focuses on simplicity\nto guarantee that we can\ncompute $\\mathcal{D}(A,B)$ fast.\n\nUnfortunately, at the expense of being computable,\nit inherits serious limitations as we explain in Section \n\\ref{sec:limitations_MOT}.\n\nIt also depends on a user-defined parameter $thr$\nthat controls how easily $\\sigma_{\\text{MOT}}(t)$ changes  from one time instant to the other. Intuitively, $thr$ allows the user to say\nhow close two objects must be for MOTP to have confidence that they should be compared.\n\n\\begin{definition}\\label{def:MOT_association}\nThe CLEAR MOT matching heuristic defines $\\Sigma_{\\text{MOT}}$ sequentially as follows.\n\n\\begin{enumerate}\n\\item Initialize $\\sigma_{\\text{MOT}}(1)$ such that\n$\\sum_{i} d^+(A^+_i(1),B^+_{\\sigma_{\\text{MOT}_i}(1)}(1))$\nis minimal;\n\\item For each $t>1$ do: for all $i,j\\in[m]$ such that\n$\\sigma_{\\text{MOT}_i}(t-1)=j$ and\n$d^+(A^+_i(t),B^+_{j}(t)) < thr$ fix\n$\\sigma_{\\text{MOT}_i}(t)=j$. We call such matches as \\emph{\\bf anchored}. Define\nthe non-fixed components of $\\sigma_{\\text{MOT}}(t)$ such that\n$\\sum_{i} d^+(A^+_i(t),B^+_{\\sigma_{\\text{MOT}_i}(t)}(t))$ is\nminimal.\n\\end{enumerate}\n\n\\end{definition}\n\n\nWhat is the value of MOTP for an example like in Fig. \\ref{fig:simple_examples_about_metric}-(d) if $thr = 0.19$? First we need to compute $\\Sigma_{\\text{MOT}}$. Let us focus on the pair $A$ and $B$. For $t=1$ we minimize distance by matching $A_1$ to $B_1$ and $A_2$ to $B_2$. This is mathematically equivalent to setting $\\sigma_{\\text{MOT}}(1) = (1,2)$. For $t=2$ the previous association is anchored because $d^+(A^+_1(1),B^+_{\\sigma_{\\text{MOT}_1}(1)}(1)) = d^+(A^+_2(1),B^+_{\\sigma_{\\text{MOT}_2}(1)}(1)) = 0 < thr$\nand so $\\sigma_{\\text{MOT}}(2) = (1,2)$. The same happens for $t=3$. For $t=4$ the previous association cannot be anchored because that would lead to distances larger than $thr$ so we need to re-minimize the distance. This leads to $\\sigma_{\\text{MOT}}(4) = (2,1)$. For $t=5$ and $t=6$ this association is anchored. In short, we get $\\Sigma_{\\text{MOT}} = ((1,2),(1,2),(1,2),(2,1),(2,1),(2,1))$. Using this value we compute $\\mathcal{D}(A,B) = 0$. We also get $\\mathcal{D}(A,C) = \\mathcal{D}(B,C) = 7.2$. In other words, MOTP says that, apart from an identity switch, tracker $B$ is better than tracker $C$, which is the intuitive answer we expect.\n\n\nRecall that, as we said before, although MOTP\ndefines a measure of closeness between sets of trajectories that is\nuseful, it is mathematically inconsistent. In other words, there\nis still no measure that\nis both mathematically consistent\nand useful in measuring the distance\nbetween sets of multiple trajectories.\nOur main contribution is to show how to capture all the good properties of\nall the definitions above, and none of their limitations, by using a definition of the form\n\n\n", "index": 9, "text": "\\begin{align}\\label{eq:slopydefDnat}\n\\mathcal{D}(A,B) \\hspace{-0.1cm}=\\hspace{-0.1cm}\n\\min_{\\Sigma \\in \\Pi^T} \\Big\\{ \\mathcal{K}(\\Sigma) \n\\hspace{-0.1cm}+\\hspace{-0.1cm}\\sum^T_{t=1} \\sum^{m}_{i=1}d^+(A^+_i(t),B^+_{\\sigma_i(t)}(t)) \\Big\\}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{D}(A,B)\\hskip-2.845276pt=\\hskip-2.845276pt\\min_{\\Sigma%&#10;\\in\\Pi^{T}}\\Big{\\{}\\mathcal{K}(\\Sigma)\\hskip-2.845276pt+\\hskip-2.845276pt\\sum^%&#10;{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma_{i}(t)}(t))\\Big{\\}}\" display=\"inline\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo rspace=\"0pt\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0pt\">=</mo><mrow><munder><mi>min</mi><mrow><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2208</mo><msup><mi mathvariant=\"normal\">\u03a0</mi><mi>T</mi></msup></mrow></munder><mo>\u2061</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">{</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a3</mi><mo rspace=\"0pt\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0pt\">+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">}</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n}\n\\end{definition}\n\n\\begin{remark}\\label{rm:scaling_factor}\nThis definition is compatible with scaling the term $\\mathcal{K}(\\Sigma)$ by some constant $\\alpha > 0$. We are not ignoring this possibility but\nsimply put any scaling factor `inside' $\\mathcal{K}$. Indeed, if $\\mathcal{K}(\\Sigma)$ satisfies properties (i), (ii) and (iii) then so does $\\alpha \\mathcal{K}(\\Sigma)$. It is the user's decision to determine, for the application she has in mind, the relative importance of the terms $\\mathcal{K}$ and $d^+$ in \\eqref{eq:defDnat}.\n\\end{remark}\n\n\n\nThis definition is related to the CLEAR MOT measure in the sense that it builds an association between parts of trajectories in $A$ and parts of trajectories in $B$ such that the distance between associated trajectories is small and the association does not change often in time. \nIt is the term $\\mathcal{K}$ in the definition of $\\mathcal{D}_{nat}$ that allows us to control the complexity of the match between the trajectories in $A$ and in $B$. This guarantees that $\\mathcal{D}_{nat}$ is as useful in practice as the CLEAR MOT.\n\nThis definition is related to the OSPA metric regarding mathematical consistency but is much more general. Indeed, we recover the OSPA metric if we confine ourselves to $\\mathcal{K} = \\mathcal{K}_{OSPA}$ defined as\n$\\mathcal{K}_{OSPA}(\\Sigma) = 0$ if $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$ and\n$\\mathcal{K}_{OSPA}(\\Sigma) = \\infty$ otherwise. Using $\\mathcal{K} = \\mathcal{K}_{OSPA}$ forces us to compare full trajectories in $A$ to full trajectories in $B$, something that as we explained in the Introduction, leads to unintuitive results.\n\nStrictly speaking our definition does not define a single measure but a family of measures,one for each choice of $d(.)$ and $\\mathcal{K}(.)$. The following theorem shows that all the measures in this family are a metric. Its proof is in Appendix \\ref{app:proof_of_th_d_nat_is_metric}.\n\n\\begin{theorem} \\label{th:Dnaturalismetric}\nThe map $\\mathcal{D}_{nat}$ is a metric on $\\mathcal{S}$.\n\\end{theorem}\n\n\nA natural choice\nfor $d$ is the Euclidian metric, that is,\n$d(x,x') = \\|x-x'\\|_2$. We now show that several desirable definitions for $\\mathcal{K}$ satisfy\nthe properties in Definition \\ref{th:property_of_Sigma}. In the context of computer vision tracking, all these $\\mathcal{K}$ allow to penalize trackers that generate many identity switches.\n\nPerhaps the most obvious definition is for $\\mathcal{K}$ to count the number of times that the association between $A$ and $B$ changes.\n\n\\begin{theorem}\\label{th:K_count}\nLet $\n\\mathcal{K}_{count}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} \\mathbb{I}(\\sigma(t+1) \\circ \\sigma(t)^{-1} \\neq I)$, $\\alpha > 0$.\n\n$\\mathcal{K}_{count}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\nAnother two desirable choices for $\\mathcal{K}$ are (a) the\nfunction that sums the minimum number of transpositions\nto go from one permutation to the next and (b) the function\nthat sums the number of adjacent transpositions to go\nfrom one permutation to the next.\n\nIn what follows $k_{Cayley}(\\sigma)$ gives the minimum number of transpositions\nto obtain the identity permutation from $\\sigma \\in \\Pi$ and $k_{Kendall}(\\sigma)$ gives the number of adjacent transposition that the\nbubble-sort algorithm performs when sorting $\\sigma$ to obtain the identity permutation. The\nCayley distance can be traced back to \\cite{cayley1849lxxvii} and the Kendall distance to\\cite{kendall1938new}.\n\n\n\\begin{theorem}\\label{th:K_trans}\nLet $\\mathcal{K}_{trans}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} k_{Cayley}(\\sigma(t+1)\\circ\\sigma(t)^{-1})$, $\\alpha > 0$.  $\\mathcal{K}_{trans}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\n\\begin{theorem}\\label{th:K_adjtrans}\nLet $\\mathcal{K}_{adjtrans}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} k_{Kendall}(\\sigma(t+1)\\circ\\sigma(t)^{-1})$, $\\alpha > 0$.  $\\mathcal{K}_{adjtrans}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\nThe proof of Theorems \\ref{th:K_count}, \\ref{th:K_trans} and \\ref{th:K_adjtrans} is in Appendix \\ref{app:proof_for_K_propreties}.\n\nAlthough many intuitive choices for $\\mathcal{K}$ satisfy\nproperties (i), (ii) and (iii) some natural ones to not. For example, given a $\\beta \\geq 1$ we might want to define\n$\\mathcal{K}_{maxcount}$ as\n$\\mathcal{K}_{maxcount}(\\Sigma) = \\mathcal{K}_{count}(\\Sigma)$ if $\\mathcal{K}_{count}(\\Sigma) \\leq \\beta$ and \n$\\mathcal{K}_{maxcount}(\\Sigma) = \\infty$ if $\\mathcal{K}_{count}(\\Sigma) > \\beta$ (we can replace $\\infty$ by some very large number if we want to be technical about the range of $\\mathcal{K}$ being $\\mathbb{R}^+_0$).\nThis $\\mathcal{K}$ basically forces us not to create an association between $A$ and $B$ more complex than a certain amount $\\beta$, something natural to desire.\nThe following is proved in Appendix \\ref{app:necessary_conditions_for_D_nat_metric}.\n\n\\begin{theorem} \\label{th:K_maxcount_not_proper}\n$\\mathcal{K}_{maxcount}$ does not satisfy (iii).\n\\end{theorem}\n\n\nEven if a function $\\mathcal{K}$ violates some of the properties it might still be the case that using that\nfunction in \\eqref{eq:defDnat} defines a metric. However,\nwe often find that from a set of associations\n$\\Sigma$, $\\Sigma'$ that violate some of the three properties in Definition \\ref{th:property_of_Sigma}\nwe can build three set of trajectories $A$, $B$ and $C$\nthat violate some of the properties required of a metric. This is the case, for example, for $\\mathcal{K}_{maxcount}$\nand $d$ the Euclidean metric.\n\n\\begin{theorem} \\label{th:K_maxcount_leads_to_not_metric}\nIf $\\mathcal{K} = \\mathcal{K}_{maxcount}$ and $d$ is the Euclidean distance then equation \\eqref{eq:defDnat} does not define a metric.\n\\end{theorem}\n\nThe proof of this theorem is in Appendix \\ref{app:necessary_conditions_for_D_nat_metric}.\nIn this sense, the conditions in Definition \\ref{th:property_of_Sigma} are both necessary and sufficient for equation \\eqref{eq:defDnat} to be a metric.\n\nSome choices for $d$ and $\\mathcal{K}$\nlead to a metric $\\mathcal{D}_{nat}$ that is easy\nto compute $\\mathcal{D}_{nat}$. For example, if we choose $\\mathcal{K} = \\mathcal{K}_{OSPA}$ and $d$ to be the\nEuclidean distance\nthen $\\mathcal{D}_{nat}$ reduces to OSPA metric which can be solved in polynomial time using, for example, the Hungarian algorithm \\cite{kuhn1955hungarian} (cf. \\cite{schuhmacher2008consistent}).\n\nUnfortunately, many desirable choices for $\\mathcal{K}$ and $d$\nlead to a hard problem. For example, if\n$d$ is the Euclidean distance and\n$\\mathcal{K} = \\mathcal{K}_{count}$ or $\\mathcal{K} = \\mathcal{K}_{Cayley}$ or $\\mathcal{K} = \\mathcal{K}_{Kendall}$\nthen computing $\\mathcal{D}_{nat}$ is related to solving\na multi-dimensional assignment problem that is\nHP-hard \\cite{garey2002computers}.\n\nWe solve this issue in the next section where we \nmodify $\\mathcal{D}_{nat}$ to obtain a new metric that is as easy to compute as solving a linear program (recall that all LPs can be solved in\npolynomial time \\cite{khachiian1979polynomial}).\n\n\n\n\n\\vspace{-0.2cm}\n\\section{A natural and computable metric}\n\nFirst we introduce some notation. Given $A,B \\in \\mathcal{S}$\nwe define $A^+$ and $B^+$ just like in Section \\ref{sec:naturalslowmetric}. We define $T$ and $m$ accordingly.\nGiven $d$ we also define $d^+$ like in Section \\ref{sec:naturalslowmetric}.\nLet $\\mathcal{P}$ be the set of all doubly stochastic matrices, that is,\n$\\mathcal{P} = \\{W \\in \\mathbb{R}^{m \\times m}: \nW^{\\dagger} {\\bf 1} = {\\bf 1},  W {\\bf 1} = {\\bf 1}, 0 \\leq W \\leq 1\\}$.\nLet $\\mathcal{P}^T$ be the set of all sequences of length $T$ of doubly stochastic matrices.\nGiven $A, B \\in \\mathcal{S}$ and $t \\leq T$\nwe define the matrix $D^{AB}(t) \\in \\mathbb{R}^{m \\times m}$ as\n$(D^{AB}(t))_{ij} = d^+(A^+_i(t),B^+_j(t))$. Let $\\|\\|$ be a matrix norm \nthat satisfies the following property\nfor any four matrices $X_1,X_2,Y_1,Y_2 \\in \\mathcal{P}$\n\n\n", "itemtype": "equation", "pos": 37835, "prevtext": "\n\nwhere $\\mathcal{K}: \\Pi^T \\mapsto \\mathbb{R}$ is a function that\npenalizes $\\sigma(t)$ changing with time. With this we fill an important gap in the literature,\n\nMore comprehensively, our contribution is the following:\n\n\\begin{enumerate}\n\\item We show that the CLEAR MOT association heuristic can be unintuitive;\n\\item We show that MOTP does not define a mathematical metric;\n\\item We use \\eqref{eq:slopydefDnat}\nto define a similarity measure that we prove is a metric and that deals with identity switches optimally;\n\\item We modify \\eqref{eq:slopydefDnat} to define the first similarity measure that is fast to compute, is a metric, and is useful in practice;\n\\end{enumerate}\n \n\nWe now present each of our contributions in order. We start\nhowever with an extensive literature\nreview  to clearly delineate the gap we will fill.\n\nNote that in this paper we repeatedly make reference to the CLEAR MOT measures and OSPA-based metrics. Not because there are no other metrics beside these two but because\nthey are excellent representatives of the two categories\nin which most the work done in this area falls: similarity\nmeasures that are practical (although even these have problems) but are\nnot a metric and similarity measures that are a metric but are not practical.\n\n\n\n\n\n\\vspace{-0.4cm}\n\\section{Related work} \\label{sec:relwork}\n\nIn this section we review existing work on metrics for sets of trajectories.\nAmong all the work we review we find no similarity measure between\ntwo sets of trajectories $A$ and $B$ that is mathematically consistent (a metric) and, at the same time, is useful and can deal with identity switches (it looks for similarities between parts of trajectories of $A$\nand parts of trajectories of $B$). As we argue in the introduction,\nthese are two desired characteristic that we are the first\nto incorporate and we focus our discussion around them.\n\nSeveral other ideas in the work we review can\nbe easily incorporated into our work and define new metrics\nthat compete with past work beyond these two characteristics.\nThe discussion of these variant metrics is beyond the scope of this paper.\n\nOur work is related to the problem of defining a distance\nbetween two sets $A$ and $B$, a topic too vast to review in this paper.\nIn \\cite{deza2009encyclopedia} the reader can find many of these\ndistances. In this paper, the sets $A$ and $B$ are sets of trajectories, and this limits the scope of our discussion.\nIn the simplest case, when trajectories have only one point/vector,\ntypical definitions involve computing an average of the distance between\nall pairs of elements from $A$ and $B$, e.g. \\cite{fujita2013metrics}, or\nthe sum of distance\nbetween a few pairs of elements from $A$ and $B$ obtained by some\nprocedure that matches elements of $A$ with elements of $B$, e.g.\n\\cite{schuhmacher2008consistent,gardner2014measuring}.\n\nIn general however, each trajectory is composed by a set of vectors indexed\nby time, which limits our discussion even more.\nTo the best of our knowledge the most rigorous works on metrics\nfor sets of trajectories are based on the ideas proposed in  \\cite{schuhmacher2008consistent}.\n\nIn \\cite{schuhmacher2008consistent} the authors propose\na distance between sets of vectors, the optimal sub-pattern\nassignment metric (OSPA), and explain its advantages for evaluating the performance of multi-object filters compared to other distances between sets.\nIn particular, the OSPA metric has better sensitivity to cardinality\ndifferences between sets than the Hausdorff metric and does not lead to complicated interpretations as the optimal mass transfer metric (OMAT)\nthat \\cite{hoffman2004multitarget} propose to address\nthe limitations of the Hausdorff metric. The OSPA metric between\ntwo sets of vectors\nis well defined for any metric between vectors.\n\nAll the spin-offs of \\cite{schuhmacher2008consistent} focus on defining\na metric between two sets of trajectories $A$ and $B$\nfor the purpose of evaluating the\nperformance of tracking algorithms. We recall however\nthat many applications in machine learning and AI apart from tracking\nbenefit if we work with a metric, for example like the ones we define in this paper, rather than a\nsimilarity measure that is not a metric. It is crucial to note that all the\nspin-offs of \\cite{schuhmacher2008consistent} only compare full\ntrajectories in $A$ to full trajectories in $B$ and hence suffer from the\nsame limitations that we describe in Example 4 in the Introduction.\n\n\nThe authors in \\cite{ristic2011metric} define\nthe OSPA-T metric in two steps. In the first step they solve an optimization\nproblem that optimally matches\nfull tracks in $A$ to full tracks in $B$ while taking into account that\ntracks have different lengths and might be incomplete. In the second step,\nthey assign labels to each track based on this match, they compute\nthe OSPA metric for each time instant using a new metric between pair of\nvectors that considers both the vectors' components as well as their labels\nand they sum all the OSPA values across all time instants.\n\nAlthough\nthe optimization problem of the first step defines a\nmetric, \\cite{vu2014new} point out that the full two-step procedure\nthat defines OSPA-T can violate the triangle inequality.\n\n\nThe authors in \\cite{vu2014new} define the OSPAMT\nto be a metric and to be more reliable than OSPA-T\nwhen we evaluate the performance of multi-target tracking algorithms.\nThe OSPAMT metric also computes an optimal match between\nfull trajectories in $A$ and full trajectories in $B$ but\nunlike OSPA-T allows to match one full trajectory in $A$ to \nmultiple full trajectories in $B$ (and vice-versa).\nThe authors make this design choice not to penalize a tracker\nwhen it outputs only one track for two objects that\nmove closely together.\n\n\nSome extensions to OSPA incorporate the uncertainty in the measurements.\nThe Q-OSPA metric defined in \\cite{QOSPA2013}\nincorporates uncertainty by weighting the distance between pairs\nof points by the product of their certainty and by adding a new term\nthat is proportional to the product of the uncertainties. The H-OSPA\nmetric defined in \\cite{nagappa2011incorporating} incorporates\nuncertainty by using OSAP with distributions as elements of\n$A$ and $B$ instead of vectors and using the Hellinger distance between\ndistributions instead of the Euclidean distance between vectors.\n\nThe authors of both works focus only on the simpler case where\nthe sets $A$ and $B$ contain vectors/points and not trajectories.\nHowever, combining their work with that of \\cite{ristic2011metric}\nor \\cite{vu2014new} to obtain a metric between sets of trajectories\nis immediate.\n\n\nThe papers above are fairly recent and\nthe search for similarity measures between sets of trajectories\nthat are a metric is not older. However, researchers in the field of\ncomputer vision have been interested in defining similarly measures\nfor sets of trajectories to evaluate the performance of tracking\nalgorithms much prior to these works. It is impossible to review all\nwork done in this area. Specially because the \nevaluation of the performance of trackers has many challenges other than\nthe problem of defining a similarity measure. See \n\\cite{ellis2002performance,milan2013challenges} for some\nexamples of these other challenges. Nonetheless,\nwe mention a few works and point out ideas\nin them that relate to our problem. We emphasize that\nnone of the following works defines\na metric mathematically.\n\nMost of our paper is about solving the problem of forming a good\nmatch between elements in $A$ and $B$.\nIn \\cite{fridling1991performance}, which is expanded\nin a subsequent paper \\cite{drummond1992ambiguities}, the authors are one of the first\nto identify this as the central problem in defining a similarity measure,\nalthough some of their ideas draw from the much earlier Ph.D. thesis\nof one of the authors \\cite{Drummond75}. They propose a one-to-one\nassociation between the different points of $A$ and $B$ but\nthis association is optimally computed independently every instant and there is no discussion about the number of changes in matching that this might create.\n\nOne of the reasons why the CLEAR MOT metrics are widely\nused is because they create a simple association between\n$A$ and $B$, i.e., the association between $A$ and $B$ does\nnot change often in time. It appears that \\cite{colegrove1996performance}\nis one of the first works that describes how to control the number of association changes when computing a similarity measure. The authors do not\nassociate $A$ and $B$ independently every time instant but rather\nuse a sequential matching procedure that tries to keep the \nassociation from the previous time instant if possible. \nThis is similar to the procedure used in the much more\nrecent CLEAR MOT measures that we discuss in the Introduction.\n\n\nThe association that \\cite{colegrove1996performance} use at every\npoint in time is not one-to-one optimal like in \\cite{fridling1991performance}\nor in the CLEAR MOT, rather the authors use a simple thresholding rule to\nassociate neighboring elements of $A$ and $B$. The idea of using a simple\nthreshold rule to compare $A$ and $B$\nseems to have survived until relatively recent. For example, in \n\\cite{yin2007performance} the authors match a full trajectory in $A$ to\na full trajectory in $B$ if they are close in space for a sufficiently long\ntime interval. The authors in \\cite{bashir2006performance} use a similar\nthresholding method to match $A$ and $B$.\n\n\nShortly after the papers \\cite{fridling1991performance,drummond1992ambiguities}\nsome of the same authors discuss again the problem of associating $A$ and $B$.\nIn \\cite{drummond1999methodologies} they propose four different\nmethods to solve this problem.\nIn the first method, $A$ and $B$ are optimally\nmatched independently at each time instant,\npossibly generating different associations every time instant.\nIn the second method, the association between $A$ and $B$ cannot change with\ntime. This is similar to what happens in the OSPA-based metrics. It creates\nsimple associations but can also\nlead to problems as we discuss in the Introduction. In the third method, the\nauthors allow the association between $A$ and $B$ to change in time\nbut only in special circumstances. Unfortunately, as they point out, this leads\nto a NP-hard problem. Finally, in the fourth method, the authors discuss some ad-hoc ideas to try to minimize the number of changes in association. Some of these ideas resemble the idea used in the CLEAR MOT of keeping the association from the previous time period if possible.\n\n\nNot all challenges in defining a measure of performance for trackers\nare related to defining a similarity measure between trajectories. In addition,\nnot all challenges in defining a similarity measure between trajectories are\nrelated to defining a way to compare and associate the trajectories in $A$ with\nthe trajectories in $B$. Even if we assume $A$ and $B$ are already matched, there is the question of computing some quantity from this\nmatch.\nA typical quantity researchers compute is\nthe sum of the distances\nbetween the different points of matched trajectories, averaged over\nall pairs of matched trajectories. As explained later,\nour metric is a combination of this\nquantity with the number of confusion of identities in the match between\n$A$ and $B$.\n\n\nApart from other distance-related quantities,\nresearchers also compute many quantities that evaluate the quality\nof the match itself. For example, the number of trajectories in $A$ that\ndo not match to any trajectory in $B$ or the number of times in which\nthe match between $A$ and $B$ changes.\n\\cite{rothrock2000performance,gorji2011performance} list many quantities that can be computed to measure the\nsimilarity between $A$ and $B$ and some of these quantities might\nbe useful to define similarity measures for applications outside tracking.\n\n\nIt is worth mentioning a few works that differ from the main stream in this\naspect. One of them is \\cite{pingali1996performance}, where the authors\ndefine a similarity measure based on comparing the occurrence of\nspecial discrete events in $A$ and $B$, and another is \n\\cite{edward2009information}, where the\nauthors propose an information theoretic measure of\nsimilarity between sets of trajectories. Finally, in \\cite{porikli2004trajectory} the authors propose a similarity\nmeasured based on hidden Markov models that does not\nassume that the temporal sampling rates of the trajectories\nare equal.\n\n\n\n\n\\vspace{-0.2cm}\n\\section{The limitations of the CLEAR MOT} \\label{sec:limitations_MOT}\n\nThe CLEAR MOT similarity measures are one of the most commonly\nused measures that are able to associate parts of\ntrajectories of $A$ with parts of trajectories in $B$ such that the sum of the distance between associated points is small and at the same time the association is simple, i.e. does not change often in time. The CLEAR MOT achieve this using the heuristic procedure in Definition \\ref{def:MOT_association}. In Theorem \\ref{th:MOT_inconsistent} we show that this heuristic can be unintuitive and in Theorem \\ref{th:MOPT_no_metric} we show that MOTP is mathematically inconsistent.\n\n\\begin{theorem}\\label{th:MOT_inconsistent}\nFor any $\\Sigma \\in \\Pi^T$ and any $A,B \\in \\mathcal{S}$ without holes and with $m$ trajectories each let $swi(\\Sigma) = \\frac{1}{T-1}\\sum^{T-1}_{t=1} \\mathbb{I}(\\sigma(t) \\neq \\sigma(t+1))$ and $dist(\\Sigma,A,B) = \\frac{1}{T}\\sum^T_{t=1} \\sum^m_{i=1} \\|A_i(t) - B_{\\sigma_i(t)}(t)\\|$.\n\nFor any CLEAR MOT threshold $thr > 0$, there exists $A$, $B$ and $\\Sigma$ such that \n$dist(\\Sigma,A,B) < \\mathcal{O}(1/T)$, $swi(\\Sigma) =0$ and  $dist(\\Sigma_{\\text{MOTP}},A,B) > m\\,thr - \\mathcal{O}(1/T))$.\n\\end{theorem}\n\nIn the context of computer vision tracking the theorem above shows that there are situations in which the average tracking performance gets arbitrarily close to optimal with time while the CLEAR MOT association $\\Sigma_{\\text{MOT}}$ says that it does not. In other words, the CLEAR MOT can be unintuitive.\n\nThe following theorem show that, for any $thr > 0$,\nthe MOTP is mathematically inconsistent.\n\n\\begin{theorem}\\label{th:MOPT_no_metric}\nMOTP is not a metric.\n\\end{theorem}\n\nThe proofs of these two theorems are in Appendix\n\\ref{app:proof_of_th_mota_bad_association}.\n\n\n\n\n\\vspace{-0.2cm}\n\\section{A natural metric for sets of trajectories} \\label{sec:naturalslowmetric}\n\nDespite the large volumes of research about similarity measures\nfor sets of trajectories, largely motivated, at least initially, by the need to\nassess the performance of tracking systems, our work is the first to propose a measure that is both mathematically consistent and practical.\n\nTo build towards our final metric, in this section we define a metric that \\emph{captures the best match\nbetween the parts of trajectories in $A$ and parts of trajectories in $B$\nwhile tacking into account that simple matches are preferred to complex\nones}. As the four scenarios in the introduction suggest, this is a desirable characteristic for a measure of distance and is only partially present in the OSPA and the CLEAR MOT which are representatives of the two currently segregated camps of (a) the consistent metrics and of (b) the practical metrics. Unfortunately the metric we now  define is hard to compute and we need an extra section to modify it and reduce computational complexity.\n\n\nBefore we introduce our metric we introduce some new notation.\n\nWe denote the identity permutation by $I = (1,2,...,m)$. We also define $\\Pi^T$ as all {sequence of permutations} of length $T$. In particular if $\\Sigma \\in \\Pi^T$ then $\\Sigma = (\\sigma(1),\\sigma(2),...,\\sigma(T))$ where\n$\\sigma(t) \\in \\Pi, \\forall t$. Given $\\Sigma \\in \\Pi^T$, we define $\\Sigma^{-1} \\in \\Pi^T$ as $ \\Sigma^{-1} \\equiv (\\sigma(1)^{-1},\\sigma(2)^{-1},...,\\sigma(T)^{-1})$ where $\\sigma(t)^{-1}$ is the inverse permutation of $\\sigma(t)$. In addition, if $\\Sigma' =  (\\sigma'(1),\\sigma'(2),...,\\sigma'(T))\\in \\Pi^T$ is another sequence\nof permutations we define $\\Sigma \\circ \\Sigma'  \\in \\Pi^T$ as $\\Sigma \\circ \\Sigma' \\equiv (\\sigma(1) \\circ \\sigma'(1),...,\\sigma(T) \\circ \\sigma'(T))$\nwhere the symbol $\\circ$ denotes composition of permutations.\n\nWe now introduce a another new definition.\n\n\\begin{definition}\\label{th:property_of_Sigma}\n$\\mathcal{K}: \\Pi^T \\mapsto \\mathbb{R}^+_0$ is a map \nthat satisfies the following three properties\n(i) $\\mathcal{K}(\\Sigma) = 0$ if and only if $\\Sigma$ is\nconstant $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$ for some $\\sigma \\in \\Pi$, (ii) $\\mathcal{K}(\\Sigma^{-1}) = \\mathcal{K}(\\Sigma)$ and (iii) $\\mathcal{K}(\\Sigma \\circ \\Sigma') \\leq \\mathcal{K}(\\Sigma) + \\mathcal{K}(\\Sigma')$.\n\\end{definition}\n\nWe now define a new distance measure.\n\n\\begin{definition}\nThe {\\bf natural distance} between two sets of trajectories\nis a map $\\mathcal{D}_{nat}: \\mathcal{S}\\times\\mathcal{S}\\mapsto\\mathbb{R}^+_0$ such that for any $A,B \\in \\mathcal{S}$\n{\\small\n\n", "index": 11, "text": "\\begin{align}\\label{eq:defDnat}\n\\mathcal{D}_{nat}(A,B) \\hspace{-0.1cm}=\\hspace{-0.1cm} \\min_{\\Sigma \\in \\Pi^T} \\Big\\{ \\mathcal{K}(\\Sigma)\n+\\sum^T_{t=1} \\sum^{m}_{i=1}d^+(A^+_i(t),B^+_{\\sigma_i(t)}(t)) \\Big\\}. \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{D}_{nat}(A,B)\\hskip-2.845276pt=\\hskip-2.845276pt\\min_{%&#10;\\Sigma\\in\\Pi^{T}}\\Big{\\{}\\mathcal{K}(\\Sigma)+\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}%&#10;(A^{+}_{i}(t),B^{+}_{\\sigma_{i}(t)}(t))\\Big{\\}}.\" display=\"inline\"><mrow><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo rspace=\"0pt\" stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0pt\">=</mo><mrow><munder><mi>min</mi><mrow><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2208</mo><msup><mi mathvariant=\"normal\">\u03a0</mi><mi>T</mi></msup></mrow></munder><mo>\u2061</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">{</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nNote that this is analougous to property (iii) that we use\nfor $\\mathcal{K}$ in Section \\ref{sec:naturalslowmetric}.\n\n\\begin{definition}\nThe {\\bf natural computable distance} between two sets of trajectories\nis a map $\\mathcal{D}_{comp}: \\mathcal{S}\\times\\mathcal{S}\\mapsto\\mathbb{R}^+_0$ such that for any $A,B \\in \\mathcal{S}$\n{\n\n", "itemtype": "equation", "pos": 45930, "prevtext": "\n}\n\\end{definition}\n\n\\begin{remark}\\label{rm:scaling_factor}\nThis definition is compatible with scaling the term $\\mathcal{K}(\\Sigma)$ by some constant $\\alpha > 0$. We are not ignoring this possibility but\nsimply put any scaling factor `inside' $\\mathcal{K}$. Indeed, if $\\mathcal{K}(\\Sigma)$ satisfies properties (i), (ii) and (iii) then so does $\\alpha \\mathcal{K}(\\Sigma)$. It is the user's decision to determine, for the application she has in mind, the relative importance of the terms $\\mathcal{K}$ and $d^+$ in \\eqref{eq:defDnat}.\n\\end{remark}\n\n\n\nThis definition is related to the CLEAR MOT measure in the sense that it builds an association between parts of trajectories in $A$ and parts of trajectories in $B$ such that the distance between associated trajectories is small and the association does not change often in time. \nIt is the term $\\mathcal{K}$ in the definition of $\\mathcal{D}_{nat}$ that allows us to control the complexity of the match between the trajectories in $A$ and in $B$. This guarantees that $\\mathcal{D}_{nat}$ is as useful in practice as the CLEAR MOT.\n\nThis definition is related to the OSPA metric regarding mathematical consistency but is much more general. Indeed, we recover the OSPA metric if we confine ourselves to $\\mathcal{K} = \\mathcal{K}_{OSPA}$ defined as\n$\\mathcal{K}_{OSPA}(\\Sigma) = 0$ if $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$ and\n$\\mathcal{K}_{OSPA}(\\Sigma) = \\infty$ otherwise. Using $\\mathcal{K} = \\mathcal{K}_{OSPA}$ forces us to compare full trajectories in $A$ to full trajectories in $B$, something that as we explained in the Introduction, leads to unintuitive results.\n\nStrictly speaking our definition does not define a single measure but a family of measures,one for each choice of $d(.)$ and $\\mathcal{K}(.)$. The following theorem shows that all the measures in this family are a metric. Its proof is in Appendix \\ref{app:proof_of_th_d_nat_is_metric}.\n\n\\begin{theorem} \\label{th:Dnaturalismetric}\nThe map $\\mathcal{D}_{nat}$ is a metric on $\\mathcal{S}$.\n\\end{theorem}\n\n\nA natural choice\nfor $d$ is the Euclidian metric, that is,\n$d(x,x') = \\|x-x'\\|_2$. We now show that several desirable definitions for $\\mathcal{K}$ satisfy\nthe properties in Definition \\ref{th:property_of_Sigma}. In the context of computer vision tracking, all these $\\mathcal{K}$ allow to penalize trackers that generate many identity switches.\n\nPerhaps the most obvious definition is for $\\mathcal{K}$ to count the number of times that the association between $A$ and $B$ changes.\n\n\\begin{theorem}\\label{th:K_count}\nLet $\n\\mathcal{K}_{count}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} \\mathbb{I}(\\sigma(t+1) \\circ \\sigma(t)^{-1} \\neq I)$, $\\alpha > 0$.\n\n$\\mathcal{K}_{count}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\nAnother two desirable choices for $\\mathcal{K}$ are (a) the\nfunction that sums the minimum number of transpositions\nto go from one permutation to the next and (b) the function\nthat sums the number of adjacent transpositions to go\nfrom one permutation to the next.\n\nIn what follows $k_{Cayley}(\\sigma)$ gives the minimum number of transpositions\nto obtain the identity permutation from $\\sigma \\in \\Pi$ and $k_{Kendall}(\\sigma)$ gives the number of adjacent transposition that the\nbubble-sort algorithm performs when sorting $\\sigma$ to obtain the identity permutation. The\nCayley distance can be traced back to \\cite{cayley1849lxxvii} and the Kendall distance to\\cite{kendall1938new}.\n\n\n\\begin{theorem}\\label{th:K_trans}\nLet $\\mathcal{K}_{trans}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} k_{Cayley}(\\sigma(t+1)\\circ\\sigma(t)^{-1})$, $\\alpha > 0$.  $\\mathcal{K}_{trans}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\n\\begin{theorem}\\label{th:K_adjtrans}\nLet $\\mathcal{K}_{adjtrans}(\\Sigma) = \\alpha \\sum^{T-1}_{t=1} k_{Kendall}(\\sigma(t+1)\\circ\\sigma(t)^{-1})$, $\\alpha > 0$.  $\\mathcal{K}_{adjtrans}$ satisfies Definition \\ref{th:property_of_Sigma}.\n\\end{theorem}\n\n\nThe proof of Theorems \\ref{th:K_count}, \\ref{th:K_trans} and \\ref{th:K_adjtrans} is in Appendix \\ref{app:proof_for_K_propreties}.\n\nAlthough many intuitive choices for $\\mathcal{K}$ satisfy\nproperties (i), (ii) and (iii) some natural ones to not. For example, given a $\\beta \\geq 1$ we might want to define\n$\\mathcal{K}_{maxcount}$ as\n$\\mathcal{K}_{maxcount}(\\Sigma) = \\mathcal{K}_{count}(\\Sigma)$ if $\\mathcal{K}_{count}(\\Sigma) \\leq \\beta$ and \n$\\mathcal{K}_{maxcount}(\\Sigma) = \\infty$ if $\\mathcal{K}_{count}(\\Sigma) > \\beta$ (we can replace $\\infty$ by some very large number if we want to be technical about the range of $\\mathcal{K}$ being $\\mathbb{R}^+_0$).\nThis $\\mathcal{K}$ basically forces us not to create an association between $A$ and $B$ more complex than a certain amount $\\beta$, something natural to desire.\nThe following is proved in Appendix \\ref{app:necessary_conditions_for_D_nat_metric}.\n\n\\begin{theorem} \\label{th:K_maxcount_not_proper}\n$\\mathcal{K}_{maxcount}$ does not satisfy (iii).\n\\end{theorem}\n\n\nEven if a function $\\mathcal{K}$ violates some of the properties it might still be the case that using that\nfunction in \\eqref{eq:defDnat} defines a metric. However,\nwe often find that from a set of associations\n$\\Sigma$, $\\Sigma'$ that violate some of the three properties in Definition \\ref{th:property_of_Sigma}\nwe can build three set of trajectories $A$, $B$ and $C$\nthat violate some of the properties required of a metric. This is the case, for example, for $\\mathcal{K}_{maxcount}$\nand $d$ the Euclidean metric.\n\n\\begin{theorem} \\label{th:K_maxcount_leads_to_not_metric}\nIf $\\mathcal{K} = \\mathcal{K}_{maxcount}$ and $d$ is the Euclidean distance then equation \\eqref{eq:defDnat} does not define a metric.\n\\end{theorem}\n\nThe proof of this theorem is in Appendix \\ref{app:necessary_conditions_for_D_nat_metric}.\nIn this sense, the conditions in Definition \\ref{th:property_of_Sigma} are both necessary and sufficient for equation \\eqref{eq:defDnat} to be a metric.\n\nSome choices for $d$ and $\\mathcal{K}$\nlead to a metric $\\mathcal{D}_{nat}$ that is easy\nto compute $\\mathcal{D}_{nat}$. For example, if we choose $\\mathcal{K} = \\mathcal{K}_{OSPA}$ and $d$ to be the\nEuclidean distance\nthen $\\mathcal{D}_{nat}$ reduces to OSPA metric which can be solved in polynomial time using, for example, the Hungarian algorithm \\cite{kuhn1955hungarian} (cf. \\cite{schuhmacher2008consistent}).\n\nUnfortunately, many desirable choices for $\\mathcal{K}$ and $d$\nlead to a hard problem. For example, if\n$d$ is the Euclidean distance and\n$\\mathcal{K} = \\mathcal{K}_{count}$ or $\\mathcal{K} = \\mathcal{K}_{Cayley}$ or $\\mathcal{K} = \\mathcal{K}_{Kendall}$\nthen computing $\\mathcal{D}_{nat}$ is related to solving\na multi-dimensional assignment problem that is\nHP-hard \\cite{garey2002computers}.\n\nWe solve this issue in the next section where we \nmodify $\\mathcal{D}_{nat}$ to obtain a new metric that is as easy to compute as solving a linear program (recall that all LPs can be solved in\npolynomial time \\cite{khachiian1979polynomial}).\n\n\n\n\n\\vspace{-0.2cm}\n\\section{A natural and computable metric}\n\nFirst we introduce some notation. Given $A,B \\in \\mathcal{S}$\nwe define $A^+$ and $B^+$ just like in Section \\ref{sec:naturalslowmetric}. We define $T$ and $m$ accordingly.\nGiven $d$ we also define $d^+$ like in Section \\ref{sec:naturalslowmetric}.\nLet $\\mathcal{P}$ be the set of all doubly stochastic matrices, that is,\n$\\mathcal{P} = \\{W \\in \\mathbb{R}^{m \\times m}: \nW^{\\dagger} {\\bf 1} = {\\bf 1},  W {\\bf 1} = {\\bf 1}, 0 \\leq W \\leq 1\\}$.\nLet $\\mathcal{P}^T$ be the set of all sequences of length $T$ of doubly stochastic matrices.\nGiven $A, B \\in \\mathcal{S}$ and $t \\leq T$\nwe define the matrix $D^{AB}(t) \\in \\mathbb{R}^{m \\times m}$ as\n$(D^{AB}(t))_{ij} = d^+(A^+_i(t),B^+_j(t))$. Let $\\|\\|$ be a matrix norm \nthat satisfies the following property\nfor any four matrices $X_1,X_2,Y_1,Y_2 \\in \\mathcal{P}$\n\n\n", "index": 13, "text": "\\begin{equation}\\label{eq:propofnormforDcomp}\n\\|Y_2X_2 - X_2X_1\\| \\leq \\|Y_2 - Y_1\\| + \\|X_2 - X_1\\|.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\|Y_{2}X_{2}-X_{2}X_{1}\\|\\leq\\|Y_{2}-Y_{1}\\|+\\|X_{2}-X_{1}\\|.\" display=\"block\"><mrow><mrow><mrow><mo>\u2225</mo><mrow><mrow><msub><mi>Y</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>X</mi><mn>2</mn></msub></mrow><mo>-</mo><mrow><msub><mi>X</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>X</mi><mn>1</mn></msub></mrow></mrow><mo>\u2225</mo></mrow><mo>\u2264</mo><mrow><mrow><mo>\u2225</mo><mrow><msub><mi>Y</mi><mn>2</mn></msub><mo>-</mo><msub><mi>Y</mi><mn>1</mn></msub></mrow><mo>\u2225</mo></mrow><mo>+</mo><mrow><mo>\u2225</mo><mrow><msub><mi>X</mi><mn>2</mn></msub><mo>-</mo><msub><mi>X</mi><mn>1</mn></msub></mrow><mo>\u2225</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n}\n\\end{definition}\n\n\\begin{remark}\nThis definition is compatible with scaling the first term by some constant $\\alpha> 0$. We are not ignoring this possibility but simply put any scaling factor ``inside'' the matrix norm. In Section \\ref{sec:num_res} we solve \\eqref{eq:defDcomp} for different values of $\\alpha$ to obtain a trade-off plot between its two terms.\n\\end{remark}\n\nThe motivation for this definition is to obtain a measure that\nis as similar as possible to $\\mathcal{D}_{nat}$ but that we can compute fast. Just like MOTP and $\\mathcal{D}_{nat}$, the measure $\\mathcal{D}_{comp}$ also builds an association between parts of trajectories in $A$ and parts of trajectories in $B$. This association is represented by the matrices $W(t)$. However, unlike $\\Sigma$ in $\\mathcal{D}_{nat}$, the $W$ matrices also give us a weight/strength for the different matches between $A$ and $B$. Just like $\\mathcal{D}_{nat}$, and as the next theorem shows, $\\mathcal{D}_{comp}$ is also mathematically consistent.\n\n\\begin{theorem} \\label{th:D_comp_is_metric}\nThe map $\\mathcal{D}_{comp}$ is a metric on $\\mathcal{S}$.\n\\end{theorem}\nThe proof of this theorem is in Appendix \\ref{app:proof_that_D_comp_is_metric}.\n\nMost importantly, unlike $\\mathcal{D}_{nat}$, computing $\\mathcal{D}_{comp}$ amounts to solving a convex optimization problem. In short, $\\mathcal{D}_{comp}$ combines all the advantages of OSPA, MOTP and $\\mathcal{D}_{comp}$.\n\n\nThe following Lemma gives sufficient conditions for a metric $\\|.\\|$\nto satisfy property \\eqref{eq:propofnormforDcomp}. See Appendix \\ref{app:proof_that_norms_for_Dcomp_are_many} for a proof.\n\n\\begin{lemma} \\label{th:many_norms_satisfy_D_comp}\nIf $\\|.\\|$ is a sub-multiplicative norm and $\\|W\\| \\leq 1$ for all\n$W \\in \\mathcal{P}$ then $\\|.\\|$ satisfies property \\eqref{eq:propofnormforDcomp}.\n\\end{lemma}\n\nThis lemma implies, for example, that the 1-norm and $\\infty$-norm\nspectral norm for matrices are valid choices for $\\|.\\|$. In particular,\nthe use of $\\|.\\|_1$ in $\\mathcal{D}_{comp}$ is extremely useful\nbecause it induces the changes of association to be sparse in time\nand, as the next theorem shows, it reduces $\\mathcal{D}_{comp}$ to solving a linear program. The theorem's proof is in Appendix \\ref{app:proof_that_D_comp_equals_LP}.\n\n\\begin{theorem} \\label{th:dcompisLP}\nFor any $A, B \\in \\mathcal{S}$, $\\mathcal{D}_{comp}(A,B)$ with\n$\\|.\\|$ equal to the matrix 1-norm can\nbe computed (in polynomial time) by solving a linear program.\n\\end{theorem}\n\n\nThe metric $\\mathcal{D}_{comp}$ allows to consider\na scaling factor $\\alpha$ in front of the term $\\sum_t\\|W(t+1)-W(t)\\|$, which we call the switch term, $swi$. We call the other term the distance term $dist$. Like the $thr$ value in the CLEAR MOT, $\\alpha$ allows us to penalize heavily the error in distances in some applications ($\\alpha = small$); and in other applications allows us to penalize heavily the number of associations switches ($\\alpha = large$). One can\nhowever report how close a set $A \\in \\mathcal{S}$ is from $B \\in \\mathcal{S}$ without choosing a specific $\\alpha$, simply plot the tradeoff curve between $swi$ and $dist$ as a function of $\\alpha$. The closer this curve is to the left/bottom edges of the positive quadrant of the cartesian plane, the closer $A$ to $B$.\n\nThe next theorem shows that the tradeoff curve produced by the two terms of $\\mathcal{D}_{\\text{comp}}$, which we denote by $(swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha),dist_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$, is, in a sense, the best trade-off curve between $dist$ and $swi$\nthat any metric can generate. \nTo state the theorem we need to define the region $\\mathcal{R}$ of pairs of distance-value and switch-value that we can improve upon with some stochastic matrices $\\{W(t)\\}$ produced by some association procedure of some similarity measure. More concretely, $\\mathcal{R} = \\{(dist,swi)\\in\\mathbb{R}^2: swi \\geq \\sum_t \\|W(t+1)-W(t)\\| \\text{ and } dist \\geq \\sum_t \\text{\\bf tr}(W(t)^\\dagger D^{AB}(t)) \\text{ for all } \\{W(t)\\} \\in \\mathcal{P}^T\\}$. The proof of following result is in Appendix \\ref{app:proof_of_optimal_trade_off_curve_for_D_comp}. \n\n\\begin{theorem} \\label{th:optimal_tradeoff}\nIf $(dis, swi) \\in \\text{int}(\\mathcal{R})$ then there exists $\\alpha$, such that $dis + \\alpha swi > dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha) + \\alpha swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha)$.\nIf $(dis, swi) \\in \\partial \\mathcal{R}$ then $(dis, swi)$ is equal to some point in the curve $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ for some $\\alpha$ or is equal to a linear combination of points in the curve.\n\\end{theorem}\n\n\\begin{remark}\nIn the proof of the above theorem we show that\n$\\mathcal{R}$ is convex. Hence, because the boundary of $\\mathcal{R}$ \nis by definition Pareto efficient, this boundary must be a convex non-increasing curve. Since the curve $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ effectively covers this boundary, \nwe can use this property to efficiently estimate the trade-off curve. Basically, we can compute $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ for some discrete set values of $\\alpha$ and then we can take the convex hull of these points.\n\\end{remark}\n\n\\vspace{-0.4cm}\n\\subsection{Computing $\\mathcal{D}_{comp}$ in practice}\n\\label{sec:num_res_run_time}\n\nThere are multiple ways to compute \n$\\mathcal{D}_{comp}$ in practice, all of which amount\nto solving a convex optimization problem. For this paper we coded a solver in C based on the Alternating Direction Method of Multipliers (ADMM) because the ADMM is known to scale well for large problems and its modular nature \nmakes it easy, in future work, for us to research variants of the formulation $\\mathcal{D}_{comp}$ without having to re-write much of our code.\nFor a good introduction to the ADMM, related methods and applications see\\cite{boyd2011distributed}.\nOur implementation is approximately $\\times 50$ faster than using Matlab CVX \\cite{cvx}.\n\nIn Figure \\ref{fig:profilingcodeforDcomp} we show the run-time of our code as a function of the total duration $T$ of the input data for a different number of free association variables $W_{ij}(t)$ per time instant $t$. We use the terminology ``free association variables'' to emphasize that some $W_{ij}(t)$ might be a priory set to zero if the distance between point $i$ and point $j$ at time $t$ is very large, which can save computation time. In the figure we choose the euclidean distance for $d(.,.)$ and the one-norm for matrix norm $\\|.\\|$ in the switch term. Similar run-times hold for other metrics. The run-time is computed for randomly generated sets of trajectories on a single core of a $1.4$GHz Intel Core i5 MacBook Air. In our tests, the ADMM always converged to $1$\\% accuracy in less than $150$ iterations.\n\n\\begin{figure}[b]\n\\vspace{-0.4cm}\n\\begin{center}\n\\includegraphics[trim=0.8cm 0.4cm 0.6cm 0cm, clip=true,height=3.0cm]{./figures/run_time_metric.eps}\n\\put(-105,23){\\rotatebox{90}{\\tiny Run-time (secs)}}\n\\put(-85,-05){\\rotatebox{0}{\\tiny Maximum length of trajectories, $T$}}\n\\put(-80,74){\\rotatebox{0}{\\tiny \\# vars. per instant}}\n\\put(-75,68){\\rotatebox{0}{\\tiny $2.5 \\times 10^3$}}\n\\put(-75,61){\\rotatebox{0}{\\tiny $3.6 \\times 10^3$}}\n\\put(-75,53){\\rotatebox{0}{\\tiny   $4.9 \\times 10^3$}}\n\\put(-75,45){\\rotatebox{0}{\\tiny   $6.4 \\times 10^3$}}\n\\put(-75,38){\\rotatebox{0}{\\tiny   $8.1 \\times 10^3$}}\n\\put(-75,31){\\rotatebox{0}{\\tiny   $10 \\times 10^3$}}\n\\includegraphics[trim=0.8cm 0.4cm 0.8cm 0cm, clip=true,height=3.0cm]{./figures/run_time_metric_function_of_size.eps}\n\\put(-75,74){\\rotatebox{0}{\\tiny Trajectory length, $T$}}\n\\put(-68,68){\\rotatebox{0}{\\tiny $50$}}\n\\put(-68,61){\\rotatebox{0}{\\tiny $250$}}\n\\put(-68,54){\\rotatebox{0}{\\tiny   $450$}}\n\\put(-68,47){\\rotatebox{0}{\\tiny   $650$}}\n\\put(-68,40){\\rotatebox{0}{\\tiny   $850$}}\n\n\\put(-70,-05){\\rotatebox{0}{\\tiny \\# vars. per instant}}\n\\put(-12,-05){\\rotatebox{0}{\\tiny ($\\times 10^3$)}}\n\n\\caption{Time it takes to compute $\\mathcal{D}_{comp}$ (within $1$\\% accuracy) as function of (a) the length of trajectories for a different number of association variables per instant; as a function of (b) the number of association variables per instant for different lengths of trajectories.}\n\\label{fig:profilingcodeforDcomp}\n\\vspace{-0.7cm}\n\\end{center}\n\\end{figure}\n\nTo interpret the plots, imagine you want to evaluate the quality of a tracker when tracking $22$ players in a\nsoccer field. Imagine that the tracker operates at $30$ frames per second and also that your tracker is noisy so that it produces a few false tracks that create approximately $10$ extra points per instant. To compute $\\mathcal{D}_{comp}$, and after you extend the ground-truth and hypothesis sets from $A$ and $B$ to $A^+$ and $B^+$, you are dealing with distance matrices with about $((22+10)\\times 2)^2 = 4096$ variables per instant $t$. Using Fig.~\\ref{fig:profilingcodeforDcomp}\nyou can conclude that it will take you about $40$ seconds to evaluate the accuracy of $800/30 = 26.6$ seconds of data if you use a C implementation of the ADMM on a $1.4$GHz MacBook Air. If you reduce the number of free variables per frame to half by setting $W_{ij}(t)$ to zero if point $i$ and $j$ are larger than a given threshold then you can reduce the time to process $26.6$ seconds of data to about $20$ seconds.\n\n\n\n\n\n\n\\vspace{-0.3cm}\n\\section{More numerical results}\n\\label{sec:num_res}\n\nTo the best of our knowledge,\n$\\mathcal{D}_{comp}$ is the first similarity measure that\nis a mathematical metric and deals with identity\nswitches in an optimal way while being computable in\npolynomial time. In particular, we can use it to generate\noptimal tradeoff curves between $dist$ and $swi$ (c.f.\nTheorem \\ref{th:optimal_tradeoff}).\n\nTo illustrate this point we now use $\\mathcal{D}_{comp}$\nto assess the closeness between sets $A$ and $B$ both\nsynthetically generated and coming from a tracking application\nand compare it with MOTP. We make the comparison through\n$dist$-$swi$ tradeoff plots. For $\\mathcal{D}_{comp}$ we use the extended Euclidean metric for $d^+$, the component-wise\n$1$-norm for $\\|.\\|$ and the tradeoff curve is parametrized by\na multiplying factor $\\alpha > 0$ that we put\nin front of the switch term.\nFor the MOTP, we compute the value for  and $swi$ in the same way as for $\\mathcal{D}_{comp}$ but using the\nMOT heuristic association between $A$ and $B$ described in Definition\n\\ref{def:MOT_association}. The MOTP tradeoff curve is parameterized by $thr$.\n\nA direct interpretation of our results is that $\\mathcal{D}_{comp}$ is better than MOTP. However, a more important interpretation of our results is that $\\mathcal{D}_{comp}$ builds better associations between $A$ and $B$ than the greedy associations that are widely used in the literature and the non-greedy association that do not allow switches, like in OSPA. Because of this, most measures of accuracy, that are dependent on first establishing a correspondence between $A$ and $B$, might be improved if we use the association that $\\mathcal{D}_{comp}$ builds. Therefore, although we restrict our numerical comparison to MOTP, indeed it is one of the most widely used metrics in computer vision, we can use our work to also improve, for example, Multiple Object Tracking Accuracy (MOTA), False Alarms per Frame, Ratio of Mostly Tracked trajectories, Ratio of Mostly Lost trajectories, number of False Positives, number of False Negatives, number of ID Switches, number of tracks Fragmentation and many of the measures in \\cite{rothrock2000performance,gorji2011performance}.\n\n\n\n\n\\vspace{-0.2cm}\n\\subsection{Real trackers and real data}\n\\label{sec:towncenternumerics}\n\nIn Figure \\ref{fig:real_data_results}-(a) we show\nthe performance of the trackers in \\cite{benfold2009guiding} and \\cite{benfold2011stable} on the AVG-TownCentre data set. We call these trackers $Tracker09$ and $Tracker11$ respectively. The data set is part of the Multiple Object Tracking Benchmark \\cite{motchallenge} that is widely used in computer vision.  It comes from a pedestrian street filmed from an elevated point at a resolution of $1920\\times1080$ for $3$ minutes and $45$ seconds and can be downloaded from\\cite{datafortracker09and11}.\nIn Figure \\ref{fig:real_data_results}-(b) we show the performance\nof the trackers in \\cite{yang2012multi} and \\cite{poiesi2015tracking}\non the PETS2009 data set, also part of the Multiple Object Tracking Benchmark. We call these trackers $Tracker12$ and $Tracker15$ respectively. Its resolution is $768\\times576$, its duration is $1$ minute and $54$ seconds and it can be downloaded from \\cite{pets2009data set}. We produced all the plots using the exact\nsame output that each tracker produced in its respective paper\nthanks to the authors who provided us with their trackers' output. For computing  we set $M = 20$ for AVG-Towncenter and $M = 50$ for PETS2009.\n\n\\begin{figure}[htbp] \n\\begin{center}\n\\includegraphics[trim=0.9cm 0.cm 0cm 0cm, clip=true,height=3.4cm]{./figures/Dcomp_vs_MOT_tradeoff_plot_real_data_sets_tracker_09_tacker_11_discrete_continuous_august_7_2015.eps}\n\n\\put(-60,95){\\rotatebox{0}{\\small (a)}}\n\\put(-120,35){\\rotatebox{90}{\\tiny Switch term, $swi$}}\n\\put(-72,01){\\rotatebox{0}{\\tiny Distance term, }}\n\\put(-100,34){\\rotatebox{0}{\\tiny Tracker11}}\n\\put(-100,28){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-55,22){\\rotatebox{0}{\\tiny Tracker09}}\n\\put(-55,16){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-80,64){\\rotatebox{0}{\\tiny Tracker11}}\n\\put(-80,58){\\rotatebox{0}{\\tiny MOTP}}\n\\put(-35,64){\\rotatebox{0}{\\tiny Tracker09}}\n\\put(-35,58){\\rotatebox{0}{\\tiny MOTP}}\n\n\\includegraphics[trim=1.2cm 0.cm 0cm 0cm, clip=true,height=3.4cm]{./figures/pets_data_set_MOTA_and_D_comp_trade_off_curves_7_august_2015.eps}\n\\put(-60,95){\\rotatebox{0}{\\small (b)}}\n\\put(-115,35){\\rotatebox{90}{\\tiny Switch term, $swi$}}\n\\put(-72,01){\\rotatebox{0}{\\tiny Distance term, }}\n\\put(-90,24){\\rotatebox{0}{\\tiny Tracker12}}\n\\put(-90,18){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-35,46){\\rotatebox{0}{\\tiny Tracker15}}\n\\put(-35,40){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-90,44){\\rotatebox{0}{\\tiny Tracker12}}\n\\put(-90,38){\\rotatebox{0}{\\tiny MOTP}}\n\\put(-35,69){\\rotatebox{0}{\\tiny Tracker15}}\n\\put(-35,63){\\rotatebox{0}{\\tiny MOTP}}\n\\caption{(a) -$swi$ tradeoff plot for $Tracker09$ and $Tracker11$ on the AVG-TownCenter data set; (b)$ dis$-$swi$ tradeoff plot for $Tracker12$ and $Tracker15$ on the PETS2009 data set. All the curves go to $swi = 0$ for large $dist$.}\n\\vspace{-0.4cm}\n\\label{fig:real_data_results}\n\\end{center} \n\\end{figure}\n\n\nAs expected from Theorem \\ref{th:optimal_tradeoff},\nthe tradeoff curves from\nMOTP understate the performance\nof the trackers. In particular, all trackers are achieving substantial smaller number of switches without incurring\nin larger distance costs that what MOTP reports. Interestingly, for these trackers and datasets\n$\\mathcal{D}_{comp}$ keeps the same relative ordering of performance as MOTP, although it is conceivable that there are situations in which a tracker $1$ is better than a tracker $2$\naccording to MOTP but not according to $\\mathcal{D}_{comp}$.\nIt would be interesting to find such an example. Finally notice that\nalthough the difference between the curves is large in absolute\nvalue, in relative values the curves are not very different. The\nabsolute values are large because both  and $swi$ terms\nare sums of distances and switches over all tracks and over all time instants and the relative values are small because all trackers are state-of-the-art and perform almost as well as possible.\n\n\n\n\n\\vspace{-0.3cm}\n\\subsection{Random ensemble of trajectories}\n \nIn the examples above $A$ and $B$ are relatively close\nto each other because the trackers are all good trackers.\n\n\n\nIn this section, to better appreciate the behavior of $\\mathcal{D}_{comp}$, we randomly generate a set $A$ with $25$ trajectories (slightly more than e.g. the number of players in a football game) and then\na set $B$ of trajectories that are a distorted version of the\ntrajectories in $A$. We generate the trajectories in $A$ by randomly starting and ending a trajectory in time and having the object in that trajectory randomly change its velocity's direction along the way. The trajectories in $B$ are generated by randomly fragmenting the trajectories in $A$, randomly removing some of the resulting trajectories, randomly adding noise to all trajectories and randomly flipping or not the ID of two trajectories if they pass by each other close enough. In the end, $B$ might have more or less than $25$ trajectories. In total we have four knobs to increase/reduce the distance between $A$ and $B$: the amplitude of noise, $AMPnoise$, the probability of fragmenting a track at each point in time, $FRAGprob$, the probability of deleting a points in the track, $DELprob$, and the threshold distance after which we allow to tracks ID to be switched or not randomly, $SWIdist$.\n\nThese random trajectories are far more diverse than the trajectories in most publicly available data sets because real objects, like people, have fairly simple trajectories\n\nIn addition, we do not just test two datasets, like in Section \n\\ref{sec:towncenternumerics}, but we datasets form about $20$ different levels of distortion for each of the $4$ knobs described above and for each of these levels of distortion we test $30$ random sets $A$ and $B$. Hence, if you will, and in the context of computer vision tracking, it is as if we test $2400$ different data sets of ground-truth and hypothesis trajectories.\n\nWe study the similarity between the random sets\n$A$ and $B$ using $dist$-$swi$ trade-off plots.\nThe smaller the area under the curve of a the trade-off plot,\nthe more similar $A$ and $B$ are. In Figure \\ref{fig:AUC_evol_synthetic_results} we show the average area under the trade-off curve (AUC) for the random sets $A$ and $B$ under the different knob setting. The AUC is normalized by the largest AUC possible. The largest AUC is the product of the largest distance-error possible with the largest switch-error possible. Each point in the plots is an average over $30$ random pairs $A$ and $B$ with the same knobs setting. In each plot we keep all but one knob constant.\n\n\\begin{figure}[h!]\n\\begin{center}\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_amp_noise_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 50){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (a)}\n\\put(-70  , 0){\\tiny $AMPnoise$}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_prob_del_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 45){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (b)}\n\\put(-70  , 0){\\tiny $DELprob$}\\\\ \\vspace{0.2cm}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_frag_prob_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 45){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (c)}\n\\put(-70  , 0){\\tiny $FRAGprob$}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_close_thres_area_evol_MOTvsDCOMP.eps}\n\n\\put(-105, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-43  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 42){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (d)}\n\\put(-70  , 0){\\tiny $SWIdist$}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\caption{AUC (normalized) versus (a) noise amplitude; (b) point deletion probability; (c) fragmenting probability; (d) switching distance. Smaller is better.}\n\\vspace{-0.5cm}\n\\label{fig:AUC_evol_synthetic_results}\n\\end{center}\n\\end{figure}\n\nAs expected from Theorem \\ref{th:optimal_tradeoff}, the AUC of $\\mathcal{D}_{comp}$ is smaller\nthan the AUC of MOTP. Note that it is incorrect to interpret these results as saying that MOTP is a like a scaled version of $\\mathcal{D}_{comp}$. Recall that we use the same $d^+$ to measure the distance between points in space in both MOTP and $\\mathcal{D}_{comp}$. We also compute the number of switches that the association of MOTP produces in the same way that we compute the number of switches that the association in $\\mathcal{D}_{comp}$ produces. The difference in the curves of Figure \\ref{fig:AUC_evol_synthetic_results} as a much deeper significance than a simple rescaling: for the $600$\nrandom pairs that we test, which consider different kinds\nof distortions between $A$ and $B$, and if we interpret each $A$ and $B$ as the ground-truth and output of a tracker, MOTP always says that the tracker is worse than it actually is. The $\\mathcal{D}_{comp}$ can see similarities between $A$ and $B$ that the MOTP cannot.\n\n\n\n\n\\vspace{-0.3cm}\n\\section{Conclusion}\n\nThe problem of defining a similarity measure between sets of trajectories\nis crucial for computer vision, machine learning and general AI.\nAn essential aspect in defining a similarity measure is finding a\ngood and simple association between the elements of the sets.\nExisting similarity measures that define useful associations fail\nto be a metric mathematically speaking and the ones that are a metric\nonly consider very primitive associations: full trajectories to full trajectories. The metric $\\mathcal{D}_{comp}$ is the first that \nsimultaneously (1) is a metric, (2) compares parts of trajectories\nto parts of trajectories, (3) allows to control the complexity of\nthe association between trajectories in an globally optimal way and (4) can be computed in polynomial time.\n\nThe general\nidea of defining mathematical metrics for sets of trajectories using\nconvex programs is our greatest overarching contribution. The next step\nis to explore variants of our metric that allow to incorporate uncertainty,\nas well as richer comparisons between $A$ and $B$ without losing\nits good properties.\n\n\\vspace{-0.3cm}\n\\bibliographystyle{IEEEtran}\n\\bibliography{tracking_metric} \n\n\n\n\n\n\\appendices\n\n\n\n\n\n\\section{The limitations of the CLEAR MOT}\\label{app:proof_of_th_mota_bad_association}\n\n\\begin{proof}[Proof of Theorem \\ref{th:MOT_inconsistent}]\nWe will construct an example for which the theorem is true. Our example proves the theorem for any $1 < thr < 2$ and for $A = \\{A_1,A_2\\}$ and $B=\\{B_1,B_2\\}$, i.e. $m=2$, where $A_i$ and $B_i$ are trajectories living in 1D. We explain how to generalize this example to any $thr$ and any $m$ at the end.\n\n\nConsider two sets of one-dimensional trajectories $A = \\{A_1,A_2 \\}$ and $B = \\{B_1, B_2\\}$ defined as in Figure \\ref{fig:clearmot_bad_metric} but where the\ntrajectories extend beyond instant $15$ until time $T$.\n\n\n\\begin{figure}[t]\n\\vspace{-0.7cm}\n\\begin{center}\n\\includegraphics[height=4.0cm]{./figures/motp_bad_not_a_metric.eps}\n\\put(-80,-5){\\small Time}\n\\put(-154,50){\\rotatebox{90}{\\small Space}}\n\\put(-35,98){\\rotatebox{0}{\\tiny $A_1$}}\n\\put(-35,92){\\rotatebox{0}{\\tiny $A_2$}}\n\\put(-35,85){\\rotatebox{0}{\\tiny $B_1$}}\n\\put(-35,79){\\rotatebox{0}{\\tiny $B_2$}}\n\\put(-35,72){\\rotatebox{0}{\\tiny $C_1$}}\n\\put(-35,65){\\rotatebox{0}{\\tiny $C_2$}}\n\\caption{Example that shows that (a) the CLEAR MOT association heuristic is bad and (b) MOTP does not define a metric.}\n\\vspace{-0.4cm}\n\\label{fig:clearmot_bad_metric}\n\\end{center}\n\\end{figure}\n\n\nIf $1 < thr <  2$ the CLEAR MOT builds a\nsequence $\\Sigma_{\\text{MOT}}$ that is equal to $\\{(1,2),...,(1,2),(2,1),(2,1),...\\}$ because at some instant between time $4$ and time $12$ the initial association $\\{A_1 \\leftrightarrow B_1, A_2 \\leftrightarrow B_2\\}$ exceeds $thr < 2$ and is replaced by $\\{A_2 \\leftrightarrow B_1, A_1 \\leftrightarrow B_2\\}$ and after instant $12$ this last  association is anchored given that $1 < thr$.\n\nThe number of times that $\\sigma_{\\text{MOT}}(t) \\neq \\sigma_{\\text{MOT}}(t+1)$ is $1$ so $swi(\\Sigma_{\\text{MOT}}) = \\frac{1}{T-1} = \\mathcal{O}(1/T)$. After instant $12$ we have $\\sum_{i} \\|A_i(t) - B_{\\sigma_{{\\text{MOT}}_i}(t)}(t)\\| = 2$\nso $dist(\\Sigma_{\\text{MOT}},A,B) >  \\frac{2(T-12)}{T} = 2 - \\mathcal{O}(1/T)$. However, if we choose $\\Sigma = \\{(1,2),...,(1,2)\\}$ we have $swi(\\Sigma) = 0$ and\n$dist(\\Sigma,A,B) < \\frac{12 \\times 7.5}{T} = \\mathcal{O}(1/T)$.\n\n\nWe can make the proof hold for an interval around any $thr$ by rescaling space. This changes the bounds on $dist$ by a factor of $thr$ and leaves the bounds on $swi$ unchanged.\n\nIn addition, we can make the proof hold for any $m$ (even) by extending $A$ and $B$ as follows. If the 1D trajectory $A_i$ above is equal to $\\{(1,A_i(1)),...,(T,A_i(T))\\}$ define the 2D trajectory $A^{(k)}_i$ to have time-state pairs $\\{(1,[A_i(1)); C k],...,(T,[A_i(T); Ck])\\}$ where $C$ is a constant large enough to guarantee that trajectories for different $k$s are not close to each other. Define $B^{(k)}_i$ in a similar way. To make the proof hold for any $m$ (even) extend $A$ to $A = \\{A^{(0)}_1,A^{(0)}_2,A^{(1)}_1,A^{(1)}_2,...,A^{(m-1)}_1,A^{(m-1)}_2\\}$ and extend $B$ in a similar way. To extend the proof for an odd $m$ simply append to $A$ and $B$ two equal trajectories far away from all other trajectories such that they are matched and hence contribute nothing to both $swi$ or $dist$. With these sets the bounds previously computed on $swi()$ change by a factor of $m$ and the bounds on $dist(.)$ change by a factor of $m/2$. In the statement of our theorem statement we are using $\\mathcal{O}(m/T) = \\mathcal{O}(1/T)$ and $\\mathcal{O}(m \\, thr/T) = \\mathcal{O}(1/T)$.\n\\end{proof}\n\n\n\n\n\n\\label{app:proof_of_th_motp_not_metric}\n\n\\begin{proof}[Proof of Theorem \\ref{th:MOPT_no_metric}]\nWe construct $A,B,C \\in \\mathcal{S}$ for which the triangle inequality is violated, specifically, $\\mathcal{D}(A,B) > \\mathcal{D}(A,C) + \\mathcal{D}(C,B)$. Our example\nproves that the theorem holds for $1 < thr < 2$ but by rescaling space the proof follows for any $thr > 0$.\n\nConsider the sets $A = \\{A_1, A_2\\}$, $B = \\{B_1, B_2\\}$ and\n$C = \\{C_1, C_2\\}$ as in Figure \\ref{fig:clearmot_bad_metric} but where the trajectories extend beyond time $15$ to some large $T$. To make calculations simpler, we work with $\\mathcal{D}$ divided by $T$ in Definition \\ref{def:MOT_metric}.\n\nLet us compute $\\mathcal{D}(A,B)$ first. The association $\\Sigma_{\\text{MOT}}$ for this distance is $\\{(1,2),..,(1,2),(2,1),...\\}$ because (1) we start with the association $\\{A_1 \\leftrightarrow B_1,A_2 \\leftrightarrow B_2\\}$, (2) at some point between instant $4$ and instant $12$ we need to change the association to $\\{A_1 \\leftrightarrow B_2,A_2 \\leftrightarrow B_1\\}$\nbecause the initial association exceeds $thr < 2$ and (3) after time $12$ the association \n$\\{A_1 \\leftrightarrow B_2,A_2 \\leftrightarrow B_1\\}$ is anchored because $thr > 1$. This association leads to $\\mathcal{D}(A,B) > \\frac{2(T-12)}{T}$.\n\nNow we compute $\\mathcal{D}(A,C)$. The computation for $\\mathcal{D}(C,B)$ is similar so we omit it. The association for $\\mathcal{D}(A,C)$ is $\\Sigma_{\\text{MOT}} = \\{(1,2),...,(1,2)\\}$ because (1) we start with $\\{A_1 \\leftrightarrow C_1,A_2 \\leftrightarrow C_2\\}$, (2) the association $A_1 \\leftrightarrow C_1$ is always anchored because the distance between $A_1$ and $C_1$ is always zero and thus always smaller than $thr > 1$ and (3) after some point between instant $4$ and instant $12$, when the distance between $A_2$ and $C_2$ exceeds $thr < 2$, MOTP still keeps the association $A_2 \\leftrightarrow C_2$ because $A_1$ and $C_1$ are already anchored.\nThis association leads to $\\mathcal{D}(A, C) < \\frac{8.5}{T}$.\n\nTherefore, for $T$ large enough we have\n$\\mathcal{D}(A, B) > \\frac{2(T-12)}{T} > \n\\frac{8.5}{T} + \\frac{8.5}{T} > \\mathcal{D}(A, C) + \\mathcal{D}(C, B)$.\n\\end{proof}\n\n\n\n\n\\section{A natural metric for sets of trajectories} \\label{app:proof_of_th_d_nat_is_metric}\n\nTo prove Theorem \\ref{th:Dnaturalismetric}\nwe need the following Lemma.\n\n\n\\begin{lemma} \\label{th:extdismetric}\nThe map $d^+$ is a metric on $\\mathbb{R}^p \\cup \\{*\\}$.\n\\end{lemma}\n\\begin{proof}\nLet $x'',x',x \\in \\mathbb{R}^p \\cup \\{*\\}$. To prove the coincidence property observe that $d^+(x,x') = 0$ either implies that $x=x'=*$ or, since $M>0$, implies that $d^+(x,x') = d(x,x') = 0$, which, because $d$ is a metric, implies that $x=x'=0$. In other words, $d^+(x,x') = 0 \\Leftrightarrow x=x'$. The symmetry property, $d^+(x,x')=d^+(x',x)$, follows directly from\nthe definition. To prove the subadditivity property we need to\nconsider eight different cases. It is trivial to check that the following six cases satisfy the triangle inequality: $x,x',x'' \\in \\mathbb{R}^p$; $x=x'=*,x'' \\in \\mathbb{R}^p$; $x''=x'=*,x \\in \\mathbb{R}^p$; $x=*,x',x'' \\in \\mathbb{R}^p$; $x''=*,x,x' \\in \\mathbb{R}^p$; $x=x''=*,x' \\in \\mathbb{R}^p$. We check the two other cases separately. If $x,x',x'' \\in \\mathbb{R}^p$ then $d^+(x,x'') = \\min\\{2M,d(x,x'') \\} \\leq \\min \\{2M,d(x,x') + d(x',x'')\\} \\leq \\min\\{2M,d(x,x')\\} + \\min\\{2M,d(x',x'')\\} = d^+(x,x') + d^+(x',x'')$. If $x'=*, x,x'' \\in \\mathbb{R}^p$ then\n$d^(x,x'') = \\min\\{2M,d(x,x'') \\} \\leq M + M = d^+(x,x') + d^+(x',x'')$.\n\\end{proof}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:Dnaturalismetric}]\nLet $A,B,C$ be any three elements in $\\mathcal{S}$.\\\\\n\\emph{Coincidence property}:\nWe show that ${\\mathcal{D}_{nat}}(A,B) = 0$ if and only if $A = B$.\nRemember that $A$ and $B$ are unordered sets\nof trajectories so $A = B$ means that there is an isomorphism\nbetween $A$ and $B$. In other words, they are equal apart tom\na relabeling of their elements.\nIf $A = B$ and we set $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$\nwhere $\\sigma$ is an isomorphism between $A$ and $B$,\nthen the objective in \\eqref{eq:defDnat} is equal to zero.\nSince the minimum of \\eqref{eq:defDnat}\nmust always be non-negative,\nwe conclude that $A = B \\Rightarrow {\\mathcal{D}_{nat}}(A,B) = 0$.\nNow assume that ${\\mathcal{D}_{nat}}(A,B) = 0$ and let $\\Sigma^*=(\\sigma^*(1),...,\\sigma^*(T))$ be a\nminimizer of \\eqref{eq:defDnat}. ${\\mathcal{D}_{nat}}(A,B) = 0$ implies that\n$\\mathcal{K}(\\Sigma^*) = 0$ and therefore $\\sigma^*_i(t) = \\sigma^*_i(1)$\nfor all $t$ and $i$. Since the labeling of the trajectories does not matter\nin computing ${\\mathcal{D}_{nat}}$, we assume without loss of generality that \ntheir labeling is such that we can write $\\sigma^*_i(t) = i$.\n${\\mathcal{D}_{nat}}(A,B) = 0$ also implies that, for all $t$ and $i$, we have\n$d^+(A^+_i(t),B^+_{\\sigma^*_i(t)}(t)) = d^+(A^+_i(t),B^+_{i}(t)) = 0$.\nSince $d^+$ is a\nmetric this in turn implies that $A^+_i(t) = B^+_i(t)$ for all $i$ and $t$, which is the same as saying that $A^+ = B^+$. If $A \\neq B$ then $A^+ \\neq B^+$\ntherefore $A^+ = B^+$ implies that $A = B$. To be more specific,\n$A$ is equal to $B$ apart from a relabeling of its trajectories, which\nwe can do because $A$ and $B$ are unordered sets of trajectories.\\\\\n\\emph{Symmetry property}: ${\\mathcal{D}_{nat}}$ only depends on $A$ and $B$ through\n$d^+$ and, like all metrics, this is a symmetric function.\nIn addition, if we swap $i$ and $\\sigma_i(t)$ in \\eqref{eq:defDnat}\nthe minimum of \\eqref{eq:defDnat} remains unchanged. It follows that\n${\\mathcal{D}_{nat}}(A,B) = {\\mathcal{D}_{nat}}(B,A)$.\\\\\n\\emph{Subadditivity property}: We prove that ${\\mathcal{D}_{nat}}(A,C) \\leq {\\mathcal{D}_{nat}}(A,B) + {\\mathcal{D}_{nat}}(B,C)$. Since $d^+$ is a metric, we can write that\n\n\n", "itemtype": "equation", "pos": 46379, "prevtext": "\n\nNote that this is analougous to property (iii) that we use\nfor $\\mathcal{K}$ in Section \\ref{sec:naturalslowmetric}.\n\n\\begin{definition}\nThe {\\bf natural computable distance} between two sets of trajectories\nis a map $\\mathcal{D}_{comp}: \\mathcal{S}\\times\\mathcal{S}\\mapsto\\mathbb{R}^+_0$ such that for any $A,B \\in \\mathcal{S}$\n{\n\n", "index": 15, "text": "\\begin{align}\\label{eq:defDcomp}\n&\\mathcal{D}_{comp}(A,B) =  \\hspace{-0.4cm}\\min_{\\{W(t)\\} \\in \\mathcal{P}^T} \\Big\\{ \\sum^{T-1}_{t = 1} \\|W(t+1) - W(t)\\|\\nonumber\\\\\n&+ \\sum^T_{t=1} \\text{\\bf tr}(W(t)^{\\dagger} D^{AB}(t)) \\Big\\}. \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{D}_{comp}(A,B)=\\hskip-11.381102pt\\min_{\\{W(t)\\}\\in%&#10;\\mathcal{P}^{T}}\\Big{\\{}\\sum^{T-1}_{t=1}\\|W(t+1)-W(t)\\|\" display=\"inline\"><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mrow><mi>c</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>p</mi></mrow></msub><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"0pt\">=</mo><munder><mi>min</mi><mrow><mrow><mo stretchy=\"false\">{</mo><mrow><mi>W</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow><mo>\u2208</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mi>T</mi></msup></mrow></munder><mrow><mo maxsize=\"160%\" minsize=\"160%\">{</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mo>\u2225</mo><mi>W</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mi>W</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2225</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum^{T}_{t=1}\\text{\\bf tr}(W(t)^{\\dagger}D^{AB}(t))\\Big{\\}}.\" display=\"inline\"><mrow><mo>+</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mtext>\ud835\udc2d\ud835\udc2b</mtext><mrow><mo stretchy=\"false\">(</mo><mi>W</mi><msup><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2020</mo></msup><msup><mi>D</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msup><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo maxsize=\"160%\" minsize=\"160%\">}</mo><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nfor any $\\Sigma' = (\\sigma'(1),...,\\sigma'(T)) \\in \\Pi^T$ and for all $i$ and $t$. Now notice that\n\n\n", "itemtype": "equation", "pos": 78059, "prevtext": "\n}\n\\end{definition}\n\n\\begin{remark}\nThis definition is compatible with scaling the first term by some constant $\\alpha> 0$. We are not ignoring this possibility but simply put any scaling factor ``inside'' the matrix norm. In Section \\ref{sec:num_res} we solve \\eqref{eq:defDcomp} for different values of $\\alpha$ to obtain a trade-off plot between its two terms.\n\\end{remark}\n\nThe motivation for this definition is to obtain a measure that\nis as similar as possible to $\\mathcal{D}_{nat}$ but that we can compute fast. Just like MOTP and $\\mathcal{D}_{nat}$, the measure $\\mathcal{D}_{comp}$ also builds an association between parts of trajectories in $A$ and parts of trajectories in $B$. This association is represented by the matrices $W(t)$. However, unlike $\\Sigma$ in $\\mathcal{D}_{nat}$, the $W$ matrices also give us a weight/strength for the different matches between $A$ and $B$. Just like $\\mathcal{D}_{nat}$, and as the next theorem shows, $\\mathcal{D}_{comp}$ is also mathematically consistent.\n\n\\begin{theorem} \\label{th:D_comp_is_metric}\nThe map $\\mathcal{D}_{comp}$ is a metric on $\\mathcal{S}$.\n\\end{theorem}\nThe proof of this theorem is in Appendix \\ref{app:proof_that_D_comp_is_metric}.\n\nMost importantly, unlike $\\mathcal{D}_{nat}$, computing $\\mathcal{D}_{comp}$ amounts to solving a convex optimization problem. In short, $\\mathcal{D}_{comp}$ combines all the advantages of OSPA, MOTP and $\\mathcal{D}_{comp}$.\n\n\nThe following Lemma gives sufficient conditions for a metric $\\|.\\|$\nto satisfy property \\eqref{eq:propofnormforDcomp}. See Appendix \\ref{app:proof_that_norms_for_Dcomp_are_many} for a proof.\n\n\\begin{lemma} \\label{th:many_norms_satisfy_D_comp}\nIf $\\|.\\|$ is a sub-multiplicative norm and $\\|W\\| \\leq 1$ for all\n$W \\in \\mathcal{P}$ then $\\|.\\|$ satisfies property \\eqref{eq:propofnormforDcomp}.\n\\end{lemma}\n\nThis lemma implies, for example, that the 1-norm and $\\infty$-norm\nspectral norm for matrices are valid choices for $\\|.\\|$. In particular,\nthe use of $\\|.\\|_1$ in $\\mathcal{D}_{comp}$ is extremely useful\nbecause it induces the changes of association to be sparse in time\nand, as the next theorem shows, it reduces $\\mathcal{D}_{comp}$ to solving a linear program. The theorem's proof is in Appendix \\ref{app:proof_that_D_comp_equals_LP}.\n\n\\begin{theorem} \\label{th:dcompisLP}\nFor any $A, B \\in \\mathcal{S}$, $\\mathcal{D}_{comp}(A,B)$ with\n$\\|.\\|$ equal to the matrix 1-norm can\nbe computed (in polynomial time) by solving a linear program.\n\\end{theorem}\n\n\nThe metric $\\mathcal{D}_{comp}$ allows to consider\na scaling factor $\\alpha$ in front of the term $\\sum_t\\|W(t+1)-W(t)\\|$, which we call the switch term, $swi$. We call the other term the distance term $dist$. Like the $thr$ value in the CLEAR MOT, $\\alpha$ allows us to penalize heavily the error in distances in some applications ($\\alpha = small$); and in other applications allows us to penalize heavily the number of associations switches ($\\alpha = large$). One can\nhowever report how close a set $A \\in \\mathcal{S}$ is from $B \\in \\mathcal{S}$ without choosing a specific $\\alpha$, simply plot the tradeoff curve between $swi$ and $dist$ as a function of $\\alpha$. The closer this curve is to the left/bottom edges of the positive quadrant of the cartesian plane, the closer $A$ to $B$.\n\nThe next theorem shows that the tradeoff curve produced by the two terms of $\\mathcal{D}_{\\text{comp}}$, which we denote by $(swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha),dist_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$, is, in a sense, the best trade-off curve between $dist$ and $swi$\nthat any metric can generate. \nTo state the theorem we need to define the region $\\mathcal{R}$ of pairs of distance-value and switch-value that we can improve upon with some stochastic matrices $\\{W(t)\\}$ produced by some association procedure of some similarity measure. More concretely, $\\mathcal{R} = \\{(dist,swi)\\in\\mathbb{R}^2: swi \\geq \\sum_t \\|W(t+1)-W(t)\\| \\text{ and } dist \\geq \\sum_t \\text{\\bf tr}(W(t)^\\dagger D^{AB}(t)) \\text{ for all } \\{W(t)\\} \\in \\mathcal{P}^T\\}$. The proof of following result is in Appendix \\ref{app:proof_of_optimal_trade_off_curve_for_D_comp}. \n\n\\begin{theorem} \\label{th:optimal_tradeoff}\nIf $(dis, swi) \\in \\text{int}(\\mathcal{R})$ then there exists $\\alpha$, such that $dis + \\alpha swi > dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha) + \\alpha swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha)$.\nIf $(dis, swi) \\in \\partial \\mathcal{R}$ then $(dis, swi)$ is equal to some point in the curve $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ for some $\\alpha$ or is equal to a linear combination of points in the curve.\n\\end{theorem}\n\n\\begin{remark}\nIn the proof of the above theorem we show that\n$\\mathcal{R}$ is convex. Hence, because the boundary of $\\mathcal{R}$ \nis by definition Pareto efficient, this boundary must be a convex non-increasing curve. Since the curve $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ effectively covers this boundary, \nwe can use this property to efficiently estimate the trade-off curve. Basically, we can compute $(dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ for some discrete set values of $\\alpha$ and then we can take the convex hull of these points.\n\\end{remark}\n\n\\vspace{-0.4cm}\n\\subsection{Computing $\\mathcal{D}_{comp}$ in practice}\n\\label{sec:num_res_run_time}\n\nThere are multiple ways to compute \n$\\mathcal{D}_{comp}$ in practice, all of which amount\nto solving a convex optimization problem. For this paper we coded a solver in C based on the Alternating Direction Method of Multipliers (ADMM) because the ADMM is known to scale well for large problems and its modular nature \nmakes it easy, in future work, for us to research variants of the formulation $\\mathcal{D}_{comp}$ without having to re-write much of our code.\nFor a good introduction to the ADMM, related methods and applications see\\cite{boyd2011distributed}.\nOur implementation is approximately $\\times 50$ faster than using Matlab CVX \\cite{cvx}.\n\nIn Figure \\ref{fig:profilingcodeforDcomp} we show the run-time of our code as a function of the total duration $T$ of the input data for a different number of free association variables $W_{ij}(t)$ per time instant $t$. We use the terminology ``free association variables'' to emphasize that some $W_{ij}(t)$ might be a priory set to zero if the distance between point $i$ and point $j$ at time $t$ is very large, which can save computation time. In the figure we choose the euclidean distance for $d(.,.)$ and the one-norm for matrix norm $\\|.\\|$ in the switch term. Similar run-times hold for other metrics. The run-time is computed for randomly generated sets of trajectories on a single core of a $1.4$GHz Intel Core i5 MacBook Air. In our tests, the ADMM always converged to $1$\\% accuracy in less than $150$ iterations.\n\n\\begin{figure}[b]\n\\vspace{-0.4cm}\n\\begin{center}\n\\includegraphics[trim=0.8cm 0.4cm 0.6cm 0cm, clip=true,height=3.0cm]{./figures/run_time_metric.eps}\n\\put(-105,23){\\rotatebox{90}{\\tiny Run-time (secs)}}\n\\put(-85,-05){\\rotatebox{0}{\\tiny Maximum length of trajectories, $T$}}\n\\put(-80,74){\\rotatebox{0}{\\tiny \\# vars. per instant}}\n\\put(-75,68){\\rotatebox{0}{\\tiny $2.5 \\times 10^3$}}\n\\put(-75,61){\\rotatebox{0}{\\tiny $3.6 \\times 10^3$}}\n\\put(-75,53){\\rotatebox{0}{\\tiny   $4.9 \\times 10^3$}}\n\\put(-75,45){\\rotatebox{0}{\\tiny   $6.4 \\times 10^3$}}\n\\put(-75,38){\\rotatebox{0}{\\tiny   $8.1 \\times 10^3$}}\n\\put(-75,31){\\rotatebox{0}{\\tiny   $10 \\times 10^3$}}\n\\includegraphics[trim=0.8cm 0.4cm 0.8cm 0cm, clip=true,height=3.0cm]{./figures/run_time_metric_function_of_size.eps}\n\\put(-75,74){\\rotatebox{0}{\\tiny Trajectory length, $T$}}\n\\put(-68,68){\\rotatebox{0}{\\tiny $50$}}\n\\put(-68,61){\\rotatebox{0}{\\tiny $250$}}\n\\put(-68,54){\\rotatebox{0}{\\tiny   $450$}}\n\\put(-68,47){\\rotatebox{0}{\\tiny   $650$}}\n\\put(-68,40){\\rotatebox{0}{\\tiny   $850$}}\n\n\\put(-70,-05){\\rotatebox{0}{\\tiny \\# vars. per instant}}\n\\put(-12,-05){\\rotatebox{0}{\\tiny ($\\times 10^3$)}}\n\n\\caption{Time it takes to compute $\\mathcal{D}_{comp}$ (within $1$\\% accuracy) as function of (a) the length of trajectories for a different number of association variables per instant; as a function of (b) the number of association variables per instant for different lengths of trajectories.}\n\\label{fig:profilingcodeforDcomp}\n\\vspace{-0.7cm}\n\\end{center}\n\\end{figure}\n\nTo interpret the plots, imagine you want to evaluate the quality of a tracker when tracking $22$ players in a\nsoccer field. Imagine that the tracker operates at $30$ frames per second and also that your tracker is noisy so that it produces a few false tracks that create approximately $10$ extra points per instant. To compute $\\mathcal{D}_{comp}$, and after you extend the ground-truth and hypothesis sets from $A$ and $B$ to $A^+$ and $B^+$, you are dealing with distance matrices with about $((22+10)\\times 2)^2 = 4096$ variables per instant $t$. Using Fig.~\\ref{fig:profilingcodeforDcomp}\nyou can conclude that it will take you about $40$ seconds to evaluate the accuracy of $800/30 = 26.6$ seconds of data if you use a C implementation of the ADMM on a $1.4$GHz MacBook Air. If you reduce the number of free variables per frame to half by setting $W_{ij}(t)$ to zero if point $i$ and $j$ are larger than a given threshold then you can reduce the time to process $26.6$ seconds of data to about $20$ seconds.\n\n\n\n\n\n\n\\vspace{-0.3cm}\n\\section{More numerical results}\n\\label{sec:num_res}\n\nTo the best of our knowledge,\n$\\mathcal{D}_{comp}$ is the first similarity measure that\nis a mathematical metric and deals with identity\nswitches in an optimal way while being computable in\npolynomial time. In particular, we can use it to generate\noptimal tradeoff curves between $dist$ and $swi$ (c.f.\nTheorem \\ref{th:optimal_tradeoff}).\n\nTo illustrate this point we now use $\\mathcal{D}_{comp}$\nto assess the closeness between sets $A$ and $B$ both\nsynthetically generated and coming from a tracking application\nand compare it with MOTP. We make the comparison through\n$dist$-$swi$ tradeoff plots. For $\\mathcal{D}_{comp}$ we use the extended Euclidean metric for $d^+$, the component-wise\n$1$-norm for $\\|.\\|$ and the tradeoff curve is parametrized by\na multiplying factor $\\alpha > 0$ that we put\nin front of the switch term.\nFor the MOTP, we compute the value for  and $swi$ in the same way as for $\\mathcal{D}_{comp}$ but using the\nMOT heuristic association between $A$ and $B$ described in Definition\n\\ref{def:MOT_association}. The MOTP tradeoff curve is parameterized by $thr$.\n\nA direct interpretation of our results is that $\\mathcal{D}_{comp}$ is better than MOTP. However, a more important interpretation of our results is that $\\mathcal{D}_{comp}$ builds better associations between $A$ and $B$ than the greedy associations that are widely used in the literature and the non-greedy association that do not allow switches, like in OSPA. Because of this, most measures of accuracy, that are dependent on first establishing a correspondence between $A$ and $B$, might be improved if we use the association that $\\mathcal{D}_{comp}$ builds. Therefore, although we restrict our numerical comparison to MOTP, indeed it is one of the most widely used metrics in computer vision, we can use our work to also improve, for example, Multiple Object Tracking Accuracy (MOTA), False Alarms per Frame, Ratio of Mostly Tracked trajectories, Ratio of Mostly Lost trajectories, number of False Positives, number of False Negatives, number of ID Switches, number of tracks Fragmentation and many of the measures in \\cite{rothrock2000performance,gorji2011performance}.\n\n\n\n\n\\vspace{-0.2cm}\n\\subsection{Real trackers and real data}\n\\label{sec:towncenternumerics}\n\nIn Figure \\ref{fig:real_data_results}-(a) we show\nthe performance of the trackers in \\cite{benfold2009guiding} and \\cite{benfold2011stable} on the AVG-TownCentre data set. We call these trackers $Tracker09$ and $Tracker11$ respectively. The data set is part of the Multiple Object Tracking Benchmark \\cite{motchallenge} that is widely used in computer vision.  It comes from a pedestrian street filmed from an elevated point at a resolution of $1920\\times1080$ for $3$ minutes and $45$ seconds and can be downloaded from\\cite{datafortracker09and11}.\nIn Figure \\ref{fig:real_data_results}-(b) we show the performance\nof the trackers in \\cite{yang2012multi} and \\cite{poiesi2015tracking}\non the PETS2009 data set, also part of the Multiple Object Tracking Benchmark. We call these trackers $Tracker12$ and $Tracker15$ respectively. Its resolution is $768\\times576$, its duration is $1$ minute and $54$ seconds and it can be downloaded from \\cite{pets2009data set}. We produced all the plots using the exact\nsame output that each tracker produced in its respective paper\nthanks to the authors who provided us with their trackers' output. For computing  we set $M = 20$ for AVG-Towncenter and $M = 50$ for PETS2009.\n\n\\begin{figure}[htbp] \n\\begin{center}\n\\includegraphics[trim=0.9cm 0.cm 0cm 0cm, clip=true,height=3.4cm]{./figures/Dcomp_vs_MOT_tradeoff_plot_real_data_sets_tracker_09_tacker_11_discrete_continuous_august_7_2015.eps}\n\n\\put(-60,95){\\rotatebox{0}{\\small (a)}}\n\\put(-120,35){\\rotatebox{90}{\\tiny Switch term, $swi$}}\n\\put(-72,01){\\rotatebox{0}{\\tiny Distance term, }}\n\\put(-100,34){\\rotatebox{0}{\\tiny Tracker11}}\n\\put(-100,28){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-55,22){\\rotatebox{0}{\\tiny Tracker09}}\n\\put(-55,16){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-80,64){\\rotatebox{0}{\\tiny Tracker11}}\n\\put(-80,58){\\rotatebox{0}{\\tiny MOTP}}\n\\put(-35,64){\\rotatebox{0}{\\tiny Tracker09}}\n\\put(-35,58){\\rotatebox{0}{\\tiny MOTP}}\n\n\\includegraphics[trim=1.2cm 0.cm 0cm 0cm, clip=true,height=3.4cm]{./figures/pets_data_set_MOTA_and_D_comp_trade_off_curves_7_august_2015.eps}\n\\put(-60,95){\\rotatebox{0}{\\small (b)}}\n\\put(-115,35){\\rotatebox{90}{\\tiny Switch term, $swi$}}\n\\put(-72,01){\\rotatebox{0}{\\tiny Distance term, }}\n\\put(-90,24){\\rotatebox{0}{\\tiny Tracker12}}\n\\put(-90,18){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-35,46){\\rotatebox{0}{\\tiny Tracker15}}\n\\put(-35,40){\\rotatebox{0}{\\tiny $\\mathcal{D}_{comp}$}}\n\\put(-90,44){\\rotatebox{0}{\\tiny Tracker12}}\n\\put(-90,38){\\rotatebox{0}{\\tiny MOTP}}\n\\put(-35,69){\\rotatebox{0}{\\tiny Tracker15}}\n\\put(-35,63){\\rotatebox{0}{\\tiny MOTP}}\n\\caption{(a) -$swi$ tradeoff plot for $Tracker09$ and $Tracker11$ on the AVG-TownCenter data set; (b)$ dis$-$swi$ tradeoff plot for $Tracker12$ and $Tracker15$ on the PETS2009 data set. All the curves go to $swi = 0$ for large $dist$.}\n\\vspace{-0.4cm}\n\\label{fig:real_data_results}\n\\end{center} \n\\end{figure}\n\n\nAs expected from Theorem \\ref{th:optimal_tradeoff},\nthe tradeoff curves from\nMOTP understate the performance\nof the trackers. In particular, all trackers are achieving substantial smaller number of switches without incurring\nin larger distance costs that what MOTP reports. Interestingly, for these trackers and datasets\n$\\mathcal{D}_{comp}$ keeps the same relative ordering of performance as MOTP, although it is conceivable that there are situations in which a tracker $1$ is better than a tracker $2$\naccording to MOTP but not according to $\\mathcal{D}_{comp}$.\nIt would be interesting to find such an example. Finally notice that\nalthough the difference between the curves is large in absolute\nvalue, in relative values the curves are not very different. The\nabsolute values are large because both  and $swi$ terms\nare sums of distances and switches over all tracks and over all time instants and the relative values are small because all trackers are state-of-the-art and perform almost as well as possible.\n\n\n\n\n\\vspace{-0.3cm}\n\\subsection{Random ensemble of trajectories}\n \nIn the examples above $A$ and $B$ are relatively close\nto each other because the trackers are all good trackers.\n\n\n\nIn this section, to better appreciate the behavior of $\\mathcal{D}_{comp}$, we randomly generate a set $A$ with $25$ trajectories (slightly more than e.g. the number of players in a football game) and then\na set $B$ of trajectories that are a distorted version of the\ntrajectories in $A$. We generate the trajectories in $A$ by randomly starting and ending a trajectory in time and having the object in that trajectory randomly change its velocity's direction along the way. The trajectories in $B$ are generated by randomly fragmenting the trajectories in $A$, randomly removing some of the resulting trajectories, randomly adding noise to all trajectories and randomly flipping or not the ID of two trajectories if they pass by each other close enough. In the end, $B$ might have more or less than $25$ trajectories. In total we have four knobs to increase/reduce the distance between $A$ and $B$: the amplitude of noise, $AMPnoise$, the probability of fragmenting a track at each point in time, $FRAGprob$, the probability of deleting a points in the track, $DELprob$, and the threshold distance after which we allow to tracks ID to be switched or not randomly, $SWIdist$.\n\nThese random trajectories are far more diverse than the trajectories in most publicly available data sets because real objects, like people, have fairly simple trajectories\n\nIn addition, we do not just test two datasets, like in Section \n\\ref{sec:towncenternumerics}, but we datasets form about $20$ different levels of distortion for each of the $4$ knobs described above and for each of these levels of distortion we test $30$ random sets $A$ and $B$. Hence, if you will, and in the context of computer vision tracking, it is as if we test $2400$ different data sets of ground-truth and hypothesis trajectories.\n\nWe study the similarity between the random sets\n$A$ and $B$ using $dist$-$swi$ trade-off plots.\nThe smaller the area under the curve of a the trade-off plot,\nthe more similar $A$ and $B$ are. In Figure \\ref{fig:AUC_evol_synthetic_results} we show the average area under the trade-off curve (AUC) for the random sets $A$ and $B$ under the different knob setting. The AUC is normalized by the largest AUC possible. The largest AUC is the product of the largest distance-error possible with the largest switch-error possible. Each point in the plots is an average over $30$ random pairs $A$ and $B$ with the same knobs setting. In each plot we keep all but one knob constant.\n\n\\begin{figure}[h!]\n\\begin{center}\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_amp_noise_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 50){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (a)}\n\\put(-70  , 0){\\tiny $AMPnoise$}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_prob_del_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 45){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (b)}\n\\put(-70  , 0){\\tiny $DELprob$}\\\\ \\vspace{0.2cm}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_frag_prob_area_evol_MOTvsDCOMP.eps}\\;\n\n\\put(-108, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-63  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 45){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (c)}\n\\put(-70  , 0){\\tiny $FRAGprob$}\n\n\\includegraphics[trim = 10mm 0mm 10mm 0mm, clip, height=3.3cm]{./figures/V2_close_thres_area_evol_MOTvsDCOMP.eps}\n\n\\put(-105, 45){\\rotatebox{90}{\\tiny AUC}}\n\\put(-43  , 70){\\tiny \\color{red} MOTP}\n\\put(-50  , 42){\\tiny \\color{blue} $\\mathcal{D}_{comp}$}\n\\put(-55  , 90){\\tiny (d)}\n\\put(-70  , 0){\\tiny $SWIdist$}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\caption{AUC (normalized) versus (a) noise amplitude; (b) point deletion probability; (c) fragmenting probability; (d) switching distance. Smaller is better.}\n\\vspace{-0.5cm}\n\\label{fig:AUC_evol_synthetic_results}\n\\end{center}\n\\end{figure}\n\nAs expected from Theorem \\ref{th:optimal_tradeoff}, the AUC of $\\mathcal{D}_{comp}$ is smaller\nthan the AUC of MOTP. Note that it is incorrect to interpret these results as saying that MOTP is a like a scaled version of $\\mathcal{D}_{comp}$. Recall that we use the same $d^+$ to measure the distance between points in space in both MOTP and $\\mathcal{D}_{comp}$. We also compute the number of switches that the association of MOTP produces in the same way that we compute the number of switches that the association in $\\mathcal{D}_{comp}$ produces. The difference in the curves of Figure \\ref{fig:AUC_evol_synthetic_results} as a much deeper significance than a simple rescaling: for the $600$\nrandom pairs that we test, which consider different kinds\nof distortions between $A$ and $B$, and if we interpret each $A$ and $B$ as the ground-truth and output of a tracker, MOTP always says that the tracker is worse than it actually is. The $\\mathcal{D}_{comp}$ can see similarities between $A$ and $B$ that the MOTP cannot.\n\n\n\n\n\\vspace{-0.3cm}\n\\section{Conclusion}\n\nThe problem of defining a similarity measure between sets of trajectories\nis crucial for computer vision, machine learning and general AI.\nAn essential aspect in defining a similarity measure is finding a\ngood and simple association between the elements of the sets.\nExisting similarity measures that define useful associations fail\nto be a metric mathematically speaking and the ones that are a metric\nonly consider very primitive associations: full trajectories to full trajectories. The metric $\\mathcal{D}_{comp}$ is the first that \nsimultaneously (1) is a metric, (2) compares parts of trajectories\nto parts of trajectories, (3) allows to control the complexity of\nthe association between trajectories in an globally optimal way and (4) can be computed in polynomial time.\n\nThe general\nidea of defining mathematical metrics for sets of trajectories using\nconvex programs is our greatest overarching contribution. The next step\nis to explore variants of our metric that allow to incorporate uncertainty,\nas well as richer comparisons between $A$ and $B$ without losing\nits good properties.\n\n\\vspace{-0.3cm}\n\\bibliographystyle{IEEEtran}\n\\bibliography{tracking_metric} \n\n\n\n\n\n\\appendices\n\n\n\n\n\n\\section{The limitations of the CLEAR MOT}\\label{app:proof_of_th_mota_bad_association}\n\n\\begin{proof}[Proof of Theorem \\ref{th:MOT_inconsistent}]\nWe will construct an example for which the theorem is true. Our example proves the theorem for any $1 < thr < 2$ and for $A = \\{A_1,A_2\\}$ and $B=\\{B_1,B_2\\}$, i.e. $m=2$, where $A_i$ and $B_i$ are trajectories living in 1D. We explain how to generalize this example to any $thr$ and any $m$ at the end.\n\n\nConsider two sets of one-dimensional trajectories $A = \\{A_1,A_2 \\}$ and $B = \\{B_1, B_2\\}$ defined as in Figure \\ref{fig:clearmot_bad_metric} but where the\ntrajectories extend beyond instant $15$ until time $T$.\n\n\n\\begin{figure}[t]\n\\vspace{-0.7cm}\n\\begin{center}\n\\includegraphics[height=4.0cm]{./figures/motp_bad_not_a_metric.eps}\n\\put(-80,-5){\\small Time}\n\\put(-154,50){\\rotatebox{90}{\\small Space}}\n\\put(-35,98){\\rotatebox{0}{\\tiny $A_1$}}\n\\put(-35,92){\\rotatebox{0}{\\tiny $A_2$}}\n\\put(-35,85){\\rotatebox{0}{\\tiny $B_1$}}\n\\put(-35,79){\\rotatebox{0}{\\tiny $B_2$}}\n\\put(-35,72){\\rotatebox{0}{\\tiny $C_1$}}\n\\put(-35,65){\\rotatebox{0}{\\tiny $C_2$}}\n\\caption{Example that shows that (a) the CLEAR MOT association heuristic is bad and (b) MOTP does not define a metric.}\n\\vspace{-0.4cm}\n\\label{fig:clearmot_bad_metric}\n\\end{center}\n\\end{figure}\n\n\nIf $1 < thr <  2$ the CLEAR MOT builds a\nsequence $\\Sigma_{\\text{MOT}}$ that is equal to $\\{(1,2),...,(1,2),(2,1),(2,1),...\\}$ because at some instant between time $4$ and time $12$ the initial association $\\{A_1 \\leftrightarrow B_1, A_2 \\leftrightarrow B_2\\}$ exceeds $thr < 2$ and is replaced by $\\{A_2 \\leftrightarrow B_1, A_1 \\leftrightarrow B_2\\}$ and after instant $12$ this last  association is anchored given that $1 < thr$.\n\nThe number of times that $\\sigma_{\\text{MOT}}(t) \\neq \\sigma_{\\text{MOT}}(t+1)$ is $1$ so $swi(\\Sigma_{\\text{MOT}}) = \\frac{1}{T-1} = \\mathcal{O}(1/T)$. After instant $12$ we have $\\sum_{i} \\|A_i(t) - B_{\\sigma_{{\\text{MOT}}_i}(t)}(t)\\| = 2$\nso $dist(\\Sigma_{\\text{MOT}},A,B) >  \\frac{2(T-12)}{T} = 2 - \\mathcal{O}(1/T)$. However, if we choose $\\Sigma = \\{(1,2),...,(1,2)\\}$ we have $swi(\\Sigma) = 0$ and\n$dist(\\Sigma,A,B) < \\frac{12 \\times 7.5}{T} = \\mathcal{O}(1/T)$.\n\n\nWe can make the proof hold for an interval around any $thr$ by rescaling space. This changes the bounds on $dist$ by a factor of $thr$ and leaves the bounds on $swi$ unchanged.\n\nIn addition, we can make the proof hold for any $m$ (even) by extending $A$ and $B$ as follows. If the 1D trajectory $A_i$ above is equal to $\\{(1,A_i(1)),...,(T,A_i(T))\\}$ define the 2D trajectory $A^{(k)}_i$ to have time-state pairs $\\{(1,[A_i(1)); C k],...,(T,[A_i(T); Ck])\\}$ where $C$ is a constant large enough to guarantee that trajectories for different $k$s are not close to each other. Define $B^{(k)}_i$ in a similar way. To make the proof hold for any $m$ (even) extend $A$ to $A = \\{A^{(0)}_1,A^{(0)}_2,A^{(1)}_1,A^{(1)}_2,...,A^{(m-1)}_1,A^{(m-1)}_2\\}$ and extend $B$ in a similar way. To extend the proof for an odd $m$ simply append to $A$ and $B$ two equal trajectories far away from all other trajectories such that they are matched and hence contribute nothing to both $swi$ or $dist$. With these sets the bounds previously computed on $swi()$ change by a factor of $m$ and the bounds on $dist(.)$ change by a factor of $m/2$. In the statement of our theorem statement we are using $\\mathcal{O}(m/T) = \\mathcal{O}(1/T)$ and $\\mathcal{O}(m \\, thr/T) = \\mathcal{O}(1/T)$.\n\\end{proof}\n\n\n\n\n\n\\label{app:proof_of_th_motp_not_metric}\n\n\\begin{proof}[Proof of Theorem \\ref{th:MOPT_no_metric}]\nWe construct $A,B,C \\in \\mathcal{S}$ for which the triangle inequality is violated, specifically, $\\mathcal{D}(A,B) > \\mathcal{D}(A,C) + \\mathcal{D}(C,B)$. Our example\nproves that the theorem holds for $1 < thr < 2$ but by rescaling space the proof follows for any $thr > 0$.\n\nConsider the sets $A = \\{A_1, A_2\\}$, $B = \\{B_1, B_2\\}$ and\n$C = \\{C_1, C_2\\}$ as in Figure \\ref{fig:clearmot_bad_metric} but where the trajectories extend beyond time $15$ to some large $T$. To make calculations simpler, we work with $\\mathcal{D}$ divided by $T$ in Definition \\ref{def:MOT_metric}.\n\nLet us compute $\\mathcal{D}(A,B)$ first. The association $\\Sigma_{\\text{MOT}}$ for this distance is $\\{(1,2),..,(1,2),(2,1),...\\}$ because (1) we start with the association $\\{A_1 \\leftrightarrow B_1,A_2 \\leftrightarrow B_2\\}$, (2) at some point between instant $4$ and instant $12$ we need to change the association to $\\{A_1 \\leftrightarrow B_2,A_2 \\leftrightarrow B_1\\}$\nbecause the initial association exceeds $thr < 2$ and (3) after time $12$ the association \n$\\{A_1 \\leftrightarrow B_2,A_2 \\leftrightarrow B_1\\}$ is anchored because $thr > 1$. This association leads to $\\mathcal{D}(A,B) > \\frac{2(T-12)}{T}$.\n\nNow we compute $\\mathcal{D}(A,C)$. The computation for $\\mathcal{D}(C,B)$ is similar so we omit it. The association for $\\mathcal{D}(A,C)$ is $\\Sigma_{\\text{MOT}} = \\{(1,2),...,(1,2)\\}$ because (1) we start with $\\{A_1 \\leftrightarrow C_1,A_2 \\leftrightarrow C_2\\}$, (2) the association $A_1 \\leftrightarrow C_1$ is always anchored because the distance between $A_1$ and $C_1$ is always zero and thus always smaller than $thr > 1$ and (3) after some point between instant $4$ and instant $12$, when the distance between $A_2$ and $C_2$ exceeds $thr < 2$, MOTP still keeps the association $A_2 \\leftrightarrow C_2$ because $A_1$ and $C_1$ are already anchored.\nThis association leads to $\\mathcal{D}(A, C) < \\frac{8.5}{T}$.\n\nTherefore, for $T$ large enough we have\n$\\mathcal{D}(A, B) > \\frac{2(T-12)}{T} > \n\\frac{8.5}{T} + \\frac{8.5}{T} > \\mathcal{D}(A, C) + \\mathcal{D}(C, B)$.\n\\end{proof}\n\n\n\n\n\\section{A natural metric for sets of trajectories} \\label{app:proof_of_th_d_nat_is_metric}\n\nTo prove Theorem \\ref{th:Dnaturalismetric}\nwe need the following Lemma.\n\n\n\\begin{lemma} \\label{th:extdismetric}\nThe map $d^+$ is a metric on $\\mathbb{R}^p \\cup \\{*\\}$.\n\\end{lemma}\n\\begin{proof}\nLet $x'',x',x \\in \\mathbb{R}^p \\cup \\{*\\}$. To prove the coincidence property observe that $d^+(x,x') = 0$ either implies that $x=x'=*$ or, since $M>0$, implies that $d^+(x,x') = d(x,x') = 0$, which, because $d$ is a metric, implies that $x=x'=0$. In other words, $d^+(x,x') = 0 \\Leftrightarrow x=x'$. The symmetry property, $d^+(x,x')=d^+(x',x)$, follows directly from\nthe definition. To prove the subadditivity property we need to\nconsider eight different cases. It is trivial to check that the following six cases satisfy the triangle inequality: $x,x',x'' \\in \\mathbb{R}^p$; $x=x'=*,x'' \\in \\mathbb{R}^p$; $x''=x'=*,x \\in \\mathbb{R}^p$; $x=*,x',x'' \\in \\mathbb{R}^p$; $x''=*,x,x' \\in \\mathbb{R}^p$; $x=x''=*,x' \\in \\mathbb{R}^p$. We check the two other cases separately. If $x,x',x'' \\in \\mathbb{R}^p$ then $d^+(x,x'') = \\min\\{2M,d(x,x'') \\} \\leq \\min \\{2M,d(x,x') + d(x',x'')\\} \\leq \\min\\{2M,d(x,x')\\} + \\min\\{2M,d(x',x'')\\} = d^+(x,x') + d^+(x',x'')$. If $x'=*, x,x'' \\in \\mathbb{R}^p$ then\n$d^(x,x'') = \\min\\{2M,d(x,x'') \\} \\leq M + M = d^+(x,x') + d^+(x',x'')$.\n\\end{proof}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:Dnaturalismetric}]\nLet $A,B,C$ be any three elements in $\\mathcal{S}$.\\\\\n\\emph{Coincidence property}:\nWe show that ${\\mathcal{D}_{nat}}(A,B) = 0$ if and only if $A = B$.\nRemember that $A$ and $B$ are unordered sets\nof trajectories so $A = B$ means that there is an isomorphism\nbetween $A$ and $B$. In other words, they are equal apart tom\na relabeling of their elements.\nIf $A = B$ and we set $\\Sigma = (\\sigma,\\sigma,...,\\sigma)$\nwhere $\\sigma$ is an isomorphism between $A$ and $B$,\nthen the objective in \\eqref{eq:defDnat} is equal to zero.\nSince the minimum of \\eqref{eq:defDnat}\nmust always be non-negative,\nwe conclude that $A = B \\Rightarrow {\\mathcal{D}_{nat}}(A,B) = 0$.\nNow assume that ${\\mathcal{D}_{nat}}(A,B) = 0$ and let $\\Sigma^*=(\\sigma^*(1),...,\\sigma^*(T))$ be a\nminimizer of \\eqref{eq:defDnat}. ${\\mathcal{D}_{nat}}(A,B) = 0$ implies that\n$\\mathcal{K}(\\Sigma^*) = 0$ and therefore $\\sigma^*_i(t) = \\sigma^*_i(1)$\nfor all $t$ and $i$. Since the labeling of the trajectories does not matter\nin computing ${\\mathcal{D}_{nat}}$, we assume without loss of generality that \ntheir labeling is such that we can write $\\sigma^*_i(t) = i$.\n${\\mathcal{D}_{nat}}(A,B) = 0$ also implies that, for all $t$ and $i$, we have\n$d^+(A^+_i(t),B^+_{\\sigma^*_i(t)}(t)) = d^+(A^+_i(t),B^+_{i}(t)) = 0$.\nSince $d^+$ is a\nmetric this in turn implies that $A^+_i(t) = B^+_i(t)$ for all $i$ and $t$, which is the same as saying that $A^+ = B^+$. If $A \\neq B$ then $A^+ \\neq B^+$\ntherefore $A^+ = B^+$ implies that $A = B$. To be more specific,\n$A$ is equal to $B$ apart from a relabeling of its trajectories, which\nwe can do because $A$ and $B$ are unordered sets of trajectories.\\\\\n\\emph{Symmetry property}: ${\\mathcal{D}_{nat}}$ only depends on $A$ and $B$ through\n$d^+$ and, like all metrics, this is a symmetric function.\nIn addition, if we swap $i$ and $\\sigma_i(t)$ in \\eqref{eq:defDnat}\nthe minimum of \\eqref{eq:defDnat} remains unchanged. It follows that\n${\\mathcal{D}_{nat}}(A,B) = {\\mathcal{D}_{nat}}(B,A)$.\\\\\n\\emph{Subadditivity property}: We prove that ${\\mathcal{D}_{nat}}(A,C) \\leq {\\mathcal{D}_{nat}}(A,B) + {\\mathcal{D}_{nat}}(B,C)$. Since $d^+$ is a metric, we can write that\n\n\n", "index": 17, "text": "\\begin{align} \\label{eq:addingBtoproofDnat}\n&d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t)) \\leq d^+(A^+_i(t),B^+_{\\sigma'_{\\sigma_i(t)}(t)}(t))\\nonumber\\\\\n& + d^+(B^+_{\\sigma'_{\\sigma_i(t)}(t)}(t),C^+_{\\sigma_i(t)}(t))\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle d^{+}(A^{+}_{i}(t),C^{+}_{\\sigma_{i}(t)}(t))\\leq d^{+}(A^{+}_{i}%&#10;(t),B^{+}_{\\sigma^{\\prime}_{\\sigma_{i}(t)}(t)}(t))\" display=\"inline\"><mrow><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+d^{+}(B^{+}_{\\sigma^{\\prime}_{\\sigma_{i}(t)}(t)}(t),C^{+}_{%&#10;\\sigma_{i}(t)}(t))\" display=\"inline\"><mrow><mo>+</mo><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nUsing this together with \\eqref{eq:addingBtoproofDnat} we can write\n\n\n", "itemtype": "equation", "pos": 78380, "prevtext": "\n\nfor any $\\Sigma' = (\\sigma'(1),...,\\sigma'(T)) \\in \\Pi^T$ and for all $i$ and $t$. Now notice that\n\n\n", "index": 19, "text": "\\begin{align*}\n\\sum^m_{i=1}d^+(B^+_{\\sigma'_{\\sigma_i(t)}(t)}(t),C^+_{\\sigma_i(t)}(t))\n= \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)).\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum^{m}_{i=1}d^{+}(B^{+}_{\\sigma^{\\prime}_{\\sigma_{i}(t)}(t)}(t)%&#10;,C^{+}_{\\sigma_{i}(t)}(t))=\\sum^{m}_{i=1}d^{+}(B^{+}_{\\sigma^{\\prime}_{i}(t)}(%&#10;t),C^{+}_{i}(t)).\" display=\"inline\"><mrow><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nLet us define $\\Sigma'' = (\\sigma''(1),...,\\sigma''(T)) \\in \\Pi^T$ where\n$\\sigma''_i(t) = \\sigma'_{\\sigma_i(t)}(t)$. This means that\n$\\Sigma'' = \\Sigma' \\circ \\Sigma$. We can use $\\Sigma'$\nto rewrite the above expression as\n\n\n", "itemtype": "equation", "pos": 78605, "prevtext": "\n\nUsing this together with \\eqref{eq:addingBtoproofDnat} we can write\n\n\n", "index": 21, "text": "\\begin{align*}\n&\\sum^T_{t=1} \\sum^m_{i=1} d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t))\n\\leq \\sum^T_{t=1} \\sum^m_{i=1}d^+(A^+_i(t),B^+_{\\sigma'_{\\sigma_i(t)}(t)}(t))\\\\\n&+ \\sum^T_{t=1} \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)).\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),C^{+}_{\\sigma_{i}(%&#10;t)}(t))\\leq\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma^{%&#10;\\prime}_{\\sigma_{i}(t)}(t)}(t))\" display=\"inline\"><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(B^{+}_{\\sigma^{\\prime}_{i}(t)}%&#10;(t),C^{+}_{i}(t)).\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nIf we use the second and third property that $\\mathcal{K}$ satisfies we can also write\n\n\n", "itemtype": "equation", "pos": 79070, "prevtext": "\n\nLet us define $\\Sigma'' = (\\sigma''(1),...,\\sigma''(T)) \\in \\Pi^T$ where\n$\\sigma''_i(t) = \\sigma'_{\\sigma_i(t)}(t)$. This means that\n$\\Sigma'' = \\Sigma' \\circ \\Sigma$. We can use $\\Sigma'$\nto rewrite the above expression as\n\n\n", "index": 23, "text": "\\begin{align} \\label{eq:distanceineqproofDnat}\n&\\sum^T_{t=1} \\sum^m_{i=1} d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t))\n\\leq \\sum^T_{t=1} \\sum^m_{i=1}d^+(A^+_i(t),B^+_{\\sigma''_{i}(t)}(t))\\nonumber\\\\\n&+ \\sum^T_{t=1} \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)).\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),C^{+}_{\\sigma_{i}(%&#10;t)}(t))\\leq\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma^{%&#10;\\prime\\prime}_{i}(t)}(t))\" display=\"inline\"><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mi>\u2032\u2032</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(B^{+}_{\\sigma^{\\prime}_{i}(t)}%&#10;(t),C^{+}_{i}(t)).\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nNow we add both sides of \\eqref{eq:distanceineqproofDnat} and\n\\eqref{eq:matchineqproofDnat} and obtain\n\n$\n\\mathcal{K}(\\Sigma) + \\sum^T_{t=1} \\sum^m_{i=1} d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t))\n \\leq \\mathcal{K}(\\Sigma'') + \\sum^T_{t=1} \\sum^m_{i=1}d^+(A^+_i(t),B^+_{\\sigma''_{i}(t)}(t))\n + \\mathcal{K}(\\Sigma')+\\sum^T_{t=1} \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)).\n$\n\nFinally, we find the minimum of both sides of the inequality over all pairs\nof $\\Sigma$ and $\\Sigma'$. Recall that we can choose $\\Sigma'$ \nindependently of $\\Sigma$. Since for every pair $(\\Sigma,\\Sigma')$\nthere is exactly one pair $(\\Sigma',\\Sigma'')$, finding the minimum over\n$\\Sigma$ and $\\Sigma'$ is the same as finding the minimum over\n$\\Sigma'$ and $\\Sigma''$. Therefore we get,\n\n\n", "itemtype": "equation", "pos": 79429, "prevtext": "\n\nIf we use the second and third property that $\\mathcal{K}$ satisfies we can also write\n\n\n", "index": 25, "text": "\\begin{align} \\label{eq:matchineqproofDnat}\n&\\mathcal{K}(\\Sigma) = \\mathcal{K}(\\Sigma'^{-1} \\circ \\Sigma' \\circ \\Sigma) \\leq \\mathcal{K}(\\Sigma'^{-1}) +  \\mathcal{K}(\\Sigma' \\circ \\Sigma) \\nonumber\\\\\n&= \\mathcal{K}(\\Sigma') +  \\mathcal{K}(\\Sigma'').\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{K}(\\Sigma)=\\mathcal{K}(\\Sigma^{\\prime-1}\\circ\\Sigma^{%&#10;\\prime}\\circ\\Sigma)\\leq\\mathcal{K}(\\Sigma^{\\prime-1})+\\mathcal{K}(\\Sigma^{%&#10;\\prime}\\circ\\Sigma)\" display=\"inline\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mrow><mo>-</mo><mn>1</mn></mrow></mrow></msup><mo>\u2218</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2032</mo></msup><mo>\u2218</mo><mi mathvariant=\"normal\">\u03a3</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mrow><mo>-</mo><mn>1</mn></mrow></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2032</mo></msup><mo>\u2218</mo><mi mathvariant=\"normal\">\u03a3</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mathcal{K}(\\Sigma^{\\prime})+\\mathcal{K}(\\Sigma^{\\prime\\prime}).\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mi>\u2032\u2032</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n\nwhich is the same as ${\\mathcal{D}_{nat}}(A,C) \\leq {\\mathcal{D}_{nat}}(A,B) + {\\mathcal{D}_{nat}}(B,C)$.\n\\end{proof}\n\n\n\n\n\n\n\n\\label{app:proof_for_K_propreties}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_count}]\nThe first two properties are\nimmediate to check. To prove the third property it sufficient to prove that \n$\\mathbb{I}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1} \\neq I) \\leq \\mathbb{I}(\\sigma(t+1) \\circ \\sigma(t)^{-1} \\neq I) +\\mathbb{I}(\\sigma'(t+1) \\circ \\sigma'(t)^{-1} \\neq I).$\nTo prove this we consider different cases. If $\\sigma'(t+1) = \\sigma'(t)$ and $\\sigma(t+1) = \\sigma(t)$ then the inequality holds as $0 \\leq 0 + 0$. If $\\sigma'(t+1) \\neq \\sigma'(t)$ and $\\sigma(t+1) \\neq \\sigma(t)$ then the inequality holds since the left hand side is at most $1$ and the right hand side in this case is equal to $1 + 1$. If $\\sigma(t+1) = \\sigma(t)$ and $\\sigma'(t+1) \\neq \\sigma'(t)$ then the inequality holds as $1 \\leq 0 + 1$. The final case is when $\\sigma(t+1) \\neq \\sigma(t)$ and $\\sigma'(t+1) = \\sigma'(t)$. Notice that\n$\\mathbb{I}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1} \\neq I) = \\mathbb{I}( \\sigma(t+1)  \\circ \\sigma(t)^{-1} \\neq \\sigma'(t+1)^{-1}\\circ\\sigma'(t))$\nand conclude that the inequality holds with $1 \\leq 1 + 0$.\n\\end{proof}\n\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_trans} and Theorem \\ref{th:K_adjtrans}]\nWe prove the theorem for $\\mathcal{K}_{trans}$. The proof\nfor $\\mathcal{K}_{adjtrans}$ is very similar. The first two properties\nare immediate to check from the definition of $\\mathcal{K}_{trans}$. To prove the third property it suffices to show that\n\n$k_{Cayley}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1}) \\leq k_{Cayley}(\\sigma(t+1)) \\circ  \\sigma(t)^{-1}) + k_{Cayley}(\\sigma'(t+1) \\circ \\sigma'(t))^{-1}).$\n\nTo prove this we use of the following two facts.\n\nFact 1: if $\\sigma,\\sigma' \\in \\Pi$ then $k_{Cayley}(\\sigma\\circ\\sigma') \\leq k_{Cayley}(\\sigma) + k_{Cayley}(\\sigma')$. Fact 2: if $\\sigma,\\sigma' \\in \\Pi$ then $k_{Cayley}(\\sigma\\circ \\sigma' \\circ\\sigma^{-1}) = k_{Cayley}(\\sigma' )$. Both facts are obvious if stated in plain english.\n\nFact 1: The shortest set of transpositions that takes $\\sigma\\circ\\sigma'$ to $I$ is shorter than any set of transpositions that first takes $\\sigma\\circ\\sigma'$ to $\\sigma'$ and then takes $\\sigma'$ to $I$. Fact 2: The shortest set of transpositions that takes a permutation of objects to the identity permutation is as short as the set of transpositions that take a relabeling of those objects to the identity permutation.\n\nLet $\\sigma_A=\\sigma(t)\\circ \\sigma(t+1)^{-1}$, $\\sigma_B = \\sigma'(t)\\circ \\sigma'(t+1)^{-1}$ and let $\\sigma_C=\\sigma'(t)\\circ \\sigma_A\\circ \\sigma'(t)^{-1}$.\n\nObserve that the permutation $\\sigma_C \\circ \\sigma_B$ satisfies\n\n", "itemtype": "equation", "pos": 80456, "prevtext": "\n\nNow we add both sides of \\eqref{eq:distanceineqproofDnat} and\n\\eqref{eq:matchineqproofDnat} and obtain\n\n$\n\\mathcal{K}(\\Sigma) + \\sum^T_{t=1} \\sum^m_{i=1} d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t))\n \\leq \\mathcal{K}(\\Sigma'') + \\sum^T_{t=1} \\sum^m_{i=1}d^+(A^+_i(t),B^+_{\\sigma''_{i}(t)}(t))\n + \\mathcal{K}(\\Sigma')+\\sum^T_{t=1} \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)).\n$\n\nFinally, we find the minimum of both sides of the inequality over all pairs\nof $\\Sigma$ and $\\Sigma'$. Recall that we can choose $\\Sigma'$ \nindependently of $\\Sigma$. Since for every pair $(\\Sigma,\\Sigma')$\nthere is exactly one pair $(\\Sigma',\\Sigma'')$, finding the minimum over\n$\\Sigma$ and $\\Sigma'$ is the same as finding the minimum over\n$\\Sigma'$ and $\\Sigma''$. Therefore we get,\n\n\n", "index": 27, "text": "\\begin{align*} \n&\\min_{\\Sigma \\in \\Pi^T} \\mathcal{K}(\\Sigma) + \\sum^T_{t=1} \\sum^m_{i=1} d^+(A^+_i(t),C^+_{\\sigma_i(t)}(t))\\\\\n& \\leq \\min_{\\Sigma''\\in \\Pi^T} \\mathcal{K}(\\Sigma'') + \\sum^T_{t=1} \\sum^m_{i=1}d^+(A^+_i(t),B^+_{\\sigma''_{i}(t)}(t))\\\\\n& + \\min_{\\Sigma'\\in \\Pi^T} \\mathcal{K}(\\Sigma')+\\sum^T_{t=1} \\sum^m_{i=1}d^+(B^+_{\\sigma'_{i}(t)}(t),C^+_{i}(t)),\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\Sigma\\in\\Pi^{T}}\\mathcal{K}(\\Sigma)+\\sum^{T}_{t=1}\\sum^{m}%&#10;_{i=1}d^{+}(A^{+}_{i}(t),C^{+}_{\\sigma_{i}(t)}(t))\" display=\"inline\"><mrow><mrow><mrow><munder><mi>min</mi><mrow><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2208</mo><msup><mi mathvariant=\"normal\">\u03a0</mi><mi>T</mi></msup></mrow></munder><mo>\u2061</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mrow><msub><mi>\u03c3</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\min_{\\Sigma^{\\prime\\prime}\\in\\Pi^{T}}\\mathcal{K}(\\Sigma^{%&#10;\\prime\\prime})+\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(A^{+}_{i}(t),B^{+}_{\\sigma^{%&#10;\\prime\\prime}_{i}(t)}(t))\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mrow><mrow><munder><mi>min</mi><mrow><msup><mi mathvariant=\"normal\">\u03a3</mi><mi>\u2032\u2032</mi></msup><mo>\u2208</mo><msup><mi mathvariant=\"normal\">\u03a0</mi><mi>T</mi></msup></mrow></munder><mo>\u2061</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mi>\u2032\u2032</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mi>\u2032\u2032</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\min_{\\Sigma^{\\prime}\\in\\Pi^{T}}\\mathcal{K}(\\Sigma^{\\prime})+%&#10;\\sum^{T}_{t=1}\\sum^{m}_{i=1}d^{+}(B^{+}_{\\sigma^{\\prime}_{i}(t)}(t),C^{+}_{i}(%&#10;t)),\" display=\"inline\"><mrow><mrow><mrow><mo>+</mo><mrow><mrow><munder><mi>min</mi><mrow><msup><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2032</mo></msup><mo>\u2208</mo><msup><mi mathvariant=\"normal\">\u03a0</mi><mi>T</mi></msup></mrow></munder><mo>\u2061</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u03a3</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><msup><mi>d</mi><mo>+</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>B</mi><mrow><msubsup><mi>\u03c3</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>C</mi><mi>i</mi><mo>+</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\nTherefore we can apply Fact 2 followed by Fact 1 and obtain\n\n$\nk_{Cayley}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1}) = k_{Cayley}(\\sigma^{-1}_B \\circ \\sigma^{-1}_C)\n\\leq k_{Cayley}(\\sigma^{-1}_B) + k_{Cayley}( \\sigma^{-1}_C) = k_{Cayley}(\\sigma^{-1}_B) + k_{Cayley}( \\sigma^{-1}_A)\n = k_{Cayley}(\\sigma(t+1)\\circ\\sigma(t)^{-1}) + k_{Cayley}(\\sigma'(t+1)\\circ\\sigma'(t)^{-1}).\n$\n\n\\end{proof}\n\n\n\n\n\n\n\n\\label{app:necessary_conditions_for_D_nat_metric}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_maxcount_not_proper}]\nWe give a counter example that violates property (iii)\nfor $\\beta = 1$. It is easy to come up with similar\ncounter examples that violate property (iii) for any value\nof $\\beta \\geq 1$. Let $I = (1,2)$ be\nthe identity permutation and let $\\sigma_0 = (2,1)$ be the permutation that swaps $1$ and $2$. Let $\\Sigma = (I,\\sigma_0,\\sigma_0)$ and let $\\Sigma' = (I,I,\\sigma_0)$.\nWe have $\\mathcal{K}_{maxcount}(\\Sigma) = 1$ and \n$\\mathcal{K}_{maxcount}(\\Sigma') = 1$ but\n$\\mathcal{K}_{maxcount}(\\Sigma' \\circ \\Sigma) = \\infty > \\mathcal{K}_{maxcount}(\\Sigma') + \\mathcal{K}_{maxcount}(\\Sigma)$.\n\\end{proof}\n\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_maxcount_leads_to_not_metric}]\nWe produce three sets of trajectories $A$, $B$ and $C$\nthat make \\eqref{eq:defDnat} violate\nthe triangle inequality. In this proof we assume $\\beta = 1$\nbut it is easy to change $A$, $B$ and $C$ such that\nthe proof holds for any $\\beta$,\\footnote{It is also not hard to see that\nwe do not really need $d$ to be the Euclidean distance for the proof to hold.}.\n\nLet $I = (1,2)$ be\nthe identity permutation and let $\\sigma_0 = (2,1)$\nbe the permutation that swaps $1$ and $2$.\nLet $A = \\{A_1,A_2\\}$ where\n$A_1 = \\{(1, 2), (2, -2),(3, -2)\\}$ and\n$A_2 = \\{(1, -2), (2, 2),(3, 2)\\}$,\nlet $B = \\{B_1,B_2\\}$\nwhere $B_1 = \\{(1,2), (2,2),(3,2)\\}$ and $B_2 = \\{(1,-2), (2,-2),(3,-2)\\}$ and let $C = \\{C_1,C_2\\}$ where\n$C_1 = \\{(1, 2), (2, 2),(3, -2)\\}$ and\n$C_2 = \\{(1, -2),$ $(2, -2),$ $(3, 2)\\}$.\n\nNow consider \\eqref{eq:defDnat} with $\\mathcal{K} = \\mathcal{K}_{maxcount}$ and $\\beta = 1$.\nThe optimization problem \n$\\mathcal{D}_{nat}(A,B)$ has a minimum of $1$ at\n$\\Sigma = (I,\\sigma_0,\\sigma_0)$.\nThe optimization problem $\\mathcal{D}_{nat}(B,C)$\nhas a minimum of $1$ at\n$\\Sigma = (I,I,\\sigma_0)$. When we solve the optimization\nproblem $\\mathcal{D}_{nat}(A,C)$ we are only allowed\nto perform one change in the association between $A$\nand $C$, otherwise the term $\\mathcal{K}_{maxcount}$\nmakes us pay a very large cost. With only one change\nin the association, we incur in a distance of $4$\nfor $t = 1$ or $t = 2$ or $t = 3$. Hence, $\\mathcal{D}_{nat}(A,C) \\geq 4 > 1 + 1 = \\mathcal{D}_{nat}(A,B) + \\mathcal{D}_{nat}(B,C)$.\n\\end{proof}\n\n\n\n\n\n\\section{A natural and computable metric} \\label{app:proof_that_D_comp_is_metric}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:D_comp_is_metric}]\nLet $A, B$ and $C$ be any three elements of $\\mathcal{S}$.\\\\\n\\emph{Coincidence property}: If $\\mathcal{D}_{comp}(A,B) = 0$\nthen $W(t) = W(1)$ for all $t$. Hence, if $\\mathcal{D}_{comp}(A,B) = 0$ then $D^{AB}(t)_{ij} = 0$ for all $i,j$ such that\n$W(1)_{ij} > 0$. Now recall that if $W_{ij}$ is a doubly stochastic matrix then there exists a permutation $\\sigma \\in \\Pi$ such that\n$W_{i\\sigma_i} > 0$ for all $i$.  Therefore, there exist $\\sigma \\in \\Pi$ such\nthat $D^{AB}(t)_{i\\sigma_i} = 0$ for all $t$ and $i$. In other words,\n$A$ and $B$ are the same apart from a relabeling of their elements.\\\\\n\\emph{Symmetry property}: Using the properties of {\\bf tr} we have\nthat $\\text{\\bf tr}(W^{\\dagger}(t)D^{AB}(t)) =$ \n$\\text{\\bf tr}((W^{\\dagger}(t)$ $D^{AB}(t))^{\\dagger})$ $= \\text{\\bf tr}(D^{AB}(t)^{\\dagger}W(t))= \\text{\\bf tr}(D^{BA}(t)W(t))= \\text{\\bf tr}(W(t) D^{BA}(t))$. Minimizing with respect to $\\{W(t)\\}$ is the same as minimizing with\nrespect to $\\{W(t)^{\\dagger}\\}$ so $\\mathcal{D}_{comp}(A,B) = \\mathcal{D}_{comp}(B,A)$.\\\\\n\\emph{Subadditivity property}: We prove that\n$\\mathcal{D}_{comp}(A,C) \\leq \\mathcal{D}_{comp}(A,B) + \\mathcal{D}_{comp}(B,C)$. First note that, since $d^+$ is a metric we have\nthat $D^{AC}(t)_{ij} \\leq D^{AB}(t)_{ik} + D^{BC}(t)_{kj}$ for any $k$.\nLet $\\{W_1(t)\\}, \\{W_2(t)\\} \\in \\mathcal{P}^T$. We multiply both\nsides of the previous inequality by $W_1(t)_{ik}W_2(t)_{kj}$ and\nsum over $ijk$ and obtain\n\n$\n\\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj} D^{AC}(t)_{ij}\\leq \\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj} D^{AB}(t)_{ik}\\\\\n+ \\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj}D^{BC}(t)_{kj}.\n$\n\nNote that $W_1(t)$ and $W_2(t)$ are doubly stochastic\nmatrices therefore we have $\\sum^m_{j=1} W_2(t)_{kj} = 1$ and\n$\\sum^m_{i=1} W_1(t)_{ik} = 1$ and we can re-write the previous\ninequality in matrix for as\n\n$\n\\text{\\bf tr}((W_1(t)W_2(t))^{\\dagger} D^{AC}(t)) \\leq\n\\text{\\bf tr}(W_1(t)^{\\dagger} D^{AB}(t)) + \n\\text{\\bf tr}(W_2(t)^{\\dagger} D^{BC}(t)).\n$\n\nFrom the definition of $\\|\\|$ we have that\n$\\|W_1(t+1)W_2(t+1) - W_1(t)W_2(t)\\| \\leq \\|W_1(t+1) - W_1(t)\\| + \\|W_2(t+1) - W_2(t)\\|.$ Summing both sides of the last two inequalities\nand, summing over $t$, and minimizing over $\\{W_1(t)\\}, \\{W_2(t)\\} \\in \\mathcal{P}^T$ we have\nthat\n\n{\\small\n\n", "itemtype": "equation", "pos": 83675, "prevtext": "\n\nwhich is the same as ${\\mathcal{D}_{nat}}(A,C) \\leq {\\mathcal{D}_{nat}}(A,B) + {\\mathcal{D}_{nat}}(B,C)$.\n\\end{proof}\n\n\n\n\n\n\n\n\\label{app:proof_for_K_propreties}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_count}]\nThe first two properties are\nimmediate to check. To prove the third property it sufficient to prove that \n$\\mathbb{I}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1} \\neq I) \\leq \\mathbb{I}(\\sigma(t+1) \\circ \\sigma(t)^{-1} \\neq I) +\\mathbb{I}(\\sigma'(t+1) \\circ \\sigma'(t)^{-1} \\neq I).$\nTo prove this we consider different cases. If $\\sigma'(t+1) = \\sigma'(t)$ and $\\sigma(t+1) = \\sigma(t)$ then the inequality holds as $0 \\leq 0 + 0$. If $\\sigma'(t+1) \\neq \\sigma'(t)$ and $\\sigma(t+1) \\neq \\sigma(t)$ then the inequality holds since the left hand side is at most $1$ and the right hand side in this case is equal to $1 + 1$. If $\\sigma(t+1) = \\sigma(t)$ and $\\sigma'(t+1) \\neq \\sigma'(t)$ then the inequality holds as $1 \\leq 0 + 1$. The final case is when $\\sigma(t+1) \\neq \\sigma(t)$ and $\\sigma'(t+1) = \\sigma'(t)$. Notice that\n$\\mathbb{I}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1} \\neq I) = \\mathbb{I}( \\sigma(t+1)  \\circ \\sigma(t)^{-1} \\neq \\sigma'(t+1)^{-1}\\circ\\sigma'(t))$\nand conclude that the inequality holds with $1 \\leq 1 + 0$.\n\\end{proof}\n\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_trans} and Theorem \\ref{th:K_adjtrans}]\nWe prove the theorem for $\\mathcal{K}_{trans}$. The proof\nfor $\\mathcal{K}_{adjtrans}$ is very similar. The first two properties\nare immediate to check from the definition of $\\mathcal{K}_{trans}$. To prove the third property it suffices to show that\n\n$k_{Cayley}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1}) \\leq k_{Cayley}(\\sigma(t+1)) \\circ  \\sigma(t)^{-1}) + k_{Cayley}(\\sigma'(t+1) \\circ \\sigma'(t))^{-1}).$\n\nTo prove this we use of the following two facts.\n\nFact 1: if $\\sigma,\\sigma' \\in \\Pi$ then $k_{Cayley}(\\sigma\\circ\\sigma') \\leq k_{Cayley}(\\sigma) + k_{Cayley}(\\sigma')$. Fact 2: if $\\sigma,\\sigma' \\in \\Pi$ then $k_{Cayley}(\\sigma\\circ \\sigma' \\circ\\sigma^{-1}) = k_{Cayley}(\\sigma' )$. Both facts are obvious if stated in plain english.\n\nFact 1: The shortest set of transpositions that takes $\\sigma\\circ\\sigma'$ to $I$ is shorter than any set of transpositions that first takes $\\sigma\\circ\\sigma'$ to $\\sigma'$ and then takes $\\sigma'$ to $I$. Fact 2: The shortest set of transpositions that takes a permutation of objects to the identity permutation is as short as the set of transpositions that take a relabeling of those objects to the identity permutation.\n\nLet $\\sigma_A=\\sigma(t)\\circ \\sigma(t+1)^{-1}$, $\\sigma_B = \\sigma'(t)\\circ \\sigma'(t+1)^{-1}$ and let $\\sigma_C=\\sigma'(t)\\circ \\sigma_A\\circ \\sigma'(t)^{-1}$.\n\nObserve that the permutation $\\sigma_C \\circ \\sigma_B$ satisfies\n\n", "index": 29, "text": "$$\\sigma_C \\circ \\sigma_B \\circ ((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1}) = I.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\sigma_{C}\\circ\\sigma_{B}\\circ((\\sigma^{\\prime}(t+1)\\circ\\sigma(t+1))\\circ(%&#10;\\sigma^{\\prime}(t)\\circ\\sigma(t))^{-1})=I.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c3</mi><mi>C</mi></msub><mo>\u2218</mo><msub><mi>\u03c3</mi><mi>B</mi></msub><mo>\u2218</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2218</mo><mi>\u03c3</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2218</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><msup><mi>\u03c3</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2218</mo><mi>\u03c3</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi>I</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03094.tex", "nexttext": "\n}\n\nNote that for any $W_1(t), W_2(t) \\in \\mathcal{P}$ we have that\n$W_1(t) W_2(t) \\in \\mathcal{P}$ so \nin the minimization performed on the left hand side\nwe can replace $W_1(t) W_2(t)$ by a single $W(t)$.\nThe subadditivity property follows.\n\\end{proof}\n\n\n\n\n\n\n\n\\label{app:proof_that_norms_for_Dcomp_are_many}\n\n\n\\begin{proof}[Proof of Lemma \\ref{th:many_norms_satisfy_D_comp}]\nLet $X_1,X_2,Y_1, Y_2 \\in \\mathcal{P}$. By an application\nof the triangle inequality followed by two applications of the\nsub-multiplicative property followed by two applications of the\nnorm-bound property we have that\n$\n\\|Y_2X_2 - Y_1 X_1\\| \\leq \\|Y_2(X_2 -X_1 + X_1)- Y_1 X_1\\| \n\\leq \\|Y_2(X_2 -X_1)\\| + \\| Y_2 X_1 - Y_1 X_1\\|\n = \n\\|Y_2(X_2 -X_1)\\| + \\| (Y_2 -Y_1)X_1\\|\n\\leq\n\\|Y_2\\| \\|(X_2 -X_1)\\| + \\| (Y_2 -Y_1)\\| \\|X_1\\|\n\\leq \\|(X_2 -X_1)\\| + \\| (Y_2 -Y_1)\\|$.\n\\end{proof}\n\n\n\n\n\n\\label{app:proof_that_D_comp_equals_LP}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:dcompisLP}]\nLet us look at the optimization problem \\eqref{eq:defDcomp}\nmore closely.\nFirst notice that the constraints that define $\\mathcal{P}$\nare a set of linear constraints. Second notice that the first term\nin the objective is a linear function of $\\{W(t)\\}$.\nThird notice that we can replace\nthe term $\\sum^{T-1}_{t=1} \\|W(t+1) - W(t)\\|$ in the objective\nby $\\sum^{T-1}_{t=1} e_t$\nif we add the additional constraints\nthat $\\|W(t+1) - W(t)\\| \\leq e_t$ for all $t$.\nNow we show that these additional constraints\ncan be represented by linear constraints.\n\nSince $\\|W(t+1) - W(t)\\| = \\max_{j} \\sum_i |W(t+1)_{ij} - W(t)_{ij}|$\neach of these constraints can be replaced by \n$\\sum_i h(t)_{ij} \\leq e_t$ for all $t$ and $j$ \nif we add the additional constrain that\n$|W(t+1)_{ij} - W(t)_{ij}| \\leq h(t)_{ij}$ for all $i$, $j$ and $t$. Each of these constrains can be written\nas $W(t+1)_{ij} - W(t)_{ij} \\leq h(t)_{ij}$ and \n$-W(t+1)_{ij} + W(t)_{ij} \\leq h(t)_{ij}$ and both of these constraints\nare linear so we are done.\n\\end{proof}\n\n\n\n\n\n\n\\label{app:proof_of_optimal_trade_off_curve_for_D_comp}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:optimal_tradeoff}]\nWe first prove that $\\mathcal{R}$ is convex. Let $(a,b) \\in \\mathcal{R}$ and $(c,d) \\in \\mathcal{R}$. We have that $a \\geq \\sum_t \\|W_1(t+1)-W_1(t)\\|$ and $b \\geq \\sum_t \\text{\\bf tr}(W_1(t)^\\dagger D^{AB}(t))$ and $c \\geq \\sum_t \\|W_2(t+1)-W_2(t)\\|$ and $d \\geq \\sum_t \\text{\\bf tr}(W_2(t)^\\dagger D^{AB}(t))$ for some $\\{W_1(t)\\},\\{W_2(t)\\} \\in \\mathcal{P}^T$. Let $W_3(t) = \\beta W_1(t) + (1-\\beta) W_2(t)$ for some $\\beta \\in [0,1]$ and all $t$. Since $\\mathcal{P}^T$ is a convex set we have that $W_3(t) \\in  \\mathcal{P}^T$. In addition, since the functions $\\sum_t \\|W(t+1)-W(t)\\|$ and $\\sum_t \\text{\\bf tr}(W(t)^\\dagger D^{AB}(t))$ are convex functions of $\\{W(t)\\}$ we have that  $\\beta a + (1-\\beta) c \\geq \\sum_t \\|W_3(t+1)-W_3(t)\\|$ and $\\beta b + (1-\\beta) d \\geq \\sum_t \\text{\\bf tr}(W_3(t)^\\dagger D^{AB}(t))$. Therefore, we conclude that $\\beta (a,b) + (1 - \\beta) (c,d) \\in \\mathcal{R}$.\n\nWe now prove the rest of the theorem. Since $\\mathcal{R}$ is convex, we can write it as the following intersection of half-planes $\\mathcal{R} = \\{(x,y)\\in \\mathbb{R}^2:x + \\alpha y \\geq \\min_{\\{W(t)\\} \\in \\mathcal{P}^T} \\alpha u +  v \\text{ s.t. } u \\geq \\sum_t \\|W(t+1)-W(t)\\| \\text{ and } v \\geq \\sum_t \\text{\\bf tr}(W(t)^\\dagger D^{AB}(t)) \\text{ for all } \\alpha \\in [0,\\infty] \\}$.\\\\ From this representation it directly follows that, for any $\\alpha \\in [0,\\infty]$, any point $(dis,swi) \\in \\text{int}(\\mathcal{R})$ satisfies \n$\n\\alpha swi + dis > \\text{minimum } \\big \\{ \\alpha u +  v \\text{ subject to }\nW(t)\\in \\mathcal{P}^T; u \\geq \\sum_t \\|W(t+1)-W(t)\\|;\nv \\geq \\sum_t \\text{\\bf tr}(W(t)^\\dagger D^{AB}(t))\\big\\}\n= \\alpha \\sum_t \\|W^*(t+1)-W^*(t)\\|\n+  \\sum_t \\text{\\bf tr}(W^*(t)^\\dagger D^{AB}(t))= \\alpha swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha) \n+ dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),\n$\n\nwhere $\\{W^*(t)\\}\\in \\mathcal{P}^T$ is the optimum point of the optimization\nproblem of $\\mathcal{D}_{comp}$.\n\nFrom this representation we also conclude that any point at the boundary of $\\mathcal{R}$ is either of the form $(\\sum_t \\|W^*(t+1)-W^*(t)\\|, \\sum_t \\text{\\bf tr}(W^*(t)^\\dagger D^{AB}(t))) = (dis_{\\mathcal{D}_{\\text{comp}}}(\\alpha),swi_{\\mathcal{D}_{\\text{comp}}}(\\alpha))$ for some optimal $\\{W^*(t)\\} \\in \\mathcal{P}^T$ and some $\\alpha$ or it is a convex combination of points of this form. \n\\end{proof}\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 88954, "prevtext": "\nTherefore we can apply Fact 2 followed by Fact 1 and obtain\n\n$\nk_{Cayley}((\\sigma'(t+1) \\circ \\sigma(t+1)) \\circ (\\sigma'(t) \\circ \\sigma(t))^{-1}) = k_{Cayley}(\\sigma^{-1}_B \\circ \\sigma^{-1}_C)\n\\leq k_{Cayley}(\\sigma^{-1}_B) + k_{Cayley}( \\sigma^{-1}_C) = k_{Cayley}(\\sigma^{-1}_B) + k_{Cayley}( \\sigma^{-1}_A)\n = k_{Cayley}(\\sigma(t+1)\\circ\\sigma(t)^{-1}) + k_{Cayley}(\\sigma'(t+1)\\circ\\sigma'(t)^{-1}).\n$\n\n\\end{proof}\n\n\n\n\n\n\n\n\\label{app:necessary_conditions_for_D_nat_metric}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_maxcount_not_proper}]\nWe give a counter example that violates property (iii)\nfor $\\beta = 1$. It is easy to come up with similar\ncounter examples that violate property (iii) for any value\nof $\\beta \\geq 1$. Let $I = (1,2)$ be\nthe identity permutation and let $\\sigma_0 = (2,1)$ be the permutation that swaps $1$ and $2$. Let $\\Sigma = (I,\\sigma_0,\\sigma_0)$ and let $\\Sigma' = (I,I,\\sigma_0)$.\nWe have $\\mathcal{K}_{maxcount}(\\Sigma) = 1$ and \n$\\mathcal{K}_{maxcount}(\\Sigma') = 1$ but\n$\\mathcal{K}_{maxcount}(\\Sigma' \\circ \\Sigma) = \\infty > \\mathcal{K}_{maxcount}(\\Sigma') + \\mathcal{K}_{maxcount}(\\Sigma)$.\n\\end{proof}\n\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:K_maxcount_leads_to_not_metric}]\nWe produce three sets of trajectories $A$, $B$ and $C$\nthat make \\eqref{eq:defDnat} violate\nthe triangle inequality. In this proof we assume $\\beta = 1$\nbut it is easy to change $A$, $B$ and $C$ such that\nthe proof holds for any $\\beta$,\\footnote{It is also not hard to see that\nwe do not really need $d$ to be the Euclidean distance for the proof to hold.}.\n\nLet $I = (1,2)$ be\nthe identity permutation and let $\\sigma_0 = (2,1)$\nbe the permutation that swaps $1$ and $2$.\nLet $A = \\{A_1,A_2\\}$ where\n$A_1 = \\{(1, 2), (2, -2),(3, -2)\\}$ and\n$A_2 = \\{(1, -2), (2, 2),(3, 2)\\}$,\nlet $B = \\{B_1,B_2\\}$\nwhere $B_1 = \\{(1,2), (2,2),(3,2)\\}$ and $B_2 = \\{(1,-2), (2,-2),(3,-2)\\}$ and let $C = \\{C_1,C_2\\}$ where\n$C_1 = \\{(1, 2), (2, 2),(3, -2)\\}$ and\n$C_2 = \\{(1, -2),$ $(2, -2),$ $(3, 2)\\}$.\n\nNow consider \\eqref{eq:defDnat} with $\\mathcal{K} = \\mathcal{K}_{maxcount}$ and $\\beta = 1$.\nThe optimization problem \n$\\mathcal{D}_{nat}(A,B)$ has a minimum of $1$ at\n$\\Sigma = (I,\\sigma_0,\\sigma_0)$.\nThe optimization problem $\\mathcal{D}_{nat}(B,C)$\nhas a minimum of $1$ at\n$\\Sigma = (I,I,\\sigma_0)$. When we solve the optimization\nproblem $\\mathcal{D}_{nat}(A,C)$ we are only allowed\nto perform one change in the association between $A$\nand $C$, otherwise the term $\\mathcal{K}_{maxcount}$\nmakes us pay a very large cost. With only one change\nin the association, we incur in a distance of $4$\nfor $t = 1$ or $t = 2$ or $t = 3$. Hence, $\\mathcal{D}_{nat}(A,C) \\geq 4 > 1 + 1 = \\mathcal{D}_{nat}(A,B) + \\mathcal{D}_{nat}(B,C)$.\n\\end{proof}\n\n\n\n\n\n\\section{A natural and computable metric} \\label{app:proof_that_D_comp_is_metric}\n\n\n\\begin{proof}[Proof of Theorem \\ref{th:D_comp_is_metric}]\nLet $A, B$ and $C$ be any three elements of $\\mathcal{S}$.\\\\\n\\emph{Coincidence property}: If $\\mathcal{D}_{comp}(A,B) = 0$\nthen $W(t) = W(1)$ for all $t$. Hence, if $\\mathcal{D}_{comp}(A,B) = 0$ then $D^{AB}(t)_{ij} = 0$ for all $i,j$ such that\n$W(1)_{ij} > 0$. Now recall that if $W_{ij}$ is a doubly stochastic matrix then there exists a permutation $\\sigma \\in \\Pi$ such that\n$W_{i\\sigma_i} > 0$ for all $i$.  Therefore, there exist $\\sigma \\in \\Pi$ such\nthat $D^{AB}(t)_{i\\sigma_i} = 0$ for all $t$ and $i$. In other words,\n$A$ and $B$ are the same apart from a relabeling of their elements.\\\\\n\\emph{Symmetry property}: Using the properties of {\\bf tr} we have\nthat $\\text{\\bf tr}(W^{\\dagger}(t)D^{AB}(t)) =$ \n$\\text{\\bf tr}((W^{\\dagger}(t)$ $D^{AB}(t))^{\\dagger})$ $= \\text{\\bf tr}(D^{AB}(t)^{\\dagger}W(t))= \\text{\\bf tr}(D^{BA}(t)W(t))= \\text{\\bf tr}(W(t) D^{BA}(t))$. Minimizing with respect to $\\{W(t)\\}$ is the same as minimizing with\nrespect to $\\{W(t)^{\\dagger}\\}$ so $\\mathcal{D}_{comp}(A,B) = \\mathcal{D}_{comp}(B,A)$.\\\\\n\\emph{Subadditivity property}: We prove that\n$\\mathcal{D}_{comp}(A,C) \\leq \\mathcal{D}_{comp}(A,B) + \\mathcal{D}_{comp}(B,C)$. First note that, since $d^+$ is a metric we have\nthat $D^{AC}(t)_{ij} \\leq D^{AB}(t)_{ik} + D^{BC}(t)_{kj}$ for any $k$.\nLet $\\{W_1(t)\\}, \\{W_2(t)\\} \\in \\mathcal{P}^T$. We multiply both\nsides of the previous inequality by $W_1(t)_{ik}W_2(t)_{kj}$ and\nsum over $ijk$ and obtain\n\n$\n\\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj} D^{AC}(t)_{ij}\\leq \\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj} D^{AB}(t)_{ik}\\\\\n+ \\sum^{m}_{i,j,k=1} W_1(t)_{ik}W_2(t)_{kj}D^{BC}(t)_{kj}.\n$\n\nNote that $W_1(t)$ and $W_2(t)$ are doubly stochastic\nmatrices therefore we have $\\sum^m_{j=1} W_2(t)_{kj} = 1$ and\n$\\sum^m_{i=1} W_1(t)_{ik} = 1$ and we can re-write the previous\ninequality in matrix for as\n\n$\n\\text{\\bf tr}((W_1(t)W_2(t))^{\\dagger} D^{AC}(t)) \\leq\n\\text{\\bf tr}(W_1(t)^{\\dagger} D^{AB}(t)) + \n\\text{\\bf tr}(W_2(t)^{\\dagger} D^{BC}(t)).\n$\n\nFrom the definition of $\\|\\|$ we have that\n$\\|W_1(t+1)W_2(t+1) - W_1(t)W_2(t)\\| \\leq \\|W_1(t+1) - W_1(t)\\| + \\|W_2(t+1) - W_2(t)\\|.$ Summing both sides of the last two inequalities\nand, summing over $t$, and minimizing over $\\{W_1(t)\\}, \\{W_2(t)\\} \\in \\mathcal{P}^T$ we have\nthat\n\n{\\small\n\n", "index": 31, "text": "\\begin{align*}\n&\\min_{\\{W_1(t)\\},\\{W_2(t)\\} \\in \\mathcal{P}^T} \\sum^{T-1}_{t=1} \\|W_1(t+1)W_2(t+1) \\\\\n&- W_1(t)W_2(t) \\| +\n\\sum^T_{t=1} \\text{\\bf tr}((W_1(t)W_2(t))^{\\dagger} D^{AC}(t))\\\\\n&\\leq \\min_{\\{W_1(t)\\} \\in \\mathcal{P}^T}\n\\sum^{T-1}_{t=1} \\|W_1(t+1)- W_1(t) \\|+\n\\sum^T_{t=1} \\text{\\bf tr}(W_1(t)^{\\dagger} D^{AB}(t)) \\\\\n&+\\min_{\\{W_2(t)\\} \\in \\mathcal{P}^T}\n\\sum^{T-1}_{t=1} \\|W_2(t+1)- W_2(t) \\|\n+\n\\sum^T_{t=1} \\text{\\bf tr}(W_2(t)^{\\dagger} D^{BC}(t)).\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\{W_{1}(t)\\},\\{W_{2}(t)\\}\\in\\mathcal{P}^{T}}\\sum^{T-1}_{t=1%&#10;}\\|W_{1}(t+1)W_{2}(t+1)\" display=\"inline\"><mrow><munder><mi>min</mi><mrow><mrow><mrow><mo stretchy=\"false\">{</mo><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>\u2208</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mi>T</mi></msup></mrow></munder><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mo>\u2225</mo><msub><mi>W</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><msub><mi>W</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-W_{1}(t)W_{2}(t)\\|+\\sum^{T}_{t=1}\\text{\\bf tr}((W_{1}(t)W_{2}(t)%&#10;)^{\\dagger}D^{AC}(t))\" display=\"inline\"><mrow><mo>-</mo><msub><mi>W</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><msub><mi>W</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2225</mo><mo>+</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mtext>\ud835\udc2d\ud835\udc2b</mtext><mrow><mo stretchy=\"false\">(</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><msub><mi>W</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2020</mo></msup><msup><mi>D</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>C</mi></mrow></msup><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\min_{\\{W_{1}(t)\\}\\in\\mathcal{P}^{T}}\\sum^{T-1}_{t=1}\\|W_{1}(%&#10;t+1)-W_{1}(t)\\|+\\sum^{T}_{t=1}\\text{\\bf tr}(W_{1}(t)^{\\dagger}D^{AB}(t))\" display=\"inline\"><mrow><mi/><mo>\u2264</mo><mrow><mrow><munder><mi>min</mi><mrow><mrow><mo stretchy=\"false\">{</mo><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow><mo>\u2208</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mi>T</mi></msup></mrow></munder><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mrow><mo>\u2225</mo><mrow><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2225</mo></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mtext>\ud835\udc2d\ud835\udc2b</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2020</mo></msup><mo>\u2062</mo><msup><mi>D</mi><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\min_{\\{W_{2}(t)\\}\\in\\mathcal{P}^{T}}\\sum^{T-1}_{t=1}\\|W_{2}(t+1%&#10;)-W_{2}(t)\\|+\\sum^{T}_{t=1}\\text{\\bf tr}(W_{2}(t)^{\\dagger}D^{BC}(t)).\" display=\"inline\"><mrow><mrow><mrow><mo>+</mo><mrow><munder><mi>min</mi><mrow><mrow><mo stretchy=\"false\">{</mo><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow><mo>\u2208</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mi>T</mi></msup></mrow></munder><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mrow><mo>\u2225</mo><mrow><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2225</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover></mstyle><mrow><mtext>\ud835\udc2d\ud835\udc2b</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2020</mo></msup><mo>\u2062</mo><msup><mi>D</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>C</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]