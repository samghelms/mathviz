[{"file": "1601.00571.tex", "nexttext": "\nThe value $\\alpha$ here is analogous to the probability of transmission (accross an edge) in an epidemic spreading process. When chosen to be sufficiently small, it ensures that long walks are discounted heavily while short walks contribute more to the dynamic communicability metric.\n\nFor the first centrality measure, known as the ``Broadcast score'' of a node $i$, we compute the sum of all the discounted walks that begin at $i$ ($b_{i}=\\sum_{j \\in N} Q_{i,j}$). Similarly, to compute the second centrality measure, known as the ``Receive score'' of a node $i$, we sum all of the discounted walks that end at $i$ ($c_{i}=\\sum_{j \\in N} Q_{j,i}$).\n  \n\\section{The model}\n\\label{model}\nWe use a simple yet versatile stochastic model to generate temporal networks. The parameters of the model can be manipulated to create synthetic data with properties similar to a wide range of temporal networks including those observed in many real interactive systems. Let there be $N$ nodes, the model proceeds over a series of discreet time-steps $\\tau\\in\\{t_{0},t_{0}+1,...,t_{\\text{end}}\\}$ by the following rule:\n\\begin{quotation}\n\\noindent\nAt time $\\tau$, with probability $\\rho_{i,j}(\\tau)$, a directed edge exists from node $i$ to node $j$. \n\\end{quotation}\n\nThe adjacency matrix at time $\\tau$,  $A_{\\tau}$, will have a $1$ in location $i,j$ with probability $\\rho_{i,j}(\\tau)$ and be $0$ otherwise (it might often be the case that $A_{\\tau}$ will be a matrix of zeros). We define $t$ to be the number of time-steps for which the network is sampled. The dynamic communicability matrix, as introduced in \\cite{grindrod2011communicability}, over the sample (starting at $t_{0}$ and ending at $t_{\\text{end}}$) is given in general by \n\n", "itemtype": "equation", "pos": 11897, "prevtext": "\n\\maketitle\n\\vspace{-0.7cm}\n\\begin{abstract}\n\\noindent\nThe recently introduced concept of dynamic communicability is a valuable tool for ranking the importance of nodes in a temporal network. Two metrics, broadcast score and receive score, were introduced to measure the centrality of a node with respect to a model of contagion based on time-respecting walks. This article examines the temporal and structural factors influencing these metrics by considering a versatile stochastic temporal network model. We analytically derive formulae to accurately predict the expectation of the broadcast and receive scores when one or more columns in a temporal edge-list are shuffled. These methods are then applied to two publicly available data-sets and we quantify how much the centrality of each individual depends on structural or temporal influences. From our analysis we highlight two practical contributions: a way to control for temporal variation when computing dynamic communicability, and the conclusion that the broadcast and receive scores can, under a range of circumstances, be replaced by the row and column sums of the matrix exponential of a weighted adjacency matrix given by the data.\n\\end{abstract}\n\n\\begin{multicols}{2}\n\n\\section{Introduction}\nEpidemics, viral marketing, cultural diffusion, the distribution of food in ant colonies, and the flow of information within the human brain, are amongst a growing number of applications of network theory which currently reside at the forefront of modern science \\cite{perra2015modeling,weng2013virality,Ronen30122014,quevillon2015social,petri2014homological}. Advances in technology continue to promote the accumulation of data, providing an optimistic light in the quest to understand these hugely complex systems. The task then, for researchers across a range of disciplines, is to find optimal ways to measure, model, analyze, and present the vast information at their disposal.\n\nNetwork theory has proved to be an invaluable resource to exploit data on a large scale. Its great utility comes partly from the its ability to translate problems into a language independent of the particular subject of study. Hence, a ``node'' can represent entities as diverse as a human, a protein or a word \\cite{granovetter1973strength,jeong2001lethality,motter2002topology}. ``Edges'' can represent any sort of interaction between the nodes, and concepts such as percolation, diffusion, paths and walks can all serve as models for various processes observed in the real world.\n\nIt is remarkable whenever the methods developed for the analysis of one subject matter are applied to seemingly unrelated problems. This occurs frequently when networks are involved. For example, the preferential attachment model can explain the distribution of citations in scientific literature as well as the distribution of popularity in a social network \\cite{de1976general,barabasi2002evolution}, the PageRank algorithm was developed to rank websites but can also measure the risk of cancer in humans \\cite{gleich}. These universalities motivate us to search for ways to measure networks and classify them by their properties; if we have a good description of the network, then we have potentially described a part of the ``real world'' which we would like to understand, moreover, we also have the entirety of past research and all the accompanying tools developed to help attack the problem.\n\\subsection{Motivation for ``dynamic communicability''}\nTransmissible disease is possibly the best example to demonstrate the versatility of network analysis. Ultimately the theoretical considerations of network epidemiology involve nodes, edges and some knowledge of the disease itself such as the transmission probability, recovery rate and so on. Transmission could occur from one person to another, from one location to another (e.g. connected by air travel), or between species, but in each case the models employed remain well within the confines of the network framework \\cite{stehle2011simulation,colizza2006role,johnson2015infectious}. This also extends to computer viruses \\cite{pastor2001epidemic}, Twitter hashtags and internet memes \\cite{10.3389/fphy.2015.00079,wang2015concurrent}, and possibly even cultural transmission on an archeological time-scale \\cite{knappett2008modelling}. Clearly there is much to be gained from having a grounded understanding of how things spread through a network regardless of what that particular network represents.\n\nThe work we present here concerns a scenario where we are given a database containing a set of distinct individuals, a set of pairwise interactions, and the exact time at which each interaction happened (see Fig.\\ref{big_fig}). Additionally it is assumed that some transmissible agent was, or potentially could have been, spreading through the network. A practical question which often arises is: ``which node is potentially the most significant when it comes to the spread of a transmissible agent?''. \n\nTo find the most influential spreader, given data of past interactions, there are several options to consider: the simplest method would be to find the individual with the highest node degree (this could be defined as either number of interactions that person had, or the number of people they interacted with). Alternatively we could use global network properties such as the betweenness centrality or closeness centrality of a node, both of which are defined on temporal networks \\cite{holme2015modern}. The most extensive approach currently being used is to build a computational model of the process, adding as many factors into the model as one sees fit; where uncertainty is present, random variables can be used; and the centrality of an individual can be computed by running the model repeatedly and counting the proportion of simulations in which they are infected \\cite{stehle2011simulation,richardson2015beyond}. \n\nDynamic communicability, which was introduced in \\cite{grindrod2011communicability} and is described in detail here in Section \\ref{score_description}, offers a balance between the approach of modeling an epidemic-like process on a network, and simply measuring the size and shape of a network. Here we determine the influence of a node by counting the number of time-respecting walks that began at the node in question. In essence, we are using a model which assumes that a transmissible agent moves from one node to another at the exact time that an interaction takes place (which is known from the data) and with a given transmission probability. The fact that it is a walk (as opposed to a path) means that the agent can revisit previously infected nodes. Assuming this, and supposing that the pathogen is administered at node $i$, the broadcast score of $i$ tells us how large the expected outbreak will be. Supposing the pathogen is administered to a random unknown node, the receive score of $i$ tells us how likely that pathogen is to reach $i$.\n\n\\subsection{Separating dependencies}\nIn this paper we interrogate the two dynamic communicability metrics: broadcast score and its opposite, receive score. Through theoretical approaches we will examine how these centrality measures respond to different temporal network structures. Further, we derive methods to deconstruct the dynamic communicability measures into ``time dependent'' and ``structure dependent'' components. The formulae we derive achieve the same result as ``shuffling'' (randomly permuting) either the structural or temporal columns of the temporal edge-list respectively. This is an increasingly common technique used to determine the importance of various relationships within a database \\cite{masucci2009differences,sanli2015local,karsai2011small,richardson2015beyond}. Here we employ this technique to unpick, from the information available, the factors most relevant to determining the outcome of a contagion-like process.\n\nThe following section explains in detail the dynamic communicability metrics. In Section \\ref{model} we describe a stochastic model which can be tuned to reproduce various properties of the data. The main results from the model are a set of ``shortcut formulae'' for decomposing the dynamic communicability metrics into time dependent and structure dependent elements in an efficient way. We demonstrate these results on two publicly available data sets, which are described in Section \\ref{data}, and the results are presented in Section \\ref{results}. Section \\ref{discussion} summarizes the findings from this work which we consider most significant.\n\n\\begin{figure*}[t]\n    \\subfloat[The left panel shows the network at each time-step (above) and its corresponding adjacency matrix (below). On the right the same information is represented as a list of temporal edges. Shown also are the different possible ways to randomize (or shuffle) the columns. Notice that simultaneously shuffling any two columns yields the completely shuffled edge-list shown in (iv).\\label{big_fig}]{\\includegraphics[width=\\textwidth]{big_fig2.eps}}\\\\\n\n\\subfloat[Each marker corresponds to a node in the example network. Each node is given a rank according to its broadcast score (left) and receive score (right). These rankings are plotted against the outgoing and incoming degree ranks respectively. The diagonal line divides the nodes into those that acheive higher broadcast (or receive) scores than expected, and those that are lower. \\label{degree_rank_example}]{\n        \\includegraphics[width=0.24\\textwidth]{Example_broadcast_plot_2.eps}\n        \\includegraphics[width=0.24\\textwidth]{Example_receive_plot_2.eps}\n\t\t\t\t}\\qquad\n\t\t\t\t\\subfloat[The expectation values for each shuffling are calculated and the corresponding rank is plotted (we have chosen only to consider the target shuffling for broadcast score and source shuffling for receive score). The actual scores are shown by the darkness of the markers. \\label{databases}]{\n        \\includegraphics[width=0.24\\textwidth]{Example_broadcast_plot.eps}\n        \\includegraphics[width=0.24\\textwidth]{Example_receive_plot.eps}\n\t\t\t\t}\n\t\t\t\t\\caption{A simple example of a directed temporal network. This example has been designed to illustrate the core concepts of this work. In Fig.(\\ref{degree_rank_example}) it is apparent that the dynamic communicability of a node is not necessarily determined by its overall activity. Fig.(\\ref{databases}) demonstrate how the dynamic communicability metrics can be broken down into temporal and structural elements. We apply the same visualization method to two real-world data-sets in Figs. (\\ref{plots_2}) and (\\ref{plots}).}\n\\end{figure*}\n\t\t\t\n\\section{Definitions of ``Broadcast score'' and ``Receive score''}\n\\label{score_description}\nDynamic communicability, as introduced in \\cite{grindrod2011communicability}, comprises of two measures of centrality in a network. Underpinning both measures is the concept of ``walking'' on a network. A walk is any sequence of nodes in which one entry may only follow another if there is an edge in the network which connects them (if the network is directed then consecutive entries must follow the direction of the edge). When dealing with temporal edges, i.e. those which exist only at specified temporal instances, we consider node sequences where consecutive nodes are connected by an edge and, the time of that edge is later than (or at the same time as) its predecessor. These are referred to here as ``time-respecting'' walks. \n\nBased on this premise it is possible to quantify the relationship between any two nodes: the ``dynamic communicability'' from node $i$ to node $j$, denoted $Q_{i,j}$, is a measure of the relative likelihood that a random walker injected into the network at $i$ will eventually pass through $j$. If we let $\\theta_{i,j}^{(k)}$ be the number of time-respecting walks of length $k$ that begin at $i$ and end at $j$, then\n\n", "index": 1, "text": "\\begin{equation}\nQ_{i,j}=\\sum_{k=0}^{\\infty}\\alpha^{k}\\theta_{i,j}^{(k)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"Q_{i,j}=\\sum_{k=0}^{\\infty}\\alpha^{k}\\theta_{i,j}^{(k)}.\" display=\"block\"><mrow><mrow><msub><mi>Q</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant=\"normal\">\u221e</mi></munderover><mrow><msup><mi>\u03b1</mi><mi>k</mi></msup><mo>\u2062</mo><msubsup><mi>\u03b8</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nBut, as suggested in \\cite{grindrod2013matrix}, we do not want to count paths that take multiple moves in a single time-step, so we will instead look at the variant definition\n\n", "itemtype": "equation", "pos": 13716, "prevtext": "\nThe value $\\alpha$ here is analogous to the probability of transmission (accross an edge) in an epidemic spreading process. When chosen to be sufficiently small, it ensures that long walks are discounted heavily while short walks contribute more to the dynamic communicability metric.\n\nFor the first centrality measure, known as the ``Broadcast score'' of a node $i$, we compute the sum of all the discounted walks that begin at $i$ ($b_{i}=\\sum_{j \\in N} Q_{i,j}$). Similarly, to compute the second centrality measure, known as the ``Receive score'' of a node $i$, we sum all of the discounted walks that end at $i$ ($c_{i}=\\sum_{j \\in N} Q_{j,i}$).\n  \n\\section{The model}\n\\label{model}\nWe use a simple yet versatile stochastic model to generate temporal networks. The parameters of the model can be manipulated to create synthetic data with properties similar to a wide range of temporal networks including those observed in many real interactive systems. Let there be $N$ nodes, the model proceeds over a series of discreet time-steps $\\tau\\in\\{t_{0},t_{0}+1,...,t_{\\text{end}}\\}$ by the following rule:\n\\begin{quotation}\n\\noindent\nAt time $\\tau$, with probability $\\rho_{i,j}(\\tau)$, a directed edge exists from node $i$ to node $j$. \n\\end{quotation}\n\nThe adjacency matrix at time $\\tau$,  $A_{\\tau}$, will have a $1$ in location $i,j$ with probability $\\rho_{i,j}(\\tau)$ and be $0$ otherwise (it might often be the case that $A_{\\tau}$ will be a matrix of zeros). We define $t$ to be the number of time-steps for which the network is sampled. The dynamic communicability matrix, as introduced in \\cite{grindrod2011communicability}, over the sample (starting at $t_{0}$ and ending at $t_{\\text{end}}$) is given in general by \n\n", "index": 3, "text": "\\begin{equation}\n\\label{com_def}\nQ=(I-\\alpha A_{t_{0}})^{-1}(I-\\alpha A_{t_{0}+1})^{-1}\\ldots(I-\\alpha A_{t_{\\text{end}}})^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"Q=(I-\\alpha A_{t_{0}})^{-1}(I-\\alpha A_{t_{0}+1})^{-1}\\ldots(I-\\alpha A_{t_{%&#10;\\text{end}}})^{-1}.\" display=\"block\"><mrow><mrow><mi>Q</mi><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>-</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><msub><mi>t</mi><mn>0</mn></msub></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>-</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>-</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><msub><mi>t</mi><mtext>end</mtext></msub></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nEqns. (\\ref{com_def}) and (\\ref{Q_prod}) are equivalent when $A_{\\tau}^2=0$ for all $\\tau$ (as this is the only way $(I-\\alpha A_{\\tau})^{-1}=(I+\\alpha A_{\\tau})$ can be true). We are effectively assuming that no walks of length $2$ can exist within any one time-slice. The  time-dependent matrix \n\n", "itemtype": "equation", "pos": 14036, "prevtext": "\nBut, as suggested in \\cite{grindrod2013matrix}, we do not want to count paths that take multiple moves in a single time-step, so we will instead look at the variant definition\n\n", "index": 5, "text": "\\begin{equation}\n\\label{Q_prod}\nQ=(I+\\alpha A_{t_{0}})(I+\\alpha A_{t_{0}+1})...(I+\\alpha A_{t_{\\text{end}}}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"Q=(I+\\alpha A_{t_{0}})(I+\\alpha A_{t_{0}+1})...(I+\\alpha A_{t_{\\text{end}}}).\" display=\"block\"><mrow><mrow><mi>Q</mi><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><msub><mi>t</mi><mn>0</mn></msub></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mn>1</mn></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><msub><mi>t</mi><mtext>end</mtext></msub></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nto a large extent, describes the entire structure of the network and its evolution over time. Our approach to exploring dynamic communicability of networks generated by this model involves considering the various forms that $P$ can take; then examining the expectation of $Q$ as we iteratively increase the number of terms on the right hand side of Eq.\\eqref{Q_prod}.\n\n\\subsection{Receive score}\nIf we think about constructing $Q$ iteratively i.e. starting at time $t_{0}$ with $Q_{0}=(I+\\alpha A_{t_{0}})$, then multiplying on the right by $(I+\\alpha A_{t_{0}+1})$, then again by the next term, then the next etc., then\n\n", "itemtype": "equation", "pos": 14459, "prevtext": "\nEqns. (\\ref{com_def}) and (\\ref{Q_prod}) are equivalent when $A_{\\tau}^2=0$ for all $\\tau$ (as this is the only way $(I-\\alpha A_{\\tau})^{-1}=(I+\\alpha A_{\\tau})$ can be true). We are effectively assuming that no walks of length $2$ can exist within any one time-slice. The  time-dependent matrix \n\n", "index": 7, "text": "\\begin{equation}\nP(\\tau) =\n \\begin{pmatrix}\n  \\rho_{1,1}(\\tau) & \\rho_{1,2}(\\tau) & \\cdots & \\rho_{1,N}(\\tau) \\\\\n  \\rho_{2,1}(\\tau) & \\rho_{2,2}(\\tau) & \\cdots & \\rho_{2,N}(\\tau) \\\\\n  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n  \\rho_{N,1}(\\tau) & \\rho_{N,2}(\\tau) & \\cdots & \\rho_{N,N}(\\tau)\n \\end{pmatrix},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"P(\\tau)=\\begin{pmatrix}\\rho_{1,1}(\\tau)&amp;\\rho_{1,2}(\\tau)&amp;\\cdots&amp;\\rho_{1,N}(%&#10;\\tau)\\\\&#10;\\rho_{2,1}(\\tau)&amp;\\rho_{2,2}(\\tau)&amp;\\cdots&amp;\\rho_{2,N}(\\tau)\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;\\rho_{N,1}(\\tau)&amp;\\rho_{N,2}(\\tau)&amp;\\cdots&amp;\\rho_{N,N}(\\tau)\\end{pmatrix},\" display=\"block\"><mrow><mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>1</mn><mo>,</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>1</mn><mo>,</mo><mi>N</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mn>2</mn><mo>,</mo><mi>N</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mi>N</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mi>N</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>\u03c1</mi><mrow><mi>N</mi><mo>,</mo><mi>N</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere $t$ indexes the number of times the iteration has been performed. After $t=t_{\\text{end}}-t_{0}$ iterations we have the desired $Q_{t}=Q$. The effect of one iteration can be seen on a $3\\times 3$ example:\n\n", "itemtype": "equation", "pos": 15401, "prevtext": "\nto a large extent, describes the entire structure of the network and its evolution over time. Our approach to exploring dynamic communicability of networks generated by this model involves considering the various forms that $P$ can take; then examining the expectation of $Q$ as we iteratively increase the number of terms on the right hand side of Eq.\\eqref{Q_prod}.\n\n\\subsection{Receive score}\nIf we think about constructing $Q$ iteratively i.e. starting at time $t_{0}$ with $Q_{0}=(I+\\alpha A_{t_{0}})$, then multiplying on the right by $(I+\\alpha A_{t_{0}+1})$, then again by the next term, then the next etc., then\n\n", "index": 9, "text": "\\begin{equation}\n\\label{iter}\nQ_{t}=Q_{t-1}\\times(I+\\alpha A_{t_{0}+t}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"Q_{t}=Q_{t-1}\\times(I+\\alpha A_{t_{0}+t}),\" display=\"block\"><mrow><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo>=</mo><mrow><msub><mi>Q</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u00d7</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n\\normalsize\nIn general, provided $A_{\\tau}^{2}=0$ for all $t_{0}<\\tau\\leq t_{\\text{end}}$, if the $i,j$th entry of $A_{\\tau}$ is $1$ then the $i$th column is multiplied by $\\alpha$ and added to the $j$th column. Since the receive score after $t$ iterations is equal to the (row) vector of column sums of $Q_{t}$,\n\n", "itemtype": "equation", "pos": 15700, "prevtext": "\nwhere $t$ indexes the number of times the iteration has been performed. After $t=t_{\\text{end}}-t_{0}$ iterations we have the desired $Q_{t}=Q$. The effect of one iteration can be seen on a $3\\times 3$ example:\n\n", "index": 11, "text": "\\begin{equation}\n\\scriptsize\n \\begin{pmatrix}\n  q_{1,1} & q_{1,2}  & q_{1,3} \\\\\n  q_{2,1} & q_{2,2}  & q_{2,3} \\\\\n  q_{3,1} & q_{3,2}  & q_{3,3}\n \\end{pmatrix}\n  \\begin{pmatrix}\n  1 & 0  & 0 \\\\\n  0 & 1  & \\alpha \\\\\n  0 & 0  & 1\n \\end{pmatrix}\n = \\begin{pmatrix}\n  q_{1,1} & q_{1,2}  & q_{1,3}+\\alpha q_{1,2} \\\\\n  q_{2,1} & q_{2,2}  & q_{2,3}+\\alpha q_{2,2} \\\\\n  q_{3,1} & q_{3,2}  & q_{3,3}+\\alpha q_{3,2}\n \\end{pmatrix}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\scriptsize\\begin{pmatrix}q_{1,1}&amp;q_{1,2}&amp;q_{1,3}\\\\&#10;q_{2,1}&amp;q_{2,2}&amp;q_{2,3}\\\\&#10;q_{3,1}&amp;q_{3,2}&amp;q_{3,3}\\end{pmatrix}\\begin{pmatrix}1&amp;0&amp;0\\\\&#10;0&amp;1&amp;\\alpha\\\\&#10;0&amp;0&amp;1\\end{pmatrix}=\\begin{pmatrix}q_{1,1}&amp;q_{1,2}&amp;q_{1,3}+\\alpha q_{1,2}\\\\&#10;q_{2,1}&amp;q_{2,2}&amp;q_{2,3}+\\alpha q_{2,2}\\\\&#10;q_{3,1}&amp;q_{3,2}&amp;q_{3,3}+\\alpha q_{3,2}\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn mathsize=\"70%\">1</mn></mtd><mtd columnalign=\"center\"><mn mathsize=\"70%\">0</mn></mtd><mtd columnalign=\"center\"><mn mathsize=\"70%\">0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn mathsize=\"70%\">0</mn></mtd><mtd columnalign=\"center\"><mn mathsize=\"70%\">1</mn></mtd><mtd columnalign=\"center\"><mi mathsize=\"70%\">\u03b1</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mn mathsize=\"70%\">0</mn></mtd><mtd columnalign=\"center\"><mn mathsize=\"70%\">0</mn></mtd><mtd columnalign=\"center\"><mn mathsize=\"70%\">1</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo mathsize=\"70%\" stretchy=\"false\">=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mrow><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub><mo mathsize=\"70%\" stretchy=\"false\">+</mo><mrow><mi mathsize=\"70%\">\u03b1</mi><mo>\u2062</mo><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mrow><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub><mo mathsize=\"70%\" stretchy=\"false\">+</mo><mrow><mi mathsize=\"70%\">\u03b1</mi><mo>\u2062</mo><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mrow><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">3</mn></mrow></msub><mo mathsize=\"70%\" stretchy=\"false\">+</mo><mrow><mi mathsize=\"70%\">\u03b1</mi><mo>\u2062</mo><msub><mi mathsize=\"70%\">q</mi><mrow><mn mathsize=\"70%\">3</mn><mo mathsize=\"70%\" stretchy=\"false\">,</mo><mn mathsize=\"70%\">2</mn></mrow></msub></mrow></mrow></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo mathsize=\"70%\" stretchy=\"false\">.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": " \nwe can describe its evolution as $t$ increases as follows: at each iteration choose $i$ and $j$ with probability $\\rho_{i,j}(t_{0}+t)$ and update by setting\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\\normalsize\nIn general, provided $A_{\\tau}^{2}=0$ for all $t_{0}<\\tau\\leq t_{\\text{end}}$, if the $i,j$th entry of $A_{\\tau}$ is $1$ then the $i$th column is multiplied by $\\alpha$ and added to the $j$th column. Since the receive score after $t$ iterations is equal to the (row) vector of column sums of $Q_{t}$,\n\n", "index": 13, "text": "\\begin{equation}\n\\mathbf{c}(t)=(c_{1}(t),c_{2}(t),...,c_{N}(t)),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{c}(t)=(c_{1}(t),c_{2}(t),...,c_{N}(t)),\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc1c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><msub><mi>c</mi><mi>N</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nIn matrix notation this is \n\n", "itemtype": "equation", "pos": 16688, "prevtext": " \nwe can describe its evolution as $t$ increases as follows: at each iteration choose $i$ and $j$ with probability $\\rho_{i,j}(t_{0}+t)$ and update by setting\n\n", "index": 15, "text": "\\begin{equation}\n\\mathbf{c}(t+1)=(c_{1}(t),c_{2}(t),...,c_{j}(t)+\\alpha c_{i}(t),...,c_{N}(t)).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{c}(t+1)=(c_{1}(t),c_{2}(t),...,c_{j}(t)+\\alpha c_{i}(t),...,c_{N}(t)).\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc1c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><mrow><msub><mi>c</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><msub><mi>c</mi><mi>N</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n\\subsection{Expectation of receive score}\n\\label{expectation}\nThe receive score is dependent on $t$. To examine this dependence, we focus on the looking for the expectation of $\\textbf{c}(t)$, denoted $\\hat{c}_{i}(t)$, which is computed by taking the mean over many networks generated by the described model for some given $P$. For analytical considerations we assume that all of the $c_{i}(t)$ are well approximated by their mean. A similar approach is found in \\cite{rogers2014null}. The growth of $\\hat{c}_{i}(t)$ is then described by\n\n", "itemtype": "equation", "pos": 16827, "prevtext": "\nIn matrix notation this is \n\n", "index": 17, "text": "\\begin{equation}\n\\label{c_evo}\n\\mathbf{c}(t+1)=\\mathbf{c}(t)(I+\\alpha A_{t_{0}+t}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{c}(t+1)=\\mathbf{c}(t)(I+\\alpha A_{t_{0}+t}).\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc1c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\ud835\udc1c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>A</mi><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThe right hand side here equation sums over all possible changes that can happen to $c_{j}$ and their associated probabilities. This is equivalent to replacing $A_{t_{0}+t}$ in Eq.(\\ref{c_evo}) with the expectation of $A_{t_{0}+t}$, which happens to be $P(t_{0}+t)$. We have \n\n", "itemtype": "equation", "pos": 17464, "prevtext": "\n\\subsection{Expectation of receive score}\n\\label{expectation}\nThe receive score is dependent on $t$. To examine this dependence, we focus on the looking for the expectation of $\\textbf{c}(t)$, denoted $\\hat{c}_{i}(t)$, which is computed by taking the mean over many networks generated by the described model for some given $P$. For analytical considerations we assume that all of the $c_{i}(t)$ are well approximated by their mean. A similar approach is found in \\cite{rogers2014null}. The growth of $\\hat{c}_{i}(t)$ is then described by\n\n", "index": 19, "text": "\\begin{equation}\n\\hat{c}_{i}(t+1)=\\hat{c}_{i}(t)+\\alpha \\sum_{j=1}^{N}\\rho_{j,i}(t_{0}+t)\\hat{c}_{j}(t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{i}(t+1)=\\hat{c}_{i}(t)+\\alpha\\sum_{j=1}^{N}\\rho_{j,i}(t_{0}+t)\\hat{c}%&#10;_{j}(t).\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>\u03c1</mi><mrow><mi>j</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": " \nFor large time-scales, we can say that $\\hat{c}_{j}(t+1)-\\hat{c}_{j}(t)\\approx \\partial \\hat{c}_{j}/\\partial t$, giving\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nThe right hand side here equation sums over all possible changes that can happen to $c_{j}$ and their associated probabilities. This is equivalent to replacing $A_{t_{0}+t}$ in Eq.(\\ref{c_evo}) with the expectation of $A_{t_{0}+t}$, which happens to be $P(t_{0}+t)$. We have \n\n", "index": 21, "text": "\\begin{equation}\n\\mathbf{\\hat{c}}(t+1)=\\mathbf{\\hat{c}}(t)[I+\\alpha P(t_{0}+t)].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t+1)=\\mathbf{\\hat{c}}(t)[I+\\alpha P(t_{0}+t)].\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>I</mi><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nAn almost identical derivation can be performed to find a similar expression for $\\mathbf{\\hat{b}}$. In this case, instead of starting the iterative process at $t_{0}$ and multiplying on the right, as in Eq.\\eqref{iter}, we start at time $t_{\\text{end}}$ with $Q_{0}=(I+\\alpha A_{t_{\\text{end}}})$ and iterate by multiplying on the left, i.e $Q_{t}=(I+\\alpha A_{t_{\\text{end}}-t})\\times Q_{t-1}$. Following similar steps we arrive at\n\n", "itemtype": "equation", "pos": 18077, "prevtext": " \nFor large time-scales, we can say that $\\hat{c}_{j}(t+1)-\\hat{c}_{j}(t)\\approx \\partial \\hat{c}_{j}/\\partial t$, giving\n\n", "index": 23, "text": "\\begin{equation}\n\\label{diff_c}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{\\hat{c}}(t)P(t_{0}+t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{\\hat{c}}(t)P(t_{0%&#10;}+t).\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere $\\mathbf{\\hat{b}}(t)$ is a column vector of the expectation of the broadcast scores. Our theoretical results stem from these two equations, solutions can be found for various forms of $P(\\tau)$, here we mention a few simple cases.\n\\subsection{Time-independent $P$ matrix}\nWhen $P$ is a constant matrix, the (well known) general solution to Eq.(\\ref{diff_c}) is\n\n", "itemtype": "equation", "pos": 18643, "prevtext": "\nAn almost identical derivation can be performed to find a similar expression for $\\mathbf{\\hat{b}}$. In this case, instead of starting the iterative process at $t_{0}$ and multiplying on the right, as in Eq.\\eqref{iter}, we start at time $t_{\\text{end}}$ with $Q_{0}=(I+\\alpha A_{t_{\\text{end}}})$ and iterate by multiplying on the left, i.e $Q_{t}=(I+\\alpha A_{t_{\\text{end}}-t})\\times Q_{t-1}$. Following similar steps we arrive at\n\n", "index": 25, "text": "\\begin{equation}\n\\label{diff_b}\n\\frac{\\partial \\mathbf{\\hat{b}}(t)}{\\partial t}=\\alpha P(t_{\\text{end}}-t)\\mathbf{\\hat{b}}(t)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{b}}(t)}{\\partial t}=\\alpha P(t_{\\text{end}}-t)%&#10;\\mathbf{\\hat{b}}(t)\" display=\"block\"><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1b</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mtext>end</mtext></msub><mo>-</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1b</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere \n\n", "itemtype": "equation", "pos": 19151, "prevtext": "\nwhere $\\mathbf{\\hat{b}}(t)$ is a column vector of the expectation of the broadcast scores. Our theoretical results stem from these two equations, solutions can be found for various forms of $P(\\tau)$, here we mention a few simple cases.\n\\subsection{Time-independent $P$ matrix}\nWhen $P$ is a constant matrix, the (well known) general solution to Eq.(\\ref{diff_c}) is\n\n", "index": 27, "text": "\\begin{equation}\n\\label{c_sol}\n\\mathbf{\\hat{c}}(t)=\\mathbf{\\hat{c}}(t_{0})e^{\\alpha Pt}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t)=\\mathbf{\\hat{c}}(t_{0})e^{\\alpha Pt}\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n\\subsubsection{Equivalence to shuffling the time column}\nConsider a temporal edge-list where the ``time'' column has been shuffled as shown in part (iii) of Fig.(\\ref{big_fig}). The overall number of interaction events between each pair of nodes is unchanged, however each of these events now occurs at some random point in time. The time-series of interaction events from node $i$ to node $j$ can be modeled by a Bernoulli process, i.e. at each discreet time-step there is a fixed probability that an edge from $i$ to $j$ will exist. If we have a sufficiently large amount of data then the matrix of these time-independent probabilities, which happens to be $P$, can be approximated easily as we show in this section. The above result can then be used to predict the dynamic communicability metrics of the time-shuffled edge-list.\n\nWe can infer $P$ from the data by constructing a weighted adjacency matrix $W$ where $W_{i,j}$ the total number of times each edge appears in the temporal edge-list. To infer a time-independent probability $\\rho_{i,j}$ that an edge exists at time $\\tau$ (for any $t_{0}\\leq \\tau < t_{\\text{end}}$) we normalize by the number of time steps in the sample:\n\n", "itemtype": "equation", "pos": 19261, "prevtext": "\nwhere \n\n", "index": 29, "text": "\\begin{equation}\n\\label{powers}\ne^{\\alpha Pt}=\\sum_{k=0}^{\\infty}\\frac{1}{k!}(\\alpha Pt)^{k}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"e^{\\alpha Pt}=\\sum_{k=0}^{\\infty}\\frac{1}{k!}(\\alpha Pt)^{k}.\" display=\"block\"><mrow><mrow><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>t</mi></mrow></msup><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant=\"normal\">\u221e</mi></munderover><mrow><mfrac><mn>1</mn><mrow><mi>k</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow></mfrac><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>k</mi></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSince $t_{0}$ lies outside the time for which data is sampled, $A_{t_{0}}$ is a zero matrix, giving $\\mathbf{\\hat{c}}(t_{0})=\\mathbf{1}$  where $\\mathbf{1}$ is a row vector of length $N$ and all entries are $1$. Substituting the $P$ matrix associated with Eq.\\eqref{normed} into Eq.\\eqref{c_sol}, and into the equivalent result for $\\mathbf{\\hat{b}}$, we arrive at the concise formulae for computing the expectation of the broadcast and receive scores of a time-shuffled network,\n\n", "itemtype": "equation", "pos": 20557, "prevtext": "\n\\subsubsection{Equivalence to shuffling the time column}\nConsider a temporal edge-list where the ``time'' column has been shuffled as shown in part (iii) of Fig.(\\ref{big_fig}). The overall number of interaction events between each pair of nodes is unchanged, however each of these events now occurs at some random point in time. The time-series of interaction events from node $i$ to node $j$ can be modeled by a Bernoulli process, i.e. at each discreet time-step there is a fixed probability that an edge from $i$ to $j$ will exist. If we have a sufficiently large amount of data then the matrix of these time-independent probabilities, which happens to be $P$, can be approximated easily as we show in this section. The above result can then be used to predict the dynamic communicability metrics of the time-shuffled edge-list.\n\nWe can infer $P$ from the data by constructing a weighted adjacency matrix $W$ where $W_{i,j}$ the total number of times each edge appears in the temporal edge-list. To infer a time-independent probability $\\rho_{i,j}$ that an edge exists at time $\\tau$ (for any $t_{0}\\leq \\tau < t_{\\text{end}}$) we normalize by the number of time steps in the sample:\n\n", "index": 31, "text": "\\begin{equation}\n\\label{normed}\n \\rho_{i,j}=\\frac{W_{i,j}}{t_{\\text{end}}-t_{0}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\rho_{i,j}=\\frac{W_{i,j}}{t_{\\text{end}}-t_{0}}.\" display=\"block\"><mrow><mrow><msub><mi>\u03c1</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><msub><mi>W</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><msub><mi>t</mi><mtext>end</mtext></msub><mo>-</mo><msub><mi>t</mi><mn>0</mn></msub></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nand\n\n", "itemtype": "equation", "pos": 21134, "prevtext": "\nSince $t_{0}$ lies outside the time for which data is sampled, $A_{t_{0}}$ is a zero matrix, giving $\\mathbf{\\hat{c}}(t_{0})=\\mathbf{1}$  where $\\mathbf{1}$ is a row vector of length $N$ and all entries are $1$. Substituting the $P$ matrix associated with Eq.\\eqref{normed} into Eq.\\eqref{c_sol}, and into the equivalent result for $\\mathbf{\\hat{b}}$, we arrive at the concise formulae for computing the expectation of the broadcast and receive scores of a time-shuffled network,\n\n", "index": 33, "text": "\\begin{equation}\n\\label{W_sol_b}\n\\mathbf{\\hat{b}}=e^{\\alpha W}\\mathbf{1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{b}}=e^{\\alpha W}\\mathbf{1}\" display=\"block\"><mrow><mover accent=\"true\"><mi>\ud835\udc1b</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>W</mi></mrow></msup><mo>\u2062</mo><mn>\ud835\udfcf</mn></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nrespectively. A very fast open-source algorithm for solving the matrix exponential for large matrices has recently been developed \\cite{al2009new}. Applying this method gives a prediction for the outcome of averaging a large number of shuffled temporal edge-lists where the ``time'' column has been shuffled. The comparison between the prediction and the actual shuffled data is shown in Fig.(\\ref{shuffle_test}).\n\\subsubsection{Heterogenous ``send'' and ``receive'' model}\n\\label{sr_section}\nConsider a temporal edge list for which all three columns have been shuffled as in part (iv) of Fig.(\\ref{big_fig}). While much of the relational information will be lost, the number of times each node is found in the ``source'' column will be unchanged and therefore the outgoing degree of each node is retained, similarly the incoming degree is unchanged by the shuffling of the ``Target'' column. This process bears much resemblance to the configuration model of \\cite{molloy1995critical} in which each node has a given degree but the pairwise connections are randomized. Related models, which replace the exact degree sequence with a sequence of fitness variables (giving the propensity of each node to attract edges), have been studied \\cite{chung2002connected}; this happens to be a case where Eqs.\\eqref{W_sol_c} and \\eqref{W_sol_b} can be solved analytically. Let $s_{i}$ be the probability that node $i$ has an outgoing edge in any given time-step (we have chosen the letter $s$ as this represents the `sending' of information), and let $r_{i}$ be the probability that $i$ has an incoming edge in any given time-step ($r$ to represent the `receiving' of information). With the vector notation, $\\mathbf{s}=[s_{1},s_{2},\\ldots,s_{N}]^{T}$ and $\\mathbf{r}=[r_{1},r_{2},\\ldots,r_{N}]^{T}$, we have \n\n", "itemtype": "equation", "pos": 21226, "prevtext": "\nand\n\n", "index": 35, "text": "\\begin{equation}\n\\label{W_sol_c}\n\\mathbf{\\hat{c}}=\\mathbf{1}^{T} e^{\\alpha W}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}=\\mathbf{1}^{T}e^{\\alpha W}\" display=\"block\"><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><msup><mn>\ud835\udfcf</mn><mi>T</mi></msup><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>W</mi></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nWe add the condition that $\\sum_{i} s_{i}=\\sum_{i} r_{i}=1$ then the expected number of edges per time-step is $1$ (meaning that when comparing to data we can treat $t$ as the total number of interactions). Under these conditions the solution to Eq.\\eqref{diff_c} (see Appendix \\ref{sr_sol}) is\n\n", "itemtype": "equation", "pos": 23117, "prevtext": "\nrespectively. A very fast open-source algorithm for solving the matrix exponential for large matrices has recently been developed \\cite{al2009new}. Applying this method gives a prediction for the outcome of averaging a large number of shuffled temporal edge-lists where the ``time'' column has been shuffled. The comparison between the prediction and the actual shuffled data is shown in Fig.(\\ref{shuffle_test}).\n\\subsubsection{Heterogenous ``send'' and ``receive'' model}\n\\label{sr_section}\nConsider a temporal edge list for which all three columns have been shuffled as in part (iv) of Fig.(\\ref{big_fig}). While much of the relational information will be lost, the number of times each node is found in the ``source'' column will be unchanged and therefore the outgoing degree of each node is retained, similarly the incoming degree is unchanged by the shuffling of the ``Target'' column. This process bears much resemblance to the configuration model of \\cite{molloy1995critical} in which each node has a given degree but the pairwise connections are randomized. Related models, which replace the exact degree sequence with a sequence of fitness variables (giving the propensity of each node to attract edges), have been studied \\cite{chung2002connected}; this happens to be a case where Eqs.\\eqref{W_sol_c} and \\eqref{W_sol_b} can be solved analytically. Let $s_{i}$ be the probability that node $i$ has an outgoing edge in any given time-step (we have chosen the letter $s$ as this represents the `sending' of information), and let $r_{i}$ be the probability that $i$ has an incoming edge in any given time-step ($r$ to represent the `receiving' of information). With the vector notation, $\\mathbf{s}=[s_{1},s_{2},\\ldots,s_{N}]^{T}$ and $\\mathbf{r}=[r_{1},r_{2},\\ldots,r_{N}]^{T}$, we have \n\n", "index": 37, "text": "\\begin{equation}\nP=\\mathbf{s}\\mathbf{r}^{T}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"P=\\mathbf{s}\\mathbf{r}^{T}.\" display=\"block\"><mrow><mrow><mi>P</mi><mo>=</mo><msup><mi>\ud835\udc2c\ud835\udc2b</mi><mi>T</mi></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nTwo main conclusions come from this result: firstly, the receive score of a node is proportional its propensity to attract incoming edges (for broadcast score it is the outgoing edges, see Appendix \\ref{sr_sol}). Second, as the sample size $t$ increases the score increases exponentially.\n\\subsection{Time-dependent $P$ matrix}\nA general solution to Eq.\\eqref{diff_c} for any $P(\\tau)$ does not exist, we instead incorporate a limited amount of temporal information by expanding the ``send'' and ``receive'' model of the previous section. Suppose we have the model from Section \\ref{sr_section} with the modification that the ``receive'' vector $\\mathbf{r}$ is now a function of time $\\mathbf{r}(\\tau)$, then Eq.\\eqref{diff_c} reduces to\n\n", "itemtype": "equation", "pos": 23472, "prevtext": "\nWe add the condition that $\\sum_{i} s_{i}=\\sum_{i} r_{i}=1$ then the expected number of edges per time-step is $1$ (meaning that when comparing to data we can treat $t$ as the total number of interactions). Under these conditions the solution to Eq.\\eqref{diff_c} (see Appendix \\ref{sr_sol}) is\n\n", "index": 39, "text": "\\begin{equation}\n\\label{c_time_dep}\n\\mathbf{\\hat{c}}(t)=\\mathbf{1}+\\frac{e^{\\alpha [\\mathbf{r}^{T}\\mathbf{s}]t}-1}{\\mathbf{r}^{T}\\mathbf{s}}\\mathbf{r}^{T}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t)=\\mathbf{1}+\\frac{e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}-1}{%&#10;\\mathbf{r}^{T}\\mathbf{s}}\\mathbf{r}^{T}.\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>\ud835\udfcf</mn><mo>+</mo><mrow><mfrac><mrow><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow></msup><mo>-</mo><mn>1</mn></mrow><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mfrac><mo>\u2062</mo><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n(see Appendix \\ref{t_model}). Eq.\\eqref{time_s} allows us to examine special cases where the order in which messages are sent affects the receive score of each node.\n\\subsubsection{Simple time-dependent example}\n\\label{simple_time}\nTo demonstrate time-dependence we consider the case where each node is active only once during the duration of the sample. Suppose node $i$ receives $r_{i}$ edges at time $\\tau_{i}$. We can write the corresponding $r$ vector using the Dirac $\\delta$:\n\n", "itemtype": "equation", "pos": 24381, "prevtext": "\nTwo main conclusions come from this result: firstly, the receive score of a node is proportional its propensity to attract incoming edges (for broadcast score it is the outgoing edges, see Appendix \\ref{sr_sol}). Second, as the sample size $t$ increases the score increases exponentially.\n\\subsection{Time-dependent $P$ matrix}\nA general solution to Eq.\\eqref{diff_c} for any $P(\\tau)$ does not exist, we instead incorporate a limited amount of temporal information by expanding the ``send'' and ``receive'' model of the previous section. Suppose we have the model from Section \\ref{sr_section} with the modification that the ``receive'' vector $\\mathbf{r}$ is now a function of time $\\mathbf{r}(\\tau)$, then Eq.\\eqref{diff_c} reduces to\n\n", "index": 41, "text": "\\begin{equation}\n\\label{time_s}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{r}(t_{0}+t)e^{\\alpha \\mathbf{s}^{T}\\int_{0}^{t}\\mathbf{r}(t_{0}+t') d t'}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{r}(t_{0}+t)e^{%&#10;\\alpha\\mathbf{s}^{T}\\int_{0}^{t}\\mathbf{r}(t_{0}+t^{\\prime})dt^{\\prime}}\" display=\"block\"><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\ud835\udc2b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><msup><mi>\ud835\udc2c</mi><mi>T</mi></msup><mo>\u2062</mo><mrow><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup></mstyle><mrow><mi>\ud835\udc2b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThe justification for this choice of $\\mathbf{r}(\\tau)$ is that the expected number of messages received by $i$ over some interval will be $r_{i}$ if the time interval includes $\\tau_{i}$. For convenience we suppose, without loss of generality, that $\\tau_{i}=i$ for all $i\\in 1,2,...,N$. Solving Eq.\\eqref{c_time_dep} with this form of $\\mathbf{r}(\\tau)$ we get\n\n", "itemtype": "equation", "pos": 25048, "prevtext": "\n(see Appendix \\ref{t_model}). Eq.\\eqref{time_s} allows us to examine special cases where the order in which messages are sent affects the receive score of each node.\n\\subsubsection{Simple time-dependent example}\n\\label{simple_time}\nTo demonstrate time-dependence we consider the case where each node is active only once during the duration of the sample. Suppose node $i$ receives $r_{i}$ edges at time $\\tau_{i}$. We can write the corresponding $r$ vector using the Dirac $\\delta$:\n\n", "index": 43, "text": "\\begin{equation}\nr_{i}(\\tau)=r_{i}\\delta(\\tau-\\tau_{i}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"r_{i}(\\tau)=r_{i}\\delta(\\tau-\\tau_{i}).\" display=\"block\"><mrow><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c4</mi><mo>-</mo><msub><mi>\u03c4</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThis result shows that nodes which interact later in the sample will have, on average, exponentially higher receive scores. In a similar way, it can be shown that a node which acts earlier in the sample has an exponentially higher broadcast score.\n\n\\subsubsection{Incorporating empirical data}\nSuppose that for each node $i$ we know the time of every received edge but do not know where the edge originated from (this corresponds to the source shuffled network). We can achieve this by choosing\n\n", "itemtype": "equation", "pos": 25483, "prevtext": "\nThe justification for this choice of $\\mathbf{r}(\\tau)$ is that the expected number of messages received by $i$ over some interval will be $r_{i}$ if the time interval includes $\\tau_{i}$. For convenience we suppose, without loss of generality, that $\\tau_{i}=i$ for all $i\\in 1,2,...,N$. Solving Eq.\\eqref{c_time_dep} with this form of $\\mathbf{r}(\\tau)$ we get\n\n", "index": 45, "text": "\\begin{equation}\n\\hat{c}_{i}(N)=1+\\alpha r_{i}\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{i}(N)=1+\\alpha r_{i}\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>i</mi></munderover><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere $K_{i}$ is the set of edges for which $i$ is the target and $\\tau_{i}^{(k)}$ is the time at which edge $k$ was present. More importantly, however, is the function $R_{i}(\\tau)$ which we define as the number of messages that have been received by $i$ between $t_{0}$ and $\\tau$, and can be expressed as\n\n", "itemtype": "equation", "pos": 26088, "prevtext": "\nThis result shows that nodes which interact later in the sample will have, on average, exponentially higher receive scores. In a similar way, it can be shown that a node which acts earlier in the sample has an exponentially higher broadcast score.\n\n\\subsubsection{Incorporating empirical data}\nSuppose that for each node $i$ we know the time of every received edge but do not know where the edge originated from (this corresponds to the source shuffled network). We can achieve this by choosing\n\n", "index": 47, "text": "\\begin{equation}\n\\label{r_delta}\nr_{i}(\\tau)=\\sum_{k\\in K_{i}}\\delta(\\tau-\\tau_{i}^{(k)})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"r_{i}(\\tau)=\\sum_{k\\in K_{i}}\\delta(\\tau-\\tau_{i}^{(k)})\" display=\"block\"><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c4</mi><mo>-</mo><msubsup><mi>\u03c4</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nTo achieve the correct normalization (for the expectation of the total number of edges to agree with the data) we choose $s_{i}$ to be the probability that any given edge is sent from $i$, this is inferred using  \n\n", "itemtype": "equation", "pos": 26501, "prevtext": "\nwhere $K_{i}$ is the set of edges for which $i$ is the target and $\\tau_{i}^{(k)}$ is the time at which edge $k$ was present. More importantly, however, is the function $R_{i}(\\tau)$ which we define as the number of messages that have been received by $i$ between $t_{0}$ and $\\tau$, and can be expressed as\n\n", "index": 49, "text": "\\begin{equation}\nR_{i}(\\tau)=\\int_{t_{0}}^{\\tau}r_{i}(t')dt'. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"R_{i}(\\tau)=\\int_{t_{0}}^{\\tau}r_{i}(t^{\\prime})dt^{\\prime}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msub><mi>t</mi><mn>0</mn></msub><mi>\u03c4</mi></msubsup><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThe solution to Eq.\\eqref{diff_c}, which we derive in Appendix \\ref{source_shuffled_derivation}, is \n\n", "itemtype": "equation", "pos": 26793, "prevtext": "\nTo achieve the correct normalization (for the expectation of the total number of edges to agree with the data) we choose $s_{i}$ to be the probability that any given edge is sent from $i$, this is inferred using  \n\n", "index": 51, "text": "\\begin{equation}\ns_{i}=\\frac{\\sum_{j}W_{i,j}}{\\sum_{i,j}W_{i,j}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"s_{i}=\\frac{\\sum_{j}W_{i,j}}{\\sum_{i,j}W_{i,j}}.\" display=\"block\"><mrow><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub><msub><mi>W</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msub><mi>W</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThis formula predicts the average of the Receive score over many networks generated by shuffling the Source column in the original data. The analytical prediction and average shuffling results are shown in Fig.(\\ref{shuffle_test}). In our data analysis we also use an equivalent formula to predict the outcome of shuffling the target column and calculating the broadcast score. The derivation is similar to that of Eq.\\eqref{time_formula}. We get\n\n", "itemtype": "equation", "pos": 26975, "prevtext": "\nThe solution to Eq.\\eqref{diff_c}, which we derive in Appendix \\ref{source_shuffled_derivation}, is \n\n", "index": 53, "text": "\\begin{equation}\n\\label{time_formula}\n\\hat{c}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}s_{j}R_{j}(\\tau_{i}^{(k)})\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}s_{j}R_{j}(%&#10;\\tau_{i}^{(k)})\\right).\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><mi>N</mi></mrow></munder><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>R</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03c4</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere $S_{j}(\\tau)$ is the number of messages that have been received by $i$ between $\\tau$ and $t_{\\text{end}}$, $r_{j}$ is the time-independent probability that $j$ receives a message in any given time-step.\n\\begin{figure}[H]\n\t\t\\includegraphics[width=0.47\\textwidth]{shuffle_test.eps}\n    \\caption{A demonstration of the accuracy of the derived formulae using a sample of $23$ nodes from the Enron data-set (all of which have at least one outgoing edge within the sample) and a total of $312$ emails. Each marker represents an employee. In both plots the $x$-axis shows the receive score computed by shuffling one column of the edge-list, as shown in Fig.(\\ref{big_fig}), and averaged over $100$ shuffles. In the left hand plot the time column was subjected to shuffling and $y$-axis shows the receive score as predicted by formula Eq.(\\ref{W_sol_c}), in the right the target column was subjected to shuffling and $y$-axis shows the receive score as predicted by formula Eq.(\\ref{time_formula}). $\\alpha=0.02$.}\n\t\t\\label{shuffle_test}\n\\end{figure}\n\\section{Data}\n\\begin{figure*}[t!]\n\\centering\n    \\subfloat[Enron email results \\label{enron_raw}]{\n\t\t\\includegraphics[height=6cm]{Enron_broadcast_plot_box.eps}}\\qquad\n\t\t    \\subfloat[Hospital results \\label{hospital_raw}]{\n\t\t\\includegraphics[height=6cm]{Hospital_receive_plot_box.eps}}\n    \\caption{Each marker (short horizontal line) represents an Enron employee or participant in the Sociopatterns experiment. The broadcast score, computed by Eq.\\eqref{bc_compute}, is displayed on the $y$-axis in (\\ref{enron_raw}) and similarly the receive score in (\\ref{hospital_raw}) from Eq.\\eqref{rc_compute} with $\\alpha=0.01$ and $\\alpha=0.005$ respectively. In both the employees (or participants) are divided into distinct categories shown along the $x$-axis. Abbreviations are given in Section \\ref{data}.}\n\t\t\\label{box}\n\\end{figure*}\n\\label{data}\n\\subsection{Enron}\nWe downloaded the entire Enron email corpus that was made publicly available during an investigation by the Federal Energy Regulatory Commission into the events leading to its bankruptcy \\cite{enron}. The data contains the mailing history of 150 Enron employees between 1999 and 2003. A folder exists for each of the named employees, each of which contain a number sub-folders, and each subfolder contains a number of text files; the text files contain the emails themselves and some meta-data. The naming of the folders is not consistent across employees; most sent emails belong to a folder labelled ``sent'', ``sent email'', or something similar but there are also many exceptions. A consistent format was found across all the text files with the time-stamp located on the first line, the ``From'' field appearing on the second, and the ``To'' field starting on the third line and often extending over several lines where emails have been sent to multiple recipients. \n\nWe crawled every text file within sub-folders named ``sent'', ``sent\\_items'' and ``\\_sent\\_mail', reading the specific lines which correspond to the ``From'' field, the ``To'' field and the time-stamp. Within the ``From'' and ``To'' lines we found all substrings which resemble a distinct email address i.e. bound on either side by blank spaces and contain the ``@'' symbol. From these data we constructed a temporal edge list of the form shown in Fig.(\\ref{big_fig}) where the node IDs are email addresses. Multiple edges were created for emails with multiple recipients. In several cases the email addresses found in the ``From'' field, across the emails of an individual employee, would not always be identical. Usually this was because of the use of email aliases although on a small number of occasions  this was clearly not the case. At our own discretion, we replaced the node ID of all aliases relating to an employee with a single node ID.  \n\nMany of the emails were sent to addresses outside of the corporation, these were removed from our data. We also found that some employees in the data-set had very little or no activity; we therefore reduced the sample to only those who have both sent, and received, at least one email to other users within the sample. After trimming, the network has $141$ nodes and a total of $21,303$ temporal edges.\n\nWe also incorporated information regarding the roles of each employee according to enron.org \\cite{names}. The following abbreviations have been used for the legend in Fig.(\\ref{enron_plot}): EMP$=$employee, TRA$=$trader, LAW$=$lawyer, MAN$=$manager, DIR$=$director, VP$=$vice president, MD$=$managing director, PRE$=$president, CEO$=$chief executive, ???$=$unknown.\n\nThe sample of emails we have chosen to use is by no means complete, however, it is our belief that the methods used to sample this data avoid introducing any biases which would compromise the results we present.\n\n\\subsection{Sociopatterns hospital ward}\nWe downloaded the Hospital ward dynamic contact network from the Sociopatterns website (refer to \\cite{10.1371/journal.pone.0073970} for details). The data was collected using proximity sensors attached to each participant. In the original data, every instance (instances are recorded every 20 seconds) in which two participants are ``interacting'' (i.e. within a given proximity of each other) is presented in a temporal edge list of the form shown in Fig.(\\ref{big_fig}). Consequently, interactions which occur for a prolonged duration appear in the data multiple times so we performed the following reduction: where the same pair of participants were found to be interacting on multiple consecutive time-steps, all but one of the corresponding rows in the edge list were removed, leaving only the first of such instances. For each remaining row we create two edges in the processed temporal edge-list, one in each direction between the pair of participants interacting, both edges have the same time-stamp. Our analysis therefore considers transmission to occur at the first moment an interaction begins and does not depend on its duration. After processing, the network has $75$ nodes and a total of $28,076$ temporal edges.\n\n\\subsection{Algorithms}\n\\label{decision}\nMuch of the related literature formulates the problem of computing a dynamic communicability matrix using a series of linear algebra operations \\cite{grindrod2011communicability}. This approach utilizes the adjacency matrix for the network at each time step (see Fig.(\\ref{big_fig})) and assumes that within each time-slice the hypothetical random walker can traverse edges instantaneously, i.e. without requiring that time move forward for them to perform the movement. Consequently, if there is any cycle within a single time-slice (including for example an edge from $i$ to $j$ and another from $j$ to $i$) then there will be paths of infinite length, meaning that $\\alpha$ must be restricted to a particular range of values to guarantee convergence \\cite{greetham2013centrality}.\n\nIn this work we remove the assumption that a walk can traverse more than one edge per time slice (as suggested in \\cite{grindrod2013matrix}). Moreover, we suggest the following recursive approach to computing the dynamic communicability metrics which avoids the need to perform any matrix operations. Suppose we have a network $G$ with each temporal edge denoted by a triple $(i,j,t)$ where $i$ is the source node, $j$ is the target node and $t$ is the time, we define  \n\n", "itemtype": "equation", "pos": 27576, "prevtext": "\nThis formula predicts the average of the Receive score over many networks generated by shuffling the Source column in the original data. The analytical prediction and average shuffling results are shown in Fig.(\\ref{shuffle_test}). In our data analysis we also use an equivalent formula to predict the outcome of shuffling the target column and calculating the broadcast score. The derivation is similar to that of Eq.\\eqref{time_formula}. We get\n\n", "index": 55, "text": "\\begin{equation}\n\\label{time_formula_b}\n\\hat{b}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}r_{j}S_{j}(\\tau_{i}^{(k)})\\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"\\hat{b}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}r_{j}S_{j}(%&#10;\\tau_{i}^{(k)})\\right)\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi>b</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><mi>N</mi></mrow></munder><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>S</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03c4</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThen the broadcast score for node $i$ computed between time $t_{0}$ and $t_{\\text{end}}$ is given by\n\n", "itemtype": "equation", "pos": 35125, "prevtext": "\nwhere $S_{j}(\\tau)$ is the number of messages that have been received by $i$ between $\\tau$ and $t_{\\text{end}}$, $r_{j}$ is the time-independent probability that $j$ receives a message in any given time-step.\n\\begin{figure}[H]\n\t\t\\includegraphics[width=0.47\\textwidth]{shuffle_test.eps}\n    \\caption{A demonstration of the accuracy of the derived formulae using a sample of $23$ nodes from the Enron data-set (all of which have at least one outgoing edge within the sample) and a total of $312$ emails. Each marker represents an employee. In both plots the $x$-axis shows the receive score computed by shuffling one column of the edge-list, as shown in Fig.(\\ref{big_fig}), and averaged over $100$ shuffles. In the left hand plot the time column was subjected to shuffling and $y$-axis shows the receive score as predicted by formula Eq.(\\ref{W_sol_c}), in the right the target column was subjected to shuffling and $y$-axis shows the receive score as predicted by formula Eq.(\\ref{time_formula}). $\\alpha=0.02$.}\n\t\t\\label{shuffle_test}\n\\end{figure}\n\\section{Data}\n\\begin{figure*}[t!]\n\\centering\n    \\subfloat[Enron email results \\label{enron_raw}]{\n\t\t\\includegraphics[height=6cm]{Enron_broadcast_plot_box.eps}}\\qquad\n\t\t    \\subfloat[Hospital results \\label{hospital_raw}]{\n\t\t\\includegraphics[height=6cm]{Hospital_receive_plot_box.eps}}\n    \\caption{Each marker (short horizontal line) represents an Enron employee or participant in the Sociopatterns experiment. The broadcast score, computed by Eq.\\eqref{bc_compute}, is displayed on the $y$-axis in (\\ref{enron_raw}) and similarly the receive score in (\\ref{hospital_raw}) from Eq.\\eqref{rc_compute} with $\\alpha=0.01$ and $\\alpha=0.005$ respectively. In both the employees (or participants) are divided into distinct categories shown along the $x$-axis. Abbreviations are given in Section \\ref{data}.}\n\t\t\\label{box}\n\\end{figure*}\n\\label{data}\n\\subsection{Enron}\nWe downloaded the entire Enron email corpus that was made publicly available during an investigation by the Federal Energy Regulatory Commission into the events leading to its bankruptcy \\cite{enron}. The data contains the mailing history of 150 Enron employees between 1999 and 2003. A folder exists for each of the named employees, each of which contain a number sub-folders, and each subfolder contains a number of text files; the text files contain the emails themselves and some meta-data. The naming of the folders is not consistent across employees; most sent emails belong to a folder labelled ``sent'', ``sent email'', or something similar but there are also many exceptions. A consistent format was found across all the text files with the time-stamp located on the first line, the ``From'' field appearing on the second, and the ``To'' field starting on the third line and often extending over several lines where emails have been sent to multiple recipients. \n\nWe crawled every text file within sub-folders named ``sent'', ``sent\\_items'' and ``\\_sent\\_mail', reading the specific lines which correspond to the ``From'' field, the ``To'' field and the time-stamp. Within the ``From'' and ``To'' lines we found all substrings which resemble a distinct email address i.e. bound on either side by blank spaces and contain the ``@'' symbol. From these data we constructed a temporal edge list of the form shown in Fig.(\\ref{big_fig}) where the node IDs are email addresses. Multiple edges were created for emails with multiple recipients. In several cases the email addresses found in the ``From'' field, across the emails of an individual employee, would not always be identical. Usually this was because of the use of email aliases although on a small number of occasions  this was clearly not the case. At our own discretion, we replaced the node ID of all aliases relating to an employee with a single node ID.  \n\nMany of the emails were sent to addresses outside of the corporation, these were removed from our data. We also found that some employees in the data-set had very little or no activity; we therefore reduced the sample to only those who have both sent, and received, at least one email to other users within the sample. After trimming, the network has $141$ nodes and a total of $21,303$ temporal edges.\n\nWe also incorporated information regarding the roles of each employee according to enron.org \\cite{names}. The following abbreviations have been used for the legend in Fig.(\\ref{enron_plot}): EMP$=$employee, TRA$=$trader, LAW$=$lawyer, MAN$=$manager, DIR$=$director, VP$=$vice president, MD$=$managing director, PRE$=$president, CEO$=$chief executive, ???$=$unknown.\n\nThe sample of emails we have chosen to use is by no means complete, however, it is our belief that the methods used to sample this data avoid introducing any biases which would compromise the results we present.\n\n\\subsection{Sociopatterns hospital ward}\nWe downloaded the Hospital ward dynamic contact network from the Sociopatterns website (refer to \\cite{10.1371/journal.pone.0073970} for details). The data was collected using proximity sensors attached to each participant. In the original data, every instance (instances are recorded every 20 seconds) in which two participants are ``interacting'' (i.e. within a given proximity of each other) is presented in a temporal edge list of the form shown in Fig.(\\ref{big_fig}). Consequently, interactions which occur for a prolonged duration appear in the data multiple times so we performed the following reduction: where the same pair of participants were found to be interacting on multiple consecutive time-steps, all but one of the corresponding rows in the edge list were removed, leaving only the first of such instances. For each remaining row we create two edges in the processed temporal edge-list, one in each direction between the pair of participants interacting, both edges have the same time-stamp. Our analysis therefore considers transmission to occur at the first moment an interaction begins and does not depend on its duration. After processing, the network has $75$ nodes and a total of $28,076$ temporal edges.\n\n\\subsection{Algorithms}\n\\label{decision}\nMuch of the related literature formulates the problem of computing a dynamic communicability matrix using a series of linear algebra operations \\cite{grindrod2011communicability}. This approach utilizes the adjacency matrix for the network at each time step (see Fig.(\\ref{big_fig})) and assumes that within each time-slice the hypothetical random walker can traverse edges instantaneously, i.e. without requiring that time move forward for them to perform the movement. Consequently, if there is any cycle within a single time-slice (including for example an edge from $i$ to $j$ and another from $j$ to $i$) then there will be paths of infinite length, meaning that $\\alpha$ must be restricted to a particular range of values to guarantee convergence \\cite{greetham2013centrality}.\n\nIn this work we remove the assumption that a walk can traverse more than one edge per time slice (as suggested in \\cite{grindrod2013matrix}). Moreover, we suggest the following recursive approach to computing the dynamic communicability metrics which avoids the need to perform any matrix operations. Suppose we have a network $G$ with each temporal edge denoted by a triple $(i,j,t)$ where $i$ is the source node, $j$ is the target node and $t$ is the time, we define  \n\n", "index": 57, "text": "\\begin{equation}\nf(i,\\tau)=1+\\alpha\\sum_{\\substack{(i,j,t)\\in G:\\\\ t_{\\text{end}}>t>\\tau}} f(j,t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"f(i,\\tau)=1+\\alpha\\sum_{\\begin{subarray}{c}(i,j,t)\\in G:\\\\&#10;t_{\\text{end}}&gt;t&gt;\\tau\\end{subarray}}f(j,t).\" display=\"block\"><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mtable class=\"ltx_align_c\" rowspacing=\"0.0pt\"><mtr><mtd><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><mi>G</mi></mrow><mo>:</mo><mi/></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>t</mi><mtext>end</mtext></msub><mo>&gt;</mo><mi>t</mi><mo>&gt;</mo><mi>\u03c4</mi></mrow></mtd></mtr></mtable></munder><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSimilarly, for the receive score we define\n\n", "itemtype": "equation", "pos": 35340, "prevtext": "\nThen the broadcast score for node $i$ computed between time $t_{0}$ and $t_{\\text{end}}$ is given by\n\n", "index": 59, "text": "\\begin{equation}\n\\label{bc_compute}\nb_{i}=f(i,t_{0}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"b_{i}=f(i,t_{0}).\" display=\"block\"><mrow><mrow><msub><mi>b</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThen the receive score for node $i$ computed between time $t_{0}$ and $t_{\\text{end}}$ is given by\n\n", "itemtype": "equation", "pos": 35452, "prevtext": "\nSimilarly, for the receive score we define\n\n", "index": 61, "text": "\\begin{equation}\ng(i,\\tau)=1+\\alpha\\sum_{\\substack{(j,i,t)\\in G:\\\\ \\tau>t>t_{0}}} g(j,t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"g(i,\\tau)=1+\\alpha\\sum_{\\begin{subarray}{c}(j,i,t)\\in G:\\\\&#10;\\tau&gt;t&gt;t_{0}\\end{subarray}}g(j,t).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mtable class=\"ltx_align_c\" rowspacing=\"0.0pt\"><mtr><mtd><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><mi>G</mi></mrow><mo>:</mo><mi/></mrow></mtd></mtr><mtr><mtd><mrow><mi>\u03c4</mi><mo>&gt;</mo><mi>t</mi><mo>&gt;</mo><msub><mi>t</mi><mn>0</mn></msub></mrow></mtd></mtr></mtable></munder><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThese methods allow for the score for a single node to be computed without wasting unnecessary time computing the score for every other node. When computing the scores of the whole sample we relied on memoization to avoid repeating a large number of calls to the functions $f$ and $g$.  \n\\begin{figure*}[t!]\n    \\centering\n    \\subfloat[Enron email directory\\label{enron_plot}]{\n        \\includegraphics[width=0.46\\textwidth]{Enron_broadcast_plot_2.eps}\n\t\t\t\t}\t\\qquad\n\t\t\\subfloat[Hospital contact network\\label{hospital_plot}]{\n        \\includegraphics[width=0.46\\textwidth]{Hospital_receive_plot_2.eps}\n\t}\n    \\caption{The rank according to broadcast score (left, computed by Eq.\\eqref{bc_compute}) and receive score (right, computed by Eq.\\eqref{rc_compute}), with $\\alpha=0.01$ and $\\alpha=0.005$ respectively, plotted against the out-degree (left) and in-degree (right). Each individual in the network is represented by a data point, their classification is given by their shape. The abbreviations in the legend are explained in Section \\ref{data}. The one-to-one line is plotted as a visual aid to partition the nodes into two groups; those which have higher than expected scores (top left), and those who have lower than expected (bottom right).}\n\\label{plots_2}\n\\end{figure*}\n\n\\section{Results}\n\\label{results}\n\\subsection{Modeling}\nIn Section \\ref{model} we derived formulae which predict the outcome of calculating the broadcast score for a large number of shuffled temporal edge-lists. The amount of error in these predictions is illustrated in Fig.(\\ref{shuffle_test}) where we see that Eq.\\eqref{W_sol_c} gives accurate results regarding temporal edge lists with the time-column shuffled. The corresponding result, Eq.\\eqref{time_formula}, appears to be less reliable however, owing to the computational cost of calculating the receive score multiple times, we chose only to test a very small sample. This contradicts the assumptions of the analytical model; particularly the assumption made in Section \\ref{expectation} that the score $c_{i}(t)$ in an individual generation of the probabilistic model is well approximated by its mean, at time $t$, over many generations. It is likely that in a small data-set that there is a high variance in the distribution of receive scores and we expect the prediction to improve as the number of interactions increases. The creation of these ``shortcut'' formulae allowed us to perform data analysis on two large scale temporal edge-lists which would have otherwise taken an inconvenient amount of computation.  \n\n\\subsection{Data analysis}\nUsing the method described in Section \\ref{score_description} we calculated the broadcast score for the Enron email corpus and the receive score for the Sociopatterns hospital ward experiment. We have chosen values of $\\alpha$ that produce visually interesting figures; when too small the calculation broadcast and receive scores are dominated by the contribution from walks of length $1$ and therefore become equivalent to the out-degree and in-degree respectively. Conversely, when $\\alpha$ is too large, long walks dominate the scores and the edges with early timestamps determine the outcome. The results are presented first in Fig.(\\ref{box}). In Fig.(\\ref{plots_2}) we compare the result of each individual with their overall activity.\n\nWe note two observations from Fig.(\\ref{plots_2}): one Enron employee (a director) stands out as having an unusually high broadcast score when compared to a low amount of overall activity (broadcast rank $50$, degree rank $125$), and that patients in the hospital ward tend to have large receive scores considering their overall activity. \n\nFig.(\\ref{plots}) shows the expected results of performing various shufflings, we can think of the $y$-axis in these plots as a measure of how much the score of each individual depends on temporal properties, and the $x$-axis for structural properties. We see that the outlier from the Enron data-set is, remarkably, unremarkable regarding both of these measures and neither predicts their high broadcast score (time-shuffled rank $86$ and target-shuffled rank $104$, both lower than the actual broadcast rank of $25$). We speculate that the individual in question was feeding information into the network which was consequently being disseminated through the network in a way that inflates their broadcast score (although similar results are not found for the CEOs who we would expect to be influential in the same way). The individual in question was a lobbyist for the corporation, after a very brief investigation we did not determine a particular reason why they should be significantly influencial.\n\nFrom Fig.(\\ref{hospital_plot2}) it is apparent that shuffling the time column can cause large changes to the receive rank of a participant whereas the source-shuffling appears to be less effective. This is because the temporal activity of the participants deviates significantly from a Bernoulli process (that is assumed in the time-independent model). More specifically, nodes exist which are inactive towards the beginning of the sampling period but have a lot of activity at later time-steps. The receive score of these nodes is amplified by the exponential increase over time that was shown in Section \\ref{simple_time}. Those which are active early on in the sampling period but have little or no activity at later times will have lower receive scores. When such effects dominate the outcome the effect of time-shuffling is significant.\n\\begin{figure*}[t!]\n    \\centering\n\t\t   \\subfloat[Enron email directory\\label{enron_plot2}]{\n        \\includegraphics[width=0.46\\textwidth]{Enron_broadcast_plot.eps}\t\n\t\t\t\t}\\qquad\n\t\t\t\t\\subfloat[Hospital contact network\\label{hospital_plot2}]{\n        \\includegraphics[width=0.46\\textwidth]{Hospital_receive_plot.eps}\n\t}\n    \\caption{As demonstrated in Fig.(\\ref{databases}). On the $x$-axis we show the ranking of each node according to expectation of the broadcast score (left, computed using Eq.\\eqref{time_formula_b}) and receive score (right, computed with Eq.\\eqref{time_formula}) for the expected outcomes of the source (left) and target (right) shuffled networks (with $\\alpha=0.01$ and $\\alpha=0.005$ respectively). The $y$-axes show the expected scores for a time-shuffled network computed with Eqs.\\eqref{W_sol_b} and \\eqref{W_sol_c}. The actual broadcast score computed with Eqs. \\eqref{bc_compute} and \\eqref{rc_compute} is shown by the darkness of the markers. Different roles are indicated by the marker shapes, the abbreviations are explained in Section \\ref{data}. These results are also presented in a table in Appendix \\ref{lists}.\n\\label{plots}}\n\n\\end{figure*}\n\n\n\\section{Discussion}\n\\label{discussion}\nWhen we look at the simple example of Fig.(\\ref{big_fig}), we can compute the broadcast scores and find that node $A$ is ranked number one. We can then ask why $A$ is the most influential broadcaster and find that it is not because it was the most active ($C$ was in fact the most active), but because of a complex interplay of temporal and structural factors; $A$ was the first to communicate, and importantly, one of those early edges was received by $C$ who was subsequently the most active node. Looking at large data-sets it is tedious to try to deconstruct every sequence of contacts that caused each individual to achieve its score. Instead, we have introduced meaningful statistics, i.e. the results of shuffling, that provide insight into the interplay of temporal and structural factors.\n\nAs data-driven industries increasingly find value in targeting the most central, most influential, individuals, it is important to scrutinize the methods and tools that network science is promoting. The idea that there is one magic formula which can produce a meaningful result regardless of the system in question is firstly, wrong, and secondly, a counter-productive way of thinking. Here we have scrutinized the dynamic communicability metrics and found that temporal variation can have a stronger effect in some systems, like the hospital ward, than in others, like Enron. We have found efficient shortcut formulae to quantify the temporal component by randomizing the structural factors and likewise quantify the structural component by randomizing the temporal factors. Those who have data and wish to analyze dynamic communicability should use these methods to add more dimensions, and more depth, to their analysis.  \n\nA specific issue that ought to be considered when using the dynamic communicability metrics is the effect of a bounded sampling window. Take for example the simple example of Fig.(\\ref{big_fig}). Here $A$ has the highest broadcast score because it is the first node to create outgoing edges. Had we observed the system just one time-step earlier we might have found one or more edges from $C$ to $A$, thus making $C$ the highest ranked broadcaster above $A$. This is a general issue; our analytical results tell us that the earlier interactions contribute exponentially more than those which occur later; therefore the first node involved in the first recorded interaction will, by chance, receive an unduly high broadcast score. In the case of the receive score, interactions that occur late in the sample inflate the score of the involved nodes. The advancement of dynamic communicability presented in \\cite{grindrod2013matrix}, that assumes infectiousness decays in the time between interactions, may mitigate these problems to some extent. We conclude this paper by suggesting two possible alternative solutions:\n\\subsection{Control for temporal variation}\nEq.\\eqref{time_formula} gives the expectation of the receive score based on temporal variation. It can therefore be considered as a control to compare to the actual score. Further, we suggest that a normalized version of the receive score would be a more appropriate measure to compare individuals in the same network. The normalized version is the ratio of the actual score, computed using Eq.\\eqref{rc_compute}, and its expectation, computed using Eq.\\eqref{time_formula}. \n\\subsection{Remove temporal variation}\nAlternatively, we ignore temporal variation altogether; in many circumstances this is sensible since the temporal variation over the duration of the sample is not usually expected to be the same in the future (unless perhaps it is driven by a cyclic process). Without knowledge of when each future interaction will occur, the Bernoulli process used in the time-independent model is a suitable choice. In such a case, the past data provides an estimate of how active each node will be, but the timing of their interactions remains random. The matrix exponential in Eqs.\\eqref{W_sol_c} and \\eqref{W_sol_b}, can be computed very efficiently to give these approximations to the receive score and broadcast score. Incidentally, the matrix exponential has previously been proposed as a centrality measure \\cite{estrada2008communicability,benzi2013total}.\n\n\\section*{Acknowledgements}\nWe thank Georgios Giasemidis for helpful discussions at early stages of the project. We are grateful to Shweta Bansal for helpful comments regarding the structure and presentation of the manuscript and to Isabel Chen for feedback in the late stages. E.R.C was funded in part by RCUK Digital Economy programme via EPSRC Grant EP/G065802/1 `The Horizon Hub' and in part by NSF Grant No. $1414296$ as part of the joint NSF-NIH-USDA Ecology and Evolution of Infectious Diseases program.\n\\end{multicols}\n\n\\small\n\\bibliography{bibfile}\n\\bibliographystyle{ieeetr}\n\\normalsize\n\n\n\\newpage\n\\begin{multicols}{2}\n\\appendix\n\\section{Modeling}\n\\subsection{Heterogeneous ``send'' and ``receive'' model}\n\\label{sr_sol}\n\\emph{The Model:}\n\\begin{quotation}\n\\noindent\nIn any given time-step, the probability that $i$ has an out going edge is $s_{i}$, the probability that it has an incoming edge is $r_{i}$.\n\\end{quotation}\nMaking no further assumptions about who communicates with whom, letting $\\mathbf{r}$ and $\\mathbf{s}$ both be column vectors we have the general stochastic model with\n\n", "itemtype": "equation", "pos": 35656, "prevtext": "\nThen the receive score for node $i$ computed between time $t_{0}$ and $t_{\\text{end}}$ is given by\n\n", "index": 63, "text": "\\begin{equation}\n\\label{rc_compute}\nc_{i}=g(i,t_{\\text{end}}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"c_{i}=g(i,t_{\\text{end}}).\" display=\"block\"><mrow><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><msub><mi>t</mi><mtext>end</mtext></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThere are at least two ways to find the expectation of broadcast and receive scores for this model. It is possible to write down an expression for the $P^{k}$ which can then be substituted into Eq.(\\ref{powers}). An alternative method is to solve Eq.(\\ref{diff_c}) directly. First we express Eq.(\\ref{diff_c}) in terms of our new variables:\n\n", "itemtype": "equation", "pos": 47830, "prevtext": "\nThese methods allow for the score for a single node to be computed without wasting unnecessary time computing the score for every other node. When computing the scores of the whole sample we relied on memoization to avoid repeating a large number of calls to the functions $f$ and $g$.  \n\\begin{figure*}[t!]\n    \\centering\n    \\subfloat[Enron email directory\\label{enron_plot}]{\n        \\includegraphics[width=0.46\\textwidth]{Enron_broadcast_plot_2.eps}\n\t\t\t\t}\t\\qquad\n\t\t\\subfloat[Hospital contact network\\label{hospital_plot}]{\n        \\includegraphics[width=0.46\\textwidth]{Hospital_receive_plot_2.eps}\n\t}\n    \\caption{The rank according to broadcast score (left, computed by Eq.\\eqref{bc_compute}) and receive score (right, computed by Eq.\\eqref{rc_compute}), with $\\alpha=0.01$ and $\\alpha=0.005$ respectively, plotted against the out-degree (left) and in-degree (right). Each individual in the network is represented by a data point, their classification is given by their shape. The abbreviations in the legend are explained in Section \\ref{data}. The one-to-one line is plotted as a visual aid to partition the nodes into two groups; those which have higher than expected scores (top left), and those who have lower than expected (bottom right).}\n\\label{plots_2}\n\\end{figure*}\n\n\\section{Results}\n\\label{results}\n\\subsection{Modeling}\nIn Section \\ref{model} we derived formulae which predict the outcome of calculating the broadcast score for a large number of shuffled temporal edge-lists. The amount of error in these predictions is illustrated in Fig.(\\ref{shuffle_test}) where we see that Eq.\\eqref{W_sol_c} gives accurate results regarding temporal edge lists with the time-column shuffled. The corresponding result, Eq.\\eqref{time_formula}, appears to be less reliable however, owing to the computational cost of calculating the receive score multiple times, we chose only to test a very small sample. This contradicts the assumptions of the analytical model; particularly the assumption made in Section \\ref{expectation} that the score $c_{i}(t)$ in an individual generation of the probabilistic model is well approximated by its mean, at time $t$, over many generations. It is likely that in a small data-set that there is a high variance in the distribution of receive scores and we expect the prediction to improve as the number of interactions increases. The creation of these ``shortcut'' formulae allowed us to perform data analysis on two large scale temporal edge-lists which would have otherwise taken an inconvenient amount of computation.  \n\n\\subsection{Data analysis}\nUsing the method described in Section \\ref{score_description} we calculated the broadcast score for the Enron email corpus and the receive score for the Sociopatterns hospital ward experiment. We have chosen values of $\\alpha$ that produce visually interesting figures; when too small the calculation broadcast and receive scores are dominated by the contribution from walks of length $1$ and therefore become equivalent to the out-degree and in-degree respectively. Conversely, when $\\alpha$ is too large, long walks dominate the scores and the edges with early timestamps determine the outcome. The results are presented first in Fig.(\\ref{box}). In Fig.(\\ref{plots_2}) we compare the result of each individual with their overall activity.\n\nWe note two observations from Fig.(\\ref{plots_2}): one Enron employee (a director) stands out as having an unusually high broadcast score when compared to a low amount of overall activity (broadcast rank $50$, degree rank $125$), and that patients in the hospital ward tend to have large receive scores considering their overall activity. \n\nFig.(\\ref{plots}) shows the expected results of performing various shufflings, we can think of the $y$-axis in these plots as a measure of how much the score of each individual depends on temporal properties, and the $x$-axis for structural properties. We see that the outlier from the Enron data-set is, remarkably, unremarkable regarding both of these measures and neither predicts their high broadcast score (time-shuffled rank $86$ and target-shuffled rank $104$, both lower than the actual broadcast rank of $25$). We speculate that the individual in question was feeding information into the network which was consequently being disseminated through the network in a way that inflates their broadcast score (although similar results are not found for the CEOs who we would expect to be influential in the same way). The individual in question was a lobbyist for the corporation, after a very brief investigation we did not determine a particular reason why they should be significantly influencial.\n\nFrom Fig.(\\ref{hospital_plot2}) it is apparent that shuffling the time column can cause large changes to the receive rank of a participant whereas the source-shuffling appears to be less effective. This is because the temporal activity of the participants deviates significantly from a Bernoulli process (that is assumed in the time-independent model). More specifically, nodes exist which are inactive towards the beginning of the sampling period but have a lot of activity at later time-steps. The receive score of these nodes is amplified by the exponential increase over time that was shown in Section \\ref{simple_time}. Those which are active early on in the sampling period but have little or no activity at later times will have lower receive scores. When such effects dominate the outcome the effect of time-shuffling is significant.\n\\begin{figure*}[t!]\n    \\centering\n\t\t   \\subfloat[Enron email directory\\label{enron_plot2}]{\n        \\includegraphics[width=0.46\\textwidth]{Enron_broadcast_plot.eps}\t\n\t\t\t\t}\\qquad\n\t\t\t\t\\subfloat[Hospital contact network\\label{hospital_plot2}]{\n        \\includegraphics[width=0.46\\textwidth]{Hospital_receive_plot.eps}\n\t}\n    \\caption{As demonstrated in Fig.(\\ref{databases}). On the $x$-axis we show the ranking of each node according to expectation of the broadcast score (left, computed using Eq.\\eqref{time_formula_b}) and receive score (right, computed with Eq.\\eqref{time_formula}) for the expected outcomes of the source (left) and target (right) shuffled networks (with $\\alpha=0.01$ and $\\alpha=0.005$ respectively). The $y$-axes show the expected scores for a time-shuffled network computed with Eqs.\\eqref{W_sol_b} and \\eqref{W_sol_c}. The actual broadcast score computed with Eqs. \\eqref{bc_compute} and \\eqref{rc_compute} is shown by the darkness of the markers. Different roles are indicated by the marker shapes, the abbreviations are explained in Section \\ref{data}. These results are also presented in a table in Appendix \\ref{lists}.\n\\label{plots}}\n\n\\end{figure*}\n\n\n\\section{Discussion}\n\\label{discussion}\nWhen we look at the simple example of Fig.(\\ref{big_fig}), we can compute the broadcast scores and find that node $A$ is ranked number one. We can then ask why $A$ is the most influential broadcaster and find that it is not because it was the most active ($C$ was in fact the most active), but because of a complex interplay of temporal and structural factors; $A$ was the first to communicate, and importantly, one of those early edges was received by $C$ who was subsequently the most active node. Looking at large data-sets it is tedious to try to deconstruct every sequence of contacts that caused each individual to achieve its score. Instead, we have introduced meaningful statistics, i.e. the results of shuffling, that provide insight into the interplay of temporal and structural factors.\n\nAs data-driven industries increasingly find value in targeting the most central, most influential, individuals, it is important to scrutinize the methods and tools that network science is promoting. The idea that there is one magic formula which can produce a meaningful result regardless of the system in question is firstly, wrong, and secondly, a counter-productive way of thinking. Here we have scrutinized the dynamic communicability metrics and found that temporal variation can have a stronger effect in some systems, like the hospital ward, than in others, like Enron. We have found efficient shortcut formulae to quantify the temporal component by randomizing the structural factors and likewise quantify the structural component by randomizing the temporal factors. Those who have data and wish to analyze dynamic communicability should use these methods to add more dimensions, and more depth, to their analysis.  \n\nA specific issue that ought to be considered when using the dynamic communicability metrics is the effect of a bounded sampling window. Take for example the simple example of Fig.(\\ref{big_fig}). Here $A$ has the highest broadcast score because it is the first node to create outgoing edges. Had we observed the system just one time-step earlier we might have found one or more edges from $C$ to $A$, thus making $C$ the highest ranked broadcaster above $A$. This is a general issue; our analytical results tell us that the earlier interactions contribute exponentially more than those which occur later; therefore the first node involved in the first recorded interaction will, by chance, receive an unduly high broadcast score. In the case of the receive score, interactions that occur late in the sample inflate the score of the involved nodes. The advancement of dynamic communicability presented in \\cite{grindrod2013matrix}, that assumes infectiousness decays in the time between interactions, may mitigate these problems to some extent. We conclude this paper by suggesting two possible alternative solutions:\n\\subsection{Control for temporal variation}\nEq.\\eqref{time_formula} gives the expectation of the receive score based on temporal variation. It can therefore be considered as a control to compare to the actual score. Further, we suggest that a normalized version of the receive score would be a more appropriate measure to compare individuals in the same network. The normalized version is the ratio of the actual score, computed using Eq.\\eqref{rc_compute}, and its expectation, computed using Eq.\\eqref{time_formula}. \n\\subsection{Remove temporal variation}\nAlternatively, we ignore temporal variation altogether; in many circumstances this is sensible since the temporal variation over the duration of the sample is not usually expected to be the same in the future (unless perhaps it is driven by a cyclic process). Without knowledge of when each future interaction will occur, the Bernoulli process used in the time-independent model is a suitable choice. In such a case, the past data provides an estimate of how active each node will be, but the timing of their interactions remains random. The matrix exponential in Eqs.\\eqref{W_sol_c} and \\eqref{W_sol_b}, can be computed very efficiently to give these approximations to the receive score and broadcast score. Incidentally, the matrix exponential has previously been proposed as a centrality measure \\cite{estrada2008communicability,benzi2013total}.\n\n\\section*{Acknowledgements}\nWe thank Georgios Giasemidis for helpful discussions at early stages of the project. We are grateful to Shweta Bansal for helpful comments regarding the structure and presentation of the manuscript and to Isabel Chen for feedback in the late stages. E.R.C was funded in part by RCUK Digital Economy programme via EPSRC Grant EP/G065802/1 `The Horizon Hub' and in part by NSF Grant No. $1414296$ as part of the joint NSF-NIH-USDA Ecology and Evolution of Infectious Diseases program.\n\\end{multicols}\n\n\\small\n\\bibliography{bibfile}\n\\bibliographystyle{ieeetr}\n\\normalsize\n\n\n\\newpage\n\\begin{multicols}{2}\n\\appendix\n\\section{Modeling}\n\\subsection{Heterogeneous ``send'' and ``receive'' model}\n\\label{sr_sol}\n\\emph{The Model:}\n\\begin{quotation}\n\\noindent\nIn any given time-step, the probability that $i$ has an out going edge is $s_{i}$, the probability that it has an incoming edge is $r_{i}$.\n\\end{quotation}\nMaking no further assumptions about who communicates with whom, letting $\\mathbf{r}$ and $\\mathbf{s}$ both be column vectors we have the general stochastic model with\n\n", "index": 65, "text": "\\begin{equation}\nP=\\mathbf{s}\\mathbf{r}^{T}=\n \\begin{pmatrix}\n  s_{1}r_{1} & s_{1}r_{2}& \\cdots & s_{1}r_{N} \\\\\n  s_{2}r_{1} & s_{2}r_{2} & \\cdots & s_{2}r_{N} \\\\\n  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n  s_{N}r_{1} & s_{N}r_{2} & \\cdots & s_{N}r_{N}\n \\end{pmatrix}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"P=\\mathbf{s}\\mathbf{r}^{T}=\\begin{pmatrix}s_{1}r_{1}&amp;s_{1}r_{2}&amp;\\cdots&amp;s_{1}r_%&#10;{N}\\\\&#10;s_{2}r_{1}&amp;s_{2}r_{2}&amp;\\cdots&amp;s_{2}r_{N}\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;s_{N}r_{1}&amp;s_{N}r_{2}&amp;\\cdots&amp;s_{N}r_{N}\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mi>P</mi><mo>=</mo><msup><mi>\ud835\udc2c\ud835\udc2b</mi><mi>T</mi></msup><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mn>1</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mn>2</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mi>N</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mn>1</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mn>2</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>r</mi><mi>N</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mi>N</mi></msub><mo>\u2062</mo><msub><mi>r</mi><mn>1</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mi>N</mi></msub><mo>\u2062</mo><msub><mi>r</mi><mn>2</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><msub><mi>s</mi><mi>N</mi></msub><mo>\u2062</mo><msub><mi>r</mi><mi>N</mi></msub></mrow></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nMultipling both sides on the right by $s$ gives\n\n", "itemtype": "equation", "pos": 48455, "prevtext": "\nThere are at least two ways to find the expectation of broadcast and receive scores for this model. It is possible to write down an expression for the $P^{k}$ which can then be substituted into Eq.(\\ref{powers}). An alternative method is to solve Eq.(\\ref{diff_c}) directly. First we express Eq.(\\ref{diff_c}) in terms of our new variables:\n\n", "index": 67, "text": "\\begin{equation}\n\\label{c_diff_rs}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{\\hat{c}}(t)\\mathbf{s}\\mathbf{r}^{T} .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{\\hat{c}}(t)%&#10;\\mathbf{s}\\mathbf{r}^{T}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc2c\ud835\udc2b</mi><mi>T</mi></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhich is a differential equation describing the time-evolution of $\\hat{c}(t)s$, a scalar variable. This has the solution\n\n", "itemtype": "equation", "pos": 48654, "prevtext": "\nMultipling both sides on the right by $s$ gives\n\n", "index": 69, "text": "\\begin{equation}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)\\mathbf{s}}{\\partial t}=\\alpha \\mathbf{\\hat{c}}(t)\\mathbf{s}\\mathbf{r}^{T}\\mathbf{s}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)\\mathbf{s}}{\\partial t}=\\alpha\\mathbf{\\hat{c}%&#10;}(t)\\mathbf{s}\\mathbf{r}^{T}\\mathbf{s}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc2c\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSubstituting the result back into Eq.\\eqref{c_diff_rs} we get\n\n", "itemtype": "equation", "pos": 48928, "prevtext": "\nwhich is a differential equation describing the time-evolution of $\\hat{c}(t)s$, a scalar variable. This has the solution\n\n", "index": 71, "text": "\\begin{equation}\n\\mathbf{\\hat{c}}(t)\\mathbf{s}=e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t)\\mathbf{s}=e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}.\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo>=</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nWhich has the solution\n\n", "itemtype": "equation", "pos": 49091, "prevtext": "\nSubstituting the result back into Eq.\\eqref{c_diff_rs} we get\n\n", "index": 73, "text": "\\begin{equation}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{r}e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{r}e^{\\alpha[%&#10;\\mathbf{r}^{T}\\mathbf{s}]t}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\ud835\udc2b</mi><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nIn a similar way one can show that the expectation of the broadcast score is\n\n", "itemtype": "equation", "pos": 49250, "prevtext": "\nWhich has the solution\n\n", "index": 75, "text": "\\begin{equation}\n\\mathbf{\\hat{c}}(t)=\\mathbf{1}+\\left(\\frac{e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}-1}{\\mathbf{r}^{T}\\mathbf{s}}\\right)\\mathbf{r}^{T}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t)=\\mathbf{1}+\\left(\\frac{e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]%&#10;t}-1}{\\mathbf{r}^{T}\\mathbf{s}}\\right)\\mathbf{r}^{T}.\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>\ud835\udfcf</mn><mo>+</mo><mrow><mrow><mo>(</mo><mfrac><mrow><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow></msup><mo>-</mo><mn>1</mn></mrow><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n\n\\subsection{Time-dependent $P$ matrix}\n\\label{t_model}\n\\emph{The Model:}\n\\begin{quotation}\n\\noindent\nAt time $\\tau$, the probability that $i$ has an out going edge is $s_{i}$, the probability that it has an incoming edge is $r_{i}(\\tau)$\n\\end{quotation}\nEq.(\\ref{diff_c}) now becomes\n\n", "itemtype": "equation", "pos": 49491, "prevtext": "\nIn a similar way one can show that the expectation of the broadcast score is\n\n", "index": 77, "text": "\\begin{equation}\n\\mathbf{\\hat{b}}(t)=\\mathbf{1}^{T}+\\left(\\frac{e^{\\alpha[\\mathbf{r}^{T}\\mathbf{s}]t}-1}{\\mathbf{r}^{T}\\mathbf{s}}\\right)\\mathbf{s}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{b}}(t)=\\mathbf{1}^{T}+\\left(\\frac{e^{\\alpha[\\mathbf{r}^{T}\\mathbf%&#10;{s}]t}-1}{\\mathbf{r}^{T}\\mathbf{s}}\\right)\\mathbf{s}.\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1b</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mn>\ud835\udfcf</mn><mi>T</mi></msup><mo>+</mo><mrow><mrow><mo>(</mo><mfrac><mrow><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow></msup><mo>-</mo><mn>1</mn></mrow><mrow><msup><mi>\ud835\udc2b</mi><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nMultiplying both sides on the right by $s$ we get\n\n", "itemtype": "equation", "pos": 49940, "prevtext": "\n\n\\subsection{Time-dependent $P$ matrix}\n\\label{t_model}\n\\emph{The Model:}\n\\begin{quotation}\n\\noindent\nAt time $\\tau$, the probability that $i$ has an out going edge is $s_{i}$, the probability that it has an incoming edge is $r_{i}(\\tau)$\n\\end{quotation}\nEq.(\\ref{diff_c}) now becomes\n\n", "index": 79, "text": "\\begin{equation}\n\\label{diff_s}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{\\hat{c}}(t)\\mathbf{s}\\mathbf{r}(t_{0}+t)^{T}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E40.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{\\hat{c}}(t)%&#10;\\mathbf{s}\\mathbf{r}(t_{0}+t)^{T}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThis equation now only includes scalar functions of $t$ so we can solve to get\n\n", "itemtype": "equation", "pos": 50146, "prevtext": "\nMultiplying both sides on the right by $s$ we get\n\n", "index": 81, "text": "\\begin{equation}\n\\begin{split}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}s&=\\alpha \\mathbf{\\hat{c}}(t) \\mathbf{s}\\mathbf{r}(t_{0}+t)^{T}\\mathbf{s}\\\\\n\\frac{\\partial \\mathbf{\\hat{c}}(t)\\mathbf{s}}{\\partial t}&=\\alpha [\\mathbf{\\hat{c}}(t)\\mathbf{s}][\\mathbf{s}\\mathbf{r}(t_{0}+t)^{T}].\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E41.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}s&amp;%&#10;\\displaystyle=\\alpha\\mathbf{\\hat{c}}(t)\\mathbf{s}\\mathbf{r}(t_{0}+t)^{T}%&#10;\\mathbf{s}\\\\&#10;\\displaystyle\\frac{\\partial\\mathbf{\\hat{c}}(t)\\mathbf{s}}{\\partial t}&amp;%&#10;\\displaystyle=\\alpha[\\mathbf{\\hat{c}}(t)\\mathbf{s}][\\mathbf{s}\\mathbf{r}(t_{0}%&#10;+t)^{T}].\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>\u2062</mo><mi>s</mi></mrow></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac></mtd><mtd columnalign=\"left\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\ud835\udc2c\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSubstituting this back into Eq.\\eqref{diff_s} we have\n\n", "itemtype": "equation", "pos": 50540, "prevtext": "\nThis equation now only includes scalar functions of $t$ so we can solve to get\n\n", "index": 83, "text": "\\begin{equation}\n\\mathbf{\\hat{c}}(t)\\mathbf{s}=\\mathbf{1}\\mathbf{s}\\exp\\left(\\alpha \\int_{0}^{t}\\mathbf{s}\\mathbf{r}(t_{0}+t')^{T}dt' \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E42.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{\\hat{c}}(t)\\mathbf{s}=\\mathbf{1}\\mathbf{s}\\exp\\left(\\alpha\\int_{0}^{t}%&#10;\\mathbf{s}\\mathbf{r}(t_{0}+t^{\\prime})^{T}dt^{\\prime}\\right).\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2c</mi></mrow><mo>=</mo><mrow><mn>\ud835\udfcf</mn><mo>\u2062</mo><mi>\ud835\udc2c</mi><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><mi>\ud835\udc2c\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSince $\\mathbf{1}s=1$.\n\\subsection{Simple time-dependent example}\n\\emph{The model:}\n\\begin{quotation}\n\\noindent\nAt time $\\tau_{i}$ person $i$ is on the receiving end of $r_{i}$ edges. As before, the number of outgoing edges is determined by a time-independent probability $s_{i}$.\n\\end{quotation}\nClearly, after $N$ iterations the process will end so we use $t_{0}=0$ and $t_{\\text{end}}=N$ as the initial and final conditions respectively. To find the broadcast score of a node $i$ we solve Eq.\\eqref{diff_srt} with \n\n", "itemtype": "equation", "pos": 50752, "prevtext": "\nSubstituting this back into Eq.\\eqref{diff_s} we have\n\n", "index": 85, "text": "\\begin{equation}\n\\label{diff_srt}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{r}(t_{0}+t)^{T}\\exp\\left(\\alpha \\int_{0}^{t}\\mathbf{s}\\mathbf{r}(t_{0}+t')^{T}dt' \\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E43.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{r}(t_{0}+t)^{T}%&#10;\\exp\\left(\\alpha\\int_{0}^{t}\\mathbf{s}\\mathbf{r}(t_{0}+t^{\\prime})^{T}dt^{%&#10;\\prime}\\right)\" display=\"block\"><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><mi>\ud835\udc2c\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nwhere $r_{i}$ is a scalar and $\\delta$ is the Dirac delta. The justification for this version of $r_{i}(\\tau)$ is that the expected number of messages sent by $i$ over some time-interval will be $r_{i}$ if the time interval includes $\\tau_{i}$. Without loss of generality we can say $\\tau_{i}=i$ meaning that node $1$ sends first, then node $2$ and so on. First we focus on expressing $\\mathbf{s}\\int_{0}^{t}\\mathbf{r}(t_{0}+t')^{T} d t'$ in a simpler form. Since\n\n", "itemtype": "equation", "pos": 51472, "prevtext": "\nSince $\\mathbf{1}s=1$.\n\\subsection{Simple time-dependent example}\n\\emph{The model:}\n\\begin{quotation}\n\\noindent\nAt time $\\tau_{i}$ person $i$ is on the receiving end of $r_{i}$ edges. As before, the number of outgoing edges is determined by a time-independent probability $s_{i}$.\n\\end{quotation}\nClearly, after $N$ iterations the process will end so we use $t_{0}=0$ and $t_{\\text{end}}=N$ as the initial and final conditions respectively. To find the broadcast score of a node $i$ we solve Eq.\\eqref{diff_srt} with \n\n", "index": 87, "text": "\\begin{equation}\nr_{i}(\\tau)=r_{i}\\delta(\\tau-\\tau_{i})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E44.m1\" class=\"ltx_Math\" alttext=\"r_{i}(\\tau)=r_{i}\\delta(\\tau-\\tau_{i})\" display=\"block\"><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c4</mi><mo>-</mo><msub><mi>\u03c4</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n(This result derives from the fact that the integral of the Dirac delta between $-\\infty$ and $t$ is the Heaviside step function $H(t)$.) we have\n\n", "itemtype": "equation", "pos": 52007, "prevtext": "\nwhere $r_{i}$ is a scalar and $\\delta$ is the Dirac delta. The justification for this version of $r_{i}(\\tau)$ is that the expected number of messages sent by $i$ over some time-interval will be $r_{i}$ if the time interval includes $\\tau_{i}$. Without loss of generality we can say $\\tau_{i}=i$ meaning that node $1$ sends first, then node $2$ and so on. First we focus on expressing $\\mathbf{s}\\int_{0}^{t}\\mathbf{r}(t_{0}+t')^{T} d t'$ in a simpler form. Since\n\n", "index": 89, "text": "\\begin{equation}\n\\int_{0}^{t}r_{j}\\delta(t'-j)dt'=\\left\\{\n   \\begin{aligned}\n     & r_{j}& \\quad \\text{if}\\quad j\\leq t\\\\\n     &0 & \\quad \\text{if}\\quad j\\geq t\n   \\end{aligned}\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E45.m1\" class=\"ltx_Math\" alttext=\"\\int_{0}^{t}r_{j}\\delta(t^{\\prime}-j)dt^{\\prime}=\\left\\{\\begin{aligned} &amp;%&#10;\\displaystyle r_{j}&amp;\\hskip 10.0pt\\quad\\text{if}\\quad j\\leq t\\\\&#10;&amp;\\displaystyle 0&amp;\\hskip 10.0pt\\quad\\text{if}\\quad j\\geq t\\end{aligned}\\right.\" display=\"block\"><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><msub><mi>r</mi><mi>j</mi></msub><mi>\u03b4</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo>\u2032</mo></msup><mo>-</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>t</mi><mo>\u2032</mo></msup><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd/><mtd columnalign=\"left\"><msub><mi>r</mi><mi>j</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded lspace=\"20pt\" width=\"+20pt\"><mtext>if</mtext></mpadded><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mi>j</mi></mrow><mo>\u2264</mo><mi>t</mi></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded lspace=\"20pt\" width=\"+20pt\"><mtext>if</mtext></mpadded><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mi>j</mi></mrow><mo>\u2265</mo><mi>t</mi></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nSubstituting this into Eq.\\eqref{diff_srt} then integrating over the whole sample gives\n\n", "itemtype": "equation", "pos": 52353, "prevtext": "\n(This result derives from the fact that the integral of the Dirac delta between $-\\infty$ and $t$ is the Heaviside step function $H(t)$.) we have\n\n", "index": 91, "text": "\\begin{equation}\n\\begin{split}\n\\mathbf{s}\\int_{0}^{t}\\mathbf{r}(t_{0}+t')^{T} d t'&=\\sum_{j=0}^{N} s_{j}\\int_{0}^{t}r_{j}\\delta(t'-j) d t'\\\\\n&=\\sum_{j=0}^{t}r_{j}s_{j}.\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E46.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\mathbf{s}\\int_{0}^{t}\\mathbf{r}(t_{0}+t^{\\prime})^{%&#10;T}dt^{\\prime}&amp;\\displaystyle=\\sum_{j=0}^{N}s_{j}\\int_{0}^{t}r_{j}\\delta(t^{%&#10;\\prime}-j)dt^{\\prime}\\\\&#10;&amp;\\displaystyle=\\sum_{j=0}^{t}r_{j}s_{j}.\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mi>\ud835\udc2c</mi><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><mi>\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>t</mi><mo>\u2032</mo></msup><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mi/><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></munderover><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThe integral is solved by the translation property of the Dirac delta and we have\n\n", "itemtype": "equation", "pos": 52637, "prevtext": "\nSubstituting this into Eq.\\eqref{diff_srt} then integrating over the whole sample gives\n\n", "index": 93, "text": "\\begin{equation}\n\\left[\\hat{c}_{i}(t')\\right]_{0}^{N}=\\int_{0}^{N}r_{i}\\delta(t'-i)\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right)dt'.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47.m1\" class=\"ltx_Math\" alttext=\"\\left[\\hat{c}_{i}(t^{\\prime})\\right]_{0}^{N}=\\int_{0}^{N}r_{i}\\delta(t^{\\prime%&#10;}-i)\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right)dt^{\\prime}.\" display=\"block\"><mrow><mrow><msubsup><mrow><mo>[</mo><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>]</mo></mrow><mn>0</mn><mi>N</mi></msubsup><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>N</mi></msubsup><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>t</mi><mo>\u2032</mo></msup><mo>-</mo><mi>i</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>i</mi></munderover><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nThis result shows that nodes which interact later in the sample will have, on average, exponentially higher receive scores. In a similar way, it can be shown that a node which acts earlier in the sample has an exponentially higher broadcast score.\n\n\\subsubsection{Incorporating empirical data}\nSuppose that for each node $i$ we know the time of every received edge but do not know where the edge originated from (this corresponds to the source shuffled network). We can achieve this by choosing\n\n", "itemtype": "equation", "pos": 25483, "prevtext": "\nThe justification for this choice of $\\mathbf{r}(\\tau)$ is that the expected number of messages received by $i$ over some interval will be $r_{i}$ if the time interval includes $\\tau_{i}$. For convenience we suppose, without loss of generality, that $\\tau_{i}=i$ for all $i\\in 1,2,...,N$. Solving Eq.\\eqref{c_time_dep} with this form of $\\mathbf{r}(\\tau)$ we get\n\n", "index": 45, "text": "\\begin{equation}\n\\hat{c}_{i}(N)=1+\\alpha r_{i}\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{i}(N)=1+\\alpha r_{i}\\exp\\left(\\alpha\\sum_{j=0}^{i}r_{j}s_{j}\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>i</mi></munderover><mrow><msub><mi>r</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nWe can choose the set $K_{i}$ and the corresponding $\\tau^{(k)}$ in a way that recreates exactly what is observed in the target and time columns of an empirical temporal edge-list. We introduce $R_{i}(\\tau)$, the number of messages sent by $i$ between time $t_{0}$ and time $\\tau$, this is expressed\n\n", "itemtype": "equation", "pos": 53361, "prevtext": "\n\\subsection{Incorporating empirical data}\n\\label{source_shuffled_derivation}\n\\emph{The model:}\n\\begin{quotation}\n\\noindent\nLet $K_{i}$ be the set of edges for which $i$ is the target node, and $\\tau^{(k)}$ be the time at which edge $k$ was present. As before, $s_{i}$ is the time-independent probability for $i$ to be the source an edge.\n\\end{quotation}\nWe achieve this by choosing\n\n", "index": 97, "text": "\\begin{equation}\nr_{i}(t)=\\sum_{k\\in K_{i}}\\delta(t-\\tau_{i}^{(k)}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m1\" class=\"ltx_Math\" alttext=\"r_{i}(t)=\\sum_{k\\in K_{i}}\\delta(t-\\tau_{i}^{(k)}).\" display=\"block\"><mrow><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo><msubsup><mi>\u03c4</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\ngiving\n\n", "itemtype": "equation", "pos": 53745, "prevtext": "\nWe can choose the set $K_{i}$ and the corresponding $\\tau^{(k)}$ in a way that recreates exactly what is observed in the target and time columns of an empirical temporal edge-list. We introduce $R_{i}(\\tau)$, the number of messages sent by $i$ between time $t_{0}$ and time $\\tau$, this is expressed\n\n", "index": 99, "text": "\\begin{equation}\nR_{i}(\\tau)=\\int_{t_{0}}^{\\tau}r_{i}(t')dt',\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E50.m1\" class=\"ltx_Math\" alttext=\"R_{i}(\\tau)=\\int_{t_{0}}^{\\tau}r_{i}(t^{\\prime})dt^{\\prime},\" display=\"block\"><mrow><mrow><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msub><mi>t</mi><mn>0</mn></msub><mi>\u03c4</mi></msubsup><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nand therefore Eq.\\eqref{diff_srt} can be expressed\n\n", "itemtype": "equation", "pos": 53829, "prevtext": "\ngiving\n\n", "index": 101, "text": "\\begin{equation}\nR_{i}(t_{0}+t)=\\int_{0}^{t}r_{i}(t_{0}+t')dt',\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E51.m1\" class=\"ltx_Math\" alttext=\"R_{i}(t_{0}+t)=\\int_{0}^{t}r_{i}(t_{0}+t^{\\prime})dt^{\\prime},\" display=\"block\"><mrow><mrow><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nIntegrating over the entire duration of the sample gives\n\n", "itemtype": "equation", "pos": 53959, "prevtext": "\nand therefore Eq.\\eqref{diff_srt} can be expressed\n\n", "index": 103, "text": "\\begin{equation}\n\\frac{\\partial \\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha \\mathbf{r}(t_{0}+t)^{T}e^{\\alpha \\sum_{j=1}^{N}s_{j}R_{j}(t_{0}+t)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E52.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial\\mathbf{\\hat{c}}(t)}{\\partial t}=\\alpha\\mathbf{r}(t_{0}+t)^{T}e^%&#10;{\\alpha\\sum_{j=1}^{N}s_{j}R_{j}(t_{0}+t)}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mover accent=\"true\"><mi>\ud835\udc1c</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\ud835\udc2b</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mstyle><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>R</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\nFinally, using the translation property of the Dirac delta function we have\n\n", "itemtype": "equation", "pos": 54172, "prevtext": "\nIntegrating over the entire duration of the sample gives\n\n", "index": 105, "text": "\\begin{equation}\n\\begin{split}\n&\\left[\\hat{c}_{i}(t')\\right]_{0}^{t_{\\text{end}}-t_{0}}\\\\\n&=\\alpha\\int_{0}^{t_{\\text{end}}-t_{0}}\\left[\\sum_{k \\in K_{i}}\\delta(t_{0}+t'-\\tau^{(k)})\\right]\\exp\\left(\\alpha\\sum_{j=1}^{N}s_{j}R_{j}(t_{0}+t')\\right)dt'\\\\\n&=\\alpha\\sum_{k \\in K_{i}}\\int_{-\\infty}^{\\infty}\\delta[t_{0}+t'-\\tau^{(k)}]\\exp\\left(\\alpha\\sum_{j=1}^{N}s_{j}R_{j}(t_{0}+t')\\right)dt'.\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E53.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}&amp;\\displaystyle\\left[\\hat{c}_{i}(t^{\\prime})\\right]_{0}^{t_{\\text{%&#10;end}}-t_{0}}\\\\&#10;&amp;\\displaystyle=\\alpha\\int_{0}^{t_{\\text{end}}-t_{0}}\\left[\\sum_{k\\in K_{i}}%&#10;\\delta(t_{0}+t^{\\prime}-\\tau^{(k)})\\right]\\exp\\left(\\alpha\\sum_{j=1}^{N}s_{j}R%&#10;_{j}(t_{0}+t^{\\prime})\\right)dt^{\\prime}\\\\&#10;&amp;\\displaystyle=\\alpha\\sum_{k\\in K_{i}}\\int_{-\\infty}^{\\infty}\\delta[t_{0}+t^{%&#10;\\prime}-\\tau^{(k)}]\\exp\\left(\\alpha\\sum_{j=1}^{N}s_{j}R_{j}(t_{0}+t^{\\prime})%&#10;\\right)dt^{\\prime}.\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd/><mtd columnalign=\"left\"><msubsup><mrow><mo>[</mo><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>t</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>]</mo></mrow><mn>0</mn><mrow><msub><mi>t</mi><mtext>end</mtext></msub><mo>-</mo><msub><mi>t</mi><mn>0</mn></msub></mrow></msubsup></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mrow><msub><mi>t</mi><mtext>end</mtext></msub><mo>-</mo><msub><mi>t</mi><mn>0</mn></msub></mrow></msubsup><mrow><mrow><mo>[</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo>-</mo><msup><mi>\u03c4</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>R</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup><mrow><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo>-</mo><msup><mi>\u03c4</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>R</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mn>0</mn></msub><mo>+</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><msup><mi>t</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00571.tex", "nexttext": "\n\\end{multicols}\n\\newpage\n\\include{AppendixB} \n\n\n\n\n", "itemtype": "equation", "pos": 54663, "prevtext": "\nFinally, using the translation property of the Dirac delta function we have\n\n", "index": 107, "text": "\\begin{equation}\n\\hat{c}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}s_{j}R_{j}(\\tau_{i}^{(k)})\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E54.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{i}=1+\\alpha\\sum_{k\\in K_{i}}\\exp\\left(\\alpha\\sum_{j\\in N}s_{j}R_{j}(%&#10;\\tau_{i}^{(k)})\\right).\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>i</mi></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><msub><mi>K</mi><mi>i</mi></msub></mrow></munder><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><mi>N</mi></mrow></munder><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>R</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03c4</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]