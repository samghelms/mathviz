[{"file": "1601.06204.tex", "nexttext": "\n\n\n\\hspace{-0.52cm}where $x_{(i)}$ denotes a permutation of the $x_{i}$\nvalues such that $x_{(1)}\\leq x_{(2)}\\leq\\ldots\\leq x_{(n)}$ and\n$C_{(i)}=\\left\\{ c_{(i)},c_{(i+1)},\\ldots,c_{(n)}\\right\\} $. \n\nAlthough it is not straightforward to see for all the cases, but all\nthe previously mentioned averaging functions, specifically the OWA\nand consequently the weighted average, the minimum and maximum, are\nall special cases of this general definition with an appropriate choice\nof fuzzy measure. As a consequence of the complexity with regard to\nthe need of estimating potentially $2^{n}$ coefficients in the fuzzy\nmeasure, the general Choquet integral has stared to gain popularity\nin different applications only in recent years \\citep{NarukawaTorra2007}.\nAs it was pointed out, the crucial aspect of the Choquet-integral\nthat makes is attractive in many applications compared to the traditional\naveraging functions is the capability of modeling interaction in the\naggregation process. In the general multi-criteria formulation of\nthe application of Choquet-integral, this can be translated to the\ninterrelation of criteria: an alternative is evaluated differently\nbased on criterion $A$ in the simultaneous presence of criterion\n$B$ than considering only $A$ without $B.$In the proposed application,\nthe risk level of an entity (country, bank) will be estimated based\non its present risk level and its connection to other entities. \n\nTo ease on the complexity of estimating the joint effect of all the\nconsidered criteria (connected components in the system) but still\nmoving beyond the simple representation of assuming independence,\none can consider only the joint effect of specific subsets and assume\nthat the others are negligible. A straightforward approach widely\ndiscussed in the literature is the case of 2-additive Choquet integral.\nIn this formulation, only the pairwise interaction between criteria\n(the joint effect of two connected components) is considered additionally\nto the individual effects. The Choquet integral in this case can be\nformulated as (see \\citet{Grabisch1997}):\n", "itemtype": "equation", "pos": 31927, "prevtext": "\n\\begin{frontmatter}\n\n\n\\title{{\\Large{}RiskRank: Measuring interconnected risk}\\tnoteref{mytitlenote}}\n\n\n\\tnotetext[mytitlenote]{The paper has benefited from presentation at the Finnish Economic\nAssociation XXXVII Annual Meeting (KT-p\u00e4ivat) in February, 2015 in\nHelsinki and at the RiskLab/Bank of Finland/European Systemic Risk\nBoard (ESRB) Conference on Systemic Risk Analytics (SRA) in September,\n2015 in Helsinki. The paper is complemented with a web-based application\nof networks that illustrate aggregation of risk in a hierarchical\nstructure: http://vis.risklab.fi/\\#/fuzzyAgg. The authors thank Gregor\nvon Schweinitz and Tuomas Peltonen for comments and discussions. Corresponding\nauthor: Peter Sarlin, Hanken School of Economics, Helsinki, Finland.\nE-mail: peter@risklab.fi.}\n\n\n\\author[P3,H]{ J\u00f3zsef Mezei}\n\n\n\\author[P2,P3]{ and Peter Sarlin}\n\n\n\\address[P2]{Department of Economics, Hanken School of Economics, Helsinki, Finland}\n\n\n\\address[P3]{RiskLab Finland at Arcada University of Applied Sciences, Helsinki,\nFinland}\n\n\n\\address[H]{Faculty of Social Sciences, Business, and Economics, \u00c5bo Akademi\nUniversity, Turku, Finland}\n\\begin{abstract}\nThis paper proposes RiskRank as a joint measure of cyclical and cross-sectional\nsystemic risk. RiskRank is a general-purpose aggregation operator\nthat concurrently accounts for risk levels for individual entities\nand their interconnectedness. The measure relies on the decomposition\nof systemic risk into sub-components that are in turn assessed using\na set of risk measures and their relationships. For this purpose,\nmotivated by the development of the Choquet integral, we employ the\nRiskRank function to aggregate risk measures, allowing for the integration\nof the interrelation of different factors in the aggregation process.\nThe use of RiskRank is illustrated through a real-world case in a\nEuropean setting, in which we show that it performs well in out-of-sample\nanalysis. In the example, we provide an estimation of systemic risk\nfrom country-level risk and cross-border linkages. \\end{abstract}\n\\begin{keyword}\nsystemic risk\\sep aggregation operators\\sep network analysis\\sep\nChoquet integral\n\n\\emph{JEL codes}: E440, F300, G010, G150, C430 \n\\end{keyword}\n\\end{frontmatter}\n\n\n\n\n\n\n\n\\newpage{}\n\n\n\\section{Introduction}\n\nThe current financial crisis has stimulated research on systemic financial\nrisks. This has led to several contributions for measuring interconnectedness\nand contagion risk, as well as for estimating probabilities of systemic\ndistress events. Yet, these two types of models have so far been built\nin isolation. This paper proposes RiskRank as a measure of connected\nrisk by joining risk likelihoods and impacts.\n\nThe literature on systemic risk measurement has evolved along two\ndimensions \\citep{Borio2011}: cyclical and cross-sectional systemic\nrisk. These two dimensions accentuate the need for modeling not only\nindividual financial components, be they economies, markets or institutions,\nbut also interconnectedness among them and their system-wide risk\ncontributions. To this end, analytical tools and models provide ample\nmeans for two types of tasks: (\\emph{i}) early identification of vulnerabilities\nand risks, and (\\emph{ii}) early assessment of transmission channels\nof and a system's resilience to shocks. While the first task is usually\ntackled with early-warning indicators and models to derive a probability\nof a systemic crisis (e.g., \\citet{Alessi2011520}), macro stress-testing\nmodels and contagion and spillover models provide means to assess\nthe resilience of the financial system to a wide variety of aggregate\nshocks (e.g., \\citet{Castrenetal2009}) and cross-sectional transmission\nof financial instability (e.g., \\citet{IMF}), respectively. RiskRank\naims at measuring both of these two dimensions concurrently.\n\nIn the vein of two strands of systemic risk measures, these can also\nbe viewed from the perspective of various approaches to aggregating\ninformation. Early-warning models tend to focus on the aggregation\nof multiple indicators into a meaningful measure of cyclical systemic\nrisk, which oftentimes takes the form of distress probabilities (e.g.,\n\\citet{Duca2012}). Further, the literature has also provided various\napproaches for aggregating multiple models in order to assure more\nrobust model output (e.g., \\citet{holopainen2015toward}). Likewise,\na large share of the literature on cross-sectional systemic risk has\nfocused on network-based measures of interconnectedness and connectivity\n(e.g., \\citet{billio2012,Peltonenetal2015}). RiskRank provides a\ncentrality measure for networks, but goes beyond link-based centrality\nby also accounting for materialization probabilities (or node importance).\n\nThis paper puts forward RiskRank as a measure of interconnected risk.\nWhile focusing on systemic risk, the approach is general-purpose in\nnature by applying to any type of risk that exhibits individual materialization\nprobabilities (i.e., risk levels of components) and impact measures\n(i.e., interlinkages among components ). In line with the literature\non aggregation operators, we put forward a framework motivated by\nthe Choquet integral as a means to aggregate risk levels to system-wide\nvulnerability by also accounting for the size of interlinkages across\nthe components of the system (be they economies, markets or institutions).\nHence, this can also be seen as a network-based centrality measure\nthat also accounts for node importance (i.e., risk levels). This provides\nnothing else than a likelihood of a systemic event at all levels of\nthe system, ranging from re-calculated risk at the lowest levels to\naggregated risk at the highest level. In this paper, we illustrate\nthe use of RiskRank from country-level early-warning models to connected\nindividual and system-wide risk. While being targeted at systemic\nfinancial risk, this flexible tool is easily adaptable to measuring\nany connected risk.\n\nThe rest of the paper is structured as follows. Section 2 discusses\nsystemic risk measurement and introduces aggregation operators and\ncentrality measures, particularly with a view to systemic risk. In\nSection 3, we motivate and describe the modification of the general\nform of Choquet integral into the Risk Rank measure and discuss its\nmost important features and use scenarios. Section 4 presents the\napplication of the RiskRank to the case of European systemic risk.\nFinally, we conclude in Section 5.\n\n\n\\section{Measuring Systemic risk: A synthesis}\n\nTo quantify systemic risk, we need a broad toolbox of models to measure\nand analyze system-wide threats to financial stability. In the vein\nof standard risk analysis, we disentangle the topic of systemic risk\ninto two tasks: probability and impact. While assigning probabilities\nto events aims at ranking individual risks and vulnerabilities as\nper intensity (i.e., tasks of early-warning models), assessing the\nseverity or impact of an event complements by modeling transmission\nchannels and quantifying losses given their materialization. This\naccentuates the need for modeling not only the likelihood of a distress\nevent $p_{i}^{t}$ in time $t$ for entity $i$, be they economies,\nmarkets or institutions, but also system-wide importance by accounting\nfor interconnectedness and other types of transmission channels $m_{ij}^{t}$\nbetween each entity $i$ and all other entities $j$ at time $t$.\n\nThis section discusses the role of systemic risk analysis from the\nviewpoint of the cyclical and cross-sectional dimensions. We discuss\nthe two strands of literature for systemic risk analysis, as well\nas motivate the need for a general-purpose approach for joining the\ntwo strands.\n\n\n\\subsection{Systemic risk models}\n\nBroadly speaking, tools and models can be divided into those for early\nidentification and assessment of systemic risks. \\citet{ECB2010}\nprovides a mapping of tools to the following three forms of systemic\nrisk: (\\emph{i}) early-warning models, (\\emph{ii}) contagion and spillover\nmodels, and (\\emph{iii}) macro stress-testing models.\n\n\n\\paragraph{Cyclical systemic risk}\n\nThe first form of systemic risk focuses on the unraveling of widespread\nimbalances and is illustrated by a thorough literature on the presence\nof risks, vulnerabilities and imbalances in banking systems and the\noverall macro-financial environment prior to historical financial\ncrises. This resembles Kindleberger\\textquoteright s \\citep{Kindleberger1996}\nand Minsky\\textquoteright s \\citep{Minsky1982} financial fragility\nview of a boom-bust credit or asset cycle. Hence, the subsequent abrupt\nunraveling of the imbalances may be endogenously or exogenously caused\nby idiosyncratic or systematic shocks, and may have adverse effects\non a wide range of financial intermediaries and markets in a simultaneous\nfashion. Early and later empirical literature alike have identified\ncommon patterns in underlying vulnerabilities preceding financial\ncrises (see, e.g., \\citet{Kaminskyetal1998b} and \\citet{ReinhartRogoff2008}).\n\nFirst, by focusing on the presence of vulnerabilities and imbalances\nin an economy, early-warning models can be used to derive probabilities\nof the occurrence of systemic financial crises in the future (e.g.,\n\\citet{Alessi2011520} and \\citet{Duca2012}). These models use a\nset of vulnerability and risk indicators to identify whether or not\nan economy is in a vulnerable state. The outputs of such models mostly\ntake the form of a probability of a crisis within a specific time\nhorizon and are monitored with respect to threshold values. Hence,\nthis provides us a probabilities of crisis $p_{i}^{t}$ in time $t$\nfor entity $i$, where entities may be economies, markets or institutions,\nbut does not provide information about the potential impact of the\nindividual entities on others. Typical methods used in early-warning\nmodels include logistic models \\citet{Duca2012} and machine learning\n\\citet{holopainen2015toward}. \n\n\n\\paragraph{Cross-sectional systemic risk}\n\nThe second type of systemic risk refers to two types of models for\nmeasuring the cross-sectional dimension. Macro stress-testing models\nprovide means to assess the resilience of the financial system to\na wide variety of aggregate shocks, such as economic downturns (e.g.,\n\\citet{Castrenetal2009} and \\citet{Hirtleetal2009}). These models\nallow policymakers to assess the consequences of assumed extreme,\nbut plausible, shocks for different entities. The key question of\nmacro stress-testing is to find the balance between plausibility and\nseverity of the stress scenarios such that they are plausible enough\nto be taken seriously and severe enough to be meaningful (e.g., \\citet{AlfaroDrehmann2009}\nand \\citet{Quagliariello2009}). Third, contagion and spillover models\ncan be employed to assess how resilient the financial system is to\ncross-sectional transmission of financial instability (e.g., \\citet{IMF}).\nHence, they attempt to answer the question: With what likelihood,\nand to what extent, could the failure of one or multiple financial\nintermediaries cause the failure of other intermediaries? Accordingly,\nthis line of work provides information on system-wide importance by\naccounting for interconnectedness and other types of transmission\nchannels $m_{ij}$ between each entity $i$ and all other entities\n$j$. Yet, this provides little information on the likelihood of individual\nentities being distressed.\n\nAnother type of cross-sectional systemic risk refers to a widespread\nexogenous aggregate shock that has negative systematic effects on\none or many financial intermediaries and markets at the same time.\nThese types of aggregate shocks have empirically been shown to co-occur\nwith financial instabilities (see, e.g., \\citet{Gorton1988} and \\citet{DemirgucDetragiache1998}).\nAn example of such an event is the collapse of banks during recessions\ndue to the vulnerability to economic downturns. The third form of\nsystemic risk is contagion and spillover, which usually refers to\nan idiosyncratic problem, be it endogenous or exogenous, that spreads\nin a sequential fashion in the cross section. The cross-sectional\ntransmission of financial instability has been empirically shown by\na large number studies (e.g., \\citet{UpperWorms2004} and \\citet{LelyveldLiedorp2006}).\nFor instance, episodes of financial instabilities have been shown\nto relate to the failure of one financial intermediary causing the\nfailure of another, which initially seemed solvent, was not vulnerable\nto the same risks and was not subject to the same original shock as\nthe former. It is worth noting that contagion refers to a situation\nwhen the initial failure is entirely responsible for subsequent ones,\nwhereas the term spillover is commonly used when the causal relationship\nis not found or cannot be tested (see, e.g., \\citet{ECB2010}). \nA recent approach presented in \\citet{Tarashev2010} makes use of\nthe Shapley index developed originally for problems of game theory.\nIn the context of games, the Shapley index measures the average contribution\nof a player that he/she individually generates to the group of players\nas a whole. As it is described by Tarashev et al. \\citet{Tarashev2010},\nthis can be naturally translated in the context of systemic risk analysis\nto the decomposition of various measures of system-wide risks into\nthe systemic importance of individual entities. Lee et al. \\citet{Lee2013} \n\n\n\\paragraph{Joining the two dimensions of systemic risk}\n\nFor the analysis of systemic risk, this provides a standard set-up\nas in any type of risk analysis: The level of risk can be calculated\nas the product of the probability that individual distress occurs\n$p_{i}^{t}$ (e.g., $p_{i}^{t}$ that bank $i$ fails in quarter $t$)\nmultiplied with the severity of that event for other entities through\ntheir interconnectedness $m_{ij}^{t}$ (e.g., the impact of bank $i$\non other banks $j$ in quarter $t$). The literature combining these\nissues is scarce. A starting point has been provided by Minoui et\nal. \\citet{Minoiu2015} and Rancan et al. \\citet{Rancan2015} by using\ninterconnectedness measures as predictors of crises.  Puliga et al.\n\\citet{Puliga2014} finds, in the case of building the network based\non Credit Default Swaps contracts, that systemic risk level estimation,\nfocusing on the time period before and after 2008, only increases\nif macroeconomic indicators are incorporated in the construction of\nthe network. Yet, this provides little information on the vulnerability\nof one entity and its impact on others. In this vein, Peltonen et\nal. \\citet{Peltonenetal2015a} have explicitly modeled the vulnerability\nof one bank as a function of the vulnerability of its neighbors through\ntail-dependence networks. While being a starting point, this provides\nno structured approach to accounting for both dimensions simultaneously.\n\n\n\n\\subsection{Systemic risk aggregation}\n\nIn order to estimate systemic risk, we most often rely on various\napproaches for aggregating information, not the least in the case\nof the above mentioned two dimensions of risk: multiple indicators\ninto risk levels and measures of interconnectedness into network centrality.\nFor a more formal view to aggregation, the value is usually obtained\nso that it provides a sufficient representation of the original set\nand satisfies a number of predefined requirements related to the underlying\nproblem. For this purpose, different functions, termed as aggregation\noperators or functions, can be defined that perform the task of producing\nthis representative value. In the following, the definitions will\nbe formulated for the case of aggregating values from the most common\n$[0,1]$ interval (which will also later on be the used range). An\naggregation operator on $n$ arguments is a function $f:[0,1]^{n}\\rightarrow[0,1]$,\nwhich satisfies the following properties \\citet{Beliakov2007}:\n\\begin{itemize}\n\\item boundary condition: if all the aggregated values are 1's (0's), then\nthe value of $f$ is 1 (0);\n\\item monotonicity: if $(x_{1},...,x_{n})\\leq(y_{1},...,y_{n})$, then $f(x_{1},...,x_{n})\\leq f(y_{1},...,y_{n})$\n\\end{itemize}\nAlthough these two basic properties are satisfied by a wide class\nof functions, in most of the use cases additional properties are required.\nFor instance, while the product of numbers on the $[0,1]$ interval\nis an aggregation function, it suffers from the fact that the aggregated\nvalue is smaller than the minimum of the original values. To overcome\nthis issue, a subclass of aggregation functions can be used \\citet{Grabisch2009}:\n$f$ is an averaging function if $\\min(x_{1},...,x_{n})\\leq f(x_{1},...,x_{n})\\leq\\max(x_{1},...,x_{n})$.\nThe application of averaging functions in economics, specifically\nin systemic risk and network analysis, is mainly restricted to the\nuse of a handful of specifications, such as the minimum, maximum,\nweighted mean, and the most commonly used arithmetic mean. The importance\nof the arithmetic mean stems from the fact that it is the value with\nminimum sum of squared deviations from the original aggregated numbers,\na crucial property used in many statistical methods. In different\ncontexts and applications, one may require the aggregated value to\nsatisfy a criterion different from minimizing the sum of squared deviations.\nFor instance, we can look at the overall financial state of a population\nby employing different aggregation techniques, such as minimum, maximum,\nmedian and average income. This section looks at the two dimensions\nof systemic risk from the view of the aggregation procedures involved,\nas both components of systemic risk are most often estimated using\ndifferent aggregation procedures related to indicators and network\nstructures.\n\n\n\\paragraph{Risk indicators into probability}\n\nIn the vein of the previous section on cyclical systemic risk, early-warning\nindicators are utilized in various ways to obtain an estimate of risk.\nThis is essentially nothing else than an aggregation procedure. Herein,\nwe categorize them into three classes and view them from the perspective\nof aggregation operators. The first class of models, denoted the signaling\napproach, monitors individual indicators and identifies risk when\nan indicator value exceeds a predefined threshold. Likewise, the multivariate\nsignaling approach monitors concurrently a set of indicators via a\nperformance-weighted average of several indicators, and monitors threshold\nexceedances. This involves either no aggregation at all or a simple\nweighted average. The second class of models makes use of different\nstatistical and machine learning approaches to estimate optimal weights\nfor combining indicators into a final probability. Some of these approaches\nrely on and result in a linear aggregation (i.e., weighted average)\nof the indicator values in the modeling process, with linear discriminant\nanalysis as one example. However, in most cases we obtain some non-linearity\nin the aggregations, such as even in the simple logistic regression.\nThe number of different approaches employed for aggregating indicators\ninto a probability is large, such as classification trees \\citet{Duttagupta2011},\nlogistic regression \\citet{Duca2012}, artificial neural networks\n\\citet{Sarlin2014Bio} and $k$-nearest neighbors \\citet{holopainen2015toward}.\nThe third class of estimation models relies on the combination of\nmethods from the second class through ensemble learning. Typical procedures\nto generate ensemble models rely on estimating a large number of individual\nmodels that are to be aggregated into a final one (for further details\non ensembles see \\citet{holopainen2015toward}). Model aggregation\ncould happen at two different levels: aggregating binary model output\nvia a majority vote (i.e., median) or aggregating probabilistic model\noutput through arithmetic or weighted means. To this end, one can\nconclude that each and every multivariate approach for deriving early-warning\nmodels relies on an aggregation of indicators.\n\n\n\\paragraph{Interlinkages into centrality}\n\nDrawing upon the literature on interconnectedness and networks, the\nliterature has obviously proposed a large number of measures that\naim at revealing network properties. Considering a single node in\na network, a traditional way is to look at different centrality measures\nthat can help to understand the role of a specific node in the network.\nCentrality measures play a key role in systemic risk analysis, as\nthey provide means to indicate interconnectedness or overall importance\nof a node. Beyond standard measures from graph theory, the literature\nalso consists of more customized measures, such as DebtRank \\citet{Battistonetal2012}\nas way of identifying systematically important nodes in a financial\nsystem using a feedback centrality measure. Instead of aggregating\ninterconnections among entities, one may also approach the problem\nfrom the perspective of decomposing risk contributions, such as the\nShapley index approach of Tarashev et al.\\citet{Tarashev2010}. Their\nproposal uses the Shapley index to estimate the systemic risk contribution\nof entities utilizing a characteristic function defined on all the\nsubsets of the system of entities. They propose to use various characteristic\nmeasures, mainly focusing on Value-at-Risk (VaR) and Expected Shortfall\n(ES), but also note that any risk measure can be used as the basis\nof calculating the Shapley index.\n\nThe purpose of various centrality measures is most often to describe\nthe nodes of a network from two perspectives: (\\emph{i}) how they\naffect other (e.g., neighboring) nodes directly or indirectly, and\n(\\emph{ii}) how they are affected by other nodes. These two different\nperspectives can be measured for example with the in and out-degree\n(strength) of a node. More complex measures focus on the centrality\nof the nodes from different perspectives: importance of a node for\nconnecting others (betweenness centrality) and how distant it is on\naverage from all the other nodes (closeness centrality). From a general\npoint of view, most centrality measures essentially serve as an aggregation\nmeasure: for every node, we collect specific information (e.g., in-degree\nor shortest path) with respect to a subset of the other nodes (e.g.\nneighboring nodes or the set of all nodes), and combine the information\ninto a single ``average value''. This corresponds to the general\nnotion of aggregation of summarizing a set of numerical values into\na single number that conveys some predefined characteristics of the\noriginal set of values. According to this, a centrality measure is\na function, that assigns a real value for every node of a network\ngiven the adjacency matrix, $A$. An important question is what information\n(which sub-matrix of the adjacency matrix) should be considered in\nobtaining a required characteristic of a node. For example, in-degree\nof a node utilizes only the column corresponding to the node, degree\ncentrality makes use of one row and one column (in and out-degrees\nof the node), while we potentially need the whole matrix to calculate\nthe shortest path or closeness centrality. Additionally, different\nmeasures use different functions to aggregate the individual values\ninto a final (centrality) measure, such as the sum of the values,\nthe minimum operator or a combination of these two. Finally, we can\nnotice that formally almost all the centrality measures used in practice\nsatisfy the property required from a well-defined aggregation procedure:\nmonotonicity. For instance, if we increase the weight of a link in\nthe network, the degree centrality for a node or the shortest possible\ndistance between two nodes can never decrease.\n\n Most of the measures in the literature rely only on link values\nwhen determining centrality, without considering values associated\nto the nodes themselves. The purpose in the following section is to\nfocus on the aggregation procedure in the context of network centrality\nmeasures and specify an operator that can incorporate both node and\nlink values in calculating different node and network characteristics.\n\n\n\n\n\\section{RiskRank as an aggregation operator}\n\nThis section describes our approach for concurrent measurement of\ninterconnected risk, particularly cyclical and cross-sectional systemic\nrisk. The considered system is represented as a directed graph, which\nis based on a hierarchical decomposition of the system into an interconnected\nnetwork of the involved actors. In our model, actors can refer to\nfinancial institutions, financial systems, countries, individual banks,\netc. As discussed in the previous section, there exists numerous approaches\nto analyze networks focusing on the importance or centrality of individual\nnodes and the level of interconnectedness to measure some generic\nattributes of the network. To represent and assess the two discussed\ndimensions of systemic risk, in the following we describe how to utilize\naggregation functions to combine information regarding both the likelihood\nof individual risk and the interconnectedness within the network to\nassess systemic risk. \n\nTo present our approach for measuring systemic risk, we use the following\nnotations throughout this section. The system is represented as a\nnetwork with a hierarchical structure. The highest level (level 0)\nof the hierarchy consists of a single node, $S$, representing the\nsystemic risk. The first level consists of the main components of\nthe system, $S_{1,1},S_{1,2},...,S_{1,n}$ (for example countries\nor different financial sectors in a country). The $n$ nodes form\na complete sub-network (there is a directed link from every node to\nall the other nodes), and additionally all of them are connected to\nnode $S$. The second level consists of $n$ complete and pair-wisely\ndisjoint sub-networks, each connected only to a single node from the\nfirst level in the same manner as the first level nodes are connected\nto $S$. According to this scheme, when creating a new level of the\nhierarchy, a complete sub-network is created for each node in the\nprevious level. Additionally, there is a numeric value associated\nto every node and link in the network: the likelihood of risk in the\ncorresponding component of the system as the node values and a measure\nof impact of the starting node on the end node as the link weight.\nIn the following, $S_{i}$ will denote the number of nodes on level\n$i$, $S_{i}^{j}$ denotes the number of nodes in the $i+1$th level\ncomplete sub-network corresponding to node $j$ from level $i$, i.e.\n$S_{i+1}=\\sum_{j=1}^{S_{i}}S_{i}^{j}$, $c_{k}$ and $l_{k,j}$ will\ndenote the value associated to node $k$ and the weight associated\nto the link between nodes $k$ and $j$, respectively. Finally, as\nwe are interested in the changes taking place in the system, the network\nis considered at different time-points with the same structure but\ndifferent node and link values.\n\n\n\\subsection{From aggregation operators to RiskRank}\n\nAs we discussed above, the main goal of our model is to provide a\nmeasure of systemic risk, and at the same time estimate the level\nof vulnerability in different components of the system; as the system\nas a whole itself is represented as a node, the task is to estimate\nthe value of a node in a future time-point given the previous values\nof the nodes and links. The basic idea is that the state of a component\nof a system (a node in the network), at least in a short time period,\nis determined by the previous state of the given component and the\nones which directly impact it. This problem can be reformulated as\napplying some kind of aggregation procedure to summarize the values\nin a node and its neighbors to predict a future value of a node with\nthe natural choice being an averaging function. The most straightforward\nsolution, which can be seen as a type of degree centrality, would\nbee obtained as the sum of the incoming links in the network. Although\nthis measure encompasses an important piece of information (the more\na component of a system is impacted by others, the more likely it\nis that problems can spread through its connections), it does not\nmake use of the additional information on the values associated to\nthe nodes. Using the weighted average for example would calculate\nthe impact-weighted risk measure value as a generalization of the\ndegree centrality; the original definition is obtained in case of\nall the node values equal 1. To improve this measure, one could potentially\nconsider the Ordered Weighted Average (OWA) operator introduced by\nYager \\citet{Yager1988}. This averaging function reorders the values\nto be aggregated into decreasing order and the associated weights\nare assigned to the values based on this order. OWA includes, as a\nspecial case, the $\\min,$$\\max,$weighted average and many of the\nmost used averaging functions offering more freedom in determining\nthe structure of the aggregation process. \n\nStill, there can be many applications where the features of OWA are\nnot sufficient to appropriately model the underlying phenomena. To\nexplain the most important information overlooked with the traditional\napproaches, one can consider aggregation as a decision making tool:\nevaluating a decision alternative by considering several criteria\nwith different importance. In many problems, the considered criteria\nare not independent from each other, but rather a positive/negative\nperformance on a criterion increases/decreases the importance of other\ncriteria. A typical example is the case of medical diagnosis: in order\nto assess a patients status, the presence of different symptoms is\nchecked. While the presence of different symptomes individually doest\nnot necessarily imply the high risk of a serious disease, the simultaneous\nappearance of the symptoms indicates high risk. This interrelated\nnature of decision criteria in various applications led to the utilization\nof Choquet-integral based aggregation in decision making literature\n\\citet{LabreucheGabrisch2003}. In the problem of estimating systemic\nrisk using a network approach, this issue can be relevant as a component\nof the system (the decision alternative) is not only affected by a\nrelated component (criterion) directly, but also indirectly through\nthe joint effect of two or several connected components (interrelated\ncriteria). \n\nBefore discussing the specific use of aggregation to obtain network\ncentrality measures to estimate systemic risk, we introduce the notion\nof discrete Choquet integral as a sufficiently general averaging operator\nto represent interdependencies and non-linear behavior. As we attempt\nto model the joint effect of different components beyond considering\nindividual ones (which is a special case of a joint effect of one\ncomponent), as the basis of the aggregation, an initial function is\nneeded to represent these joint effects. In the most complex case,\nevery possible subset of the considered components (the power set)\nneed to be accounted for. This representation is basedon the construct\nof a monotone or fuzzy measure \\citep{MurofushiSugeno1989}: \n\\begin{defn}\nA monotone measure $\\mu$ on the finite set $N=\\left\\{ 1,2,...,n\\right\\} $\nis a set function $\\mu:P(N)\\rightarrow\\left[0,1\\right]$ (where $P(N)$\nis the power set of $N$) satisfying the following two conditions:\\end{defn}\n\\begin{itemize}\n\\item $\\mu()=0,\\mu(N)=1$; \n\\item $A\\subseteq B$ implies that $\\mu(A)\\leq\\mu(B)$.\n\\end{itemize}\nOne of the most general formulations utilizing a fuzzy measure representation\nin the aggregation process is modeled by the discrete Choquet integral\n\\citep{Choquet1953,Marichal2002}. To formulate the definition, we\nsuppose that there are $n$ number of criteria to be considered (connected\nsystem components in our application), $c_{1},...,c_{n},$ based on\nwhich an evaluation is performed, which results in the corresponding\n$x_{1},...,x_{n}$ importance values (the impact of the components\non the considered central component). \n\\begin{defn}\nA discrete Choquet integral with respect to a monotone measure $\\mu$\nis defined as\n\\end{defn}\n", "index": 1, "text": "\n\\[\nC_{\\mu}(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}\\left(x_{(i)}-x_{(i-1)}\\right)\\mu\\left(C_{(i)}\\right)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"C_{\\mu}(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}\\left(x_{(i)}-x_{(i-1)}\\right)%&#10;\\mu\\left(C_{(i)}\\right)\" display=\"block\"><mrow><mrow><msub><mi>C</mi><mi>\u03bc</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mtext>\u2026</mtext><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>(</mo><mrow><msub><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msub><mo>-</mo><msub><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><mi>\u03bc</mi><mo>\u2062</mo><mrow><mo>(</mo><msub><mi>C</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\n\n\nThe interaction measure $I(c_{i},c_{j})$ can be defined by transforming\nthe measure for pairs into the $\\left[-1,1\\right]$, a detailed discussion\ncan be found for example in \\citet{Marichal2000}. As it was pointed\nout for example in \\citet{Keeney1976}, the interaction index and\nthe importance of a criteria can be interpreted in the context of\ngame theory using traditional utility theory, and the formulas can\nbe derived on that foundation as a form of the Shapley index. The\nformula can be derived by using the concept of the M\u00f6bius transformation\nof a fuzzy measure \\citet{Grabisch2000}. The Shapley-index is defined\nas\n", "itemtype": "equation", "pos": 34129, "prevtext": "\n\n\n\\hspace{-0.52cm}where $x_{(i)}$ denotes a permutation of the $x_{i}$\nvalues such that $x_{(1)}\\leq x_{(2)}\\leq\\ldots\\leq x_{(n)}$ and\n$C_{(i)}=\\left\\{ c_{(i)},c_{(i+1)},\\ldots,c_{(n)}\\right\\} $. \n\nAlthough it is not straightforward to see for all the cases, but all\nthe previously mentioned averaging functions, specifically the OWA\nand consequently the weighted average, the minimum and maximum, are\nall special cases of this general definition with an appropriate choice\nof fuzzy measure. As a consequence of the complexity with regard to\nthe need of estimating potentially $2^{n}$ coefficients in the fuzzy\nmeasure, the general Choquet integral has stared to gain popularity\nin different applications only in recent years \\citep{NarukawaTorra2007}.\nAs it was pointed out, the crucial aspect of the Choquet-integral\nthat makes is attractive in many applications compared to the traditional\naveraging functions is the capability of modeling interaction in the\naggregation process. In the general multi-criteria formulation of\nthe application of Choquet-integral, this can be translated to the\ninterrelation of criteria: an alternative is evaluated differently\nbased on criterion $A$ in the simultaneous presence of criterion\n$B$ than considering only $A$ without $B.$In the proposed application,\nthe risk level of an entity (country, bank) will be estimated based\non its present risk level and its connection to other entities. \n\nTo ease on the complexity of estimating the joint effect of all the\nconsidered criteria (connected components in the system) but still\nmoving beyond the simple representation of assuming independence,\none can consider only the joint effect of specific subsets and assume\nthat the others are negligible. A straightforward approach widely\ndiscussed in the literature is the case of 2-additive Choquet integral.\nIn this formulation, only the pairwise interaction between criteria\n(the joint effect of two connected components) is considered additionally\nto the individual effects. The Choquet integral in this case can be\nformulated as (see \\citet{Grabisch1997}):\n", "index": 3, "text": "\n\\[\nC_{\\mu}(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}(v\\left(c_{i}\\right)-\\frac{1}{2}\\sum I(c_{i},c_{j}))x_{i}+\\sum_{I(c_{i},c_{j})>0}I(c_{i},c_{j})\\min(x_{i},x_{j})+\\sum_{I(c_{i},c_{j})<0}\\mid I(c_{i},c_{j})\\mid\\max(x_{i},x_{j}).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"C_{\\mu}(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}(v\\left(c_{i}\\right)-\\frac{1}{%&#10;2}\\sum I(c_{i},c_{j}))x_{i}+\\sum_{I(c_{i},c_{j})&gt;0}I(c_{i},c_{j})\\min(x_{i},x_%&#10;{j})+\\sum_{I(c_{i},c_{j})&lt;0}\\mid I(c_{i},c_{j})\\mid\\max(x_{i},x_{j}).\" display=\"block\"><mrow><mrow><mrow><msub><mi>C</mi><mi>\u03bc</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mtext>\u2026</mtext><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>v</mi><mo>\u2062</mo><mrow><mo>(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>,</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>,</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mn>0</mn></mrow></munder><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>,</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>,</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&lt;</mo><mn>0</mn></mrow></munder><mrow><mrow><mo>\u2223</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo>,</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2223</mo></mrow><mo>\u2062</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\nThe Shapley index can be interpreted as the average contribution of\nthe node $i$ for all the possible subsets of the points including\n$i$, moreover it takes its value from the $[0,1]$ interval and $\\sum_{i=1}^{n}v_{i}=1$.\nIn our analyzed problem this translates to the overall impact a node\nhas on another node, directly (through a link) or indirectly (as a\nconsequence of interaction with another node). For example, in the\nsimplest case, a node is only connected to the central/analyzed node\nthrough a direct link, with not other path between the two nodes.\nIn this case, the only non-zero term in calculating the Shapley index\nwill be when $K=\\textrm{\\ensuremath{\\emptyset}}$, and the formula\nis simplified to $\\mu(x_{i})/n$. For our purpose, the important issue\nis to understand the differences between the types of interaction\nrepresented by the terms in the formula above, and how interaction\ncan be translated to the case of our network representation and systemic\nrisk analysis. In our 2-additive model, additionally to the individual\nimportance of a node connected to a central node to be assessed, we\nwant to account for the joint effect of two nodes on the central node.\nIn terms of the network, it means that we consider paths with length\n2 that end in the central node with positive joint effect, and every\nother path or other subset of edges is considered with 0 interaction\nvalue. This corresponds to the case of no interaction or $I(c_{i},c_{j})=0$.\nNegative interaction in the sense of the Choquet integral represents\nthe cases of disjunctive effects, which are not present in our model:\nan increase in one node value will affect the central node also indirectly\nthrough the path including the other node. This implies that in our\naggregation process, we consider only positive interaction values\nin the from of the product of the . Additionally, in our application\nthe minimum operator contradicts the intuitive idea of risk spreading\nthroughout the network along the paths; while a positive interaction\nindicates conjunctive behavior, using the minimum operator, an increase\nin the higher node value will not affect the joint effect of the two\nnodes. For this reason, we further modify the above formula by replacing\nthe minimum operator by the multiplication operator. \n\n\n\\subsection{RiskRank}\n\nTo see the correspondence between the proposed Choquet integral and\nthe Shapley index approach of Tarashev et al.\\citet{Tarashev2010},\nwe first note that the most general form of the Choquet integral requires\nthe fuzzy measure to be specified on all the subsets of the set of\nconsidered entities. In this sense, the fuzzy measure can be seen\nas an example of the characteristic measure referred to by Tarashev\net al.. However, in the general case the calculation of the Choquet-based\naggregation cannot be simplified into a function of the Shapley index\nof the individual entities. To be able to utilize the Shapley index,\nwe can restrict the measurable interlinkages to pairs of individual\nentities, meaning that we would not define the risk contribution of\nsubsets with cardinality higher than 2. While this is a simplification\ncompared to a full utilization of the Choquet integral and the Shapley\nindex approach, it allows for a natural representation in the form\nof a network and ensures the (2-)additivity of the proposed measure.\\footnote{As we will see in Section 4, the indirect effects (i.e. the effect\nresulting from the interconnectedness of two entities) are in general\nnegligible compared to direct effects.} Additionally, our approach allows for the decomposition of the individual\ncontribution of an entity further into direct and indirect effects.\nThis offers a deeper understanding of the risk structure within the\nsystem. At the same time, additionally to an interconnectedness measure,\nwe are also concerned with incorporating an individual risk level\nof the components under the analysis.\n\nBased on the above discussion, a function resembling the structure\nof the discrete 2-additive Choquet integral will be used to aggregate\nvalues in a network to estimate systemic risk. For risk level (node\nvalue) $x_{i}$ and interlinkage $I(c_{i},c_{j})$ between nodes $i$\nand $j$ combining the interlinkage values between node $i$ and the\ntarget node and between node $i$ and $j$, RiskRank is defined as\n", "itemtype": "equation", "pos": 34987, "prevtext": "\n\n\nThe interaction measure $I(c_{i},c_{j})$ can be defined by transforming\nthe measure for pairs into the $\\left[-1,1\\right]$, a detailed discussion\ncan be found for example in \\citet{Marichal2000}. As it was pointed\nout for example in \\citet{Keeney1976}, the interaction index and\nthe importance of a criteria can be interpreted in the context of\ngame theory using traditional utility theory, and the formulas can\nbe derived on that foundation as a form of the Shapley index. The\nformula can be derived by using the concept of the M\u00f6bius transformation\nof a fuzzy measure \\citet{Grabisch2000}. The Shapley-index is defined\nas\n", "index": 5, "text": "\n\\[\nv(x_{i})=\\sum_{K\\subset X\\setminus i}\\frac{(n-|K|-1)!|K|!}{n!}\\left(\\mu(K\\cup x_{i})-\\mu(K)\\right)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"v(x_{i})=\\sum_{K\\subset X\\setminus i}\\frac{(n-|K|-1)!|K|!}{n!}\\left(\\mu(K\\cup x%&#10;_{i})-\\mu(K)\\right)\" display=\"block\"><mrow><mrow><mi>v</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>K</mi><mo>\u2282</mo><mrow><mi>X</mi><mo>\u2216</mo><mi>i</mi></mrow></mrow></munder><mrow><mfrac><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mrow><mo stretchy=\"false\">|</mo><mi>K</mi><mo stretchy=\"false\">|</mo></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow><mo>\u2062</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mi>K</mi><mo stretchy=\"false\">|</mo></mrow><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow></mrow><mrow><mi>n</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mi>\u03bc</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>\u222a</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>\u03bc</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>K</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\nThe components of the formula express the two ways a node affects\nanother one. The RiskRank function estimates risk level for a specific\nnode. Accordingly, the notation $C_{\\mu}^{S_{t}}$should be used in\ngeneral as the RiskRank of node $S_{t}$, but in the following, we\nwill not use the indexing unless it is of importance for which node\nthe RiskRank is calculated. RiskRank is calculated and interpreted\nslightly differently for the central node $S,$and any other nodes\nin the network; in the following we discuss the differences between\nthe two cases.\n\nOne important use of the RiskRank measure in analyzing the described\nhierarchical network is to assign a value to the node on the top level,\n$S$, representing the level of systemic risk. In this case, as this\nspecific node does not have an initial value, the RiskRank formula\ncan be straightforwardly applied: the nodes that are either connected\nto $S$ or there is a path of length 2 from the node to $S$ are considered\nin the calculations. In case of nodes from the second level of the\nhierarchy, as they are only connected to a single node on the first\nlevel, there is only one interaction term, while for the nodes in\nthe first level, as they form a complete sub-network, there are $t-1$\ninteraction terms for every node where $t$ is the number of nodes\non the first level. The final value for the node $S$ provides and\nestimation of the likelihood that a system-wide risk is present in\nthe network. \n\nAs for the other nodes in the network, usually we have a node value\n(risk level) assigned before performing the aggregation process, for\nexample base don market estimations. According to this, additionally\nto their incoming links, we need to account for this observed node\nvalue in the aggregation process. As a straightforward solution, this\ncan be done by calculating the weighted average of this node value\nand the value obtained from the RiskRank function based on the connections\nof the node in the network. Alternatively, to keep a uniform formalism,\nwe can use the RiskRank equation without any additional aggregation\nby introducing a new link in the network: a self-loop for the evaluated\nnode. The link weight is determined based on the overall exposure\nof the corresponding system component to the elements of the system;\nthe measure of exposure can be different in different applications.\nThe interaction of the evaluated node and other nodes is set as 0,\nin order to prevent the additional link to contribute to indirect\neffect as part of paths of length 2 starting form a neighboring node.\nWe can write the formula as\n\n", "itemtype": "equation", "pos": 39422, "prevtext": "\nThe Shapley index can be interpreted as the average contribution of\nthe node $i$ for all the possible subsets of the points including\n$i$, moreover it takes its value from the $[0,1]$ interval and $\\sum_{i=1}^{n}v_{i}=1$.\nIn our analyzed problem this translates to the overall impact a node\nhas on another node, directly (through a link) or indirectly (as a\nconsequence of interaction with another node). For example, in the\nsimplest case, a node is only connected to the central/analyzed node\nthrough a direct link, with not other path between the two nodes.\nIn this case, the only non-zero term in calculating the Shapley index\nwill be when $K=\\textrm{\\ensuremath{\\emptyset}}$, and the formula\nis simplified to $\\mu(x_{i})/n$. For our purpose, the important issue\nis to understand the differences between the types of interaction\nrepresented by the terms in the formula above, and how interaction\ncan be translated to the case of our network representation and systemic\nrisk analysis. In our 2-additive model, additionally to the individual\nimportance of a node connected to a central node to be assessed, we\nwant to account for the joint effect of two nodes on the central node.\nIn terms of the network, it means that we consider paths with length\n2 that end in the central node with positive joint effect, and every\nother path or other subset of edges is considered with 0 interaction\nvalue. This corresponds to the case of no interaction or $I(c_{i},c_{j})=0$.\nNegative interaction in the sense of the Choquet integral represents\nthe cases of disjunctive effects, which are not present in our model:\nan increase in one node value will affect the central node also indirectly\nthrough the path including the other node. This implies that in our\naggregation process, we consider only positive interaction values\nin the from of the product of the . Additionally, in our application\nthe minimum operator contradicts the intuitive idea of risk spreading\nthroughout the network along the paths; while a positive interaction\nindicates conjunctive behavior, using the minimum operator, an increase\nin the higher node value will not affect the joint effect of the two\nnodes. For this reason, we further modify the above formula by replacing\nthe minimum operator by the multiplication operator. \n\n\n\\subsection{RiskRank}\n\nTo see the correspondence between the proposed Choquet integral and\nthe Shapley index approach of Tarashev et al.\\citet{Tarashev2010},\nwe first note that the most general form of the Choquet integral requires\nthe fuzzy measure to be specified on all the subsets of the set of\nconsidered entities. In this sense, the fuzzy measure can be seen\nas an example of the characteristic measure referred to by Tarashev\net al.. However, in the general case the calculation of the Choquet-based\naggregation cannot be simplified into a function of the Shapley index\nof the individual entities. To be able to utilize the Shapley index,\nwe can restrict the measurable interlinkages to pairs of individual\nentities, meaning that we would not define the risk contribution of\nsubsets with cardinality higher than 2. While this is a simplification\ncompared to a full utilization of the Choquet integral and the Shapley\nindex approach, it allows for a natural representation in the form\nof a network and ensures the (2-)additivity of the proposed measure.\\footnote{As we will see in Section 4, the indirect effects (i.e. the effect\nresulting from the interconnectedness of two entities) are in general\nnegligible compared to direct effects.} Additionally, our approach allows for the decomposition of the individual\ncontribution of an entity further into direct and indirect effects.\nThis offers a deeper understanding of the risk structure within the\nsystem. At the same time, additionally to an interconnectedness measure,\nwe are also concerned with incorporating an individual risk level\nof the components under the analysis.\n\nBased on the above discussion, a function resembling the structure\nof the discrete 2-additive Choquet integral will be used to aggregate\nvalues in a network to estimate systemic risk. For risk level (node\nvalue) $x_{i}$ and interlinkage $I(c_{i},c_{j})$ between nodes $i$\nand $j$ combining the interlinkage values between node $i$ and the\ntarget node and between node $i$ and $j$, RiskRank is defined as\n", "index": 7, "text": "\n\\[\nRR(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}\\underbrace{(v\\left(c_{i}\\right)-\\frac{1}{2}\\sum_{j}I(c_{i},c_{j}))x_{i}}_{\\mbox{Direct effect of component \\emph{i}}}+\\sum\\underbrace{I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{\\mbox{Indirect effect of component \\emph{i}}}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"RR(x_{1},\\text{\\dots},x_{n})=\\sum_{i=1}^{n}\\underbrace{(v\\left(c_{i}\\right)-%&#10;\\frac{1}{2}\\sum_{j}I(c_{i},c_{j}))x_{i}}_{\\mbox{Direct effect of component %&#10;\\emph{i}}}+\\sum\\underbrace{I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{\\mbox{Indirect %&#10;effect of component \\emph{i}}}.\" display=\"block\"><mrow><mrow><mrow><mi>R</mi><mo>\u2062</mo><mi>R</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mtext>\u2026</mtext><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munder><munder accentunder=\"true\"><mrow><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><mrow><mrow><mi>v</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">)</mo></mrow></mrow><mo movablelimits=\"false\">-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo movablelimits=\"false\">\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Direct effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">i</em></mtext></mrow></munder></mrow><mo>+</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><munder><munder accentunder=\"true\"><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>x</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Indirect effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">i</em></mtext></mrow></munder></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\n", "itemtype": "equation", "pos": 42280, "prevtext": "\nThe components of the formula express the two ways a node affects\nanother one. The RiskRank function estimates risk level for a specific\nnode. Accordingly, the notation $C_{\\mu}^{S_{t}}$should be used in\ngeneral as the RiskRank of node $S_{t}$, but in the following, we\nwill not use the indexing unless it is of importance for which node\nthe RiskRank is calculated. RiskRank is calculated and interpreted\nslightly differently for the central node $S,$and any other nodes\nin the network; in the following we discuss the differences between\nthe two cases.\n\nOne important use of the RiskRank measure in analyzing the described\nhierarchical network is to assign a value to the node on the top level,\n$S$, representing the level of systemic risk. In this case, as this\nspecific node does not have an initial value, the RiskRank formula\ncan be straightforwardly applied: the nodes that are either connected\nto $S$ or there is a path of length 2 from the node to $S$ are considered\nin the calculations. In case of nodes from the second level of the\nhierarchy, as they are only connected to a single node on the first\nlevel, there is only one interaction term, while for the nodes in\nthe first level, as they form a complete sub-network, there are $t-1$\ninteraction terms for every node where $t$ is the number of nodes\non the first level. The final value for the node $S$ provides and\nestimation of the likelihood that a system-wide risk is present in\nthe network. \n\nAs for the other nodes in the network, usually we have a node value\n(risk level) assigned before performing the aggregation process, for\nexample base don market estimations. According to this, additionally\nto their incoming links, we need to account for this observed node\nvalue in the aggregation process. As a straightforward solution, this\ncan be done by calculating the weighted average of this node value\nand the value obtained from the RiskRank function based on the connections\nof the node in the network. Alternatively, to keep a uniform formalism,\nwe can use the RiskRank equation without any additional aggregation\nby introducing a new link in the network: a self-loop for the evaluated\nnode. The link weight is determined based on the overall exposure\nof the corresponding system component to the elements of the system;\nthe measure of exposure can be different in different applications.\nThe interaction of the evaluated node and other nodes is set as 0,\nin order to prevent the additional link to contribute to indirect\neffect as part of paths of length 2 starting form a neighboring node.\nWe can write the formula as\n\n", "index": 9, "text": "\n\\[\nRR_{c}(x_{1},\\text{\\dots},x_{n},x_{c})=\\sum_{i=1}^{n+1}\\underbrace{(v\\left(c_{i}\\right)-\\frac{1}{2}\\sum_{j}I(c_{i},c_{j}))x_{i}}_{\\mbox{Direct effect of component \\emph{i}}}+\\sum_{i,j}\\underbrace{I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{\\mbox{Indirect effect of component \\emph{i}}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"RR_{c}(x_{1},\\text{\\dots},x_{n},x_{c})=\\sum_{i=1}^{n+1}\\underbrace{(v\\left(c_{%&#10;i}\\right)-\\frac{1}{2}\\sum_{j}I(c_{i},c_{j}))x_{i}}_{\\mbox{Direct effect of %&#10;component \\emph{i}}}+\\sum_{i,j}\\underbrace{I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{%&#10;\\mbox{Indirect effect of component \\emph{i}}}\" display=\"block\"><mrow><mrow><mi>R</mi><mo>\u2062</mo><msub><mi>R</mi><mi>c</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mtext>\u2026</mtext><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo>,</mo><msub><mi>x</mi><mi>c</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></munderover><munder><munder accentunder=\"true\"><mrow><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><mrow><mrow><mi>v</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">)</mo></mrow></mrow><mo movablelimits=\"false\">-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo movablelimits=\"false\">\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Direct effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">i</em></mtext></mrow></munder></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><munder><munder accentunder=\"true\"><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>x</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Indirect effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">i</em></mtext></mrow></munder></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 42563, "prevtext": "\n", "index": 11, "text": "\n\\[\n=\\underbrace{v(c)x_{c}}_{\\mbox{Individual effect of component \\emph{c}}}+\\sum_{i=1}^{n}\\underbrace{(v\\left(c_{i}\\right)-\\frac{1}{2}\\sum_{j\\neq i}I(c_{i},c_{j}))x_{i}}_{\\mbox{Direct effect of component \\emph{i }on c}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"=\\underbrace{v(c)x_{c}}_{\\mbox{Individual effect of component \\emph{c}}}+\\sum_%&#10;{i=1}^{n}\\underbrace{(v\\left(c_{i}\\right)-\\frac{1}{2}\\sum_{j\\neq i}I(c_{i},c_{%&#10;j}))x_{i}}_{\\mbox{Direct effect of component \\emph{i }on c}}\" display=\"block\"><mrow><mi/><mo>=</mo><mrow><munder><munder accentunder=\"true\"><mrow><mi>v</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><mi>c</mi><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><msub><mi>x</mi><mi>c</mi></msub></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Individual effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">c</em></mtext></mrow></munder><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munder><munder accentunder=\"true\"><mrow><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><mrow><mrow><mi>v</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">)</mo></mrow></mrow><mo movablelimits=\"false\">-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo movablelimits=\"false\">\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo movablelimits=\"false\">\u2260</mo><mi>i</mi></mrow></munder><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Direct effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">i </em></mtext><mtext>on c</mtext></mrow></munder></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\nwhere $c$ is the evaluated central node and $x_{c}$ is its associated\nnode value. The obtained number is an estimation of the ``true amount''\nof risk attributable to the node and it can be utilized as an estimation\nof the risk in a future time point. A further modification of the\naggregation procedure could be to specify the weight $v(c)$ as 1\ninstead of the value calculated by considering the network structure\nand the weights of the links ending at $c$. The main motivation for\nthis is that, in general, we would not like the new estimation to\nbe smaller as a consequences of a node being largely interconnected\nto other nodes of the network. For a node that has lot of connection\nto other nodes with low risk level, the original formula would overemphasize\nthe interconnectedness, and as a consequence the individual risk level,\neven from a very high starting value, could significantly decrease.\nIn this case it is possible that the above formula results in estimation\ngreater than one. For this reason, when applying this modified weight\nwhen estimating the level of risk associated to a node, the final\nvalue of RiskRank should be calculated as $\\min(RR_{c},1)$. \n\nThe proposed measure can be extended to account for more complex interaction\neffects. In the above discussion, paths with length not greater than\n2 were considered as the potential set of connections affecting the\nanalyzed node. By modifying the formula and considering paths with\nlength greater than 2, we can account for indirect effects that may\ntake into consideration the speed of the risk spreading throughout\nthe system. By accounting for indirect effects from nodes that can\nreach the central node on a path with length at most $k$, one can\nestimate the level of risk by adjusting for a longer future time period.\nIn this respect, the aggregated systemic risk obtained in the example\nevaluates a situation that will take place in a future time-point;\nif we assume that the delay of spreading risk from one node to a neighboring\nnode is one time unit, then the example estimates the development\nof the system in two time units from now. Formally, to estimate the\nstate of the system $k$ time units from now based on the network\nrepresentation at time point $t$, a different RiskRank measure can\nbe defined by considering non-zero interaction values for nodes along\na paths that have length not greater than $k$ and has the node for\nwhich we are estimating the risk level as the endpoint of the path.\nBased on each measure we can obtain an estimation of the risk values\nin different nodes of the network at any point between now and $k$\ntime units later. As in the case of paths of length 2, an even more\nimportant problem here is to define the interaction values to combine\nthe value associated to the edges on paths with different lengths.\nIn the original formulation of Choquet integral, this can be done\nby specifying a fuzzy measure $\\mu_{t}^{k}$ to be a $k$-additive\nmonotone measures described in \\citep{Grabisch1997} and moving beyond\nthe complexity of the 2-additive Choquet integral. For instance, considering\nthe product of values as the final path value for large $k$'s in\ngeneral results in low effect values meaning that after a point we\ndo not gain any new information by increasing the possible length\nof considered paths, while using the maximum of the individual values\non the path would increase the systemic risk value significantly after\nevery step. It always depends on the understanding of the underlying\ndomain to determine for how many steps it is still meaningful to forecast\nbased on the present situation. In highly fluctuating and rapidly\nchanging systems the recommended value should be lower than in rather\nstationary systems.\n\n\n\n\n\\section{RiskRank: An application to Europe}\n\nThis section illustrates the use of RiskRank to aggregate risk in\na European setting. It is worth noting that RiskRank does not require\nspecific definitions of ``links'' and ``individual risk'', but\nis rather open to any definition of the two measures in order to arrive\nat a final combined aggregate. The application shown herein aims at\na final target of a European aggregate. The application provides aggregations\nto higher level in the hierarchy (from individual countries to Europe),\nand accounts for the interconnections in measuring risk at the same\nlevel. To test for the added value of RiskRank relative to only measuring\nindividual risk, we show in the following performance comparisons\nin out-of-sample tests. We first describe the out-of-sample exercises\nand measures, and then move to the application.\n\n\n\\subsection{Evaluating model performance}\n\nTo judge the extent to which one measure outperforms another in a\nrealistic setup, we need sufficiently sofisticated and carefully designed\nexercises and metrics. The evaluation exercises need to both measure\nthe quality of signals when applied a realistic setup and measure\nperformance with measures that mimic the problem at hand. This paper\nuses recursive real-time out-of-sample tests assess performance. In\npractice, this implies the use of a recursive exercise that derives\na new model at each quarter using only information available up to\nthat point in time. By accounting for publication lags and using information\nin the manner of an increasing window, this enables in our cases testing\nwhether a measure would have provided means for predicting the global\nfinancial crisis of 2007--2008, and how measures are ranked in terms\nof performance for the task. \n\nFollowing the standard evaluation framework for early-warning models\nin \\citet{Sarlin2013b}, we aim at mimicking an ideal leading indicator\n$C_{n}(h)\\in\\left\\{ 0,1\\right\\} $ for observation $n$ (where $n=1,2,\\ldots,N$)\nand forecast horizon $h$. This implies nothing else than a binary\nindicator that is one during vulnerable periods and zero otherwise.\nFor detecting events $C_{n}$, we need a continuous measure indicating\nmembership in a vulnerable state $p_{n}\\in\\left[0,1\\right]$, which\nis then turned into a binary prediction $B_{n}$ that takes the value\none if $p_{n}$ exceeds a specified threshold $\\tau\\in\\left[0,1\\right]$\nand zero otherwise. The correspondence between the prediction $B_{n}$\nand the ideal leading indicator $C_{n}$ can then be summarized into\na so-called contingency matrix that assigns every classification into\none of four classes: true positives (TP, correct signals times of\ncrisis), true negatives (TN, correct silence in tranquil times), false\npositives (FP, false alarms) and false negatives (FN, missed crisis).\nIn terms of the elements of the contingency matrix, we can differentiate\nbetween two different types of classification errors that a decision\nmaker may be concerned with: missing crises and issuing false alarms.\nTo formulate the concepts of usefulness and relative usefulness as\nmeasures of classification performance in \\citet{Sarlin2013b}, we\ndefine type I errors as the share of missed crises to the frequency\nof crises, i.e. $T_{1}=FN/(FN+TP)$, and type II errors as the share\nof issued false alarms to the frequency of tranquil periods, i.e.\n$T_{2}=FP/(TN+FP)$. Further, we need two terms: policymakers' relative\npreference between type I and II errors ($\\mu$) to account for the\npotentially imbalanced costs of errors and the unconditional probabilities\nof crises $P_{1}$and tranquil periods $P_{2}$ to account for the\npotential difference in the size of the two classes. Based on these\nvalues, we can define the loss function as:\n", "itemtype": "equation", "pos": 42788, "prevtext": "\n\n\n", "index": 13, "text": "\n\\[\n+\\underbrace{\\sum_{i}^{n}\\sum_{j\\neq i}^{n}I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{\\mbox{Indirect effect of component \\emph{j via i }on c}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"+\\underbrace{\\sum_{i}^{n}\\sum_{j\\neq i}^{n}I(c_{i},c_{j})\\prod(x_{i},x_{j})}_{%&#10;\\mbox{Indirect effect of component \\emph{j via i }on c}}\" display=\"block\"><mrow><mo>+</mo><munder><munder accentunder=\"true\"><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi><mi>n</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo movablelimits=\"false\">\u2260</mo><mi>i</mi></mrow><mi>n</mi></munderover><mrow><mi>I</mi><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow><mo movablelimits=\"false\">\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mo movablelimits=\"false\" stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo movablelimits=\"false\">,</mo><msub><mi>x</mi><mi>j</mi></msub><mo movablelimits=\"false\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mrow><mtext>Indirect effect of component\u00a0</mtext><mtext><em xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_emph\" style=\"font-size:70%;\">j via i </em></mtext><mtext>on c</mtext></mrow></munder></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\nFurther, based on this loss function, the absolute usefulness of the\nprediction model can be specified by comparing it to using the best\nguess of a policymaker (always or never signaling depending on class\nfrequency and preferences):\n", "itemtype": "equation", "pos": 50426, "prevtext": "\nwhere $c$ is the evaluated central node and $x_{c}$ is its associated\nnode value. The obtained number is an estimation of the ``true amount''\nof risk attributable to the node and it can be utilized as an estimation\nof the risk in a future time point. A further modification of the\naggregation procedure could be to specify the weight $v(c)$ as 1\ninstead of the value calculated by considering the network structure\nand the weights of the links ending at $c$. The main motivation for\nthis is that, in general, we would not like the new estimation to\nbe smaller as a consequences of a node being largely interconnected\nto other nodes of the network. For a node that has lot of connection\nto other nodes with low risk level, the original formula would overemphasize\nthe interconnectedness, and as a consequence the individual risk level,\neven from a very high starting value, could significantly decrease.\nIn this case it is possible that the above formula results in estimation\ngreater than one. For this reason, when applying this modified weight\nwhen estimating the level of risk associated to a node, the final\nvalue of RiskRank should be calculated as $\\min(RR_{c},1)$. \n\nThe proposed measure can be extended to account for more complex interaction\neffects. In the above discussion, paths with length not greater than\n2 were considered as the potential set of connections affecting the\nanalyzed node. By modifying the formula and considering paths with\nlength greater than 2, we can account for indirect effects that may\ntake into consideration the speed of the risk spreading throughout\nthe system. By accounting for indirect effects from nodes that can\nreach the central node on a path with length at most $k$, one can\nestimate the level of risk by adjusting for a longer future time period.\nIn this respect, the aggregated systemic risk obtained in the example\nevaluates a situation that will take place in a future time-point;\nif we assume that the delay of spreading risk from one node to a neighboring\nnode is one time unit, then the example estimates the development\nof the system in two time units from now. Formally, to estimate the\nstate of the system $k$ time units from now based on the network\nrepresentation at time point $t$, a different RiskRank measure can\nbe defined by considering non-zero interaction values for nodes along\na paths that have length not greater than $k$ and has the node for\nwhich we are estimating the risk level as the endpoint of the path.\nBased on each measure we can obtain an estimation of the risk values\nin different nodes of the network at any point between now and $k$\ntime units later. As in the case of paths of length 2, an even more\nimportant problem here is to define the interaction values to combine\nthe value associated to the edges on paths with different lengths.\nIn the original formulation of Choquet integral, this can be done\nby specifying a fuzzy measure $\\mu_{t}^{k}$ to be a $k$-additive\nmonotone measures described in \\citep{Grabisch1997} and moving beyond\nthe complexity of the 2-additive Choquet integral. For instance, considering\nthe product of values as the final path value for large $k$'s in\ngeneral results in low effect values meaning that after a point we\ndo not gain any new information by increasing the possible length\nof considered paths, while using the maximum of the individual values\non the path would increase the systemic risk value significantly after\nevery step. It always depends on the understanding of the underlying\ndomain to determine for how many steps it is still meaningful to forecast\nbased on the present situation. In highly fluctuating and rapidly\nchanging systems the recommended value should be lower than in rather\nstationary systems.\n\n\n\n\n\\section{RiskRank: An application to Europe}\n\nThis section illustrates the use of RiskRank to aggregate risk in\na European setting. It is worth noting that RiskRank does not require\nspecific definitions of ``links'' and ``individual risk'', but\nis rather open to any definition of the two measures in order to arrive\nat a final combined aggregate. The application shown herein aims at\na final target of a European aggregate. The application provides aggregations\nto higher level in the hierarchy (from individual countries to Europe),\nand accounts for the interconnections in measuring risk at the same\nlevel. To test for the added value of RiskRank relative to only measuring\nindividual risk, we show in the following performance comparisons\nin out-of-sample tests. We first describe the out-of-sample exercises\nand measures, and then move to the application.\n\n\n\\subsection{Evaluating model performance}\n\nTo judge the extent to which one measure outperforms another in a\nrealistic setup, we need sufficiently sofisticated and carefully designed\nexercises and metrics. The evaluation exercises need to both measure\nthe quality of signals when applied a realistic setup and measure\nperformance with measures that mimic the problem at hand. This paper\nuses recursive real-time out-of-sample tests assess performance. In\npractice, this implies the use of a recursive exercise that derives\na new model at each quarter using only information available up to\nthat point in time. By accounting for publication lags and using information\nin the manner of an increasing window, this enables in our cases testing\nwhether a measure would have provided means for predicting the global\nfinancial crisis of 2007--2008, and how measures are ranked in terms\nof performance for the task. \n\nFollowing the standard evaluation framework for early-warning models\nin \\citet{Sarlin2013b}, we aim at mimicking an ideal leading indicator\n$C_{n}(h)\\in\\left\\{ 0,1\\right\\} $ for observation $n$ (where $n=1,2,\\ldots,N$)\nand forecast horizon $h$. This implies nothing else than a binary\nindicator that is one during vulnerable periods and zero otherwise.\nFor detecting events $C_{n}$, we need a continuous measure indicating\nmembership in a vulnerable state $p_{n}\\in\\left[0,1\\right]$, which\nis then turned into a binary prediction $B_{n}$ that takes the value\none if $p_{n}$ exceeds a specified threshold $\\tau\\in\\left[0,1\\right]$\nand zero otherwise. The correspondence between the prediction $B_{n}$\nand the ideal leading indicator $C_{n}$ can then be summarized into\na so-called contingency matrix that assigns every classification into\none of four classes: true positives (TP, correct signals times of\ncrisis), true negatives (TN, correct silence in tranquil times), false\npositives (FP, false alarms) and false negatives (FN, missed crisis).\nIn terms of the elements of the contingency matrix, we can differentiate\nbetween two different types of classification errors that a decision\nmaker may be concerned with: missing crises and issuing false alarms.\nTo formulate the concepts of usefulness and relative usefulness as\nmeasures of classification performance in \\citet{Sarlin2013b}, we\ndefine type I errors as the share of missed crises to the frequency\nof crises, i.e. $T_{1}=FN/(FN+TP)$, and type II errors as the share\nof issued false alarms to the frequency of tranquil periods, i.e.\n$T_{2}=FP/(TN+FP)$. Further, we need two terms: policymakers' relative\npreference between type I and II errors ($\\mu$) to account for the\npotentially imbalanced costs of errors and the unconditional probabilities\nof crises $P_{1}$and tranquil periods $P_{2}$ to account for the\npotential difference in the size of the two classes. Based on these\nvalues, we can define the loss function as:\n", "index": 15, "text": "\n\\[\nL(\\mu)=\\mu T_{1}P_{1}+(1-\\mu)T_{2}P_{2}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"L(\\mu)=\\mu T_{1}P_{1}+(1-\\mu)T_{2}P_{2}.\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>\u03bc</mi><mo>\u2062</mo><msub><mi>T</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>P</mi><mn>1</mn></msub></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bc</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>T</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>P</mi><mn>2</mn></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06204.tex", "nexttext": "\nFinally, we compute relative usefulness, $U_{r}$ to compare the absolute\nusefulness of the model to the absolute usefulness of a model with\nperfect performance ($L(\\mu)=0$). Additionally, to assess predictive\nperformance, we also calculate standard measures from the classification\nand machine learning literature, in particular the area under the\nreceiver operating characteristic ($ROC$) curve ($AUC$). These techniques\nprovide both measures tailored to the preferences of a policymaker\nas well as more general-purpose measures to assess model performance.\nOther performance measures to be used in assessing the model include:\n(i) precision of signals $TP/(FP+TP)$, i.e. the share of correct\nsignals to the frequency of signals; (ii) precision of tranquil predictions\n$TN/(FN+TN)$, i.e. the share of correct silence in tranquil times\nto the frequency of predicting tranquil time; (iii) recall of signals\n$TP/(FN+TP)$, i.e. the share of correct signals to the frequency\nof crisis times; (iv) recall of tranquil predictions $TN/(FP+TN)$,\ni.e. the share of correct silence in tranquil times to the frequency\nof tranquil times; (v) accuracy of the model $TP+TN/(FN+FP+TN+TP)$,\ni.e. the share of correct classifications.\n\n\n\\subsection{RiskRank for Europe and its countries}\n\nThis section measures systemic risk for individual European countries\nas well as aggregates to a pan-European level. In this application,\nwe focus on individual risk as measured with country-level macro-financial\nimbalance indicators and real linkages as measured with real cross-border\nlinkages. After describing the underlying data and models, we herein\nboth evaluate model performance and exemplify model output with and\nwithout RiskRank. \n\nTo be able to compute RiskRank, we need to build a network of countries\nthat includes both node and link values. We hence specify risk levels\n(probabilities $x_{c}$) for countries, and also measures of interconnectedness\nbetween all pairs of nodes (interlinkages $I(c_{i},c_{j})$). The\napproach for computing individual risk for each economy follows \\citet{holopainen2015toward}.\nTo derive individual risk with early-warning models, we need crisis\nevents and vulnerability indicators. The crisis events are based upon\nthe IMF database by \\citet{LaeevenValencia2008}. The vulnerability\nindicators used include most common measures of widespread imbalances,\nsuch as excessive credit growth, excessive increases in stock and\nhouse prices, GDP growth, loans to deposits and debt service ratio,\nas well as more structural indicators, such as government debt, current\naccount deficits and inflation. We use a standard logistic regression\nwith 14 macro-financial indicators for countries and a forecast horizon\nof 5--12 quarters prior to crisis events, as is common in the literature.\nThe network dimension is measured with BIS International Banking Statistics\nin terms of foreign claims of banking sectors on other economies.\nFrom the perspective of systemic banking crises, this provides ample\nmeans to capture the spread of vulnerabilities across borders through\nreal linkages. Yet, these are only one means to measure both the cyclical\nand cross-sectional dimensions of systemic risk and hence obviously\nalso come with a number of deficiencies. It is hence worth noting\nthat the models and data are given and the key focus is hence on relative\nperformance of RiskRank versus standalone early-warning models.\n\nTo start with, we first estimate individual risk and RiskRank for\neach economy separately. In the case of RiskRank, this involves aggregating\nat the same level of hierarchy by also accounting for interconnectedness,\nwhereafter we evaluate the performance of the individual risk model\nand RiskRank vis-\u00e1-vis the crisis event database. This provides the\nresults in Table \\ref{tab:Country_Results}. As has been pointed out\nin several works (e.g., \\citet{Sarlin2013b,Betzetal2014}), a feature\nof samples with imbalanced classes is that one needs to be more concerned\nof missing crises for models to be Useful. Given preferences $\\mu$,\na pairwise comparison shows that the performance of RiskRank is never\nworse than the traditional individual risk model and it is better\nfor preferences $\\mu\\in\\left[0.3,1\\right]$. Figure \\ref{fig:Country_examples}\nprovides an example of model output for Germany with the individual\nmodel and RiskRank. The risk level is decomposed into individual risk,\ndirect and indirect effects of other countries in case of individual\ncountries. As we can observe from the figure, indirect effects are\nmost often negligible compared to the other components, and while\nindividual risk usually dominates the aggregated value, especially\nin crisis periods the direct impact from connected countries can significantly\nincrease the risk level. More specifically, the timing of crisis signals\ncome at a much earlier stage when accounting for direct and indirect\neffects. This represents the fact that domestic imbalances were fairly\nmodest, while Germany was highly interlinked to countries with large\nvulnerabilities. As an early indication of an impending crisis, the\nfigure illustrates the importance to incorporate vulnerabilities descending\nfrom ``neighboring'' countries, in addition to those building up\nin the domestic economy. Likewise, one can observe that the latest\nincreases in risk are on the other hand related more to domestic imbalances,\nwhich again points to the potential need for and type of domestic\npolicy actions.\n\n\n\n\\begin{table}[H]\n\\protect\\caption{\\label{tab:Country_Results}Signaling performance of individual models\nand RiskRank for countries with forecast horizon 5--12 quarters prior\nto crisis events.}\n\n\n\\centering{}\n\\begin{tabular}{ccccc}\n & \\multicolumn{2}{c}{{\\small{}Individual}} & \\multicolumn{2}{c}{{\\small{}RiskRank}}\\tabularnewline\n{\\small{}$\\mu$} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC}\\tabularnewline\n\\hline \n\\hline \n{\\small{}0.0} & {\\small{}0 \\%} & {\\small{}0.915} & {\\small{}0 \\%} & {\\small{}0.921 }\\tabularnewline\n{\\small{}0.1} & {\\small{}-6 \\%} & {\\small{}0.915} & {\\small{}-6 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.2} & {\\small{}-3 \\%} & {\\small{}0.915} & {\\small{}-3 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.3} & {\\small{}6 \\%} & {\\small{}0.915} & {\\small{}7 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.4} & {\\small{}12 \\%} & {\\small{}0.915} & {\\small{}18 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.5} & {\\small{}15 \\%} & {\\small{}0.915} & {\\small{}38 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.6} & {\\small{}25 \\%} & {\\small{}0.915} & {\\small{}39 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.7} & {\\small{}44 \\%} & {\\small{}0.915} & {\\small{}54 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.8} & {\\small{}60 \\%} & {\\small{}0.915} & {\\small{}66 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}0.9} & {\\small{}73 \\%} & {\\small{}0.915} & {\\small{}74 \\%} & {\\small{}0.921}\\tabularnewline\n{\\small{}1.0} & {\\small{}0 \\%} & {\\small{}0.915} & {\\small{}0 \\%} & {\\small{}0.921}\\tabularnewline\n\\end{tabular}\n\\end{table}\n\n\n\\begin{figure}[H]\n\\begin{centering}\n\\includegraphics[scale=0.65]{FigureTable/germany_ex2}\\global\\long\\def\\newmacroname{}\n\n\\par\\end{centering}\n\n\\protect\\caption{\\label{fig:Country_examples}Examples of individual risk and RiskRank\nfor Germany and Europe}\n\\end{figure}\n\n\nRiskRank also allows to measure vulnerability at a European level\nby aggregating the country-specific measures. Figure \\ref{fig:RiskRank-for-Europe}\nprovides an example of model output for Europe with the individual\nmodel and RiskRank. In the figure, the European risk level is decomposed\ninto direct and indirect impact of countries (red and blue stacks),\nwhereas the yellow line shows the weighted average of the individual\nrisk of countries and the black line the proportion of countries being\nin a pre-crisis state in a given quarter. Thus, the figure particularly\ndepicts the increase in RiskRank when connected countries exhibit\nlarger individual Risk (blue and red stacks vis-\u00e1-vis yellow line).\nLikewise, the figure also shows that unconditional probabilities (black\nline) do exceed a simple weighted average of individual probabilities,\nwhich indeed also points to the need for an aggregation function accounting\nfor other factors.\n\n\\begin{figure}[H]\n\\centering{}\\includegraphics[scale=0.55]{FigureTable/europe_ex2}\\protect\\caption{\\label{fig:RiskRank-for-Europe}RiskRank for Europe with the yellow\nline representing the weighted average of the individual risk of countries,\nwhile the black line depicts the proportion of countries being in\na pre-crisis state in a given quarter}\n\\end{figure}\n\n\n\n\\subsection{Robustness of RiskRank}\n\nFor a more detailed comparison of predictive performance, Tables \\ref{tab:Performance_individual}\nand\\ref{tab:Performance-aggregated} lists a range of previously introduced\nperformance measures for the two above models. Further, we test the\nrobustness of the above exercise when varying model specification.\nTo check the sensitivity of the aggregation procedure with respect\nto the forecast horizon, we perform the analysis with two other scenarios:\n(\\emph{i}) 5--8 and (\\emph{ii}) 5--16 quarters prior to crisis events.\nAs can be seen in Tables \\ref{tab:Country_Results-1} and \\ref{tab:Country_Results-2},\nRiskRank still results in higher AUC values and relative usefulness\ncompared to the individual risk model. Naturally, the wider the forecast\nhorizon is, the worse the predictions are, but the aggregated risk\nlevel used in RiskRank provides a more accurate estimation with clear\nimprovements for higher values of the preference parameter $\\mu$\n(above $0.3$).\n\n\\begin{table}[H]\n\\protect\\caption{\\label{tab:Performance_individual}Performance measures based on individual\nprobabilities}\n\n\n\\centering{}{\\small{}}\n\\begin{tabular}{cccccccccc}\n{\\small{}$\\mu$} & {\\small{}TP} & {\\small{}TN} & {\\small{}FP} & {\\small{}FN} & {\\small{}Precision (C)} & {\\small{}Recall (C)} & {\\small{}Precision (T)} & {\\small{}Recall (T)} & {\\small{}Accuracy}\\tabularnewline\n\\hline \n\\hline \n{\\small{}0.0} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.1} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.2} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.3} & {\\small{}30} & {\\small{}1138} & {\\small{}9} & {\\small{}109} & {\\small{}76.92} & {\\small{}21.58} & {\\small{}91.26} & {\\small{}99.22} & {\\small{}90.82}\\tabularnewline\n\\hline \n{\\small{}0.4} & {\\small{}30} & {\\small{}1138} & {\\small{}9} & {\\small{}109} & {\\small{}76.92} & {\\small{}21.58} & {\\small{}91.26} & {\\small{}99.22} & {\\small{}90.82}\\tabularnewline\n\\hline \n{\\small{}0.5} & {\\small{}30} & {\\small{}1138} & {\\small{}9} & {\\small{}109} & {\\small{}76.92} & {\\small{}21.58} & {\\small{}91.26} & {\\small{}99.22} & {\\small{}90.82}\\tabularnewline\n\\hline \n{\\small{}0.6} & {\\small{}98} & {\\small{}1052} & {\\small{}95} & {\\small{}41} & {\\small{}50.78} & {\\small{}70.50} & {\\small{}96.25} & {\\small{}91.72} & {\\small{}89.42}\\tabularnewline\n\\hline \n{\\small{}0.7} & {\\small{}113} & {\\small{}1028} & {\\small{}119} & {\\small{}26} & {\\small{}48.71} & {\\small{}81.29} & {\\small{}97.53} & {\\small{}89.63} & {\\small{}88.72}\\tabularnewline\n\\hline \n{\\small{}0.8} & {\\small{}116} & {\\small{}1018} & {\\small{}129} & {\\small{}23} & {\\small{}47.35} & {\\small{}83.45} & {\\small{}97.79} & {\\small{}88.75} & {\\small{}88.18}\\tabularnewline\n\\hline \n{\\small{}0.9} & {\\small{}121} & {\\small{}997} & {\\small{}150} & {\\small{}18} & {\\small{}44.65} & {\\small{}87.05} & {\\small{}98.23} & {\\small{}86.92} & {\\small{}86.94}\\tabularnewline\n\\hline \n{\\small{}1.0} & {\\small{}139} & {\\small{}0} & {\\small{}1147} & {\\small{}0} & {\\small{}10.81} & {\\small{}1.00} & {\\small{}-} & {\\small{}0.00} & {\\small{}10.81}\\tabularnewline\n\\end{tabular}{\\small \\par}\n\\end{table}\n\n\n\\begin{table}[H]\n\\protect\\caption{\\label{tab:Performance-aggregated}Performance measures based on aggregated\nprobabilities}\n\n\n\\centering{}{\\small{}}\n\\begin{tabular}{cccccccccc}\n{\\small{}$\\mu$} & {\\small{}TP} & {\\small{}TN} & {\\small{}FP} & {\\small{}FN} & {\\small{}Precision (EW)} & {\\small{}Recall (EW)} & {\\small{}Precision (T)} & {\\small{}Recall (T)} & {\\small{}Accuracy}\\tabularnewline\n\\hline \n\\hline \n{\\small{}0.0} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.1} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.2} & {\\small{}0} & {\\small{}1146} & {\\small{}1} & {\\small{}139} & {\\small{}0.00} & {\\small{}0.00} & {\\small{}89.18} & {\\small{}99.91} & {\\small{}89.11}\\tabularnewline\n\\hline \n{\\small{}0.3} & {\\small{}30} & {\\small{}1138} & {\\small{}9} & {\\small{}109} & {\\small{}76.92} & {\\small{}21.58} & {\\small{}91.26} & {\\small{}99.22} & {\\small{}90.82}\\tabularnewline\n\\hline \n{\\small{}0.4} & {\\small{}30} & {\\small{}1138} & {\\small{}9} & {\\small{}109} & {\\small{}76.92} & {\\small{}21.58} & {\\small{}91.26} & {\\small{}99.22} & {\\small{}90.82}\\tabularnewline\n\\hline \n{\\small{}0.5} & {\\small{}45} & {\\small{}1127} & {\\small{}20} & {\\small{}94} & {\\small{}69.23} & {\\small{}32.37} & {\\small{}92.30} & {\\small{}98.96} & {\\small{}91.14}\\tabularnewline\n\\hline \n{\\small{}0.6} & {\\small{}114} & {\\small{}1055} & {\\small{}92} & {\\small{}25} & {\\small{}55.34} & {\\small{}82.01} & {\\small{}97.69} & {\\small{}91.98} & {\\small{}90.90}\\tabularnewline\n\\hline \n{\\small{}0.7} & {\\small{}114} & {\\small{}1055} & {\\small{}92} & {\\small{}25} & {\\small{}55.34} & {\\small{}82.01} & {\\small{}97.69} & {\\small{}91.98} & {\\small{}90.90}\\tabularnewline\n\\hline \n{\\small{}0.8} & {\\small{}114} & {\\small{}1055} & {\\small{}92} & {\\small{}25} & {\\small{}55.34} & {\\small{}82.01} & {\\small{}97.69} & {\\small{}91.98} & {\\small{}90.90}\\tabularnewline\n\\hline \n{\\small{}0.9} & {\\small{}122} & {\\small{}998} & {\\small{}149} & {\\small{}17} & {\\small{}45.02} & {\\small{}87.77} & {\\small{}98.33} & {\\small{}87.01} & {\\small{}87.09}\\tabularnewline\n\\hline \n{\\small{}1.0} & {\\small{}139} & {\\small{}0} & {\\small{}1147} & {\\small{}0} & {\\small{}10.81} & {\\small{}1.00} & {\\small{}-} & {\\small{}0.00} & {\\small{}10.81}\\tabularnewline\n\\end{tabular}{\\small \\par}\n\\end{table}\n\n\n\\begin{table}[H]\n\\protect\\caption{\\label{tab:Country_Results-1}Signaling performance of individual\nmodels and RiskRank for countries with forecast horizon 5--8 quarters\nprior to crisis events.}\n\n\n\\centering{}\n\\begin{tabular}{ccccc}\n & \\multicolumn{2}{c}{{\\small{}Individual}} & \\multicolumn{2}{c}{{\\small{}RiskRank}}\\tabularnewline\n{\\small{}$\\mu$} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC}\\tabularnewline\n\\hline \n\\hline \n{\\small{}0.0} & {\\small{}0 \\%} & {\\small{}0.927} & {\\small{}0 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.1} & {\\small{}-11 \\%} & {\\small{}0.927} & {\\small{}-11 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.2} & {\\small{}-5 \\%} & {\\small{}0.927} & {\\small{}-5 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.3} & {\\small{}-3 \\%} & {\\small{}0.927} & {\\small{}-3 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.4} & {\\small{}-2 \\%} & {\\small{}0.927} & {\\small{}1 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.5} & {\\small{}4 \\%} & {\\small{}0.927} & {\\small{}7 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.6} & {\\small{}11 \\%} & {\\small{}0.927} & {\\small{}16 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.7} & {\\small{}22 \\%} & {\\small{}0.927} & {\\small{}34 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.8} & {\\small{}47 \\%} & {\\small{}0.927} & {\\small{}55 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}0.9} & {\\small{}70 \\%} & {\\small{}0.927} & {\\small{}76 \\%} & {\\small{}0.935}\\tabularnewline\n{\\small{}1.0} & {\\small{}0 \\%} & {\\small{}0.927} & {\\small{}0 \\%} & {\\small{}0.935}\\tabularnewline\n\\end{tabular}\n\\end{table}\n\n\n\\begin{table}[H]\n\\protect\\caption{\\label{tab:Country_Results-2}Signaling performance of individual\nmodels and RiskRank for countries with forecast horizon 5--16 quarters\nprior to crisis events.}\n\n\n\\centering{}\n\\begin{tabular}{ccccc}\n & \\multicolumn{2}{c}{{\\small{}Individual}} & \\multicolumn{2}{c}{{\\small{}RiskRank}}\\tabularnewline\n{\\small{}$\\mu$} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC} & \\textbf{\\small{}$U_{r}(\\mu)$} & {\\small{}AUC}\\tabularnewline\n\\hline \n\\hline \n{\\small{}0.0} & {\\small{}0 \\%} & {\\small{}0.861} & {\\small{}0 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.1} & {\\small{}-5 \\%} & {\\small{}0.861} & {\\small{}-5 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.2} & {\\small{}-2 \\%} & {\\small{}0.861} & {\\small{}-2 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.3} & {\\small{}5 \\%} & {\\small{}0.861} & {\\small{}5 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.4} & {\\small{}9 \\%} & {\\small{}0.861} & {\\small{}9 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.5} & {\\small{}11 \\%} & {\\small{}0.861} & {\\small{}15 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.6} & {\\small{}25 \\%} & {\\small{}0.861} & {\\small{}30 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.7} & {\\small{}38 \\%} & {\\small{}0.861} & {\\small{}41 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.8} & {\\small{}50 \\%} & {\\small{}0.861} & {\\small{}50 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}0.9} & {\\small{}48 \\%} & {\\small{}0.861} & {\\small{}46 \\%} & {\\small{}0.866}\\tabularnewline\n{\\small{}1.0} & {\\small{}0 \\%} & {\\small{}0.861} & {\\small{}0 \\%} & {\\small{}0.866}\\tabularnewline\n\\end{tabular}\n\\end{table}\n\n\n\n\\section{Conclusion}\n\nEstimating systemic risk is considered nowadays as one of the most\nprominent tasks as a consequence of the recent financial crisis. In\nthis paper we introduced a new approach for assessing systemic risk\nmotivated by advances in the domains of aggregation operators and\nnetwork analysis. In the proposed approach, we combine risk indicators\nof entities in the financial markets, consequently modelling cyclical\nand cross-sectional systemic risk using our approach. As the result\nof an aggregation process, we obtain not only the aggregated risk\nlevels of individual entities in a system and also the system as a\nwhole, but the risk is decomposed into individual, direct and indirect\ncomponents. While the proposed approach is motivated by the theory\nof aggregation operators and network analysis, it is closely related\nto, and from some perspectives expands upon the Shapley-index approach\nfrequently used in economics, specifically in systemic risk analysis. \n\nThe approach is exemplified using the case of estimating systemic\nrisk in a European setting. In the example, we provide an estimation\nof systemic risk from country-level risk and cross-border linkages.\nThe out-of-sample performance of the approach in this case illustrates\nhow aggregating risk levels in the network representation can improve\non a traditional estimation method. This paper is to be extended with\nalso bank-level results, where similar aggregation procedures allow\nestimating upward in the hierarchy from bank-level individual risk\nand linkages. \\newpage{}\n\n\n\\section*{\\textmd{\\small{}\\renewcommand\\refname{References}\\bibliographystyle{plainnat}\n\\bibliography{References/references}\n}}\n\n", "itemtype": "equation", "pos": 50707, "prevtext": "\nFurther, based on this loss function, the absolute usefulness of the\nprediction model can be specified by comparing it to using the best\nguess of a policymaker (always or never signaling depending on class\nfrequency and preferences):\n", "index": 17, "text": "\n\\[\nU_{a}(\\mu)=\\min(\\mu P_{1},(1-\\mu)P_{2})-L(\\mu).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"U_{a}(\\mu)=\\min(\\mu P_{1},(1-\\mu)P_{2})-L(\\mu).\" display=\"block\"><mrow><mrow><mrow><msub><mi>U</mi><mi>a</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bc</mi><mo>\u2062</mo><msub><mi>P</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bc</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>P</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]