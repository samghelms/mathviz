[{"file": "1601.06497.tex", "nexttext": ">$, which has five template arguments: (1)~$<\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\\title{Quegel: A General-Purpose Query-Centric Framework for Querying Big Graphs}\n\n\\author{\n{Da Yan$^{*1}$,\\ \\ \\ \\ James Cheng$^{*2}$,\\ \\ \\ \\ M.\\ Tamer \\\"{O}zsu$^{\\dag3}$,\\ \\ \\ \\ Fan Yang$^{*4}$,}\\\\\n{\\ \\ \\ \\ Yi Lu$^{*5}$,\\ \\ \\ \\ \\ \\ John C.\\ S.\\ Lui$^{*6}$,\\ \\ \\ \\ Qizhen Zhang$^{*7}$,\\ \\ \\ \\ \\ Wilfred Ng$^{+8}$}\n\\vspace{1.6mm}\\\\\n\\fontsize{10}{10}\\selectfont\\itshape\\rmfamily $^*$Department of Computer Science and Engineering, The Chinese University of Hong Kong\\\\\n\\fontsize{9}{9}\\selectfont\\ttfamily\\upshape \\{$^1$yanda, $^2$jcheng, $^4$fyang, $^5$ylu, $^6$cslui, $^7$qzzhang\\}@cse.cuhk.edu.hk\\\\\n\\fontsize{10}{10}\\selectfont\\itshape\\rmfamily $^\\dag$David R.\\ Cheriton School of Computer Science, University of Waterloo\\\\\n\\fontsize{9}{9}\\selectfont\\ttfamily\\upshape $^3$tozsu@uwaterloo.ca\\\\\n\\fontsize{10}{10}\\selectfont\\itshape\\rmfamily $^+$Department of Computer Science and Engineering, The Hong Kong University of Science and Technology\\\\\n\\fontsize{9}{9}\\selectfont\\ttfamily\\upshape $^8$wilfred@cse.ust.hk\n}\n\n\\maketitle\n\n\\begin{abstract}\n\n\n\nPioneered by Google's Pregel, many distributed systems have been developed for large-scale graph analytics. These systems expose the user-friendly ``think like a vertex'' programming interface to users, and exhibit good horizontal scalability. However, these systems are designed for tasks where the majority of graph vertices participate in computation, but are not suitable for processing light-workload graph queries where only a small fraction of vertices need to be accessed. The programming paradigm adopted by these systems can seriously under-utilize the resources in a cluster for graph query processing. In this work, we develop a new open-source system, called {\\bf Quegel}, for querying big graphs, which treats queries as first-class citizens in the design of its computing model. Users only need to specify the Pregel-like algorithm for a generic query, and Quegel processes light-workload graph queries on demand using a novel superstep-sharing execution model to effectively utilize the cluster resources. Quegel further provides a convenient interface for constructing graph indexes, which significantly improve query performance but are not supported by existing graph-parallel systems. Our experiments verified that Quegel is highly efficient in answering various types of graph queries and is up to orders of magnitude faster than existing systems.\n\n\\end{abstract}\n\n\\section{Introduction}  \\label{sec:intro}\n\n\n\n\n\n\n\nBig graphs are common in real-life applications today, for example, online social networks and mobile communication networks have billions of users, and web graphs and Semantic webs can be even bigger. Processing such big graphs typically require a special infrastructure, and the most popular ones are Pregel~\\cite{pregel} and Pregel-like systems~\\cite{giraph,powergraph,graphx,graphlab,gps,pregelplus}. In a Pregel-like system, a programmer \\emph{thinks like a vertex} and only needs to specify the behavior of one vertex, and the system automatically schedules the execution of the specified computing logic on all vertices. The system also handles fault tolerance and scales out without extra effort from programmers.\n\n\n\nExisting Pregel-like systems, however, are designed for \\emph{heavy-weight} graph computation (i.e., analytic workloads), where the majority part of a graph or the entire graph is accessed. For example, Pregel's PageRank algorithm~\\cite{pregel} accesses the whole graph in each iteration. However, many real-world applications involve various types of graph querying, whose computation is \\emph{light-weight} in the sense that only a small portion of the input graph needs to be accessed. For example, in our collaboration with researchers from one of the world's largest online shopping platforms, we have seen huge demands for querying different aspects of big graphs for all sorts of analysis to boost sales and improve customer experience. In particular, they need to frequently examine the \\emph{shortest-path distance} between some users in a large network extracted from their online shopping data. While Pregel's \\emph{single-source shortest-path} (\\emph{SSSP}) algorithm~\\cite{pregel} can be applied here, much of the computation will be wasted because only those paths between the queried users are of interest. Instead, it is much more efficient to apply \\emph{point-to-point shortest-path} (\\emph{PPSP}) queries, which only traverse a small part of the input graph. We also worked with a large telecom operator, and our experience is that graph queries (with \\emph{light-weight} workloads) are integral parts of analyzing massive mobile phone and SMS networks.\n\n\n\n\n\n\n\n\n\n\n\n\nThe importance of querying big graphs has also been recognized in some recent work~\\cite{tutorial}, where two kinds of systems are identified: (1)~systems for offline graph analytics (such as Pregel and GraphLab) and (2)~systems for online graph querying, including Horton~\\cite{SarwatEHM13pvldb}, G-SPARQL~\\cite{SakrEH12pvldb} and Trinity~\\cite{trinity}. However, Horton and G-SPARQL are tailor-made only for specific types of queries. Trinity supports graph query processing, but compared with Pregel, its main advantage is that it keeps the input graph in main memories so that the graph does not have to be re-loaded for each query. The Trinity paper~\\cite{trinity} also argues that indexing is too expensive for big graphs and thus Trinity does not support indexing. In the VLDB 2015 conference, there is also a workshop ``Big-O(Q): Big Graphs Online Querying'', but the works presented there only study algorithms for specific types of queries. So far, there lacks a \\emph{general-purpose framework} that allows users to easily design distributed algorithms for answering various types of queries on big graphs.\n\n\nOne may, of course, use existing vertex-centric systems to process queries on big graphs, but these systems are not suitable for processing \\emph{light-weight} graph queries. To illustrate, consider processing PPSP queries on a 1.96-billion-edge Twitter graph used in our experiments. To answer one query $(s, t)$ by bidirectional breadth-first search (BiBFS) in our cluster, Giraph takes over 100 seconds, which is intolerable for a data analyst who wants to examine the distance between users in an online social network with short response time. To process queries on demand using an existing vertex-centric system, a user has the following two options: (1)~to process queries one after another, which leads to a low throughput since the communication workload of each query is usually too light to fully utilize the network bandwidth and many synchronization barriers are incurred; or (2)~to write a program to explicitly process a batch of queries in parallel, which is not easy for users and may not fully utilize the network bandwidth towards the end of the processing, since most queries may have finished their processing and only a small number of queries are still being processed. It is also not clear how to use graph indexing for query processing in existing vertex-centric systems.\n\n\n\nTo address the limitations of existing systems in querying big graphs, we developed a distributed system, called {\\bf Quegel}, for large-scale graph querying. We implemented the {\\em Hub$^2$-Labeling} approach~\\cite{JinRYW13corr} in Quegel, and it can achieve interactive speeds for PPSP querying on the same Twitter graph mentioned above. Quegel treats queries as first-class citizens: users only need to write a Pregel-like algorithm for processing a generic query, and the system automatically schedules the processing of multiple incoming queries on demand. As a result, Quegel has a wide application scope, since any query that can be processed by a Pregel-style vertex-centric algorithm can be answered by Quegel, and much more efficiently. Under this \\emph{query-centric} design, Quegel adopts a novel \\emph{superstep-sharing execution model} to effectively utilize the cluster resources, and an efficient mechanism for managing vertex states that significantly reduces memory consumption. Quegel further provides a convenient interface for constructing indexes to improve query performance. To our knowledge, \\emph{Quegel is the first general-purpose programming framework for querying big graphs at interactive speeds on a distributed cluster}. We have successfully applied Quegel to process five important types of graph queries (to be presented in Section~\\ref{sec:app}), and Quegel achieves performance up to orders of magnitude faster than existing systems.\n\nThe rest of this paper is organized as follows. We review related work in Section~\\ref{sec:related}. In Section~\\ref{sec:design}, we highlight important concepts in the design of Quegel, and key implementation issues. We introduce the programming model of Quegel in Section~\\ref{sec:interface}, and describe some graph querying problems as well as their Quegel algorithms in Section~\\ref{sec:app}. Finally, we evaluate the performance of Quegel in Section~\\ref{sec:results} and conclude the paper in Section~\\ref{sec:conclude}.\n\n\\section{Related Work}\\label{sec:related}\nWe first review existing vertex-centric graph-parallel systems. We consider an input graph $G=(V, E)$ stored on \\emph{Hadoop distributed file system} (\\emph{HDFS}), where each vertex $v\\in V$ is associated with its adjacency list (i.e., $v$'s neighbors). If $G$ is undirected, we denote $v$'s neighbors by $\\Gamma(v)$, while if $G$ is directed, we denote $v$'s in-neighbors and out-neighbors by $\\Gamma_{in}(v)$ and $\\Gamma_{out}(v)$, respectively. Each vertex $v$ also has a value $a(v)$ storing $v$'s vertex value. Graph computation is run on a cluster of workers, where each worker is a computing thread/process, and a machine may run multiple workers.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Pregel~\\cite{pregel}.} Pregel adopts the \\emph{bulk synchronous parallel} (\\emph{BSP}) model. It distributes vertices to workers in a cluster, where each vertex is associated with its adjacency list. A Pregel program computes in iterations, where each iteration is called a superstep. Pregel requires users to specify a \\emph{user-defined function} (\\emph{UDF}) {\\em compute}(.). In each superstep, each active vertex $v$ calls {\\em compute}({\\em msgs}), where {\\em msgs} is the set of incoming messages sent from other vertices in the previous superstep. In $v$.{\\em compute}({\\em msgs}), $v$ may process {\\em msgs} and update $a(v)$, send new messages to other vertices, and vote to halt (i.e., deactivate itself). A halted vertex is reactivated if it receives a message in a subsequent superstep. The program terminates when all vertices are deactivated and no new message is generated. Finally, the results (e.g., $a(v)$) are dumped to HDFS.\n\nPregel also allows users to implement an aggregator for global communication. Each vertex can provide a value to an aggregator in {\\em compute}(.) in a superstep. The system aggregates those values and makes the aggregated result available to all vertices in the next superstep.\n\n\\vspace{2mm}\n\n\n\n\\noindent{\\bf Distributed Vertex-Centric Systems.} Many Pregel-like systems have been developed, including Giraph~\\cite{giraph}, GPS~\\cite{gps}, GraphX~\\cite{graphx}, and Pregel+~\\cite{pregelplus}. New features are introduced by these systems, for example, GPS proposed to mirror high-degree vertices on other machines, and Pregel+ proposed the integration mirroring and message combining as well as a request-respond mechanism, to reduce communication workload. While these systems strictly follow the synchronous data-pushing model of Pregel, GraphLab~\\cite{graphlab} adopts an asynchronous data-pulling model, where each vertex actively pulls data from its neighbors rather than passively receives messages. A subsequent version of GraphLab, called PowerGraph~\\cite{powergraph}, partitions the graph by edges rather than by vertices to achieve more balanced workload. While the asynchronous model leads to faster convergence for some tasks like random walk, \\cite{ourExp} and~\\cite{tamerExp} reported that GraphLab's asynchronous mode is generally slower than synchronous execution mainly due to the expensive cost of locking/unlocking.\n\n\n\n\n\\vspace{2mm}\n\n\n\n\\noindent{\\bf Single-PC Vertex-Centric Systems.} There are also other vertex-centric systems, such as GraphChi~\\cite{graphchi} and X-Stream~\\cite{xstream}, designed to run on a single PC by manipulating a big graph on disk. However, these systems need to scan the whole graph on disk once for each iteration of computation even if only a small fraction of vertices need to perform computation, which is inefficient for light-weight querying workloads.\n\n\n\n\n\\vspace{2mm}\n\n\\noindent{\\bf Weaknesses of Existing Systems for Graph Querying.} In our experience of working with researchers in e-commerce companies and telecom operators, we found that existing vertex-centric systems cannot support query processing efficiently nor do they provide a user-friendly programming interface to do so. If we write a vertex-centric algorithm for a generic query, we have to run a job for every incoming query. As a result, each superstep transmits only the few messages of one light-weight query which cannot fully utilize the network bandwidth. Moreover, there are a lot of synchronization barriers, one for each superstep of each query, which is costly. Moreover, some systems such as Giraph bind graph loading with graph computation (i.e., processing a query in our context) for each job, and the loading time can significantly degrade the performance.\n\nAn alternative to the one-query-at-a-time approach is to hard code a vertex-centric algorithm to process a batch of $k$ queries, where $k$ can be an input argument. However, in the {\\em compute}(.) function, one has to differentiate the incoming messages and/or aggregators of different queries and update $k$ vertex values accordingly. In addition, existing vertex-centric framework checks the stop condition for the whole job, and users need to take care of additional details such as when a vertex can be deactivated (e.g., when it should be halted for all the $k$ queries), which should originally be handled by the system itself. More critically, the one-batch-at-a-time approach does not solve the problem of low utilization of network bandwidth, since in later stage when most queries finish their processing, only a small number of queries (or stragglers) are still being processed and hence the number of messages generated is too small to sufficiently utilize the network bandwidth.\n\n\n\nThe single-PC systems are clearly not suitable for light-weight querying workloads since they need to scan the whole graph on disk once for each iteration. Other existing graph databases such as Neo4j~\\cite{neo4j} and HyperGraphDB~\\cite{Iordanov10waim} support basic graph operations and simple graph queries, but they are not designed to handle big graphs. Our experiments also verified the inefficiency of single-PC systems and graph databases in querying big graphs (see Section~\\ref{sec:results}). There are other systems, e.g., the block-centric system Blogel~\\cite{blogel} and a recent general-purpose system Husky~\\cite{YangLC16pvldb}, which achieve remarkable performance on offline graph analytics, but are not designed for graph querying.\n\nThe above discussion motivates the need of a general-purpose graph processing system that treats queries as first citizens, which provides a user-friendly interface so that users can write their program easily for one generic query and the system processes queries on demand efficiently. Our Quegel system, to be presented in the following sections, fulfils this need.\n\n\\section{The Quegel System}\\label{sec:design}\nA Quegel program starts by loading the input graph $G$, i.e., distributing vertices into the main memory of different workers in a cluster. If users enable indexing, a local index will be built from the vertices of each worker. After $G$ is loaded (and index is constructed), Quegel receives and processes incoming queries using the computing logic specified by a vertex UDF {\\em compute}(.) as in Pregel. Users may type their queries from a client console, or submit a batch of queries with a file. After a query is evaluated, users may specify Quegel to print the answer to the console, or to dump the answer to HDFS if its size is large (e.g., the answer contains many subgraphs).\n\n\\subsection{Execution Model: Superstep-Sharing}\n\nTo address the weaknesses of existing systems presented in Section~\\ref{sec:related}, we need to consider a new computation model. We first present the hardness of querying a big graph in general, which influences the design of our model.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Hardness of Big Graph Querying and Our Design Objective.} We consider the processing of a large graph that is stored in distributed sites, so that the processing of each query requires network communication. Since the message transmission of each superstep incurs round-trip delay, it is difficult (if not unrealistic) for distributed vertex-centric computation (e.g., on $k$ machines) to achieve response time comparable to that of single-machine algorithms on a smaller graph (e.g., $k$ times smaller). Therefore, our goal is to answer a query in interactive speed, e.g., in a second to at most a few seconds depending on the complexity of processing a given query. We remark that even in CANDS~\\cite{cands}, a specialized distributed system dedicated for shortest path querying on big graphs, a query can take many seconds to answer, while as we shall see in Section~\\ref{sec:results}, our general-purpose Quegel system can process multiple PPSP queries per second on a graph with billions of edges.\n\nMoreover, due to the sheer size of a big graph, the total workload of a batch of queries can be huge even if each query accesses just a fraction of the graph. We remark that the workload of distributed graph computation is significantly different from traditional database applications. For example, to query the balance of a bank account, the balance value can be quickly accessed from a centralized account table using a B$^+$-tree index based on the account number, and it is possible to achieve both high throughput and low latency. However, in distributed graph computation, the complicated topology of connections among vertices (which are not present among bank accounts) results in higher-complexity algorithms and heavier workloads. Specifically, due to the poor locality of graph data, each query usually accesses vertices spreading through the whole big graph in distributed sites, and vertices need to communicate with each other through the network.\n\nThe above discussion shows that there is a latency-throughput tradeoff where one can only expect either interactive speed or high throughput but not both. As a result, our \\emph{design objective} focuses on developing a model for the following two scenarios of querying big graphs, both of which are common in real life applications.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Scenario~(i): Interactive Querying}, where a user interacts with Quegel by submitting a query, checking the query results, refining the query based on the results and re-submitting the refined query, until the desired results are obtained. As an example, a data analyst may use interactive PPSP queries to examine the distance between two users of interest in a social network. Another example is given by the XML keyword querying application (to be presented in Section~\\ref{ssec:xml}). In such applications, there are only one or several users (e.g., a data scientist) analyzing a big graph by posing interactive queries, but each query should be answered in a second or several seconds. No existing vertex-centric system can achieve such query latency on a big graph.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Scenario~(ii): Batch Querying}, where batches of queries are submitted to Quegel, and they need to be answered within a reasonable amount of time. An example of batch querying is given by the vertex-pair sampling application mentioned in Section~\\ref{sec:intro} for estimating graph metrics, where a large number of PPSP queries need to be answered. Quegel achieves throughput 186 and 38.6 times higher than Giraph and GraphLab for processing PPSP queries, and thus allows the graph metrics to be estimated more accurately.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Superstep-Sharing Model.} We propose a \\emph{superstep-sharing execution model} to meet the requirements of both interactive querying and batch querying. Specifically, Quegel processes graph queries in iterations called  \\textbf{super-rounds}. In a super-round, every query that is currently being processed proceeds its computation by one superstep; while from the perspective of an individual query, Quegel processes it superstep by superstep as in Pregel. Intuitively, a super-round in Quegel is like \\emph{many queries sharing the same superstep}. For a query $q$ whose computation takes $n_q$ supersteps, Quegel processes it in $(n_q+1)$ super-rounds, where the last super-round reports or dumps the results of $q$.\n\n\n\nQuegel allows users to specify a capacity parameter $C$, so that in any super-round, there are at most $C$ queries being processed. New incoming queries are appended to a query queue, and at the beginning of a super-round, Quegel fetches as many queries from the queue as possible to start their processing, as long as the capacity constraint $C$ permits. During the computation of a super-round, different workers run in parallel, while each worker processes (its part of) the evaluation of the queries serially. And for each query $q$, if $q$ has not been evaluated, a worker serially calls {\\em compute}(.) on each of its vertices that are activated by $q$; while if $q$ has already finished its evaluation, the worker reports or dumps the query results, and releases the resources consumed by $q$.\n\nFor the processing of each query, the supersteps are numbered. Different queries may have different superstep number in the same super-round, for example, if the queries enter the system in different super-rounds. Messages (and aggregators) of all queries are synchronized together at the end of a super-round, to be used by the next super-round.\n\nFor interactive querying where queries are posed and processed in sequence, the superstep-sharing model processes each individual query with all the cluster resources just as in Pregel. However, since Quegel decouples the costly graph loading and dumping from query processing, and supports convenient construction and adoption of graph indexes, the query latency is significantly reduced.\n\n\\begin{figure}[!t]\n\n    \\centering\n    \\includegraphics[width=\\columnwidth]{balance}\n\n    \\caption{Load balancing}\\label{balance}\n\n\\end{figure}\n\n\\begin{figure*}[!t]\n    \\centering\n    \\includegraphics[width=2\\columnwidth]{context}\n    \\caption{Illustration of context objects}\\label{context}\n\\end{figure*}\n\nFor batch querying, while the workload of each individual query is light, superstep-sharing combines the workloads of up to $C$ queries as one batch in each super-round to achieve higher resource utilization. Compared with answering each query independently as in existing graph-parallel systems, Quegel's superstep-sharing model supports much more efficient query processing since only one message (and/or aggregator) synchronization barrier is required in each super-round instead of up to $C$ synchronization barriers. We remark that the synchronization cost is relatively significant compared with the light workload of processing each single query. In addition, by sending the messages of many queries in one batch, superstep-sharing also better utilizes the network bandwidth.\n\nSuperstep-sharing also leads to more balanced workload. As an illustration, Figure~\\ref{balance} shows the execution of two queries for one superstep in a cluster of two workers. The first query (darker shading) takes 2 time units on Worker~1 and 4 time units on Worker~2, while the second query (lighter shading) takes 4 time units on Worker~1 and 2 time units on Worker~2. When the queries are processed individually, the first query needs to be synchronized before the second query starts to be processed. Thus, 8 time units are required in total. Using superstep-sharing, only one synchronization is needed at the end of the super-round, thus requiring only 6 time units.\n\nOne issue that remains is how to set the capacity parameter $C$. Obviously, the larger the number of queries being simultaneously processed, the more fully is the network bandwidth utilized. But the value of $C$ should be limited by the available RAM space. The input graph consumes $O(|V|+|E|)$ RAM space, while each query $q$ consumes $O(|V_q|)$ space, where $V_q$ denotes the set of vertices accessed by $q$. Thus, $O(|V|+|E|+C|V_q|)$ should not exceed the available RAM space, though in most case this is not a concern as $|V_q|\\ll|V|$. While setting $C$ larger tends to improve the throughput, the throughput converges when the network bandwidth is saturated. In a cluster such as ours which is connected by Gigabit Ethernet, we found that the throughput usually converges when $C$ is increased to 8 (for the graph queries we tested), which indicates that Quegel has already fully utilized the network bandwidth and shows the high complexity of querying a big graph.\n\n\\subsection{System Design}\\label{ssec:design}\n\nQuegel manages three kinds of data: {\\bf(i)~V-data}, whose value only depends on a vertex $v$, such as $v$'s adjacency list. {\\bf(ii)~VQ-data}, whose value depends on both a vertex $v$ and a query $q$. For example, the vertex value $a(v)$ is query-dependent: in a PPSP query $q=(s, t)$, $a(v)$ keeps the estimated value of the shortest distance from $s$ to $v$, denoted by $d(s, v)$, whose value depends on the source vertex $s$. As $a(v)$ is  w.r.t.\\ a query $q$, we use $a_q(v)$ to denote ``$a(v)$ w.r.t.\\ $q$''. Other examples of VQ-data include the active/halted state of a vertex $v$, and the incoming message buffer of $v$ (i.e., input to $v.${\\em compute}(.)). {\\bf(iii)~Q-data}, whose value only depends on a query $q$. For example, at any moment, each query $q$ has a unique superstep number. Other examples of Q-data include the query content (e.g., $(s, t)$ for a PPSP query), the outgoing message buffers, aggregated values, and control information that decides whether the computation should terminate.\n\nLet $Q=\\{q_1, \\ldots, q_k\\}$ be the set of queries currently being processed by Quegel, and let $id(q_i)$ be the query ID of each $q_i\\in Q$.\n\nIn Quegel, each worker maintains a hash table $HT_Q$ to keep the Q-data of each query in $Q$. The Q-data of a query $q_i$ can be obtained from $HT_Q$ by providing the query ID $id(q_i)$, and we denote it by $HT_Q[q_i]$. When a new query $q$ is fetched from the query queue to start its processing at the beginning of a super-round, the Q-data of $q$ is inserted into $HT_Q$ of every worker; while after $q$ reports or dumps its results at superstep $(n_q+1)$, the Q-data of $q$ is removed from $HT_Q$ of every worker.\n\nEach worker $W$ also maintains an array of vertices, {\\em varray}, each element of which maintains the V-data and VQ-data of a vertex $v$ that is distributed to $W$. The VQ-data of a vertex $v$ is organized by a look-up table $LUT_v$, where the VQ-data related to a query $q_i$ can be obtained by providing the query ID $id(q_i)$, and we denote it by $LUT_v[q_i]$. Since every vertex $v$ needs to maintain a table $LUT_v$, we implement it using a space-efficient balanced binary search tree rather than a hash table. The data kept by each table entry $LUT_v[q]$ include the vertex value $a_q(v)$, the active/halted state of $v$ (in $q$), and the incoming message buffer of $v$ (for $q$).\n\nUnlike the one-batch-at-a-time approach of applying existing vertex-centric systems, where each vertex $v$ needs to maintain $k$ vertex values no matter whether it is accessed by a query, we design Quegel to be more space efficient. We require that {\\it a vertex $v$ is allocated a state for a query $q$ only if $q$ accesses $v$ during its processing}, which is achieved by the following design. When vertex $v$ is activated for the first time during the processing of $q$, the VQ-data of $q$ is initialized and inserted into $LUT_v$. After a query $q$ reports or dumps its results at superstep $(n_q+1)$, the VQ-data of $q$ (i.e., $LUT_v[q]$) is removed from $LUT_v$ of every vertex $v$ in $G$.\n\nEach worker also maintains a hash table $HT_V$, such that the position of a vertex element $v$ in {\\em varray} can be obtained by providing the vertex ID of $v$. We denote the obtained vertex element by $HT_V[v]$. The table $HT_V$ is useful in two places: (1)~when a message targeted at vertex $v$ is received, the system will obtain the incoming message buffer of $v$ from {\\em varray}$[pos]$ where $pos$ is computed as $HT_V[v]$, and then append the message to the buffer; (2)~when an initial vertex $v$ is activated using its vertex ID at the beginning of a query, the system will initialize the VQ-data of $v$ for $q$, and insert it into $LUT_v$ which is obtained from {\\em varray}$[pos]$ where $pos$ is computed as $HT_V[v]$. We shall see how users can activate the (usually small) initial set of vertices in Quegel for processing without scanning all vertices in Section~\\ref{sec:interface}.\n\nAn important feature of Quegel is that, it only requires a user to specify the computing logic for a generic vertex and a generic query; the processing of concrete queries is handled by Quegel and is totally transparent to users. For this purpose, each worker $W$ maintains two \\emph{global context objects}: (i)~query context $C_{query}$, which keeps the Q-data of the query that $W$ is processing; and (ii)~vertex context $C_{vertex}$, which keeps the VQ-data of the current vertex that $W$ is processing for the current query. In a super-round, when a worker starts to process each query $q_i$, it first obtains $HT_Q[q_i]$ and assigns it to $C_{query}$, so that when a user accesses the Q-data of the current query in UDF {\\em compute}(.) (e.g., to get the superstep number or to append messages to outgoing message buffers), the system will access $C_{query}$ directly without looking up from $HT_Q$. Moreover, during the processing of $q_i$, and before the worker calls {\\em compute}(.) on each vertex $v$, it first obtains $LUT_v[q_i]$ and assigns it to $C_{vertex}$, so that any access or update to the VQ-data of $v$ in {\\em compute}(.) (e.g., obtaining $a_q(v)$ or letting $v$ vote to halt) directly operates on $C_{vertex}$ without looking up from $LUT_v$.\n\nAs an illustration, consider the example shown in Figure~\\ref{context}, where there are 3 queries being evaluated and the computation proceeds for 3 supersteps. Moreover, we assume that 4 vertices call {\\em compute}(.) in each superstep of each query. As an example, when processing a superstep~$(i+2)$, $C_{query}$ is set to $HT_Q[q_3]$ before evaluating $v_1$ for $q_3$; and when the evaluation arrives at $v_3$, $C_{vertex}$ is set to $LUT_{v_3}[q_3]$ before $v_3.${\\em compute}(.) is called. Figure~\\ref{context} also shows a simplified code of {\\em compute}(.) for shortest path computation, and inside $v_3.${\\em compute}(.) for $q_3$, $a(v)$ is accessed once in Line~1 and twice in Line~3, all of which use the value $a_{q_3}(v)$ stored in $C_{vertex}=LUT_{v_3}[q_3]$ directly; while Line~1 accesses the superstep number which is obtained from $C_{query}=HT_Q[q_3]$ directly.\n\nOne benefit of using the context objects $C_{vertex}$ and $C_{query}$ is that, due to the access pattern locality of superstep-sharing, {\\it repetitive lookups of tables $HT_Q$ and $LUT_{v}$ are avoided}. Another benefit is that, {\\it users can write their program exactly like in Pregel} (e.g., to access $a(v)$ and superstep number) and the processing of concrete queries is transparent to users.\n\n\\section{Programming Interface}\\label{sec:interface}\nThe programming interface of Quegel incorporates many unique features designed for querying workload. For example, the interface allows users to construct distributed graph indexes at graph loading. The interface also allows users to activate only an initial (usually small) set of vertices, denoted by $V^I_q$, for processing a query $q$ without checking all vertices. Note that we cannot activate $V^I_q$ during graph loading because $V^I_q$ depends on each incoming query $q$.\n\nQuegel defines a set of base classes, each of which is associated with some template arguments. To write an application program, a user only needs to (1)~subclass the base classes with the template arguments properly specified, and to (2)~implement the UDFs according to the application logic. We now describe these base classes.\n\n\\vspace{2mm}\n\n\\noindent{\\bf Vertex Class.} As in Pregel, the {\\em Vertex} class has a UDF {\\em compute}(.) for users to specify the computing logic. In {\\em compute}(.), a user may call {\\em get\\_query}() to obtain the content of the current query $q_{cur}$. A user may also access other Q-data in {\\em compute}(.), such as getting $q_{cur}$'s superstep number, sending messages (which appends messages to $q_{cur}$'s outgoing message buffers), and getting $q_{cur}$'s aggregated value from the previous superstep. Quegel also allows a vertex to call {\\em force\\_terminate}() to terminate the computation of $q_{cur}$ at the end of the current superstep. All these operations access the Q-data fields from $C_{query}$ directly.\n\nThe vertex class of Quegel is defined as {\\em Vertex}$<\n", "index": 1, "text": "$$I, V^Q, V^V, M, Q$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"I,V^{Q},V^{V},M,Q\" display=\"block\"><mrow><mi>I</mi><mo>,</mo><msup><mi>V</mi><mi>Q</mi></msup><mo>,</mo><msup><mi>V</mi><mi>V</mi></msup><mo>,</mo><mi>M</mi><mo>,</mo><mi>Q</mi></mrow></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type (e.g., {\\tt int}) of the ID of a vertex (which is V-data). (2)~$<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$, which has five template arguments: (1)~$<\n", "index": 3, "text": "$$I$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"I\" display=\"block\"><mi>I</mi></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the query-dependent attribute of a vertex $v$, i.e., $a_q(v)$ (which is VQ-data). (3)~$<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type (e.g., {\\tt int}) of the ID of a vertex (which is V-data). (2)~$<\n", "index": 5, "text": "$$V^Q$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"V^{Q}\" display=\"block\"><msup><mi>V</mi><mi>Q</mi></msup></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the query-independent attribute of a vertex $v$, denoted by $a^V(v)$ (which is V-data). We do not hard-code the adjacency list structure in order to provide more flexibility. For example, a user may define $a^V(v)$ to include two adjacency lists, one for in-neighbors and the other for out-neighbors, which is useful for algorithms such as bidirectional BFS. Other V-data can also be included in $a^V(v)$, such as vertex labels used for search space pruning in some query processing algorithms. (4)~$<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type of the query-dependent attribute of a vertex $v$, i.e., $a_q(v)$ (which is VQ-data). (3)~$<\n", "index": 7, "text": "$$V^V$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"V^{V}\" display=\"block\"><msup><mi>V</mi><mi>V</mi></msup></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the messages that are exchanged between vertices. (5)~$<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type of the query-independent attribute of a vertex $v$, denoted by $a^V(v)$ (which is V-data). We do not hard-code the adjacency list structure in order to provide more flexibility. For example, a user may define $a^V(v)$ to include two adjacency lists, one for in-neighbors and the other for out-neighbors, which is useful for algorithms such as bidirectional BFS. Other V-data can also be included in $a^V(v)$, such as vertex labels used for search space pruning in some query processing algorithms. (4)~$<\n", "index": 9, "text": "$$M$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"M\" display=\"block\"><mi>M</mi></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the content of a query. For example, for a PPSP query, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type of the messages that are exchanged between vertices. (5)~$<\n", "index": 11, "text": "$$Q$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"Q\" display=\"block\"><mi>Q</mi></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the content of a query. For example, for a PPSP query, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type of the messages that are exchanged between vertices. (5)~$<\n", "index": 11, "text": "$$Q$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"Q\" display=\"block\"><mi>Q</mi></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$, for specifying the input/output format and for executing the computation of each worker. The template argument $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ is a pair of vertex IDs indicating the source and target vertices. In {\\em compute}(.), a user may access $a^V(v)$ by calling {\\em value}$()$, and access $a_q(v)$ by calling {\\em qvalue}$()$.\n\nSuppose that a set of $k$ queries, $Q$, is being processed, then each vertex conceptually has $k$ query-dependent attributes $a_q(v)$, one for each query $q\\in Q$. Since a query normally only accesses a small fraction of all the vertices, to be space-efficient, Quegel allocates space to $a_q(v)$ as well as other VQ-data only at the time when the vertex is first accessed during the processing of $q$. Accordingly, Quegel provides a UDF {\\em init\\_value}($q$) for users to specify how to initialize $a_q(v)$ when $v$ is first accessed by $q$. For example, for a PPSP query $q=(s, t)$, where $a_q(v)$ keeps the estimated value of $d(s, v)$, one may implement {\\em init\\_value}($s, t$) as follows: if $v = s$, $a_q(v) \\gets 0$; else, $a_q(v) \\gets \\infty$. The state of $v$ is always initialized to be active by the system, since when the space of the state is allocated, $v$ is activated for the first time and should participate in the processing of $q$ in the current superstep. Function {\\em init\\_value}($q$) is the only UDF of the {\\em Vertex} class in addition to {\\em compute}(.).\n\n\\vspace{2mm}\n\n\\noindent{\\bf Worker Class.} The {\\em Vertex} class presented above is mainly for users to specify the graph computation logic. Quegel provides another base class, {\\em Worker}$<\n", "index": 15, "text": "$$T_{vtx}, T_{idx}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"T_{vtx},T_{idx}\" display=\"block\"><mrow><msub><mi>T</mi><mrow><mi>v</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></mrow></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the user-defined subclass of {\\em Vertex}. The template argument $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$, for specifying the input/output format and for executing the computation of each worker. The template argument $<\n", "index": 17, "text": "$$T_{vtx}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"T_{vtx}\" display=\"block\"><msub><mi>T</mi><mrow><mi>v</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ is optional, and if distributed indexing (to be introduced shortly) is enabled, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the user-defined subclass of {\\em Vertex}. The template argument $<\n", "index": 19, "text": "$$T_{idx}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"T_{idx}\" display=\"block\"><msub><mi>T</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ is optional, and if distributed indexing (to be introduced shortly) is enabled, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the user-defined subclass of {\\em Vertex}. The template argument $<\n", "index": 19, "text": "$$T_{idx}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"T_{idx}\" display=\"block\"><msub><mi>T</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ specifies the type of the content of a query. For example, for a PPSP query, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the type of the messages that are exchanged between vertices. (5)~$<\n", "index": 11, "text": "$$Q$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"Q\" display=\"block\"><mi>Q</mi></math>", "type": "latex"}, {"file": "1601.06497.tex", "nexttext": ">$ is optional, and if distributed indexing (to be introduced shortly) is enabled, $<\n", "itemtype": "equation", "pos": -1, "prevtext": ">$ specifies the user-defined subclass of {\\em Vertex}. The template argument $<\n", "index": 19, "text": "$$T_{idx}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"T_{idx}\" display=\"block\"><msub><mi>T</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></math>", "type": "latex"}]