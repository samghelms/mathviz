[{"file": "1601.03184.tex", "nexttext": "\nwhere the factor $2$ in the denominator accounts for even-odd preconditioning\nand $\\unit[8]{Byte}$ is the size of a complex number in single precision. From\nEq.~\\eqref{eq:sizes} we obtain message sizes of order 1 KiB for the default\nsetup, which is just the point where the effective bandwidth starts to increase\nsignificantly. By processing multiple right-hand sides simultaneously we are\nable to perform all halo exchanges and global sums, respectively, in the same\ncall to MPI. Thus the message size increases by a factor of ${N_\\text{b}} = {N_\\text{SIMD}} = 16 =\n2^4$. Fig.~\\ref{plot:comm-bw} suggests an estimated increase in effective\nbandwidth of a factor $3\\sim4$, which might translate directly to the wall-clock\ntime spent in communication.\n\n\n\\section{Mapping to SIMD registers}\n\\label{section:mapping}\n\nThe basic layout for data structures based on complex numbers in the original\nWuppertal implementation did not take vectorization into account and uses the\n\\emph{complex} data type in C. This way, a vector-like object $v$ of length\n$\\ell$ is stored such that the real and imaginary parts alternate in memory:\n\\begin{center}\n  \\begin{tabularx}{.6\\textwidth}{|c *{7}{|Y}|}\n    \\hline &&&&&&\\[-4.5mm]\n    ${\\operatorname{Re}} v_1$ & ${\\operatorname{Im}} v_1$ &\n    ${\\operatorname{Re}} v_2$ & ${\\operatorname{Im}} v_2$ &\n    $\\cdots$ & ${\\operatorname{Re}} v_\\ell$ & ${\\operatorname{Im}} v_\\ell$ \\[.7mm]\n    \\hline\n  \\end{tabularx}\n\\end{center}\nThis is known as Array-of-Structs (AoS) layout. In the code parts relevant for\nus, the implementation in \\cite{Heybrock:lat15} works with this layout by\nde-interleaving two registers using swizzle intrinsics before and after doing a\nSIMD computation. This introduces additional overhead that could be avoided with\na data layout more suitable to vectorization.\n\nOur implementation uses another index for vectorization, i.e., the index of the\ndifferent right-hand sides inside a block. For each vector index $i$ we store\n${N_\\text{SIMD}}$ $(=16)$ real parts of the right-hand sides followed by the\ncorresponding imaginary parts:\n\\begin{center}\n  \\begin{tabularx}{.8\\textwidth}{|c *{8}{|Y}|}\n    \\hline &&&&&&&\\[-3.5mm]\n    ${\\operatorname{Re}} v^{(1)}_i$ & ${\\operatorname{Re}} v^{(2)}_i$ &\n    $\\cdots$ & ${\\operatorname{Re}} v^{(16)}_i$ &\n    ${\\operatorname{Im}} v^{(1)}_i$ & ${\\operatorname{Im}} v^{(2)}_i$ &\n    $\\cdots$ & ${\\operatorname{Im}} v^{(16)}_i$ \\[1.3mm]\n    \\hline\n  \\end{tabularx}\n\\end{center}\nThis is known as Array-of-Structs-of-Short-Vectors (AoSoSV) layout. While the\nconversion required non-trivial programming effort, this layout yields a more\nnatural mapping to SIMD. The de-interleaving overhead is gone, and the\nindividual entries in the registers contain data independent of one another,\nwhich eliminates the need for reduction operations over the elements in the\nregister.\n\nWith our modifications to the data layout, matrix-vector multiplications become\nmatrix-matrix multiplications, which enables us to use a different vectorization\nscheme. In contrast to \\cite{Heybrock:lat15} we vectorize the restriction of a\nvector from the fine to the coarse grid (as an example) by broadcasting the\nelements of the projection operator $R$ as shown in\nAlg.~\\ref{alg:mrhs_restriction} (see \\cite{Heybrock:lat15} for the definition of\n${N_\\text{block}}$, $V_\\text{block}$, and $y_c$). The same vectorization scheme is used\nfor the application of $D_c$ in the coarse-grid solve. BLAS-like linear\nalgebra (e.g., vector adds) is vectorized trivially with this data layout.\n\n\\medskip\n\n\\begin{algorithm}[H]\n  \\caption{SIMD implementation of restriction $R y = y_c$ with ${N_\\text{SIMD}}$\n  right-hand sides}\n  \\label{alg:mrhs_restriction}\n  {   \\SetKwFor{ForAll}{for all}{do}{end for}   \\SetKwFor{ForEach}{foreach}{do}{end for}   \\SetKwFor{For}{for}{do}{end for}   \\SetArgSty{}   \\DontPrintSemicolon }\n  \\For {$i=1$ \\KwTo ${N_\\text{block}}$}\n  {\n    \\ForEach {$h=\\ell,r$}\n    {\n      \\For {$n=1$ \\KwTo $6V_{\\text{block}}$}\n      {\n        load real and imag.\\ parts of ${N_\\text{SIMD}}$ rhs for entry $y_{i,n}^h$ into\n        SIMD vectors\\;\n        \\For {$j=1$ \\KwTo ${N_\\text{tv}}$}\n        {\n          load real and imag.\\ parts of \\smash{$(y_c)^h_{i,j}$} for ${N_\\text{SIMD}}$\n          rhs\\;\n          \\mbox{broadcast real and imag.\\ part of entry $j$ in column $n$ of\n          $R_i^h$ into SIMD vectors\\hspace*{-10mm}}\\;\n          increase $(y_c)^h_{i,j}$ by complex fused multiply-add and\n          write to memory\\;\n        }\n      }\n    }\n  }\n\\end{algorithm}\n\n\\section{Memory-bandwidth and cache-reuse considerations}\n\\label{section:cache}\n\nA dense complex matrix-vector multiplication $c = A \\cdot b$, where $A$, $b$,\nand $c$ are of dimension $M \\times K$, $K$, and $M$, respectively, requires\ntransferring $(2M + M \\cdot K + K)\\cdot\\unit[8]{Byte}$ from and to memory in\nsingle precision. The computation needs a minimum of $4\\cdot M \\cdot K/16$\ncycles, where a complex \\emph{fmadd} consists of 4 real \\emph{fmadd} operations,\nof which a KNC core can perform $16$ in one cycle. The ratio of these numbers\nyields the memory bandwidth per core required to avoid stalls, i.e., $32 \\cdot\n(2/K + 1 + 1/M)$ Byte/cycle. For a typical working set of a core, $K$ and $M$\nare large enough so that their contribution $2/K+1/M$ is negligible compared to\n1.\\footnote{$M$ needs to be multiplied by $2$ for the spin-splitting of {\\mbox{DD-$\\alpha$AMG}}.}\nThe resulting required memory bandwidth is then $32$~Byte/cycle per core, or\n$2377$~GB/s on $60$ cores of a KNC with a clock speed of $\\unit[1.238]{GHz}$,\nwhich is well above the KNC's sustained memory bandwidth of $150-170$~GB/s,\nmeasured with the STREAM benchmark.\n\nPerforming the analogous calculation for the matrix-matrix multiplication with\n${N_\\text{SIMD}}$ right-hand sides ($A = M \\times K$, $B = K \\times {N_\\text{SIMD}}$, and $C = M\n\\times {N_\\text{SIMD}}$) yields $32 \\cdot (2/K + 1/{N_\\text{SIMD}} + 1/M)~\\text{Byte/cycle}\\sim\n2~\\text{Byte/cycle}=149~\\text{GB/s}$. Here, an element of $A$ can stay in cache\nfor ${N_\\text{SIMD}}$ right-hand sides, which results in the difference to the value\nabove. Thus our method is able to reduce the memory bandwidth requirements of\nthis code part significantly, and our estimate is now within reach of the KNC's\nsustained memory bandwidth.\n\n\\section{Results}\n\nAt the time of this writing we have finished the implementation of the\ncoarse-grid solve and the projection operators, while the smoother\n\\cite{Heybrock:2014iga} still works with the default data layout. This\nintroduces some temporary copying overhead which will disappear as soon as we\nhave a MRHS implementation of the smoother.\n\nThe results below are from runs on the CLS lattice C101 ($ 48^3\\times96$,\n$\\beta=3.4$, $m_{\\pi}=\\unit[220]{MeV}$, $a=\\unit[0.086]{fm}$) described in\n\\cite{Bruno:2014jqa}. We use ${N_\\text{SIMD}} = 16$ test vectors, a domain size of $4^4$,\nand a relative coarse-grid tolerance of $0.05$. The remaining solver\nparameters are tuned for minimal propagator wall-clock time with the default\n(SRHS) setup. To exclude algorithmic effects and allow for a direct comparison\nwe use the same parameter combination also for the MRHS setup.\n\\nopagebreak\n\\begin{figure}\n  \\centering\n    \\caption{Summary of contributions to the wall-clock time in the {\\mbox{DD-$\\alpha$AMG}}\\ setup on\n  $64$ KNCs in {QPACE~2}\\ (solve time for comparison). Improvements in parts\n  affected by our modifications are given in detail.}\n  \\label{plot:results}\n\\end{figure}\n\nWith these parameters, a lattice vector on the coarse grid requires\n$\\unit[1]{\\%}$ of the memory of a vector on the fine grid. With the MRHS setup,\nwe need $32$ lattice vectors on the fine grid and $16 \\cdot 32 = 512$ on the\ncoarse grid. This is to be compared to $17$ and $32$ with the SRHS setup. Thus,\nour method needs roughly a factor of $2.2$ more memory in total for the setup.\nIn a realistic measurement run we typically also keep around several propagators\non the fine grid (consisting of 12 vectors each), so the increase in total\nmemory consumption is actually considerably smaller.\n\nIn Fig.~\\ref{plot:results} we show the improvements in wall-clock time we\nachieve with our method. We gain a factor of $2.9$ in the projection operators\nand a factor of $2.4$ in computation on the coarse grid. Our method needs fewer\ncalls to barriers between threads, which yields an improvement of $2.7$x in\non-chip synchronization. However, the largest gains are in halo exchanges\n($4.7$x) and global sums ($10.3$x), which were the dominant contributions\npreviously. After our improvements, the wall-clock time is now dominated by\ncopying data from and to MPI buffers. This is currently done by a single thread\non a single core. In the future we will reduce the impact of these copy\noperations by threading them over cores, which will allow us to exploit a larger\nfraction of the KNC's sustained memory bandwidth.\n\nIn total, the time spent on the coarse grid is reduced by a factor of $2.9$,\nwhich translates to a factor of $1.4$ for the total setup time of {\\mbox{DD-$\\alpha$AMG}}.\n\n\\section{Conclusions and outlook}\n\nBy combining multiple right-hand sides we were able to significantly reduce the\nwall-clock time of the previously dominant contribution (i.e., coarse-grid\nsolve) to the setup of {\\mbox{DD-$\\alpha$AMG}}, see Fig.~\\ref{plot:results} for details. Our\nbiggest improvements are in communication, where we can send fewer messages that\nare larger and thus are able to reduce the impact of latency effects.\nAdditional improvements were made in computation and on-chip synchronization.\n\nAs mentioned above, the impact of the red block in Fig.~\\ref{plot:results} (copy\nfrom/to MPI buffers) will be reduced in the future by threading these copy\noperations over cores. More importantly, Fig.~\\ref{plot:results} shows that the\nbiggest optimization potential is now in the fine-grid part of the iterative\nsetup. Therefore we will complete the multiple right-hand-side V-cycle by\napplying the techniques used in the present work also to the smoother\n\\cite{Heybrock:2014iga}, which should yield similar speedups.\n\n\\bibliographystyle{jbJHEP_notitle}\n\\bibliography{Bibliography}\n\n\n", "itemtype": "equation", "pos": 7507, "prevtext": "\n\\section{Introduction and motivation}\nConventional iterative Krylov subspace solvers for the Dirac equation share a\ncommon behavior when going to small quark masses: Their iteration number and\ntime to solution (wall-clock time) increases drastically, which basically\nrenders them unusable. Therefore a lot of effort has been put into developing\nefficient preconditioning algorithms that aim at tackling this problem, such as\ndomain decomposition \\cite{Luscher:2003qa}, inexact deflation\n\\cite{Luscher:2007se}, and multigrid approaches\n\\cite{Babich:2010qb,Frommer:2013fsa}. While these methods significantly reduce\nthe iteration number, the latter two introduce an additional overhead compared\nto standard solvers since they require an initial setup phase before one can\nstart solving the Dirac equation. In HMC the setup cost can even be the dominant\ncontribution to the total wall-clock time spent in the solver since only a few\nsolves can be done before the setup has to be updated. Thus an optimization of\nthe setup code potentially has a large impact on the overall HMC performance.\n\nBased on the attractive theoretical properties and the performance of the {\\mbox{DD-$\\alpha$AMG}}\\\nalgorithm, the Regensburg group (RQCD) recently decided to port the\nimplementation of this algorithm by the Wuppertal group \\cite{Frommer:2013fsa},\nwhich is C-MPI code aimed at standard CPUs, to SIMD architectures, with a\nspecial focus on the Intel Xeon Phi architecture (KNC) used in\n{QPACE~2}~\\cite{Arts:2015jia}. This involved threading the code using OpenMP,\noptimizing it for the wide SIMD registers of the KNC, and reducing\nmemory-bandwidth requirements by enabling the use of half precision on the\ncoarse grid. For a detailed description of this effort see\n\\cite{Heybrock:lat15}.\n\nEven with the improvements achieved in \\cite{Heybrock:lat15}, there is still\noptimization potential in the setup of {\\mbox{DD-$\\alpha$AMG}}, as it remains expensive. In this\ncontribution we document our work on an improved implementation that modifies\nthe computation order in the setup phase to process multiple right-hand sides\nsimultaneously.\n\n\\section{Description of the algorithm}\n\nThe {\\mbox{DD-$\\alpha$AMG}}\\ algorithm uses FGMRES as the outer Krylov subspace solver for the\nDirac equation, preconditioned by a multigrid method that consists of two parts:\na smoother working on the fine grid that reduces the error contribution of\neigenvectors with large eigenvalues (high modes), and a coarse-grid correction\n(CGC) that reduces the error contribution of low modes.\\footnote{As in\n\\cite{Heybrock:lat15} we restrict ourselves to two grid levels.} To this end\nprojection operators between the grids and the Dirac operator on the coarse grid\nneed to be defined in an initial setup phase.\n\nThe setup procedure of {\\mbox{DD-$\\alpha$AMG}}\\ is based on a set of ${N_\\text{tv}}$ random test vectors\n(each of dimension $12V$, where $V$ is the lattice volume) that are used to\nconstruct restriction $R$, prolongation $P = R^{\\dagger}$, and coarse-grid\noperator $D_c$. The setup is split into two parts: an initial phase and an\niterative refinement phase. In the initial phase, a domain-decomposition (DD)\nsmoother based on the Schwarz alternating procedure is run on each of the test\nvectors for a few iterations with starting guess $0$. Then the initial operators\nare constructed from the updated test vectors. This completes the initial\nphase. The operators are then updated in the iterative refinement phase\n(Alg.~\\ref{alg:mgsetup}) that makes use of the full V-cycle of the multigrid\nalgorithm. For a more detailed description see\n\\cite{Frommer:2013fsa,Heybrock:lat15}.\n\n\\begin{algorithm}[ht]\n  \\caption{Iterative part of MG setup (standard implementation)}\n  \\label{alg:mgsetup}\n  {   \\SetKwFor{ForAll}{for all}{do}{end for}   \\SetKwFor{ForEach}{foreach}{do}{end for}   \\SetKwFor{For}{for}{do}{end for}   \\SetArgSty{}   \\DontPrintSemicolon }\n  \\For {$i=1$ \\KwTo ${N_\\text{setup}}$}\n  {\n    // apply V-cycle to test vectors\\;\n    \\For {$j=1$ \\KwTo ${N_\\text{tv}}$}\n    {\n      // \\emph{coarse-grid correction}\\;\n      restrict test vector $v_j$ to coarse grid: $v_{c,j} = R\\,v_j$\\;\n      solve coarse system to low accuracy: $u_{c,j} \\approx D_c^{-1}\\,v_{c,j}$\\;\n      prolongate result of coarse-grid solve to fine grid: $u_j = P\\,u_{c,j}$\\;\n      // \\emph{fine grid}\\;\n      apply smoother to test vector $v_j$, with result from CGC as starting\n      guess\\;\n      replace test vector $v_j$ by result of smoother\\;\n    }\n    setup of restriction $R$ and coarse-grid operator $D_c$\n  }\n\\end{algorithm}\n\n\\section{Basic idea}\nAfter the optimizations described in \\cite{Heybrock:lat15}, we identified the\napplication of the V-cycle to the test vectors in the iterative refinement phase\nto be the dominant contribution to the setup time. Therefore our work focuses on\nthis part of the code exclusively.\n\nIn the implementations of \\cite{Frommer:2013fsa,Heybrock:lat15} the V-cycle is\napplied to the test vectors in a loop sequentially, i.e., to a single right-hand\nside (SRHS) at a time. The basic idea of our improvements is simple. We modify\nthe computation order of the code by blocking the loop over the test vectors\n(Alg.~\\ref{alg:mgsetup2}) with a block length of ${N_\\text{b}}$ and apply the V-cycle to\nmultiple right-hand sides (MRHS), i.e., all vectors inside such a block,\nsimultaneously. Choosing ${N_\\text{b}} = {N_\\text{SIMD}}$ and moving the loop inside a block to\nthe lowest level functions of the code enables us to use this loop for SIMD\nvectorization.\n\n\\begin{algorithm}[h]\n  \\caption{Iterative part of MG setup (improved implementation)\\protect\\footnotemark}\n  \\label{alg:mgsetup2}\n  {   \\SetKwFor{ForAll}{for all}{do}{end for}   \\SetKwFor{ForEach}{foreach}{do}{end for}   \\SetKwFor{For}{for}{do}{end for}   \\SetArgSty{}   \\DontPrintSemicolon }\n  \\For {$i=1$ \\KwTo ${N_\\text{setup}}$}\n  {\n    \\For {$j=1$ \\KwTo ${N_\\text{tv}}/{N_\\text{b}}$}\n    {\n      $k = 1 + (j-1)\\cdot{N_\\text{b}},\\ \\ell = j\\cdot{N_\\text{b}}$\\;\n      apply coarse-grid correction (CGC) to test vectors\n      $v_k$,\\,\\dots,\\,$v_\\ell$\\;\n      apply smoother to test vectors $v_k$,\\,\\dots,\\,$v_\\ell$, with result from\n      CGC as starting guess\\;\n      replace test vectors $v_k$,\\,\\dots,\\,$v_\\ell$ by result of smoother\\;\n    }\n    setup of restriction $R$ and coarse-grid operator $D_c$\\;\n  }\n\\end{algorithm}\n\\footnotetext{\n  In the description of the algorithm we assume that ${N_\\text{tv}}$ is an integer\n  multiple of ${N_\\text{b}}$. If it is not the algorithm gets modified in a\n  straightforward way, but then part of the SIMD unit is wasted in the last\n  iteration, see also \\cite{Heybrock:lat15}.\n}\n\n\\section{Communication bandwidth}\n\nThe effective network bandwidth for off-chip communication via MPI depends on\nthe message size (cf.~Fig.~\\ref{plot:comm-bw}). For small messages latency\neffects are dominant, resulting in low bandwidth. For larger messages the\neffective bandwidth increases since latency effects become negligible.\n\n\\begin{figure}[ht]\n  \\centering\n    \\caption{Network bandwidth vs. message size between two KNCs (bi-directional)\n  in {QPACE~2}\\ via FDR InfiniBand. Typical message sizes in the {\\mbox{DD-$\\alpha$AMG}}\\ setup are shown\n  for SRHS (green) and MRHS (blue) setup.}\n  \\label{plot:comm-bw}\n\\end{figure}\n\nThe message size ($S_\\mu$ in direction $\\mu$) on the coarse grid of the {\\mbox{DD-$\\alpha$AMG}}\\\nsetup depends on the local volume of one MPI rank and the degrees of freedom per\nsite ($2{N_\\text{tv}}$):\n\n", "index": 1, "text": "\\begin{align}\n  S_\\mu &= \\prod_{\\nu = 0, \\nu \\neq \\mu}^{3} \\frac{\\text{(local\n  lattice)}_\\nu}{\\text{(domain size)}_\\nu} \\cdot \\frac{2 {N_\\text{tv}} }{2} \\cdot\n  \\unit[8]{Byte}\\,,\n  \\label{eq:sizes}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle S_{\\mu}\" display=\"inline\"><msub><mi>S</mi><mi>\u03bc</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\prod_{\\nu=0,\\nu\\neq\\mu}^{3}\\frac{\\text{(local&#10;lattice)}_{\\nu}}{\\text{(domain size)}_{\\nu}}\\cdot\\frac{2{N_{\\text{tv}}}}{2}%&#10;\\cdot 8\\,\\mathrm{Byte}\\,,\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mrow><mi class=\"ltx_unit\">\u03bd</mi><mo>=</mo><mn>0</mn></mrow><mo>,</mo><mrow><mi class=\"ltx_unit\">\u03bd</mi><mo>\u2260</mo><mi class=\"ltx_unit\">\u03bc</mi></mrow></mrow><mn>3</mn></munderover></mstyle><mrow><mrow><mstyle displaystyle=\"true\"><mfrac><msub><mtext>(local\nlattice)</mtext><mi class=\"ltx_unit\">\u03bd</mi></msub><msub><mtext>(domain size)</mtext><mi class=\"ltx_unit\">\u03bd</mi></msub></mfrac></mstyle><mo>\u22c5</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><msub><mi class=\"ltx_unit\">N</mi><mtext>tv</mtext></msub></mrow><mn>2</mn></mfrac></mstyle><mo>\u22c5</mo><mpadded width=\"+1.7pt\"><mn>8</mn></mpadded></mrow><mo>\u2062</mo><mpadded class=\"ltx_unit\" width=\"+1.7pt\"><mi class=\"ltx_unit\">Byte</mi></mpadded></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}]