[{"file": "1601.06763.tex", "nexttext": "\n\nLabels can then be described as $L_i = <\\!\\!P_i, d(x, x'), \\delta_{{\\varepsilon}_i}\\!\\!>$. We illustrate this idea in figure \\ref{fig:pnth}.\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype-threshold representation of a concept $L_i$. The conceptual space has dimensions $x_1$ and $x_2$. The concept has prototype $P_i$ and threshold ${\\varepsilon}_i$. The uncertainty about the threshold is represented by the dotted line. Element $a$ in the conceptual space is within the threshold, so it is appropriate to assert `$a$ is $L_i$'. Element $b$ is outside the threshold, so it is not appropriate to assert `$b$ is $L_i$'.}\n\\label{fig:pnth}\n\\end{figure}\n\n\n\\section{A HIERARCHICAL MODEL OF CONCEPT COMPOSITION}\n\\label{sec:cmp}\nExperiments in the psychological literature  propose that human concept combination can in many cases be modelled as a weighted sum of attributes such as `has feathers', `has a beak' (for the concept `Bird') \\cite{hamp1987}. These attributes differ from quality dimensions in conceptual spaces: they tend to be binary, complex, and multidimensional in themselves. We therefore view each attribute as a label in a continuous conceptual space $\\Omega_i$ and combine these labels in a binary conceptual space $\\{0,1\\}^n$ illustrated in figure \\ref{fig:binspace}. In this binary conceptual space, a conjunction of such labels ${\\alpha} = \\bigwedge_{i = 1}^n\\pm L_i$ maps to a binary vector $\\vec{y}_\\alpha$ taking value $1$ for positive labels $L_i$ and $0$ for negated labels $\\neg L_i$ (figure \\ref{fig:binspace3}).\n\\begin{figure}[h!]\n\\small\n  \\centering  \n    \\caption{Combining labels in a binary space}\n\\label{fig:binspace}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype for ${\\alpha} = L_1 \\land L_2 \\land L_3$ and weighted dimensions in binary space.}\n\\label{fig:binspace3}\n\\end{figure}\n\n We treat membership in ${\\alpha}$ in the binary conceptual space within the label semantics framework. So ${\\alpha}$ is described in the binary space by $\\tilde{\\alpha}=<\\!\\!\\vec{y}_\\alpha, d(\\vec{y}, \\vec{y}'), \\delta\\!\\!>$ as before, and $\\mu_{\\alpha}(y) = \\int_{d(y, y_\\alpha)}^\\infty  \\delta_{{\\varepsilon}}({\\varepsilon})\\mathrm{d}{\\varepsilon}$. Since the dimensions of the space are weighted, some are considered more important than others. The presence or absence of some attributes may be relaxed. For example, `Bird' might be characterised by (among others) the attributes `has feathers', `has wings', `flies'. The attributes `has wings' and `has feathers' should be given more importance than `flies'. This is because various species of birds do not fly, so this attribute may be relaxed whilst still allowing something to be categorised as a bird. The effect this has is to create elliptical regions of the conceptual space, as illustrated in figure \\ref{fig:binspace4}.\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype for $\\alpha = L_1 \\land L_2$ and weighted dimensions in a two dimensional binary space, together with the threshold ${\\varepsilon}$ for $\\alpha$. The point $(0, 1)$, indicated by an open circle, can be considered to be an instance of the concept for which $y_\\alpha$ is the prototype.}\n\\label{fig:binspace4}\n\\end{figure}\n\nThe distance metric between two vectors $\\vec{y},\\vec{y}^\\prime$ in the binary space $\\{0,1\\}^n$ is written $H_{\\vec{\\lambda}}(\\vec{y},\\vec{y}^\\prime)$ and defined as a weighted city block metric. \n\nThen, under certain constraints, membership in the combined concept $\\alpha = \\bigwedge_{i = 1}^n\\pm L_i$ is equal to the weighted sum of membership in each of the $L_i$. This is stated in the following theorem:\n\n\n\n\n\n\n\n\\begin{thm}[Compound Concepts]\n\\label{thm:sumthm}\nLet $L_i$ be attributes described by membership functions $\\mu_{L_i}(x_i)$ in conceptual spaces $\\Omega_i$. Let $\\alpha$ be a conjunction of such attributes (or their negation):  $\\alpha=\\bigwedge_{i=1}^n \\pm L_i$. If we combine these labels in a binary space $\\{0,1\\}^n$ with $\\tilde{\\alpha}=<\\!\\!\\vec{y}_\\alpha, H_{\\vec{\\lambda}}, U(0,\\lambda_T)\\!\\!>$ where $\\lambda_T = \\sum_{i = 1}^n \\lambda_i$, then we may calculate the membership in $\\alpha$ in the space $\\Omega_1 \\times ... \\times \\Omega_n$ by:\n\n", "itemtype": "equation", "pos": 5669, "prevtext": "\n\\newtheorem{dfn}{Definition}\n\\newtheorem{lem}[dfn]{Lemma}\n\\newtheorem{prop}[dfn]{Proposition}\n\\newtheorem{thm}[dfn]{Theorem}\n\\newtheorem{cor}[dfn]{Corollary}\n\\newtheorem{fact}[dfn]{Fact}\n\\newtheorem {exa}[dfn]{Example}\n\n\n\\title{Emerging Dimension Weights in a Conceptual Spaces Model of Concept Combination}\n\n\\author{Martha Lewis \\and Jonathan Lawry \\institute{University of Bristol, England, email: martha.lewis@bristol.ac.uk, j.lawry@bristol.ac.uk} }\n\n\\maketitle\n\\bibliographystyle{AISB}\n\n\\begin{abstract}\nWe investigate the generation of new concepts from combinations of properties as an artificial language develops. To do so, we have developed a new framework for conjunctive concept combination. This framework gives a semantic grounding to the weighted sum approach to concept combination seen in the literature. We implement the framework in a multi-agent simulation of language evolution and show that shared combination weights emerge. The expected value and the variance of these weights across agents may be predicted from the distribution of elements in the conceptual space, as determined by the underlying environment, together with the rate at which agents adopt others' concepts. When this rate is smaller, the agents are able to converge to weights with lower variance. However, the time taken to converge to a steady state distribution of weights is longer.\n\\end{abstract}\n\n\\section{INTRODUCTION}\nHumans are skilled at making sense of novel combinations of concepts, so to create artificial languages for implementation in AI systems, we must model this ability. Standard approaches to combining concepts, e.g. fuzzy set theory, have been shown to be inadequate \\cite{osh1981}. Concepts formed through the combination of properties frequently have `emergent attributes' \\cite{hamp1987} which cannot be explicated by decomposing the label into its constituent parts.  We have developed a model of concept combination within the label semantics framework as given in \\cite{lawry2009, lewishierarchical}. The model is inspired by and reflects results in \\cite{hamp1987}, in which membership in a compound concept can be rendered as the weighted sum of memberships in individual concepts, however, it can also account for emergent attributes, where e.g. importance in a conjunctive concept is greater than the importance of an attribute in the constituent concepts. We implement a simple version of this model in a multi-agent simulation of language users, and show that the agents converge to shared combination weights, allowing effective communication. These weights are determined by the distribution of objects in the agents' conceptual space. This provides a theoretical grounding to the proposal seen in the literature \\cite{gard2004,hamp1987,lakoffhedges,zadehhedges} that complex concepts can be characterised as weighted sums of attributes. Further, it relates the weights in the combined concept to the external world. In this paper, we firstly summarise the theoretical framework we use (section \\ref{sec:bkg}), and in section \\ref{sec:cmp} give a brief account of our model of concept combination. In section \\ref{sec:expts}, we implement a simple version of our model in a multi-agent simulation of a community of language users in order to examine whether an how such a community is able to converge to shared combination weights. We give simulation methods and results, and analyse the behaviour of the agents. Finally, section \\ref{sec:disc} discusses our results and gives an indication of future work.\n\n\\section{BACKGROUND}\n\\label{sec:bkg}\nWe model concepts within the label semantics framework \\cite{lawry2004, lawry2009}, combined with prototype theory \\cite{rosch} and the conceptual spaces model of concepts \\cite{gard2004}. Prototype theory offers an alternative to the classical theory of concepts, basing categorization on proximity to a prototype. This approach is based on experimental results where human subjects were found to view membership in a concept as a matter of degree, with some objects having higher membership than others \\cite{rosch}. Fuzzy set theory \\cite{zadeh1965}, in which an object $x$ has a graded membership $\\mu_L(x)$ in a concept $L$, was proposed as a formalism for prototype theory. However, numerous objections to its suitability have been made \\cite{ hamp, hamp1987, kp, osh1981, smith}. \n\nConceptual spaces theory renders concepts as convex regions of a \\emph{conceptual space} - a geometrical structure with quality dimensions and a distance metric. Examples are: the RGB colour cube, pictured in figure \\ref{fig:rgbcube}; physical dimensions of height, breadth and depth; or the taste tetrahedron. Since concepts are convex regions of such spaces, the centroid of such a region can naturally be viewed as the prototype of the concept.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.3\\textwidth]{rgbcube.png}\n\\caption{The RGB cube represents colours in three dimensions of Red, Green and Blue. A colour concept such as `purple' can be represented as a region of this conceptual space.}\n\\label{fig:rgbcube}\n\\end{figure}\n\nLabel semantics proposes that agents use a set of labels $LA = \\{L_1, ..., L_n\\}$ to describe a conceptual space $\\Omega$ with distance metric $d(x, x')$. Labels $L_i$ are associated with prototypes $P_i \\subseteq \\Omega$ and uncertain thresholds ${\\varepsilon}_i$, drawn from probability distributions $\\delta_{{\\varepsilon}_i}$. The threshold ${\\varepsilon}_i$ captures the notion that an element $x \\in \\Omega$ is sufficiently close to $P_i$  to be labelled $L_i$. The membership of an object $x$ in a concept $L_i$ is quantified by $\\mu_{L_i}(x)$, given by \n\n", "index": 1, "text": "\n\\[\n\\mu_{L_i}(x) = P(d(x, P_i) \\leq {\\varepsilon}_i) = \\int_{d(x, P_i)}^\\infty  \\delta_{{\\varepsilon}_i}({\\varepsilon}_i)\\mathrm{d}{\\varepsilon}_i \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mu_{L_{i}}(x)=P(d(x,P_{i})\\leq{\\varepsilon}_{i})=\\int_{d(x,P_{i})}^{\\infty}%&#10;\\delta_{{\\varepsilon}_{i}}({\\varepsilon}_{i})\\mathrm{d}{\\varepsilon}_{i}\" display=\"block\"><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><msub><mi>P</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><msub><mi>\u03b5</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><msub><mi>P</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup><msub><mi>\u03b4</mi><msub><mi>\u03b5</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03b5</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">d</mi><msub><mi>\u03b5</mi><mi>i</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nwhere $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$.\n\n\\end{thm}\n\nWe may further combine such compound concepts ${\\theta}, {\\varphi}$ in a higher level binary space.\nThen, again under certain constraints, $ \\tilde{\\theta}\\bullet \\tilde{\\varphi}$ can be expressed in the continuous space as a weighted sum of ${\\theta}$ and ${\\varphi}$.\n\\begin{thm}[Conjunction of Compound Concepts]\n\\label{conjthm}\n Let $\\tilde{\\theta} \\bullet \\tilde{\\varphi} = <\\!\\!\\{(1,1)\\}, H_{\\vec{w}}, \\delta\\!\\!>$, where $\\theta$ and $\\varphi$ are compound concepts as described in theorem \\ref{thm:sumthm}, so that $\\theta$ is characterised by membership function $\\mu_{{\\theta}}(\\vec{x})=\\sum_{i=1}^n \\frac{\\lambda_{\\theta_i}}{\\lambda_{\\theta_T}} \\mu_{\\pm L_i}(x_i)$ for $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$, and $\\varphi$ is similarly characterised. Then \n", "itemtype": "equation", "pos": 9993, "prevtext": "\n\nLabels can then be described as $L_i = <\\!\\!P_i, d(x, x'), \\delta_{{\\varepsilon}_i}\\!\\!>$. We illustrate this idea in figure \\ref{fig:pnth}.\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype-threshold representation of a concept $L_i$. The conceptual space has dimensions $x_1$ and $x_2$. The concept has prototype $P_i$ and threshold ${\\varepsilon}_i$. The uncertainty about the threshold is represented by the dotted line. Element $a$ in the conceptual space is within the threshold, so it is appropriate to assert `$a$ is $L_i$'. Element $b$ is outside the threshold, so it is not appropriate to assert `$b$ is $L_i$'.}\n\\label{fig:pnth}\n\\end{figure}\n\n\n\\section{A HIERARCHICAL MODEL OF CONCEPT COMPOSITION}\n\\label{sec:cmp}\nExperiments in the psychological literature  propose that human concept combination can in many cases be modelled as a weighted sum of attributes such as `has feathers', `has a beak' (for the concept `Bird') \\cite{hamp1987}. These attributes differ from quality dimensions in conceptual spaces: they tend to be binary, complex, and multidimensional in themselves. We therefore view each attribute as a label in a continuous conceptual space $\\Omega_i$ and combine these labels in a binary conceptual space $\\{0,1\\}^n$ illustrated in figure \\ref{fig:binspace}. In this binary conceptual space, a conjunction of such labels ${\\alpha} = \\bigwedge_{i = 1}^n\\pm L_i$ maps to a binary vector $\\vec{y}_\\alpha$ taking value $1$ for positive labels $L_i$ and $0$ for negated labels $\\neg L_i$ (figure \\ref{fig:binspace3}).\n\\begin{figure}[h!]\n\\small\n  \\centering  \n    \\caption{Combining labels in a binary space}\n\\label{fig:binspace}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype for ${\\alpha} = L_1 \\land L_2 \\land L_3$ and weighted dimensions in binary space.}\n\\label{fig:binspace3}\n\\end{figure}\n\n We treat membership in ${\\alpha}$ in the binary conceptual space within the label semantics framework. So ${\\alpha}$ is described in the binary space by $\\tilde{\\alpha}=<\\!\\!\\vec{y}_\\alpha, d(\\vec{y}, \\vec{y}'), \\delta\\!\\!>$ as before, and $\\mu_{\\alpha}(y) = \\int_{d(y, y_\\alpha)}^\\infty  \\delta_{{\\varepsilon}}({\\varepsilon})\\mathrm{d}{\\varepsilon}$. Since the dimensions of the space are weighted, some are considered more important than others. The presence or absence of some attributes may be relaxed. For example, `Bird' might be characterised by (among others) the attributes `has feathers', `has wings', `flies'. The attributes `has wings' and `has feathers' should be given more importance than `flies'. This is because various species of birds do not fly, so this attribute may be relaxed whilst still allowing something to be categorised as a bird. The effect this has is to create elliptical regions of the conceptual space, as illustrated in figure \\ref{fig:binspace4}.\n\n\\begin{figure}[h!]\n\\centering\n    \\caption{Prototype for $\\alpha = L_1 \\land L_2$ and weighted dimensions in a two dimensional binary space, together with the threshold ${\\varepsilon}$ for $\\alpha$. The point $(0, 1)$, indicated by an open circle, can be considered to be an instance of the concept for which $y_\\alpha$ is the prototype.}\n\\label{fig:binspace4}\n\\end{figure}\n\nThe distance metric between two vectors $\\vec{y},\\vec{y}^\\prime$ in the binary space $\\{0,1\\}^n$ is written $H_{\\vec{\\lambda}}(\\vec{y},\\vec{y}^\\prime)$ and defined as a weighted city block metric. \n\nThen, under certain constraints, membership in the combined concept $\\alpha = \\bigwedge_{i = 1}^n\\pm L_i$ is equal to the weighted sum of membership in each of the $L_i$. This is stated in the following theorem:\n\n\n\n\n\n\n\n\\begin{thm}[Compound Concepts]\n\\label{thm:sumthm}\nLet $L_i$ be attributes described by membership functions $\\mu_{L_i}(x_i)$ in conceptual spaces $\\Omega_i$. Let $\\alpha$ be a conjunction of such attributes (or their negation):  $\\alpha=\\bigwedge_{i=1}^n \\pm L_i$. If we combine these labels in a binary space $\\{0,1\\}^n$ with $\\tilde{\\alpha}=<\\!\\!\\vec{y}_\\alpha, H_{\\vec{\\lambda}}, U(0,\\lambda_T)\\!\\!>$ where $\\lambda_T = \\sum_{i = 1}^n \\lambda_i$, then we may calculate the membership in $\\alpha$ in the space $\\Omega_1 \\times ... \\times \\Omega_n$ by:\n\n", "index": 3, "text": "\\begin{gather*}\n\\mu_{{\\alpha}}(\\vec{x})=\\sum_{i=1}^n \\frac{\\lambda_i}{\\lambda_T} \\mu_{\\pm L_i}(x_i)\n\\end{gather*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{{\\alpha}}(\\vec{x})=\\sum_{i=1}^{n}\\frac{\\lambda_{i}}{\\lambda_%&#10;{T}}\\mu_{\\pm L_{i}}(x_{i})\" display=\"block\"><mrow><mrow><msub><mi>\u03bc</mi><mi>\u03b1</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mfrac><msub><mi>\u03bb</mi><mi>i</mi></msub><msub><mi>\u03bb</mi><mi>T</mi></msub></mfrac><mo>\u2062</mo><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mi>i</mi></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nwhere $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$.\n\\end{thm}\n\nThese results show that under the constraint ${\\varepsilon} \\sim U(0,\\lambda_T)$, combining labels in a weighted binary conceptual space leads naturally to the creation of compound concepts as weighted sums of individual labels, reflecting results in \\cite{hamp1987}. An important aspect of these results is that non-compositional phenomena are seen, such as emergent attributes. These are attributes that become more important in the conjunction of two concepts than in either of the constituent concepts. A specific example seen in \\cite{hamp1987} is that the attribute`talks' becomes more important in the conjunction `Birds that are Pets' than in either `Birds' or `Pets'. Relaxing the constraint ${\\varepsilon} \\sim U(0,\\lambda_T)$ allows us to account for phenomena such as emergent attributes and overextension of concepts. In the current paper, however, we concentrate on a simple weighted sum combination and examine the properties of this type of combination in multi-agent simulations.\n\n\\section{CONVERGENCE OF DIMENSION WEIGHTS ACROSS A POPULATION}\n\\label{sec:expts}\nWe implement a simple version of the hierarchical model of concept combination in a multi-agent simulation of agents playing a series of language games, similar to those used in \\cite{belp}. We investigate how agents using compound concepts $\\alpha$ in a conceptual space converge to a shared weighting of the constituent concepts $L_i$. Agents do indeed converge to a shared weighting, which is dependent on the distribution of objects in the environment and also on the rate at which they move towards other agents' concepts. Section \\ref{sec:methods} describes the methods and simulation set-up. Section \\ref{sec:simulations} gives simulation results, and section \\ref{sec:analysis} gives an analysis of the results.\n\n\\subsection{Methods}\n\\label{sec:methods} \nConsider agents each with labels $L_1 = <\\!\\!P_1, d(x,y), \\delta_1\\!\\!> \\in \\Omega_1$, $L_2=<\\!\\!P_2, d(x,y), \\delta_2\\!\\!> \\in \\Omega_2$. We assume that agents combine these two labels as in section \\ref{sec:cmp} - i.e., in a binary space $\\{0,1\\}^2$ with weight vector $\\vec{\\lambda} = (\\lambda_1, \\lambda_2)^\\top$ and where the threshold in the binary space ${\\varepsilon}$ has distribution $\\delta = U(0, \\lambda_T)$, where $\\lambda_T = \\lambda_1 + \\lambda_2$. Then, membership in the conjunction $L_1 \\land L_2$ in the space $\\Omega_1 \\times \\Omega_2$ may be calculated as a weighted sum of membership in the individual spaces. W.l.o.g. we assume that $\\lambda_T = 1$. We therefore have  $\\mu_{L_1 \\land L_2}(\\vec{x}) = \\lambda \\mu_{L_1}(x_1) + (1 - \\lambda) \\mu_{L_2}(x_2)$.\n\nTo investigate how these weights are to be determined, we run simulations in which agents with equal labels but randomly initiated weights engage in a series of dialogues about elements in the conceptual space, adjusting their weights after each dialogue is completed.\n\n\\subsubsection{Assertion algorithm}\nAgents are equipped with shared labels $L_1 \\in \\Omega_1 = [0,1]$ and $L_2 \\in \\Omega_2 = [0,1]$, and a weight $\\lambda$. At each timestep agents are paired into speaker and listener agents. Each pair of agents is shown an element $x \\in \\Omega_1 \\times \\Omega_2 = [0,1]^2$. The speaker agent asserts one of \n\n", "itemtype": "equation", "pos": 10994, "prevtext": "\nwhere $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$.\n\n\\end{thm}\n\nWe may further combine such compound concepts ${\\theta}, {\\varphi}$ in a higher level binary space.\nThen, again under certain constraints, $ \\tilde{\\theta}\\bullet \\tilde{\\varphi}$ can be expressed in the continuous space as a weighted sum of ${\\theta}$ and ${\\varphi}$.\n\\begin{thm}[Conjunction of Compound Concepts]\n\\label{conjthm}\n Let $\\tilde{\\theta} \\bullet \\tilde{\\varphi} = <\\!\\!\\{(1,1)\\}, H_{\\vec{w}}, \\delta\\!\\!>$, where $\\theta$ and $\\varphi$ are compound concepts as described in theorem \\ref{thm:sumthm}, so that $\\theta$ is characterised by membership function $\\mu_{{\\theta}}(\\vec{x})=\\sum_{i=1}^n \\frac{\\lambda_{\\theta_i}}{\\lambda_{\\theta_T}} \\mu_{\\pm L_i}(x_i)$ for $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$, and $\\varphi$ is similarly characterised. Then \n", "index": 5, "text": "\n\\[ \n\\mu_{\\tilde{\\theta}\\bullet\\tilde{\\varphi}}(\\vec{x}) = \\sum_{i=1}^n (\\frac{w_1 \\lambda_{\\varphi_T} \\lambda_{\\theta_i} + w_2 \\lambda_{\\theta_T} \\lambda_{\\varphi_i}}{w_T \\lambda_{\\theta_T} \\lambda_{\\varphi_T}}) \\mu_{\\pm L_i}(\\vec{x})\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\mu_{\\tilde{\\theta}\\bullet\\tilde{\\varphi}}(\\vec{x})=\\sum_{i=1}^{n}(\\frac{w_{1}%&#10;\\lambda_{\\varphi_{T}}\\lambda_{\\theta_{i}}+w_{2}\\lambda_{\\theta_{T}}\\lambda_{%&#10;\\varphi_{i}}}{w_{T}\\lambda_{\\theta_{T}}\\lambda_{\\varphi_{T}}})\\mu_{\\pm L_{i}}(%&#10;\\vec{x})\" display=\"block\"><mrow><mrow><msub><mi>\u03bc</mi><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2219</mo><mover accent=\"true\"><mi>\u03c6</mi><mo stretchy=\"false\">~</mo></mover></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mfrac><mrow><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03c6</mi><mi>T</mi></msub></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03b8</mi><mi>i</mi></msub></msub></mrow><mo>+</mo><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03b8</mi><mi>T</mi></msub></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03c6</mi><mi>i</mi></msub></msub></mrow></mrow><mrow><msub><mi>w</mi><mi>T</mi></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03b8</mi><mi>T</mi></msub></msub><mo>\u2062</mo><msub><mi>\u03bb</mi><msub><mi>\u03c6</mi><mi>T</mi></msub></msub></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mi>i</mi></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nwhere the membership in the compound concept is determined by the weighted sum of the memberships in the constituent concepts.\n\n", "itemtype": "equation", "pos": 14560, "prevtext": "\nwhere $\\vec{x} \\in \\Omega_1 \\times ... \\times \\Omega_n$, $x_i \\in \\Omega_i$.\n\\end{thm}\n\nThese results show that under the constraint ${\\varepsilon} \\sim U(0,\\lambda_T)$, combining labels in a weighted binary conceptual space leads naturally to the creation of compound concepts as weighted sums of individual labels, reflecting results in \\cite{hamp1987}. An important aspect of these results is that non-compositional phenomena are seen, such as emergent attributes. These are attributes that become more important in the conjunction of two concepts than in either of the constituent concepts. A specific example seen in \\cite{hamp1987} is that the attribute`talks' becomes more important in the conjunction `Birds that are Pets' than in either `Birds' or `Pets'. Relaxing the constraint ${\\varepsilon} \\sim U(0,\\lambda_T)$ allows us to account for phenomena such as emergent attributes and overextension of concepts. In the current paper, however, we concentrate on a simple weighted sum combination and examine the properties of this type of combination in multi-agent simulations.\n\n\\section{CONVERGENCE OF DIMENSION WEIGHTS ACROSS A POPULATION}\n\\label{sec:expts}\nWe implement a simple version of the hierarchical model of concept combination in a multi-agent simulation of agents playing a series of language games, similar to those used in \\cite{belp}. We investigate how agents using compound concepts $\\alpha$ in a conceptual space converge to a shared weighting of the constituent concepts $L_i$. Agents do indeed converge to a shared weighting, which is dependent on the distribution of objects in the environment and also on the rate at which they move towards other agents' concepts. Section \\ref{sec:methods} describes the methods and simulation set-up. Section \\ref{sec:simulations} gives simulation results, and section \\ref{sec:analysis} gives an analysis of the results.\n\n\\subsection{Methods}\n\\label{sec:methods} \nConsider agents each with labels $L_1 = <\\!\\!P_1, d(x,y), \\delta_1\\!\\!> \\in \\Omega_1$, $L_2=<\\!\\!P_2, d(x,y), \\delta_2\\!\\!> \\in \\Omega_2$. We assume that agents combine these two labels as in section \\ref{sec:cmp} - i.e., in a binary space $\\{0,1\\}^2$ with weight vector $\\vec{\\lambda} = (\\lambda_1, \\lambda_2)^\\top$ and where the threshold in the binary space ${\\varepsilon}$ has distribution $\\delta = U(0, \\lambda_T)$, where $\\lambda_T = \\lambda_1 + \\lambda_2$. Then, membership in the conjunction $L_1 \\land L_2$ in the space $\\Omega_1 \\times \\Omega_2$ may be calculated as a weighted sum of membership in the individual spaces. W.l.o.g. we assume that $\\lambda_T = 1$. We therefore have  $\\mu_{L_1 \\land L_2}(\\vec{x}) = \\lambda \\mu_{L_1}(x_1) + (1 - \\lambda) \\mu_{L_2}(x_2)$.\n\nTo investigate how these weights are to be determined, we run simulations in which agents with equal labels but randomly initiated weights engage in a series of dialogues about elements in the conceptual space, adjusting their weights after each dialogue is completed.\n\n\\subsubsection{Assertion algorithm}\nAgents are equipped with shared labels $L_1 \\in \\Omega_1 = [0,1]$ and $L_2 \\in \\Omega_2 = [0,1]$, and a weight $\\lambda$. At each timestep agents are paired into speaker and listener agents. Each pair of agents is shown an element $x \\in \\Omega_1 \\times \\Omega_2 = [0,1]^2$. The speaker agent asserts one of \n\n", "index": 7, "text": "\\begin{align*}\n\\alpha_1 &= L_1 \\land L_2\\\\\n\\alpha_2 &= L_1 \\land \\neg L_2\\\\\n\\alpha_3 &= \\neg L_1 \\land L_2\\\\\n\\alpha_4 &= \\neg L_1 \\land \\neg L_2\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{1}\" display=\"inline\"><msub><mi>\u03b1</mi><mn>1</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=L_{1}\\land L_{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>L</mi><mn>1</mn></msub><mo>\u2227</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{2}\" display=\"inline\"><msub><mi>\u03b1</mi><mn>2</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=L_{1}\\land\\neg L_{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>L</mi><mn>1</mn></msub><mo>\u2227</mo><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{3}\" display=\"inline\"><msub><mi>\u03b1</mi><mn>3</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\neg L_{1}\\land L_{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>\u2227</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha_{4}\" display=\"inline\"><msub><mi>\u03b1</mi><mn>4</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\neg L_{1}\\land\\neg L_{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>\u2227</mo><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nThe concept $\\alpha_i$ asserted is that for which $\\mu_{\\alpha_i}(x)$ is maximal. Note that this implies that if $\\alpha_i$ asserted then $\\mu_{\\alpha_i}(x) \\geq 0.5$.\n\n\\subsubsection{Updating algorithm}\n\\label{sec:updating}\nWe compare two different updating algorithms. The first implements the idea that the listener agent updates its concepts when the agent's belief in the appropriateness of a compound label, $\\mu_{\\alpha_i}(x)$, is less than the reliability of the speaker as measured by a weight $w \\in [0, 1]$. So if $\\mu_{\\alpha_i}(x) \\leq w$ the listener agent updates its label set.\n\nThe update consists in moving the dimension weight $\\lambda$ towards the value $A$ which satisfies $\\mu_{\\theta}(x) = w$, where  \n", "itemtype": "equation", "pos": 14847, "prevtext": "\nwhere the membership in the compound concept is determined by the weighted sum of the memberships in the constituent concepts.\n\n", "index": 9, "text": "\\begin{align*}\n\\mu_{\\alpha_1}(x) &= \\lambda \\mu_{L_1}(x_1) + (1 - \\lambda) \\mu_{L_2}(x_2)\\\\\n\\mu_{\\alpha_2}(x) &= \\lambda \\mu_{L_1}(x_1) + (1 - \\lambda)(1 -  \\mu_{L_2}(x_2))\\\\\n\\mu_{\\alpha_3}(x) &= \\lambda (1 - \\mu_{L_1}(x_1)) + (1 - \\lambda) \\mu_{L_2}(x_2)\\\\\n\\mu_{\\alpha_4}(x) &= \\lambda (1 - \\mu_{L_1}(x_1)) + (1 - \\lambda)(1 -  \\mu_{L_2}(x_2))\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{\\alpha_{1}}(x)\" display=\"inline\"><mrow><msub><mi>\u03bc</mi><msub><mi>\u03b1</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda\\mu_{L_{1}}(x_{1})+(1-\\lambda)\\mu_{L_{2}}(x_{2})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{\\alpha_{2}}(x)\" display=\"inline\"><mrow><msub><mi>\u03bc</mi><msub><mi>\u03b1</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda\\mu_{L_{1}}(x_{1})+(1-\\lambda)(1-\\mu_{L_{2}}(x_{2}))\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{\\alpha_{3}}(x)\" display=\"inline\"><mrow><msub><mi>\u03bc</mi><msub><mi>\u03b1</mi><mn>3</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda(1-\\mu_{L_{1}}(x_{1}))+(1-\\lambda)\\mu_{L_{2}}(x_{2})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{\\alpha_{4}}(x)\" display=\"inline\"><mrow><msub><mi>\u03bc</mi><msub><mi>\u03b1</mi><mn>4</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda(1-\\mu_{L_{1}}(x_{1}))+(1-\\lambda)(1-\\mu_{L_{2}}(x_{2}))\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nHowever, it is possible for $A < 0$ or $A > 1$, in which cases we set $A = 0$ or $A = 1$, giving us:\n\n", "itemtype": "equation", "pos": 15931, "prevtext": "\nThe concept $\\alpha_i$ asserted is that for which $\\mu_{\\alpha_i}(x)$ is maximal. Note that this implies that if $\\alpha_i$ asserted then $\\mu_{\\alpha_i}(x) \\geq 0.5$.\n\n\\subsubsection{Updating algorithm}\n\\label{sec:updating}\nWe compare two different updating algorithms. The first implements the idea that the listener agent updates its concepts when the agent's belief in the appropriateness of a compound label, $\\mu_{\\alpha_i}(x)$, is less than the reliability of the speaker as measured by a weight $w \\in [0, 1]$. So if $\\mu_{\\alpha_i}(x) \\leq w$ the listener agent updates its label set.\n\nThe update consists in moving the dimension weight $\\lambda$ towards the value $A$ which satisfies $\\mu_{\\theta}(x) = w$, where  \n", "index": 11, "text": "\n\\[\nA = \\frac{w - \\mu_{L_2}(x_2)}{\\mu_{\\pm L_1}(x_1) - \\mu_{\\pm L_2}(x_2)}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"A=\\frac{w-\\mu_{L_{2}}(x_{2})}{\\mu_{\\pm L_{1}}(x_{1})-\\mu_{\\pm L_{2}}(x_{2})}\" display=\"block\"><mrow><mi>A</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nThe listener agent updates the weight $\\lambda$ to $\\lambda'$ by:\n\n", "itemtype": "equation", "pos": 16110, "prevtext": "\nHowever, it is possible for $A < 0$ or $A > 1$, in which cases we set $A = 0$ or $A = 1$, giving us:\n\n", "index": 13, "text": "\\begin{align*}\nA = \n\\begin{cases}\n1 & \\quad\\text{if }\\frac{w - \\mu_{L_2}(x_2)}{\\mu_{\\pm L_1}(x_1) - \\mu_{\\pm L_2}(x_2)} >1\\\\\n0 & \\quad\\text{if }\\frac{w - \\mu_{L_2}(x_2)}{\\mu_{\\pm L_1}(x_1) - \\mu_{\\pm L_2}(x_2)} <0\\\\\n\\frac{w - \\mu_{L_2}(x_2)}{\\mu_{\\pm L_1}(x_1) - \\mu_{\\pm L_2}(x_2)} &\\quad \\text{otherwise}\n\\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A=\\begin{cases}1&amp;\\quad\\text{if }\\frac{w-\\mu_{L_{2}}(x_{2})}{\\mu_%&#10;{\\pm L_{1}}(x_{1})-\\mu_{\\pm L_{2}}(x_{2})}&gt;1\\\\&#10;0&amp;\\quad\\text{if }\\frac{w-\\mu_{L_{2}}(x_{2})}{\\mu_{\\pm L_{1}}(x_{1})-\\mu_{\\pm L%&#10;_{2}}(x_{2})}&lt;0\\\\&#10;\\frac{w-\\mu_{L_{2}}(x_{2})}{\\mu_{\\pm L_{1}}(x_{1})-\\mu_{\\pm L_{2}}(x_{2})}&amp;%&#10;\\quad\\text{otherwise}\\end{cases}\" display=\"inline\"><mrow><mi>A</mi><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mn>1</mn></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded lspace=\"10pt\" width=\"+10pt\"><mtext>if\u00a0</mtext></mpadded><mo>\u2062</mo><mfrac><mrow><mi>w</mi><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow><mo>&gt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded lspace=\"10pt\" width=\"+10pt\"><mtext>if\u00a0</mtext></mpadded><mo>\u2062</mo><mfrac><mrow><mi>w</mi><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow><mo>&lt;</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mfrac><mrow><mi>w</mi><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mo>\u00b1</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mtd><mtd columnalign=\"left\"><mpadded lspace=\"10pt\" width=\"+10pt\"><mtext>otherwise</mtext></mpadded></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nWe measure the convergence between $\\lambda_i$ across the agents as the standard deviation (SD) of the $\\lambda_i$. \n\nWe also introduce a second updating algorithm. This is similar to the first with the exception that the criterion for updating is that $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. This means that if an agent with low reliability makes an assertion, the listener agent shifts the dimension weight $\\lambda$ to reduce the appropriateness of the assertion $\\alpha_i$.\n\n\\subsubsection{Simulation Details}\nAgents have labels $L_1 = L_2 = <\\!\\!1, d, U[0,1]\\!\\!>$, where $d$ is Euclidean distance, to describe the conceptual space $\\Omega = \\Omega_1 \\times \\Omega_2 = [0,1]^2$. In this case, we have $\\mu_{L_i}(x) = x_i$. Simulations are run with $10$ agents for $2,000$ timesteps with increment $h = 10^{-3}$ unless otherwise indicated.  At each timestep, each agent talks to every other agent, in a randomised order. Simulation results are averaged across 25 runs. \n\nParameters varied are the distribution of elements within the conceptual space and the reliability of the agents. So, for example, one simulation might include elements sampled uniformly across the whole conceptual space, whereas another might include elements sampled uniformly from one half of the space. This difference in distribution leads to differences in the combination weights.\n\n\\subsection{Simulation Results}\n\\label{sec:simulations}\n\\subsubsection{Updating model 1: $\\mu_{\\alpha_i}(\\vec{x}) < w$}\nWithin this updating model, the listener agent updates only when $\\mu_{\\alpha_i}(\\vec{x}) < w$. We find that when the agent reliability $w > 0.5$, agents are able to converge to a shared weight $\\lambda$.  The weight to which agents converge is dependent on the distribution of objects in the environment, and the reliability $w$ of the agents. When $w = 1$ for all agents, and $x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$, so that elements are encountered within half of the total space $\\Omega = [0,1]^2$, the agents converge to a value of $\\lambda = 0.5$, as seen in figure \\ref{fig:fig1all}.\n\nze\n\n\nWhen the distribution of elements in the environment is changed, $\\lambda$ may converge to a different value. For example, changing the distribution of the elements in the space to $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, with $w = 1$ for all agents, results in a final value of $\\lambda = 0.25$, illustrated in figure \\ref{fig:fig2all}.\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.65\\columnwidth}\n\n                \\hspace{5pt}\n                \\includegraphics[width=\\textwidth]{fig2.pdf}\n                \\caption{SD and mean $\\lambda$ over time.}\n                \\label{fig:fig2}\n        \\end{subfigure}\n\n\n\n\n\n\n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{mlfig2.pdf}\n                \\caption{Behaviour of individual $\\lambda_i$ over time (results from just one simulation).}\n                \\label{fig:mlfig2}\n        \\end{subfigure}\n\t\\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, $w = 1$ for all agents.}\n\t\\label{fig:fig2all}\n\\end{figure}\n\nThe final value of $\\lambda$ may also be dependent on the reliability of the agents as parameterised by $w$. For some distributions, the value of $w$ does not affect the value of $\\lambda$ to which agents converge. In others, the value of $w$ alters the weighting $\\lambda$. This is illustrated in figure \\ref{fig:cmp1}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.65\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeq1.pdf}\n                \\caption{$x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$. Values of $w$ vary as indicated.}\n                \\label{fig:cmpeqAPD1}\n        \\end{subfigure}\n        ~ \n        \\begin{subfigure}[t]{0.65\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeq075.pdf}\n                \\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$. Values of $w$ vary as indicated.}\n                \\label{fig:cmpeqmean1}\n        \\end{subfigure}\n\t\\caption{SD and mean $\\lambda$ at time $t = 2000$ for different values of $w$. For $x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$, provided that $w > 0.5$, agents converge to $\\lambda = 0.5$ (LHS). In contrast, for $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, agents converge to varying values depending on the value of $w$ (RHS).}\n\t\\label{fig:cmp1}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Updating model 2: $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$}\nWe also introduce a second updating model, in which the listener agent updates whenever $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. Although this model is slightly less realistic, it is more amenable to analysis, and so we use this as a starting point for the analysis of these systems. Again, each set of simulations is run 25 times and results are averaged. Figure \\ref{fig:cmpeq075} compares the results of simulations run using the two different assertion models, where $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$.\n\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeqltAPD.pdf}\n                \\caption{SD at time $t = 2000$ for different values of $w$ under the two different updating algorithms.}\n                \\label{fig:cmpeqAPD075}\n        \\end{subfigure}\n        ~ \n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeqltmean.pdf}\n                \\caption{Mean $\\lambda$ at time $t = 2000$ for different values of $w$ under the two different updating algorithms.}\n                \\label{fig:cmpeqmean075}\n        \\end{subfigure}\n\t\\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, values of $w$ vary as indicated. The population of agents converges to different values of $\\lambda$ depending on the updating algorithm used.}\n\t\\label{fig:cmpeq075}\n\\end{figure}\n\nWhen the updating condition requires that $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$, agents converge to a shared weight $\\lambda$ even when their reliability $w \\leq 0.5$. However, the values of $\\lambda$ to which agents converge are not the same as those converged to under the first assertion algorithm.\n\nThese results show that the combination weights that the agents converge to are dependent on firstly the distribution of elements in the conceptual space, as determined by the environment, and secondly the reliability of the agents in the space. We go on to give an analysis of these results, and to prove some results relating the values of the final weights to the distribution of objects within the conceptual space.\n\n\n\\subsection{Analysis}\n\\label{sec:analysis}\nWe wish to analyse the results seen in section \\ref{sec:simulations} in order to predict the value to which $\\lambda$  will converge and also the extent to which it will converge across agents as measured by the standard deviation of the $\\lambda_i$ across agents. To do so, we start with some analysis of the particular space and labels we have used before giving some more general results.\n\nWithin the results in section \\ref{sec:simulations}, agents have labels $L_1 = L_2 = <1, U[0,1]>$ to describe the conceptual space $\\Omega = [0,1]^2$. In this case, we have $\\mu_{L_i}(x) = x_i$. Each assertion $\\alpha_i$ is made exactly when each component $\\mu_{\\pm L_1}(x)>0.5$, $\\mu_{\\pm L_2}(x) >0.5$ (since otherwise another $\\alpha_j$ would be maximal). We can therefore split up the conceptual space into quadrants corresponding to where each $\\alpha_i$ is asserted, displayed in figure \\ref{fig:quadrants}. Each quadrant where $\\alpha_i$ is asserted is called $R_i$.\n\n\\begin{figure}[h!]\n\t \\centering\n\t\t\\vspace{10pt}\n\t \\caption{Each assertion $\\alpha_i$ is made when $\\vec{x} = (x_1, x_2)$ falls in $R_i$}\n\t\\label{fig:quadrants}\n\\end{figure}\n\nTo investigate the value to which the $\\lambda_i$ converge, we look at the quantity $(A - \\lambda)$. If $(A - \\lambda)$ is positive, $\\lambda$ will increase, and if it is negative, $\\lambda$ will decrease. We therefore look at the circumstances that lead to $\\lambda$ increasing or decreasing. We do this on a case by case basis depending on which assertion is being made.\n\n\\subsubsection*{Case: $\\alpha_1$ is asserted}\nWhen $\\alpha_1$ is asserted, $\\mu_{L_1}(x_1) = x_1 > 0.5$, $\\mu_{L_2}(x_2) = x_2 > 0.5$. We wish to know when $A > \\lambda$\n\n\n", "itemtype": "equation", "pos": 16508, "prevtext": "\nThe listener agent updates the weight $\\lambda$ to $\\lambda'$ by:\n\n", "index": 15, "text": "\n\\[\n\\lambda' = \\lambda + h(A - \\lambda)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\lambda^{\\prime}=\\lambda+h(A-\\lambda)\" display=\"block\"><mrow><msup><mi>\u03bb</mi><mo>\u2032</mo></msup><mo>=</mo><mrow><mi>\u03bb</mi><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\n$\\lambda$ is updated when $\\mu_{\\alpha_1} = \\lambda x_1 + (1 - \\lambda) x_2 < w$, i.e. when\n\n", "itemtype": "equation", "pos": 25078, "prevtext": "\n\nWe measure the convergence between $\\lambda_i$ across the agents as the standard deviation (SD) of the $\\lambda_i$. \n\nWe also introduce a second updating algorithm. This is similar to the first with the exception that the criterion for updating is that $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. This means that if an agent with low reliability makes an assertion, the listener agent shifts the dimension weight $\\lambda$ to reduce the appropriateness of the assertion $\\alpha_i$.\n\n\\subsubsection{Simulation Details}\nAgents have labels $L_1 = L_2 = <\\!\\!1, d, U[0,1]\\!\\!>$, where $d$ is Euclidean distance, to describe the conceptual space $\\Omega = \\Omega_1 \\times \\Omega_2 = [0,1]^2$. In this case, we have $\\mu_{L_i}(x) = x_i$. Simulations are run with $10$ agents for $2,000$ timesteps with increment $h = 10^{-3}$ unless otherwise indicated.  At each timestep, each agent talks to every other agent, in a randomised order. Simulation results are averaged across 25 runs. \n\nParameters varied are the distribution of elements within the conceptual space and the reliability of the agents. So, for example, one simulation might include elements sampled uniformly across the whole conceptual space, whereas another might include elements sampled uniformly from one half of the space. This difference in distribution leads to differences in the combination weights.\n\n\\subsection{Simulation Results}\n\\label{sec:simulations}\n\\subsubsection{Updating model 1: $\\mu_{\\alpha_i}(\\vec{x}) < w$}\nWithin this updating model, the listener agent updates only when $\\mu_{\\alpha_i}(\\vec{x}) < w$. We find that when the agent reliability $w > 0.5$, agents are able to converge to a shared weight $\\lambda$.  The weight to which agents converge is dependent on the distribution of objects in the environment, and the reliability $w$ of the agents. When $w = 1$ for all agents, and $x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$, so that elements are encountered within half of the total space $\\Omega = [0,1]^2$, the agents converge to a value of $\\lambda = 0.5$, as seen in figure \\ref{fig:fig1all}.\n\nze\n\n\nWhen the distribution of elements in the environment is changed, $\\lambda$ may converge to a different value. For example, changing the distribution of the elements in the space to $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, with $w = 1$ for all agents, results in a final value of $\\lambda = 0.25$, illustrated in figure \\ref{fig:fig2all}.\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.65\\columnwidth}\n\n                \\hspace{5pt}\n                \\includegraphics[width=\\textwidth]{fig2.pdf}\n                \\caption{SD and mean $\\lambda$ over time.}\n                \\label{fig:fig2}\n        \\end{subfigure}\n\n\n\n\n\n\n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{mlfig2.pdf}\n                \\caption{Behaviour of individual $\\lambda_i$ over time (results from just one simulation).}\n                \\label{fig:mlfig2}\n        \\end{subfigure}\n\t\\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, $w = 1$ for all agents.}\n\t\\label{fig:fig2all}\n\\end{figure}\n\nThe final value of $\\lambda$ may also be dependent on the reliability of the agents as parameterised by $w$. For some distributions, the value of $w$ does not affect the value of $\\lambda$ to which agents converge. In others, the value of $w$ alters the weighting $\\lambda$. This is illustrated in figure \\ref{fig:cmp1}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.65\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeq1.pdf}\n                \\caption{$x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$. Values of $w$ vary as indicated.}\n                \\label{fig:cmpeqAPD1}\n        \\end{subfigure}\n        ~ \n        \\begin{subfigure}[t]{0.65\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeq075.pdf}\n                \\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$. Values of $w$ vary as indicated.}\n                \\label{fig:cmpeqmean1}\n        \\end{subfigure}\n\t\\caption{SD and mean $\\lambda$ at time $t = 2000$ for different values of $w$. For $x_1 \\sim U[0,1]$, $x_2 \\sim U[0,0.5]$, provided that $w > 0.5$, agents converge to $\\lambda = 0.5$ (LHS). In contrast, for $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, agents converge to varying values depending on the value of $w$ (RHS).}\n\t\\label{fig:cmp1}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Updating model 2: $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$}\nWe also introduce a second updating model, in which the listener agent updates whenever $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. Although this model is slightly less realistic, it is more amenable to analysis, and so we use this as a starting point for the analysis of these systems. Again, each set of simulations is run 25 times and results are averaged. Figure \\ref{fig:cmpeq075} compares the results of simulations run using the two different assertion models, where $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$.\n\n\\begin{figure} [h!]\n        \\centering\n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeqltAPD.pdf}\n                \\caption{SD at time $t = 2000$ for different values of $w$ under the two different updating algorithms.}\n                \\label{fig:cmpeqAPD075}\n        \\end{subfigure}\n        ~ \n        \\begin{subfigure}[t]{0.7\\columnwidth}\n                \\centering\n                \\includegraphics[width=\\textwidth]{cmpeqltmean.pdf}\n                \\caption{Mean $\\lambda$ at time $t = 2000$ for different values of $w$ under the two different updating algorithms.}\n                \\label{fig:cmpeqmean075}\n        \\end{subfigure}\n\t\\caption{$x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, values of $w$ vary as indicated. The population of agents converges to different values of $\\lambda$ depending on the updating algorithm used.}\n\t\\label{fig:cmpeq075}\n\\end{figure}\n\nWhen the updating condition requires that $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$, agents converge to a shared weight $\\lambda$ even when their reliability $w \\leq 0.5$. However, the values of $\\lambda$ to which agents converge are not the same as those converged to under the first assertion algorithm.\n\nThese results show that the combination weights that the agents converge to are dependent on firstly the distribution of elements in the conceptual space, as determined by the environment, and secondly the reliability of the agents in the space. We go on to give an analysis of these results, and to prove some results relating the values of the final weights to the distribution of objects within the conceptual space.\n\n\n\\subsection{Analysis}\n\\label{sec:analysis}\nWe wish to analyse the results seen in section \\ref{sec:simulations} in order to predict the value to which $\\lambda$  will converge and also the extent to which it will converge across agents as measured by the standard deviation of the $\\lambda_i$ across agents. To do so, we start with some analysis of the particular space and labels we have used before giving some more general results.\n\nWithin the results in section \\ref{sec:simulations}, agents have labels $L_1 = L_2 = <1, U[0,1]>$ to describe the conceptual space $\\Omega = [0,1]^2$. In this case, we have $\\mu_{L_i}(x) = x_i$. Each assertion $\\alpha_i$ is made exactly when each component $\\mu_{\\pm L_1}(x)>0.5$, $\\mu_{\\pm L_2}(x) >0.5$ (since otherwise another $\\alpha_j$ would be maximal). We can therefore split up the conceptual space into quadrants corresponding to where each $\\alpha_i$ is asserted, displayed in figure \\ref{fig:quadrants}. Each quadrant where $\\alpha_i$ is asserted is called $R_i$.\n\n\\begin{figure}[h!]\n\t \\centering\n\t\t\\vspace{10pt}\n\t \\caption{Each assertion $\\alpha_i$ is made when $\\vec{x} = (x_1, x_2)$ falls in $R_i$}\n\t\\label{fig:quadrants}\n\\end{figure}\n\nTo investigate the value to which the $\\lambda_i$ converge, we look at the quantity $(A - \\lambda)$. If $(A - \\lambda)$ is positive, $\\lambda$ will increase, and if it is negative, $\\lambda$ will decrease. We therefore look at the circumstances that lead to $\\lambda$ increasing or decreasing. We do this on a case by case basis depending on which assertion is being made.\n\n\\subsubsection*{Case: $\\alpha_1$ is asserted}\nWhen $\\alpha_1$ is asserted, $\\mu_{L_1}(x_1) = x_1 > 0.5$, $\\mu_{L_2}(x_2) = x_2 > 0.5$. We wish to know when $A > \\lambda$\n\n\n", "index": 17, "text": "\\begin{align*}\n\\label{eq:gt}\nA &= \\frac{w - \\mu_{L_2}(x_2)}{\\mu_{L_1}(x_1) - \\mu_{L_2}(x_2)} = \\frac{w - x_2}{x_1 - x_2} \\geq \\lambda\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A\" display=\"inline\"><mi>A</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{w-\\mu_{L_{2}}(x_{2})}{\\mu_{L_{1}}(x_{1})-\\mu_{L_{2}}(x_{2}%&#10;)}=\\frac{w-x_{2}}{x_{1}-x_{2}}\\geq\\lambda\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>w</mi><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>w</mi><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac></mstyle><mo>\u2265</mo><mi>\u03bb</mi></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nThen if $(x_1 - x_2) > 0$ then $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_2$ is asserted}\nWhen $\\alpha_2$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_2} = \\lambda x_1 + (1 - \\lambda) (1 - x_2) < w$, i.e. when\n\n", "itemtype": "equation", "pos": 25318, "prevtext": "\n\n$\\lambda$ is updated when $\\mu_{\\alpha_1} = \\lambda x_1 + (1 - \\lambda) x_2 < w$, i.e. when\n\n", "index": 19, "text": "\n\\[\nw - x_2 \\geq \\lambda(x_1 - x_2)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"w-x_{2}\\geq\\lambda(x_{1}-x_{2})\" display=\"block\"><mrow><mrow><mi>w</mi><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>\u2265</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nThen if $(x_1 + x_2 - 1) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_3$ is asserted}\nWhen $\\alpha_3$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_3}(\\vec{x}) = \\lambda(1 -  x_1) + (1 - \\lambda) x_2 < w$, i.e. when\n\n", "itemtype": "equation", "pos": 25713, "prevtext": "\n\nThen if $(x_1 - x_2) > 0$ then $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_2$ is asserted}\nWhen $\\alpha_2$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_2} = \\lambda x_1 + (1 - \\lambda) (1 - x_2) < w$, i.e. when\n\n", "index": 21, "text": "\n\\[\nw -(1 -  x_2) \\geq \\lambda(x_1 + x_2 - 1)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"w-(1-x_{2})\\geq\\lambda(x_{1}+x_{2}-1)\" display=\"block\"><mrow><mrow><mi>w</mi><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nThen if $(1 - x_1 - x_2) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_4$ is asserted}\nWhen $\\alpha_4$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_4}(\\vec{x}) = \\lambda(1 -  x_1) + (1 - \\lambda) (1 - x_2) < w$, i.e. when\n\n", "itemtype": "equation", "pos": 26127, "prevtext": "\n\nThen if $(x_1 + x_2 - 1) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_3$ is asserted}\nWhen $\\alpha_3$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_3}(\\vec{x}) = \\lambda(1 -  x_1) + (1 - \\lambda) x_2 < w$, i.e. when\n\n", "index": 23, "text": "\n\\[\nw - x_2 \\geq \\lambda(1 - x_1 - x_2)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"w-x_{2}\\geq\\lambda(1-x_{1}-x_{2})\" display=\"block\"><mrow><mrow><mi>w</mi><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>\u2265</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nThen if $(x_2 - x_1) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment.  \n\nEach of these cases can be represented graphically, since the conditions are determined by the lines $x_1 = x_2$ and $x_1 = 1 - x_2$. This is illustrated in figure \\ref{fig:octants}. We call areas of the space where a positive update is made \\emph{positive regions} and areas of the space where negative updates are made \\emph{negative regions}.\n\n\\begin{figure}\n\t \\centering\n\t\t\\vspace{10pt}\n\t  \\caption{The type of update made when $\\vec{x} = (x_1, x_2)$ falls in each area of the space}\n\t\\label{fig:octants}\n\\end{figure}\n\nWe can now prove some results concerning the final value of $\\lambda$ across the population of agents.\n\n\\begin{thm}\nSuppose that agents have labels $L_1 = L_2 = <1, U(0,1)>$ and all agents have weight 1. Agents update their concepts according to the language game described using updating model 1. Suppose that there is a probability $p^+$ of $\\vec{x}$ falling in a positive region and probability $p^- = 1 - p^+$ of $\\vec{x}$ falling in a negative region. Then the expected value of $\\lambda$ converges to $p^+$\n\\end{thm}\n\n\\begin{proof}\nWhenever $\\vec{x}$ falls in the positive region, $A \\geq 1$ and hence we set $A = 1$. For example, suppose $\\vec{x} \\in R_1$. Then \n\n", "itemtype": "equation", "pos": 26541, "prevtext": "\n\nThen if $(1 - x_1 - x_2) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment. \n\n\\subsubsection*{Case: $\\alpha_4$ is asserted}\nWhen $\\alpha_4$ is asserted, $\\lambda$ is updated when $\\mu_{\\alpha_4}(\\vec{x}) = \\lambda(1 -  x_1) + (1 - \\lambda) (1 - x_2) < w$, i.e. when\n\n", "index": 25, "text": "\n\\[\nw - (1 - x_2) \\geq \\lambda(x_2 - x_1)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"w-(1-x_{2})\\geq\\lambda(x_{2}-x_{1})\" display=\"block\"><mrow><mrow><mi>w</mi><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>-</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nNow $1 - x_2 \\geq 0$ so the sign of $A$ is determined by $x_1-x_2$. If  $\\vec{x}$ falls in the positive quadrant then $x_1 > x_2$ so\n", "itemtype": "equation", "pos": 27960, "prevtext": "\n\nThen if $(x_2 - x_1) > 0$, $A \\geq \\lambda$, and the update is a positive increment. Otherwise the reverse holds, i.e. $A \\leq \\lambda$ and the update is a negative increment.  \n\nEach of these cases can be represented graphically, since the conditions are determined by the lines $x_1 = x_2$ and $x_1 = 1 - x_2$. This is illustrated in figure \\ref{fig:octants}. We call areas of the space where a positive update is made \\emph{positive regions} and areas of the space where negative updates are made \\emph{negative regions}.\n\n\\begin{figure}\n\t \\centering\n\t\t\\vspace{10pt}\n\t  \\caption{The type of update made when $\\vec{x} = (x_1, x_2)$ falls in each area of the space}\n\t\\label{fig:octants}\n\\end{figure}\n\nWe can now prove some results concerning the final value of $\\lambda$ across the population of agents.\n\n\\begin{thm}\nSuppose that agents have labels $L_1 = L_2 = <1, U(0,1)>$ and all agents have weight 1. Agents update their concepts according to the language game described using updating model 1. Suppose that there is a probability $p^+$ of $\\vec{x}$ falling in a positive region and probability $p^- = 1 - p^+$ of $\\vec{x}$ falling in a negative region. Then the expected value of $\\lambda$ converges to $p^+$\n\\end{thm}\n\n\\begin{proof}\nWhenever $\\vec{x}$ falls in the positive region, $A \\geq 1$ and hence we set $A = 1$. For example, suppose $\\vec{x} \\in R_1$. Then \n\n", "index": 27, "text": "\\[\n A = \\frac{1 - x_2}{x_1 - x_2}\n \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"A=\\frac{1-x_{2}}{x_{1}-x_{2}}\" display=\"block\"><mrow><mi>A</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nSo $A = 1$ and the update is $\\lambda_{n+1} = \\lambda_n + h(1 - \\lambda_n)$ \n \nIf  $\\vec{x}$ falls in the negative quadrant then $x_1 < x_2$ so\n\n", "itemtype": "equation", "pos": 28130, "prevtext": "\nNow $1 - x_2 \\geq 0$ so the sign of $A$ is determined by $x_1-x_2$. If  $\\vec{x}$ falls in the positive quadrant then $x_1 > x_2$ so\n", "index": 29, "text": "\n\\[\nA = \\frac{1 - x_2}{x_1 - x_2} \\geq 1\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"A=\\frac{1-x_{2}}{x_{1}-x_{2}}\\geq 1\" display=\"block\"><mrow><mi>A</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo>\u2265</mo><mn>1</mn></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nSo $A = 0$ and the update is $\\lambda_{n+1} = \\lambda_n - h\\lambda_n$. Similar arguments can be made for the other quadrants, giving us the following updating rule:\n", "itemtype": "equation", "pos": 28319, "prevtext": "\nSo $A = 1$ and the update is $\\lambda_{n+1} = \\lambda_n + h(1 - \\lambda_n)$ \n \nIf  $\\vec{x}$ falls in the negative quadrant then $x_1 < x_2$ so\n\n", "index": 31, "text": "\\[\n A = \\frac{1 - x_2}{x_1 - x_2} \\leq 0\n \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m1\" class=\"ltx_Math\" alttext=\"A=\\frac{1-x_{2}}{x_{1}-x_{2}}\\leq 0\" display=\"block\"><mrow><mi>A</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mfrac><mo>\u2264</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nThen consider the behaviour of the expected value of $\\lambda$ over time:\n\n", "itemtype": "equation", "pos": 28528, "prevtext": "\nSo $A = 0$ and the update is $\\lambda_{n+1} = \\lambda_n - h\\lambda_n$. Similar arguments can be made for the other quadrants, giving us the following updating rule:\n", "index": 33, "text": "\n\\[\n\\lambda_{t+1} = \n\\begin{cases}\n\t\\lambda_t(1-h) &\\text{if $\\vec{x} \\in R^-$ } \\\\\n  \t\\lambda_t(1-h)  + h &\\text{if $\\vec{x} \\in R^+$}\n\\end{cases}\u00e2\u0080\u00a2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m1\" class=\"ltx_Math\" alttext=\"\\lambda_{t+1}=\\begin{cases}\\lambda_{t}(1-h)&amp;\\text{if $\\vec{x}\\in R^{-}$ }\\\\&#10;\\lambda_{t}(1-h)+h&amp;\\text{if $\\vec{x}\\in R^{+}$}\\end{cases}\u00e2\u0080\u00a2\" display=\"block\"><mrow><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mtext>if\u00a0</mtext><mrow><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>-</mo></msup></mrow><mtext>\u00a0</mtext></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>h</mi></mrow></mtd><mtd columnalign=\"left\"><mrow><mtext>if\u00a0</mtext><mrow><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>+</mo></msup></mrow></mrow></mtd></mtr></mtable></mrow><mo>\u2062</mo><mi>\u00c3</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u00a2</mi><mo>\u2062</mo><mi>\u00c2</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u0080</mi><mo>\u2062</mo><mi>\u00c2</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u00a2</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nAs $t\\rightarrow \\infty$, we have\n\n", "itemtype": "equation", "pos": 28756, "prevtext": "\nThen consider the behaviour of the expected value of $\\lambda$ over time:\n\n", "index": 35, "text": "\\begin{align*}\nE(\\lambda_{t+1}) & = E(\\lambda_{t+1}| \\vec{x} \\in R^+) p^+ + E(\\lambda_{t+1}| \\vec{x} \\in R^-) p^-\\\\\n& = E(\\lambda_t(1 - h) + h|  \\vec{x} \\in R^+)p^+ \\\\\n&\\qquad+ E(\\lambda_t(1 - h)|  \\vec{x} \\in R^-)p^- \\\\\n& = (1-h)E(\\lambda_t) + p^+h\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda_{t+1})\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{t+1}|\\vec{x}\\in R^{+})p^{+}+E(\\lambda_{t+1}|\\vec{x}%&#10;\\in R^{-})p^{-}\" display=\"inline\"><mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>+</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>p</mi><mo>+</mo></msup><mo>+</mo><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>-</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>p</mi><mo>-</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{t}(1-h)+h|\\vec{x}\\in R^{+})p^{+}\" display=\"inline\"><mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>h</mi><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>+</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>p</mi><mo>+</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\qquad+E(\\lambda_{t}(1-h)|\\vec{x}\\in R^{-})p^{-}\" display=\"inline\"><mrow><mi>\u2003\u2003</mi><mo>+</mo><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u2208</mo><msup><mi>R</mi><mo>-</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>p</mi><mo>-</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(1-h)E(\\lambda_{t})+p^{+}h\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>p</mi><mo>+</mo></msup><mo>\u2062</mo><mi>h</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\\end{proof}\n\nWe have therefore related the value of $\\lambda$ to which agents converge to the distribution of elements $\\vec{x}$ in the conceptual space $\\Omega$.\n\n\\begin{thm}\n\\label{thm:E}\nSuppose agents are equipped with labels $L_1$, $L_2$ and combine and update these label according to the language game described. Then the expected value of $\\lambda$, $E(\\lambda) = E(A)$.\n\\end{thm}\n\n\\begin{proof}\nTo obtain $E(\\lambda)$, consider:\n", "itemtype": "equation", "pos": 29053, "prevtext": "\nAs $t\\rightarrow \\infty$, we have\n\n", "index": 37, "text": "\\begin{align*}\nE(\\lambda) &= E(\\lambda)(1-h) + p^+h\\\\\n&=p+\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda)(1-h)+p^{+}h\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>p</mi><mo>+</mo></msup><mo>\u2062</mo><mi>h</mi></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex31.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=p+\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>p</mi><mo>+</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 29562, "prevtext": "\n\\end{proof}\n\nWe have therefore related the value of $\\lambda$ to which agents converge to the distribution of elements $\\vec{x}$ in the conceptual space $\\Omega$.\n\n\\begin{thm}\n\\label{thm:E}\nSuppose agents are equipped with labels $L_1$, $L_2$ and combine and update these label according to the language game described. Then the expected value of $\\lambda$, $E(\\lambda) = E(A)$.\n\\end{thm}\n\n\\begin{proof}\nTo obtain $E(\\lambda)$, consider:\n", "index": 39, "text": "\n\\[\n\\lambda_{t+1} = \\lambda_t(1 - h) + hA\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex32.m1\" class=\"ltx_Math\" alttext=\"\\lambda_{t+1}=\\lambda_{t}(1-h)+hA\" display=\"block\"><mrow><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>A</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nThen as $t\\rightarrow \\infty$, we have\n\n", "itemtype": "equation", "pos": 29607, "prevtext": "\n\n", "index": 41, "text": "\\begin{align*}\nE(\\lambda_{t+1}) & = E(\\lambda_t(1 - h) + hA)\\\\\n\\label{eq:exp}\n& = (1-h)E(\\lambda_t) + hE(A)\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda_{t+1})\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{t}(1-h)+hA)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>A</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex34.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(1-h)E(\\lambda_{t})+hE(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\\end{proof}\n\nThis result shows that the weighting given to the compound concepts $\\alpha_i$ may be directly predicted from the distribution of elements in the conceptual space and the membership functions used to categorise the constituent labels $L_j$.  \n\nIf we consider updating model 2, where agents update whenever $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$, we may also obtain an expression for the variance of the $\\lambda_i$ across agents.\n\n\\begin{thm}\nSuppose agents have labels $L_1$, $L_2$ and that agents update according to updating model 2: $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. Then the variance of the $\\lambda$ across agents is $Var(\\lambda) = \\frac{h}{2-h}Var(A)$\t\n\\end{thm}\n\\begin{proof}\nWe obtain $Var(\\lambda)$ by firstly calculating $E(\\lambda^2)$:\n\n", "itemtype": "equation", "pos": 29767, "prevtext": "\nThen as $t\\rightarrow \\infty$, we have\n\n", "index": 43, "text": "\\begin{align*}\nE(\\lambda) &= E(\\lambda)(1-h) + hE(A)\\\\\n&=E(A)\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex35.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex35.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda)(1-h)+hE(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex36.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\nWe  may then calculate\n\\begin {align*}\nVar(\\lambda_{t+1}) &= E(\\lambda_{t+1}^2) - (E(\\lambda_{t+1}))^2 \\\\\n&= (1-h)^2E(\\lambda_t^2) +2h(1-h)E(\\lambda_t)E(A)\\\\\n&\\qquad + h^2E(A^2) - (E(\\lambda)(1-h) + hE(A))^2\\\\\n&=  (1-h)^2E(\\lambda_t^2) + 2h(1-h)E(\\lambda_t)E(A)\\\\\n& \\qquad + h^2E(A^2) - (1-h)^2(E(\\lambda_t))^2\\\\\n& \\qquad - 2h(1-h)E(\\lambda_t)E(A) - h^2 (E(A))^2\\\\\n&=(1-h)^2Var(\\lambda_t) - h^2Var(A)\n\\end{align*}\nAs $t \\rightarrow \\infty$, we have\n\n", "itemtype": "equation", "pos": 30598, "prevtext": "\n\\end{proof}\n\nThis result shows that the weighting given to the compound concepts $\\alpha_i$ may be directly predicted from the distribution of elements in the conceptual space and the membership functions used to categorise the constituent labels $L_j$.  \n\nIf we consider updating model 2, where agents update whenever $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$, we may also obtain an expression for the variance of the $\\lambda_i$ across agents.\n\n\\begin{thm}\nSuppose agents have labels $L_1$, $L_2$ and that agents update according to updating model 2: $\\mu_{\\alpha_i}(\\vec{x}) \\neq w$. Then the variance of the $\\lambda$ across agents is $Var(\\lambda) = \\frac{h}{2-h}Var(A)$\t\n\\end{thm}\n\\begin{proof}\nWe obtain $Var(\\lambda)$ by firstly calculating $E(\\lambda^2)$:\n\n", "index": 45, "text": "\\begin{align*}\nE(\\lambda_{t+1}^2) & = E((\\lambda_t(1 - h) + hA)^2)\\\\\n&=E((1-h)^2\\lambda_t^2 +2h(1-h)\\lambda_tA +h^2A^2))\\\\\n& = (1-h)^2E(\\lambda_t^2) +2h(1-h)E(\\lambda_t)E(A) + h^2E(A^2)\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex37.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda_{t+1}^{2})\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03bb</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex37.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E((\\lambda_{t}(1-h)+hA)^{2})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>A</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex38.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E((1-h)^{2}\\lambda_{t}^{2}+2h(1-h)\\lambda_{t}A+h^{2}A^{2}))\" display=\"inline\"><mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><msubsup><mi>\u03bb</mi><mi>t</mi><mn>2</mn></msubsup><mo>+</mo><mn>2</mn><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><msub><mi>\u03bb</mi><mi>t</mi></msub><mi>A</mi><mo>+</mo><msup><mi>h</mi><mn>2</mn></msup><msup><mi>A</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex39.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(1-h)^{2}E(\\lambda_{t}^{2})+2h(1-h)E(\\lambda_{t})E(A)+h^{2}E(A^{%&#10;2})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03bb</mi><mi>t</mi><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>h</mi><mn>2</mn></msup><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>A</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can further examine how quickly the mean and variance of $\\lambda_i$ approach that of $A$. We obtain an expression for $E(\\lambda_t)$ and $Var(\\lambda_t)$ in terms of t and solve. The speed at which the $\\lambda_i$ converge to the resting state is dependent on $h$. \n\n\\begin{thm}\nSuppose agents are equipped with labels $L_1$, $L_2$ and combine and update these label according to the language game described, using updating model 2. Then the number of timesteps until $ |E(\\lambda_t) - E(A)| \\leq \\epsilon$ for some small $\\epsilon$ is $t \\geq (\\log(\\epsilon) - \\log(|E(\\lambda_0) - E(A)|))/\\log(1-h)$, and the number of timesteps until $|Var(\\lambda_t) - \\frac{h}{2-h}Var(A)| \\leq \\epsilon$ is \n", "itemtype": "equation", "pos": 31248, "prevtext": "\nWe  may then calculate\n\\begin {align*}\nVar(\\lambda_{t+1}) &= E(\\lambda_{t+1}^2) - (E(\\lambda_{t+1}))^2 \\\\\n&= (1-h)^2E(\\lambda_t^2) +2h(1-h)E(\\lambda_t)E(A)\\\\\n&\\qquad + h^2E(A^2) - (E(\\lambda)(1-h) + hE(A))^2\\\\\n&=  (1-h)^2E(\\lambda_t^2) + 2h(1-h)E(\\lambda_t)E(A)\\\\\n& \\qquad + h^2E(A^2) - (1-h)^2(E(\\lambda_t))^2\\\\\n& \\qquad - 2h(1-h)E(\\lambda_t)E(A) - h^2 (E(A))^2\\\\\n&=(1-h)^2Var(\\lambda_t) - h^2Var(A)\n\\end{align*}\nAs $t \\rightarrow \\infty$, we have\n\n", "index": 47, "text": "\\begin{align*}\nVar(\\lambda) &= (1-h)^2Var(\\lambda) - h^2Var(A)\\\\\n&= \\frac{h}{2 - h} Var(A)\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex41.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle Var(\\lambda)\" display=\"inline\"><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex41.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(1-h)^{2}Var(\\lambda)-h^{2}Var(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>h</mi><mn>2</mn></msup><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex42.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{h}{2-h}Var(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\\end{thm}\n\\begin {proof}\n\nWe firstly obtain an expression for $E(\\lambda_t)$ in terms of $t$, $h$, $E(A)$ and $E(\\lambda_0)$\n\n\n\n\n", "itemtype": "equation", "pos": 32082, "prevtext": "\n\\end{proof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can further examine how quickly the mean and variance of $\\lambda_i$ approach that of $A$. We obtain an expression for $E(\\lambda_t)$ and $Var(\\lambda_t)$ in terms of t and solve. The speed at which the $\\lambda_i$ converge to the resting state is dependent on $h$. \n\n\\begin{thm}\nSuppose agents are equipped with labels $L_1$, $L_2$ and combine and update these label according to the language game described, using updating model 2. Then the number of timesteps until $ |E(\\lambda_t) - E(A)| \\leq \\epsilon$ for some small $\\epsilon$ is $t \\geq (\\log(\\epsilon) - \\log(|E(\\lambda_0) - E(A)|))/\\log(1-h)$, and the number of timesteps until $|Var(\\lambda_t) - \\frac{h}{2-h}Var(A)| \\leq \\epsilon$ is \n", "index": 49, "text": "\n\\[t \\geq \\frac{(\\log(\\epsilon) - \\log(|Var(\\lambda_0) - \\frac{h}{2-h}Var(A)|))}{2\\log(1-h)}\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex43.m1\" class=\"ltx_Math\" alttext=\"t\\geq\\frac{(\\log(\\epsilon)-\\log(|Var(\\lambda_{0})-\\frac{h}{2-h}Var(A)|))}{2%&#10;\\log(1-h)}\" display=\"block\"><mrow><mi>t</mi><mo>\u2265</mo><mfrac><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03f5</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nNow, consider\n\n\n\n", "itemtype": "equation", "pos": 32305, "prevtext": "\n\\end{thm}\n\\begin {proof}\n\nWe firstly obtain an expression for $E(\\lambda_t)$ in terms of $t$, $h$, $E(A)$ and $E(\\lambda_0)$\n\n\n\n\n", "index": 51, "text": "\\begin{align*}\nE(\\lambda_{t}) & = E(\\lambda_{t-1})(1 - h) + hE(A)\\\\\n& = E(\\lambda_0)(1-h)^t + E(A)\\sum_{k = 1}^t(h(1-h)^{t-1})\\\\\n&= E(\\lambda_0)(1-h)^t + E(A)(1 - (1-h)^t)\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex44.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda_{t})\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex44.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{t-1})(1-h)+hE(A)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>h</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex45.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{0})(1-h)^{t}+E(A)\\sum_{k=1}^{t}(h(1-h)^{t-1})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>t</mi></msup></mrow><mo>+</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover></mstyle><mrow><mo stretchy=\"false\">(</mo><mrow><mi>h</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex46.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=E(\\lambda_{0})(1-h)^{t}+E(A)(1-(1-h)^{t})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>t</mi></msup></mrow><mo>+</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>t</mi></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nTo calculate the number of timesteps needed until $Var(\\lambda)$ has reached its resting state, we again obtain an expression for $Var(\\lambda_t)$ in terms of $t$, $h$, $Var(A)$ and $Var(\\lambda_0)$.\n\n", "itemtype": "equation", "pos": 32509, "prevtext": "\n\nNow, consider\n\n\n\n", "index": 53, "text": "\\begin{align*}\n\\epsilon &\\geq |E(\\lambda_t) - E(A)|\\\\\n& = |E(\\lambda_0) -E(A)|(1-h)^t\\\\\nt &\\geq (\\log(\\epsilon) - \\log(|E(\\lambda_0) - E(A)|))/\\log(1-h)\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex48.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\epsilon\" display=\"inline\"><mi>\u03f5</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex48.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\geq|E(\\lambda_{t})-E(A)|\" display=\"inline\"><mrow><mi/><mo>\u2265</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex49.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=|E(\\lambda_{0})-E(A)|(1-h)^{t}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>t</mi></msup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex50.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle t\" display=\"inline\"><mi>t</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex50.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\geq(\\log(\\epsilon)-\\log(|E(\\lambda_{0})-E(A)|))/\\log(1-h)\" display=\"inline\"><mrow><mi/><mo>\u2265</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03f5</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\nAgain, consider \n\n", "itemtype": "equation", "pos": 32876, "prevtext": "\n\nTo calculate the number of timesteps needed until $Var(\\lambda)$ has reached its resting state, we again obtain an expression for $Var(\\lambda_t)$ in terms of $t$, $h$, $Var(A)$ and $Var(\\lambda_0)$.\n\n", "index": 55, "text": "\\begin{align*}\nVar{\\lambda_t} &= (1-h)^2Var(\\lambda_(t-1)) - h^2Var(A)\\\\\n&= Var(\\lambda_0)(1-h)^{2t} + Var(A)\\sum_{k = 1}^t h^2(1-h)^{2t}\\\\\n& = Var(\\lambda_0)(1-h)^{2t} + \\frac{h}{2-h}Var(A)(1 - (1-h)^{2t})\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex51.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle Var{\\lambda_{t}}\" display=\"inline\"><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><msub><mi>\u03bb</mi><mi>t</mi></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex51.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(1-h)^{2}Var(\\lambda_{(}t-1))-h^{2}Var(A)\" display=\"inline\"><mrow><mo>=</mo><msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mo stretchy=\"false\">(</mo></msub><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo><mo>-</mo><mi>h</mi><msup><mi/><mn>2</mn></msup><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex52.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=Var(\\lambda_{0})(1-h)^{2t}+Var(A)\\sum_{k=1}^{t}h^{2}(1-h)^{2t}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow><mo>+</mo><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover></mstyle><mrow><msup><mi>h</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex53.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=Var(\\lambda_{0})(1-h)^{2t}+\\frac{h}{2-h}Var(A)(1-(1-h)^{2t})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06763.tex", "nexttext": "\n\n\\end{proof}\n\nTo illustrate these results, we ran simulations of the language game with 1000 agents each with $L_1 = L_2 = <\\!\\!1, U(0,1)\\!\\!>$, $w = 1$, $x_1 \\sim U[0.25,0.75]$, $x_2 \\sim U[0,0.5]$, and $h \\in \\{10^{-2}, 10^{-3}, 10^{-4}, 10^{-5}\\}$. Figure $\\ref{fig:limE}$ shows the values of $E(\\lambda_t)$ over time obtained from simulations, together with the predicted value of $E(\\lambda_t)$ and also the resting state $E(\\lambda)$. \n\n\\begin{figure} [htbp]\n                \\centering\n                \\includegraphics[width=\\columnwidth]{limE.pdf}\n                \\caption{Predicted value of $E(\\lambda)$ and actual value of $E(\\lambda)$ over time for different values of $h$. The rate at which $E(\\lambda)$ approaches its resting state is slower for smaller $h$.}\n                \\label{fig:limE}\n        \\end{figure}\n\n Figure $\\ref{fig:limVar}$ shows the values of $Var(\\lambda_t)$ over time obtained from simulations, together with the predicted value of $Var(\\lambda_t)$ and also the resting state $Var(\\lambda)$.\n \n\\begin{figure}[t]\n                \\centering\n                \\includegraphics[width=\\columnwidth]{limVar.pdf}\n                \\caption{Predicted value of $Var(\\lambda)$ and actual value of $Var(\\lambda)$ over time for different values of $h$. The rate at which $Var(\\lambda)$ approaches its resting state is slower for smaller $h$}\n                \\label{fig:limVar}\n\\end{figure}\n\nThese results illustrate that the rate at which agents converge to the resting state is dependent on the value $h$ by which agents adopt others agents' viewpoints. Larger values of $h$ allow faster convergence to the resting state, however that resting state will have a larger variance when $h$ is larger.\n\n\\section{DISCUSSION}\n\\label{sec:disc}\nCharacterising concepts as a weighted sum of attributes is seen throughout the literature \\cite{gard2004, hamp1987, lakoffhedges, zadehhedges}. However, this has been proposed in an ad hoc fashion, and many concepts do not adhere to this formulation. Further, no mechanism for determining the weights has been proposed. We have developed a hierarchical model of concept combination from which the characterisation of concepts as a weighted sum of attributes arises naturally, summarised in section \\ref{sec:bkg}. We have implemented a simple version of this model within the language game framework in which agents make assertions that consist of a weighted sum of two constituent concepts. We have shown that within a multi-agent simulation of a community of such language users agents can converge to shared weightings (section \\ref{sec:simulations}). The weights $\\lambda_i$ to which the community of agents converge are related to the distribution of elements $x_j$ in the conceptual space, the membership functions $\\mu_{L_j}(x_j)$ used for the constituent concepts, and the reliability $w$ of the agents. We have derived explicit expressions relating the mean of the final weights $\\lambda_i$ across all agents to the distribution of the $x_j$, $\\mu_{L_j}(x_j)$, and $w$. In a modified updating model that is more amenable to analysis, we have derived expressions for the variance of the $\\lambda_i$ in terms of $x_j$, $\\mu_{L_j}(x_j)$, $w$ and also $h$, the rate at which agents adopt other agents' concepts. When $h$ is small, i.e. agents are slower to adopt others' concepts, the variance of the $\\lambda_i$ is smaller, perhaps indicating that more robust concepts are formed. We have also derived expressions for the speed at which the resting distribution of the $\\lambda_i$ are approached, dependent on the value of $h$ (section \\ref{sec:analysis}). The results from this model indicate how weightings in a weighted sum of concepts can be related to the elements encountered in a conceptual space. \n\n This model is of course extremely simple, and numerous extensions are ongoing. The use of more complex labels $L_i$ is under investigation, with labels being extended to multiple dimensions. We are also developing the updating algorithm in order to combine more than two labels and to include noise in agents' labels. In previous work \\cite{ettie, melinghedges}, the agents in the simulations have had varying reliability $w$, which could be incorporated into these simulations. Future work will also incorporate the theoretical aspects alluded to in section \\ref{sec:bkg} that account for non-compositional properties such as emergent attributes.\n\n\\ack\nMartha Lewis gratefully acknowledges support from EPSRC Grant No. EP/E501214/1\n\n\\bibliography{../phd}\n\n\n", "itemtype": "equation", "pos": 33114, "prevtext": "\n\nAgain, consider \n\n", "index": 57, "text": "\\begin{align*}\n\\epsilon &\\geq |Var(\\lambda_t) - \\frac{h}{2-h}Var(A)|\\\\\n& = |Var(\\lambda_0) - \\frac{h}{2-h}Var(A)|(1-h)^{2t}\\\\\nt &\\geq \\frac{(\\log(\\epsilon) - \\log(|Var(\\lambda_0) - \\frac{h}{2-h}Var(A)|))}{2\\log(1-h)}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex54.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\epsilon\" display=\"inline\"><mi>\u03f5</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex54.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\geq|Var(\\lambda_{t})-\\frac{h}{2-h}Var(A)|\" display=\"inline\"><mrow><mi/><mo>\u2265</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex55.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=|Var(\\lambda_{0})-\\frac{h}{2-h}Var(A)|(1-h)^{2t}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>t</mi></mrow></msup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex56.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle t\" display=\"inline\"><mi>t</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex56.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\geq\\frac{(\\log(\\epsilon)-\\log(|Var(\\lambda_{0})-\\frac{h}{2-h}Var%&#10;(A)|))}{2\\log(1-h)}\" display=\"inline\"><mrow><mi/><mo>\u2265</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03f5</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mi>h</mi><mrow><mn>2</mn><mo>-</mo><mi>h</mi></mrow></mfrac><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>h</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}]