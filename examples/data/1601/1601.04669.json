[{"file": "1601.04669.tex", "nexttext": "\nwhere $\\vec{\\tau}$ is the torque vector,\n$\\vec{r}$ is the displacement vector,\nand $\\vec{F}$ is the force vector.\n\nTo define a torque measure for images,\nwe consider  forces  applied at  edge points and parallel to the tangent of the local edge.\nFor an arbitrary point, called the center point, we consider a rotation axis in three-dimensional space passing through that point and perpendicular to the image plane.\nThen we can measure the torque at any point in the image with respect to the rotation axis, as  defined in physics (see Fig.~\\ref{fig:Image torque idea}).\n\nSince the displacement vector and the force vector are both on the image surface, the torque vector is  perpendicular to the image surface, and we call the magnitude of the torque vector along the rotation axis simply the \\emph{torque} or \\emph{torque value} here and after.\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{overpic}[width=0.695\\columnwidth,keepaspectratio=true,clip]\n\t{ImageTorqueIdea.eps}\n    \\put(154,39){$p$}\n   \n   \n   \n    \\put(164,35){$\\vec{r}$}\n    \\put(188,35){$\\vec{F}$}\n    \\put(163,69){$\\vec{\\tau}$}\n    \\put( 11,27){\\rotatebox{53}{\\tiny displacement}}\n    \\put( 28,22){\\rotatebox{-25}{\\tiny force}}\n    \\put( 44,72){\\tiny torque}\n    \\end{overpic}\n  \\end{center}\n\\caption{The idea of the image torque measure is inspired by the concept of the torque in physics: Given a point $p$ and an edge point $q$ in an image, we assign a unit force vector $\\vec{F}$ along the tangent of the edge. Denoting as $\\vec{r}$ the vector from $p$ to $q$, the torque vector at $q$ is defined as $\\vec{\\tau} = \\vec{r} \\times \\vec{F}$.\nIts value along the axis perpendicular the image will be called the \\emph{torque}.\n\\label{fig:Image torque idea}}\n\\end{figure}\n\n\n\nSince our images are discrete, edges are  represented by a set of pixels. Let  $q$ be an edge point, whose edge we represent by  a vector $\\vec{F}_q$, and let  $p$ denote the center point and $\\vec{r}_{pq}$  the displacement vector from $p$ to $q$. Then the torque value at $p$ is\n\n", "itemtype": "equation", "pos": 24717, "prevtext": "\n\n\\title{The Image Torque Operator for Contour Processing}\n\n\\author{Morimichi Nishigaki and Cornelia Ferm\\\"{u}ller\\\\\nInstitute for Advanced Computer Studies, University of Maryland\\\\ College Park, MD 20742, U.S.A.}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\\begin{abstract}\nContours are salient features for image description, but the detection and localization of boundary contours is still considered a challenging problem. This paper introduces a new tool for edge processing implementing  the Gestaltism idea of edge grouping. This tool is\na mid-level  image operator, called the \\emph{Torque} operator, that is  designed to help detect closed contours in images.\n\nThe torque operator  takes as input the raw image and  creates  an image map by computing from the image gradients within regions of multiple sizes  a measure of how well the edges are aligned to form  closed, convex contours. Fundamental  properties of the torque are explored and illustrated through examples. Then it is applied in pure bottom-up processing in a variety of applications, including  edge detection, visual attention and segmentation and experimentally demonstrated  a useful  tool that can improve existing techniques. Finally, its extension as a more general grouping mechanism and  application  in  object recognition is discussed.\n\\end{abstract}\n\n\\noindent \\textbf{Keywords:}\nMid-level Vision; Image Operator; Segmentation; Object proposal\n\n\n\\section{Introduction}\n\\label{Introduction}\nVisual scene interpretation is very complex and involves computations  at  different levels of abstraction. Most theorists of vision adapt a categorization of visual processes and representations into low-, mid- and high-level vision \\cite{Marr82}.\nThe idea is that low level vision is about computing  features, such as local edges, color, texture and image motion; mid-level vision groups  local features to obtain object surfaces and  global scene information, such as  3D motion and  lighting; and\nhigh level vision  utilizes semantic information to recognize objects, actions and scenes.\n\nThe most influential ideas of mid-level vision are due to the Gestalt theorists. These psychologists of the early twentieth century \\cite{Wertheimer1923} argued that human vision organizes  image features at the early stages of interpretation through a process of  figure ground segmentation. They suggested that certain principles are applied to group pieces of image and locate borders of figures.\nIn this  view, mid-level vision is about implementing organizational principles, such as similarity, symmetry, common fate (i.e. common motion),  closure, bias from prior experience, {\\emph{etc}\\onedot}, in order to \nidentify the image regions which are object-related for further processing.\n\nA very important cue of mid-level vision  is the contour. Objects and parts of objects are delineated from their surroundings by closed contours, which make up their boundary. Many papers over the years have focused on contour detection \\cite{Martin2004,Ferrari2006,Toshev2012}, and  there has been a renewed interest in recent years. A number of recent papers also have discussed mid-level cues and inspiration from Gestalt theory for contour processing in applications of detection \\cite{DollarZitnick2013,Kennedy2011,Ming2012}, recognition \\cite{Opelt2006,Lim2013}, and segmentation \\cite{Arbelaez2009,Yu2004}. These  works mostly learn from data \\cite{Ren2005} to acquire mid-level representations.\nHere we pursue  a very different approach; we propose  a bottom-up mid-level mechanism for  grouping edges into closed contours. Thus this mechanisms implements the so-called principle of \\emph{closure}, which refers to the idea that objects and object parts are perceived as whole, and simple features tend to be grouped together into closed figures even when they are not complete.\n\n\nThe grouping of edges is implemented with a  semi-global image operator, which we call the \\emph{torque operator}. This operator is defined on oriented edges and provides a measure of the edge structure within a patch. It takes on  large value when the  patch contains a  closed contour.\n The operator was designed as a tool to help  detect regions likely to contain object or parts of objects. This is achieved by collecting edge information from regions of different extent in a way that enforces edges on convex contours and attenuates random  edges due to texture.\n  The torque within a patch is computed by taking  at every edge point the value of  the cross-product of the oriented edge and the vector from the center point of the patch, and summing over all values. To help  the reader  get a quick grasp of the basic idea, the concept is illustrated in\nFigure~\\ref{fig:Illustration of the torque} before  a proper definition of the operator will be given in Section~\\ref{sec:Torque Operator}.\n\nReferring to the figure, for the image on the upper left from the Berkeley data set \\cite{Martin2001}, torque maps were  computed for  four different patch sizes ( $5 \\times 5$, $21 \\times 21$, $45 \\times 45$, and $81 \\times 81$ ). In these maps every pixel $p$ encodes  the torque value from the patch of   given size centered at $p$.\nWe used the color coding as explained in the third row. Because edges are oriented, torque values can be positive (shown in red)  and negative (shown in blue).\nWe then define data structures: We call the three-dimensional structure of the  torque maps at different scale the \\emph{torque volume}, and we combine the different scales into  two-dimensional maps, which we\ncall  the \\emph{torque value map} and the \\emph{scale map} (as shown in the third row of Fig.~\\ref{fig:Illustration of the torque}). The torque value map at every pixel codes the value of largest absolute value over all scales, and the scale map codes the scale and the sign corresponding to the largest absolute torque value.\nThese data structures will be used as tools to solve a number of applications.\n\n\n\n\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n  \\begin{tabular}[htbp]{@{}c@{}c@{}}\n\n\t\\begin{minipage}{0.25\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n    {101085.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.75\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n    {ConceptApplyingTorqueOperator.eps}\n    \\end{center}\n    \\end{minipage}\n\n  \\end{tabular}\\vspace{1mm}\n\n  \\begin{tabular}[htbp]{@{\\extracolsep{0.02\\columnwidth}}c@{}c@{}c@{}c@{}}\n\n    \\begin{minipage}{0.23\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {TorqueMap05.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.23\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {TorqueMap21.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.23\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {TorqueMap45.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.23\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {TorqueMap81.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n    5 & 21 & 45 & 81\n  \\end{tabular}\n\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{}c@{}}\n\n    \\begin{minipage}{0.35\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {ValueMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.092\\columnwidth}\n    \\begin{flushleft}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {ColorbarValueMap.eps}\n    \\end{flushleft}\n    \\end{minipage}\n\n    \\begin{minipage}{0.35\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1\\columnwidth,keepaspectratio=true]\n    {ScaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.092\\columnwidth}\n    \\begin{flushleft}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {ColorbarScaleMap.eps}\n    \\end{flushleft}\n    \\end{minipage}\n\n  \\end{tabular}\n  \\end{center}\n\\caption{Illustration of the torque.\nUpper row: left: Test image. right: Usage of the torque operator. The torque operator is applied to multi-scale image patches at every pixel in an image.\nMiddle row: For the test image, examples of torque maps are shown for  four patches of increasing size.\nLower row: Combination of the torque at all patch sizes into one map, called the value map and the corresponding scale map.\n\\label{fig:Illustration of the torque}}\n\\end{figure}\n\n\n\nThe paper is organized as follows.\nAfter a description of related work in the next section, we provide a formal definition of the torque operator and discussion of its  properties.\nThen we apply the torque  operator in a few Computer Vision applications, specifically the problems of boundary detection, visual attention, segmentation, and object recognition, and we verify its usefulness as a tool that can improve existing techniques.\nFinally we conclude with a discussion on extending this operator to the spatio-temporal domain and as a grouping mechanism of high-level semantic edge information. Parts of this paper have previously appeared in \\cite{Nishigaki2012}.\n\n\\section{Related Work}\n\nContours are an essential cue for  many vision applications, including segmentation, tracking and recognition. By the term contour, we generally refer to  extended edges delineating objects and parts of objects. Already in  the early days of Computer Vision\nit became clear that simple point-wise edge responses, computed with filters, are not sufficient to obtain salient edges corresponding to contours; some grouping mechanisms are necessary \\cite{RenMalik2002}. Earlier approaches employed  semi-local edge-linking processes to obtain extended edges from edgels computed with local filters.\nFor example, the well-known Canny edge detector traces edges using hysteresis thresholding. In more recent years the top performing algorithms employ edge detection methods  specifically tuned to boundaries, and they use various  linking and globalization processes, designed either for segmentation or recognition.\n\n{\\noindent \\emph{Boundary detection:}}\nData-driven approaches to contour detection have been championed in the work of Martin {et al\\onedot} \\cite{Martin2004}.\nIn this study, local cues, such as brightness, color, texture, and their gradients are combined, and weights for each cue are learned using labeled image data sets to distinguish edge points at boundaries from others.\nIn similar spirit Doll{\\'a}r et al.~\\cite{Dollar2006} learn edge classifiers from simple features in image patches, Ren \\cite{Ren2008} combines information of local operators from multiple scales, and the high performance contour detection algorithm in \\cite{Arbelaez2011} includes a globalization process to combine local edges based on the  affinity of distant pixels. The latter method was further improved by  Ren and Bo \\cite{RenBo2012}, who replaced the hand-selected features using patches obtained through sparse coding and dictionary learning, and integrated them   through multi-scale pooling in the globalization. Zheng et al. \\cite{Zheng2010} proposed an object-specific boundary detector by combining low-level information using the BEL edge detector \\cite{Dollar2006} and  foreground background cues, middle-level information about short and long-range connections of pixels, and high-level information from shape priors.\n\nRecently Lim et al. \\cite{Lim2013} proposed an interesting generic mid-level detector, which they call sketch tokens. From patches of human-generated contours they learn different classes of edge features. Then using random forests,  edge pixels are detected and classified as the center points of edge tokens. The approach was demonstrated in the bottom-up task of  contour detection and the top-down task of   object detection. In \\cite{DollarZitnick2013} a real-time algorithm for edge detection was proposed using the sketch tokens as features of structured information in a random forest \\cite{Kontschieder2011}. This way edge detection is formulated as the prediction of local segmentation masks.\n\n\nOver the years many computational models have been proposed for contour completion \\cite{ElderZucker96,GuyMedioni93}. For example in more recent work Kokkinos \\cite{Kokkinos2010} first classifies boundary pixels based on SIFT features, and then groups the edge pixels using fractional linear programming based on the edge strength and a smoothness constraint, and Ren \\cite{Ren2008} linearly approximates edges  and connects pixels  using a conditional random field (CRF), which  captures the  statistics of continuity and different junction types. Most approaches to  contour completion  model  the  Gestalt rules of proximity and good-continuity. The principle of closure has also been proposed \\cite{ElderZucker96}, for example in \\cite{Schoenemann2011} for the  task of segmentation.\nIn recent work Ming et al. \\cite{Ming2012} used  a higher-order CRF to model short and long range connections between  edgels and junctions and implemented this way  various edge completion principles, including the one of closure.\n\nMost closely related to our work are the ideas of Lindeberg \\cite{Lindeberg1994,Lindeberg1998} and  Craft et al.~\\cite{Craft2007}.\nIn his seminal work on a  computational theory  of  scale space, Lindeberg introduces, among other image feature detectors, the blob detector. Circular blobs in general can be  detected using the Laplacian (or Difference of Gaussian) operator and scale space blobs are computed by filtering the image with scale-normalized Laplacians and detecting  the local extrema in space and time. Lindeberg \\cite{Lindeberg1993} also discussed the scale selection mechanism as a tool for selecting the focus of attention. The torque mechanism, introduced here, can be used in a similar way for attention selection, and if implemented with square windows or circular windows, has a very similar behavior. The torque, however, is more general. First, even if implemented with square (circular) windows, the torque value map can detect a larger range of shapes not just circular ones, and if used with differently shaped windows, it can also be tuned to certain structures.\n\nSecondly, we view the torque as a tool that can be used in many applications by using both the value and scale map.\n\nCraft et al. \\cite{Craft2007} developed a computational neural model for figure-ground organization using a circular grouping mechanism. Their motivation was to provide an explanatory  mechanism that can account for border-ownership and attention processes. At the first layer  (modeling cells in area V1) oriented edge responses are computed and stored as pairs, one for each orientation. These cells are grouped in a second layer (modeling  area V2) with top-down modulation from a third higher layer of larger-receptive cells, which tunes the grouping so it prefers  annular patterns of different  size (similar to a Laplacian filter). Our torque mechanism works in a similar way, but is more general. Instead of  being tuned only to circular figures, the torque can group any closed figure, and it also has a scale selection mechanism. Craft et al. \\cite{Craft2007} proposed their model, not to solve Computer Vision applications, but  to explain neurophysiological data. They also discussed   physiological evidence  in support of their biological model. Since the torque is a grouping mechanism for closure, it is linked to border-ownership and  attention, and all  of the arguments provided in  \\cite{Craft2007} also apply to the torque mechanism.  The most important ones are: Early edge signals involved in border-ownership representation code not only direction, but also orientation \\cite{Heydt2005}. The speed of  processing and size of fibers \\cite{Zhou2000} indicate that  border-ownership is not  implemented through lateral connections, but  rather requires a processing in higher order areas that feed back the signal. The processing time in border ownership signals was found  not to dependent on the  figure size. Finally, since figure-ground processes  interact with higher-level processes, it must play a role in visual attention selection, and the two processes must be closely related. Our torque mechanism has all these features: (a) it uses orientation of edges; (b) is an additional mechanism (higher level than edge-linking) which can feed back to simple edges; (c) as a scale-space mechanism its computation does not depend on the size of object, and (d) it lends itself  naturally as a tool for attention selection.\n\n\n\n{\\noindent \\emph{Segmentation:}}\nThe fundamental approach to segmentation is to separate surfaces, assuming that  individual  surfaces are homogeneous in some local measurements, such as color intensity, texture \\cite{Alpert2007,Shi2000,Bitsakos2010}, motion \\cite{Criminisi2006,Yin2007,Ogale2005a,Fermuller99} or depth \\cite{Kolmogorov2005,Woo2000}, and neighboring surfaces are separated by discontinuities in these cues.\nWe here differentiate between approaches that treat segmentation as the problem of dividing\nthe image into multiple regions, and approaches that consider the problem as separating one foreground object from background.\nExamples of the former are the mean-shift method \\cite{Comaniciu2002}\n\nand graph-partitioning methods using the  graph cuts algorithm \\cite{Boykov2004} or the normalized cut approach \\cite{Shi2000}.\nThese segmentation approaches are usually based on local cues  as input to a global optimization, but recently many methods first compute super-pixels \\cite{Ren2003,Kohli2009} by over-segmenting the image into perceptual uniform  regions based on the statistics in neighborhoods or affinity between points.\n\nApproaches that consider foreground-background segmentation include probabilistic models that formulate the problem as optimization for a binary labeling and use belief propagation  or graph cut  algorithms \\cite{Rother2004,Kolmogorov2005} and continuous models  based on differential equations using methods such as active contours and variational approaches \\cite{Blake2000,Mumford1989,Osher1988}. Our evaluation here uses graphcut methods. We use the classical graphcut segmentation into multiple segments \\cite{Boykov2001} and the foreground-background separation approach of \\cite{Mishra2009b}. The latter method segments in the polar coordinate system by minimizing for  a closed contour surrounding a fixation point using a graph cut formulation defined on edges only.\nAll segmentation approaches have the problem of being biased, usually towards small regions with small and smooth boundary.\nThis is because of texture edges, which in real images are always present, in conjunction with  minimizations biased towards certain shapes.\nFor example graph cuts \\cite{Kolmogorov2005} are known to favor small areas, the polar coordinate representation favors circular blobs, and variational minimizations \\cite{Vese2002} also prefer smaller segments, as they explicitly minimize the length and/or smoothness of the bounding contour. By using the  torque  in a preprocessing step to find object-like regions,\n it can  alleviate the bias.  It can help  locate  the regions surrounded by contours, locate contours of larger extent, and separate texture edges from boundary edges.\n\n{\\noindent \\emph{Visual attention:}}\n\nAttention mechanisms are classified into bottom-up and top-down processes.\nTop-down attention is more complex because it represents objects in memory \\cite{Hollingworth2001} and uses the memory to detect likely objects in an attended visual scene.\nBottom up attention is driven by low level processes.\nThe best  known  model of visual attention has been proposed by Itti {et al\\onedot} \\cite{Itti1998}.\nIn this model, first local feature maps are computed from color, intensity and orientation information as the difference of Gaussian filters at multiple scales, which approximate the \\emph{center-surround} differences of neurons.\nLarger center surround differences are considered more \\emph{conspicuous}.\nThen a combined saliency map is constructed by adding the normalized feature maps. Related approaches differ in the choice of feature vectors and combination of features.\nIn our experimental section we will compare against the method of Harel {et al\\onedot} \\cite{Harel2006}, which computes a saliency map based on the dissimilarity of features in regions using a graph-based approach.\nHarel {et al\\onedot} evaluated the performance of their detector on its ability to predict  human attention  using the  human fixation data of Einh\\\"auser {et al\\onedot} \\cite{Einhauser2006}, and  reported to achieve  98\\% of the ROC area of a human based control, while the model by Itti {et al\\onedot} achieved only 84\\%.\nRecent works in fixation and attention \\cite{Holm2008,Einhauser2008}  offer an alternative to the traditional \\emph{early} feature saliency theories.\nBased on  systematic psychophysical experiments, \\cite{Holm2008} suggests that observers look at objects as if they knew them before they became aware of their identity, and \\cite{Einhauser2008} shows that the hypothesis that humans attend to objects has a better predictive power in the data than any other theory. A number of works recently proposed algorithms for the implementation of this idea calling it proto-segmentation and object proposal \\cite{Alexe2012,Cheng2014,Hosang2016}.\nIn our paper we will use the torque measure to derive a saliency map for visual attention.\nThe extrema of the torque measure often appear at the locations in the image where objects are surrounded by  edges.\nThus the torque appears to be a good measure to model object driven visual attention.\n\n{\\noindent \\emph{Object recognition:}}\n The best known object recognition methods use descriptors  based on point detectors  tuned to texture features \\cite{Lowe2004,DT05}, but object  recognition from contours has also received significant attention. We can roughly classify existing   approaches  according to how they  detect and describe  local contour features and how they  represent and classify  the overall contour.\nOften, so-called contour patches, or shape  fragments, are  used as  local descriptors. For example, the shape context descriptor \\cite{Belongie2002} encodes the spatial distribution of edge points in log polar space, or the feature detector defined by \\cite{Jurie2004} is based on the saliency of local convexity. Some approaches  acquire the contour fragments and their detectors \\cite{Kumar2004,Shotton2005,Opelt2006,Leibe2004,Mairal2008} from data using learning techniques. For, example Shotton et al. \\cite{Shotton2005} and  Opelt et al. \\cite{Opelt2006} learn a codebook of shape fragments. To detect objects, the learned class specific shape fragments are then matched using oriented chamfer matching and voted via a star-shape model.  Leibe et al. \\cite{Leibe2004} encode with the patches the relative location to the  object center, to create a codebook that in addition to appearance also represents  spatial information for particular object classes.\n For a better representation of object classes, some techniques  group contour pieces into longer lines and curves \\cite{Ferrari2006,Ravishankar2008} and match object  parts. A descriptor for matching partial shape fragments was introduced in \\cite{Riemenschneider2010}, and\n Toshev et. al.~\\cite{Toshev2010} proposed the \\emph{chordiogram} descriptor to encode  relative angles of boundary segments. Our contribution to recognition here is a contour-based patch detector and a patch descriptor. The  contour patch detector is based on extrema in the  torque map, and the contour patch descriptor is is based on  the torque values in the detected patch at multiple scales. We then use a simple bag-of-word representation and an SVM for object classification.\n\n\n\n\n\\label{sec:Torque Operator}\nAfter providing a definition of the torque operator,  we discuss its properties that make it useful for contour processing. Then  we provide the data-structure for  representing the torque, illustrate its application on various examples, and  discuss issues related to scale selection. Finally, we provide an efficient implementation of the torque using the so-called integral images.\n\\subsection{Definition}\n\nTorque, as defined in physics, is the tendency of a force to rotate an object about an axis.\nMathematically, torque is defined as the cross product of the force and the displacement vector from the point at which  torque is measured to the point to  which  the force is applied, as depicted in Fig.~\\ref{fig:Image torque idea}:\n\n", "index": 1, "text": "\\begin{align}\n  \\vec{\\tau} = \\vec{r} \\times \\vec{F},\\label{eq:torque}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\vec{\\tau}=\\vec{r}\\times\\vec{F},\" display=\"inline\"><mrow><mrow><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>=</mo><mrow><mover accent=\"true\"><mi>r</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>\u00d7</mo><mover accent=\"true\"><mi>F</mi><mo stretchy=\"false\">\u2192</mo></mover></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\n With slight abuse of notation, here  the cross product of  two-dimensional vectors denotes the scalar obtained by cross-multiplying the vectors. If we  further assume the force vector  of unit length, the value of the torque amounts to:\n \n", "itemtype": "equation", "pos": 26823, "prevtext": "\nwhere $\\vec{\\tau}$ is the torque vector,\n$\\vec{r}$ is the displacement vector,\nand $\\vec{F}$ is the force vector.\n\nTo define a torque measure for images,\nwe consider  forces  applied at  edge points and parallel to the tangent of the local edge.\nFor an arbitrary point, called the center point, we consider a rotation axis in three-dimensional space passing through that point and perpendicular to the image plane.\nThen we can measure the torque at any point in the image with respect to the rotation axis, as  defined in physics (see Fig.~\\ref{fig:Image torque idea}).\n\nSince the displacement vector and the force vector are both on the image surface, the torque vector is  perpendicular to the image surface, and we call the magnitude of the torque vector along the rotation axis simply the \\emph{torque} or \\emph{torque value} here and after.\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{overpic}[width=0.695\\columnwidth,keepaspectratio=true,clip]\n\t{ImageTorqueIdea.eps}\n    \\put(154,39){$p$}\n   \n   \n   \n    \\put(164,35){$\\vec{r}$}\n    \\put(188,35){$\\vec{F}$}\n    \\put(163,69){$\\vec{\\tau}$}\n    \\put( 11,27){\\rotatebox{53}{\\tiny displacement}}\n    \\put( 28,22){\\rotatebox{-25}{\\tiny force}}\n    \\put( 44,72){\\tiny torque}\n    \\end{overpic}\n  \\end{center}\n\\caption{The idea of the image torque measure is inspired by the concept of the torque in physics: Given a point $p$ and an edge point $q$ in an image, we assign a unit force vector $\\vec{F}$ along the tangent of the edge. Denoting as $\\vec{r}$ the vector from $p$ to $q$, the torque vector at $q$ is defined as $\\vec{\\tau} = \\vec{r} \\times \\vec{F}$.\nIts value along the axis perpendicular the image will be called the \\emph{torque}.\n\\label{fig:Image torque idea}}\n\\end{figure}\n\n\n\nSince our images are discrete, edges are  represented by a set of pixels. Let  $q$ be an edge point, whose edge we represent by  a vector $\\vec{F}_q$, and let  $p$ denote the center point and $\\vec{r}_{pq}$  the displacement vector from $p$ to $q$. Then the torque value at $p$ is\n\n", "index": 3, "text": "\\begin{align}\n\\vec{\\tau}_{pq} = \\vec{r}_{pq} \\times \\vec{F}_q.\\label{eq:torque_vector}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\vec{\\tau}_{pq}=\\vec{r}_{pq}\\times\\vec{F}_{q}.\" display=\"inline\"><mrow><mrow><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>=</mo><mrow><msub><mover accent=\"true\"><mi>r</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u00d7</mo><msub><mover accent=\"true\"><mi>F</mi><mo stretchy=\"false\">\u2192</mo></mover><mi>q</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nNote that in our definition edges are oriented, where the orientation is defined by contrast.\nThus, the value of the torque can have positive and negative values.\nWe define the orientation of an edge  as perpendicular clockwise to the image gradient, such that the brighter side is on its right and the darker side on its left.\n\n\nWe then define an image operator on  local image patches.\nThe \\emph{torque operator}  is defined as the sum over the torque values of  all edge points within an image patch of arbitrary shape. Applying the torque operator, $\\tau_P$, to a patch  we obtain the \\emph{torque of an image patch} as:\n\n", "itemtype": "equation", "pos": 27161, "prevtext": "\n With slight abuse of notation, here  the cross product of  two-dimensional vectors denotes the scalar obtained by cross-multiplying the vectors. If we  further assume the force vector  of unit length, the value of the torque amounts to:\n \n", "index": 5, "text": "\\begin{align}\n\\tau_{pq} = \\left\\|\\vec{r}_{pq}\\right\\|\\sin\\theta_{pq}.\\label{eq:torque for edge point}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{pq}=\\left\\|\\vec{r}_{pq}\\right\\|\\sin\\theta_{pq}.\" display=\"inline\"><mrow><mrow><msub><mi>\u03c4</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>=</mo><mrow><mrow><mo>\u2225</mo><msub><mover accent=\"true\"><mi>r</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u2225</mo></mrow><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><msub><mi>\u03b8</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $E\\left(P\\right)$ is a set of edge points in the patch $P$, and $p$ is the center point of the patch.\n$\\left|P\\right|$ is the area of the patch,\nwhich is used for normalization to achieve independence of the patch size. This will become clear in the next section, where it is shown that the torque of a patch is related to the area under the curve.\n\nWe apply the torque operator over the entire edge map, shifting the position of the patch and  varying the size of the patch as depicted in Fig.~\\ref{fig:Illustration of the torque}.\nIn principle, the shape of the patch could be arbitrary, but in this paper we will use disk or square patches for illustration (Sec. \\ref{sec:Torque Operator}), and square and rectangle patches in our efficient implementation and the experiments (Sec. \\ref{sec:app}).\n\n\n\\subsection{Properties of Torque Operator}\n\nNext some of the basic properties of the torque operator are explained to motivate the usefulness of the torque in different applications.\n\n\n\\subsubsection{Torque and Area}\n\nSince the torque is defined by the cross product of vectors, it is essentially related to the area defined by these vectors as shown in Fig.~\\ref{fig:Cross Product and Area}.\nThis relationship can  be easily extended to edge curves.\nAssuming edges are clean continuous curves, the value  of the torque in a patch is related to the position of the curves in the patch and their shape. For curve segments intersecting the boundary of the patch with center $p$ at two intersection points $q_1$ and $q_2$ as in Fig.~\\ref{fig:Torque and Area}(a), the torque is proportional to the area enclosed by the edge curve and the two line segments $\\overline{p q_1}$ and $\\overline{p q_2}$. The torque of a closed curve, completely inside the patch, is proportional to the  area under the curve (Fig.~\\ref{fig:Torque and Area} (b)). The closer  the curve to the patch boundaries, the larger the torque of the image patch. We normalize for the patch size, so we can compare the torque across scales.\n\n\nIntuitively, it then can be understood  that the  torque operator can be useful for finding the scale of closed curves.\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{overpic}[width=0.521\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaColor.eps}\n    \\put( 42,17){$p$}\n    \\put( 60,10){$\\vec{r}$}\n    \\put(105,14){$\\vec{F}$}\n    \\put( 40,45){$\\vec{\\tau}$}\n    \\put( 70,20){\\scriptsize{$\\frac{1}{2}\\left\\|\\vec{r}\\times \\vec{F}\\right\\|$}}\n    \\end{overpic}\n  \\end{center}\n\\caption{Cross product and area.\nThe triangle enclosed by  vectors $\\vec{r}$ and $\\vec{F}$ is equivalent to $\\left\\|\\vec{r}\\times \\vec{F}\\right\\|/2$.\n\\label{fig:Cross Product and Area}}\n\\end{figure}\n\n\\begin{figure}[tb]\n  \\begin{center}\n  \\begin{tabular}[htbp]{cc}\n    \\begin{minipage}{0.3\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaPartial.eps}\n      \\put( 35, 30){$p$}\n      \\put( 70, 50){$q_1$}\n      \\put( 70, 20){$q_2$}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.3\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaFull.eps}\n      \\put( 35, 30){$p$}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    (a) & (b)\n  \\end{tabular}\n  \\end{center}\n\\caption{Relationship between torque and area.\nTwo cases are shown: (a) the disk patch is smaller than the object, and it covers only a part of the boundary; (b) the disk patch covers the whole object boundary.\n\n\\label{fig:Torque and Area}}\n\\end{figure}\n\\subsubsection{Texture vs Boundary}\n An important function of the torque as a mid-level operator is to separate aligned edge structures from random texture edges.\nThe torque of  a patch will be larger when the patch has long contours and it will be largest if the edges  are structured into closed contours. On the other hand, the torque is expected to be small when the edges are due to random texture as illustrated in Fig.~\\ref{fig:Torque on Texture Edges and Boundary Edges}. This is, because in our  definition of the torque, edges have an orientation defined by the contrast. Therefore,  in textures (made up of blobs and textons)  where oriented edges in the patch appear in pairs, they cancel  each other. Assuming there is sufficient randomness in the  edge distribution, the  sum of contributions will be small.\n\n\\begin{figure}[tb]\n  \\begin{center}\n  \\begin{tabular}[htbp]{cccc}\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {EdgeMap_texture.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {TorqueValueMap_texture.eps}\n      \\put(  5,12){Max torque}\n      \\put( 20, 2){0.39}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {EdgeMap_boundary.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {TorqueValueMap_boundary.eps}\n      \\put(  5, 12){Max torque}\n      \\put( 20,  2){0.79}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    (a) & (b) & (c) & (d)\n  \\end{tabular}\n  \\end{center}\n\\caption{Torque on texture edges and boundary edges. The maximum absolute torque value (over all patch sizes) tends to be small for random texture edges (a and b) and large for closed boundaries (c and d).\n\\label{fig:Torque on Texture Edges and Boundary Edges}}\n\\end{figure}\n\\subsubsection{Extrema in Torque}\n\\label{sec:Extrema in Torque}\n\nThe torque  tends to be large in magnitude if the patch contains extended contours close to\nthe boundaries of the patch.\nTherefore, it is expected that the torque measure is useful for  finding the locations in the image  where edges are in structure forming closed contours. Furthermore, the torque can give us  the scale of the region of those  structured edges. This concepts is illustrated in\nFigure~\\ref{fig:Torque Maps for Triangle over Patch Sizes} for  an example where the structured edges form a triangle. The figure shows the torque value maps for four sizes, and graphs the torque values at the center of the triangle over all patch sizes. As can be seen, the location of structured edges, {i.e\\onedot} the triangle, can be inferred from the maximum of the torque over space and patch sizes. The patch size of the torque maximum indicates the size of the triangle.\n\n\nNext we formally define the  data-structures used in the torque computation, then we provide further examples illustrating the torque value on real objects of different shape.\n\n\\begin{figure}[tb]\n\\begin{center}\n\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{}c@{}c@{}}\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_edges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_005.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_021.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_043.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_061.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    & 2 & 10 & 21 & 30\n  \\end{tabular}\n\n\n  \\begin{tabular}{@{}c@{}}\n\n    \\begin{minipage}{0.73\\columnwidth}\n    \\begin{overpic}[width=1\\textwidth,keepaspectratio=true,clip]\n    {TorquePlotTriangle.eps}\n    \\put(  5,  0){$0$}\n    \\put( 31,  0){$5$}\n    \\put( 56,  0){$10$}\n    \\put( 83,  0){$15$}\n    \\put(109,  0){$20$}\n    \\put(135,  0){$25$}\n    \\put(163,  0){$30$}\n    \\put( 50, -8){Patch Radius (Scale)}\n    \\put( -5,  5){$0.0$}\n    \\put( -5, 23){$0.1$}\n    \\put( -5, 41){$0.2$}\n    \\put( -5, 59){$0.3$}\n    \\put( -5, 77){$0.4$}\n    \\put( -5, 95){$0.5$}\n    \\put(-13, 40){\\rotatebox{90}{Torque}}\n\t\\end{overpic}\n    \\end{minipage}\n\n  \\end{tabular}\n\n\\end{center}\n\\caption{First row: Torque maps for a triangle for  different patch sizes.\nThe numbers below the torque maps denote  the radius of the disk patch in pixels.\n\n\nSecond row: Torque values at the center of the triangle shown over patch sizes.\n\\label{fig:Torque Maps for Triangle over Patch Sizes}}\n\\end{figure}\n\n\n\\subsection{Representation of the Torque}\n\\label{sec:rep}\nBy applying the torque operator to an image using  a single patch size, we obtain a two-dimensional map of torque values.  Applying the torque operator using  multiple  patch sizes, we obtain multiple maps at different scale\n(see Fig.~\\ref{fig:Illustration of the torque}).\n \nThe set of maps at  different scales makes a  three-dimensional volume.\nHowever, it is often convenient for applications to combine the  maps at different scales into  two dimensional maps, $V$ and $S$, which we describe by the following equations:\n\n", "itemtype": "equation", "pos": 27900, "prevtext": "\nNote that in our definition edges are oriented, where the orientation is defined by contrast.\nThus, the value of the torque can have positive and negative values.\nWe define the orientation of an edge  as perpendicular clockwise to the image gradient, such that the brighter side is on its right and the darker side on its left.\n\n\nWe then define an image operator on  local image patches.\nThe \\emph{torque operator}  is defined as the sum over the torque values of  all edge points within an image patch of arbitrary shape. Applying the torque operator, $\\tau_P$, to a patch  we obtain the \\emph{torque of an image patch} as:\n\n", "index": 7, "text": "\\begin{align}\n\\tau_{P,p} = \\frac{1}{2\\left|P\\right|}\\sum_{q\\in E\\left(P\\right)}\\tau_{pq},\\label{eq:torque for patch pixel-wise}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{P,p}=\\frac{1}{2\\left|P\\right|}\\sum_{q\\in E\\left(P\\right)}%&#10;\\tau_{pq},\" display=\"inline\"><mrow><mrow><msub><mi>\u03c4</mi><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>q</mi><mo>\u2208</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>P</mi><mo>)</mo></mrow></mrow></mrow></munder></mstyle><msub><mi>\u03c4</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\n$\\tau\\left(x,y,s\\right)$ is the torque value at point $\\left(x,y\\right)$ with patch size (scale $s$). We call the three-dimensional volume of $\\tau$ the  \\emph{torque volume}, and $V$ and $S$ the  \\emph{torque value map} and \\emph{scale map}, respectively.\n\n\nFigure~\\ref{fig:Torque Value Maps and Scale Maps for Simple Shapes} shows examples of torque value maps and scale maps for some simple figures. As can be seen the torque operator captures well the concept of closure. For these simple shapes, the torque value map directly provides the location of the object, i.e. the center of the polygon, and the scale map provides its scale (at the point corresponding to the extrema in the value map).\n\n\n\n\n\n\nThe torque  maps are more complex for multiple objects located close to each other, or for objects of different topology. Figure~\\ref{fig:Torque Value Maps and Scale Maps for Multiple Objects}  illustrates the theoretical and empirical maps for two situations: the case of an object on top of another object, and the case  an object with a hole. The former is illustrated for two dark objects on  bright background with the object  at the bottom  darker than the one on top. The object regions have  negative torque value, but positive torque  values appear on the brighter object around the edges shared with the darker object. This is because  the edge orientation is defined by  polarity. In this region the  edge boundary abuts a darker region, which is in conflict with the other edges which abut brighter regions. Thus, these edges give\ntorque values of opposite sign, and result in a  positive torque value region close\nto the edge. For the case where the object has a hole, we do not have such a confusion.\n\n\n\nFigure~\\ref{fig:Torque Value Maps and Extrema in Torque} illustrates the application of the torque operator on  real images from the Berkeley dataset \\cite{Martin2001}.\nHere square patches were used with their sizes  varying from 3 to 91 pixels, and the images were downsized by a factor of two  to $161 \\times 241$. Thus the largest image patch covers about 21\\% of the  image area. Figures~\\ref{fig:Torque Value Maps and Extrema in Torque} (a)- (d) show the test images, torque value maps, and location of the extrema and corresponding patch sizes (as green squares for minima and yellow squares for maxima).\nFor each test image, the 25 maxima and 25 minima of largest absolute torque values are shown (in \\ref{fig:Torque Value Maps and Extrema in Torque} (c) and (d), respectively).\nAs can be seen from column (b), the negative torque regions match well object regions for these images. We should note  that the sign of the torque  depends on the relative brightness of an object to the background, and in all these examples the objects are darker than their surroundings (as reflected in the torque  minima in column (d)).\nAn interesting property of the torque operator is that the extrema are  not located simply at the dense edges, but at locations surrounded by edges.\nFor example, in  the image of the pheasant, the inner part of the pheasant doesn't have clear edges. Nevertheless, local minima are found in the torque volume, and  the location of structured, surrounding boundaries in these parts are detected.\nA second interesting property of the torque operator is that the extrema indicate the size of structured edges.\nReferring to the figure,\nit can be seen that the patches associated with local minima (shown in green) cover most of the object regions.\nThese properties of indicating roughly the location and size of structured edges are useful for further image processes, such as visual attention and object segmentation.\n\nFig.~\\ref{fig:Torque Value Maps and Extrema in Torque}(e) provides a comparison to the blob detection of \\cite{Lindeberg1998} using the implementation in \\cite{Kokkinos2006}. The blob detector locates the points in scale space where the square of a normalized Laplacian assumes maxima with respect to space and scale. The extrema are thus contrast invariant (i.e, both dark blobs on light background and light blobs on dark background). The torque extrema also amount to local extrema with respect to space and scale, but we separate them according to contrast.\nComparing visually the  blob detection to the  torque minima, we can see that  the latter tends to have extrema representing  whole objects. We can see that the regions of the  eagle, the pheasant, the horses, and the persons are detected by negative torque extrema in the test images. This indicates  that the torque detector has greater flexibility to shape variation.  The blob detector is maximally tuned to annular-like image patches (like the Laplacian kernel). The torque detector, if implemented with square or disk windows, also is maximally tuned to circular structures, but it also responds  to  other shapes, especially closed convex shapes, as it adds up all the edgels in the window. Furthermore, we see the torque mechanism as  a more general concept, and it can be extended in various ways. For example, we can use other window shapes, as in section \\ref{sec:rec}, or  we can also tune it to favor  certain shapes.\n\nFurthermore, besides the extrema, we can also utilize the  torque values and scales, as in Section \\ref{sec:rec}.\n\n\\begin{figure}[tb]\n\\begin{center}\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{}c@{}c@{}c@{}}\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch4_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch5_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch6_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch20_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatchNonConvex5_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch4_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch5_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch6_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch20_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatchNonConvex5_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}\n  \\end{tabular}\n\\end{center}\n\\caption{Torque value maps (upper row) and scale maps  (lower row)  for simple shapes.\nThe shapes are overlaid  onto the torque value with black lines.\nBlack regions in the scale map denote areas where  the torque value is the same over scales.\n\\label{fig:Torque Value Maps and Scale Maps for Simple Shapes}}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure}[tb]\n\\begin{center}\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{\\hspace{0.03\\columnwidth}}c@{}c@{}c@{}}\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_edgesColor.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_valueMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_edgesColor.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_valueMap.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_downsample.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_valueMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_downsample.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_valueMap.eps}\n    \\end{center}\n    \\end{minipage}\n  \\end{tabular}\n\\end{center}\n\\caption{Torque for two configurations with multiple objects.\nThe first row shows graphical examples of the configuration, and the second row shows real images with objects of such configuration.\nColumns (1 and 4), (2 and 5) and (3 and 6) show the test images, the  scale maps and  torque value maps, respectively.\n\\label{fig:Torque Value Maps and Scale Maps for Multiple Objects}}\n\\end{figure}\n\n\n\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}c@{}c@{}}\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c) & (d) & (e)\n\n    \\end{tabular}\n  \\end{center}\n\\caption{Torque value maps and extrema in torque.\n(a) Original test images. \n(b) Torque value maps.\n(c) and (d) Local maxima and local minima in torque volume, respectively. Dots indicate the location of extrema in image space, and the corresponding squares indicate  the size of the patch producing the extrema.\n(e) Blob detection \\cite{Lindeberg1998,Kokkinos2006} as reference.\n\\label{fig:Torque Value Maps and Extrema in Torque}}\n\\end{figure}\n\n\n\\subsection{Scale Selection}\n\\label{sec:Scale Selection}\n\nIn the previous section we proposed a two-dimensional representation of the torque volume as torque value map and scale map. The  torque value map and scale map are generated from the torque volume by selecting at each pixel the scale corresponding to the largest absolute torque value over scales.\nScale selection in general is an important topic in computer vision \\cite{Lindeberg1994,Lindeberg1998}, and selecting the appropriate scale can lead to  better performance  in most image processing tasks \\cite{Galun2007,XuY2012}.\n\n\nOur main focus in this paper is detection of object-like structures, and thus for most images we want  to  avoid attention to smaller structures.\nOne strategy to handle this within the torque framework, is to first reduce the noise in the torque volume due to edge fragments and then select the scale.\nStandard techniques for noise reduction such as filtering and optimization can be applied to the torque volume.\n\nAnother way to modify the scale selection is by modifying the normalization factor. This is motivated by the work of  Galun et al.~\\cite{Galun2007}, who studied the ideal threshold for multi-scale edge detection under Gaussian noise assumptions.\nThe torque for a patch is defined (from eq. \\ref{eq:torque for patch pixel-wise}) as:\n\n", "itemtype": "equation", "pos": 37605, "prevtext": "\nwhere $E\\left(P\\right)$ is a set of edge points in the patch $P$, and $p$ is the center point of the patch.\n$\\left|P\\right|$ is the area of the patch,\nwhich is used for normalization to achieve independence of the patch size. This will become clear in the next section, where it is shown that the torque of a patch is related to the area under the curve.\n\nWe apply the torque operator over the entire edge map, shifting the position of the patch and  varying the size of the patch as depicted in Fig.~\\ref{fig:Illustration of the torque}.\nIn principle, the shape of the patch could be arbitrary, but in this paper we will use disk or square patches for illustration (Sec. \\ref{sec:Torque Operator}), and square and rectangle patches in our efficient implementation and the experiments (Sec. \\ref{sec:app}).\n\n\n\\subsection{Properties of Torque Operator}\n\nNext some of the basic properties of the torque operator are explained to motivate the usefulness of the torque in different applications.\n\n\n\\subsubsection{Torque and Area}\n\nSince the torque is defined by the cross product of vectors, it is essentially related to the area defined by these vectors as shown in Fig.~\\ref{fig:Cross Product and Area}.\nThis relationship can  be easily extended to edge curves.\nAssuming edges are clean continuous curves, the value  of the torque in a patch is related to the position of the curves in the patch and their shape. For curve segments intersecting the boundary of the patch with center $p$ at two intersection points $q_1$ and $q_2$ as in Fig.~\\ref{fig:Torque and Area}(a), the torque is proportional to the area enclosed by the edge curve and the two line segments $\\overline{p q_1}$ and $\\overline{p q_2}$. The torque of a closed curve, completely inside the patch, is proportional to the  area under the curve (Fig.~\\ref{fig:Torque and Area} (b)). The closer  the curve to the patch boundaries, the larger the torque of the image patch. We normalize for the patch size, so we can compare the torque across scales.\n\n\nIntuitively, it then can be understood  that the  torque operator can be useful for finding the scale of closed curves.\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{overpic}[width=0.521\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaColor.eps}\n    \\put( 42,17){$p$}\n    \\put( 60,10){$\\vec{r}$}\n    \\put(105,14){$\\vec{F}$}\n    \\put( 40,45){$\\vec{\\tau}$}\n    \\put( 70,20){\\scriptsize{$\\frac{1}{2}\\left\\|\\vec{r}\\times \\vec{F}\\right\\|$}}\n    \\end{overpic}\n  \\end{center}\n\\caption{Cross product and area.\nThe triangle enclosed by  vectors $\\vec{r}$ and $\\vec{F}$ is equivalent to $\\left\\|\\vec{r}\\times \\vec{F}\\right\\|/2$.\n\\label{fig:Cross Product and Area}}\n\\end{figure}\n\n\\begin{figure}[tb]\n  \\begin{center}\n  \\begin{tabular}[htbp]{cc}\n    \\begin{minipage}{0.3\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaPartial.eps}\n      \\put( 35, 30){$p$}\n      \\put( 70, 50){$q_1$}\n      \\put( 70, 20){$q_2$}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.3\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1\\columnwidth,keepaspectratio=true,clip]\n    {TorqueAreaFull.eps}\n      \\put( 35, 30){$p$}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    (a) & (b)\n  \\end{tabular}\n  \\end{center}\n\\caption{Relationship between torque and area.\nTwo cases are shown: (a) the disk patch is smaller than the object, and it covers only a part of the boundary; (b) the disk patch covers the whole object boundary.\n\n\\label{fig:Torque and Area}}\n\\end{figure}\n\\subsubsection{Texture vs Boundary}\n An important function of the torque as a mid-level operator is to separate aligned edge structures from random texture edges.\nThe torque of  a patch will be larger when the patch has long contours and it will be largest if the edges  are structured into closed contours. On the other hand, the torque is expected to be small when the edges are due to random texture as illustrated in Fig.~\\ref{fig:Torque on Texture Edges and Boundary Edges}. This is, because in our  definition of the torque, edges have an orientation defined by the contrast. Therefore,  in textures (made up of blobs and textons)  where oriented edges in the patch appear in pairs, they cancel  each other. Assuming there is sufficient randomness in the  edge distribution, the  sum of contributions will be small.\n\n\\begin{figure}[tb]\n  \\begin{center}\n  \\begin{tabular}[htbp]{cccc}\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {EdgeMap_texture.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {TorqueValueMap_texture.eps}\n      \\put(  5,12){Max torque}\n      \\put( 20, 2){0.39}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {EdgeMap_boundary.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.2\\columnwidth}\n    \\begin{center}\n    \\begin{overpic}[width=1.0\\columnwidth,keepaspectratio=true,clip]\n    {TorqueValueMap_boundary.eps}\n      \\put(  5, 12){Max torque}\n      \\put( 20,  2){0.79}\n    \\end{overpic}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    (a) & (b) & (c) & (d)\n  \\end{tabular}\n  \\end{center}\n\\caption{Torque on texture edges and boundary edges. The maximum absolute torque value (over all patch sizes) tends to be small for random texture edges (a and b) and large for closed boundaries (c and d).\n\\label{fig:Torque on Texture Edges and Boundary Edges}}\n\\end{figure}\n\\subsubsection{Extrema in Torque}\n\\label{sec:Extrema in Torque}\n\nThe torque  tends to be large in magnitude if the patch contains extended contours close to\nthe boundaries of the patch.\nTherefore, it is expected that the torque measure is useful for  finding the locations in the image  where edges are in structure forming closed contours. Furthermore, the torque can give us  the scale of the region of those  structured edges. This concepts is illustrated in\nFigure~\\ref{fig:Torque Maps for Triangle over Patch Sizes} for  an example where the structured edges form a triangle. The figure shows the torque value maps for four sizes, and graphs the torque values at the center of the triangle over all patch sizes. As can be seen, the location of structured edges, {i.e\\onedot} the triangle, can be inferred from the maximum of the torque over space and patch sizes. The patch size of the torque maximum indicates the size of the triangle.\n\n\nNext we formally define the  data-structures used in the torque computation, then we provide further examples illustrating the torque value on real objects of different shape.\n\n\\begin{figure}[tb]\n\\begin{center}\n\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{}c@{}c@{}}\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_edges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_005.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_021.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_043.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.15\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_torque_061.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    & 2 & 10 & 21 & 30\n  \\end{tabular}\n\n\n  \\begin{tabular}{@{}c@{}}\n\n    \\begin{minipage}{0.73\\columnwidth}\n    \\begin{overpic}[width=1\\textwidth,keepaspectratio=true,clip]\n    {TorquePlotTriangle.eps}\n    \\put(  5,  0){$0$}\n    \\put( 31,  0){$5$}\n    \\put( 56,  0){$10$}\n    \\put( 83,  0){$15$}\n    \\put(109,  0){$20$}\n    \\put(135,  0){$25$}\n    \\put(163,  0){$30$}\n    \\put( 50, -8){Patch Radius (Scale)}\n    \\put( -5,  5){$0.0$}\n    \\put( -5, 23){$0.1$}\n    \\put( -5, 41){$0.2$}\n    \\put( -5, 59){$0.3$}\n    \\put( -5, 77){$0.4$}\n    \\put( -5, 95){$0.5$}\n    \\put(-13, 40){\\rotatebox{90}{Torque}}\n\t\\end{overpic}\n    \\end{minipage}\n\n  \\end{tabular}\n\n\\end{center}\n\\caption{First row: Torque maps for a triangle for  different patch sizes.\nThe numbers below the torque maps denote  the radius of the disk patch in pixels.\n\n\nSecond row: Torque values at the center of the triangle shown over patch sizes.\n\\label{fig:Torque Maps for Triangle over Patch Sizes}}\n\\end{figure}\n\n\n\\subsection{Representation of the Torque}\n\\label{sec:rep}\nBy applying the torque operator to an image using  a single patch size, we obtain a two-dimensional map of torque values.  Applying the torque operator using  multiple  patch sizes, we obtain multiple maps at different scale\n(see Fig.~\\ref{fig:Illustration of the torque}).\n \nThe set of maps at  different scales makes a  three-dimensional volume.\nHowever, it is often convenient for applications to combine the  maps at different scales into  two dimensional maps, $V$ and $S$, which we describe by the following equations:\n\n", "index": 9, "text": "\\begin{align}\nV\\left(x,y\\right) &= \\tau\\left(x, y, \\hat{s}\\left(x,y\\right)\\right),\\\\\nS\\left(x,y\\right) &= {\\operatorname{sgn}}\\left(V\\left(x,y\\right)\\right)\\cdot \\hat{s}\\left(x,y\\right),\\\\\n\\hat{s}\\left(x,y\\right) &= {\\operatornamewithlimits{argmax}}_s \\left|\\tau\\left(x,y,s\\right)\\right|.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle V\\left(x,y\\right)\" display=\"inline\"><mrow><mi>V</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\tau\\left(x,y,\\hat{s}\\left(x,y\\right)\\right),\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>\u03c4</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mrow><mover accent=\"true\"><mi>s</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle S\\left(x,y\\right)\" display=\"inline\"><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle={\\operatorname{sgn}}\\left(V\\left(x,y\\right)\\right)\\cdot\\hat{s}%&#10;\\left(x,y\\right),\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo>sgn</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><mi>V</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u22c5</mo><mover accent=\"true\"><mi>s</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{s}\\left(x,y\\right)\" display=\"inline\"><mrow><mover accent=\"true\"><mi>s</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle={\\operatornamewithlimits{argmax}}_{s}\\left|\\tau\\left(x,y,s\\right%&#10;)\\right|.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><munder><mo movablelimits=\"false\">argmax</mo><mi>s</mi></munder><mo>\u2061</mo><mrow><mo>|</mo><mrow><mi>\u03c4</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>s</mi><mo>)</mo></mrow></mrow><mo>|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere  $Z$ is the normalization factor, and it was set to $|P|$, i.e. the area of the patch in eq.~(\\ref{eq:torque for patch pixel-wise}). For a disk patch of radius $R$ it amounts\nto $|P|=\\pi R^2$.\nWe now vary the normalization factor by introducing a parameter $\\alpha$  as follows:\n\n", "itemtype": "equation", "pos": 55530, "prevtext": "\n$\\tau\\left(x,y,s\\right)$ is the torque value at point $\\left(x,y\\right)$ with patch size (scale $s$). We call the three-dimensional volume of $\\tau$ the  \\emph{torque volume}, and $V$ and $S$ the  \\emph{torque value map} and \\emph{scale map}, respectively.\n\n\nFigure~\\ref{fig:Torque Value Maps and Scale Maps for Simple Shapes} shows examples of torque value maps and scale maps for some simple figures. As can be seen the torque operator captures well the concept of closure. For these simple shapes, the torque value map directly provides the location of the object, i.e. the center of the polygon, and the scale map provides its scale (at the point corresponding to the extrema in the value map).\n\n\n\n\n\n\nThe torque  maps are more complex for multiple objects located close to each other, or for objects of different topology. Figure~\\ref{fig:Torque Value Maps and Scale Maps for Multiple Objects}  illustrates the theoretical and empirical maps for two situations: the case of an object on top of another object, and the case  an object with a hole. The former is illustrated for two dark objects on  bright background with the object  at the bottom  darker than the one on top. The object regions have  negative torque value, but positive torque  values appear on the brighter object around the edges shared with the darker object. This is because  the edge orientation is defined by  polarity. In this region the  edge boundary abuts a darker region, which is in conflict with the other edges which abut brighter regions. Thus, these edges give\ntorque values of opposite sign, and result in a  positive torque value region close\nto the edge. For the case where the object has a hole, we do not have such a confusion.\n\n\n\nFigure~\\ref{fig:Torque Value Maps and Extrema in Torque} illustrates the application of the torque operator on  real images from the Berkeley dataset \\cite{Martin2001}.\nHere square patches were used with their sizes  varying from 3 to 91 pixels, and the images were downsized by a factor of two  to $161 \\times 241$. Thus the largest image patch covers about 21\\% of the  image area. Figures~\\ref{fig:Torque Value Maps and Extrema in Torque} (a)- (d) show the test images, torque value maps, and location of the extrema and corresponding patch sizes (as green squares for minima and yellow squares for maxima).\nFor each test image, the 25 maxima and 25 minima of largest absolute torque values are shown (in \\ref{fig:Torque Value Maps and Extrema in Torque} (c) and (d), respectively).\nAs can be seen from column (b), the negative torque regions match well object regions for these images. We should note  that the sign of the torque  depends on the relative brightness of an object to the background, and in all these examples the objects are darker than their surroundings (as reflected in the torque  minima in column (d)).\nAn interesting property of the torque operator is that the extrema are  not located simply at the dense edges, but at locations surrounded by edges.\nFor example, in  the image of the pheasant, the inner part of the pheasant doesn't have clear edges. Nevertheless, local minima are found in the torque volume, and  the location of structured, surrounding boundaries in these parts are detected.\nA second interesting property of the torque operator is that the extrema indicate the size of structured edges.\nReferring to the figure,\nit can be seen that the patches associated with local minima (shown in green) cover most of the object regions.\nThese properties of indicating roughly the location and size of structured edges are useful for further image processes, such as visual attention and object segmentation.\n\nFig.~\\ref{fig:Torque Value Maps and Extrema in Torque}(e) provides a comparison to the blob detection of \\cite{Lindeberg1998} using the implementation in \\cite{Kokkinos2006}. The blob detector locates the points in scale space where the square of a normalized Laplacian assumes maxima with respect to space and scale. The extrema are thus contrast invariant (i.e, both dark blobs on light background and light blobs on dark background). The torque extrema also amount to local extrema with respect to space and scale, but we separate them according to contrast.\nComparing visually the  blob detection to the  torque minima, we can see that  the latter tends to have extrema representing  whole objects. We can see that the regions of the  eagle, the pheasant, the horses, and the persons are detected by negative torque extrema in the test images. This indicates  that the torque detector has greater flexibility to shape variation.  The blob detector is maximally tuned to annular-like image patches (like the Laplacian kernel). The torque detector, if implemented with square or disk windows, also is maximally tuned to circular structures, but it also responds  to  other shapes, especially closed convex shapes, as it adds up all the edgels in the window. Furthermore, we see the torque mechanism as  a more general concept, and it can be extended in various ways. For example, we can use other window shapes, as in section \\ref{sec:rec}, or  we can also tune it to favor  certain shapes.\n\nFurthermore, besides the extrema, we can also utilize the  torque values and scales, as in Section \\ref{sec:rec}.\n\n\\begin{figure}[tb]\n\\begin{center}\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{}c@{}c@{}c@{}}\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch4_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch5_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch6_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch20_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatchNonConvex5_valueMapEdges.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch3_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch4_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch5_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch6_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatch20_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.166\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentCirclePatchNonConvex5_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}\n  \\end{tabular}\n\\end{center}\n\\caption{Torque value maps (upper row) and scale maps  (lower row)  for simple shapes.\nThe shapes are overlaid  onto the torque value with black lines.\nBlack regions in the scale map denote areas where  the torque value is the same over scales.\n\\label{fig:Torque Value Maps and Scale Maps for Simple Shapes}}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure}[tb]\n\\begin{center}\n  \\begin{tabular}[htbp]{@{}c@{}c@{}c@{\\hspace{0.03\\columnwidth}}c@{}c@{}c@{}}\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_edgesColor.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects01_valueMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_edgesColor.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {TheoriticalLineSegmentsCirclePatchMultiObjects3_06_valueMap.eps}\n    \\end{center}\n    \\end{minipage}\\\\\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_downsample.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-028_valueMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_downsample.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_scaleMap.eps}\n    \\end{center}\n    \\end{minipage}&\n\n    \\begin{minipage}{0.16\\columnwidth}\n    \\begin{center}\n    \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true]\n    {sc-032_valueMap.eps}\n    \\end{center}\n    \\end{minipage}\n  \\end{tabular}\n\\end{center}\n\\caption{Torque for two configurations with multiple objects.\nThe first row shows graphical examples of the configuration, and the second row shows real images with objects of such configuration.\nColumns (1 and 4), (2 and 5) and (3 and 6) show the test images, the  scale maps and  torque value maps, respectively.\n\\label{fig:Torque Value Maps and Scale Maps for Multiple Objects}}\n\\end{figure}\n\n\n\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}c@{}c@{}}\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_042049_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_043074_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_197017_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_image.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_valueMap.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_extremaPositive.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_extremaNegative.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {Extrema_170057_blobs2.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c) & (d) & (e)\n\n    \\end{tabular}\n  \\end{center}\n\\caption{Torque value maps and extrema in torque.\n(a) Original test images. \n(b) Torque value maps.\n(c) and (d) Local maxima and local minima in torque volume, respectively. Dots indicate the location of extrema in image space, and the corresponding squares indicate  the size of the patch producing the extrema.\n(e) Blob detection \\cite{Lindeberg1998,Kokkinos2006} as reference.\n\\label{fig:Torque Value Maps and Extrema in Torque}}\n\\end{figure}\n\n\n\\subsection{Scale Selection}\n\\label{sec:Scale Selection}\n\nIn the previous section we proposed a two-dimensional representation of the torque volume as torque value map and scale map. The  torque value map and scale map are generated from the torque volume by selecting at each pixel the scale corresponding to the largest absolute torque value over scales.\nScale selection in general is an important topic in computer vision \\cite{Lindeberg1994,Lindeberg1998}, and selecting the appropriate scale can lead to  better performance  in most image processing tasks \\cite{Galun2007,XuY2012}.\n\n\nOur main focus in this paper is detection of object-like structures, and thus for most images we want  to  avoid attention to smaller structures.\nOne strategy to handle this within the torque framework, is to first reduce the noise in the torque volume due to edge fragments and then select the scale.\nStandard techniques for noise reduction such as filtering and optimization can be applied to the torque volume.\n\nAnother way to modify the scale selection is by modifying the normalization factor. This is motivated by the work of  Galun et al.~\\cite{Galun2007}, who studied the ideal threshold for multi-scale edge detection under Gaussian noise assumptions.\nThe torque for a patch is defined (from eq. \\ref{eq:torque for patch pixel-wise}) as:\n\n", "index": 11, "text": "\\begin{align}\n\\tau_{P,p} &= \\frac{1}{2 Z}\\sum_{q\\in E\\left(P\\right)}\\tau_{pq},\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{P,p}\" display=\"inline\"><msub><mi>\u03c4</mi><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{2Z}\\sum_{q\\in E\\left(P\\right)}\\tau_{pq},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>Z</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>q</mi><mo>\u2208</mo><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>P</mi><mo>)</mo></mrow></mrow></mrow></munder></mstyle><msub><mi>\u03c4</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nFig.~\\ref{fig:Torque value maps with different normalization factor} shows torque value maps  for different  $\\alpha$ values.\nAs can be seen from the figure, the torque value maps  become   smoother as $\\alpha$ gets smaller.\n This is because  image patches of larger size now have a  smaller normalization factor, and therefore they tend to produce relatively higher torque values. As a result larger edge structures get favored.\nThus, a smaller $\\alpha$ gives the effect of smoothing the torque value maps. An $\\alpha=1$  corresponds to a normalization by the square root of the patch area, which is also the ideal  normalization of the area term derived  by \\cite{Galun2007} for edge multi-scale detection.\nIn general, the amount of smoothing preferred will depend on the application, and by adjusting  the normalization factor, $\\alpha$, one can easily adapt the torque operator.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}c@{}}\n\n      Test Image & $\\alpha=1.0$ & $\\alpha=1.5$ & $\\alpha=2.0$\\\\\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\\if 0\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\\fi\n\t  (a) & (b) & (c) & (d)\n    \\end{tabular}\n  \\end{center}\n\\caption{Torque value maps with different normalization factors.\n(a)  Test images;\n(b)-(d)  torque value maps corresponding to the normalization factor $\\alpha$ shown at the top of each column.\nAs  $\\alpha$ gets larger, the number of positive and negative regions in the torque value map increases.\n\n\\label{fig:Torque value maps with different normalization factor}}\n\\end{figure}\n\n\n\\subsection{Efficient Torque Computation}\n\nThe computation of torque would be time consuming with a straightforward implementation.\nHowever, the torque can be computed efficiently  using the concept of integral images, which will be explained next.  \\ref{sec:gradient} then discusses a slightly modified torque definition, which allows for a very efficient computation.\n\n\nFirst, let us quickly review the concept. An integral image (or summed area table) is a data-structure and algorithm to generate the sum of values in rectangular areas of an image. Let $k(x,y)$  be some image quantity. The  value  $K(x,y)$ for the  region of pixels in the range $[0 \\dots x, 0 \\dots y]$ amounts to\n\n", "itemtype": "equation", "pos": 55906, "prevtext": "\nwhere  $Z$ is the normalization factor, and it was set to $|P|$, i.e. the area of the patch in eq.~(\\ref{eq:torque for patch pixel-wise}). For a disk patch of radius $R$ it amounts\nto $|P|=\\pi R^2$.\nWe now vary the normalization factor by introducing a parameter $\\alpha$  as follows:\n\n", "index": 13, "text": "\\begin{align}\nZ &= \\pi R^\\alpha.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle Z\" display=\"inline\"><mi>Z</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\pi R^{\\alpha}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mi>\u03b1</mi></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nand it can be computed in a single pass over the image\n\nas\n\n", "itemtype": "equation", "pos": 60519, "prevtext": "\nFig.~\\ref{fig:Torque value maps with different normalization factor} shows torque value maps  for different  $\\alpha$ values.\nAs can be seen from the figure, the torque value maps  become   smoother as $\\alpha$ gets smaller.\n This is because  image patches of larger size now have a  smaller normalization factor, and therefore they tend to produce relatively higher torque values. As a result larger edge structures get favored.\nThus, a smaller $\\alpha$ gives the effect of smoothing the torque value maps. An $\\alpha=1$  corresponds to a normalization by the square root of the patch area, which is also the ideal  normalization of the area term derived  by \\cite{Galun2007} for edge multi-scale detection.\nIn general, the amount of smoothing preferred will depend on the application, and by adjusting  the normalization factor, $\\alpha$, one can easily adapt the torque operator.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}c@{}}\n\n      Test Image & $\\alpha=1.0$ & $\\alpha=1.5$ & $\\alpha=2.0$\\\\\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {291000_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {296059_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\\if 0\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_10.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_15.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {58060_valueMap_20.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\\fi\n\t  (a) & (b) & (c) & (d)\n    \\end{tabular}\n  \\end{center}\n\\caption{Torque value maps with different normalization factors.\n(a)  Test images;\n(b)-(d)  torque value maps corresponding to the normalization factor $\\alpha$ shown at the top of each column.\nAs  $\\alpha$ gets larger, the number of positive and negative regions in the torque value map increases.\n\n\\label{fig:Torque value maps with different normalization factor}}\n\\end{figure}\n\n\n\\subsection{Efficient Torque Computation}\n\nThe computation of torque would be time consuming with a straightforward implementation.\nHowever, the torque can be computed efficiently  using the concept of integral images, which will be explained next.  \\ref{sec:gradient} then discusses a slightly modified torque definition, which allows for a very efficient computation.\n\n\nFirst, let us quickly review the concept. An integral image (or summed area table) is a data-structure and algorithm to generate the sum of values in rectangular areas of an image. Let $k(x,y)$  be some image quantity. The  value  $K(x,y)$ for the  region of pixels in the range $[0 \\dots x, 0 \\dots y]$ amounts to\n\n", "index": 15, "text": "\\begin{equation}\\label{eq:k}\n    K(x,y) =\\sum_{u\\leq x} \\sum_{v\\leq y} k(x,y),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"K(x,y)=\\sum_{u\\leq x}\\sum_{v\\leq y}k(x,y),\" display=\"block\"><mrow><mrow><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>u</mi><mo>\u2264</mo><mi>x</mi></mrow></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2264</mo><mi>y</mi></mrow></munder><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nOnce the table has been created, the sum of values in any rectangular region $[a \\dots b, c \\dots d]$\n \n can be computed  in constant time\nwith only one addition and two subtractions\nas:\n\\begin{eqnarray}\\label{eq:sum}\n\\sum_{u=a}^{b} \\sum_{v=c}^{d}k(u,v)&=& K(a,c) + K(b, d) -K(a, d) - K(b, c).\n\\end{eqnarray}\n\nLet us now explain  how to use these concepts  to compute the torque.\nLet $o$ be the origin of the image coordinate system in the left top corner of the image,\nand let $p$ be the center of a patch $P$, and  $\\overrightarrow {F_q}$  the edge vector at $q$.\n We emphasize that now we need to change the  center  with respect to which  we compute the torque, which is denoted as  subscript in our notation.\n\nUsing a vector notation, the torque of the patch $P$ with respect to center $p$ without normalization can be written as:\n\\begin{eqnarray}\\label{eqn:torque_integral}\n\\vec{\\tau}_{P,p} \\cdot (2\\left|P\\right|)\n& = & \\sum\\limits_{q \\in P} \\overrightarrow {pq} \\times  \\overrightarrow {F_q} \\notag \\\\\n& = & \\sum\\limits_{q \\in P} (\\overrightarrow {po} + \\overrightarrow {oq}) \\times  \\overrightarrow {F_q} \\notag  \\\\\n& = & -\\overrightarrow {op} \\times \\sum_{q \\in P} {\\overrightarrow {F_q}} + \\sum_{q \\in P} {\\overrightarrow{oq}} \\times {\\overrightarrow{F_q}}.\n\\end{eqnarray}\nThe first term in eq. (\\ref{eqn:torque_integral}) amounts to the cross-product of the vector from the origin to $p$ and the vector of the sum of edges in the patch. The second term is the torque computed with respect to the origin of the image. If we express the vectors in terms of their components to denote $\\overrightarrow {op}=(x,y)$, $\\overrightarrow {oq}=(u,v)$ and   $F_q = (F^x(u,v), F^y(u,v))$, we can rewrite eq. (\\ref{eqn:torque_integral})\nas\n\n", "itemtype": "equation", "pos": 60672, "prevtext": "\nand it can be computed in a single pass over the image\n\nas\n\n", "index": 17, "text": "\\begin{equation}\\label{eq:K_(x,y)}\n   K(x,y) = k(x,y) + K(x-1,y) + K(x, y-1) - K(x-1,y-1).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"K(x,y)=k(x,y)+K(x-1,y)+K(x,y-1)-K(x-1,y-1).\" display=\"block\"><mrow><mrow><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mrow><mi>y</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mrow><mi>y</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nNow it becomes clear that for each of the terms $F^x$, $F^y$,$u F^y$ and $v F^x$  we can pre-compute summed area tables with respect to the origin, and then compute the values  for any patch in linear time to derive the torque of the patch.\n\n\n\nFurther efficiency in the torque computation can be obtained by approximating the edge orientation to one of equally  divided eight directions:\n\n", "itemtype": "equation", "pos": 62517, "prevtext": "\nOnce the table has been created, the sum of values in any rectangular region $[a \\dots b, c \\dots d]$\n \n can be computed  in constant time\nwith only one addition and two subtractions\nas:\n\\begin{eqnarray}\\label{eq:sum}\n\\sum_{u=a}^{b} \\sum_{v=c}^{d}k(u,v)&=& K(a,c) + K(b, d) -K(a, d) - K(b, c).\n\\end{eqnarray}\n\nLet us now explain  how to use these concepts  to compute the torque.\nLet $o$ be the origin of the image coordinate system in the left top corner of the image,\nand let $p$ be the center of a patch $P$, and  $\\overrightarrow {F_q}$  the edge vector at $q$.\n We emphasize that now we need to change the  center  with respect to which  we compute the torque, which is denoted as  subscript in our notation.\n\nUsing a vector notation, the torque of the patch $P$ with respect to center $p$ without normalization can be written as:\n\\begin{eqnarray}\\label{eqn:torque_integral}\n\\vec{\\tau}_{P,p} \\cdot (2\\left|P\\right|)\n& = & \\sum\\limits_{q \\in P} \\overrightarrow {pq} \\times  \\overrightarrow {F_q} \\notag \\\\\n& = & \\sum\\limits_{q \\in P} (\\overrightarrow {po} + \\overrightarrow {oq}) \\times  \\overrightarrow {F_q} \\notag  \\\\\n& = & -\\overrightarrow {op} \\times \\sum_{q \\in P} {\\overrightarrow {F_q}} + \\sum_{q \\in P} {\\overrightarrow{oq}} \\times {\\overrightarrow{F_q}}.\n\\end{eqnarray}\nThe first term in eq. (\\ref{eqn:torque_integral}) amounts to the cross-product of the vector from the origin to $p$ and the vector of the sum of edges in the patch. The second term is the torque computed with respect to the origin of the image. If we express the vectors in terms of their components to denote $\\overrightarrow {op}=(x,y)$, $\\overrightarrow {oq}=(u,v)$ and   $F_q = (F^x(u,v), F^y(u,v))$, we can rewrite eq. (\\ref{eqn:torque_integral})\nas\n\n", "index": 19, "text": "\\begin{align}\n\\vec{\\tau}_{P,p} \\cdot (2\\left|P\\right|) &=\\nonumber\\\\\n&\\left. - x \\sum_{\\left(u,v\\right)\\in P} F^y\\left(u,v\\right) + y \\sum_{\\left(u,v\\right)\\in P} F^x\\left(u,v\\right)\\right.\\nonumber\\\\\n&\\left. + \\sum_{\\left(u,v\\right)\\in P} u F^y\\left(u,v\\right) - \\sum_{\\left(u,v\\right)\\in P} v F^x\\left(u,v\\right)\\right.\n\\label{eq:torque summation}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\vec{\\tau}_{P,p}\\cdot(2\\left|P\\right|)\" display=\"inline\"><mrow><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\" display=\"inline\"><mo>=</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left.-x\\sum_{\\left(u,v\\right)\\in P}F^{y}\\left(u,v\\right)+y\\sum_{%&#10;\\left(u,v\\right)\\in P}F^{x}\\left(u,v\\right)\\right.\" display=\"inline\"><mrow><mrow><mo>-</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><msup><mi>F</mi><mi>y</mi></msup><mo>\u2062</mo><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mi>y</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><msup><mi>F</mi><mi>x</mi></msup><mo>\u2062</mo><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left.+\\sum_{\\left(u,v\\right)\\in P}uF^{y}\\left(u,v\\right)-\\sum_{%&#10;\\left(u,v\\right)\\in P}vF^{x}\\left(u,v\\right)\\right.\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><mi>u</mi><mo>\u2062</mo><msup><mi>F</mi><mi>y</mi></msup><mo>\u2062</mo><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><mi>v</mi><mo>\u2062</mo><msup><mi>F</mi><mi>x</mi></msup><mo>\u2062</mo><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $i\\in \\left\\{1,2,3,4,5,6,7,8\\right\\}$ is the index to the orientation.\nAn edge vector of orientation $\\theta_i$  is represented by a unit vector\n$\\left(\\cos\\theta_i,\\sin\\theta_i\\right)$.\n\n\n\nThe torque at a point $q = (x,y)$ with respect to center $o$ for an edge vector in orientation $i$ then amounts to\n\n", "itemtype": "equation", "pos": 63267, "prevtext": "\nNow it becomes clear that for each of the terms $F^x$, $F^y$,$u F^y$ and $v F^x$  we can pre-compute summed area tables with respect to the origin, and then compute the values  for any patch in linear time to derive the torque of the patch.\n\n\n\nFurther efficiency in the torque computation can be obtained by approximating the edge orientation to one of equally  divided eight directions:\n\n", "index": 21, "text": "\\begin{align}\n\\theta_i = \\left(i-1\\right)\\frac{2\\pi}{8},\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\theta_{i}=\\left(i-1\\right)\\frac{2\\pi}{8},\" display=\"inline\"><mrow><mrow><msub><mi>\u03b8</mi><mi>i</mi></msub><mo>=</mo><mrow><mrow><mo>(</mo><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mn>8</mn></mfrac></mstyle></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $\\delta\\left(q,i\\right)\\in \\left\\{0,1\\right\\}$ is a binary indicator for the existence of an edge at pixel $q$ in the  orientation indicated by $i$, and\nthe torque at  point $q$ is:\n\n", "itemtype": "equation", "pos": 63647, "prevtext": "\nwhere $i\\in \\left\\{1,2,3,4,5,6,7,8\\right\\}$ is the index to the orientation.\nAn edge vector of orientation $\\theta_i$  is represented by a unit vector\n$\\left(\\cos\\theta_i,\\sin\\theta_i\\right)$.\n\n\n\nThe torque at a point $q = (x,y)$ with respect to center $o$ for an edge vector in orientation $i$ then amounts to\n\n", "index": 23, "text": "\\begin{align}\n\\tau_{oq}(i) &= (x \\sin \\theta_i-y \\cos\\theta_i )\\cdot \\delta\\left(q,i\\right), \\label{eq:torque for edge point approximated}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{oq}(i)\" display=\"inline\"><mrow><msub><mi>\u03c4</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(x\\sin\\theta_{i}-y\\cos\\theta_{i})\\cdot\\delta\\left(q,i\\right),\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>x</mi><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><msub><mi>\u03b8</mi><mi>i</mi></msub></mrow></mrow><mo>-</mo><mrow><mi>y</mi><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><msub><mi>\u03b8</mi><mi>i</mi></msub></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>\u03b4</mi></mrow><mo>\u2062</mo><mrow><mo>(</mo><mi>q</mi><mo>,</mo><mi>i</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\n\n\n\nWith this approximation, the torque  in an  image patch before normalization in eq. (\\ref{eqn:torque_integral}) becomes\n\n", "itemtype": "equation", "pos": 63986, "prevtext": "\nwhere $\\delta\\left(q,i\\right)\\in \\left\\{0,1\\right\\}$ is a binary indicator for the existence of an edge at pixel $q$ in the  orientation indicated by $i$, and\nthe torque at  point $q$ is:\n\n", "index": 25, "text": "\\begin{align}\n\\tau_{oq}  &= \\sum^{8}_{i=1} \\tau_{oq}(i). \\label{eq:torque approximate}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{oq}\" display=\"inline\"><msub><mi>\u03c4</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>q</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum^{8}_{i=1}\\tau_{oq}(i).\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>8</mn></munderover></mstyle><mrow><msub><mi>\u03c4</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nWe then implement the torque by keeping two three-dimensional arrays, one\n to store the edges, represented as $\\delta\\left(x,y,i\\right)$, and  one to store the torque values $\\tau\\left(x,y,i\\right)$, and we compute summed area tables for each $\\delta\\left(x,y,i\\right)$ and  $\\tau\\left(x,y,i\\right)$.\nThe computational cost is independent of  the patch size. For any given patch size, computing the torque for all patches in the  image is linear in the  number of pixels $N$, i.e. $O\\left(N\\right)$.\n\nFinally, let us  look at the computational efficiency of the Torque operator  and compare it to common approaches.\nThe well-known SIFT algorithm involves  two steps: detection of  key points and generation of a description.\nThe key point search in SIFT, which is like  blob detection, has  similarity to the extrema detection in the torque volume as both are  multi-scale  localization procedures of interest points.\nAs analyzed in \\cite{Grabner2006}, the highest costs in the key point search in  SIFT  are due to the multiple convolutions with the Gaussian operator to compute extrema in DoG space. Although it is common to down-sample the  image to avoid  computational costs due to increasing operator size, the convolutions  require time linear in the  size of image, $N$, times the size of Gaussian operator, $M$, for each scale, i.e. $O\\left(N M\\right)$. On the other hand, because of the use of integral images, the computational complexity deriving a torque map from edge responses, is linear in the image size.\n\nThe torque operator requires as input edges, whose computational cost depends on the sophistication of the edge detection algorithm. Assuming a simple edge detection, based on differences only, as  in the code provided, the computation of the torque is more efficient than standard interest point detection. However, we should note that alternative more efficient  approaches have been proposed for keypoint detection, such as the use of the box filter \\cite{Grabner2006} or the Harris detector \\cite{Suzuki2013} with integral images, instead of Laplacian filtering.\n\n\n\n\n\\label{sec:app}\n\nNext we demonstrate the usefulness of the torque in a number of applications.\nWe focus on the   visual  processes for locating objects in the scene: visual attention, boundary detection, and foreground segmentation, as depicted in Fig.~\\ref{fig:Visual Processing using Torque}.\nAlthough there could be different approaches to object detection and localization when one considers single images, an approach involving  the above  three modules is necessary in mobile robot applications: First the\nattention mechanism  focuses the processing to a conspicuous region - the region of interest. Then contours are extracted and the object in the region of interest is segmented.\nWe evaluate how much the proposed torque operator could improve these three processes by comparing against other methods in standard database settings. Finally, we demonstrate  the torque mechanism in a contour based object detection and recognition scheme. \n \n\\begin{figure}[htbp]\n\\begin{center}\n  \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n  {Process.eps}\n\\end{center}\n\\caption{Visual processing using the image torque operator.\n\\label{fig:Visual Processing using Torque}}\n\\end{figure}\n\n\\subsection{Visual Attention}\n\nAs  discussed in section \\ref{sec:Extrema in Torque}\n\nthe torque operator tends to produce extrema  at  points surrounded by boundary edges, and for  patch sizes corresponding to  object size.\nThis property of the torque operator is expected to be useful as a cue for bottom-up visual attention.\nIn the following experiment, we computed two torque-based saliency maps. One is generated as  mixture of Gaussians with the  Gaussian distributions centered at the  extrema in the torque volume, and the other is a weighted sum of the generated saliency map and the graph-based visual saliency (GBVS) by Harel {et al\\onedot} \\cite{Harel2006}.\nWe used weights of 0.3 for the torque-based saliency map and 0.7 for the GBVS,\nwhich were found empirically from  evaluations on subsets of the dataset.\n\n\n\n\nWe used the eye tracking data by Judd {et al\\onedot}. \\cite{Judd2009} to generate ground truth saliency maps.\nFixation points were extracted from the data, and saliency maps were generated as mixture of Gaussian distributions centered at the fixation points, and the generated saliency maps were normalized in the range $[0,1]$. The ground truth saliency maps were  binarized by a threshold (we used 0.5) in the quantitative comparison.\n\nWe resized the test images such that the shorter side of the images was  150 pixels, in order to reduce computational time and standardize the image size.\nThe standard deviation of the Gaussian distributions used to generate the ground truth and torque-based saliency maps were both set to 25 pixels.\n\nThe torque-based saliency maps were quantitatively compared with the saliency maps of \\cite{Itti1998} and \\cite{Harel2006}.\nWe binarized the computed saliency maps  for a set of threshold values  equally distant in $[0,1]$, and  evaluated precision and recall of the binarized saliency maps as follows:\n\n", "itemtype": "equation", "pos": 64208, "prevtext": "\n\n\n\nWith this approximation, the torque  in an  image patch before normalization in eq. (\\ref{eqn:torque_integral}) becomes\n\n", "index": 27, "text": "\\begin{align}\n\\vec{\\tau}_{P,p} \\cdot (2\\left|P\\right|)=& \\nonumber\\\\\n&\\left. \\sum^{8}_{i=1} \\left((- x \\sin \\theta_i + y \\cos \\theta_i) \\sum_{\\left(u,v\\right)\\in P} \\delta\\left((u,v),i\\right) \\right\n) \\right.\\nonumber\\\\\n&\\left. + \\sum^{8}_{i=1} \\sum_{\\left(u,v\\right)\\in P} \\tau_o((u,v),i) \\right.\n\\label{eq:torque summation2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\vec{\\tau}_{P,p}\\cdot(2\\left|P\\right|)=\" display=\"inline\"><mrow><mrow><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left.\\sum^{8}_{i=1}\\left((-x\\sin\\theta_{i}+y\\cos\\theta_{i})\\sum_%&#10;{\\left(u,v\\right)\\in P}\\delta\\left((u,v),i\\right)\\right)\\right.\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>8</mn></munderover></mstyle><mrow><mo>(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo>-</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><msub><mi>\u03b8</mi><mi>i</mi></msub></mrow></mrow></mrow><mo>+</mo><mrow><mi>y</mi><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><msub><mi>\u03b8</mi><mi>i</mi></msub></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi>i</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left.+\\sum^{8}_{i=1}\\sum_{\\left(u,v\\right)\\in P}\\tau_{o}((u,v),i%&#10;)\\right.\" display=\"inline\"><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>8</mn></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>)</mo></mrow><mo>\u2208</mo><mi>P</mi></mrow></munder></mstyle><mrow><msub><mi>\u03c4</mi><mi>o</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $S$ is the binarized  saliency map, and\n$\\mathcal{G}$ is the binarized ground truth saliency map.\n$P$ and $R$ denote precision and recall respectively.\n$TP$, $FP$, $FN$ are true positive, false positive, and false negative, respectively.\nFig.~\\ref{fig:Evaluation of Attention Models} shows the\nROC curves and maximum F-measures computed from the  898 test images in the dataset.\nExamples of computed saliency maps along  with the ground-truth are shown in Fig.~\\ref{fig:Visual Attention Models Comparison}.\nThe quantitative comparison shows that  the attention map  based only on torque does not outperform GBVS.\nHowever, the torque measure as additional mid-level visual cue improves the quality of GBVS.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{}c@{}}\n      \\begin{minipage}{0.50\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {Attention_ROCs.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.45\\columnwidth}\n      \\begin{center}\n      \\begin{tabular}{|c|c|}\n      \\hline\n\t   method & F-measure \\\\\n\t  \\hline\n\t  Itti & 0.528 \\\\\n\t  GBVS & 0.588 \\\\\n\t  Torque & 0.538 \\\\\n\t  GBVS+Torque & {\\bfseries 0.599}\\\\\n\t  \\hline\n      \\end{tabular}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b)\n    \\end{tabular}\n  \\end{center}\n\\caption{Evaluation of attention models. (a) ROC curves. (b) F-measure scores.\n\\label{fig:Evaluation of Attention Models}}\n\\end{figure}\n\n\\if 0\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|}\n\n\t  \\hline\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Itti}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{GBVS}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\scriptsize{GBVS+Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Ground truth}\n      \\end{center}\n      \\end{minipage}\\\\\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\hline\n\n    \\end{tabular}\n  \\end{center}\n  \\caption{Examples of visual attention.\nSaliency maps computed by four different methods and ground-truth saliency map are visualized by overlaying onto test image respectively.\n  \\label{fig:Visual Attention Models Comparison}}\n\\end{figure}\n\\fi\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|}\n\n\t  \\hline\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Itti {et al\\onedot}}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{GBVS}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Troque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\scriptsize{GBVS+Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Ground truth}\n      \\end{center}\n      \\end{minipage}\\\\\n\t\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.608 & 0.486 & {\\bf 0.687} & 0.544 & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n\t  0.700 & 0.718 & 0.789 & {\\bf 0.794} & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.558 & {\\bf 0.604} & 0.481 & 0.585 & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.775 & 0.795 & 0.774 & {\\bf 0.811} & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.690 & 0.760 & 0.815 & {\\bf 0.818} & \\\\\n\n      \\hline\n\n    \\end{tabular}\n  \\end{center}\n\\caption{Examples of Visual Attention.\nSaliency maps computed by four different methods and the ground-truth saliency map  are overlayed on the respective test images. The maximum F-measure is shown below each saliency map.\n\\label{fig:Visual Attention Models Comparison}}\n\\end{figure}\n\n\n\\subsection{Boundary Detection}\n\n\nIn our boundary detection we use the torque volume to reweigh edges according to their contribution to large torque values.\nThe contribution of an edge point to  torque values of different patches can be obtained  as:\n\\begin{eqnarray}\n\\upsilon_q = \\sum_{\\left\\{P|q\\in P\\right\\}}\\tau_{p\\left(P\\right)q},\\label{eq:edge contribution}\n\\end{eqnarray}\nwhere $p\\left(P\\right)$ indicates the center of the patch $P$, and\n$q$ is an edge point.\n\nThe  idea is the same as for the  attention mechanism. Extrema in the torque volume indicate the existence of edges surrounding the center of a patch.\nTherefore, edges on object boundaries  should have a large contribution to  extrema (eq.~\\ref{eq:edge contribution}).\nEdges are strengthened by combining the original edge with the value of this contribution  as follows:\n\n", "itemtype": "equation", "pos": 69711, "prevtext": "\nWe then implement the torque by keeping two three-dimensional arrays, one\n to store the edges, represented as $\\delta\\left(x,y,i\\right)$, and  one to store the torque values $\\tau\\left(x,y,i\\right)$, and we compute summed area tables for each $\\delta\\left(x,y,i\\right)$ and  $\\tau\\left(x,y,i\\right)$.\nThe computational cost is independent of  the patch size. For any given patch size, computing the torque for all patches in the  image is linear in the  number of pixels $N$, i.e. $O\\left(N\\right)$.\n\nFinally, let us  look at the computational efficiency of the Torque operator  and compare it to common approaches.\nThe well-known SIFT algorithm involves  two steps: detection of  key points and generation of a description.\nThe key point search in SIFT, which is like  blob detection, has  similarity to the extrema detection in the torque volume as both are  multi-scale  localization procedures of interest points.\nAs analyzed in \\cite{Grabner2006}, the highest costs in the key point search in  SIFT  are due to the multiple convolutions with the Gaussian operator to compute extrema in DoG space. Although it is common to down-sample the  image to avoid  computational costs due to increasing operator size, the convolutions  require time linear in the  size of image, $N$, times the size of Gaussian operator, $M$, for each scale, i.e. $O\\left(N M\\right)$. On the other hand, because of the use of integral images, the computational complexity deriving a torque map from edge responses, is linear in the image size.\n\nThe torque operator requires as input edges, whose computational cost depends on the sophistication of the edge detection algorithm. Assuming a simple edge detection, based on differences only, as  in the code provided, the computation of the torque is more efficient than standard interest point detection. However, we should note that alternative more efficient  approaches have been proposed for keypoint detection, such as the use of the box filter \\cite{Grabner2006} or the Harris detector \\cite{Suzuki2013} with integral images, instead of Laplacian filtering.\n\n\n\n\n\\label{sec:app}\n\nNext we demonstrate the usefulness of the torque in a number of applications.\nWe focus on the   visual  processes for locating objects in the scene: visual attention, boundary detection, and foreground segmentation, as depicted in Fig.~\\ref{fig:Visual Processing using Torque}.\nAlthough there could be different approaches to object detection and localization when one considers single images, an approach involving  the above  three modules is necessary in mobile robot applications: First the\nattention mechanism  focuses the processing to a conspicuous region - the region of interest. Then contours are extracted and the object in the region of interest is segmented.\nWe evaluate how much the proposed torque operator could improve these three processes by comparing against other methods in standard database settings. Finally, we demonstrate  the torque mechanism in a contour based object detection and recognition scheme. \n \n\\begin{figure}[htbp]\n\\begin{center}\n  \\includegraphics[width=1.0\\columnwidth,keepaspectratio=true,clip]\n  {Process.eps}\n\\end{center}\n\\caption{Visual processing using the image torque operator.\n\\label{fig:Visual Processing using Torque}}\n\\end{figure}\n\n\\subsection{Visual Attention}\n\nAs  discussed in section \\ref{sec:Extrema in Torque}\n\nthe torque operator tends to produce extrema  at  points surrounded by boundary edges, and for  patch sizes corresponding to  object size.\nThis property of the torque operator is expected to be useful as a cue for bottom-up visual attention.\nIn the following experiment, we computed two torque-based saliency maps. One is generated as  mixture of Gaussians with the  Gaussian distributions centered at the  extrema in the torque volume, and the other is a weighted sum of the generated saliency map and the graph-based visual saliency (GBVS) by Harel {et al\\onedot} \\cite{Harel2006}.\nWe used weights of 0.3 for the torque-based saliency map and 0.7 for the GBVS,\nwhich were found empirically from  evaluations on subsets of the dataset.\n\n\n\n\nWe used the eye tracking data by Judd {et al\\onedot}. \\cite{Judd2009} to generate ground truth saliency maps.\nFixation points were extracted from the data, and saliency maps were generated as mixture of Gaussian distributions centered at the fixation points, and the generated saliency maps were normalized in the range $[0,1]$. The ground truth saliency maps were  binarized by a threshold (we used 0.5) in the quantitative comparison.\n\nWe resized the test images such that the shorter side of the images was  150 pixels, in order to reduce computational time and standardize the image size.\nThe standard deviation of the Gaussian distributions used to generate the ground truth and torque-based saliency maps were both set to 25 pixels.\n\nThe torque-based saliency maps were quantitatively compared with the saliency maps of \\cite{Itti1998} and \\cite{Harel2006}.\nWe binarized the computed saliency maps  for a set of threshold values  equally distant in $[0,1]$, and  evaluated precision and recall of the binarized saliency maps as follows:\n\n", "index": 29, "text": "\\begin{align}\nP = \\frac{TP}{TP+FP}, \\quad R = \\frac{TP}{TP+FN},\\quad\\\\\nTP = \\left|S \\cap \\mathcal{G}\\right|,\nFP = \\left|S \\cap \\overline{\\mathcal{G}}\\right|,\nFN = \\left|\\overline{S} \\cap \\mathcal{G}\\right|,\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P=\\frac{TP}{TP+FP},\\quad R=\\frac{TP}{TP+FN},\" display=\"inline\"><mrow><mrow><mrow><mi>P</mi><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>T</mi><mo>\u2062</mo><mi>P</mi></mrow><mrow><mrow><mi>T</mi><mo>\u2062</mo><mi>P</mi></mrow><mo>+</mo><mrow><mi>F</mi><mo>\u2062</mo><mi>P</mi></mrow></mrow></mfrac></mstyle></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>R</mi><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>T</mi><mo>\u2062</mo><mi>P</mi></mrow><mrow><mrow><mi>T</mi><mo>\u2062</mo><mi>P</mi></mrow><mo>+</mo><mrow><mi>F</mi><mo>\u2062</mo><mi>N</mi></mrow></mrow></mfrac></mstyle></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle TP=\\left|S\\cap\\mathcal{G}\\right|,FP=\\left|S\\cap\\overline{%&#10;\\mathcal{G}}\\right|,FN=\\left|\\overline{S}\\cap\\mathcal{G}\\right|,\" display=\"inline\"><mrow><mrow><mrow><mrow><mi>T</mi><mo>\u2062</mo><mi>P</mi></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi>S</mi><mo>\u2229</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi></mrow><mo>|</mo></mrow></mrow><mo>,</mo><mrow><mrow><mrow><mi>F</mi><mo>\u2062</mo><mi>P</mi></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mi>S</mi><mo>\u2229</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mo>\u00af</mo></mover></mrow><mo>|</mo></mrow></mrow><mo>,</mo><mrow><mrow><mi>F</mi><mo>\u2062</mo><mi>N</mi></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mover accent=\"true\"><mi>S</mi><mo>\u00af</mo></mover><mo>\u2229</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi></mrow><mo>|</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $d_o$ is the original edge intensity, and $d_\\tau$ is the normalized torque contribution.\nThe computed edge's contribution to torque is normalized into $[0,1]$.\n$c_0$, $c_1$, and $c_2$ are constants.\nWe call the edges reweighted by the value $d_s$ in eq.~(\\ref{eq:Edge Strengthing}) \\emph{Strengthened edges}.\nExamples of such strengthened edges are shown in Fig.~\\ref{fig:Strengthened Edges}.\nIn this experiment,   the constant parameters $c_0$, $c_1$ and $c_2$ were set to  -2.54, 1.86 and 2.69, respectively, and  these parameter were learned using training  images.\nCanny edges were used to compute the torque as shown in (b). As can be seen from (c),\nthe strengthened edges tend to be stronger at boundary edges of objects, while weaker at texture edges.\n\nWe used the  Berkeley dataset \\cite{Martin2001} to quantitatively\n evaluate the improvement of boundary detection.\nWhile the Canny edge method scored 0.57, the torque-based strengthened edge method using the Canny edges increased the score to 0.59 in the F-measure of the Berkeley benchmark.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{}}\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {21077_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_021077.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_021077.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {38092_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_038092.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_038092.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {253055_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_253055.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_253055.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {069020_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_069020.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_069020.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {296059_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_296059.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_296059.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {197017_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_197017.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_197017.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c)\n    \\end{tabular}\n  \\end{center}\n\\caption{Examples of Strengthened edges. (a) Test images. (b) Canny edges. (c) Strengthened edges.\nThe Canny edges shown in (b) are used to compute the Strengthened edges in (c).\n\\label{fig:Strengthened Edges}}\n\\end{figure}\n\n\nIn a second experiment we evaluated the torque on a  dataset that is focused on objects.\nWe used the images and boundary annotations for the \\emph{car side} category in the Caltech dataset \\cite{FeiFei2006}. Edge maps were computed  using  Canny, pb boundary  \\cite{Martin2001}, and gPb boundary detection \\cite{Arbelaez2011}, and these edge maps were used to derive  the torque.\nThen the torque-based strengthened edges were  computed and combined with the base  edge maps. Here we  simply used a weighted sum to combine the two terms as follows:\n\n", "itemtype": "equation", "pos": 82338, "prevtext": "\nwhere $S$ is the binarized  saliency map, and\n$\\mathcal{G}$ is the binarized ground truth saliency map.\n$P$ and $R$ denote precision and recall respectively.\n$TP$, $FP$, $FN$ are true positive, false positive, and false negative, respectively.\nFig.~\\ref{fig:Evaluation of Attention Models} shows the\nROC curves and maximum F-measures computed from the  898 test images in the dataset.\nExamples of computed saliency maps along  with the ground-truth are shown in Fig.~\\ref{fig:Visual Attention Models Comparison}.\nThe quantitative comparison shows that  the attention map  based only on torque does not outperform GBVS.\nHowever, the torque measure as additional mid-level visual cue improves the quality of GBVS.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{}c@{}}\n      \\begin{minipage}{0.50\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {Attention_ROCs.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.45\\columnwidth}\n      \\begin{center}\n      \\begin{tabular}{|c|c|}\n      \\hline\n\t   method & F-measure \\\\\n\t  \\hline\n\t  Itti & 0.528 \\\\\n\t  GBVS & 0.588 \\\\\n\t  Torque & 0.538 \\\\\n\t  GBVS+Torque & {\\bfseries 0.599}\\\\\n\t  \\hline\n      \\end{tabular}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b)\n    \\end{tabular}\n  \\end{center}\n\\caption{Evaluation of attention models. (a) ROC curves. (b) F-measure scores.\n\\label{fig:Evaluation of Attention Models}}\n\\end{figure}\n\n\\if 0\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|}\n\n\t  \\hline\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Itti}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{GBVS}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\scriptsize{GBVS+Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Ground truth}\n      \\end{center}\n      \\end{minipage}\\\\\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\hline\n\n    \\end{tabular}\n  \\end{center}\n  \\caption{Examples of visual attention.\nSaliency maps computed by four different methods and ground-truth saliency map are visualized by overlaying onto test image respectively.\n  \\label{fig:Visual Attention Models Comparison}}\n\\end{figure}\n\\fi\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|}\n\n\t  \\hline\n\t\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Itti {et al\\onedot}}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{GBVS}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Troque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\scriptsize{GBVS+Torque}\n      \\end{center}\n      \\end{minipage}&\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n\t  \\footnotesize{Ground truth}\n      \\end{center}\n      \\end{minipage}\\\\\n\t\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i2215088717_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.608 & 0.486 & {\\bf 0.687} & 0.544 & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i132672866_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n\t  0.700 & 0.718 & 0.789 & {\\bf 0.794} & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i10feb04_static_cars_highland_img_0847_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.558 & {\\bf 0.604} & 0.481 & 0.585 & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i156568569_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.775 & 0.795 & 0.774 & {\\bf 0.811} & \\\\\n\n      \\hline\n\n\t  \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_IttiKoch.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_GBVS.eps}\n      \\end{center}\n      \\end{minipage}&\n\t\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_GBVSTorque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.2\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {i1011319098_Attention_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n\n      0.690 & 0.760 & 0.815 & {\\bf 0.818} & \\\\\n\n      \\hline\n\n    \\end{tabular}\n  \\end{center}\n\\caption{Examples of Visual Attention.\nSaliency maps computed by four different methods and the ground-truth saliency map  are overlayed on the respective test images. The maximum F-measure is shown below each saliency map.\n\\label{fig:Visual Attention Models Comparison}}\n\\end{figure}\n\n\n\\subsection{Boundary Detection}\n\n\nIn our boundary detection we use the torque volume to reweigh edges according to their contribution to large torque values.\nThe contribution of an edge point to  torque values of different patches can be obtained  as:\n\\begin{eqnarray}\n\\upsilon_q = \\sum_{\\left\\{P|q\\in P\\right\\}}\\tau_{p\\left(P\\right)q},\\label{eq:edge contribution}\n\\end{eqnarray}\nwhere $p\\left(P\\right)$ indicates the center of the patch $P$, and\n$q$ is an edge point.\n\nThe  idea is the same as for the  attention mechanism. Extrema in the torque volume indicate the existence of edges surrounding the center of a patch.\nTherefore, edges on object boundaries  should have a large contribution to  extrema (eq.~\\ref{eq:edge contribution}).\nEdges are strengthened by combining the original edge with the value of this contribution  as follows:\n\n", "index": 31, "text": "\\begin{align}\nd_s = \\frac{1}{1+e^{-\\left(c_0 + c_1 d_o + c_2 d_\\tau \\right)}},\\label{eq:Edge Strengthing}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle d_{s}=\\frac{1}{1+e^{-\\left(c_{0}+c_{1}d_{o}+c_{2}d_{\\tau}\\right)%&#10;}},\" display=\"inline\"><mrow><mrow><msub><mi>d</mi><mi>s</mi></msub><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mo>(</mo><mrow><msub><mi>c</mi><mn>0</mn></msub><mo>+</mo><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>d</mi><mi>o</mi></msub></mrow><mo>+</mo><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>d</mi><mi>\u03c4</mi></msub></mrow></mrow><mo>)</mo></mrow></mrow></msup></mrow></mfrac></mstyle></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere  $d_o$ denotes the edge map, $d_\\tau$  the  torque contribution map, and\n$d_s$ the strengthened edge map.\nWe computed Precision and Recall for   the strengthened edge maps $d_s$ and the base edge maps $d_o$, and\n evaluated the maximum F-measure  as a function of parameter $\\alpha$ and the number of torque extrema in the computation of the torque contribution map, as shown in Fig~\\ref{fig:Performance of Boundary Detection and Number of Extrema}.\nBased on this evaluation, $\\alpha$ was set to  0.5.\nIn addition, we evaluated  the recently proposed method of Sketch Tokens \\cite{Lim2013} for boundary detection and the effect of  edge strengthening on this method.\nThe precision-recall (PR) curve for all four methods are shown in Fig~\\ref{fig:Boundary detection PR curve}.\nComparing in Fig.~\\ref{fig:Performance of Boundary Detection and Number of Extrema} the maximum F-measure of the strengthened edge maps with  the base edge maps, we can verify that the torque operator  improves silhouette boundary detection. Table~\\ref{tbl:F-masure comparison in boundary detection}  summarizes the results for $\\alpha=0.5$ and 5000 torque extrema for all four methods.\n\n\\begin{table}[tb]\n\n\\begin{center}\n\\begin{tabular}{|c|c|}\n\n\t\\hline\n\tMethod & F-measure\\\\\n\t\\hline\n\tCanny & 0.20\\\\\n\tTorque (Canny) & {\\bfseries 0.23}\\\\\n\t\\hline\n\tpb & 0.21\\\\\n\tTorque (pb) & {\\bfseries 0.24}\\\\\n\t\\hline\n\tgPb & 0.20\\\\\n\tTorque (gPb) & {\\bfseries 0.21}\\\\\n\t\\hline\n\tSketch Tokens & 0.24\\\\\n\tTorque (Sketch Tokens) & {\\bfseries 0.25}\\\\\n\t\\hline\n\n\\end{tabular}\n\\end{center}\n\\caption{F-measure comparison in boundary detection between base edge maps and torque-based strengthened edge maps.\n\\label{tbl:F-masure comparison in boundary detection}}\n\\end{table}\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}}\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_pb.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_gPb.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) Canny & (b) pb & (c) gPb\n    \\end{tabular}\n  \\end{center}\n\\caption{Performance of boundary detection evaluated by the maximum F-measure as a function of $\\alpha$ and the number of extrema. Three edge detection methods were used to compute base edge maps: (a) Canny edges, (b) pb edges, and (c) gPb edges. The base edge maps were blended with the torque contribution map to generate strengthened edge maps.\nIn the legend \\emph{base} refers to the base edge maps, and the numbers  indicate the weight $\\alpha$ in eq.(\\ref{eq:Edge Strengthing2}) used to obtain strengthened edge maps.\n\\label{fig:Performance of Boundary Detection and Number of Extrema}}\n\\end{figure}\n\n\\begin{figure}[htbp]\n\\caption{Precision-recall (PR) curves for boundary detection. The torque-based strengthened edge map (green ) is is compared to the base edge map (gray) for: (a) Canny edges, (b) pb edges, (c) gPb edges, and (d) Sketch tokens edges.\n\\label{fig:Boundary detection PR curve}}\n  \\begin{center}\n    \\begin{tabular}{cc}\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_pb.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) Canny & (b) pb\\\\\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_gPb.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_ST.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (c) gPb & (d) Sketch Tokens\n    \\end{tabular}\n  \\end{center}\n\\end{figure}\n\n\\subsection{Segmentation}\n\nNext the torque operator is demonstrated  for segmentation in two graphcut approaches, and a quantitative comparison to other methods is given.\nThe first approach is a generic multi-region segmentation, and the second is a\nfigure-ground segmentation.  Both approaches basically rely on the torque as attention and scale selection mechanism. The attended region is then  utilized to obtain  foreground color models or to strengthen  edges.\n\n\n\\subsubsection{Multi-region Segmentation}\n\nWe used the torque extrema and their corresponding scales to obtain  image regions  likely to correspond to interesting  elements of the image.\n\nIn this experiment, each such image region is modeled by a color histogram, and these histograms are used to create the weights in a multi-label graph-cut segmentation.\nThe data term in  the graph-cut is derived from  how well the color at a pixel matches  each color model, and the smoothness term is based on   color similarity of  adjacent pixels.\nThe segmentation method was applied to the Berkeley image data set and the quality of the segmentation was evaluated using the  covering criteria \\cite{Arbelaez2009}. We compared against the normalized cut segmentation \\cite{Shi2000}. \nFig.~\\ref{fig:Examples of Generic Segmentations} shows example segmentations of the two  segmentation methods. A visual evaluation shows, that the  graphcut method better segments than the normalized cut, in the sense of being able to better extract object-like regions, and  the  quantitative evaluation demonstrates  that the graphcut method clearly outperforms the normalized cut (Table 2).\n\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{}}\n\n     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {41069.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_041069_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_041069_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {42049.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_042049_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_042049_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {58060.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_058060_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_058060_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {62096.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_062096_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_062096_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {85048.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_085048_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_085048_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c)\n    \\end{tabular}\n  \\end{center}\n  \\caption{Examples of generic multi-region segmentation: (a)  Test images. (b) Segmentation using the torque operator (c) Segmentation using the normalized cut.\n\\label{fig:Examples of Generic Segmentations}}\n\\end{figure}\n\n\\begin{table}[tb]\n\\caption{Comparison  of multi-region segmentations  based on the  covering criteria.}\n\\label{tbl:Covering of Multi-region Segmentation}\n\\begin{center}\n\\begin{tabular}{|c|c|}\n\n    \\hline\n      Method&  Covering \\\\\n    \\hline\n      Torque&  {\\bfseries 0.429}\\\\\n   \n      N-Cut &  0.390\\\\\n    \\hline\n\n\\end{tabular}\n\\end{center}\n\\end{table}\n\n\n\\subsubsection{Figure-ground Segmentation}\n\nThe strengthened edges are expected to be useful for figure-ground segmentation because object boundaries are emphasized.\nHere we demonstrate an edge-based graph cut algorithm using the strengthened edges.\nFor a quantitative evaluation of figure-ground segmentation, we used the dataset by Stein {et al\\onedot} \\cite{Stein2008}, which has  ground truth segmentations for multiple foreground objects.\nFor each reference image in the data set we selected a single  foreground object, and used the centroid of the object  as  fixation point.\nThen we applied the fixation based segmentation algorithm of \\cite{Mishra2009b}. This algorithm separates foreground from background using a graphcut on a probability map of edges in a polar coordinate system.\nDifferent visual cues were  used in  the graph-cut segmentation for comparison: the  Canny edge map, the boundary probability map (Pb)  \\cite{Martin2004}, a strengthened edge map using  Canny edges, and a strengthened edge map using  Pb edges.\nSo we can separate the effect  of the torque measure, we used as strengthened edge directly  the normalized torque value contribution, $d_\\tau$.\n\nThe quality of segmentation was evaluated by the segmentation covering \\cite{Arbelaez2009}.\n In the case of foreground-background segmentation this measure amounts to the ratio of the true positive area and the union of computed segmentation and ground truth segmentation.\n\nTable 3 shows the results of the comparison for the dataset. For each visual cue\nthe average covering over  28 test images is shown.\nAs can seen from the table, adding the torque significantly improves the segmentation.\nFinally, we also compared with the non-edge based level-set segmentation by Chan and Vese \\cite{Chan2001}.\nFrom the the performance of this method, we can see that the segmentation of objects for this data\nset, given only the fixation point, is a challenging task.\nExamples of segmentation results are shown in Fig.~\\ref{fig:Examples of Segmentations}.\n\n\\begin{table}[tb]\n\\begin{center}\n\\caption{Comparison  of foreground-background  segmentations  based on the  covering criteria. The notation \\emph{Torque (Canny)} and \\emph{Torque (pb)} refer to  strengthened edges by the torque operator using as base  Canny or  the pb edges, respectively.}\n\n\\begin{tabular}{|c|c|}\n\n    \\hline\n      Visual Cue&  Covering \\\\\n    \\hline\n      Canny&   0.32\\\\\n      Torque (Canny)&  {\\bfseries 0.47}\\\\\n    \\hline\n      pb&   0.40 \\\\\n      Torque (pb)&  {\\bfseries 0.48} \\\\\n    \\hline\n      Chan-Vese& 0.21\\\\\n    \\hline\n\n\\end{tabular}\n\\end{center}\n\\label{tbl:Covering of Foreground Segmentation with Different Visual Cues}\n\\end{table}\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{\\,}c@{}}\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_ChanVese.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_ChanVese.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c) & (d)\n    \\end{tabular}\n  \\end{center}\n\\caption{Example of a segmentation: (a)  using Canny edges (b) using strengthened edges by the torque (c) using the Chan-Vese method \\cite{Chan2001}. (d) Ground truth. The green dot denotes the fixation point.\n\\label{fig:Examples of Segmentations}}\n\\end{figure}\n\n\\if 0\n\n\\subsubsection{Segmentation with Approximate  Shape Knowledge}\n\\label{sec:approximate}\nSo far we have used the torque  in purely bottom-up processing.\nIf we have some knowledge about the shape we are looking for, we can adapt the torque computation appropriately. For example, we can adapt the shape of the patches in the torque computation. Insetad of square patches we can use rectangular patches, if we know the approximate dimensions of the object. Next we discuss a possible application in a segmentation task, when  top-down knowledge of the general shape of the segmented object is available.\n\nLet us assume  that we know that the target object shape is approximated by an ellipse.\nThen, to localize the ellipse, instead of performing matching   in image space, we match using the torque value map.\nA set of points $\\left(x,y\\right)$, for which the following condition holds, represent an ellipse:\n\n", "itemtype": "equation", "pos": 88067, "prevtext": "\nwhere $d_o$ is the original edge intensity, and $d_\\tau$ is the normalized torque contribution.\nThe computed edge's contribution to torque is normalized into $[0,1]$.\n$c_0$, $c_1$, and $c_2$ are constants.\nWe call the edges reweighted by the value $d_s$ in eq.~(\\ref{eq:Edge Strengthing}) \\emph{Strengthened edges}.\nExamples of such strengthened edges are shown in Fig.~\\ref{fig:Strengthened Edges}.\nIn this experiment,   the constant parameters $c_0$, $c_1$ and $c_2$ were set to  -2.54, 1.86 and 2.69, respectively, and  these parameter were learned using training  images.\nCanny edges were used to compute the torque as shown in (b). As can be seen from (c),\nthe strengthened edges tend to be stronger at boundary edges of objects, while weaker at texture edges.\n\nWe used the  Berkeley dataset \\cite{Martin2001} to quantitatively\n evaluate the improvement of boundary detection.\nWhile the Canny edge method scored 0.57, the torque-based strengthened edge method using the Canny edges increased the score to 0.59 in the F-measure of the Berkeley benchmark.\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{}}\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {21077_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_021077.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_021077.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {38092_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_038092.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_038092.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {253055_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_253055.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_253055.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {069020_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_069020.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_069020.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {296059_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_296059.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_296059.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {197017_s.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {pbCanny_sig2_20_197017.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {TorqueTrial039_197017.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c)\n    \\end{tabular}\n  \\end{center}\n\\caption{Examples of Strengthened edges. (a) Test images. (b) Canny edges. (c) Strengthened edges.\nThe Canny edges shown in (b) are used to compute the Strengthened edges in (c).\n\\label{fig:Strengthened Edges}}\n\\end{figure}\n\n\nIn a second experiment we evaluated the torque on a  dataset that is focused on objects.\nWe used the images and boundary annotations for the \\emph{car side} category in the Caltech dataset \\cite{FeiFei2006}. Edge maps were computed  using  Canny, pb boundary  \\cite{Martin2001}, and gPb boundary detection \\cite{Arbelaez2011}, and these edge maps were used to derive  the torque.\nThen the torque-based strengthened edges were  computed and combined with the base  edge maps. Here we  simply used a weighted sum to combine the two terms as follows:\n\n", "index": 33, "text": "\\begin{align}\nd_s = (1-\\alpha) d_o + \\alpha d_\\tau,\\label{eq:Edge Strengthing2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle d_{s}=(1-\\alpha)d_{o}+\\alpha d_{\\tau},\" display=\"inline\"><mrow><mrow><msub><mi>d</mi><mi>s</mi></msub><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>d</mi><mi>o</mi></msub></mrow><mo>+</mo><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mi>d</mi><mi>\u03c4</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $a$ and $b$ are the major and minor axis.\n$\\left(c_x, c_y\\right)$ and $\\theta$ are the center and orientation of the ellipse.\nGiven, that we know the  major and minor axis, $a$ and $b$, we want to find the object location $\\left(c_x, c_y\\right)$ and orientation $\\theta$. This can be solved as an optimization using the torque value map.\nWe define a  cost function on the torque value $tv\\left(x,y\\right)$ with respect to $\\left(c_x, c_y, \\theta\\right)$  as follows:\n\n", "itemtype": "equation", "pos": 103582, "prevtext": "\nwhere  $d_o$ denotes the edge map, $d_\\tau$  the  torque contribution map, and\n$d_s$ the strengthened edge map.\nWe computed Precision and Recall for   the strengthened edge maps $d_s$ and the base edge maps $d_o$, and\n evaluated the maximum F-measure  as a function of parameter $\\alpha$ and the number of torque extrema in the computation of the torque contribution map, as shown in Fig~\\ref{fig:Performance of Boundary Detection and Number of Extrema}.\nBased on this evaluation, $\\alpha$ was set to  0.5.\nIn addition, we evaluated  the recently proposed method of Sketch Tokens \\cite{Lim2013} for boundary detection and the effect of  edge strengthening on this method.\nThe precision-recall (PR) curve for all four methods are shown in Fig~\\ref{fig:Boundary detection PR curve}.\nComparing in Fig.~\\ref{fig:Performance of Boundary Detection and Number of Extrema} the maximum F-measure of the strengthened edge maps with  the base edge maps, we can verify that the torque operator  improves silhouette boundary detection. Table~\\ref{tbl:F-masure comparison in boundary detection}  summarizes the results for $\\alpha=0.5$ and 5000 torque extrema for all four methods.\n\n\\begin{table}[tb]\n\n\\begin{center}\n\\begin{tabular}{|c|c|}\n\n\t\\hline\n\tMethod & F-measure\\\\\n\t\\hline\n\tCanny & 0.20\\\\\n\tTorque (Canny) & {\\bfseries 0.23}\\\\\n\t\\hline\n\tpb & 0.21\\\\\n\tTorque (pb) & {\\bfseries 0.24}\\\\\n\t\\hline\n\tgPb & 0.20\\\\\n\tTorque (gPb) & {\\bfseries 0.21}\\\\\n\t\\hline\n\tSketch Tokens & 0.24\\\\\n\tTorque (Sketch Tokens) & {\\bfseries 0.25}\\\\\n\t\\hline\n\n\\end{tabular}\n\\end{center}\n\\caption{F-measure comparison in boundary detection between base edge maps and torque-based strengthened edge maps.\n\\label{tbl:F-masure comparison in boundary detection}}\n\\end{table}\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{@{}c@{}c@{}c@{}}\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_pb.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.33\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {BD_Fextrema_gPb.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) Canny & (b) pb & (c) gPb\n    \\end{tabular}\n  \\end{center}\n\\caption{Performance of boundary detection evaluated by the maximum F-measure as a function of $\\alpha$ and the number of extrema. Three edge detection methods were used to compute base edge maps: (a) Canny edges, (b) pb edges, and (c) gPb edges. The base edge maps were blended with the torque contribution map to generate strengthened edge maps.\nIn the legend \\emph{base} refers to the base edge maps, and the numbers  indicate the weight $\\alpha$ in eq.(\\ref{eq:Edge Strengthing2}) used to obtain strengthened edge maps.\n\\label{fig:Performance of Boundary Detection and Number of Extrema}}\n\\end{figure}\n\n\\begin{figure}[htbp]\n\\caption{Precision-recall (PR) curves for boundary detection. The torque-based strengthened edge map (green ) is is compared to the base edge map (gray) for: (a) Canny edges, (b) pb edges, (c) gPb edges, and (d) Sketch tokens edges.\n\\label{fig:Boundary detection PR curve}}\n  \\begin{center}\n    \\begin{tabular}{cc}\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_pb.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) Canny & (b) pb\\\\\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_gPb.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.4\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {PR_5000_add_050_ST.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (c) gPb & (d) Sketch Tokens\n    \\end{tabular}\n  \\end{center}\n\\end{figure}\n\n\\subsection{Segmentation}\n\nNext the torque operator is demonstrated  for segmentation in two graphcut approaches, and a quantitative comparison to other methods is given.\nThe first approach is a generic multi-region segmentation, and the second is a\nfigure-ground segmentation.  Both approaches basically rely on the torque as attention and scale selection mechanism. The attended region is then  utilized to obtain  foreground color models or to strengthen  edges.\n\n\n\\subsubsection{Multi-region Segmentation}\n\nWe used the torque extrema and their corresponding scales to obtain  image regions  likely to correspond to interesting  elements of the image.\n\nIn this experiment, each such image region is modeled by a color histogram, and these histograms are used to create the weights in a multi-label graph-cut segmentation.\nThe data term in  the graph-cut is derived from  how well the color at a pixel matches  each color model, and the smoothness term is based on   color similarity of  adjacent pixels.\nThe segmentation method was applied to the Berkeley image data set and the quality of the segmentation was evaluated using the  covering criteria \\cite{Arbelaez2009}. We compared against the normalized cut segmentation \\cite{Shi2000}. \nFig.~\\ref{fig:Examples of Generic Segmentations} shows example segmentations of the two  segmentation methods. A visual evaluation shows, that the  graphcut method better segments than the normalized cut, in the sense of being able to better extract object-like regions, and  the  quantitative evaluation demonstrates  that the graphcut method clearly outperforms the normalized cut (Table 2).\n\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{}}\n\n     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {41069.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_041069_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_041069_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {42049.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_042049_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_042049_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n     \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {58060.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_058060_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_058060_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {62096.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_062096_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_062096_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {85048.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_085048_extremaNegative4.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {GCSeg_085048_Ncut.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c)\n    \\end{tabular}\n  \\end{center}\n  \\caption{Examples of generic multi-region segmentation: (a)  Test images. (b) Segmentation using the torque operator (c) Segmentation using the normalized cut.\n\\label{fig:Examples of Generic Segmentations}}\n\\end{figure}\n\n\\begin{table}[tb]\n\\caption{Comparison  of multi-region segmentations  based on the  covering criteria.}\n\\label{tbl:Covering of Multi-region Segmentation}\n\\begin{center}\n\\begin{tabular}{|c|c|}\n\n    \\hline\n      Method&  Covering \\\\\n    \\hline\n      Torque&  {\\bfseries 0.429}\\\\\n   \n      N-Cut &  0.390\\\\\n    \\hline\n\n\\end{tabular}\n\\end{center}\n\\end{table}\n\n\n\\subsubsection{Figure-ground Segmentation}\n\nThe strengthened edges are expected to be useful for figure-ground segmentation because object boundaries are emphasized.\nHere we demonstrate an edge-based graph cut algorithm using the strengthened edges.\nFor a quantitative evaluation of figure-ground segmentation, we used the dataset by Stein {et al\\onedot} \\cite{Stein2008}, which has  ground truth segmentations for multiple foreground objects.\nFor each reference image in the data set we selected a single  foreground object, and used the centroid of the object  as  fixation point.\nThen we applied the fixation based segmentation algorithm of \\cite{Mishra2009b}. This algorithm separates foreground from background using a graphcut on a probability map of edges in a polar coordinate system.\nDifferent visual cues were  used in  the graph-cut segmentation for comparison: the  Canny edge map, the boundary probability map (Pb)  \\cite{Martin2004}, a strengthened edge map using  Canny edges, and a strengthened edge map using  Pb edges.\nSo we can separate the effect  of the torque measure, we used as strengthened edge directly  the normalized torque value contribution, $d_\\tau$.\n\nThe quality of segmentation was evaluated by the segmentation covering \\cite{Arbelaez2009}.\n In the case of foreground-background segmentation this measure amounts to the ratio of the true positive area and the union of computed segmentation and ground truth segmentation.\n\nTable 3 shows the results of the comparison for the dataset. For each visual cue\nthe average covering over  28 test images is shown.\nAs can seen from the table, adding the torque significantly improves the segmentation.\nFinally, we also compared with the non-edge based level-set segmentation by Chan and Vese \\cite{Chan2001}.\nFrom the the performance of this method, we can see that the segmentation of objects for this data\nset, given only the fixation point, is a challenging task.\nExamples of segmentation results are shown in Fig.~\\ref{fig:Examples of Segmentations}.\n\n\\begin{table}[tb]\n\\begin{center}\n\\caption{Comparison  of foreground-background  segmentations  based on the  covering criteria. The notation \\emph{Torque (Canny)} and \\emph{Torque (pb)} refer to  strengthened edges by the torque operator using as base  Canny or  the pb edges, respectively.}\n\n\\begin{tabular}{|c|c|}\n\n    \\hline\n      Visual Cue&  Covering \\\\\n    \\hline\n      Canny&   0.32\\\\\n      Torque (Canny)&  {\\bfseries 0.47}\\\\\n    \\hline\n      pb&   0.40 \\\\\n      Torque (pb)&  {\\bfseries 0.48} \\\\\n    \\hline\n      Chan-Vese& 0.21\\\\\n    \\hline\n\n\\end{tabular}\n\\end{center}\n\\label{tbl:Covering of Foreground Segmentation with Different Visual Cues}\n\\end{table}\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}[t]{@{}c@{\\,}c@{\\,}c@{\\,}c@{}}\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_ChanVese.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {linus1_seg_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Canny.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Torque.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_ChanVese.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.23\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\textwidth,keepaspectratio=true,clip]\n      {trash_seg_Truth.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b) & (c) & (d)\n    \\end{tabular}\n  \\end{center}\n\\caption{Example of a segmentation: (a)  using Canny edges (b) using strengthened edges by the torque (c) using the Chan-Vese method \\cite{Chan2001}. (d) Ground truth. The green dot denotes the fixation point.\n\\label{fig:Examples of Segmentations}}\n\\end{figure}\n\n\\if 0\n\n\\subsubsection{Segmentation with Approximate  Shape Knowledge}\n\\label{sec:approximate}\nSo far we have used the torque  in purely bottom-up processing.\nIf we have some knowledge about the shape we are looking for, we can adapt the torque computation appropriately. For example, we can adapt the shape of the patches in the torque computation. Insetad of square patches we can use rectangular patches, if we know the approximate dimensions of the object. Next we discuss a possible application in a segmentation task, when  top-down knowledge of the general shape of the segmented object is available.\n\nLet us assume  that we know that the target object shape is approximated by an ellipse.\nThen, to localize the ellipse, instead of performing matching   in image space, we match using the torque value map.\nA set of points $\\left(x,y\\right)$, for which the following condition holds, represent an ellipse:\n\n", "index": 35, "text": "\\begin{align}\nx'^2+y'^2 &= 1,\\\\\n\\left( \\begin{array}{c}\n x'\\\\\n y'\n\\end{array} \\right)\n&= \\left( \\begin{array}{cc}\n  1/a & 0\\\\\n  0 & 1/b\n\\end{array} \\right)\n\\left( \\begin{array}{cc}\n \\cos\\theta & \\sin\\theta\\\\\n -\\sin\\theta & \\cos\\theta\n\\end{array} \\right)\n\\left( \\begin{array}{c}\n x-c_x\\\\\n y-c_y\n\\end{array} \\right),\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle x^{\\prime 2}+y^{\\prime 2}\" display=\"inline\"><mrow><msup><mi>x</mi><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi>y</mi><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mn>2</mn></mrow></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1,\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mn>1</mn></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left(\\begin{array}[]{c}x^{\\prime}\\\\&#10;y^{\\prime}\\end{array}\\right)\" display=\"inline\"><mrow><mo>(</mo><mtable rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msup><mi>x</mi><mo>\u2032</mo></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>y</mi><mo>\u2032</mo></msup></mtd></mtr></mtable><mo>)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left(\\begin{array}[]{cc}1/a&amp;0\\\\&#10;0&amp;1/b\\end{array}\\right)\\left(\\begin{array}[]{cc}\\cos\\theta&amp;\\sin\\theta\\\\&#10;-\\sin\\theta&amp;\\cos\\theta\\end{array}\\right)\\left(\\begin{array}[]{c}x-c_{x}\\\\&#10;y-c_{y}\\end{array}\\right),\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mn>1</mn><mo>/</mo><mi>a</mi></mrow></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mrow><mn>1</mn><mo>/</mo><mi>b</mi></mrow></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mi>cos</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow></mtd><mtd columnalign=\"center\"><mrow><mi>sin</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mo>-</mo><mrow><mi>sin</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow></mrow></mtd><mtd columnalign=\"center\"><mrow><mi>cos</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mtable rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mi>x</mi><mo>-</mo><msub><mi>c</mi><mi>x</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mi>y</mi><mo>-</mo><msub><mi>c</mi><mi>y</mi></msub></mrow></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nAssuming that the object region is negative in torque value, i.e that the object is of darker value than the background, we need to minimize $E$, which here we solved simply by search.\n The process is illustrated in Fig. \\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}. For the torque value map in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(b), the value $E$ in the optimization is the sum of torque values over the region masked  in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(c) in the initial state. After minimization of  $E$ with respect to the location and orientation parameters of the ellipse, the ellipse was fit to the region of a foreground object, as shown in (Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(d). Finally, using the optimized parameters, the object was segmented successfully as\n\nshown in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(e). In this step, using the ellipse center as fixation point, edges were reweighted to simulate an elliptic coordinate system.\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{ccc}\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {101085.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMap.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b)\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMapMasked.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMapMasked3.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {SegmentationSuccess.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (c) & (d) & (e)\n\n    \\end{tabular}\n  \\end{center}\n  \\caption{Segmentation using optimization with top-down knowledge of elliptic shape.\n(a) Test image.\n(b) Torque value map.\n(c) Region of the torque value map within an elliptic region (for  initialized parameters).\n\n(d) Optimal elliptic region  found by optimization of the cost function $E$ in eq.~(\\ref{eq:energy for searching object}). (e.) Final segmentation.\n\\label{fig:Segmentation using optimization with top-down knowledge of elliptic shape}}\n\\end{figure}\n\n\\fi\n\n\\subsection{Recognition}\n\\label{sec:rec}\n\nThis section summarizes  experiments from \\cite{XuY2012}, where we used the torque mechanism for  object  recognition in the bag-of-features framework. The approach consists of two steps: a patch detection, and a patch description.  First, torque value extrema in space and scale and their corresponding patches are detected.  These  patches are separated into minima, i.e the dark patches on brighter background and maxima, i.e. bright patches on darker background. This detection scheme  is called \\emph{Maximal/Minimal Torque Patch (MTP) detector}.\n\nSecond,  the density and variance of the local edge structure is described in a multi-scale manner in the so-called   \\emph{Multiscale Torque (MST) descriptor}. For a given patch   regions of multiple sizes  having an overlap with the patch along the eight axes at discrete\nspace intervals are selected and their torque values are concatenated into a vector. To keep the number of selected areas the same for all patches, the step size is adapted to the patch size, and  to make it robust to rotation, the patch is rotated such that its x-axis becomes the direction\nclosest in direction to the vector pointing from the patch center\nto the centroid of the edges inside the patch P\n(see  Fig.~\\ref{fig:MST framework}).\n\n\n\\begin{figure*}[t]\n\\begin{center}\n\\begin{tabular}{cccc}\n    \\includegraphics[height=2.3in]{MST_1.eps}&\n    \\includegraphics[height=2.3in]{MST_2.eps}&\n    \\includegraphics[height=2.3in]{MST_3.eps}&\n    \\includegraphics[height=2.3in]{MST_4.eps}\\\\\n\\tiny{(a) An MTP patch}&\\tiny{(b) Torque magnitudes}&\\tiny{(c) Multi-scale sampling}&\\tiny{(d) Orientation alignment}\n\\end{tabular}\n\\end{center}\n\\caption{Outline of MST descriptor. From left to right: (a) An interesting patch is detected by the MTP detector.\n  (b) The torque magnitudes of regions  centered at points inside the detected patch are computed.\n  (c) The torque values  are  sampled along 8 directions at several scales.\n  The sampled values are collected  and concatenated as the local feature of the MTP patch.\n  (d) Alignment of the orientation of the feature by circular-shifting.}\n  \\label{fig:MST framework}\n\\end{figure*}\n\n\n This descriptor  was evaluated  for  object recognition following  the  {\\it bag of features} (BoF) representation paradigm evaluated on the Caltech-101 dataset.\n Table \\ref{table:rec} shows the performance of the  method in comparison to a number of   top feature-based recognition methods (which were also  used for comparison in \\cite{WYYLHG10}).\n As can be seen,  by itself the torque-based method performs about the same as \\cite{JainKG08}, but does not perform as well as methods based on SIFT-based features (such as \\cite{BoimanSI08cvpr},  \\cite{YangYGH09}, and \\cite{WYYLHG10}). This is because, these images are better captured by texture content (extracted through SIFT features). However by combining  the contour-based feature with SIFT, better performance was achieved. Our  implementation of the SIFT feature followed that of \\cite{WYYLHG10}, and  we combined the  two features by concatenating them into a single vector and weighing them 1:2 (ours v.s. SIFT). Our method had  an  additional  $2.45\\%-4.66\\%$ accuracy gain over the best results of other methods with respect to different sizes of the training set. These results demonstrate that the proposed contour-based feature does capture meaningful\ninformation of object contour and adds to objection recognition.\n\n\n\\begin{table*}\\label{table:result_101}\n\\begin{center}\n{\n\\begin{tabular}{|c||c|c|c|c|c|c|}\n\\hline\n& 5 & 10 & 15 & 20 & 25 & 30\\\\ \\hline\\hline\nJain~{et al\\onedot} \\cite{JainKG08} & - & - & 61.00 & - & - & 69.10 \\\\ \\hline\nBoiman~{et al\\onedot} \\cite{BoimanSI08cvpr} & - & - & 65.00 & - & - & 70.40 \\\\ \\hline\nYang~{et al\\onedot} \\cite{YangYGH09} & - & - & 67.00 & - & - & 73.20 \\\\ \\hline\nWang~{et al\\onedot} \\cite{WYYLHG10} & 51.15 & 59.77 & 65.43 & 67.74 & 70.16 & 73.44 \\\\ \\hline\\hline\nOurs & 48.17 & 57.65 & 62.33 & 65.32 & 67.39 & 68.97\\\\ \\hline\nOurs + SIFT & \\textbf{53.60} & \\textbf{64.01} & \\textbf{69.15} & \\textbf{72.40} & \\textbf{74.52} & \\textbf{76.22} \\\\\n\\hline\n\\end{tabular}\n}\n\\end{center}\n\\caption{Classification accuracy for different methods on the Caltech-101 dataset.}\n\\label{table:rec}\n\\end{table*}\n\n\n\n\nWe introduced a new tool of mid-level vision, the \\emph{Torque Operator}, and explored its fundamental properties using both theory and experiments.\nThe torque operator creates maps, which encode the structure of edges within patches, and it tends to generate larger absolute values when edges are aligned in a way surrounding the center of the patch, and the region enclosed by these edges matches the size of patch. This basic property was first discussed and examined on synthesized images. Then, this  property was demonstrated in the  applications of attention, boundary detection,  segmentation, and object recognition.\n\n\nExperiments showed that for all these  applications the torque operator enhances the performance. An efficient implementation of the torque based on integral images has  also been provided (see \\cite{code}).\n\nWe believe that the concept of a grouping mechanism implemented via image processing operations is a powerful concept, and there are many way this concept can be generalized.\n\nThis paper discussed a number of  ways on how to use the Torque  operator in bottom-up processing for various  applications. An immediate  extension would be to use  the information it provides in different ways. For example the torque value itself is also expected to be a useful visual cue for segmentation. Furthermore, the torque operator could be applied to image gradient maps instead of edge maps. Such a torque measure can be derived as the  average brightness difference between the  inside  and the boundary of an image patch (see Appendix A).\n\nThe general concept of a mid-level operator acting as grouping mechanism can be  developed along a number of directions.\nWe could have  various mechanisms tuned to different edge configurations. For example, instead of adding curve contribution, such that circles are favored, we can add them such that  radial lines or spirals are favored, and this way create a set of operators tuned to semi-global patterns. We demonstrated such operators for boundary ownership classification \\cite{Teoboundary2015}, but this generalization  could be useful also for texture or object recognition.\n\n\nWhile in this paper we applied the torque  to edges of single images, the torque operator is applicable also to geometric edges, such as depth edges and motion edges. Because these edges are due to depth discontinuities, which  usually are at the  boundary of surfaces, it is expected that such a torque operator  will perform better for finding objects.\n\nIt is clear that pure bottom-up processing has its limitations, and object recognition or object segmentation  in single images requires higher level knowledge. The torque mechanism as a mid-level grouping tool can be modified also to interact with  higher-level processes encoding semantic information. We believe that there is room for research that embeds mid-level operators into object recognition and learning. Such an approach was demonstrated in  \\cite{Teo2013} and \\cite{Teo2015}, where  torque-like operators  were tuned to  specific shapes.\nContour processing of specific object classes using generalized torque then proceeds in two steps. First the bottom-up torque acts as an attention (or saliency) mechanism. Then  torque-like operators, that are tuned to respond to learned categories of objects, object parts,  or attributes  can be used in task-guided top-down  processing.\n\\section{Acknowledgements}\nThe support of the European Union under the Cognitive Systems program (project POETICON++), the National Science Foundation under INSPIRE\ngrant SMA 1248056, and  DARPA through U.S. Army grant\nW911NF-14-1-0384 are gratefully acknowledged.  \\newline\n\n\n\n The authors would like to thank Daniel Dementhon for sharing his code, which originated this project.\n\n\n\\section{Torque based on Gradient}\n\\label{sec:gradient}\n\nIn previous sections, the torque was defined on edges, where edges were normalized as unit vectors.\nNext we consider a slightly different formulation of the torque, which considers the strength of edges.\nImages have strong edges and weak edges, and the strength is defined by the gradient. \nAs will be shown next, a torque  of patches defined on gradients can be computed simply from the intensity in the area and at  the boundary of the patch.\n\nThe {\\it gradient torque} is defined as follows:\n\n", "itemtype": "equation", "pos": 104382, "prevtext": "\nwhere $a$ and $b$ are the major and minor axis.\n$\\left(c_x, c_y\\right)$ and $\\theta$ are the center and orientation of the ellipse.\nGiven, that we know the  major and minor axis, $a$ and $b$, we want to find the object location $\\left(c_x, c_y\\right)$ and orientation $\\theta$. This can be solved as an optimization using the torque value map.\nWe define a  cost function on the torque value $tv\\left(x,y\\right)$ with respect to $\\left(c_x, c_y, \\theta\\right)$  as follows:\n\n", "index": 37, "text": "\\begin{align}\nE &= \\sum_{\\left(x,y\\right)\\in\\left\\{x'^2+y'^2<1\\right\\}} tv\\left(x,y\\right).\\label{eq:energy for searching object}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E\" display=\"inline\"><mi>E</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{\\left(x,y\\right)\\in\\left\\{x^{\\prime 2}+y^{\\prime 2}&lt;1%&#10;\\right\\}}tv\\left(x,y\\right).\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow><mo>\u2208</mo><mrow><mo>{</mo><msup><mi>x</mi><mrow><mi mathsize=\"200%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi>y</mi><mrow><mi mathsize=\"200%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mn>2</mn></mrow></msup><mo>&lt;</mo><mn>1</mn><mo>}</mo></mrow></mrow></munder></mstyle><mrow><mi>t</mi><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $p$ is the center point and\n$q$ is some  point on the image.\n$\\vec{r}_{pq}$ is the displacement vector from $p$ to $q$.\n$\\tilde{\\nabla} I\\left(q\\right)$ is the image gradient at $q$ rotated by  90 degree, i.e. $\\left(\\frac{\\partial I}{\\partial y},-\\frac{\\partial I}{\\partial x}\\right)$, representing an edge-like vector.\nSimilarly, the {\\it gradient torque  for a patch} is defined as:\n\n", "itemtype": "equation", "pos": 116000, "prevtext": "\nAssuming that the object region is negative in torque value, i.e that the object is of darker value than the background, we need to minimize $E$, which here we solved simply by search.\n The process is illustrated in Fig. \\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}. For the torque value map in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(b), the value $E$ in the optimization is the sum of torque values over the region masked  in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(c) in the initial state. After minimization of  $E$ with respect to the location and orientation parameters of the ellipse, the ellipse was fit to the region of a foreground object, as shown in (Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(d). Finally, using the optimized parameters, the object was segmented successfully as\n\nshown in Fig.~\\ref{fig:Segmentation using optimization with top-down knowledge of elliptic shape}(e). In this step, using the ellipse center as fixation point, edges were reweighted to simulate an elliptic coordinate system.\n\n\n\\begin{figure}[htbp]\n  \\begin{center}\n    \\begin{tabular}{ccc}\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {101085.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMap.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (a) & (b)\\\\\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMapMasked.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {TorqueValueMapMasked3.eps}\n      \\end{center}\n      \\end{minipage}&\n\n      \\begin{minipage}{0.25\\columnwidth}\n      \\begin{center}\n      \\includegraphics[width=1\\columnwidth,keepaspectratio=true,clip]\n      {SegmentationSuccess.eps}\n      \\end{center}\n      \\end{minipage}\\\\\n\n      (c) & (d) & (e)\n\n    \\end{tabular}\n  \\end{center}\n  \\caption{Segmentation using optimization with top-down knowledge of elliptic shape.\n(a) Test image.\n(b) Torque value map.\n(c) Region of the torque value map within an elliptic region (for  initialized parameters).\n\n(d) Optimal elliptic region  found by optimization of the cost function $E$ in eq.~(\\ref{eq:energy for searching object}). (e.) Final segmentation.\n\\label{fig:Segmentation using optimization with top-down knowledge of elliptic shape}}\n\\end{figure}\n\n\\fi\n\n\\subsection{Recognition}\n\\label{sec:rec}\n\nThis section summarizes  experiments from \\cite{XuY2012}, where we used the torque mechanism for  object  recognition in the bag-of-features framework. The approach consists of two steps: a patch detection, and a patch description.  First, torque value extrema in space and scale and their corresponding patches are detected.  These  patches are separated into minima, i.e the dark patches on brighter background and maxima, i.e. bright patches on darker background. This detection scheme  is called \\emph{Maximal/Minimal Torque Patch (MTP) detector}.\n\nSecond,  the density and variance of the local edge structure is described in a multi-scale manner in the so-called   \\emph{Multiscale Torque (MST) descriptor}. For a given patch   regions of multiple sizes  having an overlap with the patch along the eight axes at discrete\nspace intervals are selected and their torque values are concatenated into a vector. To keep the number of selected areas the same for all patches, the step size is adapted to the patch size, and  to make it robust to rotation, the patch is rotated such that its x-axis becomes the direction\nclosest in direction to the vector pointing from the patch center\nto the centroid of the edges inside the patch P\n(see  Fig.~\\ref{fig:MST framework}).\n\n\n\\begin{figure*}[t]\n\\begin{center}\n\\begin{tabular}{cccc}\n    \\includegraphics[height=2.3in]{MST_1.eps}&\n    \\includegraphics[height=2.3in]{MST_2.eps}&\n    \\includegraphics[height=2.3in]{MST_3.eps}&\n    \\includegraphics[height=2.3in]{MST_4.eps}\\\\\n\\tiny{(a) An MTP patch}&\\tiny{(b) Torque magnitudes}&\\tiny{(c) Multi-scale sampling}&\\tiny{(d) Orientation alignment}\n\\end{tabular}\n\\end{center}\n\\caption{Outline of MST descriptor. From left to right: (a) An interesting patch is detected by the MTP detector.\n  (b) The torque magnitudes of regions  centered at points inside the detected patch are computed.\n  (c) The torque values  are  sampled along 8 directions at several scales.\n  The sampled values are collected  and concatenated as the local feature of the MTP patch.\n  (d) Alignment of the orientation of the feature by circular-shifting.}\n  \\label{fig:MST framework}\n\\end{figure*}\n\n\n This descriptor  was evaluated  for  object recognition following  the  {\\it bag of features} (BoF) representation paradigm evaluated on the Caltech-101 dataset.\n Table \\ref{table:rec} shows the performance of the  method in comparison to a number of   top feature-based recognition methods (which were also  used for comparison in \\cite{WYYLHG10}).\n As can be seen,  by itself the torque-based method performs about the same as \\cite{JainKG08}, but does not perform as well as methods based on SIFT-based features (such as \\cite{BoimanSI08cvpr},  \\cite{YangYGH09}, and \\cite{WYYLHG10}). This is because, these images are better captured by texture content (extracted through SIFT features). However by combining  the contour-based feature with SIFT, better performance was achieved. Our  implementation of the SIFT feature followed that of \\cite{WYYLHG10}, and  we combined the  two features by concatenating them into a single vector and weighing them 1:2 (ours v.s. SIFT). Our method had  an  additional  $2.45\\%-4.66\\%$ accuracy gain over the best results of other methods with respect to different sizes of the training set. These results demonstrate that the proposed contour-based feature does capture meaningful\ninformation of object contour and adds to objection recognition.\n\n\n\\begin{table*}\\label{table:result_101}\n\\begin{center}\n{\n\\begin{tabular}{|c||c|c|c|c|c|c|}\n\\hline\n& 5 & 10 & 15 & 20 & 25 & 30\\\\ \\hline\\hline\nJain~{et al\\onedot} \\cite{JainKG08} & - & - & 61.00 & - & - & 69.10 \\\\ \\hline\nBoiman~{et al\\onedot} \\cite{BoimanSI08cvpr} & - & - & 65.00 & - & - & 70.40 \\\\ \\hline\nYang~{et al\\onedot} \\cite{YangYGH09} & - & - & 67.00 & - & - & 73.20 \\\\ \\hline\nWang~{et al\\onedot} \\cite{WYYLHG10} & 51.15 & 59.77 & 65.43 & 67.74 & 70.16 & 73.44 \\\\ \\hline\\hline\nOurs & 48.17 & 57.65 & 62.33 & 65.32 & 67.39 & 68.97\\\\ \\hline\nOurs + SIFT & \\textbf{53.60} & \\textbf{64.01} & \\textbf{69.15} & \\textbf{72.40} & \\textbf{74.52} & \\textbf{76.22} \\\\\n\\hline\n\\end{tabular}\n}\n\\end{center}\n\\caption{Classification accuracy for different methods on the Caltech-101 dataset.}\n\\label{table:rec}\n\\end{table*}\n\n\n\n\nWe introduced a new tool of mid-level vision, the \\emph{Torque Operator}, and explored its fundamental properties using both theory and experiments.\nThe torque operator creates maps, which encode the structure of edges within patches, and it tends to generate larger absolute values when edges are aligned in a way surrounding the center of the patch, and the region enclosed by these edges matches the size of patch. This basic property was first discussed and examined on synthesized images. Then, this  property was demonstrated in the  applications of attention, boundary detection,  segmentation, and object recognition.\n\n\nExperiments showed that for all these  applications the torque operator enhances the performance. An efficient implementation of the torque based on integral images has  also been provided (see \\cite{code}).\n\nWe believe that the concept of a grouping mechanism implemented via image processing operations is a powerful concept, and there are many way this concept can be generalized.\n\nThis paper discussed a number of  ways on how to use the Torque  operator in bottom-up processing for various  applications. An immediate  extension would be to use  the information it provides in different ways. For example the torque value itself is also expected to be a useful visual cue for segmentation. Furthermore, the torque operator could be applied to image gradient maps instead of edge maps. Such a torque measure can be derived as the  average brightness difference between the  inside  and the boundary of an image patch (see Appendix A).\n\nThe general concept of a mid-level operator acting as grouping mechanism can be  developed along a number of directions.\nWe could have  various mechanisms tuned to different edge configurations. For example, instead of adding curve contribution, such that circles are favored, we can add them such that  radial lines or spirals are favored, and this way create a set of operators tuned to semi-global patterns. We demonstrated such operators for boundary ownership classification \\cite{Teoboundary2015}, but this generalization  could be useful also for texture or object recognition.\n\n\nWhile in this paper we applied the torque  to edges of single images, the torque operator is applicable also to geometric edges, such as depth edges and motion edges. Because these edges are due to depth discontinuities, which  usually are at the  boundary of surfaces, it is expected that such a torque operator  will perform better for finding objects.\n\nIt is clear that pure bottom-up processing has its limitations, and object recognition or object segmentation  in single images requires higher level knowledge. The torque mechanism as a mid-level grouping tool can be modified also to interact with  higher-level processes encoding semantic information. We believe that there is room for research that embeds mid-level operators into object recognition and learning. Such an approach was demonstrated in  \\cite{Teo2013} and \\cite{Teo2015}, where  torque-like operators  were tuned to  specific shapes.\nContour processing of specific object classes using generalized torque then proceeds in two steps. First the bottom-up torque acts as an attention (or saliency) mechanism. Then  torque-like operators, that are tuned to respond to learned categories of objects, object parts,  or attributes  can be used in task-guided top-down  processing.\n\\section{Acknowledgements}\nThe support of the European Union under the Cognitive Systems program (project POETICON++), the National Science Foundation under INSPIRE\ngrant SMA 1248056, and  DARPA through U.S. Army grant\nW911NF-14-1-0384 are gratefully acknowledged.  \\newline\n\n\n\n The authors would like to thank Daniel Dementhon for sharing his code, which originated this project.\n\n\n\\section{Torque based on Gradient}\n\\label{sec:gradient}\n\nIn previous sections, the torque was defined on edges, where edges were normalized as unit vectors.\nNext we consider a slightly different formulation of the torque, which considers the strength of edges.\nImages have strong edges and weak edges, and the strength is defined by the gradient. \nAs will be shown next, a torque  of patches defined on gradients can be computed simply from the intensity in the area and at  the boundary of the patch.\n\nThe {\\it gradient torque} is defined as follows:\n\n", "index": 39, "text": "\\begin{align}\n\\tau_{pq} = \\vec{r}_{pq} \\times \\tilde{\\nabla} I\\left(q\\right),\\label{eq:torque of gradient}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{pq}=\\vec{r}_{pq}\\times\\tilde{\\nabla}I\\left(q\\right),\" display=\"inline\"><mrow><mrow><msub><mi>\u03c4</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>=</mo><mrow><mrow><msub><mover accent=\"true\"><mi>r</mi><mo stretchy=\"false\">\u2192</mo></mover><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u00d7</mo><mover accent=\"true\"><mo>\u2207</mo><mo stretchy=\"false\">~</mo></mover></mrow><mo>\u2062</mo><mi>I</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>q</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $P$ is the patch, and the integral is taken over the patch.\n\nNext we show that the gradient torque of a patch can be computed as the\ndifference of the average image intensity inside the patch and the average image intensity on the patch boundary.\nConsidering a  disk patch, it thus amounts to:\n\n", "itemtype": "equation", "pos": 116511, "prevtext": "\nwhere $p$ is the center point and\n$q$ is some  point on the image.\n$\\vec{r}_{pq}$ is the displacement vector from $p$ to $q$.\n$\\tilde{\\nabla} I\\left(q\\right)$ is the image gradient at $q$ rotated by  90 degree, i.e. $\\left(\\frac{\\partial I}{\\partial y},-\\frac{\\partial I}{\\partial x}\\right)$, representing an edge-like vector.\nSimilarly, the {\\it gradient torque  for a patch} is defined as:\n\n", "index": 41, "text": "\\begin{align}\n\\tau_{P,p} = \\frac{1}{2\\left|P\\right|}\\int_{q\\in P} \\tau_{pq} dq,\\label{eq:torque of gradient for patch}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{P,p}=\\frac{1}{2\\left|P\\right|}\\int_{q\\in P}\\tau_{pq}dq,\" display=\"inline\"><mrow><mrow><msub><mi>\u03c4</mi><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo>|</mo><mi>P</mi><mo>|</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msub><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mi>q</mi><mo>\u2208</mo><mi>P</mi></mrow></msub></mstyle><mrow><msub><mi>\u03c4</mi><mrow><mi>p</mi><mo>\u2062</mo><mi>q</mi></mrow></msub><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>q</mi></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nwhere $I\\left(r,\\theta\\right)$ is the image intensity at $\\left(r,\\theta\\right)$ in the  polar coordinate system.\nWithout loss of generality, it is  assumed that the center of the  patch is the origin of the coordinate system so that $\\vec{r}_{pq} = \\left(x,y\\right)$ for $q=\\left(x,y\\right)$.\nThen, using the substitution $\\left(x,y\\right)=\\left(r\\cos\\theta,r\\sin\\theta\\right)$, eq.(\\ref{eq:torque intnsity difference}) can be  deduced as follows:\n\n", "itemtype": "equation", "pos": 116942, "prevtext": "\nwhere $P$ is the patch, and the integral is taken over the patch.\n\nNext we show that the gradient torque of a patch can be computed as the\ndifference of the average image intensity inside the patch and the average image intensity on the patch boundary.\nConsidering a  disk patch, it thus amounts to:\n\n", "index": 43, "text": "\\begin{align}\n\\tau_{P,p} &= \\frac{1}{\\pi R^2}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}I\\left(r,\\theta\\right)\\cdot rd\\theta dr \\nonumber\\\\\n&- \\frac{1}{2\\pi R}\\int^{\\pi}_{-\\pi}I\\left(R,\\theta\\right)\\cdot Rd\\theta,\\label{eq:torque intnsity difference}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{P,p}\" display=\"inline\"><msub><mi>\u03c4</mi><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{\\pi R^{2}}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}I\\left(r,\\theta%&#10;\\right)\\cdot rd\\theta dr\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>R</mi></msubsup></mstyle><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi>\u03c0</mi></mrow><mi>\u03c0</mi></msubsup></mstyle><mrow><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>r</mi><mo>,</mo><mi>\u03b8</mi><mo>)</mo></mrow></mrow><mo>\u22c5</mo><mi>r</mi></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>r</mi></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle-\\frac{1}{2\\pi R}\\int^{\\pi}_{-\\pi}I\\left(R,\\theta\\right)\\cdot Rd\\theta,\" display=\"inline\"><mrow><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mi>R</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi>\u03c0</mi></mrow><mi>\u03c0</mi></msubsup></mstyle><mrow><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>R</mi><mo>,</mo><mi>\u03b8</mi><mo>)</mo></mrow></mrow><mo>\u22c5</mo><mi>R</mi></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03b8</mi></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04669.tex", "nexttext": "\nEq. (\\ref{eq:forty})  is equivalent to eq. (\\ref{eq:torque intnsity difference}), which concludes the proof.\n\n\n\n\n\n\n\n\\bibliographystyle{plain}\n\\bibliography{references}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 117640, "prevtext": "\nwhere $I\\left(r,\\theta\\right)$ is the image intensity at $\\left(r,\\theta\\right)$ in the  polar coordinate system.\nWithout loss of generality, it is  assumed that the center of the  patch is the origin of the coordinate system so that $\\vec{r}_{pq} = \\left(x,y\\right)$ for $q=\\left(x,y\\right)$.\nThen, using the substitution $\\left(x,y\\right)=\\left(r\\cos\\theta,r\\sin\\theta\\right)$, eq.(\\ref{eq:torque intnsity difference}) can be  deduced as follows:\n\n", "index": 45, "text": "\\begin{align}\n\\tau_{P,p} &= \\frac{1}{2\\pi R^2}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}\n\\left\\{x\\left(-\\frac{\\partial  I}{\\partial x}\\right)-y\\frac{\\partial I}{\\partial y}\\right\\}rd\\theta dr\\\\\n&= \\frac{1}{2\\pi R^2}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}\\cos\\theta\\left(\\sin\\theta\\frac{\\partial I}{\\partial \\theta}-r\\cos\\theta\\frac{\\partial I}{\\partial r}\\right)\\\\ \\nonumber\n& - \\sin\\theta\\left(\\cos\\theta\\frac{\\partial I}{\\partial \\theta}+r\\sin\\theta\\frac{\\partial I}{\\partial r}\\right)r d\\theta dr\\\\\n&= - \\frac{1}{2\\pi R^2}\\int^{R}_{0}\\int^{\\pi}_{\\pi} r^2\\frac{\\partial I}{\\partial r} d\\theta dr\\\\\n&= -\\frac{1}{2\\pi R^2} \\int^{\\pi}_{-\\pi} \\left\\{R^2I\\left(R,\\theta\\right)-\\int^{R}_{0}2rI\\left(r,\\theta\\right) dr\\right\\}d\\theta. \\label{eq:forty}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tau_{P,p}\" display=\"inline\"><msub><mi>\u03c4</mi><mrow><mi>P</mi><mo>,</mo><mi>p</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{2\\pi R^{2}}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}\\left\\{x\\left(-%&#10;\\frac{\\partial I}{\\partial x}\\right)-y\\frac{\\partial I}{\\partial y}\\right\\}rd%&#10;\\theta dr\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>R</mi></msubsup></mstyle><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi>\u03c0</mi></mrow><mi>\u03c0</mi></msubsup></mstyle><mrow><mrow><mo>{</mo><mrow><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>x</mi></mrow></mfrac></mstyle></mrow><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mi>y</mi><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>y</mi></mrow></mfrac></mstyle></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>r</mi></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{2\\pi R^{2}}\\int^{R}_{0}\\int^{\\pi}_{-\\pi}\\cos\\theta\\left%&#10;(\\sin\\theta\\frac{\\partial I}{\\partial\\theta}-r\\cos\\theta\\frac{\\partial I}{%&#10;\\partial r}\\right)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>R</mi></msubsup></mstyle><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi>\u03c0</mi></mrow><mi>\u03c0</mi></msubsup></mstyle><mrow><mrow><mi>cos</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03b8</mi></mrow></mfrac></mstyle></mrow></mrow><mo>-</mo><mrow><mi>r</mi><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>r</mi></mrow></mfrac></mstyle></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle-\\sin\\theta\\left(\\cos\\theta\\frac{\\partial I}{\\partial\\theta}+r%&#10;\\sin\\theta\\frac{\\partial I}{\\partial r}\\right)rd\\theta dr\" display=\"inline\"><mrow><mo>-</mo><mrow><mrow><mi>sin</mi><mo>\u2061</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03b8</mi></mrow></mfrac></mstyle></mrow></mrow><mo>+</mo><mrow><mi>r</mi><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>r</mi></mrow></mfrac></mstyle></mrow></mrow></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>\u03b8</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>r</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\frac{1}{2\\pi R^{2}}\\int^{R}_{0}\\int^{\\pi}_{\\pi}r^{2}\\frac{%&#10;\\partial I}{\\partial r}d\\theta dr\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>R</mi></msubsup></mstyle><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>\u03c0</mi><mi>\u03c0</mi></msubsup></mstyle><mrow><msup><mi>r</mi><mn>2</mn></msup><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>I</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>r</mi></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03b8</mi></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>r</mi></mrow></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\frac{1}{2\\pi R^{2}}\\int^{\\pi}_{-\\pi}\\left\\{R^{2}I\\left(R,%&#10;\\theta\\right)-\\int^{R}_{0}2rI\\left(r,\\theta\\right)dr\\right\\}d\\theta.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mo>-</mo><mi>\u03c0</mi></mrow><mi>\u03c0</mi></msubsup></mstyle><mrow><mrow><mo>{</mo><mrow><mrow><msup><mi>R</mi><mn>2</mn></msup><mo>\u2062</mo><mi>I</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>R</mi><mo>,</mo><mi>\u03b8</mi><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>R</mi></msubsup></mstyle><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>I</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>r</mi><mo>,</mo><mi>\u03b8</mi><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>r</mi></mrow></mrow></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>\u03b8</mi></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]