[{"file": "1601.00025.tex", "nexttext": " \nwhere $\\mathbf{x}$ (bold) is the visual feature vector of an image $x$ (not bold) amended with 1   and $\\mathbf{c}_j \\in \\mathbb{R}^{d_v}$ is the linear classifier parameters for class $j$. Given a test image, its class is determined by\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\n\n\n\n\n\n\n\n\\title{Write a Classifier:  Predicting Visual Classifiers from Unstructured Text Descriptions}\n\n\n\n\n\n\n\n\n\n\n\n\\author{Mohamed ~Elhoseiny,~\\IEEEmembership{Member,~IEEE,}\n        Ahmed~Elgammal,~\\IEEEmembership{Senior Member,~IEEE,}\n        and~Babak~Saleh\n\n\n\n\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\\begin{abstract}\nPeople typically learn through exposure to visual concepts associated with linguistic descriptions. For instance, teaching visual object categories to children is often accompanied by descriptions in text or speech. In a machine learning context, these observations motivates us to ask whether this learning process could be computationally modeled to learn visual classifiers\\ignore{ recognition accuracy, compared to traditional   approaches that depend only on the visual domain}. More specifically, the main question of this work is how to utilize purely textual description of visual classes\\ignore{, as privileged information,} with no\\ignore{or few} training images, to learn explicit visual classifiers for them. We propose and investigate two baseline formulations, based on regression and domain transfer that predict a linear classifier. Then, we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to predict the linear classifier parameters for new classes. We also propose a generic kernelized  models where a kernel classifier, in the form defined by the representer  theorem, is predicted. The kernelized models allow defining any two RKHS kernel functions in the visual space and text space, respectively, and could be useful for other applications. We finally propose a kernel function between unstructured text descriptions that builds on distributional semantics, which shows an advantage in our  setting  and could be useful for other applications. We applied all the studied models to predict visual classifiers for two fine-grained categorization datasets, and the results indicate successful predictions of our final model against  several baselines that we designed.  \n\n\n\n\\end{abstract}\n\n\\begin{IEEEkeywords}\nLanguage and Vision, Zero Shot Learning, Unstructured Text. \n\\end{IEEEkeywords}\n\n\n\n\\section{Introduction}\n\\label{intro}\n\n\nOne of the main challenges for scaling up object recognition systems is the lack of annotated images for real-world categories. \n\nTypically there are few images available for training classifiers for most of these categories. This is reflected in the number of images per category available for training in most object categorization datasets, which, as pointed out in~\\cite{Salakhutdinov11}, shows a Zipf distribution. \nThe problem of lack of training images becomes even more severe when we target recognition problems within a general category, {\\latinabbrev{i.e}}, fine-grained categorization, for example building classifiers for different bird species or flower types  (there are estimated over 10000 living bird species, similar for flowers). \nResearchers try to exploit shared knowledge between categories to target such scalability issue.\nThis motivated many researchers who looked into approaches that learn visual classifiers from few examples, {\\latinabbrev{e.g}}~\\cite{deng2010does,fe2003bayesian,BartU05}.   This even motivated a more recent work on zero-shot learning of visual categories where there are no training images available for test categories (unseen classes), {\\latinabbrev{e.g}}~\\cite{Lampert09}. Such approaches exploit the similarity (visual or semantic) between seen classes and unseen ones, or describe unseen classes in terms of a learned vocabulary of semantic visual attributes. \n\n\n  \\begin{figure}[t!]\n\\centering\n\\vspace{-3mm}\n    \\includegraphics[width=0.83\\linewidth]{figproblem2.png} \n      \\vspace{-2mm}\n  \\caption{{Our proposed setting where machine can predict unseen class from class-level unstructured  text description}}\n  \\label{fig:problem}\n    \\vspace{-6mm}\n\\end{figure}\n\nIn contrast to the lack of reasonable size training sets for a large number of real world categories, there are abundant of textual descriptions of these categories. This comes in the form of dictionary entries, encyclopedia articles, and various online resources. For example, it is possible to find several good descriptions of a ``bobolink'' in encyclopedias of birds, while there are only a few images available for that bird online. \n\n{\\em The main question we address in this paper is how to use purely textual description of categories with no training images to learn visual classifiers for these categories.} In other words, we aim at zero-shot learning of object categories where the description of unseen categories comes in the form of typical text such as an encyclopedia entry; see figure~\\ref{fig:problem}. We explicitly address the question of how to automatically decide which information to transfer between classes without the need of human intervention.  In contrast to most related work, we go beyond the simple use of tags and image captions, and apply standard Natural Language Processing techniques to typical text to learn visual classifiers. \n\n\nFine-grained categorization \\ignore{(also known as subordinate categorization)} refers to classification of highly similar objects. This similarity can be due to natural intrinsic characteristics of subordinates of one category of objects (e.g. different breeds of dogs) or artificial subcategories of an object class (different types of airplanes). Diverse applications of fine-grained categories range from classification of natural species~\\cite{wah2011caltech,Flower08,wang2009learning,liu2012dog} to retrieval of different types of commercial products~\\cite{maji2013fine}. \n\\begin{figure*}[t]\n\\centering\n\\input{bobolink_example}\n\n\\includegraphics[width=0.92\\linewidth,height=.46\\linewidth]{probDef_overall.png}\n\n\\caption{ Top: Example Wikipedia article about the Painted Bunting, with an example image. Bottom: The proposed learning setting. For each category we are give one (or more) textual description (only a synopsis of a larger text is shown),  and a set of training images. Our goal is to be able to predict a classifier for a  category based only on the narrative (zero-shot learning). }\n\\label{F:prob_def}\n\\vspace{-14pt}\n\\end{figure*}\n\nIn this problem, When we learn from an expert about different species of birds, the teacher will not just give you sample images of each species and their class labels; the teacher will tell you about discriminative visual or non-visual features for each species, similarity and differences between species, hierarchal relations between species, and many other aspects. The same learning experience takes place when you read a book or a web page to learn about the different species of birds; For example, Fig.~\\ref{F:prob_def} shows an example narrative about the {\\sf Bobolink}. Typically, the narrative tells you about the bird's taxonomy, highlights discriminative features about that bird and discusses similarities and differences between species, as well as within-species variations (male vs. female). The narrative might eventually show very few example images, which are often selected wisely to illustrate certain visual aspects that might be hard to explain in the narrative.  This learning strategy using textual narrative and images makes the learning effective without a huge number of images  that a typical visual learning algorithm would need to learn the class boundaries. \n \n \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHowever, a narrative about a specific species does not contain only ``visually\" relevant information, but also gives abundant information about the species's habitat, diet, mating habits that is not relevant for visual identification. In a sense, this information might be textual clutter for that task. The same problem takes place in images. While one image can be very effective in highlighting an important feature for learning, many images  might have a lot of visual clutter that makes their uses in learning not effective. \nThus, a picture can be worth a thousand words, but not always, and an abundant number of pictures might not be the most effective way for learning. Similarly, one text paragraph can be worth a thousand pictures for learning a concept, but not always, and large amounts of text might not necessarily be effective.\n\n\n\n\n\n \n\n\\textbf{Contributions.} The contribution of the paper is on exploring this new problem, which to the best of our knowledge, is firstly explored in the computer vision community in this work. We learn from an image corpus and a textual corpus, however not in the form of image-caption pairs, instead the only alignment between the corpora is at the level of the category. In particular, we address the problem of formulating a visual classifier prediction function ${\\Phi (\\cdot)}$, which predicts a  classifier of unseen visual class given its text description; see figure~\\ref{F:prob_def}.  While a part of this work was  published in~\\cite{Hoseini13}, we extend the work here to study more formulations to solve the problem in Sec.~\\ref{formulation} (B,E). In addition, we also propose a kernel method to explicitly  predict a kernel classifier  in the form defined in the representer theorem~\\cite{rth01}.  The kernelized prediction has an advantage that it opens the door for using any kind of side information about classes, as long as kernels can be used on the side information representation.  The side information can be in the form of textual, parse trees, grammar, visual representations, concepts in the ontologies (adopted in NLP domain), or any form. We focus here on unstructured text descriptions.\\ignore{; see figure~\\ref{fig:problem}} The image features also do not need to be in a vectorized format. The kernelized classifiers also facilitates combining different types of features through a multi-kernel learning (MKL) paradigm, where the fusion of different features can be effectively achieved.\n\n\\ignore{We propose and investigate two baseline formulations based on regression and domain adaptation. Then we propose a new constrained optimization formulation that combines a regression function and a knowledge transfer function with additional constraints to solve the problem.} \n\nBeyond the introduction and the related work sections, the paper is structured as follows: Sec~\\ref{obvformulation} and ~\\ref{sec_reganKT} details the problem definition and relation to regression and knowledge transfer models. Sec~\\ref{formulation} shows different formulations of $\\Phi(\\cdot)$ that we studied to predict a linear visual classifier; see figure~\\ref{F:prob_def}. Section~\\ref{sec:app} developed extends our notion where  $\\Phi(\\cdot)$ predicts kernel classifier in the form defined by the representer theorem~\\cite{rth01}. Sec~\\ref{dskernel} presents our proposed distributional semantic kernel  between unstructured text description, which is applicable to  our kernel formulation and could be useful for other applications. Sec~\\ref{experiments} presents our experiments  on Flower Dataset~\\cite{Flower08} (102 classes) and Caltech-UCSD dataset~\\cite{CU20010} (200 classes) for both the linear and the kernel classifier prediction.\n\n\n\n\n\n\\section{Related Work}\n\\label{relwork}\n\n\nWe focus our related work discussion on three related lines of research: ``zero/few-shot learning'', ``visual knowledge transfer'', and ``Language and Vision''.\n\n\n\n\n\\textbf{Zero/Few-Shot Learning: }Similar to the setting of zero-shot learning, we use classes with training data (seen classes) to predict classifiers for classes with no training data (unseen classes).  Recent works on zero-shot learning of object categories focused on leveraging knowledge about common attributes and shared parts~\\cite{Lampert09}.  Typically, attributes ~\\cite{babak,Farhadi09}  are manually defined by humans and are used to transfer knowledge between seen and unseen classes.  In contrast, in our work we do not use any explicit attributes. The description of a new category is purely textual and the process is totally automatic without human annotation beyond the class labels.\n\n\nMotivated by the practical need to learn visual classifiers of rare categories, researchers have explored approaches for learning from a single image (one-shot learning~\\cite{Miller2000,fe2003bayesian,Fink04,BartU05}) or even from no images (zero-shot learning).\nOne way of recognizing object instances from previously unseen test categories\n(the zero-shot learning problem) is by leveraging knowledge about common attributes and shared parts.\nTypically an intermediate semantic layer is introduced to enable sharing knowledge between classes and facilitate describing knowledge about novel unseen classes, {\\latinabbrev{e.g}}~\\cite{Palatucci09}.\n For instance, given adequately labeled training data, one can learn classifiers for the attributes occurring in the training object categories. These classifiers can then be used to recognize the same attributes in object instances from the novel test categories. Recognition can then proceed on the basis of these learned attributes~\\cite{Lampert09, Farhadi09}. Such attribute-based ``knowledge transfer'' approaches use an intermediate visual attribute representation to enable describing unseen object categories. Typically attributes are manually defined by humans to describe shape, color, surface material, {\\latinabbrev{e.g}}, furry, striped, {\\latinabbrev{etc}}  Therefore, an unseen category has to be specified in terms of the used vocabulary of attributes.  Rohrbach {\\latinabbrev{et al}}~\\cite{rohrbach10eccv} investigated extracting useful attributes from large text corpora. In~\\cite{ParikhG11},  an approach was introduced for interactively defining a vocabulary of attributes that are both human understandable and visually discriminative. Huang {\\latinabbrev{et al}}~\\cite{Huang_2015_CVPR} relaxed the attribute independence assumption by modeling correlation between attributes to achieve better zero shot performance, as opposed to prior models. \n In contrast, our work does not use any explicit attributes. The description of a new category is purely textual. \n \n \n\n\\textbf{Visual Knowledge Transfer: }Our proposed work can be seen in the context of knowledge sharing and inductive transfer. \nIn general, knowledge transfer aims at enhancing recognition by exploiting shared knowledge between classes. Most existing research focused on knowledge sharing within the visual domain only, {\\latinabbrev{e.g}}~\\cite{griffin2008learning}; or exporting semantic knowledge at the level of category similarities and hierarchies, {\\latinabbrev{e.g}}~\\cite{fergus2010semantic,Salakhutdinov11}.  We go beyond the state-of-the-art to explore cross-domain knowledge sharing and transfer. We explore how knowledge from the visual and textual domains can be used to learn across-domain correlation, which facilitates prediction of visual classifiers from textual description.  \n\n\n\n\n\n\n\n\n\n\n\\textbf{Language and Vision:} The relation between linguistic semantic representations and visual recognition have been explored. For example in~\\cite{deng2010does}, it was shown that there is a strong correlation between semantic similarity between classes, based on WordNet, and confusion between classes. Linguistic semantics in terms of nouns from WordNet \\cite{wordNet95} have been used in collecting large-scale image datasets such as ImageNet\\cite{imNet09} and Tiny Images~\\cite{tinyimages}. It was also shown that hierarchies based on WordNet are useful in learning visual classifiers, {\\latinabbrev{e.g}}~\\cite{Salakhutdinov11}.\n\n\n\n\n\n\nOne of the earliest work on learning from images and text corpora is the work of Barnard {\\latinabbrev{et al}}~\\cite{barnard2001clustering}, which showed that learning  a joint distribution of words and visual elements facilitates clustering the images in a semantic way, generating illustrative images from a caption, and generating annotations for novel images.\nThere has been an increasing recent interest in the intersection between computer vision and natural language processing with researches that focus on generating textual description of images and videos, {\\latinabbrev{e.g}}~\\cite{farhadi2010every,kulkarni2011baby,yang2011corpus,krishnamoorthy2013generating}. This includes generating sentences about objects, actions, attributes, patial relation between objects, contextual information in the images, scene information, {\\latinabbrev{etc}}\n        ~In contrast, our work is different in two fundamental ways. In terms of the goal, we do not target generating textual description from images, instead we target  predicting classifiers from text, in a zero-shot setting. In terms of the learning setting, the textual descriptions that we use is at the level of the category  and do not come in the form of image-caption pairs, as in typical datasets used for text generation from images, {\\latinabbrev{e.g}}~\\cite{ordonez2011im2text}. Recent impressive works has been proposed for image captioning (e.g., ~\\cite{karpathy2014deep,vinyals2015show,xu2015show,mao2015deep}), which are based on the success of sequence to sequence training of neural nets \n\nfor translation \n(e.g.,~\\cite{cho2014learning}).  In contrast, our work focus on a different  setting, which is  transforming an Encyclopedia text description to visual classifier.\n\n\nThere are several recent works that involved unannotated text\\ignore{ \\cite{NIPS13DeViSE,NIPS13CMT,Hoseini13}}.  In \\cite{NIPS13DeViSE} and ~\\cite{NIPS13CMT},  word  embedding language models ({\\latinabbrev{e.g}} ~\\cite{wvecNIPs13}) was adopted to represent class names as vectors which requires training using a  big text-corpus. Their goal is to embed images into the language space then perform classification. There are several differences between these works and our method. First, one limitation of the adopted language model is that it produces only one vector per word, which produces problems when a word has multiple meanings.  Second, it can not represent a big text description of a class instead of a single or few words or others forms that could be ambiguous. Third,  our goal is different which is to map the text description to a classifier in the visual domain, {\\latinabbrev{i.e}} the apposite direction of their goal. Forth, these models do not support non-linear classification, supported by the kernelized version proposed in this work\\ignore{, which is supported by our method}. We finally focus on fine-grained recognition, which is very  challenging\\ignore{; see figure~\\ref{fig:problem}}.  \n\n\n\nWe can summarize the features of our proposed framework in contrast to prior work as follows: 1) Our framework explicitly predicts classifiers; 2) The predicted classifiers could be linear or  kernelized; 3) The approach requires the text description at the class level, not at the image level, hence, it needs only weak annotation. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Problem Definition}\n\\label{obvformulation}\n\n\n\nFig~\\ref{F:prob_def} illustrates the learning setting. \nThe information in our problem comes from two different domains: the visual domain  and the textual domain, denoted by $\\mathcal{V}$ and $\\mathcal{T}$, respectively. Similar to traditional visual learning problems, we are given training data in the form $V=\\{({x}_i , l_i)\\}_{N}$, where $x_i$ is an image and $l_i \\in \\{1\\cdots N_{sc}\\}$ is its class label. We denote the number of classes available at training as $N_{sc}$, where $sc$ indicates ``seen classes''. As typically done in visual classification setting, we can learn $N_{sc}$ binary one-vs-all classifiers, one for each of these classes.  \n\nOur goal is to be able to predict a classifier for a new category based only on the learned classes and a textual description(s) of that category. In order to achieve that, the learning process has to also include textual description of the seen classes (as shown in Fig ~\\ref{F:prob_def} ). Depending on the domain we might find a few, a couple, or as little as one textual description to each class. We denote the textual training data for class $j$ by $\\{t_i\\in \\mathcal{T} \\}^j$. \nIn this paper we assume we are dealing with the extreme case of having only one textual description available per class, which makes the problem even more challenging. For simplicity, the text description of class $j$ is denoted by $t_j$. However, the formulation we propose in this paper directly applies to the case of multiple textual descriptions per class.\n\n\n\nIn this paper, we cover predicting  visual classifier ${\\Phi}(t_*)$ from an unseen text description $t_*$  in  linear form or RKHS kernalized form, defined as follows \n\n\n\\subsection{Linear Classifier}\n\\label{sec_lin_pdef}\nLet us consider a typical \\ignore{binary }linear classifier in the feature space in the form\n", "index": 1, "text": "\n\\[\n    f_j(\\mathbf{x}) = \\mathbf{c}_j^\\textsf{T} \\cdot \\mathbf{x}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"f_{j}(\\mathbf{x})=\\mathbf{c}_{j}^{\\textsf{T}}\\cdot\\mathbf{x}\" display=\"block\"><mrow><mrow><msub><mi>f</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mi>\ud835\udc1c</mi><mi>j</mi><mtext>\ud835\uddb3</mtext></msubsup><mo>\u22c5</mo><mi>\ud835\udc31</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n  \n Similar to the visual domain, the raw textual descriptions have to go through a feature extraction process\\ignore{, which will be described in Sec~\\ref{experiments}}. Let us denote the linear extracted textual feature by \n$T=\\{\\mathbf{t}_j \\in \\mathbb{R}^{d_t}\\}_{j=1\\cdots N_{sc}}$, where $\\mathbf{t}_j$ is the features of text description $t_j$ (not bold).  Given a textual description ${t}_*$  of a new unseen category $\\mathcal{U}$  with linear feature vector representation $\\mathbf{t}_*$, the problem can now be defined as predicting a one-vs-all linear classifier parameters ${\\Phi}{(t_*)} = c(\\mathbf{t}_*) \\in \\mathbb{R}^{d_v}$,  such that it can be directly used to classify any test image $\\mathbf{x}$ as \n\\begin{eqnarray}\n      c(\\mathbf{t}_*)^\\textsf{T} \\cdot \\mathbf{x} >  0 & \\text{if} \\;  \\mathbf{x} \\; \\text{belongs to} \\;\\mathcal{U} \\nonumber \\\\\n      c(\\mathbf{t}_*)^\\textsf{T} \\cdot \\mathbf{x} <  0 &  \\text{otherwise} \\label{E:PredictedClass}\n\\end{eqnarray}\n\n\n\n\\subsection{Kernel Classifier}\n\\label{sec_kernel_pdef}\nFor kernel classifiers, we assume that each of the domains is equipped with a kernel function corresponding to a \\textit{reproducing kernel Hilbert space} (RKHS). Let us denote the kernel for $\\mathcal{V}$ by $k(\\cdot,\\cdot)$, and the kernel for $\\mathcal{T}$ by $g(\\cdot,\\cdot)$. \n\\ignore{Since, we are studying explicit kernel-classifier prediction from privileged information, we first present an overview on multi-class classification on kernel space.  One} \n\\normalsize \n\n\nAccording to the generalized representer theorem~\\cite{rth01},  a minimizer of a regularized empirical risk function over an RKHS could be represented as a linear combination of kernels, evaluated on the training set. Adopting the representer theorem on classification risk function, we define a kernel-classifier of a visual class $j$ as follows\n\n\n\n", "itemtype": "equation", "pos": 21228, "prevtext": " \nwhere $\\mathbf{x}$ (bold) is the visual feature vector of an image $x$ (not bold) amended with 1   and $\\mathbf{c}_j \\in \\mathbb{R}^{d_v}$ is the linear classifier parameters for class $j$. Given a test image, its class is determined by\n\n", "index": 3, "text": "\\begin{equation}\n\\small\nl^* = \\arg \\max_j f_j(\\mathbf{x})\n\\label{eq:mclass}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\small l^{*}=\\arg\\max_{j}f_{j}(\\mathbf{x})\" display=\"block\"><mrow><msup><mi mathsize=\"90%\">l</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msup><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><mrow><mi mathsize=\"90%\">arg</mi><mo>\u2061</mo><mrow><munder><mi mathsize=\"90%\">max</mi><mi mathsize=\"90%\">j</mi></munder><mo>\u2061</mo><msub><mi mathsize=\"90%\">f</mi><mi mathsize=\"90%\">j</mi></msub></mrow></mrow><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nwhere ${x} \\in \\mathcal{V}$ is the test image, ${x}_i$ is the $i^{th}$ image in the training data $V$,  $\\textbf{k}({x})= [k({x}, {x}_1), \\cdots, k({x}, {x}_N), 1]^\\textsf{T},$  $\\boldsymbol{\\beta}_j = [\\beta_j^1 \\cdots \\beta_j^N, b]^\\textsf{T} $. Having learned $f_j({x}^*)$ for each class $j$ (for example using SVM classifier), the class label of the test image ${x}$ can be predicted by  Eq.~\\ref{eq:mclass}, similar to the linear case. Eq.~\\ref{eq_fkernel} also shows how $\\boldsymbol{\\beta}_j$ is related to $\\mathbf{c}_j$ in the linear classifier, where $k(x, x')= \\varphi(x)^\\mathsf{T} \\cdot \\varphi(x')$ and $\\varphi(\\cdot)$ is a feature map  that does not have to be defined given $k(\\cdot, \\cdot)$ on $\\cal{V}$. Hence, our goal in the kernel classifier prediction  is to predict $\\boldsymbol{\\beta}(t_*)$ instead of $\\mathbf{c}(t_*)$ since it is sufficient to define  ${f}_{t_*}(x)$ for a text description $t_*$ of an unseen class given $\\mathbf{k}(x)$\n\n\n\n\n\n\n\n\n\\ignore{Under our setting, i}It is clear that $f_j({x})$ could be learned for  all classes with training data $j \\in  {1} \\cdots {N_{sc}}$, since there are examples for the seen classes; we denote the kernel-classifier parameters of the seen classes as $\\mathcal{B}_{sc} =  \\{  \\boldsymbol{\\beta}_j \\}_{N_{sc}}, \\forall j$. However, it is not obvious how to predict $f_{{t}_*}({x})$ for an unseen class given its text description ${t}_*$. Similar to the linear classifier prediction, our main notion is to use the text description ${t}_{*}$, associated with unseen class, and the training data to directly predict the unseen kernel-classifier parameters. In other words, the kernel classifier parameters of the unseen class is a function of  its text description ${t}_*$ , the image training data $V$ and the text training data $\\{t_j\\}, j\\in 1 \\cdots N_{sc}$; {\\latinabbrev{i.e}} \\small\n", "itemtype": "equation", "pos": 23187, "prevtext": "\n  \n Similar to the visual domain, the raw textual descriptions have to go through a feature extraction process\\ignore{, which will be described in Sec~\\ref{experiments}}. Let us denote the linear extracted textual feature by \n$T=\\{\\mathbf{t}_j \\in \\mathbb{R}^{d_t}\\}_{j=1\\cdots N_{sc}}$, where $\\mathbf{t}_j$ is the features of text description $t_j$ (not bold).  Given a textual description ${t}_*$  of a new unseen category $\\mathcal{U}$  with linear feature vector representation $\\mathbf{t}_*$, the problem can now be defined as predicting a one-vs-all linear classifier parameters ${\\Phi}{(t_*)} = c(\\mathbf{t}_*) \\in \\mathbb{R}^{d_v}$,  such that it can be directly used to classify any test image $\\mathbf{x}$ as \n\\begin{eqnarray}\n      c(\\mathbf{t}_*)^\\textsf{T} \\cdot \\mathbf{x} >  0 & \\text{if} \\;  \\mathbf{x} \\; \\text{belongs to} \\;\\mathcal{U} \\nonumber \\\\\n      c(\\mathbf{t}_*)^\\textsf{T} \\cdot \\mathbf{x} <  0 &  \\text{otherwise} \\label{E:PredictedClass}\n\\end{eqnarray}\n\n\n\n\\subsection{Kernel Classifier}\n\\label{sec_kernel_pdef}\nFor kernel classifiers, we assume that each of the domains is equipped with a kernel function corresponding to a \\textit{reproducing kernel Hilbert space} (RKHS). Let us denote the kernel for $\\mathcal{V}$ by $k(\\cdot,\\cdot)$, and the kernel for $\\mathcal{T}$ by $g(\\cdot,\\cdot)$. \n\\ignore{Since, we are studying explicit kernel-classifier prediction from privileged information, we first present an overview on multi-class classification on kernel space.  One} \n\\normalsize \n\n\nAccording to the generalized representer theorem~\\cite{rth01},  a minimizer of a regularized empirical risk function over an RKHS could be represented as a linear combination of kernels, evaluated on the training set. Adopting the representer theorem on classification risk function, we define a kernel-classifier of a visual class $j$ as follows\n\n\n\n", "index": 5, "text": "\\begin{equation}\n\\small\n\\begin{split}\nf_j({x})=&   \\sum_{i=1}^{N} \\beta_j^i k({x}, {x}_i) + b  = \\sum_{i=1}^{N} \\beta_j^i \\varphi({x_i})^\\textsf{T} \\varphi( {x}) + b \\\\\nf_j({x})=&  {\\boldsymbol{\\beta}_j}^\\textsf{T} \\cdot  \\textbf{k}({x}) =  \\mathbf{c}_j^\\textsf{T} \\cdot [\\varphi(x); 1] , \\mathbf{c}_j =  [\\sum_{i=1}^{N} \\beta_j^i \\varphi({x_i}); b]\\\\\n\n\\end{split}\n\\label{eq_fkernel}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\small\\begin{split}\\displaystyle f_{j}({x})=&amp;\\displaystyle\\sum_{i=1}^{N}\\beta_%&#10;{j}^{i}k({x},{x}_{i})+b=\\sum_{i=1}^{N}\\beta_{j}^{i}\\varphi({x_{i}})^{\\textsf{T%&#10;}}\\varphi({x})+b\\\\&#10;\\displaystyle f_{j}({x})=&amp;\\displaystyle{\\boldsymbol{\\beta}_{j}}^{\\textsf{T}}%&#10;\\cdot\\textbf{k}({x})=\\mathbf{c}_{j}^{\\textsf{T}}\\cdot[\\varphi(x);1],\\mathbf{c}%&#10;_{j}=[\\sum_{i=1}^{N}\\beta_{j}^{i}\\varphi({x_{i}});b]\\\\&#10;\\par&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><msub><mi mathsize=\"90%\">f</mi><mi mathsize=\"90%\">j</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">N</mi></munderover><mrow><msubsup><mi mathsize=\"90%\">\u03b2</mi><mi mathsize=\"90%\">j</mi><mi mathsize=\"90%\">i</mi></msubsup><mo>\u2062</mo><mi mathsize=\"90%\">k</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><msub><mi mathsize=\"90%\">x</mi><mi mathsize=\"90%\">i</mi></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mi mathsize=\"90%\">b</mi></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><mrow><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">N</mi></munderover><mrow><msubsup><mi mathsize=\"90%\">\u03b2</mi><mi mathsize=\"90%\">j</mi><mi mathsize=\"90%\">i</mi></msubsup><mo>\u2062</mo><mi mathsize=\"90%\">\u03c6</mi><mo>\u2062</mo><msup><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">x</mi><mi mathsize=\"90%\">i</mi></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><mi mathsize=\"90%\">\u03c6</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mi mathsize=\"90%\">b</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><msub><mi mathsize=\"90%\">f</mi><mi mathsize=\"90%\">j</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mrow><mmultiscripts><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">j</mi><none/><none/><mtext mathsize=\"90%\">\ud835\uddb3</mtext></mmultiscripts><mo mathsize=\"90%\" stretchy=\"false\">\u22c5</mo><mtext mathsize=\"90%\">\ud835\udc24</mtext></mrow><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><msubsup><mi mathsize=\"90%\">\ud835\udc1c</mi><mi mathsize=\"90%\">j</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msubsup><mo mathsize=\"90%\" stretchy=\"false\">\u22c5</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">[</mo><mrow><mi mathsize=\"90%\">\u03c6</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">x</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">;</mo><mn mathsize=\"90%\">1</mn><mo maxsize=\"90%\" minsize=\"90%\">]</mo></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mrow><msub><mi mathsize=\"90%\">\ud835\udc1c</mi><mi mathsize=\"90%\">j</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">[</mo><mrow><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">N</mi></munderover><mrow><msubsup><mi mathsize=\"90%\">\u03b2</mi><mi mathsize=\"90%\">j</mi><mi mathsize=\"90%\">i</mi></msubsup><mo>\u2062</mo><mi mathsize=\"90%\">\u03c6</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">x</mi><mi mathsize=\"90%\">i</mi></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">;</mo><mi mathsize=\"90%\">b</mi><mo maxsize=\"90%\" minsize=\"90%\">]</mo></mrow></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": " \\normalsize\n $ f_{{t}_*}({x})$ could be used to classify new points that\t belong to an  unseen class as follows: 1) one-vs-all setting  $f_{{t}_*}({x})  \\gtrless  0$  \\ignore{if ${x}^*\\,$  belongs to unseen category $z^*$, $\\boldsymbol{\\beta}(\\mathbf{t}_*),)^\\textsf{T} \\cdot \\textbf{k}(x^*)< 0$  otherwise}; or 2) in a Multi-class prediction as in Eq~\\ref{eq:mclass}. ${\\Phi}(t_*)$ in this case is $\\boldsymbol{\\beta}({t}_{*})$. In contrast to linear classifier prediction, there is no need to explicitly represent an image $x$ or a text description $t$ by features, which are denoted by the bold symbols in the previous section. Rather, only the  $k(\\cdot,\\cdot)$  and $g(\\cdot,\\cdot)$ needs to be defined which is general. \n\n\n\n\\section{Relation to Regression and Knowledge Transfer Models}\n\\label{sec_reganKT}\nWe introduce two possible frameworks for this problem and discuss potential limitations for them. In this background section,  we focus on predicting linear classifiers for simplicity, which motivates the the evaluated linear classifier formulations that follow in Sec~\\ref{formulation}. \n\n\\subsection{Regression Models}\nA straightforward way to solve this problem is to pose it as a regression problem where the goal is to use the textual data and the learned classifiers, $\\{(\\mathbf{t}_j,\\mathbf{c}_j) \\}_{j=1\\cdots N_{sc}}$ to learn a regression function from the textual feature domain to the visual classifier domain, {\\latinabbrev{i.e}}, a function $c(\\cdot) : \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R}^{d_v} $.  The question is which regression model would be suitable for this problem? and would posing the problem this way give reasonable results?\n\nA typical regression model, such as ridge regression~\\cite{ridgeReg70} or Gaussian Process (GP) Regression~\\cite{Rasmussen:2005}, learns the regressor to each dimension of the output domain (the parameters of a linear classifier) separately, {\\latinabbrev{i.e}},  a set of functions $c^i(\\cdot) : \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R} $. Clearly this will not capture the correlation between the visual classifier dimensions. Instead, a structured prediction regressor would be more suitable since it would learn the correlation between the input and output domain. However, even a structured prediction model, will only learn the correlation between the textual and visual domain through the information available in the input-output pairs  $(\\mathbf{t}_j,\\mathbf{c}_j)$.  Here the visual domain information is encapsulated in the pre-learned classifiers and prediction does not have access to the original data in the visual domain. Instead we need to directly learn the correlation between the visual and textual domain and use that for prediction.\n\nAnother fundamental problem  that a regressor would face, is the sparsity of the data; the data points are the textual description-classifier pairs, and typically the number of classes can be very small compared to the dimension of the classifier space ({\\latinabbrev{i.e}} $N_{sc} \\ll d_v$). In a setting like that, any regression model is bound to suffer from an under fitting problem. This can be best explained in terms of GP regression, where the predictive variance increases in the regions of the input space where there are no data points. This will result in  poor prediction of classifiers at these regions. \n\n\\subsection{Knowledge Transfer Models}\nAn alternative formulation is to pose the problem as domain adaptation from the textual to the visual domain. In the computer vision context, domain adaptation work has focused on transferring categories learned from a source domain,  with a given distribution of images, to a target domain with different distribution, {\\latinabbrev{e.g}}, images or videos from different sources~\\cite{yang07,saenko10,da11,duan12}. \nWhat we need is an approach that learns the correlation between the textual domain features and the visual domain features, and uses that correlation to predict new visual classifier given textual features. \n\nIn particular, in~\\cite{da11} an approach for learning cross domain transformation was introduced. In that work a regularized asymmetric transformation between points in two domains were learned. The approach was applied to transfer learned categories between different data distributions, both in the visual domain. A particular attractive characteristic of~\\cite{da11}, over other domain adaptation models, is that the source and target domains do not have to share the same feature spaces or the same dimensionality. \n\nWhile a totally different setting is studied in ~\\cite{da11}, it inspired us to formulate the zero-shot learning problem as a domain transfer problem. This can be achieved by learning a linear transfer function $\\mathbf{W}$ between $\\mathcal{T}$ and $\\mathcal{V}$.  The transformation matrix $\\mathbf{W}$ can be learned  by optimizing, with a suitable regularizer, over constraints of the form $\\mathbf{t}^\\textsf{T}\\mathbf{W}\\mathbf{x} \\geq l $ if $\\mathbf{t} \\in \\mathcal{T}$  and $\\mathbf{x}\\in \\mathcal{V}$  belong to the same class, and $\\mathbf{t}^\\textsf{T}\\mathbf{W}\\mathbf{x} \\leq u $  otherwise. Here $l$ and $u$ are model parameters. This transfer function acts as a compatibility function between the textual features and visual features, which gives high values if they are from the same class and a low value if they are from different classes. \n\n\n\nIt is not hard to see that this transfer function can act as a classifier. Given a textual feature $\\mathbf{t}^*$ and a test image, represented by $\\mathbf{x}$, a classification decision can be obtained by $\\mathbf{t}_*^\\textsf{T}\\mathbf{W}\\mathbf{x} \\gtrless b$ where $b$ is a decision boundary which can be set to $(l+u)/2$. Hence, our desired predicted classifier in Eq~\\ref{E:PredictedClass} can be obtained as $c(\\mathbf{t}_*) = \\mathbf{t}_*^\\textsf{T}\\mathbf{W} $ (note that the features vectors are amended with ones).  However, since learning  $\\mathbf{W}$ was done over seen classes only, it is not clear how the predicted classifier $c(\\mathbf{t}_*)$ will behave for unseen classes. There is no guarantee that such a classifier will put all the seen data on one side and the new unseen class on the other side of that hyperplane. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Formulations for Predicting a linear   classifier form of ${\\Phi (t_*)}$}\n\\label{formulation}\n\nThe proposed formulations in this section aims at predicting a linear hyperplane parameter $\\mathbf{c}$ of a one-vs-all classifier for a new unseen class given a textual description, encoded as a feature vector $\\mathbf{t_*}$ and the knowledge learned at the training phase from seen classes\\footnote{The notations follow from Subsection~\\ref{sec_lin_pdef}}. We start by  defining the learning components that were used by the formulations described in this section:\n\n\\begin{description}\n\\item [Classifiers:]$\\,\\,\\,\\,\\,\\,\\,\\,$ \n\na set of linear one-vs-all classifiers $\\{\\mathbf{c}_j\\}$ are learned, one for each seen class.\n\\item [Probabilistic Regressor:] $\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,$\n\nGiven $\\{(\\mathbf{t}_j,\\mathbf{c}_j)\\}$ a regressor is learned that can be used to give a prior estimate for $p_{reg}(\\mathbf{c} | \\mathbf{t})$ (Details in Sec~\\ref{S:Reg}).\n\\item [Domain Transfer:]$\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,$ \n\nGiven $T$ and $V$ a domain transfer function, encoded in the matrix $\\mathbf{W}$ is learned, which captures the correlation between the textual and visual domains (Details in Sec~\\ref{S:DA}).\n\\end{description} \n  \n  \n  \nEach of the following subsections show a different approach to predict a linear classifier from $t_*$ as $\\Phi(t_*) = \\mathbf{c}(\\textbf{t}_*)$; see Sec~\\ref{sec_lin_pdef}. The final approach (E) combines  regression, domain transfer, and additional constraints, which achieves the best performance. We compare between these alternative formulations in our experiments. Hyper-parameter selection is detailed in the supplementary materials for all the approaches. \n\n\\begin{figure*}[t]\n\\centering\n\\includegraphics[width=1.0\\linewidth,height=.38\\linewidth]{fig_NLP4.pdf}\n\\vspace{-10pt}\n\\caption{Illustration of the Proposed Linear Prediction Framework (Constrained Regression and Domain Transfer) for the task Zero-shot learning from textual description (Linear Formulation (E))}\n\\label{F:prob_sol}\n\\vspace{-12pt}\n\\end{figure*}\n\n\\subsection{Probabilistic Regressor}\n\\label{S:Reg}\nThere are different regressors that can be used, however we need a regressor that provide a probabilistic estimate $p_{reg}(\\mathbf{c} | \\mathbf(t))$. For the reasons explained in Sec~\\ref{obvformulation}, we also need a structure prediction approach that is able to predict all the dimensions of the classifiers together. For these reasons, we use the Twin Gaussian Process (TGP)~\\cite{Bo:2010}. \nTGP encodes the relations between both the inputs and structured outputs using Gaussian Process priors. This is achieved by minimizing the Kullback-Leibler divergence between the marginal GP of the outputs (i.e. classifiers in our case) and observations (i.e. textual features). The estimated regressor output ($\\tilde{c}(\\mathbf{t}_*)$) in TGP is given by the solution of the following non-linear optimization problem~\\cite{Bo:2010} \\footnote{notice we are using $\\mathbf{\\tilde{c}}$ to denote the output of the regressor, while using $\\mathbf{\\hat{c}}$ to denote the output of the final optimization problem in Eq~\\ref{eq:form}}.\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere ${x} \\in \\mathcal{V}$ is the test image, ${x}_i$ is the $i^{th}$ image in the training data $V$,  $\\textbf{k}({x})= [k({x}, {x}_1), \\cdots, k({x}, {x}_N), 1]^\\textsf{T},$  $\\boldsymbol{\\beta}_j = [\\beta_j^1 \\cdots \\beta_j^N, b]^\\textsf{T} $. Having learned $f_j({x}^*)$ for each class $j$ (for example using SVM classifier), the class label of the test image ${x}$ can be predicted by  Eq.~\\ref{eq:mclass}, similar to the linear case. Eq.~\\ref{eq_fkernel} also shows how $\\boldsymbol{\\beta}_j$ is related to $\\mathbf{c}_j$ in the linear classifier, where $k(x, x')= \\varphi(x)^\\mathsf{T} \\cdot \\varphi(x')$ and $\\varphi(\\cdot)$ is a feature map  that does not have to be defined given $k(\\cdot, \\cdot)$ on $\\cal{V}$. Hence, our goal in the kernel classifier prediction  is to predict $\\boldsymbol{\\beta}(t_*)$ instead of $\\mathbf{c}(t_*)$ since it is sufficient to define  ${f}_{t_*}(x)$ for a text description $t_*$ of an unseen class given $\\mathbf{k}(x)$\n\n\n\n\n\n\n\n\n\\ignore{Under our setting, i}It is clear that $f_j({x})$ could be learned for  all classes with training data $j \\in  {1} \\cdots {N_{sc}}$, since there are examples for the seen classes; we denote the kernel-classifier parameters of the seen classes as $\\mathcal{B}_{sc} =  \\{  \\boldsymbol{\\beta}_j \\}_{N_{sc}}, \\forall j$. However, it is not obvious how to predict $f_{{t}_*}({x})$ for an unseen class given its text description ${t}_*$. Similar to the linear classifier prediction, our main notion is to use the text description ${t}_{*}$, associated with unseen class, and the training data to directly predict the unseen kernel-classifier parameters. In other words, the kernel classifier parameters of the unseen class is a function of  its text description ${t}_*$ , the image training data $V$ and the text training data $\\{t_j\\}, j\\in 1 \\cdots N_{sc}$; {\\latinabbrev{i.e}} \\small\n", "index": 7, "text": "\n\\[   f_{{t}_*}({x}) = \\boldsymbol{\\beta}({t}_*)^\\textsf{T} \\cdot \\textbf{k}({x}), \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"f_{{t}_{*}}({x})=\\boldsymbol{\\beta}({t}_{*})^{\\textsf{T}}\\cdot\\textbf{k}({x}),\" display=\"block\"><mrow><mrow><mrow><msub><mi>f</mi><msub><mi>t</mi><mo>*</mo></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mi>\ud835\udf37</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mtext>\ud835\uddb3</mtext></msup></mrow><mo>\u22c5</mo><mtext>\ud835\udc24</mtext></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nwhere $\\mathbf{u} = (\\mathbf{K}_\\textsf{T} + \\lambda_t  \\mathbf{I})^{-1} k_t(\\mathbf{t}_*)$, $\\eta  = K_T(\\mathbf{t}_*,\\mathbf{t}_*) -k(\\mathbf{t}_*)^\\textsf{T}  \\mathbf{u} $,  $K_T(\\mathbf{t}_l,\\mathbf{t}_m) $ and $K_C(\\mathbf{c}_l,\\mathbf{c}_m)$ are Gaussian kernel for input feature $\\mathbf{t}$ and output vector $\\mathbf{c}$.  $k_c(\\mathbf{c}) = [K_C(\\mathbf{c},\\mathbf{c}_1), \\cdots, K_C($ $\\mathbf{c},\\mathbf{c}_{N_{sc}})]^\\textsf{T}$. $k_t(\\mathbf{t}_*) = [K_T(\\mathbf{t}_*,\\mathbf{t}_1), \\cdots, K_T(\\mathbf{t}_*,\\mathbf{t}_{N_{sc})}]^\\textsf{T}$.  $\\lambda_t$ and $\\lambda_c$ are regularization parameters to avoid overfitting. This optimization problem can be solved using a second order, BFGS quasi-Newton optimizer with cubic polynomial line search for optimal step size selection~\\cite{Bo:2010}. In this case the classifier dimension are predicted jointly. In this case $p_{reg}(\\mathbf{c}|\\mathbf{t}_*)$ is defined as a normal distribution.\n\n", "itemtype": "equation", "pos": 34937, "prevtext": " \\normalsize\n $ f_{{t}_*}({x})$ could be used to classify new points that\t belong to an  unseen class as follows: 1) one-vs-all setting  $f_{{t}_*}({x})  \\gtrless  0$  \\ignore{if ${x}^*\\,$  belongs to unseen category $z^*$, $\\boldsymbol{\\beta}(\\mathbf{t}_*),)^\\textsf{T} \\cdot \\textbf{k}(x^*)< 0$  otherwise}; or 2) in a Multi-class prediction as in Eq~\\ref{eq:mclass}. ${\\Phi}(t_*)$ in this case is $\\boldsymbol{\\beta}({t}_{*})$. In contrast to linear classifier prediction, there is no need to explicitly represent an image $x$ or a text description $t$ by features, which are denoted by the bold symbols in the previous section. Rather, only the  $k(\\cdot,\\cdot)$  and $g(\\cdot,\\cdot)$ needs to be defined which is general. \n\n\n\n\\section{Relation to Regression and Knowledge Transfer Models}\n\\label{sec_reganKT}\nWe introduce two possible frameworks for this problem and discuss potential limitations for them. In this background section,  we focus on predicting linear classifiers for simplicity, which motivates the the evaluated linear classifier formulations that follow in Sec~\\ref{formulation}. \n\n\\subsection{Regression Models}\nA straightforward way to solve this problem is to pose it as a regression problem where the goal is to use the textual data and the learned classifiers, $\\{(\\mathbf{t}_j,\\mathbf{c}_j) \\}_{j=1\\cdots N_{sc}}$ to learn a regression function from the textual feature domain to the visual classifier domain, {\\latinabbrev{i.e}}, a function $c(\\cdot) : \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R}^{d_v} $.  The question is which regression model would be suitable for this problem? and would posing the problem this way give reasonable results?\n\nA typical regression model, such as ridge regression~\\cite{ridgeReg70} or Gaussian Process (GP) Regression~\\cite{Rasmussen:2005}, learns the regressor to each dimension of the output domain (the parameters of a linear classifier) separately, {\\latinabbrev{i.e}},  a set of functions $c^i(\\cdot) : \\mathbb{R}^{d_t} \\rightarrow \\mathbb{R} $. Clearly this will not capture the correlation between the visual classifier dimensions. Instead, a structured prediction regressor would be more suitable since it would learn the correlation between the input and output domain. However, even a structured prediction model, will only learn the correlation between the textual and visual domain through the information available in the input-output pairs  $(\\mathbf{t}_j,\\mathbf{c}_j)$.  Here the visual domain information is encapsulated in the pre-learned classifiers and prediction does not have access to the original data in the visual domain. Instead we need to directly learn the correlation between the visual and textual domain and use that for prediction.\n\nAnother fundamental problem  that a regressor would face, is the sparsity of the data; the data points are the textual description-classifier pairs, and typically the number of classes can be very small compared to the dimension of the classifier space ({\\latinabbrev{i.e}} $N_{sc} \\ll d_v$). In a setting like that, any regression model is bound to suffer from an under fitting problem. This can be best explained in terms of GP regression, where the predictive variance increases in the regions of the input space where there are no data points. This will result in  poor prediction of classifiers at these regions. \n\n\\subsection{Knowledge Transfer Models}\nAn alternative formulation is to pose the problem as domain adaptation from the textual to the visual domain. In the computer vision context, domain adaptation work has focused on transferring categories learned from a source domain,  with a given distribution of images, to a target domain with different distribution, {\\latinabbrev{e.g}}, images or videos from different sources~\\cite{yang07,saenko10,da11,duan12}. \nWhat we need is an approach that learns the correlation between the textual domain features and the visual domain features, and uses that correlation to predict new visual classifier given textual features. \n\nIn particular, in~\\cite{da11} an approach for learning cross domain transformation was introduced. In that work a regularized asymmetric transformation between points in two domains were learned. The approach was applied to transfer learned categories between different data distributions, both in the visual domain. A particular attractive characteristic of~\\cite{da11}, over other domain adaptation models, is that the source and target domains do not have to share the same feature spaces or the same dimensionality. \n\nWhile a totally different setting is studied in ~\\cite{da11}, it inspired us to formulate the zero-shot learning problem as a domain transfer problem. This can be achieved by learning a linear transfer function $\\mathbf{W}$ between $\\mathcal{T}$ and $\\mathcal{V}$.  The transformation matrix $\\mathbf{W}$ can be learned  by optimizing, with a suitable regularizer, over constraints of the form $\\mathbf{t}^\\textsf{T}\\mathbf{W}\\mathbf{x} \\geq l $ if $\\mathbf{t} \\in \\mathcal{T}$  and $\\mathbf{x}\\in \\mathcal{V}$  belong to the same class, and $\\mathbf{t}^\\textsf{T}\\mathbf{W}\\mathbf{x} \\leq u $  otherwise. Here $l$ and $u$ are model parameters. This transfer function acts as a compatibility function between the textual features and visual features, which gives high values if they are from the same class and a low value if they are from different classes. \n\n\n\nIt is not hard to see that this transfer function can act as a classifier. Given a textual feature $\\mathbf{t}^*$ and a test image, represented by $\\mathbf{x}$, a classification decision can be obtained by $\\mathbf{t}_*^\\textsf{T}\\mathbf{W}\\mathbf{x} \\gtrless b$ where $b$ is a decision boundary which can be set to $(l+u)/2$. Hence, our desired predicted classifier in Eq~\\ref{E:PredictedClass} can be obtained as $c(\\mathbf{t}_*) = \\mathbf{t}_*^\\textsf{T}\\mathbf{W} $ (note that the features vectors are amended with ones).  However, since learning  $\\mathbf{W}$ was done over seen classes only, it is not clear how the predicted classifier $c(\\mathbf{t}_*)$ will behave for unseen classes. There is no guarantee that such a classifier will put all the seen data on one side and the new unseen class on the other side of that hyperplane. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Formulations for Predicting a linear   classifier form of ${\\Phi (t_*)}$}\n\\label{formulation}\n\nThe proposed formulations in this section aims at predicting a linear hyperplane parameter $\\mathbf{c}$ of a one-vs-all classifier for a new unseen class given a textual description, encoded as a feature vector $\\mathbf{t_*}$ and the knowledge learned at the training phase from seen classes\\footnote{The notations follow from Subsection~\\ref{sec_lin_pdef}}. We start by  defining the learning components that were used by the formulations described in this section:\n\n\\begin{description}\n\\item [Classifiers:]$\\,\\,\\,\\,\\,\\,\\,\\,$ \n\na set of linear one-vs-all classifiers $\\{\\mathbf{c}_j\\}$ are learned, one for each seen class.\n\\item [Probabilistic Regressor:] $\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,$\n\nGiven $\\{(\\mathbf{t}_j,\\mathbf{c}_j)\\}$ a regressor is learned that can be used to give a prior estimate for $p_{reg}(\\mathbf{c} | \\mathbf{t})$ (Details in Sec~\\ref{S:Reg}).\n\\item [Domain Transfer:]$\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,$ \n\nGiven $T$ and $V$ a domain transfer function, encoded in the matrix $\\mathbf{W}$ is learned, which captures the correlation between the textual and visual domains (Details in Sec~\\ref{S:DA}).\n\\end{description} \n  \n  \n  \nEach of the following subsections show a different approach to predict a linear classifier from $t_*$ as $\\Phi(t_*) = \\mathbf{c}(\\textbf{t}_*)$; see Sec~\\ref{sec_lin_pdef}. The final approach (E) combines  regression, domain transfer, and additional constraints, which achieves the best performance. We compare between these alternative formulations in our experiments. Hyper-parameter selection is detailed in the supplementary materials for all the approaches. \n\n\\begin{figure*}[t]\n\\centering\n\\includegraphics[width=1.0\\linewidth,height=.38\\linewidth]{fig_NLP4.pdf}\n\\vspace{-10pt}\n\\caption{Illustration of the Proposed Linear Prediction Framework (Constrained Regression and Domain Transfer) for the task Zero-shot learning from textual description (Linear Formulation (E))}\n\\label{F:prob_sol}\n\\vspace{-12pt}\n\\end{figure*}\n\n\\subsection{Probabilistic Regressor}\n\\label{S:Reg}\nThere are different regressors that can be used, however we need a regressor that provide a probabilistic estimate $p_{reg}(\\mathbf{c} | \\mathbf(t))$. For the reasons explained in Sec~\\ref{obvformulation}, we also need a structure prediction approach that is able to predict all the dimensions of the classifiers together. For these reasons, we use the Twin Gaussian Process (TGP)~\\cite{Bo:2010}. \nTGP encodes the relations between both the inputs and structured outputs using Gaussian Process priors. This is achieved by minimizing the Kullback-Leibler divergence between the marginal GP of the outputs (i.e. classifiers in our case) and observations (i.e. textual features). The estimated regressor output ($\\tilde{c}(\\mathbf{t}_*)$) in TGP is given by the solution of the following non-linear optimization problem~\\cite{Bo:2010} \\footnote{notice we are using $\\mathbf{\\tilde{c}}$ to denote the output of the regressor, while using $\\mathbf{\\hat{c}}$ to denote the output of the final optimization problem in Eq~\\ref{eq:form}}.\n\n", "index": 9, "text": "\\begin{equation}                                               \n\\centering\n\\begin{split}\n{\\Phi (t_*)} = \\tilde{c}(\\mathbf{t}_*) = & \\underset{\\mathbf{c}}{\\operatorname{argmin}}[  K_C(\\mathbf{c},\\mathbf{c})  -2 k_c(\\mathbf{c})^\\textsf{T} \\mathbf{u} - \\eta  \\log ( \\\\ & K_C(\\mathbf{c},\\mathbf{c} -k_c(\\mathbf{c})^\\textsf{T} (\\mathbf{K}_C+ \\lambda_c \\mathbf{I})^{-1} k_c(c) ) ]\n\\end{split}\n\\label{eq:tgp}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\centering\\begin{split}\\displaystyle{\\Phi(t_{*})}=\\tilde{c}(\\mathbf{t}_{*})=&amp;%&#10;\\displaystyle\\underset{\\mathbf{c}}{\\operatorname{argmin}}[K_{C}(\\mathbf{c},%&#10;\\mathbf{c})-2k_{c}(\\mathbf{c})^{\\textsf{T}}\\mathbf{u}-\\eta\\log(\\\\&#10;&amp;\\displaystyle K_{C}(\\mathbf{c},\\mathbf{c}-k_{c}(\\mathbf{c})^{\\textsf{T}}(%&#10;\\mathbf{K}_{C}+\\lambda_{c}\\mathbf{I})^{-1}k_{c}(c))]\\end{split}\\@add@centering\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><munder accentunder=\"true\"><mo>argmin</mo><mo>\ud835\udc1c</mo></munder><mrow><mo stretchy=\"false\">[</mo><msub><mi>K</mi><mi>C</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo>,</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mn>2</mn><msub><mi>k</mi><mi>c</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">)</mo></mrow><mtext>\ud835\uddb3</mtext></msup><mi>\ud835\udc2e</mi><mo>-</mo><mi>\u03b7</mi><mi>log</mi><mo stretchy=\"false\">(</mo></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><msub><mi>K</mi><mi>C</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo>,</mo><mi>\ud835\udc1c</mi><mo>-</mo><msub><mi>k</mi><mi>c</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">)</mo></mrow><mtext>\ud835\uddb3</mtext></msup><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc0a</mi><mi>C</mi></msub><mo>+</mo><msub><mi>\u03bb</mi><mi>c</mi></msub><mi>\ud835\udc08</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><msub><mi>k</mi><mi>c</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nThe reason that $\\Sigma_c = \\mathbf{I}$ is that TGP does not provide predictive variance, unlike Gaussian Process Regression. However, it has the advantage of handling the dependency between the dimensions of the classifiers $\\mathbf{c}$ given the textual features $\\mathbf{t}$. \n \n\\subsection{Constrained Probabilistic Regressor}\n\\label{S:Reg_con}\nWe also investigated formulations that use regression to predict an initial hyperplane  $\\tilde{c}(\\mathbf{t}_*)$ as described in section ~\\ref{S:Reg}, which is then optimized to put all seen data in one side, {\\latinabbrev{i.e}}\n\n", "itemtype": "equation", "pos": 36310, "prevtext": "\nwhere $\\mathbf{u} = (\\mathbf{K}_\\textsf{T} + \\lambda_t  \\mathbf{I})^{-1} k_t(\\mathbf{t}_*)$, $\\eta  = K_T(\\mathbf{t}_*,\\mathbf{t}_*) -k(\\mathbf{t}_*)^\\textsf{T}  \\mathbf{u} $,  $K_T(\\mathbf{t}_l,\\mathbf{t}_m) $ and $K_C(\\mathbf{c}_l,\\mathbf{c}_m)$ are Gaussian kernel for input feature $\\mathbf{t}$ and output vector $\\mathbf{c}$.  $k_c(\\mathbf{c}) = [K_C(\\mathbf{c},\\mathbf{c}_1), \\cdots, K_C($ $\\mathbf{c},\\mathbf{c}_{N_{sc}})]^\\textsf{T}$. $k_t(\\mathbf{t}_*) = [K_T(\\mathbf{t}_*,\\mathbf{t}_1), \\cdots, K_T(\\mathbf{t}_*,\\mathbf{t}_{N_{sc})}]^\\textsf{T}$.  $\\lambda_t$ and $\\lambda_c$ are regularization parameters to avoid overfitting. This optimization problem can be solved using a second order, BFGS quasi-Newton optimizer with cubic polynomial line search for optimal step size selection~\\cite{Bo:2010}. In this case the classifier dimension are predicted jointly. In this case $p_{reg}(\\mathbf{c}|\\mathbf{t}_*)$ is defined as a normal distribution.\n\n", "index": 11, "text": "\\begin{equation}\n\\label{eq:ptgp}\np_{reg}(\\mathbf{c}|\\mathbf{t}_*) =  \\mathcal{N} (\\mu_c = \\tilde{c}(\\mathbf{t}_*),\\Sigma_c = \\mathbf{I})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"p_{reg}(\\mathbf{c}|\\mathbf{t}_{*})=\\mathcal{N}(\\mu_{c}=\\tilde{c}(\\mathbf{t}_{*%&#10;}),\\Sigma_{c}=\\mathbf{I})\" display=\"block\"><mrow><msub><mi>p</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>g</mi></mrow></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bc</mi><mi>c</mi></msub><mo>=</mo><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>c</mi></msub><mo>=</mo><mi>\ud835\udc08</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\nwhere $\\psi(\\cdot,\\cdot)$ is a similarity function between hyperplanes, {\\latinabbrev{e.g}} a dot product used in this work,  $\\alpha$ is its constant weight, and $C$ is the weight to the soft constraints of existing images as negative examples (inspired by linear SVM formulation)\\ignore{, or other functions incorporating the predictive variance}. We call this class of methods {\\em constrained GPR/TGP}, since $\\tilde{c}(\\mathbf{t}_*)$ is initially predicted through GPR or TGP. \n \n\n\n\\subsection{Domain Transfer (DT)}\n\\label{S:DA}\nTo learn the domain transfer function $\\mathbf{W}$ we adapted the approach in~\\cite{da11} as follows. Let $\\mathbf{T}$ be the textual feature data matrix and $\\mathbf{X}$ be the visual feature data matrix where each feature vector is amended with a 1. Notice that amending the feature vectors with a 1 is essential in our formulation since we need $\\mathbf{t}^\\textsf{T} \\mathbf{W}$ to act as a classifier. We need to solve the following optimization problem \n\n", "itemtype": "equation", "pos": 37041, "prevtext": "\nThe reason that $\\Sigma_c = \\mathbf{I}$ is that TGP does not provide predictive variance, unlike Gaussian Process Regression. However, it has the advantage of handling the dependency between the dimensions of the classifiers $\\mathbf{c}$ given the textual features $\\mathbf{t}$. \n \n\\subsection{Constrained Probabilistic Regressor}\n\\label{S:Reg_con}\nWe also investigated formulations that use regression to predict an initial hyperplane  $\\tilde{c}(\\mathbf{t}_*)$ as described in section ~\\ref{S:Reg}, which is then optimized to put all seen data in one side, {\\latinabbrev{i.e}}\n\n", "index": 13, "text": "\\begin{equation*}\n\\begin{split}\n {\\Phi (t_*)} = \\small \\hat{c}(\\mathbf{t}_*) =   \\underset{\\mathbf{c},\\zeta_i}{\\operatorname{argmin }}[  \\mathbf{c}^\\textsf{T} \\mathbf{c}  + \\alpha \\, \\psi( \\mathbf{c},\\tilde{c}(\\mathbf{t}_*)) + C   \\sum_{i=1}^N{\\zeta_i} ] \\\\ \\; s.t.:  -\\mathbf{c}^\\textsf{T} {\\mathbf{x}}_{i}  \\geq \\zeta_i , \\; \\zeta_i \\geq 0 , i=1,\\cdots,N \n\\end{split}\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle{\\Phi(t_{*})}=\\small\\hat{c}(\\mathbf{t}_{*})=%&#10;\\underset{\\mathbf{c},\\zeta_{i}}{\\operatorname{argmin}}[\\mathbf{c}^{\\textsf{T}}%&#10;\\mathbf{c}+\\alpha\\,\\psi(\\mathbf{c},\\tilde{c}(\\mathbf{t}_{*}))+C\\sum_{i=1}^{N}{%&#10;\\zeta_{i}}]\\\\&#10;\\displaystyle\\;s.t.:-\\mathbf{c}^{\\textsf{T}}{\\mathbf{x}}_{i}\\geq\\zeta_{i},\\;%&#10;\\zeta_{i}\\geq 0,i=1,\\cdots,N\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi mathsize=\"90%\">c</mi><mo mathsize=\"90%\" stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">\ud835\udc2d</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><munder accentunder=\"true\"><mo mathsize=\"90%\" stretchy=\"false\">argmin</mo><mrow><mi mathsize=\"90%\">\ud835\udc1c</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><msub><mi mathsize=\"90%\">\u03b6</mi><mi mathsize=\"90%\">i</mi></msub></mrow></munder><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">[</mo><mrow><mrow><msup><mi mathsize=\"90%\">\ud835\udc1c</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc1c</mi></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><mpadded width=\"+1.7pt\"><mi mathsize=\"90%\">\u03b1</mi></mpadded><mo>\u2062</mo><mi mathsize=\"90%\">\u03c8</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc1c</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mrow><mover accent=\"true\"><mi mathsize=\"90%\">c</mi><mo mathsize=\"90%\" stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">\ud835\udc2d</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><mi mathsize=\"90%\">C</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">N</mi></munderover><msub><mi mathsize=\"90%\">\u03b6</mi><mi mathsize=\"90%\">i</mi></msub></mrow></mrow></mrow><mo maxsize=\"90%\" minsize=\"90%\">]</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mpadded lspace=\"2.8pt\" width=\"+2.8pt\"><mi>s</mi></mpadded><mo>.</mo><mi>t</mi><mo>.</mo><mo>:</mo><mo>-</mo><msup><mi>\ud835\udc1c</mi><mtext>\ud835\uddb3</mtext></msup><msub><mi>\ud835\udc31</mi><mi>i</mi></msub><mo>\u2265</mo><msub><mi>\u03b6</mi><mi>i</mi></msub><mo rspace=\"5.3pt\">,</mo><msub><mi>\u03b6</mi><mi>i</mi></msub><mo>\u2265</mo><mn>0</mn><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>,</mo><mi>N</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\nwhere $c_i$'s are loss functions over the constraints and $r(\\cdot)$ is a matrix regularizer.  It was shown in~\\cite{da11}, under condition on the regularizer, that the optimal $\\mathbf{W}$  is in the form of \n $ \\mathbf{W}^* = \\mathbf{T} \\mathbf{K}_{T}^{-\\frac{1}{2}} \\mathbf{L}^*  \\mathbf{K}_{X}^{-\\frac{1}{2}} \\mathbf{X}^\\textsf{T}$, where  $\\mathbf{K}_{T}  = \\mathbf{T} \\mathbf{T}^\\textsf{T}$,  $\\mathbf{K}_{X}  = \\mathbf{X} \\mathbf{X}^\\textsf{T}$.   $\\mathbf{L}^*$ is computed by minimizing the following minimization problem\n\n", "itemtype": "equation", "pos": 38422, "prevtext": "\n\nwhere $\\psi(\\cdot,\\cdot)$ is a similarity function between hyperplanes, {\\latinabbrev{e.g}} a dot product used in this work,  $\\alpha$ is its constant weight, and $C$ is the weight to the soft constraints of existing images as negative examples (inspired by linear SVM formulation)\\ignore{, or other functions incorporating the predictive variance}. We call this class of methods {\\em constrained GPR/TGP}, since $\\tilde{c}(\\mathbf{t}_*)$ is initially predicted through GPR or TGP. \n \n\n\n\\subsection{Domain Transfer (DT)}\n\\label{S:DA}\nTo learn the domain transfer function $\\mathbf{W}$ we adapted the approach in~\\cite{da11} as follows. Let $\\mathbf{T}$ be the textual feature data matrix and $\\mathbf{X}$ be the visual feature data matrix where each feature vector is amended with a 1. Notice that amending the feature vectors with a 1 is essential in our formulation since we need $\\mathbf{t}^\\textsf{T} \\mathbf{W}$ to act as a classifier. We need to solve the following optimization problem \n\n", "index": 15, "text": "\\begin{equation}\n  \\min_{\\mathbf{W}}  r(\\mathbf{W}) + \\lambda \\sum_i c_i(\\mathbf{T} \\mathbf{W} \\mathbf{X}^\\textsf{T})\n  \\label{Eq:DA1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\min_{\\mathbf{W}}r(\\mathbf{W})+\\lambda\\sum_{i}c_{i}(\\mathbf{T}\\mathbf{W}%&#10;\\mathbf{X}^{\\textsf{T}})\" display=\"block\"><mrow><mrow><mrow><munder><mi>min</mi><mi>\ud835\udc16</mi></munder><mo>\u2061</mo><mi>r</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc16</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc13\ud835\udc16\ud835\udc17</mi><mtext>\ud835\uddb3</mtext></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nwhere $c_p(\\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2}  ) = (max(0, (l-e_i \\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2} e_j) ))^2$ for same class pairs of index $i$,$j$, or $ =(max(0, (e_i \\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2} e_j -u) ))^ 2$ otherwise, where $e_k$ is a one-hot vector of zeros except a one at the $k^{th}$ element, and $u>l$ (note any appropriate $l$, $u$ could work. In our case, we used $l =2$, $u=-2$ ). We used a Frobenius norm regularizer.  This energy is minimized using a second order BFGS quasi-Newton optimizer. Once $L$ is computed $\\textbf{W}^*$ is computed using the transformation above. Finally ${\\Phi (t_*)}  = c(\\mathbf{t}_*) = \\mathbf{t}_*^\\textsf{T}\\mathbf{W}$, simplifying  $\\textbf{W}^*$ as $\\textbf{W}$.  \n\n\n\n\n\\subsection{Constrained-DT}\nWe also investigated constrained-DT formulations that learns a transfer matrix $\\mathbf{W}$ and  enforce $\\mathbf{t}_j^\\textsf{T}\\mathbf{W}$ to be close to the classifiers learned on seen data, $\\{\\mathbf{c}_j \\}$ ,{\\latinabbrev{i.e}}\n", "itemtype": "equation", "pos": 39104, "prevtext": "\n\nwhere $c_i$'s are loss functions over the constraints and $r(\\cdot)$ is a matrix regularizer.  It was shown in~\\cite{da11}, under condition on the regularizer, that the optimal $\\mathbf{W}$  is in the form of \n $ \\mathbf{W}^* = \\mathbf{T} \\mathbf{K}_{T}^{-\\frac{1}{2}} \\mathbf{L}^*  \\mathbf{K}_{X}^{-\\frac{1}{2}} \\mathbf{X}^\\textsf{T}$, where  $\\mathbf{K}_{T}  = \\mathbf{T} \\mathbf{T}^\\textsf{T}$,  $\\mathbf{K}_{X}  = \\mathbf{X} \\mathbf{X}^\\textsf{T}$.   $\\mathbf{L}^*$ is computed by minimizing the following minimization problem\n\n", "index": 17, "text": "\\begin{equation}\n \\underset{\\mathbf{L}}{\\operatorname{min       }}[   r(\\mathbf{L})+ \\lambda \\sum_p c_p(\\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2}  ) ],\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\underset{\\mathbf{L}}{\\operatorname{min}}[r(\\mathbf{L})+\\lambda\\sum_{p}c_{p}(%&#10;\\mathbf{K}_{T}^{\\frac{1}{2}}\\mathbf{L}\\mathbf{K}_{X}^{\\frac{1}{2}})],\" display=\"block\"><mrow><mrow><munder accentunder=\"true\"><mo>min</mo><mo>\ud835\udc0b</mo></munder><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0b</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>p</mi></munder><mrow><msub><mi>c</mi><mi>p</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\ud835\udc0a</mi><mi>T</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msubsup><mo>\u2062</mo><msubsup><mi>\ud835\udc0b\ud835\udc0a</mi><mi>X</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nA classifier can be then obtained by ${\\Phi (t_*)}  =c(\\mathbf{t}_*)= \\mathbf{t}_*^\\textsf{T}\\mathbf{W}$.\n\n\n\n\n\\subsection{Constrained  Regression and Domain Transfer for classifier prediction}\n Fig~\\ref{F:prob_sol} illustrates our final  framework which combines regression (formulation A (using TGP)) and domain transfer (formulation C) with additional constraints. This formulation combines the three learning components described in the beginning of this section. \n\n\n\n\n\n\nEach of these components contains partial knowledge about the problem. The question is how to combine such knowledge to predict a new classifier given a textual description. The new classifier has to be consistent with the seen classes. \nThe new classifier has to put all the seen instances at one side of the hyperplane, and has to be consistent with the learned domain transfer function. This leads to the following constrained  optimization problem \n\n", "itemtype": "equation", "pos": 40380, "prevtext": "\nwhere $c_p(\\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2}  ) = (max(0, (l-e_i \\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2} e_j) ))^2$ for same class pairs of index $i$,$j$, or $ =(max(0, (e_i \\mathbf{K}_{T}^{\\frac{1}{2}} \\mathbf{L} \\mathbf{K}_{X}^\\frac{1}{2} e_j -u) ))^ 2$ otherwise, where $e_k$ is a one-hot vector of zeros except a one at the $k^{th}$ element, and $u>l$ (note any appropriate $l$, $u$ could work. In our case, we used $l =2$, $u=-2$ ). We used a Frobenius norm regularizer.  This energy is minimized using a second order BFGS quasi-Newton optimizer. Once $L$ is computed $\\textbf{W}^*$ is computed using the transformation above. Finally ${\\Phi (t_*)}  = c(\\mathbf{t}_*) = \\mathbf{t}_*^\\textsf{T}\\mathbf{W}$, simplifying  $\\textbf{W}^*$ as $\\textbf{W}$.  \n\n\n\n\n\\subsection{Constrained-DT}\nWe also investigated constrained-DT formulations that learns a transfer matrix $\\mathbf{W}$ and  enforce $\\mathbf{t}_j^\\textsf{T}\\mathbf{W}$ to be close to the classifiers learned on seen data, $\\{\\mathbf{c}_j \\}$ ,{\\latinabbrev{i.e}}\n", "index": 19, "text": "\n\\[\\small \\min_{\\mathbf{W}}  r(\\mathbf{W}) + \\lambda_1 \\sum_i c_i(\\mathbf{T} \\mathbf{W} \\mathbf{X}^\\textsf{T}) +\\lambda_2 \\sum_k{(\\mathbf{c}_j - \\mathbf{t}^\\textsf{T}_j \\mathbf{W})^T (\\mathbf{c}_j - \\mathbf{t}^\\textsf{T}_j \\mathbf{W})}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\small\\min_{\\mathbf{W}}r(\\mathbf{W})+\\lambda_{1}\\sum_{i}c_{i}(\\mathbf{T}%&#10;\\mathbf{W}\\mathbf{X}^{\\textsf{T}})+\\lambda_{2}\\sum_{k}{(\\mathbf{c}_{j}-\\mathbf%&#10;{t}^{\\textsf{T}}_{j}\\mathbf{W})^{T}(\\mathbf{c}_{j}-\\mathbf{t}^{\\textsf{T}}_{j}%&#10;\\mathbf{W})}\" display=\"block\"><mrow><mrow><mrow><munder><mi mathsize=\"90%\">min</mi><mi mathsize=\"90%\">\ud835\udc16</mi></munder><mo>\u2061</mo><mi mathsize=\"90%\">r</mi></mrow><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc16</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><msub><mi mathsize=\"90%\">\u03bb</mi><mn mathsize=\"90%\">1</mn></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mi mathsize=\"90%\">i</mi></munder><mrow><msub><mi mathsize=\"90%\">c</mi><mi mathsize=\"90%\">i</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msup><mi mathsize=\"90%\">\ud835\udc13\ud835\udc16\ud835\udc17</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><msub><mi mathsize=\"90%\">\u03bb</mi><mn mathsize=\"90%\">2</mn></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mi mathsize=\"90%\">k</mi></munder><mrow><msup><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mrow><msub><mi mathsize=\"90%\">\ud835\udc1c</mi><mi mathsize=\"90%\">j</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mrow><msubsup><mi mathsize=\"90%\">\ud835\udc2d</mi><mi mathsize=\"90%\">j</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msubsup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc16</mi></mrow></mrow><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow><mi mathsize=\"90%\">T</mi></msup><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mrow><msub><mi mathsize=\"90%\">\ud835\udc1c</mi><mi mathsize=\"90%\">j</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mrow><msubsup><mi mathsize=\"90%\">\ud835\udc2d</mi><mi mathsize=\"90%\">j</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msubsup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc16</mi></mrow></mrow><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nThe first term is a regularizer over the classifier $\\mathbf{c}$.  The second term enforces that the predicted classifier has high correlation with $\\mathbf{t}_*^\\textsf{T} \\mathbf{W}$; $\\mathbf{W}$ is learnt by Eq~\\ref{Eq:DA1}. The third term favors a classifier that has high probability given the prediction of the regressor. The constraints $ -\\mathbf{c}^\\textsf{T} {\\mathbf{x}}_{i} \\geq \\zeta_i $  enforce all the seen data instances to be at the negative side of the predicted classifier hyperplane with some missclassification allowed through the  slack variables $ \\zeta_i$. The constraint $ {\\mathbf{t}_*}^\\textsf{T} \\mathbf{W} \\mathbf{c} \\geq l$ enforces that the correlation between the predicted classifier and ${\\mathbf{t}_*}^\\textsf{T} \\mathbf{W}$ is no less than $l$, this is to enforce a minimum correlation between the text and visual features. \n\n\n\n\n\n\n\n\n\n\n\\textbf{Solving for $\\hat{c}$ as a quadratic program: }\nAccording to  the definition of $p_{reg}(\\mathbf{c}|\\mathbf{t}_*)$ for  TGP,  $\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ is a quadratic term in $c$ in the form  \n\n", "itemtype": "equation", "pos": 41546, "prevtext": "\nA classifier can be then obtained by ${\\Phi (t_*)}  =c(\\mathbf{t}_*)= \\mathbf{t}_*^\\textsf{T}\\mathbf{W}$.\n\n\n\n\n\\subsection{Constrained  Regression and Domain Transfer for classifier prediction}\n Fig~\\ref{F:prob_sol} illustrates our final  framework which combines regression (formulation A (using TGP)) and domain transfer (formulation C) with additional constraints. This formulation combines the three learning components described in the beginning of this section. \n\n\n\n\n\n\nEach of these components contains partial knowledge about the problem. The question is how to combine such knowledge to predict a new classifier given a textual description. The new classifier has to be consistent with the seen classes. \nThe new classifier has to put all the seen instances at one side of the hyperplane, and has to be consistent with the learned domain transfer function. This leads to the following constrained  optimization problem \n\n", "index": 21, "text": "\\begin{equation}\n\\begin{split}\n {\\Phi (t_*)} = \\hat{c}(\\mathbf{t}_*) =  &   \\underset{\\mathbf{c},\\zeta_i}{\\operatorname{argmin }}\\big[    \\mathbf{c}^\\textsf{T} \\mathbf{c} - \\alpha {\\mathbf{t}_*}^\\textsf{T} \\mathbf{W} \\mathbf{c}  - \\gamma  \\ln( p_{reg}(\\mathbf{c}|\\mathbf{t}_*))  \\\\\n& + C   \\sum{\\zeta_i} \\big]\\\\\n&s.t.:  -(\\mathbf{c}^\\textsf{T} {\\mathbf{x}}_{i} ) \\geq \\zeta_i ,  \\,\\, \\zeta_i \\geq 0 ,\\; \\; i = 1 \\cdots N \\\\\n&\t   \\,\\, {\\mathbf{t}_*}^\\textsf{T} \\mathbf{W} \\mathbf{c} \\geq l     \\\\\n& \\alpha , \\gamma, C, l \\,  \\text{: hyperparameters}\\\\ \n\\end{split}\n\\label{eq:form}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle{\\Phi(t_{*})}=\\hat{c}(\\mathbf{t}_{*})=&amp;\\displaystyle%&#10;\\underset{\\mathbf{c},\\zeta_{i}}{\\operatorname{argmin}}\\big{[}\\mathbf{c}^{%&#10;\\textsf{T}}\\mathbf{c}-\\alpha{\\mathbf{t}_{*}}^{\\textsf{T}}\\mathbf{W}\\mathbf{c}-%&#10;\\gamma\\ln(p_{reg}(\\mathbf{c}|\\mathbf{t}_{*}))\\\\&#10;&amp;\\displaystyle+C\\sum{\\zeta_{i}}\\big{]}\\\\&#10;&amp;\\displaystyle s.t.:-(\\mathbf{c}^{\\textsf{T}}{\\mathbf{x}}_{i})\\geq\\zeta_{i},\\,%&#10;\\,\\zeta_{i}\\geq 0,\\;\\;i=1\\cdots N\\\\&#10;&amp;\\displaystyle\\,\\,{\\mathbf{t}_{*}}^{\\textsf{T}}\\mathbf{W}\\mathbf{c}\\geq l\\\\&#10;&amp;\\displaystyle\\alpha,\\gamma,C,l\\,\\text{: hyperparameters}\\\\&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><munder accentunder=\"true\"><mo>argmin</mo><mrow><mi>\ud835\udc1c</mi><mo>,</mo><msub><mi>\u03b6</mi><mi>i</mi></msub></mrow></munder><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mi>\ud835\udc1c</mi><mtext>\ud835\uddb3</mtext></msup><mi>\ud835\udc1c</mi><mo>-</mo><mi>\u03b1</mi><mmultiscripts><mi>\ud835\udc2d</mi><mo>*</mo><none/><none/><mtext>\ud835\uddb3</mtext></mmultiscripts><mi>\ud835\udc16\ud835\udc1c</mi><mo>-</mo><mi>\u03b3</mi><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>p</mi><mrow><mi>r</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>g</mi></mrow></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mo>+</mo><mi>C</mi><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msub><mi>\u03b6</mi><mi>i</mi></msub><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mo>:</mo><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc1c</mi><mtext>\ud835\uddb3</mtext></msup><msub><mi>\ud835\udc31</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2265</mo><msub><mi>\u03b6</mi><mi>i</mi></msub><mo rspace=\"5.9pt\">,</mo><msub><mi>\u03b6</mi><mi>i</mi></msub><mo>\u2265</mo><mn>0</mn><mo rspace=\"8.1pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mi mathvariant=\"normal\">\u22ef</mi><mi>N</mi></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mmultiscripts><mpadded lspace=\"3.4pt\" width=\"+3.4pt\"><mi>\ud835\udc2d</mi></mpadded><mo>*</mo><none/><none/><mtext>\ud835\uddb3</mtext></mmultiscripts><mo>\u2062</mo><mi>\ud835\udc16\ud835\udc1c</mi></mrow><mo>\u2265</mo><mi>l</mi></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi>\u03b1</mi><mo>,</mo><mi>\u03b3</mi><mo>,</mo><mi>C</mi><mo>,</mo><mrow><mpadded width=\"+1.7pt\"><mi>l</mi></mpadded><mo>\u2062</mo><mtext>: hyperparameters</mtext></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nWe reduce $-\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ to $-2 \\mathbf{c}^\\textsf{T} \\tilde{c}(\\mathbf{t}_*))$, since 1) $\\tilde{c}(\\mathbf{t}_*)^\\textsf{T} \\tilde{c}(\\mathbf{t}_*)$ is a constant ({\\latinabbrev{i.e}} does not affect the optimization), 2) $\\mathbf{c}^\\textsf{T} \\mathbf{c}$ is already included as regularizer in equation ~\\ref{eq:form}.  In our setting, the dot product  is a better similarity measure between two hyperplanes. Hence,  $-2 \\mathbf{c}^\\textsf{T} \\tilde{c}(\\mathbf{t}_*)$ is minimized.\nGiven $-\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ from the TGP and  $\\mathbf{W}$, Eq~\\ref{eq:form} reduces to a quadratic program on $\\mathbf{c}$ with linear constraints. We tried different quadratic solvers, however the IBM CPLEX solver \\footnote{http://www-01.ibm.com/software/integration/optimization/cplex-optimizer} gives the best performance in speed and optimization for our problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\label{sec:app}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrediction of ${\\Phi (t_*)}  = \\boldsymbol{\\beta}(t_*)$ (Sec.~\\ref{sec_kernel_pdef}), is decomposed into training (domain transfer) and prediction phases, detailed as follows\n\\subsection{Kernelized Domain Transfer}\n\\label{ss:tr}\nDuring training, we firstly learn $\\mathcal{B}_{sc} = \\{ \\boldsymbol{\\beta}_j \\}, j=1\\to N_sc$ as SVM-kernel classifiers based on  the training data and defined by $k(\\cdot, \\cdot)$ visual kernel\\ignore{, see Sec~\\ref{sec:pdef}}. Then, we learn a kernel domain transfer function to transfer the text description information ${t_*} \\in \\mathcal{T}$ to kernel-classifier parameters $\\boldsymbol{\\beta} \\in \\mathbb{R}^{N+1}$ in $\\mathcal{V}$ domain. We call this domain transfer function $\\boldsymbol{\\beta}_{DA}(t_*)$, which has the form as ${\\mathbf{\\Psi}}^\\textsf{T} {\\textbf{g}(t_*)}$, where $\\textbf{g}(t_*)  = [g({t_*}, {t}_1) \\cdots g({t_*}, {t}_{N_{sc}})]^\\textsf{T}$\\ignore{, $g({t}, {t}')\\,$\\normalsize is a kernel function that measures the similarity between ${t}$ and ${t}'$ on  domain $\\mathcal{E}$}; $\\mathbf{\\Psi}$ is an $N_{sc}  \\times {N+1}$ matrix, which transforms ${t}$ to  kernel classifier parameters for the class that ${t_*}$ represents.  \n\n\n\n\\ignore{Inspired by the domain transfer proposed by~\\cite{da11}, w}We aim to learn  $\\mathbf{\\Psi}$ from $V$ and $\\{t_j\\}, j=1 \\cdots N_{sc}$, such that $\\textbf{g}(t)^\\textsf{T} \\mathbf{\\Psi} \\textbf{k}(x) > l$ if ${t}$ and  $x\\,$ correspond to the same class, $\\textbf{g}(t)^\\textsf{T} {\\mathbf{\\Psi}} \\textbf{k}(x) < u\\,$ otherwise. Here $l\\,$ controls similarity lower-bound if $t$ and $x$ correspond to  same class, and $u$ controls similarity upper-bound if $t$ and $x$ belong to different classes. In our setting, the term   ${\\mathbf{\\Psi}}^\\textsf{T} {\\textbf{g}(t_j)}$ should act as a classifier parameter for class $j$ in the training data. Therefore,  we introduce  penalization constraints to our minimization function  if  ${\\mathbf{\\Psi}}^\\textsf{T}\\,{\\textbf{g}(t_j)}$ is distant from $\\boldsymbol{\\beta}_j \\in \\mathcal{B}_{sc}$, where ${t}_i$ corresponds to the class that $\\boldsymbol{\\beta}_i$ classifies.\\ignore{Hence,  in order to learn \\small${\\textbf{T}}\\,$\\normalsize, we solve the following objective function  Inspired by domain adaptation \\footnote{A totally different problem/setting but the optimization methods inspired our solution} optimization methods ({\\latinabbrev{e.g}} \\cite{da11}),  we model our solution using the following objective functionInspired by domain adaptation optimization methods ({\\latinabbrev{e.g}} \\cite{da11}) }\\ignore{ \\footnote{A totally different problem/setting but the optimization methods inspired our solution},  in order to learn ${\\textbf{T}}$,,} we model the kernel domain transfer function as follows \\ignore{by the following objective function}\n\\small\n\n", "itemtype": "equation", "pos": 43222, "prevtext": "\nThe first term is a regularizer over the classifier $\\mathbf{c}$.  The second term enforces that the predicted classifier has high correlation with $\\mathbf{t}_*^\\textsf{T} \\mathbf{W}$; $\\mathbf{W}$ is learnt by Eq~\\ref{Eq:DA1}. The third term favors a classifier that has high probability given the prediction of the regressor. The constraints $ -\\mathbf{c}^\\textsf{T} {\\mathbf{x}}_{i} \\geq \\zeta_i $  enforce all the seen data instances to be at the negative side of the predicted classifier hyperplane with some missclassification allowed through the  slack variables $ \\zeta_i$. The constraint $ {\\mathbf{t}_*}^\\textsf{T} \\mathbf{W} \\mathbf{c} \\geq l$ enforces that the correlation between the predicted classifier and ${\\mathbf{t}_*}^\\textsf{T} \\mathbf{W}$ is no less than $l$, this is to enforce a minimum correlation between the text and visual features. \n\n\n\n\n\n\n\n\n\n\n\\textbf{Solving for $\\hat{c}$ as a quadratic program: }\nAccording to  the definition of $p_{reg}(\\mathbf{c}|\\mathbf{t}_*)$ for  TGP,  $\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ is a quadratic term in $c$ in the form  \n\n", "index": 23, "text": "\\begin{equation}\n\\begin{split}\n-\\ln p(\\mathbf{c}|\\mathbf{t}_*) \\propto ( \\mathbf{c} - \\tilde{c}(\\mathbf{t}_*))^\\textsf{T} (\\mathbf{c} - \\tilde{c}(\\mathbf{t}_*)) \\\\= \\mathbf{c}^\\textsf{T} \\mathbf{c} -2 \\mathbf{c}^\\textsf{T} \\tilde{c}(\\mathbf{t}_*) +  \\tilde{c}(\\mathbf{t}_*)^\\textsf{T} \\tilde{c}(\\mathbf{t}_*) \n\\end{split}\n\\label{eq:lnptgp}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle-\\ln p(\\mathbf{c}|\\mathbf{t}_{*})\\propto(\\mathbf{c}-%&#10;\\tilde{c}(\\mathbf{t}_{*}))^{\\textsf{T}}(\\mathbf{c}-\\tilde{c}(\\mathbf{t}_{*}))%&#10;\\\\&#10;\\displaystyle=\\mathbf{c}^{\\textsf{T}}\\mathbf{c}-2\\mathbf{c}^{\\textsf{T}}\\tilde%&#10;{c}(\\mathbf{t}_{*})+\\tilde{c}(\\mathbf{t}_{*})^{\\textsf{T}}\\tilde{c}(\\mathbf{t}%&#10;_{*})\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mo>-</mo><mi>ln</mi><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo>-</mo><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mtext>\ud835\uddb3</mtext></msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1c</mi><mo>-</mo><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><msup><mi>\ud835\udc1c</mi><mtext>\ud835\uddb3</mtext></msup><mo>\u2062</mo><mi>\ud835\udc1c</mi></mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\ud835\udc1c</mi><mtext>\ud835\uddb3</mtext></msup><mo>\u2062</mo><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow><mtext>\ud835\uddb3</mtext></msup><mo>\u2062</mo><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2d</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\\normalsize\n where, \n\\small$\\mathbf{G}\\,\\,$\\normalsize is an \\small$N_{sc} \\times N_{sc}\\,$\\normalsize symmetric matrix, such that both the \\small$i^{th}\\,$\\normalsize   row and the \\small$i^{th}\\,$\\normalsize column are equal to \\small$\\textbf{g}(t_i)$\\normalsize, \\small$i=1: N_{sc}$\\normalsize; \\small$\\mathbf{K}\\,\\,$\\normalsize  is an \\small$N+1 \\times N\\,$\\normalsize matrix, such that the \\small$i^{th}\\,$\\normalsize column is equal to \\small$\\textbf{k}(x_i)$\\normalsize, \\small$x_i, i=1:N$\\normalsize.\n\\small$c_k$\\normalsize's are loss functions over the constraints defined as\n  \\small$c_k(\\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K})) = (max(0, (l-\\textbf{1}_i^\\textsf{T} \\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K} \\textbf{1}_j) ))^2\\,$\\normalsize for same class pairs of index \\small$i\\,$\\normalsize and \\small$j$\\normalsize,  or \\small$ =r\\cdot(max(0, (\\textbf{1}_i^\\textsf{T} \\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K} \\textbf{1}_j -u) ))^ 2\\,$\\normalsize otherwise, where \\small$\\textbf{1}_i\\,$\\normalsize is an \\small$N_{sc} \\times 1\\,$\\normalsize vector with all zeros except at index \\small$i$\\normalsize, \\small$\\textbf{1}_j\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector with all zeros except at index \\small$j$\\normalsize. This leads to that   \\small$ c_k(\\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K})) = (max(0, (l-\\textbf{g}(t_i)^\\textsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) ))^2\\,$\\normalsize for same class pairs of index \\small$i\\,$\\normalsize and \\small$j$\\normalsize, or \\small$ =r\\cdot(max(0, (\\textbf{g}(t_i)^\\textsf{T}\\, {\\mathbf{\\Psi}}\\,\\textbf{k}(x_j) -u) ))^ 2$\\normalsize otherwise, where \\small$u>l$\\normalsize\\ignore{ (note any appropriate $l$, $u$ could work in our case we used $l =2$, $u=-2$ )}, \\small$r = \\frac{nd}{ns}\\,$\\normalsize such that \\small$nd\\,$\\normalsize and \\small$ns\\,$\\normalsize are the number of pairs \\small$(i,j)\\,$\\normalsize of different classes and similar pairs respectively. \\ignore{ \\small$r(\\cdot)\\,$\\normalsize is a matrix regularizer;} Finally, we used a Frobenius norm regularizer for \\small$r({\\mathbf{\\Psi}})$\\normalsize. \n\n\nThe objective function in Eq ~\\ref{Eq:DA1}  controls the involvement of the constraints \\small$c_k\\,$\\normalsize by the term multiplied by \\small$\\lambda_1$\\normalsize, which controls its importance; we call it \\small$C_{l,u}({\\mathbf{\\Psi}})$\\normalsize. While, the trained classifiers penalty is captured by the term multiplied by \\small$\\lambda_2$\\normalsize; we call it \\small$C_{\\beta}({\\mathbf{\\Psi}})$\\normalsize. One important observation on  \\small$C_{\\beta}({\\mathbf{\\Psi}})$\\normalsize, is that it reaches zero when \\small${\\mathbf{\\Psi}} = \\mathbf{G}^{-1} \\textbf{B}^\\mathsf{T}$\\normalsize, where \\small$\\textbf{B}  = [\\boldsymbol{\\beta}_1 \\cdots \\boldsymbol{\\beta}_{N_{sc}}]$\\normalsize, since it could be rewritten as \\small$C_{\\beta}({\\mathbf{\\Psi}}) = \\|\\textbf{B}^\\mathsf{T} - \\mathbf{G} \\, {\\mathbf{\\Psi}}  \\|_{F}^2$\\normalsize.\\ignore{ Our intuition is that for the model to have good generalization, the effect of \\small$C_{\\beta}({\\textbf{T}})\\,$\\normalsize should be  minimal ({\\latinabbrev{i.e}} \\small$\\lambda_2 \\to 0$\\normalsize), since this case indicates successful modeling of the transfer from \\small$\\mathcal{E}\\,$\\normalsize domain to the kernel-classifier parameters in \\small$\\mathcal{X}\\,$ domain. }\n\\ignore{\nIn contrast to the linear-classifier restricted approach proposed by Elhoseiny et al    \\cite{Hoseini13}, our domain transfer model can transfer any type of classifier of an arbitrary kernel from $\\mathcal{T}$ to $\\mathcal{V}$. Furthermore, the classifier penalty term was not studied in \\cite{Hoseini13}, which is captured here by $C_{\\beta}({\\textbf{T}})$.}\n\nWe minimize \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize is by gradient-based optimization using a \\ignore{second order BFGS }quasi-Newton optimizer. Our  gradient derivation of \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize leads to the following form\n\\small\n\n", "itemtype": "equation", "pos": 47349, "prevtext": "\nWe reduce $-\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ to $-2 \\mathbf{c}^\\textsf{T} \\tilde{c}(\\mathbf{t}_*))$, since 1) $\\tilde{c}(\\mathbf{t}_*)^\\textsf{T} \\tilde{c}(\\mathbf{t}_*)$ is a constant ({\\latinabbrev{i.e}} does not affect the optimization), 2) $\\mathbf{c}^\\textsf{T} \\mathbf{c}$ is already included as regularizer in equation ~\\ref{eq:form}.  In our setting, the dot product  is a better similarity measure between two hyperplanes. Hence,  $-2 \\mathbf{c}^\\textsf{T} \\tilde{c}(\\mathbf{t}_*)$ is minimized.\nGiven $-\\ln p(\\mathbf{c}|\\mathbf{t}_*)$ from the TGP and  $\\mathbf{W}$, Eq~\\ref{eq:form} reduces to a quadratic program on $\\mathbf{c}$ with linear constraints. We tried different quadratic solvers, however the IBM CPLEX solver \\footnote{http://www-01.ibm.com/software/integration/optimization/cplex-optimizer} gives the best performance in speed and optimization for our problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\label{sec:app}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrediction of ${\\Phi (t_*)}  = \\boldsymbol{\\beta}(t_*)$ (Sec.~\\ref{sec_kernel_pdef}), is decomposed into training (domain transfer) and prediction phases, detailed as follows\n\\subsection{Kernelized Domain Transfer}\n\\label{ss:tr}\nDuring training, we firstly learn $\\mathcal{B}_{sc} = \\{ \\boldsymbol{\\beta}_j \\}, j=1\\to N_sc$ as SVM-kernel classifiers based on  the training data and defined by $k(\\cdot, \\cdot)$ visual kernel\\ignore{, see Sec~\\ref{sec:pdef}}. Then, we learn a kernel domain transfer function to transfer the text description information ${t_*} \\in \\mathcal{T}$ to kernel-classifier parameters $\\boldsymbol{\\beta} \\in \\mathbb{R}^{N+1}$ in $\\mathcal{V}$ domain. We call this domain transfer function $\\boldsymbol{\\beta}_{DA}(t_*)$, which has the form as ${\\mathbf{\\Psi}}^\\textsf{T} {\\textbf{g}(t_*)}$, where $\\textbf{g}(t_*)  = [g({t_*}, {t}_1) \\cdots g({t_*}, {t}_{N_{sc}})]^\\textsf{T}$\\ignore{, $g({t}, {t}')\\,$\\normalsize is a kernel function that measures the similarity between ${t}$ and ${t}'$ on  domain $\\mathcal{E}$}; $\\mathbf{\\Psi}$ is an $N_{sc}  \\times {N+1}$ matrix, which transforms ${t}$ to  kernel classifier parameters for the class that ${t_*}$ represents.  \n\n\n\n\\ignore{Inspired by the domain transfer proposed by~\\cite{da11}, w}We aim to learn  $\\mathbf{\\Psi}$ from $V$ and $\\{t_j\\}, j=1 \\cdots N_{sc}$, such that $\\textbf{g}(t)^\\textsf{T} \\mathbf{\\Psi} \\textbf{k}(x) > l$ if ${t}$ and  $x\\,$ correspond to the same class, $\\textbf{g}(t)^\\textsf{T} {\\mathbf{\\Psi}} \\textbf{k}(x) < u\\,$ otherwise. Here $l\\,$ controls similarity lower-bound if $t$ and $x$ correspond to  same class, and $u$ controls similarity upper-bound if $t$ and $x$ belong to different classes. In our setting, the term   ${\\mathbf{\\Psi}}^\\textsf{T} {\\textbf{g}(t_j)}$ should act as a classifier parameter for class $j$ in the training data. Therefore,  we introduce  penalization constraints to our minimization function  if  ${\\mathbf{\\Psi}}^\\textsf{T}\\,{\\textbf{g}(t_j)}$ is distant from $\\boldsymbol{\\beta}_j \\in \\mathcal{B}_{sc}$, where ${t}_i$ corresponds to the class that $\\boldsymbol{\\beta}_i$ classifies.\\ignore{Hence,  in order to learn \\small${\\textbf{T}}\\,$\\normalsize, we solve the following objective function  Inspired by domain adaptation \\footnote{A totally different problem/setting but the optimization methods inspired our solution} optimization methods ({\\latinabbrev{e.g}} \\cite{da11}),  we model our solution using the following objective functionInspired by domain adaptation optimization methods ({\\latinabbrev{e.g}} \\cite{da11}) }\\ignore{ \\footnote{A totally different problem/setting but the optimization methods inspired our solution},  in order to learn ${\\textbf{T}}$,,} we model the kernel domain transfer function as follows \\ignore{by the following objective function}\n\\small\n\n", "index": 25, "text": "\\begin{equation}\n\\begin{split}\n{\\mathbf{\\Psi}^*}= \n \\arg \\min_{{\\mathbf{\\Psi}}}  L({\\mathbf{\\Psi}}) = [&\\frac{1}{2} r({\\mathbf{\\Psi}}) + \\lambda_1 \\sum_k c_k(\\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K}) + \\\\ & \\lambda_2 \\sum_{i=1}^{N_{sc}}{\\|\\boldsymbol{ \\beta}_i - {\\mathbf{\\Psi}}^\\textsf{T}\\,{\\textbf{g}(t_i)}\\|^2} \n  \\end{split}\n  \\label{Eq:DA1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle{\\mathbf{\\Psi}^{*}}=\\arg\\min_{{\\mathbf{\\Psi}}}L({%&#10;\\mathbf{\\Psi}})=[&amp;\\displaystyle\\frac{1}{2}r({\\mathbf{\\Psi}})+\\lambda_{1}\\sum_{%&#10;k}c_{k}(\\mathbf{G}\\,{\\mathbf{\\Psi}}\\,\\mathbf{K})+\\\\&#10;&amp;\\displaystyle\\lambda_{2}\\sum_{i=1}^{N_{sc}}{\\|\\boldsymbol{\\beta}_{i}-{\\mathbf%&#10;{\\Psi}}^{\\textsf{T}}\\,{\\textbf{g}(t_{i})}\\|^{2}}\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><msup><mi>\ud835\udebf</mi><mo>*</mo></msup><mo>=</mo><mi>arg</mi><munder><mi>min</mi><mi>\ud835\udebf</mi></munder><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udebf</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mo stretchy=\"false\">[</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udebf</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>k</mi></munder><mrow><msub><mi>c</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mpadded width=\"+1.7pt\"><mi>\ud835\udc06</mi></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>\ud835\udebf</mi></mpadded><mo>\u2062</mo><mi>\ud835\udc0a</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><msub><mi>\u03bb</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mrow><mi>s</mi><mo>\u2062</mo><mi>c</mi></mrow></msub></munderover><msup><mrow><mo>\u2225</mo><mrow><msub><mi>\ud835\udf37</mi><mi>i</mi></msub><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><msup><mi>\ud835\udebf</mi><mtext>\ud835\uddb3</mtext></msup></mpadded><mo>\u2062</mo><mtext>\ud835\udc20</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2225</mo></mrow><mn>2</mn></msup></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\\normalsize\nwhere \\small$v_{ij} = - 2 \\cdot max(0, (l-\\textbf{g}(t_i)^\\mathsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) )\\,$\\normalsize if \\small$i\\,$\\normalsize and \\small$j\\,$\\normalsize correspond to the same class, \\small$2 \\cdot max(0, (\\textbf{g}(t_i)^\\mathsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) -u )\\,$\\normalsize otherwise. Another approach that can be used to minimize \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize is through alternating projection using Bregman algorithm \\cite{bregman97}, where \\small${\\mathbf{\\Psi}}\\,$\\normalsize is updated by a single constraint every iteration.\n\n\n\n\\subsection{Kernel Classifier Prediction}\nWe study two ways to infer the final kernel-classifier prediction. (1) Direct Kernel Domain Transfer Prediction, denoted by ``DT-kernel'', (2) One-class SVM adjusted DT Prediction, denoted by ``SVM-DT kernel''. Hyper-parameter selection is attached in the supplementary materials. The source code is available here \n\\footnotesize{\\url{https://sites.google.com/site/mhelhoseiny/computer-vision-projects/write_kernel_classifier}}.\\normalsize  \n\n\\medskip\n\\noindent \\textbf{Direct Domain Transfer (DT) Prediction:} By construction a classifier of an unseen class can be directly computed from our trained domain transfer model as follows\n\\small\n\n", "itemtype": "equation", "pos": 51666, "prevtext": "\n\\normalsize\n where, \n\\small$\\mathbf{G}\\,\\,$\\normalsize is an \\small$N_{sc} \\times N_{sc}\\,$\\normalsize symmetric matrix, such that both the \\small$i^{th}\\,$\\normalsize   row and the \\small$i^{th}\\,$\\normalsize column are equal to \\small$\\textbf{g}(t_i)$\\normalsize, \\small$i=1: N_{sc}$\\normalsize; \\small$\\mathbf{K}\\,\\,$\\normalsize  is an \\small$N+1 \\times N\\,$\\normalsize matrix, such that the \\small$i^{th}\\,$\\normalsize column is equal to \\small$\\textbf{k}(x_i)$\\normalsize, \\small$x_i, i=1:N$\\normalsize.\n\\small$c_k$\\normalsize's are loss functions over the constraints defined as\n  \\small$c_k(\\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K})) = (max(0, (l-\\textbf{1}_i^\\textsf{T} \\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K} \\textbf{1}_j) ))^2\\,$\\normalsize for same class pairs of index \\small$i\\,$\\normalsize and \\small$j$\\normalsize,  or \\small$ =r\\cdot(max(0, (\\textbf{1}_i^\\textsf{T} \\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K} \\textbf{1}_j -u) ))^ 2\\,$\\normalsize otherwise, where \\small$\\textbf{1}_i\\,$\\normalsize is an \\small$N_{sc} \\times 1\\,$\\normalsize vector with all zeros except at index \\small$i$\\normalsize, \\small$\\textbf{1}_j\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector with all zeros except at index \\small$j$\\normalsize. This leads to that   \\small$ c_k(\\mathbf{G}\\, {\\mathbf{\\Psi}}\\, \\mathbf{K})) = (max(0, (l-\\textbf{g}(t_i)^\\textsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) ))^2\\,$\\normalsize for same class pairs of index \\small$i\\,$\\normalsize and \\small$j$\\normalsize, or \\small$ =r\\cdot(max(0, (\\textbf{g}(t_i)^\\textsf{T}\\, {\\mathbf{\\Psi}}\\,\\textbf{k}(x_j) -u) ))^ 2$\\normalsize otherwise, where \\small$u>l$\\normalsize\\ignore{ (note any appropriate $l$, $u$ could work in our case we used $l =2$, $u=-2$ )}, \\small$r = \\frac{nd}{ns}\\,$\\normalsize such that \\small$nd\\,$\\normalsize and \\small$ns\\,$\\normalsize are the number of pairs \\small$(i,j)\\,$\\normalsize of different classes and similar pairs respectively. \\ignore{ \\small$r(\\cdot)\\,$\\normalsize is a matrix regularizer;} Finally, we used a Frobenius norm regularizer for \\small$r({\\mathbf{\\Psi}})$\\normalsize. \n\n\nThe objective function in Eq ~\\ref{Eq:DA1}  controls the involvement of the constraints \\small$c_k\\,$\\normalsize by the term multiplied by \\small$\\lambda_1$\\normalsize, which controls its importance; we call it \\small$C_{l,u}({\\mathbf{\\Psi}})$\\normalsize. While, the trained classifiers penalty is captured by the term multiplied by \\small$\\lambda_2$\\normalsize; we call it \\small$C_{\\beta}({\\mathbf{\\Psi}})$\\normalsize. One important observation on  \\small$C_{\\beta}({\\mathbf{\\Psi}})$\\normalsize, is that it reaches zero when \\small${\\mathbf{\\Psi}} = \\mathbf{G}^{-1} \\textbf{B}^\\mathsf{T}$\\normalsize, where \\small$\\textbf{B}  = [\\boldsymbol{\\beta}_1 \\cdots \\boldsymbol{\\beta}_{N_{sc}}]$\\normalsize, since it could be rewritten as \\small$C_{\\beta}({\\mathbf{\\Psi}}) = \\|\\textbf{B}^\\mathsf{T} - \\mathbf{G} \\, {\\mathbf{\\Psi}}  \\|_{F}^2$\\normalsize.\\ignore{ Our intuition is that for the model to have good generalization, the effect of \\small$C_{\\beta}({\\textbf{T}})\\,$\\normalsize should be  minimal ({\\latinabbrev{i.e}} \\small$\\lambda_2 \\to 0$\\normalsize), since this case indicates successful modeling of the transfer from \\small$\\mathcal{E}\\,$\\normalsize domain to the kernel-classifier parameters in \\small$\\mathcal{X}\\,$ domain. }\n\\ignore{\nIn contrast to the linear-classifier restricted approach proposed by Elhoseiny et al    \\cite{Hoseini13}, our domain transfer model can transfer any type of classifier of an arbitrary kernel from $\\mathcal{T}$ to $\\mathcal{V}$. Furthermore, the classifier penalty term was not studied in \\cite{Hoseini13}, which is captured here by $C_{\\beta}({\\textbf{T}})$.}\n\nWe minimize \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize is by gradient-based optimization using a \\ignore{second order BFGS }quasi-Newton optimizer. Our  gradient derivation of \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize leads to the following form\n\\small\n\n", "index": 27, "text": "\\begin{equation}\n\n\\frac{\\delta L({\\mathbf{\\Psi}})}{\\delta \\, {\\mathbf{\\Psi}}} =  {\\mathbf{\\Psi}} + \\lambda_1 \\cdot  \\sum_{i,j} {\\mathbf{g}(t_i)}   {\\mathbf{k}(x_j)}^\\mathsf{T} v_{ij} +\nr \\cdot \\lambda_2 \\cdot ( \\mathbf{G}^2\\,\\, {\\mathbf{\\Psi}} - \\mathbf{G} \\textbf{B}) \n\n\\label{eq:grd}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\frac{\\delta L({\\mathbf{\\Psi}})}{\\delta\\,{\\mathbf{\\Psi}}}={\\mathbf{\\Psi}}%&#10;+\\lambda_{1}\\cdot\\sum_{i,j}{\\mathbf{g}(t_{i})}{\\mathbf{k}(x_{j})}^{\\mathsf{T}}%&#10;v_{ij}+r\\cdot\\lambda_{2}\\cdot(\\mathbf{G}^{2}\\,\\,{\\mathbf{\\Psi}}-\\mathbf{G}%&#10;\\textbf{B})\\par&#10;\" display=\"block\"><mrow><mfrac><mrow><mi>\u03b4</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udebf</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mpadded width=\"+1.7pt\"><mi>\u03b4</mi></mpadded><mo>\u2062</mo><mi>\ud835\udebf</mi></mrow></mfrac><mo>=</mo><mrow><mi>\ud835\udebf</mi><mo>+</mo><mrow><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>\u22c5</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mrow><mi>\ud835\udc20</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc24</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi>\ud835\uddb3</mi></msup><mo>\u2062</mo><msub><mi>v</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow></mrow><mo>+</mo><mrow><mi>r</mi><mo>\u22c5</mo><msub><mi>\u03bb</mi><mn>2</mn></msub><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mpadded width=\"+3.4pt\"><msup><mi>\ud835\udc06</mi><mn>2</mn></msup></mpadded><mo>\u2062</mo><mi>\ud835\udebf</mi></mrow><mo>-</mo><mrow><mi>\ud835\udc06</mi><mo>\u2062</mo><mtext>\ud835\udc01</mtext></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": " \n\\normalsize\n\\medskip\n\\noindent \\textbf{One-class-SVM adjusted DT (SVM-DT) Prediction:} \nIn order to increase separability against seen classes, we adopted the inverse of the idea of the one class kernel-svm, whose main idea is to build a confidence function that takes only positive examples of the  class. Our setting is the opposite scenario; seen examples are negative examples of the unseen class.\nIn order introduce our proposed adjustment method, we  start by presenting the one-class SVM objective function. The  Lagrangian dual  of the one-class SVM~\\cite{oneclasssvm07} can be written as\n\\small\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\\normalsize\nwhere \\small$v_{ij} = - 2 \\cdot max(0, (l-\\textbf{g}(t_i)^\\mathsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) )\\,$\\normalsize if \\small$i\\,$\\normalsize and \\small$j\\,$\\normalsize correspond to the same class, \\small$2 \\cdot max(0, (\\textbf{g}(t_i)^\\mathsf{T}\\, {\\mathbf{\\Psi}}\\, \\textbf{k}(x_j) -u )\\,$\\normalsize otherwise. Another approach that can be used to minimize \\small$L({\\mathbf{\\Psi}})\\,$\\normalsize is through alternating projection using Bregman algorithm \\cite{bregman97}, where \\small${\\mathbf{\\Psi}}\\,$\\normalsize is updated by a single constraint every iteration.\n\n\n\n\\subsection{Kernel Classifier Prediction}\nWe study two ways to infer the final kernel-classifier prediction. (1) Direct Kernel Domain Transfer Prediction, denoted by ``DT-kernel'', (2) One-class SVM adjusted DT Prediction, denoted by ``SVM-DT kernel''. Hyper-parameter selection is attached in the supplementary materials. The source code is available here \n\\footnotesize{\\url{https://sites.google.com/site/mhelhoseiny/computer-vision-projects/write_kernel_classifier}}.\\normalsize  \n\n\\medskip\n\\noindent \\textbf{Direct Domain Transfer (DT) Prediction:} By construction a classifier of an unseen class can be directly computed from our trained domain transfer model as follows\n\\small\n\n", "index": 29, "text": "\\begin{equation}\n\\centering\n\\begin{split}\n\\Phi(t_*) = \\tilde{\\boldsymbol{\\beta}}_{DT}(t_*) = {\\mathbf{\\Psi}^*}^\\textsf{T} \\, \\mathbf{g}(t_*)\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\centering\\begin{split}\\displaystyle\\Phi(t_{*})=\\tilde{\\boldsymbol{\\beta}}_{DT%&#10;}(t_{*})={\\mathbf{\\Psi}^{*}}^{\\textsf{T}}\\,\\mathbf{g}(t_{*})\\end{split}\\@add@centering\" display=\"block\"><mtable displaystyle=\"true\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udf37</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>D</mi><mo>\u2062</mo><mi>T</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mpadded width=\"+1.7pt\"><mmultiscripts><mi>\ud835\udebf</mi><none/><mo>*</mo><none/><mtext>\ud835\uddb3</mtext></mmultiscripts></mpadded><mo>\u2062</mo><mi>\ud835\udc20</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mo>*</mo></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\\normalsize\nwhere \\small$\\mathbf{K^{' }}\\,$\\normalsize is an \\small$N \\times N\\,$\\normalsize matrix, \\small$\\mathbf{K^{' }}(i,j) = k({x}_i, {x}_j)$\\normalsize, \\small$\\forall {x}_i,{x}_j \\in \\mathcal{S}_x$\\normalsize ({\\latinabbrev{i.e}} in the training data), \\small$\\textbf{a}\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector, \\small$\\textbf{a}_i = k({x}_i, {x}_i)$\\normalsize, \\small$C\\,$\\normalsize is a hyper-parameter . It is straightforward to see that, if $\\beta$ is aimed to be a negative decision function instead, the objective function becomes in the form\n\\small\n\n", "itemtype": "equation", "pos": 54014, "prevtext": " \n\\normalsize\n\\medskip\n\\noindent \\textbf{One-class-SVM adjusted DT (SVM-DT) Prediction:} \nIn order to increase separability against seen classes, we adopted the inverse of the idea of the one class kernel-svm, whose main idea is to build a confidence function that takes only positive examples of the  class. Our setting is the opposite scenario; seen examples are negative examples of the unseen class.\nIn order introduce our proposed adjustment method, we  start by presenting the one-class SVM objective function. The  Lagrangian dual  of the one-class SVM~\\cite{oneclasssvm07} can be written as\n\\small\n\n", "index": 31, "text": "\\begin{equation}\n\\label{eq:1class}\n\\small\n\\begin{split}\n{\\boldsymbol{\\beta}}^*_{+} =  &   \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin }}\\big[    \\boldsymbol{\\beta}^\\textsf{T} \\mathbf{K^{' }}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T \\mathbf{a} \\big]\\\\\n&s.t.: \\boldsymbol{\\beta}^T \\mathbf{1} = 1,  0 \\le \\boldsymbol{\\beta}_i \\le C; i = 1 \\cdots N   \\\\\n\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\small\\begin{split}\\displaystyle{\\boldsymbol{\\beta}}^{*}_{+}=&amp;\\displaystyle%&#10;\\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}}\\big{[}\\boldsymbol{\\beta}^%&#10;{\\textsf{T}}\\mathbf{K^{{}^{\\prime}}}\\boldsymbol{\\beta}-\\boldsymbol{\\beta}^{T}%&#10;\\mathbf{a}\\big{]}\\\\&#10;&amp;\\displaystyle s.t.:\\boldsymbol{\\beta}^{T}\\mathbf{1}=1,0\\leq\\boldsymbol{\\beta}%&#10;_{i}\\leq C;i=1\\cdots N\\\\&#10;\\par&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><msubsup><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msubsup><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><munder accentunder=\"true\"><mo mathsize=\"90%\" stretchy=\"false\">argmin</mo><mo mathsize=\"90%\" stretchy=\"false\">\ud835\udf37</mo></munder><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><msup><mi mathsize=\"90%\">\ud835\udc0a</mi><msup><mi/><mo mathsize=\"90%\" stretchy=\"false\">\u2032</mo></msup></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udf37</mi></mrow><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc1a</mi></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi mathsize=\"90%\">s</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mo mathsize=\"90%\" stretchy=\"false\">:</mo><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mn mathsize=\"90%\">\ud835\udfcf</mn><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mn mathsize=\"90%\">0</mn><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><msub><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">i</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><mi mathsize=\"90%\">C</mi><mo mathsize=\"90%\" stretchy=\"false\">;</mo><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn><mi mathsize=\"90%\" mathvariant=\"normal\">\u22ef</mi><mi mathsize=\"90%\">N</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\\normalsize\nWhile \\small${\\boldsymbol{\\beta}}^*_{-}  = - {\\boldsymbol{\\beta}}^*_{+}$\\normalsize, the objective function in Eq~\\ref{eq:1classneg} of the one-negative class SVM inspires us with the idea to adjust the kernel-classifier parameters to increase separability of the unseen kernel-classifier against the points of the seen classes, which leads to the following objective function \n\\small\n\n", "itemtype": "equation", "pos": 54984, "prevtext": "\n\\normalsize\nwhere \\small$\\mathbf{K^{' }}\\,$\\normalsize is an \\small$N \\times N\\,$\\normalsize matrix, \\small$\\mathbf{K^{' }}(i,j) = k({x}_i, {x}_j)$\\normalsize, \\small$\\forall {x}_i,{x}_j \\in \\mathcal{S}_x$\\normalsize ({\\latinabbrev{i.e}} in the training data), \\small$\\textbf{a}\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector, \\small$\\textbf{a}_i = k({x}_i, {x}_i)$\\normalsize, \\small$C\\,$\\normalsize is a hyper-parameter . It is straightforward to see that, if $\\beta$ is aimed to be a negative decision function instead, the objective function becomes in the form\n\\small\n\n", "index": 33, "text": "\\begin{equation}\n\\label{eq:1classneg}\n\\small\n\\begin{split}\n{\\boldsymbol{\\beta}}^*_{-} =  &   \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin }}\\big[    \\boldsymbol{\\beta}^\\textsf{T} \\mathbf{K^{' }}\\boldsymbol{\\beta} + \\boldsymbol{\\beta}^T \\mathbf{a} \\big]\\\\\n&s.t.: \\boldsymbol{\\beta}^T \\mathbf{1} = -1, -C \\le \\boldsymbol{\\beta}_i \\le 0; i = 1 \\cdots N \\\\\n\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\small\\begin{split}\\displaystyle{\\boldsymbol{\\beta}}^{*}_{-}=&amp;\\displaystyle%&#10;\\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}}\\big{[}\\boldsymbol{\\beta}^%&#10;{\\textsf{T}}\\mathbf{K^{{}^{\\prime}}}\\boldsymbol{\\beta}+\\boldsymbol{\\beta}^{T}%&#10;\\mathbf{a}\\big{]}\\\\&#10;&amp;\\displaystyle s.t.:\\boldsymbol{\\beta}^{T}\\mathbf{1}=-1,-C\\leq\\boldsymbol{%&#10;\\beta}_{i}\\leq 0;i=1\\cdots N\\\\&#10;\\par&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><msubsup><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msubsup><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><munder accentunder=\"true\"><mo mathsize=\"90%\" stretchy=\"false\">argmin</mo><mo mathsize=\"90%\" stretchy=\"false\">\ud835\udf37</mo></munder><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><msup><mi mathsize=\"90%\">\ud835\udc0a</mi><msup><mi/><mo mathsize=\"90%\" stretchy=\"false\">\u2032</mo></msup></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udf37</mi></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc1a</mi></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi mathsize=\"90%\">s</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mo mathsize=\"90%\" stretchy=\"false\">:</mo><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mn mathsize=\"90%\">\ud835\udfcf</mn><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mn mathsize=\"90%\">1</mn><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mi mathsize=\"90%\">C</mi><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><msub><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">i</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><mn mathsize=\"90%\">0</mn><mo mathsize=\"90%\" stretchy=\"false\">;</mo><mi mathsize=\"90%\">i</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn><mi mathsize=\"90%\" mathvariant=\"normal\">\u22ef</mi><mi mathsize=\"90%\">N</mi></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\n\\normalsize\nwhere  \\small$\\hat{\\boldsymbol{\\beta}}_{DT}\\,$\\normalsize is the first \\small$N\\,$\\normalsize elements in \\small$\\tilde{\\boldsymbol{\\beta}}_{DT}(t^*) \\in \\mathbb{R}^{N+1}$\\normalsize, \\small$\\mathbf{1}\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector of ones. The objective function, in Eq~\\ref{eq:form},  pushes the classifier of the unseen class to be highly correlated with the domain transfer prediction of the kernel classifier, while putting  the points of the seen classes as negative examples. It is not hard to see that Eq~\\ref{eq:form_kernel} is a quadratic program in \\small$\\mathbf{\\beta}$\\normalsize, which could be solved using any quadratic solver.\n\\ignore{In contrast to our formulation, the approaches presented in~\\cite{NIPS13DeViSE,NIPS13CMT,Hoseini13} assumes that \\small$\\mathcal{X} \\in R^{d_b}$ and  $\\mathcal{E} \\in R^{d_E}\\,$\\normalsize ({\\latinabbrev{i.e}}  vectorized).} It is worth to mention that,  linear classifier prediction in Eq~\\ref{eq:form} (best Linear formulation in our results)  predicts  classifiers by solving an optimization problem of size  \\small$N+d_v+1\\,$\\normalsize  variables, \\small$d_v+1\\,$\\normalsize linear-classifier parameters\\ignore{, which is the same as the length of the visual feature vector,} and \\small$N\\,$\\normalsize slack variables\\ignore{; a similar limitation can be found in~\\cite{NIPS13DeViSE,NIPS13CMT} where the architecture depends on the number on visual features}.  In contrast, the kernelized objective function (Eq~\\ref{eq:form_kernel}) solves a  quadratic program of only \\small$N\\,$\\normalsize variables, and  predicts a kernel-classifier instead with fewer parameters. Using very high-dimensional features  will not affect the optimization complexity.  \\ignore{\nTherefore, it is clear that the kernel formulation is expected to have better generalization properties. In addition, the kernel-approach does not assume that any of \\small$\\mathcal{V}\\,$\\normalsize and \\small$ \\mathcal{T}\\,$\\normalsize is a vector space.}\n\n\n\n\n \n\\section{Distributional Semantic (DS) Kernel for text  descriptions}\n\\label{dskernel}\n\n\nWe propose a distributional semantic kernel $g(\\cdot, \\cdot) = g_{DS}(\\cdot, \\cdot)$  to define the similarity between two text descriptions in $\\mathcal{T}$ domain\\ignore{of visual classes in our setting}. While this kernel is applicable to  kernel classifier predictors  presented in Sec~\\ref{sec:app}, it could be used for other applications. We start by  distributional semantic models by~\\cite{mikolov2013distributed,mikolov2013efficient} to represent the semantic manifold $\\mathcal{M}_s$, and a function $vec(\\cdot)$ that maps a word to a $K\\times 1$ vector in $\\mathcal{M}_s$. The main assumption behind this class of distributional semantic model  is that similar words share similar context. Mathematically speaking, these models  learn a vector for each word $w_n$, such  that $p(w_n|(w_{n-L}, w_{n-L+1}, \\cdots,  w_{n+L-1},w_{n+L})$ is maximized over the training corpus, where $2\\times L$ is the context window size. Hence similarity between $vec(w_i)$ and $vec(w_j)$ is high if they co-occurred a lot in context of size $2\\times L$ in the training text-corpus. We normalize all the word vectors to length $1$ under L2 norm, i.e., $\\| vec(\\cdot) \\|^2=1$. \n\nLet us assume a  text description ${D}$ that we represent by a set of triplets ${D} = \\{(w_l,f_l, vec(w_l)), l=1\\cdots M\\}$, where $w_l$ is a word that occurs in ${D}$ with frequency $f_l$ and its corresponding word vector is $vec(w_l)$ in $\\mathcal{M}_s$. We drop the stop words from ${D}$. We define  $\\textbf{F} = [f_1, \\cdots, f_M]^\\textsf{T}$ and $\\textbf{P} = [vec(w_1), \\cdots, vec(w_M)]^\\textsf{T}$, where $\\textbf{F}$ is an $M\\times1$  vector of term frequencies and $\\textbf{P}$ is an $M \\times K$ matrix of the corresponding term vectors. \n\nGiven two text descriptions ${D}_i$ and ${D}_j$ which contains $M_i$ and $M_j$ terms respectively. We compute $\\textbf{P}_i$ ($M_i \\times 1$) and $\\textbf{V}_i$ ($M_i \\times K$) for  ${D}_i$  and $\\textbf{P}_j$ ($M_j \\times 1$) and $\\textbf{V}_j$ ($M_j \\times K$) for  ${D}_j$. Finally  $g_{DS}({D}_i, {D}_j)$ is defined as \n\n", "itemtype": "equation", "pos": 55768, "prevtext": "\n\\normalsize\nWhile \\small${\\boldsymbol{\\beta}}^*_{-}  = - {\\boldsymbol{\\beta}}^*_{+}$\\normalsize, the objective function in Eq~\\ref{eq:1classneg} of the one-negative class SVM inspires us with the idea to adjust the kernel-classifier parameters to increase separability of the unseen kernel-classifier against the points of the seen classes, which leads to the following objective function \n\\small\n\n", "index": 35, "text": "\\begin{equation}\n\\label{eq:form_kernel}\n\\small\n\\begin{split}\n\\Phi(t_*) = \\hat{\\boldsymbol{\\beta}}(t_*) =  &   \\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin }}\\big[    \\boldsymbol{\\beta}^\\textsf{T} \\mathbf{K^{' }}\\boldsymbol{\\beta} - \\zeta \\hat{\\boldsymbol{\\beta}}_{DT}(t_*)^\\textsf{T} \\mathbf{K^{'}} \\boldsymbol{\\beta}   + \\boldsymbol{\\beta}^T \\mathbf{a} \\big]\\\\\n&s.t.:   \\boldsymbol{\\beta}^T \\mathbf{1} = -1, {\\hat{\\boldsymbol{\\beta}}_{DT}}^{\\mathsf{T}} \\mathbf{K^{' }} \\boldsymbol{\\beta}> l, -C \\le \\boldsymbol{\\beta}_i \\le 0;\\forall i \\\\\n& C, \\zeta , l \\,  \\text{: hyper-parameters},\\\\ \n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\small\\begin{split}\\displaystyle\\Phi(t_{*})=\\hat{\\boldsymbol{\\beta}}(t_{*})=&amp;%&#10;\\displaystyle\\underset{\\boldsymbol{\\beta}}{\\operatorname{argmin}}\\big{[}%&#10;\\boldsymbol{\\beta}^{\\textsf{T}}\\mathbf{K^{{}^{\\prime}}}\\boldsymbol{\\beta}-%&#10;\\zeta\\hat{\\boldsymbol{\\beta}}_{DT}(t_{*})^{\\textsf{T}}\\mathbf{K^{{}^{\\prime}}}%&#10;\\boldsymbol{\\beta}+\\boldsymbol{\\beta}^{T}\\mathbf{a}\\big{]}\\\\&#10;&amp;\\displaystyle s.t.:\\boldsymbol{\\beta}^{T}\\mathbf{1}=-1,{\\hat{\\boldsymbol{%&#10;\\beta}}_{DT}}^{\\mathsf{T}}\\mathbf{K^{{}^{\\prime}}}\\boldsymbol{\\beta}&gt;l,-C\\leq%&#10;\\boldsymbol{\\beta}_{i}\\leq 0;\\forall i\\\\&#10;&amp;\\displaystyle C,\\zeta,l\\,\\text{: hyper-parameters},\\\\&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mi mathsize=\"90%\" mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><mover accent=\"true\"><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><munder accentunder=\"true\"><mo mathsize=\"90%\" stretchy=\"false\">argmin</mo><mo mathsize=\"90%\" stretchy=\"false\">\ud835\udf37</mo></munder><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><mrow><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><msup><mi mathsize=\"90%\">\ud835\udc0a</mi><msup><mi/><mo mathsize=\"90%\" stretchy=\"false\">\u2032</mo></msup></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udf37</mi></mrow><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mrow><mi mathsize=\"90%\">\u03b6</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">^</mo></mover><mrow><mi mathsize=\"90%\">D</mi><mo>\u2062</mo><mi mathsize=\"90%\">T</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><msub><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">*</mo></msub><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow><mtext mathsize=\"90%\">\ud835\uddb3</mtext></msup><mo>\u2062</mo><msup><mi mathsize=\"90%\">\ud835\udc0a</mi><msup><mi/><mo mathsize=\"90%\" stretchy=\"false\">\u2032</mo></msup></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udf37</mi></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mrow><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mo>\u2062</mo><mi mathsize=\"90%\">\ud835\udc1a</mi></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi mathsize=\"90%\">s</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">.</mo><mo mathsize=\"90%\" stretchy=\"false\">:</mo><msup><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">T</mi></msup><mn mathsize=\"90%\">\ud835\udfcf</mn><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mn mathsize=\"90%\">1</mn><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mmultiscripts><mover accent=\"true\"><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">^</mo></mover><mrow><mi mathsize=\"90%\">D</mi><mo>\u2062</mo><mi mathsize=\"90%\">T</mi></mrow><none/><none/><mi mathsize=\"90%\">\ud835\uddb3</mi></mmultiscripts><msup><mi mathsize=\"90%\">\ud835\udc0a</mi><msup><mi/><mo mathsize=\"90%\" stretchy=\"false\">\u2032</mo></msup></msup><mi mathsize=\"90%\">\ud835\udf37</mi><mo mathsize=\"90%\" stretchy=\"false\">&gt;</mo><mi mathsize=\"90%\">l</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mi mathsize=\"90%\">C</mi><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><msub><mi mathsize=\"90%\">\ud835\udf37</mi><mi mathsize=\"90%\">i</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><mn mathsize=\"90%\">0</mn><mo mathsize=\"90%\" stretchy=\"false\">;</mo><mo mathsize=\"90%\" stretchy=\"false\">\u2200</mo><mi mathsize=\"90%\">i</mi></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mi mathsize=\"90%\">C</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mi mathsize=\"90%\">\u03b6</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mrow><mpadded width=\"+1.7pt\"><mi mathsize=\"90%\">l</mi></mpadded><mo>\u2062</mo><mtext mathsize=\"90%\">: hyper-parameters</mtext></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.00025.tex", "nexttext": "\nOne advantage of this similarity measure is that it captures semantically related terms. It is not hard to see that the standard Term Frequency (TF) similarity could be thought as a special case of this kernel where $vec(w_l)^\\mathsf{T} vec(w_m)=1$ if $w_l=w_m$, 0 otherwise, i.e., different terms are orthogonal. However, in our case the word vectors are learnt through a distributional semantic model which makes semantically related terms have higher dot product ($vec(w_l)^\\mathsf{T} vec(w_m)$).   \n\n\n\n\n\\section{Experiments}\n\\label{experiments}\n\n\n\n\n\\subsection{Datasets and Features}\n\\label{ss_ds_feats}\n\n\\noindent{\\bf Datasets:}\nWe used  the CU200 Birds~\\cite{CU20010} (200 classes - 6033 images) and the Oxford Flower-102~\\cite{Flower08} (102 classes - ~8189 images) image dataset to test our methods, since they are among the largest and widely used fine-grained datasets.  We created  textual descriptions for each class in both datasets. The CUB200 Birds image dataset was created based on birds that have a corresponding Wikipedia article, so we have developed a tool to automatically extract Wikipedia articles given the class name. The tool succeeded to automatically generate 178 articles, and the remaining 22 articles was extracted manually from Wikipedia. These mismatches happens only when article title is a different synonym of the same bird class. On the other hand, Flower image dataset was not created using the same criteria as the Bird dataset, so classes of the Flower dataset classes does not necessarily have corresponding Wikipedia article. The tool managed to generate only 16 classes from Wikipedia out of 102, the remaining 86 articles was generated manually for each class from Wikipedia, Plant Database  \\footnote{http://plants.usda.gov/java/}, Plant Encyclopedia \\footnote{http://www.theplantencyclopedia.org/wiki/Main$\\_$Page}, and BBC articles \\footnote{http://www.bbc.co.uk/science/0/}. The collected textual description for FLower and Birds dataset are available here  \\url{https://sites.google.com/site/mhelhoseiny/1202-Elhoseiny-sup.zip} .\n\n\\noindent{\\bf Textual Feature Extraction:}\nThe textual features were extracted in two phases, which are typical in document retrieval literature. The first phase is an indexing phase that generates textual features with tf-idf (Term Frequency-Inverse Document Frequency) configuration (Term frequency as local weighting while inverse document frequency as a global weighting). The tf-idf is a measure of how important is a word to a text corpus. The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to control for the fact that some words are generally more common than others. We used the normalized frequency of a term in the given textual description~\\cite{salton1988term}. The inverse document frequency is a measure of whether the term is common; in this work we used the standard logarithmic idf~\\cite{salton1988term}.   \nThe second phase is a dimensionality reduction step, in which  Clustered Latent Semantic Indexing (CLSI) algorithm~\\cite{clsi05} is used. CLSI is a low-rank approximation approach for dimensionality reduction, used for document retrieval. In the Flower Dataset, tf-idf features $\\in \\mathbb{R}^{8875}$ and after CLSI the final textual features $\\in \\mathbb{R}^{102}$. In the Birds Dataset, tf-idf features is in $\\mathbb{R}^{7086}$ and after CLSI the final textual features is in $\\mathbb{R}^{200}$. \n\n\n\n\n\\noindent{\\bf  Visual features Extraction:}\nWe used the Classeme features~\\cite{classemes} as the visual feature for our experiments since they provide an intermediate semantic representation of the input image. Classeme features are output of a set of classifiers corresponding to a set of $C$ category labels, which are drawn from an appropriate term list defined in~\\cite{classemes}, and not related to our textual features. For each category $c \\in \\lbrace 1 \\cdots C \\rbrace $, a set of training images is gathered by issuing a query on the category label to an image search engine.\nAfter a set of coarse feature descriptors (Pyramid HOG, GIST, {\\latinabbrev{etc}}) is extracted, a subset of feature dimensions was selected~\\cite{classemes}, and  a one-versus-all classifier $\\varphi_{c}$ is trained for each category. The classifier output is real-valued, and is such that $\\varphi_{c}(x) > \\varphi_{c}(y)$ implies that $x$ is more similar to class $c$ than $y$ is. Given an image $x$,  the feature vector (descriptor) used to represent it is the classeme vector $  [\\varphi_{1} (x),  \\cdots, \\varphi_{d_v} (x)]$, $d_v=2569$.\n\nFor Kernel classifier prediction, we evaluated  these features and also additional representations  for text descriptions (by the proposed distributional semantic kernel using word embedding) and  images ( (a) CNN features and (b)  combined kernel over different features learnt by MKL (multiple kernel learning)), discussed later in Subsection~\\ref{ss_exp_kernel}.\n\n\n \n\n\\begin{figure*}[ht!]\n\\centering\n\\hspace{-10mm}\n\\begin{minipage}{0.33\\textwidth}\n  \\centering\n\\includegraphics[width=1.1\\linewidth,height=.75\\linewidth]{birds_top10_ROC_final.eps}\n\n\\end{minipage}\n\\hspace{-3mm}\n\\begin{minipage}{0.33\\textwidth}\n  \\centering\n \\includegraphics[width=1.1\\linewidth,height=.75\\linewidth]{flower_top10_ROC_final.eps}\n \n\\end{minipage}\n\\begin{minipage}{0.33\\textwidth}\n  \\centering\n\\includegraphics[width=1.1\\linewidth,height=.75\\linewidth]{flower_AUC_imp_final.eps}\n\n\\end{minipage}\n\\vspace{-1mm}\n\\caption{Linear : \\textbf{Left and Middle}: ROC curves of best 10 predicted classes by the final formulation (E) for Bird  and Flower datasets respectively, \\textbf{Right}: AUC improvement over the three baselines on Flower dataset (Formulations A (GPR), A (TGP), C). The improvement is sorted in an increasing order for each baseline separately (best seen in color)}\n\\vspace{-2mm}\n\\label{fig:result3fig}\n\\end{figure*}\n\n\n\\begin{table*}[b!]\n\\small\n\\centering\n\\caption{ Linear: Comparative Evaluation of Different Formulations on the Flower and Bird Datasets}\n\\label{T:AUC}\n\n\\scalebox{1.0}{\n\\begin{tabular}{|l|l|l|}\n  \\hline\n  \t\t&  Oxford Flowers   & UC-UCSD Birds   \\\\\n  Approach  & Avg AUC (+/- std) & Avg AUC (+/- std)\\\\ \n  \\hline\n  \\hline\n  (A) Regression - GPR & 0.54 (+/- 0.02) & 0.52 (+/- 0.001) \\\\ \n  (A) Structured Regression - TGP & 0.58 (+/- 0.02) & 0.61 (+/- 0.02)\\\\\n  (C)  Domain Transfer(DT) &  0.62(+/- 0.03)  &  0.59 (+/- 0.01)\\\\\n  \\hline \n  (B) Constrained GPR & 0.62(+/- 0.005) & - \\\\\n  (B) Constrained TGP & 0.63(+/- 0.007) & - \\\\\n  (D) Constrained Domain Adaptation (CDT) on Eq~\\ref{eq:form} & 0.64 (+/- 0.006)& -  \\\\\n       \\hline\n  (E) Regression+DT + constraints (final best linear approach) & {0.68} (+/- 0.01) & { 0.62} (+/- 0.02) \\\\\n      \\hline\n\\end{tabular}}\n\n\n\n\n\n\n\n\n\\ignore{\n{\n\\scalebox{0.7}{\n\\begin{tabular}{|l|l|l|l|l|}\n  \\hline\n  \\multicolumn{5}{c}{Top-5 Classes with highest combined improvement} \\\\\n  \\hline\n  \\hline\n  class      &  (A) TGP (AUC) & (C) DT (AUC) & (D) TGP+DT+C  & \\% Improv. \\\\\n  \\hline\n  \\hline\n   2   &  0.51 & 0.55 & 0.83 & 57\\% \\\\  \n   28 & 0.52 & 0.54 & 0.76 &  43.5\\% \\\\\n   26 &  0.54 & 0.53 & 0.76 & 41.7\\% \\\\\n   81 & 0.52 & 0.82 & 0.87   & 37\\%  \\\\\n   37 & 0.72 & 0.53 & 0.83   & 35.7 \\% \\\\\n  \\hline \n\\end{tabular}}\n}}\n\n\\end{table*}\n\n\\subsection{Experimental Results for Linear Classifier Prediction}\n\n\n\\noindent{\\bf Evaluation Methodology:} Similar to zero-shot learning literature, we evaluated the performance of an unseen classifier in a one-vs-all setting where the test images of unseen classes are considered to be the positives and the test images from the seen classes are considered to be the negatives. We computed the ROC curve and report the area under that curve (AUC) as a comparative measure of different approaches. In zero-shot learning setting the test data from the seen class are typically very large compared to those from unseen classes. This makes other measures, such as accuracy, useless since high accuracy can be obtained even if all the unseen class test data are wrongly classified; hence we used ROC curves, which are independent of this problem. Five-fold cross validation over the classes were performed, where in each fold 4/5 of the classes are considered as ``seen classes'' and are used for training and 1/5th of the classes were considered as ``unseen classes'' where their classifiers are predicted and tested. Within each of these class-folds, the data of the seen classes are further split into training and test sets. The hyper-parameters for the  approach were selected through another five-fold cross validation within the class-folds  (i.e. the $80\\%$ training classes are further split into $5$ folds to select the hyper-parameters). We made the seen-unseen folds used in our experiments available here \\url{https://sites.google.com/site/mhelhoseiny/computer-vision-projects/Write_a_Classifier}.\n\n\\noindent{\\bf Baselines:}\nSince our work is the first to predict classifiers based on pure textual description, there are no other reported results to compare against. However, we designed three state-of-the-art baselines to compare against, which are designed to be inline with our argument in Sec~\\ref{obvformulation}. Namely we used: 1) A Gaussian Process Regressor (GPR)~\\cite{Rasmussen:2005}, 2) Twin Gaussian Process (TGP)~\\cite{Bo:2010} as a structured regression method, 3)  Domain Transfer (DT)~\\cite{da11}. The TGP and DT baselines are of particular importance since our formulation utilizes them, so we need to test if the formulation is making any improvement over them. It has to be noted that we also evaluate TGP and DT as alternative formulations that we are proposing for the problem, none of them was used in the same context before. \n\n\n\n\n\n\\noindent{\\bf Results:}\nTable~\\ref{T:AUC} shows the average AUCs for the final linear approach in comparison to the three baselines on both datasets. GPR performed poorly in all classes in both data sets, which was expected since it is not a structure prediction approach.  The DT formulation outperformed TGP in the flower dataset but slightly underperformed on the Bird dataset. The proposed approach outperformed all the baselines on both datasets, with significant difference on the flower dataset. It is also clear that the TGP performance was improved on the Bird dataset since it has more classes (more points are used for prediction). Fig ~\\ref{fig:result3fig} shows the ROC curves for our approach on best predicted unseen classes from the Birds dataset on the Left  and Flower dataset on the middle. Fig ~\\ref{F:AUCs} shows the AUC for all the classes on Flower dataset. \n\n\n\n\n\n\n\n\n\n\\begin{table}[t]\n\\small\n\\caption{\\small Linear: Percentage of classes that the final proposed approach (formulation (E)) makes an improvement in predicting over the baselines (relative to the total number of classes in each dataset}\n\\label{T:classimprov}\n\n\\centering\n\\scalebox{1.0}{\n\\begin{tabular}{|l|l|l|}\n  \\hline\n  \t\t&  Flowers (102)  & Birds (200)\\\\ \n baseline      &  \\%  improvement & \\%  improvement\\\\  \n  \\hline\n  \\hline\n  (A) GPR  & 100 \\% & 98.31 \\% \\\\ \n  (A) TGP  & 66 \\% & 51.81 \\%\\\\\n  (C) DT  &   54\\% &  56.5\\% \\\\\n  \n  \\hline \n\\end{tabular}}\n\n\\end{table}\n\nFig ~\\ref{fig:result3fig}, on the right, shows the improvement over (A) GPR,\\begin{figure}\n\\vspace{-3mm}\n\\centering\n \\hspace*{-12mm}\n\\includegraphics[width=1.24\\linewidth,height=.27\\linewidth]{flower_AUC_for_all_classes_final.eps}\n\n\\caption{Linear: AUC of the predicated classifiers for all classes of the flower datasets (Formulation E)}\n\\label{F:AUCs}\n\\end{figure} A(TGP), and (C) DT for each class, where the improvement is calculated as (our AUC- baseline AUC)/ baseline AUC \\%. \nTable~\\ref{T:classimprov} shows the percentage of the classes which our approach makes a prediction improvement for each of  the three baselines\n. Table~\\ref{T:top5improv} shows the five classes in Flower dataset where our approach made the best average improvement.\n\n The point of that table is to show that in these cases both TGP and DT did poorly while our formulation that is based on both of them did significantly better. This shows that our formulation does not simply combine the best of the two approaches but can significantly improve the prediction performance.\n\n\\begin{table}[t]\n\\small\n\\caption{\\small Linear: Top-5 classes with highest combined improvement in Flower dataset}\n\\label{T:top5improv}\n\\centering\n\n{\n\\scalebox{0.85}{\n\\begin{tabular}{|l|l|l|l|l|}\n  \\hline\n  class      &  (A) TGP (AUC) & (C) DT (AUC) & (E) Our (AUC)  & \\% Improv. \\\\\n  \\hline\n  \\hline\n   2   &  0.51 & 0.55 & 0.83 & 57\\% \\\\  \n   28 & 0.52 & 0.54 & 0.76 &  43.5\\% \\\\\n   26 &  0.54 & 0.53 & 0.76 & 41.7\\% \\\\\n   81 & 0.52 & 0.82 & 0.87   & 37\\%  \\\\\n   37 & 0.72 & 0.53 & 0.83   & 35.7 \\% \\\\\n  \\hline \n\\end{tabular}}\n}\n\\vspace{-2pt}\n\\end{table}\n\n\n\n\n\n\n\nTo evaluate the effect of the constraints in the objective function, we removed the constraints $- (\\mathbf{c}^\\textsf{T} {\\mathbf{x}}_{i} ) \\geq \\zeta_i$ which try to enforces all the seen examples to be on the negative side of the predicted classifier hyperplane and evaluated the approach. The result on the flower dataset (using one fold) was reduced to average AUC=0.59 compared to AUC=0.65 with the constraints. Similarly, we evaluated the effect of the constraint  $\\mathbf{t}_*^\\textsf{T} \\mathbf{W} \\mathbf{c} \\ge l$. The result was reduced to average AUC=0.58 compared to AUC=0.65 with the constraint.  This illustrates the importance of this constraint in the formulation.\n\n\\noindent{\\bf Constrained Baselines:}\n\n\\ignore{We computed the ROC curves and report the area under that curve (AUC) as a comparative measure\\footnote{In zero-shot learning setting the test data from the seen class are typically very large compared to those from unseen classes. This makes other measures, such as accuracy, useless since high accuracy can be obtained even if all the unseen class test data are wrongly classified; hence we used ROC curves, which are independent of this problem.} Five-fold cross validation over the classes were performed, within each of these class-folds, the data of the seen classes are further split into training and test sets.}\nTable~\\ref{T:AUC} (bottom three lines) also shows the average AUCs for the constrained baselines formulations, namely Constrained GPR, TGP and DT; see section~\\ref{formulation}. Even though the visual features and textual features were independently extracted, by learning correlation between them, we can predict classifiers for new categories. As shown previously, GPR performed poorly, while, as expected, TGP performed better. Adding constraints to GPR/TGP improved their performance. Combining regression and DT gave significantly better results for classes where both approaches individually perform poorly, as can be seen in Table~\\ref{T:AUC}-right. We performed an additional experiment, where  $\\mathbf{W}$ is firstly computed using Constrained Domain Transfer (CDT). Then, the unseen classifier is predicted using equation~\\ref{eq:form} with $\\gamma=0$, which performs worse. This indicates that adding constraints to align to seen classifiers hurts the learnt domain transfer function on unseen classes. In conclusion, the final formulation that combines TGP and DT with additional constraints performs the best in both Birds and Flower datasets, where the effect of TGP is very limited since it was trained on sparse points. \n\n\n\n\n\n\\input{Knewexperiments}\n\n\n\n\\section{Conclusion}\nWe explored the problem of predicting visual classifiers from textual description of classes with no training images.  We investigated and  experimented with different formulations for the problem within the fine-grained categorization context.  We first proposed  a novel formulation that captures information between the visual and textual domains by involving knowledge transfer from textual features to visual features, which indirectly leads to predicting a linear visual classifier described by the text. \\ignore{In the future, we are planning to propose a kernel version to tackle the problem instead of using linear classifiers. Furthermore, } We also proposed a new zero-shot learning technique to predict kernel-classifiers of unseen categories using information from a privilege space. We formulated the problem as domain transfer function from text description  to the visual classification space, while supporting kernels in both domains. We proposed a one-class SVM adjustment to our domain transfer function in order to improve the prediction. We validated the performance of our model by several experiments. We also showed that   our approach using with weak-attributes. We illustrated the value of proposing a kernelized version by applying kernels generated by Multiple Kernel Learning (MKL) and achieved better results.  \\ignore{We  compared our approach with  state-of-the-art approaches and interesting findings have been reported.} In the future, we aim to improve this model by learning the unseen classes jointly and on a larger scale. \n\n\\ignore{\nWe are also looking forward to studying more features for the $\\mathcal{X}$ and $\\mathcal{E}$ domains in a  large scale setting (number of classes $>$ 1000). }\n\n\n\n\n\n\\noindent \\textbf{Acknowledgment. } This research was partially funded by NSF award IIS-1218872 and IIS-1409683. \n\n\n\n\n\n\n\\ifCLASSOPTIONcaptionsoff\n  \\newpage\n\\fi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\n\n\n\\bibliographystyle{IEEEtran}\n\\bibliography{egbib,write_a_classifier,elgammal,NLPVision,NLPVisionProposal,smara}\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 60550, "prevtext": "\n\\normalsize\nwhere  \\small$\\hat{\\boldsymbol{\\beta}}_{DT}\\,$\\normalsize is the first \\small$N\\,$\\normalsize elements in \\small$\\tilde{\\boldsymbol{\\beta}}_{DT}(t^*) \\in \\mathbb{R}^{N+1}$\\normalsize, \\small$\\mathbf{1}\\,$\\normalsize is an \\small$N \\times 1\\,$\\normalsize vector of ones. The objective function, in Eq~\\ref{eq:form},  pushes the classifier of the unseen class to be highly correlated with the domain transfer prediction of the kernel classifier, while putting  the points of the seen classes as negative examples. It is not hard to see that Eq~\\ref{eq:form_kernel} is a quadratic program in \\small$\\mathbf{\\beta}$\\normalsize, which could be solved using any quadratic solver.\n\\ignore{In contrast to our formulation, the approaches presented in~\\cite{NIPS13DeViSE,NIPS13CMT,Hoseini13} assumes that \\small$\\mathcal{X} \\in R^{d_b}$ and  $\\mathcal{E} \\in R^{d_E}\\,$\\normalsize ({\\latinabbrev{i.e}}  vectorized).} It is worth to mention that,  linear classifier prediction in Eq~\\ref{eq:form} (best Linear formulation in our results)  predicts  classifiers by solving an optimization problem of size  \\small$N+d_v+1\\,$\\normalsize  variables, \\small$d_v+1\\,$\\normalsize linear-classifier parameters\\ignore{, which is the same as the length of the visual feature vector,} and \\small$N\\,$\\normalsize slack variables\\ignore{; a similar limitation can be found in~\\cite{NIPS13DeViSE,NIPS13CMT} where the architecture depends on the number on visual features}.  In contrast, the kernelized objective function (Eq~\\ref{eq:form_kernel}) solves a  quadratic program of only \\small$N\\,$\\normalsize variables, and  predicts a kernel-classifier instead with fewer parameters. Using very high-dimensional features  will not affect the optimization complexity.  \\ignore{\nTherefore, it is clear that the kernel formulation is expected to have better generalization properties. In addition, the kernel-approach does not assume that any of \\small$\\mathcal{V}\\,$\\normalsize and \\small$ \\mathcal{T}\\,$\\normalsize is a vector space.}\n\n\n\n\n \n\\section{Distributional Semantic (DS) Kernel for text  descriptions}\n\\label{dskernel}\n\n\nWe propose a distributional semantic kernel $g(\\cdot, \\cdot) = g_{DS}(\\cdot, \\cdot)$  to define the similarity between two text descriptions in $\\mathcal{T}$ domain\\ignore{of visual classes in our setting}. While this kernel is applicable to  kernel classifier predictors  presented in Sec~\\ref{sec:app}, it could be used for other applications. We start by  distributional semantic models by~\\cite{mikolov2013distributed,mikolov2013efficient} to represent the semantic manifold $\\mathcal{M}_s$, and a function $vec(\\cdot)$ that maps a word to a $K\\times 1$ vector in $\\mathcal{M}_s$. The main assumption behind this class of distributional semantic model  is that similar words share similar context. Mathematically speaking, these models  learn a vector for each word $w_n$, such  that $p(w_n|(w_{n-L}, w_{n-L+1}, \\cdots,  w_{n+L-1},w_{n+L})$ is maximized over the training corpus, where $2\\times L$ is the context window size. Hence similarity between $vec(w_i)$ and $vec(w_j)$ is high if they co-occurred a lot in context of size $2\\times L$ in the training text-corpus. We normalize all the word vectors to length $1$ under L2 norm, i.e., $\\| vec(\\cdot) \\|^2=1$. \n\nLet us assume a  text description ${D}$ that we represent by a set of triplets ${D} = \\{(w_l,f_l, vec(w_l)), l=1\\cdots M\\}$, where $w_l$ is a word that occurs in ${D}$ with frequency $f_l$ and its corresponding word vector is $vec(w_l)$ in $\\mathcal{M}_s$. We drop the stop words from ${D}$. We define  $\\textbf{F} = [f_1, \\cdots, f_M]^\\textsf{T}$ and $\\textbf{P} = [vec(w_1), \\cdots, vec(w_M)]^\\textsf{T}$, where $\\textbf{F}$ is an $M\\times1$  vector of term frequencies and $\\textbf{P}$ is an $M \\times K$ matrix of the corresponding term vectors. \n\nGiven two text descriptions ${D}_i$ and ${D}_j$ which contains $M_i$ and $M_j$ terms respectively. We compute $\\textbf{P}_i$ ($M_i \\times 1$) and $\\textbf{V}_i$ ($M_i \\times K$) for  ${D}_i$  and $\\textbf{P}_j$ ($M_j \\times 1$) and $\\textbf{V}_j$ ($M_j \\times K$) for  ${D}_j$. Finally  $g_{DS}({D}_i, {D}_j)$ is defined as \n\n", "index": 37, "text": "\\begin{equation}\ng_{DS}({D}_i, {D}_j) = \\textbf{F}_i^\\textsf{T} \\textbf{P}_i \\textbf{P}_j^\\textsf{T}  \\textbf{F}_j\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"g_{DS}({D}_{i},{D}_{j})=\\textbf{F}_{i}^{\\textsf{T}}\\textbf{P}_{i}\\textbf{P}_{j%&#10;}^{\\textsf{T}}\\textbf{F}_{j}\" display=\"block\"><mrow><mrow><msub><mi>g</mi><mrow><mi>D</mi><mo>\u2062</mo><mi>S</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>D</mi><mi>i</mi></msub><mo>,</mo><msub><mi>D</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mtext>\ud835\udc05</mtext><mi>i</mi><mtext>\ud835\uddb3</mtext></msubsup><mo>\u2062</mo><msub><mtext>\ud835\udc0f</mtext><mi>i</mi></msub><mo>\u2062</mo><msubsup><mtext>\ud835\udc0f</mtext><mi>j</mi><mtext>\ud835\uddb3</mtext></msubsup><mo>\u2062</mo><msub><mtext>\ud835\udc05</mtext><mi>j</mi></msub></mrow></mrow></math>", "type": "latex"}]