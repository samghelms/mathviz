[{"file": "1601.06792.tex", "nexttext": "\n\nAs an additional summary statistic, we consider the counts of local\n$\\kappa$ maxima of a certain height $\\kappa_0$, $n_r(\\kappa_0)$\n(hereafter \\textit{peak counts}), with varying $\\kappa_0$ chosen\nbetween the minimum and maximum values measured from the maps\n$(\\kappa_{\\rm min},\\kappa_{\\rm max})=(-0.06,0.45)$. Different choices\nof $\\kappa_0$ binning used in this work are outlined in Table\n\\ref{featuretable}.  The fact that the ensemble of $N_r$ realizations\nis not completely independent if $N_s$ is not large enough can have an\neffect on the covariance estimators of both $P^{\\kappa\\kappa}$ and\n$n(\\kappa_0)$.\n\nTo measure the cosmological dependence of the $\\kappa$ peak counts, we\nperformed a set of additional ray--tracing simulations with different\ncombinations of the cosmological parameter triplet\n$(\\Omega_m,w,\\sigma_8)$. A summary of the complete set of shear\nensembles used in this work is listed in Table \\ref{simtable}.\n\n\\subsection{Cosmological parameter inference}\n\nLet ${\\mathbf{\\hat{{d}}}}$ be a single estimate for a feature of dimension $N_b$,\n${\\mathbf{{d}}}({\\mathbf{{p}}})$ be the true value of this feature at a point ${\\mathbf{{p}}}$\nin parameter space (which has a dimension $N_p$) and ${\\mathbf{{C}}}$ be the\n$N_b\\times N_b$ feature covariance matrix. For the purpose of this\nwork ${\\mathbf{{p}}}$ is the triplet $(\\Omega_m,w,\\sigma_8)$ and ${\\mathbf{{d}}}$ is\none of the features -- either a power spectrum or a peak count\nhistogram -- in Table \\ref{featuretable}. Although existing emulators\ncan be used, in principle, to compute both ${\\mathbf{{d}}}({\\mathbf{{p}}})$ and\n${\\mathbf{{C}}}$, the latter is more difficult, and typically only the mean,\n${\\mathbf{{d}}}({\\mathbf{{p}}})$, has been computed to date\n(refs.~\\citep{coyote2,Nicaea}, but see an exception by\nref.~\\citep{SchneiderKnoxCovariance}).  Estimating ${\\mathbf{{C}}}$ from\nsimulations involves generating a series of mock realizations\n${\\mathbf{\\hat{{d}}}}_r$ with $r=1...N_r$ and computing the sample covariance\n${\\mathbf{\\hat{{C}}}}$,\n\n\n", "itemtype": "equation", "pos": 10277, "prevtext": "\n\n\\title{Sample variance in weak lensing: how many simulations are required?}\n\n\\author{Andrea Petri}\n\\email{apetri@phys.columbia.edu}\n\\affiliation{Department of Physics, Columbia University, New York, NY 10027, USA}\n\\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}\n\n\\author{Zolt\\'an Haiman}\n\\affiliation{Department of Astronomy, Columbia University, New York, NY 10027, USA}\n\n\\author{Morgan May}\n\\affiliation{Physics Department, Brookhaven National Laboratory, Upton, NY 11973, USA}\n\n\\date{\\today}\n\n\\label{firstpage}\n\n\\begin{abstract}\n\nConstraining cosmology using weak gravitational lensing consists of\ncomparing a measured feature vector of dimension $N_b$ with its\nsimulated counterpart. An accurate estimate of the $N_b\\times N_b$\nfeature covariance matrix ${\\mathbf{{C}}}$ is essential to obtain accurate\nparameter confidence intervals. When ${\\mathbf{{C}}}$ is measured from a set\nof simulations, an important question is how large this set should\nbe. To answer this question, we construct different ensembles of $N_r$\nrealizations of the shear field, using a common randomization\nprocedure that recycles the outputs from a smaller number $N_s\\leq\nN_r$ of independent ray-tracing $N$--body simulations.  We study\nparameter confidence intervals as a function of ($N_s,N_r$) in the\nrange $1\\leq N_s\\leq 200$ and $1\\leq N_r\\lesssim 10^5$.  Previous work\n\\citep{DodelsonSchneider13} has shown that Gaussian noise in the\nfeature vectors (from which the covariance is estimated) lead, at quadratic order, to an $O(1/N_r)$\ndegradation of the parameter confidence intervals. Using a variety of\nlensing features measured in our simulations, including shear-shear\npower spectra and peak counts, we show that cubic and quartic\ncovariance fluctuations lead to additional $O(1/N_r^2)$ error\ndegradation that is not negligible when $N_r$ is only a factor of few\nlarger than $N_b$. We study the large $N_r$ limit, and find that a\nsingle, 240Mpc$/h$ sized $512^3$-particle $N$--body simulation ($N_s=1$) can be repeatedly recycled to\nproduce as many as $N_r={\\rm few}\\times10^4$ shear maps whose power spectra and high-significance peak counts can be treated as statistically independent. As a result, a small number of simulations ($N_s=1$ or $2$) is sufficient to forecast parameter confidence intervals at percent accuracy. \n\n\\end{abstract}\n\n\n\\keywords{Weak Gravitational Lensing --- Simulations --- Methods: analytical, numerical, statistical}\n\\pacs{98.80.-k, 95.36.+x, 95.30.Sf, 98.62.Sb}\n\n\\maketitle\n\n\n\n\n\\section{Introduction}\n\nWeak gravitational lensing (WL) is a promising cosmological probe for\nconstraining the dark energy equation of state $w$, and has been\nconsidered by a range of past (CFHTLens \\citep{cfht1,cfht2}, COSMOS\n\\citep{cosmos}), ongoing (DES \\citep{DES}) and future (LSST\n\\citep{LSST}, Euclid \\citep{Euclid}, WFIRST \\citep{WFIRST})\nexperiments. In an era where cosmology is data driven, accurate\nnumerical simulations of shear fields are becoming important for\nseveral reasons, including assessing baryonic effects\n\\citep{BaryonXiuyuan,BaryonSemboloni,BaryonsWhite,BaryonsKnox,BaryonsZentner1,BaryonsZentner2},\nthe utility of non--Gaussian statistics\n\\citep{PeaksJan,MinkJan,MinkPetri,NG-Marian,NG-Jain1,NG-Jain2,NG-Jain3,NG-Refregier,NG-Dietrich}\nand various systematic effects\n\\citep{MinkShirasaki,Sys-Bard,Sys-Chang,Sys-Huterer}.\n\nA fundamental issue with predictions from simulations is that the\nfinite number of simulations naturally introduces fluctuations in the\nforecasts, due to inevitable sample variance~\\footnote{Sample variance is a broad term that has been used in the literature to describe a range of phenomena. Throughout this paper, we use it to refer to the fluctuations in an ensemble of simulations, which represent random realizations of the same initial conditions.}. In general,\nquantities such as the mean or the variance of any feature (e.g. the\nshear power spectrum at a multipole $\\ell$), measured from a finite\nset of simulations, will fluctuate, and can also suffer a bias.  While\nbiases in the estimates of both the mean and the variance have been\nstudied extensively, the impact of fluctuations in the variance has\nreceived less attention.  These fluctuations have been shown to have non-negligible effects on estimates of\nfeatures covariances and hence on parameter constraints. In\nparticular, in the limit of Gaussian fluctuations, the parameter\nconfidence limits are degraged by a factor\n$1+O(1/N_r)$~\\citep{DodelsonSchneider13,Taylor12}.\n\nThis work studies these issues further, focusing on the number of\nindependent $N$--body simulations required for an accurate estimate of\nthe parameter constraints.  Ray-tracing simulations that resolve the\ncosmic structures responsible for lensing on arcminute scales are\nlimited to physical sizes of hundreds of Mpc, and thus cover a solid\nangle of only $O(10$ deg$^2)$.  As a result, many simulations are\nrequired to tile a significant fraction of the sky, and to make\npredictions for large ``all-sky'' surveys, such as the ones by DES,\nLSST, Euclid, WFIRST.  In practice, this has led to the wide-spread\nuse of ``pseudo-independent'' realizations, i.e. a procedure in which\none randomizes and re-cycles the output of a single 3D simulation\nmultiple times.  In light of the forthcoming large surveys, it is\nimperative to assess the statistical validity of this approach, and to\nask how many times a single simulation can be fairly recycled.  In\nthis paper, we address these questions with ensembles of up to\n$N_r=10^5$ random realizations, extracted from up to $N_s=200$\nindependent ray-tracing $N$--body simulations. We focus in particular on\nthe parameter $w$, and on two different statistics: the (convergence)\npower spectrum and the number counts of peaks.\n\n\nThis paper is organized as follows.  In \\S~II, we summarize the shear\nsimulation methods we utilized, and describe the formalism we adopted\nto forecast cosmological parameter constraints. We then vary the\nnumber of simulations and the number of pseudo-independent\nrealizations, and present our main findings in \\S~III. These results\nare discussed further in \\S~IV.  We offer our conclusions, and suggest\nfollow-up future work in \\S~V.\n\n\n\n\\section{Methods}\n\n\\subsection{Ray-tracing simulations of the convergence field}\n\\label{shearsim}\n\nIn this section, we describe how we constructed our shear field\nensembles. Background galaxies at redshift $z_s$ are lensed by large\nscale structures between $z=0$ and $z_s$. The shape distortions due to\nthe cosmic shear $\\pmb{\\gamma}$ can be computed in terms of the dark\nmatter gravitational potential $\\Phi({\\mathbf{{x}}},z)$. Because the evolution\nof $\\Phi$ with redshift is non--linear, it needs to be computed with\nnumerical simulations. We make use of the public code \\texttt{Gadget2}\n\\citep{Gadget2}, with which we run a sequence of $200$ independent\ndark--matter--only $N$--body simulations that track the evolution of\nthe density fluctuations. We assume a standard $\\Lambda$CDM background\nuniverse with the parameters\n$(\\Omega_m,\\Omega_\\Lambda,h,w,\\sigma_8,n_s)=(0.26,0.74,0.72,-1,0.8,0.96)$.\nWe fix the comoving size of the simulation box to $240\\mathrm{Mpc}/h$,\nand use $512^3$ particles, corresponding to a dark matter particle\nmass of $\\approx 10^{10}M_\\odot$.\n\nWe assume a uniform galaxy distribution at a constant redshift $z_s=2$\n(at which the simulation box has an angular size of $\\theta_{\\rm\n  box}=3.5^\\circ$) and we discretize the mass distribution\nbetween $z_s$ and the observer at $z=0$ with a sequence of 46 two\ndimensional lenses of thickness $80\\mathrm{Mpc}/h$. The surface\ndensity on each lens plane is computed by projecting the\nthree--dimensional density measured from \\texttt{Gadget2}\nsnapshots. We then apply the multi--lens--plane algorithm (see\n\\citep{RayTracingHartlap,RayTracingJain} for example) to trace the\ndeflections of $n_{\\rm ray}^2=2048^2$ light rays arranged on a square grid\nof total size $\\theta_{\\rm box}$, from $z=0$ to $z_s$. This corresponds to a pixel angular resolution of $0.1^\\prime$. \nOur implementation of this algorithm is part of the \\texttt{LensTools}\ncomputing package we have been developing \\citep{LensTools}, and have\nreleased under the \\texttt{MIT} license. Many different realizations\n$r$ of the same shear field $\\pmb{\\gamma}_r(\\pmb{\\theta})$ can be\ngenerated by picking different lens planes that lie between the\nobserver and $z_s$. The randomization procedure we adopt is the\nfollowing (see \\citep{Sato12} for reference):\n\n\\begin{itemize}\n\\item For each lens-plane redshift $z_l$, select the snapshot at $z_l$ from the $i$--th $N$--body simulation, where $i$ is a random integer $i\\in [1,N_s]$.\n\\item Choose randomly between the three orthogonal directions ${{\\mathbf{{n}}}_x,{\\mathbf{{n}}}_y,{\\mathbf{{n}}}_z}$: the lens plane will be perpendicular to this direction.\n\\item Choose the position of the plane along the snapshot: because the lens thickness is 1/3 the size of the box, we can cut three different slices of the simulation box for each orientation ${{\\mathbf{{n}}}_x,{\\mathbf{{n}}}_y,{\\mathbf{{n}}}_z}$. This gives a total of 9 choices for generating a lens plane out of a single $N$--body snapshot.\n\\item Perform a periodic random shift of the lens plane along its two directions.\n\\item Repeat the above procedure for each lens-plane redshift $z_l$.\n\\end{itemize}  \n\nThis randomization procedure allows us to produce an (almost)\narbitrary number $N_r$ of shear realizations\n$\\pmb{\\gamma}_r(\\pmb{\\theta})$. However, these realizations are not\nguaranteed to be independent, if $N_s$ is not large enough. Using the\nset of 200 independent $N$--body simulations, we construct different\nensembles with different choices of $N_s\\in[1,200]$. Each of these\nensembles consists of the same number $N_r=1000$ of shear\nrealizations. We also build an additional ensemble with $N_s=1$ and\n$N_r=10^5$ realizations. For each realization of each ensemble, we\nreconstruct the convergence $\\kappa_r(\\pmb{\\theta})$ from the trace of\nthe light-ray deflection Jacobian matrix, measured from the difference\nin deflection angles between nearby light-rays\n\\citep{RayTracingHartlap,RayTracingJain,Sato12}.\n\nWe measure the $\\kappa$ angular power spectrum $P^{\\kappa\\kappa}_r(\\ell)$ defined as\n\n", "index": 1, "text": "\\begin{equation}\n\\langle\\tilde{\\kappa}_r(\\pmb{\\ell})\\tilde{\\kappa}_r(\\pmb{\\ell}')\\rangle = (2\\pi)^2\\delta_D(\\pmb{\\ell}+\\pmb{\\ell}')P^{\\kappa\\kappa}_r(\\ell)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\langle\\tilde{\\kappa}_{r}(\\boldsymbol{\\ell})\\tilde{\\kappa}_{r}(\\boldsymbol{%&#10;\\ell}^{\\prime})\\rangle=(2\\pi)^{2}\\delta_{D}(\\boldsymbol{\\ell}+\\boldsymbol{\\ell%&#10;}^{\\prime})P^{\\kappa\\kappa}_{r}(\\ell)\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><msub><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"bold\">\u2113</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msub><mi>\u03b4</mi><mi>D</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"bold\">\u2113</mi><mo>+</mo><msup><mi mathvariant=\"bold\">\u2113</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msubsup><mi>P</mi><mi>r</mi><mrow><mi>\u03ba</mi><mo>\u2062</mo><mi>\u03ba</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 12480, "prevtext": "\n\nAs an additional summary statistic, we consider the counts of local\n$\\kappa$ maxima of a certain height $\\kappa_0$, $n_r(\\kappa_0)$\n(hereafter \\textit{peak counts}), with varying $\\kappa_0$ chosen\nbetween the minimum and maximum values measured from the maps\n$(\\kappa_{\\rm min},\\kappa_{\\rm max})=(-0.06,0.45)$. Different choices\nof $\\kappa_0$ binning used in this work are outlined in Table\n\\ref{featuretable}.  The fact that the ensemble of $N_r$ realizations\nis not completely independent if $N_s$ is not large enough can have an\neffect on the covariance estimators of both $P^{\\kappa\\kappa}$ and\n$n(\\kappa_0)$.\n\nTo measure the cosmological dependence of the $\\kappa$ peak counts, we\nperformed a set of additional ray--tracing simulations with different\ncombinations of the cosmological parameter triplet\n$(\\Omega_m,w,\\sigma_8)$. A summary of the complete set of shear\nensembles used in this work is listed in Table \\ref{simtable}.\n\n\\subsection{Cosmological parameter inference}\n\nLet ${\\mathbf{\\hat{{d}}}}$ be a single estimate for a feature of dimension $N_b$,\n${\\mathbf{{d}}}({\\mathbf{{p}}})$ be the true value of this feature at a point ${\\mathbf{{p}}}$\nin parameter space (which has a dimension $N_p$) and ${\\mathbf{{C}}}$ be the\n$N_b\\times N_b$ feature covariance matrix. For the purpose of this\nwork ${\\mathbf{{p}}}$ is the triplet $(\\Omega_m,w,\\sigma_8)$ and ${\\mathbf{{d}}}$ is\none of the features -- either a power spectrum or a peak count\nhistogram -- in Table \\ref{featuretable}. Although existing emulators\ncan be used, in principle, to compute both ${\\mathbf{{d}}}({\\mathbf{{p}}})$ and\n${\\mathbf{{C}}}$, the latter is more difficult, and typically only the mean,\n${\\mathbf{{d}}}({\\mathbf{{p}}})$, has been computed to date\n(refs.~\\citep{coyote2,Nicaea}, but see an exception by\nref.~\\citep{SchneiderKnoxCovariance}).  Estimating ${\\mathbf{{C}}}$ from\nsimulations involves generating a series of mock realizations\n${\\mathbf{\\hat{{d}}}}_r$ with $r=1...N_r$ and computing the sample covariance\n${\\mathbf{\\hat{{C}}}}$,\n\n\n", "index": 3, "text": "\\begin{equation}\n{\\mathbf{{\\bar{d}}}} = \\frac{1}{N_r}\\sum_{r=1}^{N_r} {\\mathbf{\\hat{{d}}}}_r,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{{\\bar{d}}}}=\\frac{1}{N_{r}}\\sum_{r=1}^{N_{r}}{\\mathbf{\\hat{{d}}}}_{r},\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mi>r</mi></msub></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></munderover><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>r</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nAssuming a normal feature likelihood, together with a flat prior on\nthe parameter space, the parameter posterior distribution\n$\\mathcal{L}({\\mathbf{{p}}}\\vert{\\mathbf{\\hat{{d}}}}_{\\rm obs})$ given an observed instance of\n${\\mathbf{\\hat{{d}}}}$, which we call ${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, follows from Bayes' theorem,\n\n\n", "itemtype": "equation", "pos": 12590, "prevtext": "\n\n\n", "index": 5, "text": "\\begin{equation}\n\\label{covest}\n{\\mathbf{\\hat{{C}}}} = \\frac{1}{N_r-1}\\sum_{r=1}^{N_r} ({\\mathbf{\\hat{{d}}}}_r - \\bar{{\\mathbf{{d}}}}) ({\\mathbf{\\hat{{d}}}}_r - \\bar{{\\mathbf{{d}}}})^T.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{\\hat{{C}}}}=\\frac{1}{N_{r}-1}\\sum_{r=1}^{N_{r}}({\\mathbf{\\hat{{d}}}}_%&#10;{r}-\\bar{{\\mathbf{{d}}}})({\\mathbf{\\hat{{d}}}}_{r}-\\bar{{\\mathbf{{d}}}})^{T}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mi>r</mi></msub><mo>-</mo><mn>1</mn></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>r</mi></msub><mo>-</mo><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>r</mi></msub><mo>-</mo><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nFor the sake of simplicity, we approximate the posterior as a Gaussian\naround its maximum. This corresponds to Taylor-expanding the simulated\nfeature to first order around a point ${\\mathbf{{p}}}_0$ (ideally the maximum\nof Eq.~\\ref{posteriorbayes}):\n\n\n", "itemtype": "equation", "pos": 13115, "prevtext": "\n\nAssuming a normal feature likelihood, together with a flat prior on\nthe parameter space, the parameter posterior distribution\n$\\mathcal{L}({\\mathbf{{p}}}\\vert{\\mathbf{\\hat{{d}}}}_{\\rm obs})$ given an observed instance of\n${\\mathbf{\\hat{{d}}}}$, which we call ${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, follows from Bayes' theorem,\n\n\n", "index": 7, "text": "\\begin{equation}\n\\label{posteriorbayes}\n-2\\log\\mathcal{L}({\\mathbf{{p}}}\\vert{\\mathbf{\\hat{{d}}}}_{\\rm obs}) = [{\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}({\\mathbf{{p}}})]^T{\\mathbf{\\hat{{C}}}}^{-1}[{\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}({\\mathbf{{p}}})].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"-2\\log\\mathcal{L}({\\mathbf{{p}}}|{\\mathbf{\\hat{{d}}}}_{\\rm obs})=[{\\mathbf{%&#10;\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}({\\mathbf{{p}}})]^{T}{\\mathbf{\\hat{{C}}}}^%&#10;{-1}[{\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}({\\mathbf{{p}}})].\" display=\"block\"><mrow><mo>-</mo><mn>2</mn><mi>log</mi><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">|</mo><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy=\"false\">[</mo><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo>-</mo><mi>\ud835\udc1d</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><mi>T</mi></msup><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo stretchy=\"false\">[</mo><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo>-</mo><mi>\ud835\udc1d</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\nTo measure the derivatives of the features ${\\mathbf{{d}}}'_0$ with respect to\nthe cosmological parameters, we make use of the public code\n\\texttt{Nicaea} \\citep{Nicaea} for the power spectrum, and we use an\nindependent simulation set (containing simulations with a variety of\ndifferent combinations of $(\\Omega_m,w,\\sigma_8)$, see Table\n\\ref{simtable}) for the peak counts.\n\n\\begin{table*}\n\\begin{center}\n\\begin{tabular}{c|c|c||c|c}\n\\toprule\n$\\Omega_m$ &  $w$ & $\\sigma_8$ & $(N_s,N_r)$ & Number of $\\kappa$ ensembles \\\\ \\hline \\hline\n\\midrule\n\n0.26 & $-$1 & 0.8 & (1 to 200,1024) & 16 \\\\\n0.26 & $-$1 & 0.8 & (1,128000) & 1 \\\\\n0.29 & $-$1 & 0.8 & (1,1024) & 1 \\\\\n0.26 & $-$0.8 & 0.8 & (1,1024) & 1 \\\\\n0.26 & $-$1 & 0.6 & (1,1024) & 1 \\\\\n\n\\bottomrule\n\\end{tabular}\n\\end{center}\n\\caption{Summary of the shear ensembles used in this work. $N_s$ and\n  $N_r$ refer to the number of independent $N$--body simulations, and the\n  number of pseudo-independent realizations created from these\n  simulations, respectively.}\n\\label{simtable}\n\\end{table*}\n\nWe can build the estimator for the posterior maximum ${\\mathbf{\\hat{{p}}}}$, given\nthe observation ${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, as follows:\n\n\n", "itemtype": "equation", "pos": 13648, "prevtext": "\n\nFor the sake of simplicity, we approximate the posterior as a Gaussian\naround its maximum. This corresponds to Taylor-expanding the simulated\nfeature to first order around a point ${\\mathbf{{p}}}_0$ (ideally the maximum\nof Eq.~\\ref{posteriorbayes}):\n\n\n", "index": 9, "text": "\\begin{equation}\n{\\mathbf{{d}}}({\\mathbf{{p}}}) \\approx {\\mathbf{{d}}}_0 + {\\mathbf{{d}}}_0^\\prime({\\mathbf{{p}}}-{\\mathbf{{p}}}_0).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{{d}}}({\\mathbf{{p}}})\\approx{\\mathbf{{d}}}_{0}+{\\mathbf{{d}}}_{0}^{%&#10;\\prime}({\\mathbf{{p}}}-{\\mathbf{{p}}}_{0}).\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc1d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><msub><mi>\ud835\udc1d</mi><mn>0</mn></msub><mo>+</mo><mrow><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc29</mi><mo>-</mo><msub><mi>\ud835\udc29</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 14989, "prevtext": "\n\n\nTo measure the derivatives of the features ${\\mathbf{{d}}}'_0$ with respect to\nthe cosmological parameters, we make use of the public code\n\\texttt{Nicaea} \\citep{Nicaea} for the power spectrum, and we use an\nindependent simulation set (containing simulations with a variety of\ndifferent combinations of $(\\Omega_m,w,\\sigma_8)$, see Table\n\\ref{simtable}) for the peak counts.\n\n\\begin{table*}\n\\begin{center}\n\\begin{tabular}{c|c|c||c|c}\n\\toprule\n$\\Omega_m$ &  $w$ & $\\sigma_8$ & $(N_s,N_r)$ & Number of $\\kappa$ ensembles \\\\ \\hline \\hline\n\\midrule\n\n0.26 & $-$1 & 0.8 & (1 to 200,1024) & 16 \\\\\n0.26 & $-$1 & 0.8 & (1,128000) & 1 \\\\\n0.29 & $-$1 & 0.8 & (1,1024) & 1 \\\\\n0.26 & $-$0.8 & 0.8 & (1,1024) & 1 \\\\\n0.26 & $-$1 & 0.6 & (1,1024) & 1 \\\\\n\n\\bottomrule\n\\end{tabular}\n\\end{center}\n\\caption{Summary of the shear ensembles used in this work. $N_s$ and\n  $N_r$ refer to the number of independent $N$--body simulations, and the\n  number of pseudo-independent realizations created from these\n  simulations, respectively.}\n\\label{simtable}\n\\end{table*}\n\nWe can build the estimator for the posterior maximum ${\\mathbf{\\hat{{p}}}}$, given\nthe observation ${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, as follows:\n\n\n", "index": 11, "text": "\\begin{equation}\n\\label{estimatormean}\n{\\mathbf{\\hat{{p}}}} = {\\mathbf{{p}}}_0 + {\\mathbf{\\hat{{T}}}}({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{\\hat{{p}}}}={\\mathbf{{p}}}_{0}+{\\mathbf{\\hat{{T}}}}({\\mathbf{\\hat{{d}%&#10;}}}_{\\rm obs}-{\\mathbf{{d}}}_{0}),\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc29</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><msub><mi>\ud835\udc29</mi><mn>0</mn></msub><mo>+</mo><mrow><mover accent=\"true\"><mi>\ud835\udc13</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo>-</mo><msub><mi>\ud835\udc1d</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nBecause ${\\mathbf{\\hat{{p}}}}$ is estimated using a single noisy data instance\n${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, its estimate will be scattered around the true\nvalue $\\langle{\\mathbf{\\hat{{p}}}}\\rangle_O$. In the following we use the\n$\\langle\\rangle_O$ notation for expectation values taken with respect\nto observations, while we keep the notation $\\langle\\rangle$ for\nexpectation values taken with respect to the simulations. Defining the\n\\textit{precision matrix} ${\\mathbf{\\hat{{\\Psi}}}}={\\mathbf{\\hat{{C}}}}^{-1}$, we can express\nthe estimator of the observational scatter in ${\\mathbf{\\hat{{p}}}}$:\n\n\n", "itemtype": "equation", "pos": 15157, "prevtext": "\n\n\n", "index": 13, "text": "\\begin{equation}\n{\\mathbf{\\hat{{T}}}} = ({\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{C}}}}^{-1}{\\mathbf{{d}}}_0')^{-1}{\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{C}}}}^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{\\hat{{T}}}}=({\\mathbf{{d}}}_{0}^{\\prime T}{\\mathbf{\\hat{{C}}}}^{-1}{%&#10;\\mathbf{{d}}}_{0}^{\\prime})^{-1}{\\mathbf{{d}}}_{0}^{\\prime T}{\\mathbf{\\hat{{C}%&#10;}}}^{-1}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc13</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 15932, "prevtext": "\n\nBecause ${\\mathbf{\\hat{{p}}}}$ is estimated using a single noisy data instance\n${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, its estimate will be scattered around the true\nvalue $\\langle{\\mathbf{\\hat{{p}}}}\\rangle_O$. In the following we use the\n$\\langle\\rangle_O$ notation for expectation values taken with respect\nto observations, while we keep the notation $\\langle\\rangle$ for\nexpectation values taken with respect to the simulations. Defining the\n\\textit{precision matrix} ${\\mathbf{\\hat{{\\Psi}}}}={\\mathbf{\\hat{{C}}}}^{-1}$, we can express\nthe estimator of the observational scatter in ${\\mathbf{\\hat{{p}}}}$:\n\n\n", "index": 15, "text": "\\begin{equation}\n\\label{estimatorcovariance}\n{\\hat{{\\Sigma}}}_{\\mathbf{{p}}} = {\\mathbf{\\hat{{F}}}}^{-1}{\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{\\Psi}}}}\\langle({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)^T\\rangle_O{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_0'{\\mathbf{\\hat{{F}}}}^{-1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}={\\mathbf{\\hat{{F}}}}^{-1}{\\mathbf{{d}}}_{0}^{%&#10;\\prime T}{\\mathbf{\\hat{{\\Psi}}}}\\langle({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{%&#10;\\mathbf{{d}}}_{0})({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_{0})^{T}%&#10;\\rangle_{O}{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_{0}^{\\prime}{\\mathbf{\\hat{{F}%&#10;}}}^{-1},\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo>=</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo>-</mo><msub><mi>\ud835\udc1d</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>\ud835\udc1d</mi><mo stretchy=\"false\">^</mo></mover><mi>obs</mi></msub><mo>-</mo><msub><mi>\ud835\udc1d</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mi>O</mi></msub><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nHere we introduced the familiar Fisher matrix estimator ${\\mathbf{\\hat{{F}}}} =\n{\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_0'$ and, for simplicity, we assumed\n$\\langle{\\mathbf{\\hat{{d}}}}_{\\rm obs}\\rangle_O={\\mathbf{{d}}}_0$, so that\n$\\langle({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)^T\\rangle_O={\\mathbf{{C}}}$.  When we perform an observation\n${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, the parameter estimate ${\\mathbf{\\hat{{p}}}}$ is a random draw\nfrom a probability distribution with variance ${\\hat{{\\Sigma}}}_{\\mathbf{{p}}}$,\nwhich inherits noise from the simulations. The noise in the covariance\nestimator (Eq.~\\ref{covest}) and in its inverse ${\\mathbf{\\hat{{\\Psi}}}}$ propagate\nall the way to the posterior (Eq.~\\ref{posteriorbayes}), the parameter\nestimate (Eq.~\\ref{estimatormean}) and its variance\n(Eq.~\\ref{estimatorcovariance}). Following\nrefs.~\\citep{DodelsonSchneider13,Taylor12,MasumotoWishart} we compute\nthe expectation value of Eq.~(\\ref{estimatorcovariance}) over\nsimulations, $\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle$, up to $O(1/N_r^2)$ by\nexpanding Eq.~(\\ref{estimatorcovariance}) to quartic order in the\nstatistical fluctuations of ${\\mathbf{\\hat{{\\Psi}}}}$. Denoting the noiseless\nparameter covariance, i.e. the usual Fisher matrix, as\n$\\Sigma_{\\mathbf{{p}}}={\\mathbf{{F}}}^{-1}$, we find the result~\\footnote{The details\n  of the calculation are given in Appendix A.}:\n\n\\begin{widetext}\n\n", "itemtype": "equation", "pos": 16277, "prevtext": "\n\n\n", "index": 17, "text": "\\begin{equation}\n\\label{estimatorfisher}\n{\\mathbf{\\hat{{F}}}} = {\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_0'.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{\\hat{{F}}}}={\\mathbf{{d}}}_{0}^{\\prime T}{\\mathbf{\\hat{{\\Psi}}}}{%&#10;\\mathbf{{d}}}_{0}^{\\prime}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\\end{widetext}\n\nNext, we restrict ourselves to the large $N_r$ limit, and we further\ninvestigate the behavior of the $O(1/N_r)$ term. We consider three\ncases \\footnote{The details of these calculations are given in Appendix B}:\n\n\n\\begin{enumerate}\n\\item If the true data covariance ${\\mathbf{{C}}}$ is known, the estimator in\n  eq.~(\\ref{estimatorcovariance}) is biased, and the dominant\n  contribution of the bias comes from the second order fluctuations in\n  ${\\mathbf{\\hat{{\\Psi}}}}$. Once the expectation values over simulations are\n  taken, the bias sums up to\n\n\n", "itemtype": "equation", "pos": 17899, "prevtext": "\n\nHere we introduced the familiar Fisher matrix estimator ${\\mathbf{\\hat{{F}}}} =\n{\\mathbf{{d}}}_0'^T{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_0'$ and, for simplicity, we assumed\n$\\langle{\\mathbf{\\hat{{d}}}}_{\\rm obs}\\rangle_O={\\mathbf{{d}}}_0$, so that\n$\\langle({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)({\\mathbf{\\hat{{d}}}}_{\\rm obs}-{\\mathbf{{d}}}_0)^T\\rangle_O={\\mathbf{{C}}}$.  When we perform an observation\n${\\mathbf{\\hat{{d}}}}_{\\rm obs}$, the parameter estimate ${\\mathbf{\\hat{{p}}}}$ is a random draw\nfrom a probability distribution with variance ${\\hat{{\\Sigma}}}_{\\mathbf{{p}}}$,\nwhich inherits noise from the simulations. The noise in the covariance\nestimator (Eq.~\\ref{covest}) and in its inverse ${\\mathbf{\\hat{{\\Psi}}}}$ propagate\nall the way to the posterior (Eq.~\\ref{posteriorbayes}), the parameter\nestimate (Eq.~\\ref{estimatormean}) and its variance\n(Eq.~\\ref{estimatorcovariance}). Following\nrefs.~\\citep{DodelsonSchneider13,Taylor12,MasumotoWishart} we compute\nthe expectation value of Eq.~(\\ref{estimatorcovariance}) over\nsimulations, $\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle$, up to $O(1/N_r^2)$ by\nexpanding Eq.~(\\ref{estimatorcovariance}) to quartic order in the\nstatistical fluctuations of ${\\mathbf{\\hat{{\\Psi}}}}$. Denoting the noiseless\nparameter covariance, i.e. the usual Fisher matrix, as\n$\\Sigma_{\\mathbf{{p}}}={\\mathbf{{F}}}^{-1}$, we find the result~\\footnote{The details\n  of the calculation are given in Appendix A.}:\n\n\\begin{widetext}\n\n", "index": 19, "text": "\\begin{equation}\n\\label{quarticdegradation}\n\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle = \\Sigma_{\\mathbf{{p}}}\\left[1+\\frac{N_b-N_p}{N_r}+\\frac{(N_b-N_p)(N_b-N_p+2)}{N_r^2}\\right] + O\\left(\\frac{1}{N_r^3}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left[1+%&#10;\\frac{N_{b}-N_{p}}{N_{r}}+\\frac{(N_{b}-N_{p})(N_{b}-N_{p}+2)}{N_{r}^{2}}\\right%&#10;]+O\\left(\\frac{1}{N_{r}^{3}}\\right).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac><mo>+</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo>+</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msubsup><mi>N</mi><mi>r</mi><mn>2</mn></msubsup></mfrac></mrow><mo>]</mo></mrow></mrow><mo>+</mo><mrow><mi>O</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mn>1</mn><msubsup><mi>N</mi><mi>r</mi><mn>3</mn></msubsup></mfrac><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nThis is the result obtained by ref.~\\citep{DodelsonSchneider13}.\n\n\\item Usually the true data covariance is unknown, and it is tempting\n  to plug in its estimator ${\\mathbf{\\hat{{C}}}}$, measured from the same\n  simulation set we use to compute ${\\mathbf{\\hat{{\\Psi}}}}$. This approach has\n  been used before in the literature\n  (e.g.~\\citep{MinkPetri,MinkShirasaki}). If this is done without\n  correcting for the bias in ${\\mathbf{\\hat{{\\Psi}}}}$ (see Ref.~\\citep{Taylor12}\n  and eq.~\\ref{firstmoment} below), the parameter variance will have a\n  contribution from both the second and first-order fluctuations in\n  ${\\mathbf{\\hat{{\\Psi}}}}$, which now have a nonzero expectation value. In this\n  case the bias sums up to\n\n\n", "itemtype": "equation", "pos": 18697, "prevtext": "\n\\end{widetext}\n\nNext, we restrict ourselves to the large $N_r$ limit, and we further\ninvestigate the behavior of the $O(1/N_r)$ term. We consider three\ncases \\footnote{The details of these calculations are given in Appendix B}:\n\n\n\\begin{enumerate}\n\\item If the true data covariance ${\\mathbf{{C}}}$ is known, the estimator in\n  eq.~(\\ref{estimatorcovariance}) is biased, and the dominant\n  contribution of the bias comes from the second order fluctuations in\n  ${\\mathbf{\\hat{{\\Psi}}}}$. Once the expectation values over simulations are\n  taken, the bias sums up to\n\n\n", "index": 21, "text": "\\begin{equation}\n\\label{dodelsonscaling}\n\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1+\\frac{N_b-N_p}{N_r}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1+%&#10;\\frac{N_{b}-N_{p}}{N_{r}}\\right).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\\item If we repeat the same exercise as above, but we correct for the\n  bias in the precision matrix estimator, we are left with\n\n\n", "itemtype": "equation", "pos": 19580, "prevtext": "\n\nThis is the result obtained by ref.~\\citep{DodelsonSchneider13}.\n\n\\item Usually the true data covariance is unknown, and it is tempting\n  to plug in its estimator ${\\mathbf{\\hat{{C}}}}$, measured from the same\n  simulation set we use to compute ${\\mathbf{\\hat{{\\Psi}}}}$. This approach has\n  been used before in the literature\n  (e.g.~\\citep{MinkPetri,MinkShirasaki}). If this is done without\n  correcting for the bias in ${\\mathbf{\\hat{{\\Psi}}}}$ (see Ref.~\\citep{Taylor12}\n  and eq.~\\ref{firstmoment} below), the parameter variance will have a\n  contribution from both the second and first-order fluctuations in\n  ${\\mathbf{\\hat{{\\Psi}}}}$, which now have a nonzero expectation value. In this\n  case the bias sums up to\n\n\n", "index": 23, "text": "\\begin{equation}\n\\label{mockscalinguncorrected}\n\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1-\\frac{N_b-N_p}{N_r}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1-%&#10;\\frac{N_{b}-N_{p}}{N_{r}}\\right).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\\end{enumerate} \n\nThe error degradation in each parameter $p$, at leading order, scales\nas $D/N_r$, where $D=N_b-N_p$, $N_p-N_b$, and $1+N_p$ for cases 1, 2,\nand 3, respectively.  Note that in the last case, which is most\nrelevant when fitting actual data, the estimated degradation turns out\nto be too optimistic: the parameter estimate ${\\mathbf{\\hat{{p}}}}$ has a variance\nwhose noise grows linearly with $N_b$ (eq.~\\ref{quarticdegradation}),\nwhereas the degradation estimated via eq. (\\ref{mockscalingcorrected})\nis constant with $N_b$. This can lead to underestimation of error\nbars, which can be mistakenly interpreted as a parameter bias. We test\nscaling relations of the form\n\n\n", "itemtype": "equation", "pos": 19877, "prevtext": "\n\n\\item If we repeat the same exercise as above, but we correct for the\n  bias in the precision matrix estimator, we are left with\n\n\n", "index": 25, "text": "\\begin{equation}\n\\label{mockscalingcorrected}\n\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1+\\frac{1+N_p}{N_r}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1+%&#10;\\frac{1+N_{p}}{N_{r}}\\right).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><mn>1</mn><mo>+</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nagainst our simulations, in the limits of both high and low $N_r$.  We\nindicate the diagonal elements of ${\\hat{{\\Sigma}}}_{{\\mathbf{{p}}}}$ as\n${\\hat{{\\sigma}}}^2_p=\\mathrm{diag}({\\hat{{\\Sigma}}}_{{\\mathbf{{p}}}})$ and we indicate by\n$\\sigma^2_{p,\\infty}$ the expectation value of the variance of each\nparameter in the limit of an infinite number of realizations\n$N_r\\rightarrow\\infty$.  We call $D$ the \\textit{effective\n  dimensionality} of the feature space (which, as seen before, can be\nnegative in some pathological cases).  We compute the expectation\nvalues of ${\\hat{{\\sigma}}}^2_p$ (eqs.~\\ref{estimatorcovariance} and\n\\ref{ourscaling}) by averaging over 100 random resamplings of our\nshear ensembles. For the true feature covariance matrix\n$\\langle({\\mathbf{\\hat{{d}}}}-{\\mathbf{{d}}}_0)({\\mathbf{\\hat{{d}}}}-{\\mathbf{{d}}}_0)^T\\rangle={\\mathbf{{C}}}$ we use\nthe estimated covariance from a grand ensemble built with the union of\nall the ensembles with different $N_s$.\n\nThe true parameter variance $\\sigma^2_{p,\\infty}(N_s)$ in principle\ncan depend on the number of independent $N$--body simulations $N_s$,\nwhich appears in the randomization procedure described in\n\\S~\\ref{shearsim} above. This is because if $N_s$ is not large enough,\nthe different shear realizations cannot be all independent, and hence\nthe true variance $\\sigma^2_{p,\\infty}(N_s\\rightarrow\\infty)$ cannot\nbe recovered for low $N_s$ even if $N_r$ is arbitrarily large. In the\nnext section, we present our main findings.\n \n\n\n\n\\section{Results} \n\n\n\n\\begin{figure*}\n\\includegraphics[scale=0.4]{ps_pdf.eps}\n\\caption{PDF of the $\\kappa$ power spectrum\n  $\\mathcal{L}(P_l^{\\kappa\\kappa})$ at four selected multipoles\n  $\\ell=115,344,1349,5283$, for different shear ensembles constructed\n  from on $N_s=$1 (black), 2 (blue), 5 (green), 50 (red), and 100\n  (purple) independent $N$--body simulations. Each curve is based on\n  $N_r=1024$ realizations.  The dashed black curves correspond to\n  ensembles generated with $N_s=1$ and $N_r=128000$. For $N_s\\geq2$,\n  the distributions appear similar to the eye; this similarity is\n  confirmed by the comparisons in Figures \\ref{means_ns} and\n  \\ref{ps_var} below.}\n\\label{ps_pdf}\n\\end{figure*}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{means_ns.eps}\n\\caption{The mean value ${\\mathbf{{\\bar{d}}}}$ of various features, measured\n  from ensembles created from different numbers $N_s$ of simulations.\n  For each case, the difference compared to the mean in the $N_s=200$\n  ensemble is shown, in units of the statistical error measured in the\n  $N_s=200$ ensemble.  The colored curves refer to shear--shear power\n  spectra measured at $\\ell=115$ (black), 1027 (cyan), and 5283\n  (green), and peak counts with heights $\\kappa_0=0.05$ (red), 0.17\n  (purple), and 0.28 (orange). The $\\kappa$ bin width for the peak\n  counts has been fixed to $\\Delta\\kappa=0.011$. The dashed black line\n  shows a level of $0.1\\sigma$ accuracy for reference.  For $N_s\\geq\n  2$, the means are statistically indistinguishable (even at\n  $\\sim0.1\\sigma$) from those in the ensemble with $N_s=200$.}\n\\label{means_ns}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{ps_variance.eps}\n\\caption{Variance of the $\\kappa$ power spectrum as a function of the\n  multipole $\\ell$, in units of the expected Gaussian variance from\n  equation (\\ref{gaussianvar}). The variance is measured from\n  different shear ensembles based on $N_s=$1 (black), 2 (blue), 5\n  (green), 10 (red), 50 (purple), or 100 (orange) N--body simulations.\n  Non--Gaussianities of the underlying structures increase the\n  variance on small scales, but no clear trend with $N_s$ can be\n  identied on any scale.}\n\\label{ps_var}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{curving_nb.eps}\n\\caption{Expectation value of the variance of $w$ computed from\n  equation (\\ref{estimatorcovariance}), shown as a function of\n  $1/N_r$. The different symbols and colors correspond to the features\n  listed in Table~\\ref{featuretable}.  The dashed and solid curves\n  show the analytic predictions from equation\n  (\\ref{quarticdegradation}) at orders $O(1/N_r)$ and $O(1/N_r^2)$,\n  respectively. The asymptotic variance $\\sigma^2_{w,\\infty}$ has been\n  computed from a linear regression of $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$\n  vs $1/N_r$ for $N_r>500$. The figure clearly shows that terms beyond\n  $O(1/N_r)$ need to be considered, unless $N_r\\gg N_b$.}\n\\label{curvingnb}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{scaling_nr.eps}\n\\caption{Bias in the variance of $w$,\n  $\\langle{\\hat{{\\sigma}}}^2_w\\rangle-\\sigma^2_{w,\\infty}$, as a function of\n  the number of realizations $N_r$ used to estimate the covariance\n  (eq.~\\ref{covest}). The figure shows both the trend measured in the\n  simulations (solid lines) and their scaling expected from\n  Eq.~(\\ref{ourscaling}) with $D=N_b-N_p$ (dashed lines). The\n  asymptotic variance $\\sigma^2_{w,\\infty}$ has been estimated to be the value $\\langle{\\hat{{\\sigma}}}^2_w\\rangle(N_r=10^5)$. Different features are considered: power spectra with logarithmically spaced $\\ell\\in[100,6000]$ (black), $\\ell\\in[100,250]$ (red), peak counts in the unsmoothed maps with height $\\kappa_0\\in[0.44,0.48]$ (green) and peak counts in the smoothed maps (with a Gaussian kernel of size $\\theta_G=1^\\prime$) with height $\\kappa_0>0.15$ (blue). No deviations from the expected $1/N_r$ behavior are observed up to $N_r\\approx{\\rm few}\\times10^4$, except for the large-scale power spectrum, in which case the deviations occur much earlier ($N_r\\approx 10^3$).}\n\\label{wvar_nr}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{scaling_ns.eps}\n\\caption{The variance of $w$ in the limit of $N_r\\rightarrow\\infty$\n  (measured from the intercept of the fit $\\sigma^2_w$ vs $1/N_r$),\n  varying the number of simulations $N_s$ used in the ensemble to\n  estimate the covariance (eq.~\\ref{covest}). We show the dependence\n  of $\\sigma_{w,\\infty}^2(N_s)$ in units of the mean over the 16\n  ensembles with different $N_s$, for the power spectrum\n  logarithmically binned (black, $N_b=15,\\ell\\in[100,6000]$), the\n  power spectrum linearly binned (red,$N_b=39,\\ell\\in[100,6000]$) and\n  the peak counts (green,$N_b=45,\\kappa_0\\in[-0.06,0.45]$).  No trend\n  with $N_s$ is seen for $N_s\\geq 2$, and the differences are only of\n  order 1\\%.}\n\\label{wvar_ns}\n\\end{figure}\n\n\\begin{table*}\n\\begin{center}\n\\begin{tabular}{ccccc}\n\\toprule\n\\textbf{Feature} &  \\textbf{Specifications} & $N_b$ &  \\textbf{Symbol} & \\textbf{Color} \\\\ \\hline \\hline\n\\midrule\nPower Spectrum, log binning  & $\\ell \\in [100,800] $ & 8 & $\\times$ & black  \\\\ \nPower Spectrum, log binning  & $\\ell \\in [1000,6000] $ & 7 & $\\blacksquare$ & black  \\\\ \nPower Spectrum, log binning  & $\\ell \\in [100,6000] $ & 15 & \\textcolor{red}{$\\bullet$} & \\textcolor{red}{red}  \\\\\nPower Spectrum, linear binning  & $\\ell \\in [100,2000] $ & 15 & \\textcolor{red}{$+$} & \\textcolor{red}{red}  \\\\ \nPower Spectrum, linear binning  & $\\ell \\in [2500,4500] $ & 15 & \\textcolor{red}{$\\times$} & \\textcolor{red}{red}  \\\\\nPower Spectrum, linear binning  & $\\ell \\in [100,4500] $ & 30 & \\textcolor{OliveGreen}{$\\bullet$} & \\textcolor{OliveGreen}{green}  \\\\ \nPower Spectrum, linear binning  & $\\ell \\in [100,6000] $ & 39 & \\textcolor{blue}{$\\bullet$} & \\textcolor{blue}{blue}  \\\\ \\hline\nLow peaks  & $\\kappa_0 \\in [-0.06,0.09] $ & 15 & \\textcolor{red}{$+$} & \\textcolor{red}{red}  \\\\ \nIntermediate peaks  & $\\kappa_0 \\in [0.1,0.27] $ & 15 & \\textcolor{red}{$\\bigstar$} & \\textcolor{red}{red}  \\\\ \nHigh peaks  & $\\kappa_0 \\in [0.28,0.45] $ & 15 & \\textcolor{red}{$\\diamond$} & \\textcolor{red}{red}  \\\\\nLow+Intermediate peaks  & $\\kappa_0 \\in [-0.06,0.27] $ & 30 & \\textcolor{OliveGreen}{$\\times$} & \\textcolor{OliveGreen}{green}  \\\\\nIntermediate+High peaks  & $\\kappa_0 \\in [0.1,0.45] $ & 30 & \\textcolor{OliveGreen}{$\\blacksquare$} & \\textcolor{OliveGreen}{green}  \\\\\nAll peaks  & $\\kappa_0 \\in [-0.06,0.45] $ & 45 & \\textcolor{magenta}{$\\blacksquare$} & \\textcolor{magenta}{magenta}  \\\\ \\hline\n\\bottomrule\n\\end{tabular}\n\\end{center}\n\\caption{Catalog of feature types used in this work, along with the\n  chosen number of bands $N_b$ and the plot legends for Figure\n  \\ref{curvingnb}.}\n\\label{featuretable}\n\\end{table*}\n\n\n\nIn this section we present the main results of this work. We show the\nqualitative behavior of a variety of feature ${\\mathbf{\\hat{{d}}}}_r$ probability\ndistribution functions (PDFs) in ensembles built with different $N_s$\nand $N_r$. In Figure~\\ref{ps_pdf}, we show the PDF of the power\nspectrum at four selected multipoles, spanning the linear ($\\ell=115$)\nto the nonlinear ($\\ell=5283$) regime. In Figure~\\ref{means_ns}, we\nshows the ensemble mean for these power spectra, as well as for peak\ncounts of three different $\\kappa_0$ heights (corresponding to\n$\\approx 2-13\\sigma$ peaks), as a function of $N_s$.  In\nFigure~\\ref{ps_var}, we show the variance of the power spectrum at\neach multipole, as a function of $N_s$, in units of the variance\nexpected if the convergence $\\kappa$ was a Gaussian random field\n\n\n", "itemtype": "equation", "pos": 20725, "prevtext": "\n\n\\end{enumerate} \n\nThe error degradation in each parameter $p$, at leading order, scales\nas $D/N_r$, where $D=N_b-N_p$, $N_p-N_b$, and $1+N_p$ for cases 1, 2,\nand 3, respectively.  Note that in the last case, which is most\nrelevant when fitting actual data, the estimated degradation turns out\nto be too optimistic: the parameter estimate ${\\mathbf{\\hat{{p}}}}$ has a variance\nwhose noise grows linearly with $N_b$ (eq.~\\ref{quarticdegradation}),\nwhereas the degradation estimated via eq. (\\ref{mockscalingcorrected})\nis constant with $N_b$. This can lead to underestimation of error\nbars, which can be mistakenly interpreted as a parameter bias. We test\nscaling relations of the form\n\n\n", "index": 27, "text": "\\begin{equation}\n\\label{ourscaling}\n\\langle{\\hat{{\\sigma}}}_p^2\\rangle = \\sigma^2_{p,\\infty}(N_s)\\left(1+\\frac{D}{N_r}\\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\sigma}}}_{p}^{2}\\rangle=\\sigma^{2}_{p,\\infty}(N_{s})\\left(1+%&#10;\\frac{D}{N_{r}}\\right)\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msubsup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">^</mo></mover><mi>p</mi><mn>2</mn></msubsup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msubsup><mi>\u03c3</mi><mrow><mi>p</mi><mo>,</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>N</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mi>D</mi><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nHere $N_{\\rm eff}(l)$ is the number of independent modes used to\nestimate the power spectrum at $\\ell$.  \n\nIn practice, we measure $P^{\\kappa\\kappa}_\\ell$ on the Fourier\ntransform of the pixelized simulated map $\\kappa_r(\\pmb{\\theta})$,\nusing the FFT algorithm, and some care must be taken to count the\nnumber of modes $N_{\\rm eff}(\\ell)$ correctly. Each pixel $(i_x,j_y)$\nin Fourier space corresponds to a mode\n$(\\ell_x,\\ell_y)=2\\pi(i_x,i_y)/\\theta_{\\rm box}$, with $i_x=-n_{\\rm\n  ray}/2,...,n_{\\rm ray}/2$ and $i_y=0,...,n_{\\rm ray}/2$.  Here\n$n_{\\rm ray}=2048$ is the linear number of pixels on the ray--traced\nconvergence maps.  We count the number of pixels $N(\\ell)$ that fall\ninside a multipole bin $(\\ell_1,\\ell_2)$. Because the $\\kappa$ field\nis real, the modes $(\\pm \\ell_x,0)$ are not independent. If we let\n$N(\\ell,\\ell_y=0)$ be the number of non--independent modes, the\neffective number of independent modes for the variance is given by\n\n\n", "itemtype": "equation", "pos": 29929, "prevtext": "\n\nagainst our simulations, in the limits of both high and low $N_r$.  We\nindicate the diagonal elements of ${\\hat{{\\Sigma}}}_{{\\mathbf{{p}}}}$ as\n${\\hat{{\\sigma}}}^2_p=\\mathrm{diag}({\\hat{{\\Sigma}}}_{{\\mathbf{{p}}}})$ and we indicate by\n$\\sigma^2_{p,\\infty}$ the expectation value of the variance of each\nparameter in the limit of an infinite number of realizations\n$N_r\\rightarrow\\infty$.  We call $D$ the \\textit{effective\n  dimensionality} of the feature space (which, as seen before, can be\nnegative in some pathological cases).  We compute the expectation\nvalues of ${\\hat{{\\sigma}}}^2_p$ (eqs.~\\ref{estimatorcovariance} and\n\\ref{ourscaling}) by averaging over 100 random resamplings of our\nshear ensembles. For the true feature covariance matrix\n$\\langle({\\mathbf{\\hat{{d}}}}-{\\mathbf{{d}}}_0)({\\mathbf{\\hat{{d}}}}-{\\mathbf{{d}}}_0)^T\\rangle={\\mathbf{{C}}}$ we use\nthe estimated covariance from a grand ensemble built with the union of\nall the ensembles with different $N_s$.\n\nThe true parameter variance $\\sigma^2_{p,\\infty}(N_s)$ in principle\ncan depend on the number of independent $N$--body simulations $N_s$,\nwhich appears in the randomization procedure described in\n\\S~\\ref{shearsim} above. This is because if $N_s$ is not large enough,\nthe different shear realizations cannot be all independent, and hence\nthe true variance $\\sigma^2_{p,\\infty}(N_s\\rightarrow\\infty)$ cannot\nbe recovered for low $N_s$ even if $N_r$ is arbitrarily large. In the\nnext section, we present our main findings.\n \n\n\n\n\\section{Results} \n\n\n\n\\begin{figure*}\n\\includegraphics[scale=0.4]{ps_pdf.eps}\n\\caption{PDF of the $\\kappa$ power spectrum\n  $\\mathcal{L}(P_l^{\\kappa\\kappa})$ at four selected multipoles\n  $\\ell=115,344,1349,5283$, for different shear ensembles constructed\n  from on $N_s=$1 (black), 2 (blue), 5 (green), 50 (red), and 100\n  (purple) independent $N$--body simulations. Each curve is based on\n  $N_r=1024$ realizations.  The dashed black curves correspond to\n  ensembles generated with $N_s=1$ and $N_r=128000$. For $N_s\\geq2$,\n  the distributions appear similar to the eye; this similarity is\n  confirmed by the comparisons in Figures \\ref{means_ns} and\n  \\ref{ps_var} below.}\n\\label{ps_pdf}\n\\end{figure*}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{means_ns.eps}\n\\caption{The mean value ${\\mathbf{{\\bar{d}}}}$ of various features, measured\n  from ensembles created from different numbers $N_s$ of simulations.\n  For each case, the difference compared to the mean in the $N_s=200$\n  ensemble is shown, in units of the statistical error measured in the\n  $N_s=200$ ensemble.  The colored curves refer to shear--shear power\n  spectra measured at $\\ell=115$ (black), 1027 (cyan), and 5283\n  (green), and peak counts with heights $\\kappa_0=0.05$ (red), 0.17\n  (purple), and 0.28 (orange). The $\\kappa$ bin width for the peak\n  counts has been fixed to $\\Delta\\kappa=0.011$. The dashed black line\n  shows a level of $0.1\\sigma$ accuracy for reference.  For $N_s\\geq\n  2$, the means are statistically indistinguishable (even at\n  $\\sim0.1\\sigma$) from those in the ensemble with $N_s=200$.}\n\\label{means_ns}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{ps_variance.eps}\n\\caption{Variance of the $\\kappa$ power spectrum as a function of the\n  multipole $\\ell$, in units of the expected Gaussian variance from\n  equation (\\ref{gaussianvar}). The variance is measured from\n  different shear ensembles based on $N_s=$1 (black), 2 (blue), 5\n  (green), 10 (red), 50 (purple), or 100 (orange) N--body simulations.\n  Non--Gaussianities of the underlying structures increase the\n  variance on small scales, but no clear trend with $N_s$ can be\n  identied on any scale.}\n\\label{ps_var}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{curving_nb.eps}\n\\caption{Expectation value of the variance of $w$ computed from\n  equation (\\ref{estimatorcovariance}), shown as a function of\n  $1/N_r$. The different symbols and colors correspond to the features\n  listed in Table~\\ref{featuretable}.  The dashed and solid curves\n  show the analytic predictions from equation\n  (\\ref{quarticdegradation}) at orders $O(1/N_r)$ and $O(1/N_r^2)$,\n  respectively. The asymptotic variance $\\sigma^2_{w,\\infty}$ has been\n  computed from a linear regression of $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$\n  vs $1/N_r$ for $N_r>500$. The figure clearly shows that terms beyond\n  $O(1/N_r)$ need to be considered, unless $N_r\\gg N_b$.}\n\\label{curvingnb}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{scaling_nr.eps}\n\\caption{Bias in the variance of $w$,\n  $\\langle{\\hat{{\\sigma}}}^2_w\\rangle-\\sigma^2_{w,\\infty}$, as a function of\n  the number of realizations $N_r$ used to estimate the covariance\n  (eq.~\\ref{covest}). The figure shows both the trend measured in the\n  simulations (solid lines) and their scaling expected from\n  Eq.~(\\ref{ourscaling}) with $D=N_b-N_p$ (dashed lines). The\n  asymptotic variance $\\sigma^2_{w,\\infty}$ has been estimated to be the value $\\langle{\\hat{{\\sigma}}}^2_w\\rangle(N_r=10^5)$. Different features are considered: power spectra with logarithmically spaced $\\ell\\in[100,6000]$ (black), $\\ell\\in[100,250]$ (red), peak counts in the unsmoothed maps with height $\\kappa_0\\in[0.44,0.48]$ (green) and peak counts in the smoothed maps (with a Gaussian kernel of size $\\theta_G=1^\\prime$) with height $\\kappa_0>0.15$ (blue). No deviations from the expected $1/N_r$ behavior are observed up to $N_r\\approx{\\rm few}\\times10^4$, except for the large-scale power spectrum, in which case the deviations occur much earlier ($N_r\\approx 10^3$).}\n\\label{wvar_nr}\n\\end{figure}\n\n\\begin{figure}\n\\includegraphics[scale=0.3]{scaling_ns.eps}\n\\caption{The variance of $w$ in the limit of $N_r\\rightarrow\\infty$\n  (measured from the intercept of the fit $\\sigma^2_w$ vs $1/N_r$),\n  varying the number of simulations $N_s$ used in the ensemble to\n  estimate the covariance (eq.~\\ref{covest}). We show the dependence\n  of $\\sigma_{w,\\infty}^2(N_s)$ in units of the mean over the 16\n  ensembles with different $N_s$, for the power spectrum\n  logarithmically binned (black, $N_b=15,\\ell\\in[100,6000]$), the\n  power spectrum linearly binned (red,$N_b=39,\\ell\\in[100,6000]$) and\n  the peak counts (green,$N_b=45,\\kappa_0\\in[-0.06,0.45]$).  No trend\n  with $N_s$ is seen for $N_s\\geq 2$, and the differences are only of\n  order 1\\%.}\n\\label{wvar_ns}\n\\end{figure}\n\n\\begin{table*}\n\\begin{center}\n\\begin{tabular}{ccccc}\n\\toprule\n\\textbf{Feature} &  \\textbf{Specifications} & $N_b$ &  \\textbf{Symbol} & \\textbf{Color} \\\\ \\hline \\hline\n\\midrule\nPower Spectrum, log binning  & $\\ell \\in [100,800] $ & 8 & $\\times$ & black  \\\\ \nPower Spectrum, log binning  & $\\ell \\in [1000,6000] $ & 7 & $\\blacksquare$ & black  \\\\ \nPower Spectrum, log binning  & $\\ell \\in [100,6000] $ & 15 & \\textcolor{red}{$\\bullet$} & \\textcolor{red}{red}  \\\\\nPower Spectrum, linear binning  & $\\ell \\in [100,2000] $ & 15 & \\textcolor{red}{$+$} & \\textcolor{red}{red}  \\\\ \nPower Spectrum, linear binning  & $\\ell \\in [2500,4500] $ & 15 & \\textcolor{red}{$\\times$} & \\textcolor{red}{red}  \\\\\nPower Spectrum, linear binning  & $\\ell \\in [100,4500] $ & 30 & \\textcolor{OliveGreen}{$\\bullet$} & \\textcolor{OliveGreen}{green}  \\\\ \nPower Spectrum, linear binning  & $\\ell \\in [100,6000] $ & 39 & \\textcolor{blue}{$\\bullet$} & \\textcolor{blue}{blue}  \\\\ \\hline\nLow peaks  & $\\kappa_0 \\in [-0.06,0.09] $ & 15 & \\textcolor{red}{$+$} & \\textcolor{red}{red}  \\\\ \nIntermediate peaks  & $\\kappa_0 \\in [0.1,0.27] $ & 15 & \\textcolor{red}{$\\bigstar$} & \\textcolor{red}{red}  \\\\ \nHigh peaks  & $\\kappa_0 \\in [0.28,0.45] $ & 15 & \\textcolor{red}{$\\diamond$} & \\textcolor{red}{red}  \\\\\nLow+Intermediate peaks  & $\\kappa_0 \\in [-0.06,0.27] $ & 30 & \\textcolor{OliveGreen}{$\\times$} & \\textcolor{OliveGreen}{green}  \\\\\nIntermediate+High peaks  & $\\kappa_0 \\in [0.1,0.45] $ & 30 & \\textcolor{OliveGreen}{$\\blacksquare$} & \\textcolor{OliveGreen}{green}  \\\\\nAll peaks  & $\\kappa_0 \\in [-0.06,0.45] $ & 45 & \\textcolor{magenta}{$\\blacksquare$} & \\textcolor{magenta}{magenta}  \\\\ \\hline\n\\bottomrule\n\\end{tabular}\n\\end{center}\n\\caption{Catalog of feature types used in this work, along with the\n  chosen number of bands $N_b$ and the plot legends for Figure\n  \\ref{curvingnb}.}\n\\label{featuretable}\n\\end{table*}\n\n\n\nIn this section we present the main results of this work. We show the\nqualitative behavior of a variety of feature ${\\mathbf{\\hat{{d}}}}_r$ probability\ndistribution functions (PDFs) in ensembles built with different $N_s$\nand $N_r$. In Figure~\\ref{ps_pdf}, we show the PDF of the power\nspectrum at four selected multipoles, spanning the linear ($\\ell=115$)\nto the nonlinear ($\\ell=5283$) regime. In Figure~\\ref{means_ns}, we\nshows the ensemble mean for these power spectra, as well as for peak\ncounts of three different $\\kappa_0$ heights (corresponding to\n$\\approx 2-13\\sigma$ peaks), as a function of $N_s$.  In\nFigure~\\ref{ps_var}, we show the variance of the power spectrum at\neach multipole, as a function of $N_s$, in units of the variance\nexpected if the convergence $\\kappa$ was a Gaussian random field\n\n\n", "index": 29, "text": "\\begin{equation}\n\\label{gaussianvar}\n\\mathrm{Var}(P^{\\kappa\\kappa}_\\ell) = \\frac{(P^{\\kappa\\kappa}_\\ell)^2}{N_{\\rm eff}(\\ell).}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\mathrm{Var}(P^{\\kappa\\kappa}_{\\ell})=\\frac{(P^{\\kappa\\kappa}_{\\ell})^{2}}{N_{%&#10;\\rm eff}(\\ell).}\" display=\"block\"><mrow><mrow><mi>Var</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>P</mi><mi mathvariant=\"normal\">\u2113</mi><mrow><mi>\u03ba</mi><mo>\u2062</mo><mi>\u03ba</mi></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>P</mi><mi mathvariant=\"normal\">\u2113</mi><mrow><mi>\u03ba</mi><mo>\u2062</mo><mi>\u03ba</mi></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mrow><msub><mi>N</mi><mi>eff</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nThis correction is important at low $\\ell$, where pixelization effects\nare non-negligible; $N_{\\rm eff}(\\ell\\gg2\\pi/\\theta_{\\rm box})\\approx\nN(\\ell)$.\n\nIn Figures~\\ref{curvingnb} and \\ref{wvar_nr}, we show the dependence\nof the confidence range $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$ on $N_r$,\nderived from the features used in this work (see Table\n\\ref{featuretable} for a comprehensive list). \nFigure~\\ref{curvingnb} shows the\nbehavior in the limit of a large number $N_r\\gg500$ of realizations,\nand compares it with the scaling of the form in\nequation~(\\ref{ourscaling}).\nFigure \\ref{wvar_nr} shows the large $N_r$ trends of the $w$ constraint.\nFigure~\\ref{curvingnb} illustrates the behavior at relatively low\n$N_r$, and compares $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$ measured directly\nfrom the simulations with the analytic expectations from\nequation~(\\ref{quarticdegradation}). Finally, in Figure~\\ref{wvar_ns}, we show\nhow the $w$ confidence limit changes with $N_s$.\n\n\n\n\\section{Discussion}\n\nIn this section we discuss our main findings and their\nimplications. Figure \\ref{ps_pdf} shows that, although different\nchoices of $N_s$ do not affect the power spectrum PDF on large scales\n(top two panels), there are some qualitative differences on smaller\nscales (bottom two panels). On these smaller scales, shear ensembles\nbuilt from $N_s=1$ do not produce the same statistical behavior as\nensembles built with larger $N_s$. In particular, looking at the black\ncurves, we see that the $N_s=1$ ensembles exibit large shifts with\nrespect to the other PDFs to lower power, including the locations of\nthe peaks of the PDFs.  We attribute these offsets to large (random)\nstatistical errors.\n\nInterestingly, we need as few as $N_s=2$ simulations to recover the\nright PDF for the small--scale power spectrum.  Figure~\\ref{means_ns}\nshows that multiple independent $N$--body simulations $N_s\\geq2$ are\nindeed necessary for measuring the means of feature ensembles to an\naccuracy corresponding to 10\\% of the statistical error. The number of\nrequired simulations $N_s$ depends on the feature type and ranges from\na few ($N_s=1$ or 2) for the power spectrum at low multipoles\n($\\ell\\lesssim 500$) to $N_s\\approx 30-50$ for the power spectrum at\nlarger multipoles ($\\ell\\gtrsim1000$) or peak counts above a high\nthreshold ($\\kappa_0\\approx0.3$).  On the other hand, relaxing the\nrequired accuracy to 50\\% of the statistical error, we find $N_s=2$ to\nbe always sufficient.\n\nFigure \\ref{ps_var} shows the variance of convergence power spectrum\ncomputed from different ensembles, in units of the Gaussian\nexpectation. We find that, even with $N_s=1$, we are able to recover\nthe known result that non--Gaussian structures increase the variance\nsignificantly on small scales (see \\citep{Sato12,TakadaSpergel14} for\nreference).  Our results are in fact in excellent quantitative\nagreement with \\citep{Sato12}, which used $N_s=400$ independent $N$--body\nsimulations.  This result is highly encouraging, suggesting that\nindividual $N$--body runs can be recycled repeatedly.  However, it is\nnot sufficient by itself to conclude that $N_s$ does not impact the\nparameter inferences, since these depend on the cross band\ncovariances.\n\nFigure \\ref{curvingnb} investigates the parameter errors. This figure\nshows that error degradation estimates truncated at order $O(1/N_r)$\nare too optimistic when the number of simulations $N_r$ used to\nmeasure the covariance is only a factor of few larger than the\ndimension of the feature space $N_b$. In these cases effects coming\nthe next--to--leading orders $O(1/N_r^2)$ become non--negligible on\nconstraint degradation. In particular, we find that already for\n$N_b=30$ and $N_r\\sim100$, the error degradation estimates to the next\nleading order, $O(1/N_r^2)$, remain too optimistic. Accurate analytic\nestimates in this regime would require at least terms of order\n$O(1/N_r^3)$, which come from higher--than--quartic ${\\mathbf{\\hat{{\\Psi}}}}$\nfluctations.\n\nIn Figure \\ref{wvar_nr}, we examine how the degradation in the $w$\nconstraint depends on the number of simulations used to estimate the\ncovariance, in the limit of large $N_r$. We find excellent agreement\nwith the expected scaling (eq.~\\ref{ourscaling}) up to $N_r\\sim {\\rm few}\\times10^4$ when using the $\\kappa$ power spectrum in the multipole range $\\ell\\in[100,6000]$. The same behavior is observed when considering the high-significance peak counts ($>10\\sigma$ for unsmoothed maps and $>5\\sigma$ for $1^\\prime$ smoothed maps). As the figure shows, around these values of $N_r$ the $\\langle\\hat{\\sigma}^2_w\\rangle - \\sigma^2_{w,\\infty}$ curve\nbecomes noisy and reaches negative values. This is a clear indication that the $1/N_r$ behavior is broken and a plateau in\n$\\langle\\hat{\\sigma}^2_w\\rangle$ is reached. The negative values in\nthe plot are a consequence of the noise in the estimation of this\nplateau value (or equivalently in the estimated value of\n$\\sigma^2_{w,\\infty}$). \n\nWe conclude that a single $N$--body\nsimulation is sufficient to construct an ensemble of up to a\nfew$\\times 10^4$ mutually independent convergence power spectra. For\n$N_r\\gg10^4$, the shear realizations can no longer be considered\nindependent. We emphasize that the precise value of this $N_r$ will depend on the size of the simulation box (which, in our case, is (240Mpc$/h$)$^3$, with $512^3$ particles) and also on the range of multipoles $\\ell$ used to constrain the parameters. Figure \\ref{wvar_nr} shows that when we infer $w$ only from large--scale modes, $\\ell\\lesssim250$, the plateau is reached at least an order of magnitude earlier in the number of realizations. In other words, the number of independent power spectra we can generate decreases as we increase the spatial scales of interest. This is due to the fact that, because of the finite box size, the number of independent lens plane shifts (as described in \\S~\\ref{shearsim}) decreases as the mode size approaches the size of the box.    Similarly, one may expect that the independence in the statistics of high-amplitude peaks, which are predominantly produced by single massive halos, may be compromised by these halos being present repeatedly, in many of the pseudo-independent realizations.  However, Figure \\ref{wvar_nr} shows that this is not the case: the peak count statistics are shown at $\\kappa$ thresholds corresponding to massive ($\\approx 10^{15}~{\\rm M_\\odot}$) halos, yet there is no evidence that the independence of the maps breaks down until $N_r=$few$\\times 10^4$.  Apparently, randomly projected structures, which vary from realization-to-realization, contribute significantly to the statistics of these high peaks.\n\n\nFigure \\ref{wvar_ns} shows how the ``true'' $w$ constraint (in the\nlimit $N_r\\rightarrow \\infty$; or equivalently the $w$ constraint with\nthe known $N_r$ dependence factored out), depends on $N_s$. We find\nthat, in the range $N_s\\in[1,200]$ the inferred $w$--variance\n$\\sigma_{w,\\infty}^2$ fluctuates stochastically only by 1\\%, and does\nnot show any trend with $N_s$.\n\nFinally, we found that when we estimate the data covariance ${\\mathbf{{C}}}$\nfrom the same simulation set used to measure ${\\mathbf{\\hat{{\\Psi}}}}$, the\neffective dimensionality $D$ decreases with increasing $N_b$ in the\ncase where the ${\\mathbf{\\hat{{\\Psi}}}}$ bias is not corrected\n(eq.~\\ref{mockscalinguncorrected}).  This $N_b$-dependence disappears\nwhen the bias is corrected (eq.~\\ref{mockscalingcorrected}).  This\nfact that should be taken into consideration when forecasting\nparameter errors purely from simulations, as the errors will otherwise\nbe underestimated. A similar conclusion was reached by\n\\citep{Hartlap07} (although their paper did not address the impact of\nusing the same simulation set for ${\\mathbf{{C}}}$ and ${\\mathbf{\\hat{{\\Psi}}}}$).\n\n\n\n\n\n\\section{Conclusions}\n\nIn this work, we have examined the effect of forecasting cosmological\nconstraints based on shear ensembles generated from a finite number of\n$N$--body simulations.  Our main results can be summarized as follows:\n\\vspace{0.4\\baselineskip}\n\\begin{itemize}\n\n\\item When the feature covariance matrix is measured from simulations,\n  parameter constraints are degraded. This degradation is appreciably\n  larger than the $O(1/N_r)$ computed by \\citep{DodelsonSchneider13}\n  when the number of realizations $N_r$ is only a factor of few larger\n  than the feature vector size $N_b$.\n\\item We can recycle a single 240Mpc$/h$ $N$--body simulation to produce an\n  ensemble of $O(10^4)$ shear maps whose small-scale power spectra and high-signficiance peak counts are statistically independent. The mean feature measured from a shear ensemble, though, could be inaccurate if only one $N$--body simulation is used.\n\\item As few as one or two independent $N$--body simulations are\n  sufficient to forecast $w$ error bars to 1\\% accuracy, provided that\n  a sufficiently large number $N_r$ of realizations are used to\n  measure feature covariances.  In particular, provided that biases\n  in the inverse covariance are corrected, percent--level forecasts\n  require $N_r{\\mathrel{\\rlap{\\lower4pt\\hbox{\\hskip1pt$\\sim$}}         \\raise1pt\\hbox{$>$}}} 100 (N_b-N_p)$ realizations.\n\\item Depending on the feature type used to constrain cosmology, a\n  larger number of $N$--body simulations might be needed to measure\n  accurate ensemble means to an accuracy corresponding 10\\% of the\n  statistical error. If this accuracy requirement is relaxed to 50\\%\n  of the statistical error, we find that as low as $N_s=2$ simulations\n  are sufficient for the feature types we consider in this work.\n\\end{itemize}\n\nFuture extensions of this work should involve extending our analysis\nto a larger set of cosmological parameters, and to more general\nfeature spaces, such as the ones that characterize non--Gaussian\nstatistics (e.g. including higher moments of the $\\kappa$ field,\nMinkowski Functionals, and higher-order $\\kappa$ correlators). While\nour results are highly encouraging, and suggest that a single $N$--body\nsimulation can be recycled repeatedly, to produce as many as $10^4$\nindependent shear power spectra or peak count histograms. In order to\nscale our results to large future surveys, such as LSST, it will be\nnecessary to determine if our findings hold when challenged by larger\nand higher-resolution $N$--body simulations \\citep{Qcontinuum}.\n\n\n \n\n\\section*{Acknowledgements}\nWe thank Lam Hui for useful discussions.  The simulations in this work\nwere performed at the NSF XSEDE facility, supported by grant number\nACI-1053575, and at the New York Center for Computational Sciences, a\ncooperative effort between Brookhaven National Laboratory and Stony\nBrook University, supported in part by the State of New York. This\nwork was supported in part by the U.S. Department of Energy under\nContract Nos. DE-AC02-98CH10886 and DE-SC0012704, and by the NSF Grant\nNo. AST-1210877 (to Z.H.) and by the Research Opportunities and\nApproaches to Data Science (ROADS) program at the Institute for Data\nSciences and Engineering at Columbia University (to Z.H.).  \n\n\\bibliography{ref}\n\n\n\\section*{Appendix A: cubic and quartic covariance fluctuations}\n\\label{appendixA}\n\nThe goal of this appendix is to give a derivation of\neq. (\\ref{quarticdegradation}). When the simulated feature vector\n${\\mathbf{\\hat{{d}}}}_r$ is drawn from a Gaussian distribution, the covariance\nestimator ${\\mathbf{\\hat{{C}}}}$ follows the Wishart distribution, and its inverse\n${\\mathbf{\\hat{{\\Psi}}}}$ follows the inverse Wishart distribution (see\nRef.~\\citep{Taylor12} for analytical expressions for these probability\ndistributions). Computing expectation values of\neq. (\\ref{estimatorcovariance}) over the inverse Wishart distribution\nis not possible analytically, and a perturbative expansion is\nnecessary. Writing ${\\mathbf{\\hat{{\\Psi}}}}={\\mathbf{{\\Psi}}}+\\delta{\\mathbf{\\hat{{\\Psi}}}}$, we can\nexpand eq.~(\\ref{estimatorcovariance}) in powers of\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$. The expectation value of each term in this\nexpansion can be calculated in terms of moments of the inverse Wishart\ndistribution. Ref.~\\citep{MasumotoWishart} provides a general\nframework to compute these moments, and give exact expressions for\nmoments up to quartic order. First, let us expand the inverse of the\nFisher matrix estimator (eq.~\\ref{estimatorfisher}) in powers of\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$. The $n$--th order of this expansion will be\n\n\n", "itemtype": "equation", "pos": 31024, "prevtext": "\n\nHere $N_{\\rm eff}(l)$ is the number of independent modes used to\nestimate the power spectrum at $\\ell$.  \n\nIn practice, we measure $P^{\\kappa\\kappa}_\\ell$ on the Fourier\ntransform of the pixelized simulated map $\\kappa_r(\\pmb{\\theta})$,\nusing the FFT algorithm, and some care must be taken to count the\nnumber of modes $N_{\\rm eff}(\\ell)$ correctly. Each pixel $(i_x,j_y)$\nin Fourier space corresponds to a mode\n$(\\ell_x,\\ell_y)=2\\pi(i_x,i_y)/\\theta_{\\rm box}$, with $i_x=-n_{\\rm\n  ray}/2,...,n_{\\rm ray}/2$ and $i_y=0,...,n_{\\rm ray}/2$.  Here\n$n_{\\rm ray}=2048$ is the linear number of pixels on the ray--traced\nconvergence maps.  We count the number of pixels $N(\\ell)$ that fall\ninside a multipole bin $(\\ell_1,\\ell_2)$. Because the $\\kappa$ field\nis real, the modes $(\\pm \\ell_x,0)$ are not independent. If we let\n$N(\\ell,\\ell_y=0)$ be the number of non--independent modes, the\neffective number of independent modes for the variance is given by\n\n\n", "index": 31, "text": "\\begin{equation}\nN_{\\rm eff}(\\ell) = \\frac{N^2(\\ell)}{N(\\ell)+N(\\ell,\\ell_y=0)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"N_{\\rm eff}(\\ell)=\\frac{N^{2}(\\ell)}{N(\\ell)+N(\\ell,\\ell_{y}=0)}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>N</mi><mi>eff</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><msup><mi>N</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>N</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>N</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2113</mi><mo>,</mo><msub><mi mathvariant=\"normal\">\u2113</mi><mi>y</mi></msub><mo>=</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nwith\n\n", "itemtype": "equation", "pos": 43537, "prevtext": "\n\nThis correction is important at low $\\ell$, where pixelization effects\nare non-negligible; $N_{\\rm eff}(\\ell\\gg2\\pi/\\theta_{\\rm box})\\approx\nN(\\ell)$.\n\nIn Figures~\\ref{curvingnb} and \\ref{wvar_nr}, we show the dependence\nof the confidence range $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$ on $N_r$,\nderived from the features used in this work (see Table\n\\ref{featuretable} for a comprehensive list). \nFigure~\\ref{curvingnb} shows the\nbehavior in the limit of a large number $N_r\\gg500$ of realizations,\nand compares it with the scaling of the form in\nequation~(\\ref{ourscaling}).\nFigure \\ref{wvar_nr} shows the large $N_r$ trends of the $w$ constraint.\nFigure~\\ref{curvingnb} illustrates the behavior at relatively low\n$N_r$, and compares $\\langle{\\hat{{\\sigma}}}^2_w\\rangle$ measured directly\nfrom the simulations with the analytic expectations from\nequation~(\\ref{quarticdegradation}). Finally, in Figure~\\ref{wvar_ns}, we show\nhow the $w$ confidence limit changes with $N_s$.\n\n\n\n\\section{Discussion}\n\nIn this section we discuss our main findings and their\nimplications. Figure \\ref{ps_pdf} shows that, although different\nchoices of $N_s$ do not affect the power spectrum PDF on large scales\n(top two panels), there are some qualitative differences on smaller\nscales (bottom two panels). On these smaller scales, shear ensembles\nbuilt from $N_s=1$ do not produce the same statistical behavior as\nensembles built with larger $N_s$. In particular, looking at the black\ncurves, we see that the $N_s=1$ ensembles exibit large shifts with\nrespect to the other PDFs to lower power, including the locations of\nthe peaks of the PDFs.  We attribute these offsets to large (random)\nstatistical errors.\n\nInterestingly, we need as few as $N_s=2$ simulations to recover the\nright PDF for the small--scale power spectrum.  Figure~\\ref{means_ns}\nshows that multiple independent $N$--body simulations $N_s\\geq2$ are\nindeed necessary for measuring the means of feature ensembles to an\naccuracy corresponding to 10\\% of the statistical error. The number of\nrequired simulations $N_s$ depends on the feature type and ranges from\na few ($N_s=1$ or 2) for the power spectrum at low multipoles\n($\\ell\\lesssim 500$) to $N_s\\approx 30-50$ for the power spectrum at\nlarger multipoles ($\\ell\\gtrsim1000$) or peak counts above a high\nthreshold ($\\kappa_0\\approx0.3$).  On the other hand, relaxing the\nrequired accuracy to 50\\% of the statistical error, we find $N_s=2$ to\nbe always sufficient.\n\nFigure \\ref{ps_var} shows the variance of convergence power spectrum\ncomputed from different ensembles, in units of the Gaussian\nexpectation. We find that, even with $N_s=1$, we are able to recover\nthe known result that non--Gaussian structures increase the variance\nsignificantly on small scales (see \\citep{Sato12,TakadaSpergel14} for\nreference).  Our results are in fact in excellent quantitative\nagreement with \\citep{Sato12}, which used $N_s=400$ independent $N$--body\nsimulations.  This result is highly encouraging, suggesting that\nindividual $N$--body runs can be recycled repeatedly.  However, it is\nnot sufficient by itself to conclude that $N_s$ does not impact the\nparameter inferences, since these depend on the cross band\ncovariances.\n\nFigure \\ref{curvingnb} investigates the parameter errors. This figure\nshows that error degradation estimates truncated at order $O(1/N_r)$\nare too optimistic when the number of simulations $N_r$ used to\nmeasure the covariance is only a factor of few larger than the\ndimension of the feature space $N_b$. In these cases effects coming\nthe next--to--leading orders $O(1/N_r^2)$ become non--negligible on\nconstraint degradation. In particular, we find that already for\n$N_b=30$ and $N_r\\sim100$, the error degradation estimates to the next\nleading order, $O(1/N_r^2)$, remain too optimistic. Accurate analytic\nestimates in this regime would require at least terms of order\n$O(1/N_r^3)$, which come from higher--than--quartic ${\\mathbf{\\hat{{\\Psi}}}}$\nfluctations.\n\nIn Figure \\ref{wvar_nr}, we examine how the degradation in the $w$\nconstraint depends on the number of simulations used to estimate the\ncovariance, in the limit of large $N_r$. We find excellent agreement\nwith the expected scaling (eq.~\\ref{ourscaling}) up to $N_r\\sim {\\rm few}\\times10^4$ when using the $\\kappa$ power spectrum in the multipole range $\\ell\\in[100,6000]$. The same behavior is observed when considering the high-significance peak counts ($>10\\sigma$ for unsmoothed maps and $>5\\sigma$ for $1^\\prime$ smoothed maps). As the figure shows, around these values of $N_r$ the $\\langle\\hat{\\sigma}^2_w\\rangle - \\sigma^2_{w,\\infty}$ curve\nbecomes noisy and reaches negative values. This is a clear indication that the $1/N_r$ behavior is broken and a plateau in\n$\\langle\\hat{\\sigma}^2_w\\rangle$ is reached. The negative values in\nthe plot are a consequence of the noise in the estimation of this\nplateau value (or equivalently in the estimated value of\n$\\sigma^2_{w,\\infty}$). \n\nWe conclude that a single $N$--body\nsimulation is sufficient to construct an ensemble of up to a\nfew$\\times 10^4$ mutually independent convergence power spectra. For\n$N_r\\gg10^4$, the shear realizations can no longer be considered\nindependent. We emphasize that the precise value of this $N_r$ will depend on the size of the simulation box (which, in our case, is (240Mpc$/h$)$^3$, with $512^3$ particles) and also on the range of multipoles $\\ell$ used to constrain the parameters. Figure \\ref{wvar_nr} shows that when we infer $w$ only from large--scale modes, $\\ell\\lesssim250$, the plateau is reached at least an order of magnitude earlier in the number of realizations. In other words, the number of independent power spectra we can generate decreases as we increase the spatial scales of interest. This is due to the fact that, because of the finite box size, the number of independent lens plane shifts (as described in \\S~\\ref{shearsim}) decreases as the mode size approaches the size of the box.    Similarly, one may expect that the independence in the statistics of high-amplitude peaks, which are predominantly produced by single massive halos, may be compromised by these halos being present repeatedly, in many of the pseudo-independent realizations.  However, Figure \\ref{wvar_nr} shows that this is not the case: the peak count statistics are shown at $\\kappa$ thresholds corresponding to massive ($\\approx 10^{15}~{\\rm M_\\odot}$) halos, yet there is no evidence that the independence of the maps breaks down until $N_r=$few$\\times 10^4$.  Apparently, randomly projected structures, which vary from realization-to-realization, contribute significantly to the statistics of these high peaks.\n\n\nFigure \\ref{wvar_ns} shows how the ``true'' $w$ constraint (in the\nlimit $N_r\\rightarrow \\infty$; or equivalently the $w$ constraint with\nthe known $N_r$ dependence factored out), depends on $N_s$. We find\nthat, in the range $N_s\\in[1,200]$ the inferred $w$--variance\n$\\sigma_{w,\\infty}^2$ fluctuates stochastically only by 1\\%, and does\nnot show any trend with $N_s$.\n\nFinally, we found that when we estimate the data covariance ${\\mathbf{{C}}}$\nfrom the same simulation set used to measure ${\\mathbf{\\hat{{\\Psi}}}}$, the\neffective dimensionality $D$ decreases with increasing $N_b$ in the\ncase where the ${\\mathbf{\\hat{{\\Psi}}}}$ bias is not corrected\n(eq.~\\ref{mockscalinguncorrected}).  This $N_b$-dependence disappears\nwhen the bias is corrected (eq.~\\ref{mockscalingcorrected}).  This\nfact that should be taken into consideration when forecasting\nparameter errors purely from simulations, as the errors will otherwise\nbe underestimated. A similar conclusion was reached by\n\\citep{Hartlap07} (although their paper did not address the impact of\nusing the same simulation set for ${\\mathbf{{C}}}$ and ${\\mathbf{\\hat{{\\Psi}}}}$).\n\n\n\n\n\n\\section{Conclusions}\n\nIn this work, we have examined the effect of forecasting cosmological\nconstraints based on shear ensembles generated from a finite number of\n$N$--body simulations.  Our main results can be summarized as follows:\n\\vspace{0.4\\baselineskip}\n\\begin{itemize}\n\n\\item When the feature covariance matrix is measured from simulations,\n  parameter constraints are degraded. This degradation is appreciably\n  larger than the $O(1/N_r)$ computed by \\citep{DodelsonSchneider13}\n  when the number of realizations $N_r$ is only a factor of few larger\n  than the feature vector size $N_b$.\n\\item We can recycle a single 240Mpc$/h$ $N$--body simulation to produce an\n  ensemble of $O(10^4)$ shear maps whose small-scale power spectra and high-signficiance peak counts are statistically independent. The mean feature measured from a shear ensemble, though, could be inaccurate if only one $N$--body simulation is used.\n\\item As few as one or two independent $N$--body simulations are\n  sufficient to forecast $w$ error bars to 1\\% accuracy, provided that\n  a sufficiently large number $N_r$ of realizations are used to\n  measure feature covariances.  In particular, provided that biases\n  in the inverse covariance are corrected, percent--level forecasts\n  require $N_r{\\mathrel{\\rlap{\\lower4pt\\hbox{\\hskip1pt$\\sim$}}         \\raise1pt\\hbox{$>$}}} 100 (N_b-N_p)$ realizations.\n\\item Depending on the feature type used to constrain cosmology, a\n  larger number of $N$--body simulations might be needed to measure\n  accurate ensemble means to an accuracy corresponding 10\\% of the\n  statistical error. If this accuracy requirement is relaxed to 50\\%\n  of the statistical error, we find that as low as $N_s=2$ simulations\n  are sufficient for the feature types we consider in this work.\n\\end{itemize}\n\nFuture extensions of this work should involve extending our analysis\nto a larger set of cosmological parameters, and to more general\nfeature spaces, such as the ones that characterize non--Gaussian\nstatistics (e.g. including higher moments of the $\\kappa$ field,\nMinkowski Functionals, and higher-order $\\kappa$ correlators). While\nour results are highly encouraging, and suggest that a single $N$--body\nsimulation can be recycled repeatedly, to produce as many as $10^4$\nindependent shear power spectra or peak count histograms. In order to\nscale our results to large future surveys, such as LSST, it will be\nnecessary to determine if our findings hold when challenged by larger\nand higher-resolution $N$--body simulations \\citep{Qcontinuum}.\n\n\n \n\n\\section*{Acknowledgements}\nWe thank Lam Hui for useful discussions.  The simulations in this work\nwere performed at the NSF XSEDE facility, supported by grant number\nACI-1053575, and at the New York Center for Computational Sciences, a\ncooperative effort between Brookhaven National Laboratory and Stony\nBrook University, supported in part by the State of New York. This\nwork was supported in part by the U.S. Department of Energy under\nContract Nos. DE-AC02-98CH10886 and DE-SC0012704, and by the NSF Grant\nNo. AST-1210877 (to Z.H.) and by the Research Opportunities and\nApproaches to Data Science (ROADS) program at the Institute for Data\nSciences and Engineering at Columbia University (to Z.H.).  \n\n\\bibliography{ref}\n\n\n\\section*{Appendix A: cubic and quartic covariance fluctuations}\n\\label{appendixA}\n\nThe goal of this appendix is to give a derivation of\neq. (\\ref{quarticdegradation}). When the simulated feature vector\n${\\mathbf{\\hat{{d}}}}_r$ is drawn from a Gaussian distribution, the covariance\nestimator ${\\mathbf{\\hat{{C}}}}$ follows the Wishart distribution, and its inverse\n${\\mathbf{\\hat{{\\Psi}}}}$ follows the inverse Wishart distribution (see\nRef.~\\citep{Taylor12} for analytical expressions for these probability\ndistributions). Computing expectation values of\neq. (\\ref{estimatorcovariance}) over the inverse Wishart distribution\nis not possible analytically, and a perturbative expansion is\nnecessary. Writing ${\\mathbf{\\hat{{\\Psi}}}}={\\mathbf{{\\Psi}}}+\\delta{\\mathbf{\\hat{{\\Psi}}}}$, we can\nexpand eq.~(\\ref{estimatorcovariance}) in powers of\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$. The expectation value of each term in this\nexpansion can be calculated in terms of moments of the inverse Wishart\ndistribution. Ref.~\\citep{MasumotoWishart} provides a general\nframework to compute these moments, and give exact expressions for\nmoments up to quartic order. First, let us expand the inverse of the\nFisher matrix estimator (eq.~\\ref{estimatorfisher}) in powers of\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$. The $n$--th order of this expansion will be\n\n\n", "index": 33, "text": "\\begin{equation}\n\\label{nthterm}\n\\delta{\\mathbf{\\hat{{F}}}}^{-1}_{(n)} = (-1)^{n}({\\mathbf{{F}}}^{-1}\\delta{\\mathbf{\\hat{{F}}}})^n{\\mathbf{{F}}}^{-1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\delta{\\mathbf{\\hat{{F}}}}^{-1}_{(n)}=(-1)^{n}({\\mathbf{{F}}}^{-1}\\delta{%&#10;\\mathbf{\\hat{{F}}}})^{n}{\\mathbf{{F}}}^{-1}\" display=\"block\"><mrow><mrow><mi>\u03b4</mi><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mi>n</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mi>n</mi></msup><mo>\u2062</mo><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nUsing eq. (\\ref{nthterm}), we can expand\neq. (\\ref{estimatorcovariance}) to an arbitrary order in\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$, take the expectation values of the fluctuations\nover the inverse Wishart distribution, and finally arrive at\neq.~(\\ref{quarticdegradation}). We use the notation $\\nu\\equiv N_r-1$\nand $\\gamma\\equiv (\\nu-N_b-1)/2$, and we indicate with capital letters\npairs of matrix indices, for example $I=(i_1,i_2)$, where\n$i_a=1..N_b$. The main results we utilize from\nref.~\\citep{MasumotoWishart} regarding the first four moments are (up\nto order $O(1/\\nu^2)$)\n\n\\begin{widetext}\n\n\n", "itemtype": "equation", "pos": 43708, "prevtext": "\n\nwith\n\n", "index": 35, "text": "\\begin{equation}\n\\delta{\\mathbf{\\hat{{F}}}} = {\\mathbf{{d}}}_0'^T\\delta{\\mathbf{\\hat{{\\Psi}}}}{\\mathbf{{d}}}_0'\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\delta{\\mathbf{\\hat{{F}}}}={\\mathbf{{d}}}_{0}^{\\prime T}\\delta{\\mathbf{\\hat{{%&#10;\\Psi}}}}{\\mathbf{{d}}}_{0}^{\\prime}\" display=\"block\"><mrow><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>=</mo><mrow><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 44434, "prevtext": "\n\nUsing eq. (\\ref{nthterm}), we can expand\neq. (\\ref{estimatorcovariance}) to an arbitrary order in\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$, take the expectation values of the fluctuations\nover the inverse Wishart distribution, and finally arrive at\neq.~(\\ref{quarticdegradation}). We use the notation $\\nu\\equiv N_r-1$\nand $\\gamma\\equiv (\\nu-N_b-1)/2$, and we indicate with capital letters\npairs of matrix indices, for example $I=(i_1,i_2)$, where\n$i_a=1..N_b$. The main results we utilize from\nref.~\\citep{MasumotoWishart} regarding the first four moments are (up\nto order $O(1/\\nu^2)$)\n\n\\begin{widetext}\n\n\n", "index": 37, "text": "\\begin{equation}\n\\label{firstmoment}\n\\langle{\\hat{{\\Psi}}}_I\\rangle = \\frac{\\nu}{2\\gamma}\\Psi_I\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Psi}}}_{I}\\rangle=\\frac{\\nu}{2\\gamma}\\Psi_{I}\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>I</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mfrac><mi>\u03bd</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow></mfrac><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mi>I</mi></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 44546, "prevtext": "\n\n\n", "index": 39, "text": "\\begin{equation}\n\\label{secondmoment}\n\\langle\\delta{\\hat{{\\Psi}}}_I\\delta{\\hat{{\\Psi}}}_J\\rangle = \\frac{\\nu^2\\Psi_I\\Psi_J + \\nu^2\\gamma\\Psi_{\\{I}\\Psi_{J\\}}}{4\\gamma^2(\\gamma-1)(2\\gamma+1)}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\langle\\delta{\\hat{{\\Psi}}}_{I}\\delta{\\hat{{\\Psi}}}_{J}\\rangle=\\frac{\\nu^{2}%&#10;\\Psi_{I}\\Psi_{J}+\\nu^{2}\\gamma\\Psi_{\\{I}\\Psi_{J\\}}}{4\\gamma^{2}(\\gamma-1)(2%&#10;\\gamma+1)}\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>I</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>J</mi></msub></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mfrac><mrow><mrow><msup><mi>\u03bd</mi><mn>2</mn></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mi>I</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mi>J</mi></msub></mrow><mo>+</mo><mrow><msup><mi>\u03bd</mi><mn>2</mn></msup><mo>\u2062</mo><mi>\u03b3</mi><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mo stretchy=\"false\">{</mo><mi>I</mi></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mi>J</mi><mo stretchy=\"false\">}</mo></mrow></msub></mrow></mrow><mrow><mn>4</mn><mo>\u2062</mo><msup><mi>\u03b3</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 44752, "prevtext": "\n\n\n", "index": 41, "text": "\\begin{equation}\n\\label{thirdmoment}\n\\langle\\delta{\\hat{{\\Psi}}}_I\\delta{\\hat{{\\Psi}}}_J\\delta{\\hat{{\\Psi}}}_K\\rangle = \\frac{\\nu^3\\Psi_{\\{I}\\Psi_J\\Psi_{K\\}}}{8\\gamma(\\gamma-1)(\\gamma-2)(\\gamma+1)(2\\gamma+1)}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\langle\\delta{\\hat{{\\Psi}}}_{I}\\delta{\\hat{{\\Psi}}}_{J}\\delta{\\hat{{\\Psi}}}_{K%&#10;}\\rangle=\\frac{\\nu^{3}\\Psi_{\\{I}\\Psi_{J}\\Psi_{K\\}}}{8\\gamma(\\gamma-1)(\\gamma-2%&#10;)(\\gamma+1)(2\\gamma+1)}\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>I</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>J</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>K</mi></msub></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi>\u03bd</mi><mn>3</mn></msup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mo stretchy=\"false\">{</mo><mi>I</mi></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mi>J</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mi>K</mi><mo stretchy=\"false\">}</mo></mrow></msub></mrow><mrow><mn>8</mn><mo>\u2062</mo><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\n\\end{widetext}\n\nHere the curly bracket notation is a shorthand for a symmetrization over pair of indices: for example\n\n", "itemtype": "equation", "pos": 44977, "prevtext": "\n\n\n", "index": 43, "text": "\\begin{equation}\n\\label{fourthmoment}\n\\langle\\delta{\\hat{{\\Psi}}}_I\\delta{\\hat{{\\Psi}}}_J\\delta{\\hat{{\\Psi}}}_K\\delta{\\hat{{\\Psi}}}_L\\rangle = \\frac{\\nu^4(2\\gamma^2-5\\gamma+9)\\Psi_{\\{I}\\Psi_{J\\}}\\Psi_{\\{K}\\Psi_{L\\}}}{16\\gamma(\\gamma-1)(\\gamma-2)(\\gamma-3)(2\\gamma-1)(\\gamma+1)(2\\gamma+1)(2\\gamma+3)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\langle\\delta{\\hat{{\\Psi}}}_{I}\\delta{\\hat{{\\Psi}}}_{J}\\delta{\\hat{{\\Psi}}}_{K%&#10;}\\delta{\\hat{{\\Psi}}}_{L}\\rangle=\\frac{\\nu^{4}(2\\gamma^{2}-5\\gamma+9)\\Psi_{\\{I%&#10;}\\Psi_{J\\}}\\Psi_{\\{K}\\Psi_{L\\}}}{16\\gamma(\\gamma-1)(\\gamma-2)(\\gamma-3)(2%&#10;\\gamma-1)(\\gamma+1)(2\\gamma+1)(2\\gamma+3)}.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>I</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>J</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>K</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a8</mi><mo stretchy=\"false\">^</mo></mover><mi>L</mi></msub></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi>\u03bd</mi><mn>4</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\u03b3</mi><mn>2</mn></msup></mrow><mo>-</mo><mrow><mn>5</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow></mrow><mo>+</mo><mn>9</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mo stretchy=\"false\">{</mo><mi>I</mi></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mi>J</mi><mo stretchy=\"false\">}</mo></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mo stretchy=\"false\">{</mo><mi>K</mi></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mi>L</mi><mo stretchy=\"false\">}</mo></mrow></msub></mrow><mrow><mn>16</mn><mo>\u2062</mo><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>3</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>+</mo><mn>3</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\nEq. (\\ref{firstmoment}) expresses the bias in the ${\\mathbf{\\hat{{\\Psi}}}}$\nestimator that already appears in the literature~\\citep{Hartlap07}. If\nwe want to use the bias-corrected ${\\mathbf{\\hat{{\\Psi}}}}$ estimator (required for\nthe perturbative expansion of eq.~\\ref{estimatorcovariance}), we need\nto apply an additional factor of $(2\\gamma/\\nu)^n$ to\neqs. (\\ref{firstmoment}--\\ref{fourthmoment}), where $n$ is the order\nof the moment up to which we are applying the correction. If we limit\nourselves to computing the expectation value of\neq. (\\ref{estimatorcovariance}) up to order $O(1/\\nu^2)$, we do not\nneed to worry about this correction for\neqs. (\\ref{thirdmoment}--\\ref{fourthmoment}), as the dominant term\nhere is already $O(1/\\nu^2)$. The next step is expanding\neq. (\\ref{estimatorcovariance}) in powers of $\\delta{\\mathbf{\\hat{{\\Psi}}}}$ up to\nfourth order: this is easily done:\n\n\\begin{widetext}\n\n", "itemtype": "equation", "pos": 45412, "prevtext": "\n\n\\end{widetext}\n\nHere the curly bracket notation is a shorthand for a symmetrization over pair of indices: for example\n\n", "index": 45, "text": "\\begin{equation}\n\\Psi_{\\{I}\\Psi_{J\\}} = \\Psi_{i_1j_1}\\Psi_{i_2j_2} + \\Psi_{i_1j_2}\\Psi_{i_2j_1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\Psi_{\\{I}\\Psi_{J\\}}=\\Psi_{i_{1}j_{1}}\\Psi_{i_{2}j_{2}}+\\Psi_{i_{1}j_{2}}\\Psi_%&#10;{i_{2}j_{1}}\" display=\"block\"><mrow><mrow><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mo stretchy=\"false\">{</mo><mi>I</mi></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><mi>J</mi><mo stretchy=\"false\">}</mo></mrow></msub></mrow><mo>=</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>j</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><msub><mi>i</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>j</mi><mn>2</mn></msub></mrow></msub></mrow><mo>+</mo><mrow><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>j</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a8</mi><mrow><msub><mi>i</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>j</mi><mn>1</mn></msub></mrow></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\\end{widetext}\n\nCarrying out the calculations is simpler than it looks: because of the\nstructure of eq. (\\ref{fullpertexpansion}), each term in the expansion\nis proportional to $\\Sigma_{\\mathbf{{p}}}f_a(N_b,N_p)/N_r^a$, where\n$f_a(N_b,N_p)$ is a polynomial in $N_b$ and $N_p$. Terms proportional\nto $N_b$ arise from index contractions of type $\\mathrm{tr}({\\mathbf{{\\Psi   C}}})=N_b$, which come from symmetrization terms of type\n$\\Psi_{\\{I}\\Psi_{J\\}}$. Symmetrization factors of type\n$\\Psi_{\\{I}\\Psi_J\\Psi_{K\\}}$ or $\\Psi_{\\{I}\\Psi_{J\\}}\\Psi_{\\{K}\\Psi_{L\\}}$,\non the other hand, give rise to contractions of type\n$\\mathrm{tr}({\\mathbf{{\\Psi   C}}})\\mathrm{tr}({\\mathbf{{{\\mathbf{{F}}}{\\mathbf{{F}}}^{-1}}}})=N_bN_p$. Moreover, we know\nthat, at every order $O(1/N_r^a)$, $f_a(N_b,N_p)$ has to be\nproportional to $N_b-N_p$, because it must vanish when $N_b=N_p$. The\nreason for this is that if the feature derivative matrix ${\\mathbf{{d}}}'_0$\nis square and invertible (which it should be in absence of\ndegeneracies), then eq. (\\ref{estimatorcovariance}) reduces to\n\n\n", "itemtype": "equation", "pos": 46434, "prevtext": "\n\nEq. (\\ref{firstmoment}) expresses the bias in the ${\\mathbf{\\hat{{\\Psi}}}}$\nestimator that already appears in the literature~\\citep{Hartlap07}. If\nwe want to use the bias-corrected ${\\mathbf{\\hat{{\\Psi}}}}$ estimator (required for\nthe perturbative expansion of eq.~\\ref{estimatorcovariance}), we need\nto apply an additional factor of $(2\\gamma/\\nu)^n$ to\neqs. (\\ref{firstmoment}--\\ref{fourthmoment}), where $n$ is the order\nof the moment up to which we are applying the correction. If we limit\nourselves to computing the expectation value of\neq. (\\ref{estimatorcovariance}) up to order $O(1/\\nu^2)$, we do not\nneed to worry about this correction for\neqs. (\\ref{thirdmoment}--\\ref{fourthmoment}), as the dominant term\nhere is already $O(1/\\nu^2)$. The next step is expanding\neq. (\\ref{estimatorcovariance}) in powers of $\\delta{\\mathbf{\\hat{{\\Psi}}}}$ up to\nfourth order: this is easily done:\n\n\\begin{widetext}\n\n", "index": 47, "text": "\\begin{equation}\n\\label{fullpertexpansion}\n{\\hat{{\\Sigma}}}_{\\mathbf{{p}}} = \\left({\\mathbf{{F}}}^{-1}+\\sum_{n=1}^4\\delta{\\mathbf{\\hat{{F}}}}^{-1}_{(n)}\\right){\\mathbf{{d}}}'^T_0({\\mathbf{{\\Psi}}}+\\delta{\\mathbf{\\hat{{\\Psi}}}}){\\mathbf{{C}}}({\\mathbf{{\\Psi}}}+\\delta{\\mathbf{\\hat{{\\Psi}}}}){\\mathbf{{d}}}'_0\\left({\\mathbf{{F}}}^{-1}+\\sum_{n=1}^4\\delta{\\mathbf{\\hat{{F}}}}^{-1}_{(n)}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}=\\left({\\mathbf{{F}}}^{-1}+\\sum_{n=1}^{4}\\delta%&#10;{\\mathbf{\\hat{{F}}}}^{-1}_{(n)}\\right){\\mathbf{{d}}}^{\\prime T}_{0}({\\mathbf{{%&#10;\\Psi}}}+\\delta{\\mathbf{\\hat{{\\Psi}}}}){\\mathbf{{C}}}({\\mathbf{{\\Psi}}}+\\delta{%&#10;\\mathbf{\\hat{{\\Psi}}}}){\\mathbf{{d}}}^{\\prime}_{0}\\left({\\mathbf{{F}}}^{-1}+%&#10;\\sum_{n=1}^{4}\\delta{\\mathbf{\\hat{{F}}}}^{-1}_{(n)}\\right).\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo>=</mo><mrow><mrow><mo>(</mo><mrow><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><mrow><mi>\u03b4</mi><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udebf</mi><mo>+</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc02</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udebf</mi><mo>+</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><mrow><mi>\u03b4</mi><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": " \n\nEvery trace of the noise is gone, hence powers of $1/N_r^a$ must not\nappear at any order if $N_b=N_p$. Armed with the knowledge of the\nabove considerations, we can compute the expectation value of\neq. (\\ref{fullpertexpansion}) at second, third and fourth order in\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$, keeping the terms that are at most\n$O(1/\\nu^2)=O(1/N_r^2)$. When the combinatorial factors that arise\nfrom the expansion of eq. (\\ref{fullpertexpansion}) are properly\ncomputed and the expectation values over the inverse Wishart\ndistribution are taken according to\neqs. (\\ref{firstmoment}--\\ref{fourthmoment}), the results take the form\n\n\\begin{widetext}\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\\end{widetext}\n\nCarrying out the calculations is simpler than it looks: because of the\nstructure of eq. (\\ref{fullpertexpansion}), each term in the expansion\nis proportional to $\\Sigma_{\\mathbf{{p}}}f_a(N_b,N_p)/N_r^a$, where\n$f_a(N_b,N_p)$ is a polynomial in $N_b$ and $N_p$. Terms proportional\nto $N_b$ arise from index contractions of type $\\mathrm{tr}({\\mathbf{{\\Psi   C}}})=N_b$, which come from symmetrization terms of type\n$\\Psi_{\\{I}\\Psi_{J\\}}$. Symmetrization factors of type\n$\\Psi_{\\{I}\\Psi_J\\Psi_{K\\}}$ or $\\Psi_{\\{I}\\Psi_{J\\}}\\Psi_{\\{K}\\Psi_{L\\}}$,\non the other hand, give rise to contractions of type\n$\\mathrm{tr}({\\mathbf{{\\Psi   C}}})\\mathrm{tr}({\\mathbf{{{\\mathbf{{F}}}{\\mathbf{{F}}}^{-1}}}})=N_bN_p$. Moreover, we know\nthat, at every order $O(1/N_r^a)$, $f_a(N_b,N_p)$ has to be\nproportional to $N_b-N_p$, because it must vanish when $N_b=N_p$. The\nreason for this is that if the feature derivative matrix ${\\mathbf{{d}}}'_0$\nis square and invertible (which it should be in absence of\ndegeneracies), then eq. (\\ref{estimatorcovariance}) reduces to\n\n\n", "index": 49, "text": "\\begin{equation}\n{\\hat{{\\Sigma}}}_{\\mathbf{{p}}} = ({\\mathbf{{d}}}'_0)^{-1}{\\mathbf{{C}}}({\\mathbf{{d}}}'^T_0)^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}=({\\mathbf{{d}}}^{\\prime}_{0})^{-1}{\\mathbf{{C}%&#10;}}({\\mathbf{{d}}}^{\\prime T}_{0})^{-1}.\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mo>\u2032</mo></msubsup><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\ud835\udc02</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc1d</mi><mn>0</mn><mrow><mi mathsize=\"142%\" mathvariant=\"normal\">\u2032</mi><mo>\u2063</mo><mi>T</mi></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\\end{widetext}\n\nWhen the results from eq. (\\ref{expansionbreakdown}) are summed, eq. (\\ref{quarticdegradation}) immediately follows. \n\n\n\\clearpage\n\\newpage\n\\section*{Appendix B: negative effective dimensionality}\n\\label{appendixB}\n\nThe goal of this appendix is to give a justification for why the effective dimensionality $D$ that appears in eq. (\\ref{ourscaling}) can be negative in some cases. When we use the same simulation set to estimate ${\\mathbf{{C}}},{\\mathbf{\\hat{{\\Psi}}}}$, eq. (\\ref{estimatorcovariance}) reduces to the inverse Fisher estimator ${\\hat{{\\Sigma}}}_{\\mathbf{{p}}}={\\mathbf{\\hat{{F}}}}^{-1}$. At second order in the $\\Psi$ fluctuations this becomes\n\n\n", "itemtype": "equation", "pos": 48691, "prevtext": " \n\nEvery trace of the noise is gone, hence powers of $1/N_r^a$ must not\nappear at any order if $N_b=N_p$. Armed with the knowledge of the\nabove considerations, we can compute the expectation value of\neq. (\\ref{fullpertexpansion}) at second, third and fourth order in\n$\\delta{\\mathbf{\\hat{{\\Psi}}}}$, keeping the terms that are at most\n$O(1/\\nu^2)=O(1/N_r^2)$. When the combinatorial factors that arise\nfrom the expansion of eq. (\\ref{fullpertexpansion}) are properly\ncomputed and the expectation values over the inverse Wishart\ndistribution are taken according to\neqs. (\\ref{firstmoment}--\\ref{fourthmoment}), the results take the form\n\n\\begin{widetext}\n\n", "index": 51, "text": "\\begin{equation}\n\\label{expansionbreakdown}\n\\begin{cases}\n\\begin{displaystyle}\n(\\delta{\\mathbf{\\hat{{\\Psi}}}})^2 \\rightarrow \\Sigma_{\\mathbf{{p}}}\\frac{\\gamma(N_b-N_p)}{(\\gamma-1)(2\\gamma+1)} = \\Sigma_{\\mathbf{{p}}}\\left[\\frac{N_b-N_p}{N_r}+\\frac{(N_b-N_p)(N_b+3)}{N_r^2}\\right]\n\\end{displaystyle} \\\\ \\\\\n\n\\begin{displaystyle}\n(\\delta{\\mathbf{\\hat{{\\Psi}}}})^3 \\rightarrow -4\\Sigma_{\\mathbf{{p}}}\\frac{(N_b-N_p)(1+N_p)}{N_r^2}\n\\end{displaystyle} \\\\ \\\\\n\n\n\\begin{displaystyle}\n(\\delta{\\mathbf{\\hat{{\\Psi}}}})^4 \\rightarrow 3\\Sigma_{\\mathbf{{p}}}\\frac{(N_b-N_p)(1+N_p)}{N_r^2}.\n\\end{displaystyle}\n\n\\end{cases}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"\\begin{cases}\\displaystyle(\\delta{\\mathbf{\\hat{{\\Psi}}}})^{2}\\rightarrow\\Sigma%&#10;_{\\mathbf{{p}}}\\frac{\\gamma(N_{b}-N_{p})}{(\\gamma-1)(2\\gamma+1)}=\\Sigma_{%&#10;\\mathbf{{p}}}\\left[\\frac{N_{b}-N_{p}}{N_{r}}+\\frac{(N_{b}-N_{p})(N_{b}+3)}{N_{%&#10;r}^{2}}\\right]\\\\&#10;\\\\&#10;\\par&#10;\\displaystyle(\\delta{\\mathbf{\\hat{{\\Psi}}}})^{3}\\rightarrow-4\\Sigma_{%&#10;\\mathbf{{p}}}\\frac{(N_{b}-N_{p})(1+N_{p})}{N_{r}^{2}}\\\\&#10;\\\\&#10;\\par&#10;\\par&#10;\\displaystyle(\\delta{\\mathbf{\\hat{{\\Psi}}}})^{4}\\rightarrow 3\\Sigma_%&#10;{\\mathbf{{p}}}\\frac{(N_{b}-N_{p})(1+N_{p})}{N_{r}^{2}}.\\par&#10;\\end{cases}\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2192</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mfrac><mrow><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b3</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>[</mo><mrow><mfrac><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac><mo>+</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>+</mo><mn>3</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msubsup><mi>N</mi><mi>r</mi><mn>2</mn></msubsup></mfrac></mrow><mo>]</mo></mrow></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mi/></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mn>3</mn></msup><mo>\u2192</mo><mrow><mo>-</mo><mrow><mn>4</mn><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msubsup><mi>N</mi><mi>r</mi><mn>2</mn></msubsup></mfrac></mrow></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mi/></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udebf</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mn>4</mn></msup><mo>\u2192</mo><mrow><mn>3</mn><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>-</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msubsup><mi>N</mi><mi>r</mi><mn>2</mn></msubsup></mfrac></mrow></mrow><mo>.</mo></mrow></mtd><mtd/></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "  \n\nIf the biased estimator for ${\\mathbf{\\hat{{\\Psi}}}}$ is used, we can use eqs. (\\ref{firstmoment}--\\ref{secondmoment}) at order $O(1/\\nu)$ to compute \n\\begin{widetext}\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\\end{widetext}\n\nWhen the results from eq. (\\ref{expansionbreakdown}) are summed, eq. (\\ref{quarticdegradation}) immediately follows. \n\n\n\\clearpage\n\\newpage\n\\section*{Appendix B: negative effective dimensionality}\n\\label{appendixB}\n\nThe goal of this appendix is to give a justification for why the effective dimensionality $D$ that appears in eq. (\\ref{ourscaling}) can be negative in some cases. When we use the same simulation set to estimate ${\\mathbf{{C}}},{\\mathbf{\\hat{{\\Psi}}}}$, eq. (\\ref{estimatorcovariance}) reduces to the inverse Fisher estimator ${\\hat{{\\Sigma}}}_{\\mathbf{{p}}}={\\mathbf{\\hat{{F}}}}^{-1}$. At second order in the $\\Psi$ fluctuations this becomes\n\n\n", "index": 53, "text": "\\begin{equation}\n{\\hat{{\\Sigma}}}_{\\mathbf{{p}}} = {\\mathbf{{F}}}^{-1} + {\\mathbf{{F}}}^{-1}\\left(- \\delta{{\\mathbf{\\hat{{F}}}}}+ \\delta{{\\mathbf{\\hat{{F}}}}}{\\mathbf{{F}}}^{-1}\\delta{{\\mathbf{\\hat{{F}}}}}\\right){\\mathbf{{F}}}^{-1}  \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}={\\mathbf{{F}}}^{-1}+{\\mathbf{{F}}}^{-1}\\left(-%&#10;\\delta{{\\mathbf{\\hat{{F}}}}}+\\delta{{\\mathbf{\\hat{{F}}}}}{\\mathbf{{F}}}^{-1}%&#10;\\delta{{\\mathbf{\\hat{{F}}}}}\\right){\\mathbf{{F}}}^{-1}\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo>=</mo><mrow><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>+</mo><mrow><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mo>-</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo>+</mo><mrow><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mover accent=\"true\"><mi>\ud835\udc05</mi><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc05</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06792.tex", "nexttext": "\n\\end{widetext}\n\nWe immediately see that the coefficient of $1/N_r$ is negative, because $N_b>N_p$. This is the result shown in eq. (\\ref{mockscalinguncorrected}). If the bias correction for ${\\mathbf{\\hat{{\\Psi}}}}$ is applied, the first order terms $\\delta{{\\mathbf{\\hat{{F}}}}}$ average to 0, and we are left with only the last term in the sum eq.~(\\ref{negativeD}), which immediately yields eq. (\\ref{mockscalingcorrected}). \n\n\n\\label{lastpage}\n\n", "itemtype": "equation", "pos": 50408, "prevtext": "  \n\nIf the biased estimator for ${\\mathbf{\\hat{{\\Psi}}}}$ is used, we can use eqs. (\\ref{firstmoment}--\\ref{secondmoment}) at order $O(1/\\nu)$ to compute \n\\begin{widetext}\n\n", "index": 55, "text": "\\begin{equation}\n\\label{negativeD}\n\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle = \\Sigma_{\\mathbf{{p}}}\\left(1-\\frac{N_b+1}{N_r}+\\frac{1+N_p}{N_r}\\right) = \\Sigma_{\\mathbf{{p}}}\\left(1+\\frac{N_p-N_b}{N_r}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"\\langle{\\hat{{\\Sigma}}}_{\\mathbf{{p}}}\\rangle=\\Sigma_{\\mathbf{{p}}}\\left(1-%&#10;\\frac{N_{b}+1}{N_{r}}+\\frac{1+N_{p}}{N_{r}}\\right)=\\Sigma_{\\mathbf{{p}}}\\left(%&#10;1+\\frac{N_{p}-N_{b}}{N_{r}}\\right).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u03a3</mi><mo stretchy=\"false\">^</mo></mover><mi>\ud835\udc29</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><msub><mi>N</mi><mi>b</mi></msub><mo>+</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>+</mo><mfrac><mrow><mn>1</mn><mo>+</mo><msub><mi>N</mi><mi>p</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>\ud835\udc29</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><msub><mi>N</mi><mi>p</mi></msub><mo>-</mo><msub><mi>N</mi><mi>b</mi></msub></mrow><msub><mi>N</mi><mi>r</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]