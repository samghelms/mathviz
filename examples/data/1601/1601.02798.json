[{"file": "1601.02798.tex", "nexttext": "\n\n\nwhere $\\varepsilon_i$, $i=1,\\ldots,n$ are i.i.d. centered real random\nvariables with\n$\\mathbb{E}(\\varepsilon_i^2)=\\sigma^2<\\infty$, which are independent of\n$X_i(t)$ for all $t$,\n$\\beta\\in L^2([a,b])$ is an unknown, bounded slope function and\n$ \\int_a^b \\beta(t) X_i(t) \\,dt$ describes a common effect of the\nwhole trajectory $X_i(\\cdot)$ on $Y_i$. In addition, the model\nincorporates an\nunknown number $S\\in\\mathbb{N}$ of ``points of impact,'' that is, \\emph{specific} time points $\\tau_1,\\ldots,\\tau_S$ with the\nproperty that the corresponding functional values\n$X_i(\\tau_1),\\ldots,X_i(\\tau_S)$ possess some significant influence on\nthe response variable\n$Y_i$. The function $\\beta(t)$, the number $S\\geq0$, as well as $\\tau\n_r$ and $\\beta_r$,\n$r=1,\\ldots,S$, are unknown and have to be estimated from the data.\nThroughout the paper, we will assume that all points of impact are in the\ninterior of the interval, $\\tau_r\\in(a,b)$, $r=1,\\ldots,S$. Standard\nfunctional linear regression with $S=0$ as well as the point impact model\nof \\citet{McKeagueSen2010}, which assumes $\\beta(t)\\equiv0$ and\n$S=1$, are special cases\nof the above model.\n\nIf $S=0$, then (\\ref{impact-model}) reduces to $Y_i= \\int_a^b\\beta\n(t)X_i(t)\\,dt +\\varepsilon_i$. This\nmodel has been studied in depth in theoretical and applied statistical\nliterature. The most\nfrequently used approach for estimating $\\beta(t)$ then is based on functional\nprincipal components regression [see, e.g., \\citet{FrankFriedman1993},\n\\citet{Bosq2000}, Cardot, Ferraty and Sarda (\\citeyear{CardotFerratySarda1999}), Cardot, Mas and Sarda (\\citeyear{CardotMasSarda2007}) or M\\\"{u}ller and Stadtm\\\"{u}ller\n(\\citeyear{MuellerStadtmueller2005}) in the context of generalized\nlinear models]. Rates of convergence of the estimates are derived in\n\\citet{HallHorowitz2007} and \\citet{CaiHall2006}. Alternative approaches and\nfurther theoretical\nresults can, for example, be found in Crambes, Kneip and Sarda (\\citeyear{CrambesKneipSarda2009}), \\citet{CardotJohannes2010}, \\citet{ComteJohannes2012} or \\citet{DelaigleHall2012}.\n\nThere are many successful applications of the standard linear\nfunctional regression\nmodel. At the same time, results are often difficult to analyze from\nthe points of\nview of model building and substantial interpretation. The underlying\nproblem is that\n$\\int_a^b\\beta(t)X_i(t)\\,dt$ is a weighted average of the whole\ntrajectory $X_i(\\cdot)$\nwhich makes it difficult to assess specific effects of local\ncharacteristics of the\nprocess. This lead James, Wang and Zhu (\\citeyear{JamesWangZhu2009}) to consider ``interpretable\nfunctional regression'' by assuming that $\\beta(t)=0$ for most points\n$t\\in[a,b]$ and\nidentifying subintervals of $[a,b]$ with nonzero $\\beta(t)$.\n\nA different approach based on impact points is proposed by Ferraty, Hall and Vieu (\\citeyear{FerratyHallVieu2010}). For a pre-specified $q\\in\\mathbb{N,}$ they aim to identify\na function $g$ as well as\nthose design points $\\tau_1,\\ldots,\\tau_q$ which are\n``most influential'' in the sense that $g(X_i(\\tau_1),\\ldots,X_i(\\tau\n_q))$ provides a best possible prediction of $Y_i$. Nonparametric\nsmoothing methods are used to estimate\n$g$, while $\\tau_1,\\ldots,\\tau_q$ are selected by a cross-validation\nprocedure. The method is applied to data from spectroscopy, where it is\nof practical interest to know\nwhich values $X_i(t)$ have greatest influence on $Y_i$.\n\nTo our knowledge, \\citet{McKeagueSen2010} are the first to explicitly\nstudy identifiability and\nestimation of a point of impact in a functional regression model. For\ncentered variables, their model takes the form\n$Y_i=\\beta X_i(\\tau)+\\varepsilon_i$ with a single point of impact $\\tau\\in\n[a,b]$. The underlying process $X$ is assumed to be a fractional\nBrownian motion with Hurst parameter $H$. The approach is motivated by\nthe analysis of\ngene expression data, where a key problem is to identify individual\ngenes associated\nwith the clinical outcome. \\citet{McKeagueSen2010} show that consistent\nestimators are obtained by\nleast squares,\nand that the estimator of $\\tau$ has the rate of convergence $n^{-{1}/{(2H)}}$. The\ncoefficient $\\beta$ can be estimated with a parametric rate of\nconvergence $n^{-{1}/{2}}$.\n\nThere also exists a link between our approach and the work of \\citet{HsingRen2009} who for a given grid $t_1,\\ldots,t_p$ of\nobservation points propose a procedure for estimating linear\ncombinations $m(X_i)=\\sum_{j=1}^p c_j X_i(t_j)$ influencing $Y_i$.\nTheir approach is based on an RKHS formulation of the inverse\nregression dimension-reduction problem which for any $k=1,2,3,\\ldots$\nallows to determine a suitable\nelement $(\\hat c_1,\\ldots,\\hat c_p)^T$ of the eigenspace spanned by\nthe eigenvectors of the $k$ leading eigenvalues\nof the empirical covariance matrix of $(X_{i}(t_1),\\ldots\n,X_{i}(t_p))^T$. They then show consistency of the resulting estimators\n$\\hat m(X_i)$ as $n,p\\rightarrow\\infty$ and then $k\\rightarrow\\infty$.\nNote that (\\ref{impact-model}) necessarily implies that\n$Y_i=m(X_i)+\\varepsilon_i$, where as $p\\rightarrow\\infty$ $m(X_i)$ may be\nwritten as a linear combination as considered by \\citet{HsingRen2009}.\nTheir method\ntherefore\noffers a way to determine consistent estimators $\\hat m(X_i)$ of\n$m(X_i)$, although the structure of the estimator will not allow a\nstraightforward identification of model components.\n\nAssuming a linear relationship between $Y$ and $X$, (\\ref\n{impact-model}) constitutes\na unified approach which incorporates the standard linear regression\nmodel as well\nas specific effects of possible point of impacts. The latter may be of\nsubstantial\ninterest in many applications.\n\nAlthough in this paper we concentrate on the case of unknown points of\nimpact, we want to emphasize that in practice also models with\npre-specified points of impact may be of potential importance. This in\nparticular applies to situations with a functional response variable\n${{\\mathcal} Y}_i(t)$, defined over the same time period $t\\in[a,b]$ as\n$X_i$. For a specified time\npoint $\\tau\\in[a,b]$, the standard approach [see, e.g., He, M{\\\"{u}}ller and Wang (\\citeyear{HeMuellerWang2000})] will then assume that $Y_i:={{\\mathcal} Y}_i(\\tau) =\\int_a^b\\beta_\\tau\n(t)X_i(t)\\,dt+\\varepsilon_i$, where $\\beta_\\tau\\in L^2([a,b])$ may vary\nwith $\\tau$. But the value\n$X_i(\\tau)$ of $X_i$ at the point $\\tau$ of interest may have a\nspecific influence, and the alternative model\n$Y_i:={{\\mathcal} Y}_i(\\tau) =\\int_a^b\\beta_\\tau(t)X_i(t)\\,dt+\\beta_1X_i(\\tau\n)+\\varepsilon_i$ with $S=1$ and a fixed point of impact may be seen as\na promising alternative. The estimation procedure proposed in Section~\\ref{sec5}\ncan also be applied in this situation, and theoretical results imply\nthat under mild conditions $\\beta_1$ as well as $\\beta_\\tau(t)$ can be\nconsistently estimated with nonparametric rates of convergence.\nA similar modification may be\napplied in the related context of functional autoregression, where\n$X_1,\\ldots,X_n$\ndenote a stationary time series of random function, and ${{\\mathcal} Y}(\\tau\n)\\equiv X_i(\\tau)$ is to be predicted from $X_{i-1}$ [see, e.g., \\citet{Bosq2000}].\n\nThe focus of our work lies on developing conditions ensuring\nidentifiability of the\ncomponents of model (\\ref{impact-model}) as well as on determining\nprocedures for estimating number and locations of points of impact,\nregression coefficients and slope parameter.\n\nThe problem of identifiability is studied in detail in Section~\\ref{sec2}. The\nkey assumption\nis that the process possesses ``specific local variation.''\nIntuitively, this means that\nat least some part of the local variation of $X(t)$ in a\nsmall neighborhood $[\\tau-\\epsilon, \\tau+\\epsilon]$ of a point $\\tau\\in\n[a,b]$ is essentially uncorrelated with the remainder of the\ntrajectories outside the interval $[\\tau-\\epsilon, \\tau+\\epsilon]$.\nModel (\\ref{impact-model}) is uniquely identified for\nall processes exhibiting specific local variation. It is also shown\nthat the condition\nof specific local variation is surprisingly weak and only requires some suitable\napproximation properties of the corresponding Karhunen--Lo\\`eve basis.\n\nIdentifiability of (\\ref{impact-model}) does not impose any restriction\non the degree of smoothness of\nthe random functions $X_i$ or of the underlying covariance function.\nThe same is true for\nthe theoretical results of Section~\\ref{sec5} which yield rates of convergence\nof coefficient estimates, provided that points of impact are known or\nthat locations can be estimated with sufficient accuracy.\n\nBut nonsmooth trajectories are advantageous when trying to identify\npoints of impact. In order\nto define a procedure for estimating number and locations of points of impact,\nwe therefore restrict attention to processes whose covariance\nfunction is nonsmooth at the diagonal. It is proved in Section~\\ref{sec3} that\nany such process has specific local variation. Prominent examples are\nthe fractional Brownian motion or the Ornstein--Uhlenbeck process. From\na practical point of view, the setting of processes with nonsmooth\ntrajectories covers a wide range of applications. Examples are given in\nSection~\\ref{sec7} and in the supplementary material [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})],\nwhere the methodology is applied to temperature curves and near\ninfrared data.\n\nAn easily implementable and computationally efficient algorithm for\nestimating number and locations of points of impact is presented in\nSection~\\ref{SEC:4}. The basic idea is to\nperform a decorrelation. Instead of regressing on $X_i(t)$, we analyze\nthe empirical correlation\nbetween $Y _i$ and a process $Z_{\\delta,i}(t):=X_i(t)-\\frac\n{1}{2}(X_i(t-\\delta)+\nX_i(t+\\delta))$ for some $\\delta>0$. For the class of processes defined\nin Section~\\ref{sec3},\n$Z_{\\delta,i}(t)$ is highly correlated with $X_i(t)$ but only possesses\nextremely\nweak correlations with $X_i(s)$ if $|t-s|$ is large. This implies that under\nmodel (\\ref{impact-model}) local maxima\n$\\widehat{\\tau}_r$ of the empirical correlation between $Y_i$ and\n$Z_{\\delta,i}(t)$\nshould be found at locations close to existing points of impact. The\nnumber $S$ is\nthen estimated by a cut-off criterion. It is proved that the resulting estimator\n$\\widehat S$ of $S$ is consistent, and we derive rates of convergence\nfor the estimators\n$\\widehat{\\tau}_r$. In the special case of a fractional Brownian\nmotion and $S=1$,\nwe retrieve the basic results of \\citet{McKeagueSen2010}.\n\nIn Section~\\ref{sec5}, we introduce least squares estimates of $\\beta(t)$ and\n$\\beta_r$, $r=1,\\ldots, S$, based on a Karhunen--Lo\\`eve decomposition.\nRates of convergence for these estimates are then derived. A simulation\nstudy is performed in Section~\\ref{sec6}, while applications to a dataset is\npresented in Section~\\ref{sec7}. The \\hyperref[app]{Appendix} is devoted to the proofs of some of\nthe main results. The remaining proofs as well as the application of\nour method to a second dataset are gathered in the supplementary material.\n\n\n\n\\section{Identifiability}\\label{sec2}\n\n\nOur setup implies that $X_1,\\ldots,X_n$ are i.i.d. random functions with\nthe same distribution as\na generic $X\\in L^2([a,b])$.\nIn the following, we will additionally assume that $X$ possesses a\ncontinuous covariance function\n$\\sigma(t,s)$, $t,s\\in[a,b]$.\n\nIn a natural way, the components of model (\\ref{impact-model}) possess\ndifferent interpretations. The linear\nfunctional $ \\int_a^b \\beta(t) X_i(t) \\,dt$ describes a \\textit{common\neffect} of the\nwhole trajectory $X_i(\\cdot)$ on $Y_i$. The additional terms $ \\sum_{r=1}^S \\beta_r X_i(\\tau_r)$\nquantify \\textit{specific effects} of\nthe functional values $X_i(\\tau_1),\\ldots,X_i(\\tau_S)$ at the points of\nimpact $\\tau_1,\\ldots,\\tau_S$.\nIdentifiability of an impact point $\\tau_r$ quite obviously requires\nthat at least some part of the\nlocal variation of $X_i(t)$ in small neighborhoods of $\\tau_r$, is\nuncorrelated with the remainder of the\ntrajectories. This idea is formalized by introducing the concept of\n``specific local variation.''\n\n\\begin{definition}\\label{de1}\nA process $X\\in L^2([a,b])$ with continuous covariance function $\\sigma\n(\\cdot,\\cdot)$ possesses\n\\textit{specific local variation} if for any $t\\in(a,b)$ and all\nsufficiently small $\\epsilon>0$ there\nexists a real random variable $\\zeta_{\\epsilon,t}(X)$ such that\nwith $f_{\\epsilon,t}(s):=\\frac{\\operatorname{cov}(X(s),\\zeta_{\\epsilon\n,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}$ the following\nconditions are satisfied:\n\n\\begin{longlist}[(iii)]\n\n\\item[(i)] $0<\\operatorname{var}(\\zeta_{\\epsilon,t}(X))<\\infty$,\n\n\\item[(ii)] $f_{\\epsilon,t}(t)>0$,\n\n\\item[(iii)] $|f_{\\epsilon,t}(s)|\\leq(1+\\epsilon)f_{\\epsilon,t}(t)$ for\nall $s\\in[a,b]$,\n\n\\item[(iv)] $|f_{\\epsilon,t}(s)|\\le\\epsilon\\cdot f_{\\epsilon,t}(t)$\nfor all $s\\in[a,b]$ with\n$s\\notin[t-\\epsilon,t+\\epsilon]$.\n\\end{longlist}\n\\end{definition}\n\n The definition of course implies that for given $t\\in(a,b)$\nand small $\\epsilon>0$ any process $X$ with specific local variation\ncan be decomposed into\n\n\n\n", "itemtype": "equation", "pos": 3704, "prevtext": "\n\n\\begin{frontmatter}\n\n\n\\title{Functional linear regression with points of impact}\n\n\n\n\\runtitle{Point impact}\n\n\\begin{aug}\n\n\n\\author[A]{\\fnms{Alois}~\\snm{Kneip}\\corref{}\\thanksref{T1}\\ead[label=e1]{akneip@uni-bonn.de}},\n\\author[B]{\\fnms{Dominik}~\\snm{Po{\\ss}}\\thanksref{T2}\\ead[label=e3]{dposs@uni-bonn.de}}\n\\and\n\\author[C]{\\fnms{Pascal}~\\snm{Sarda}\\ead[label=e2]{Pascal.Sarda@math.ups-tlse.fr}}\n\\runauthor{A. Kneip, D. Poss and P. Sarda}\n\n\\thankstext{T1}{Supported by the DFG through GRK 1707 and the Hausdorff\nCenter for Mathematics.}\n\\thankstext{T2}{Supported by the DFG through GRK 1707.} \n\n\\affiliation{Universit\\\"{a}t Bonn and Institut de Math\\'ematiques de Toulouse}\n\\address[A]{A. Kneip\\\\\nInstitut f\\\"ur Finanzmarkt\\\"okonomik und Statistik\\\\\nDepartment of Economics and Hausdorff\\\\\nCenter for Mathematics\\\\\nUniversit\\\"at Bonn\\\\\nAdenauerallee 24-26\\\\\n53113 Bonn\\\\\nGermany\\\\\n\\printead{e1}}\n\n\\address[B]{D. Poss\\\\\nBonn Graduate School of Economics\\\\\nDepartment of Economics\\\\\nInstitut f\\\"ur Finanzmarkt\\\"okonomik\\\\\n\\quad und Statistik \\\\\nUniversit\\\"at Bonn\\\\\nAdenauerallee 24-26\\\\\n53113 Bonn\\\\\nGermany\\\\\n\\printead{e3}}\n\n\\address[C]{P. Sarda\\\\\nInstitut de Math\\'ematiques de Toulouse; UMR 5219 \\\\\nUniversit\\'{e} de Toulouse and CNRS\\\\\n118, Route de Narbonne\\\\\n31062 Toulouse Cedex\\\\\nFrance\\\\\n\\printead{e2}}\n\n\n\\end{aug}\n\n\n\n\\received{\\smonth{7} \\syear{2014}}\n\n\n\\revised{\\smonth{2} \\syear{2015}}\n\n\n\n\n\\begin{abstract}\nThe paper considers functional linear regression, where scalar\nresponses $Y_1,\\ldots,Y_n$ are modeled in dependence of i.i.d. random functions\n$X_1,\\ldots, X_n$.\nWe study\na generalization of the classical functional linear regression model.\nIt is assumed that there exists an unknown number of ``points of\nimpact,'' that is, discrete observation times where the corresponding\nfunctional values possess significant influences on the response\nvariable. In addition to estimating\na functional slope parameter, the problem then is to determine the\nnumber and locations of points of impact\nas well as corresponding regression coefficients.\nIdentifiability of the generalized model is considered in detail. It is\nshown that points of impact are\nidentifiable if the underlying process generating $X_1,\\ldots,X_n$\npossesses ``specific local variation.''\nExamples are well-known processes like the Brownian motion, fractional\nBrownian motion or the\nOrnstein--Uhlenbeck process.\nThe paper then proposes an easily implementable method for estimating\nthe number and locations of points of impact. It is shown that this\nnumber can be estimated consistently. Furthermore, rates of convergence for\nlocation estimates, regression coefficients and the slope parameter are derived.\nFinally, some simulation results as well as a real data application are\npresented.\n\\end{abstract}\n\n\n\n\n\\begin{keyword}[class=AMS]\n\\kwd[Primary ]{62G08}\n\\kwd{62M99}\n\\kwd[; secondary ]{62J05}\n\\end{keyword}\n\n\\begin{keyword}\n\\kwd{Functional linear regression}\n\\kwd{model selection}\n\\kwd{stochastic processes}\n\\kwd{nonstandard asymptotics}\n\\end{keyword}\n\n\n\n\n\n\n\n\n\n\\end{frontmatter}\n\n\n\n\\section{Introduction}\\label{sec1}\n\n\nWe consider linear regression involving a scalar response variable $Y$\nand a functional predictor\nvariable $X\\in L^2([a,b])$, where $[a,b]$ is a bounded interval of\n$\\mathbb{R}$. It is assumed that data consist of an i.i.d. sample\n$(X_i,Y_i)$, $i=1,\\ldots,n$, from $(X,Y)$. The functional variable $X$\nis such that $\\mathbb{E}( \\int_a^bX^2(t)\\,dt)<+\\infty$ and for\nsimplicity the variables are supposed to be centered in the following:\n$\\mathbb{E}(Y)=0$ and $\\mathbb{E}(X(t))=0$ for $t\\in[a,b]$ a.e.\n\nIn this paper, we study the following \\textit{functional linear\nregression model with points of impact}\n\n\n\n", "index": 1, "text": "\\begin{equation}\n\\label{impact-model} Y_i= \\int_a^b\n\\beta(t)X_i(t)\\,dt + \\sum_{r=1}^S\n\\beta_r X_i(\\tau _r)+\\varepsilon_i,\\qquad\ni=1,\\ldots,n,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"Y_{i}=\\int_{a}^{b}\\beta(t)X_{i}(t)\\,dt+\\sum_{r=1}^{S}\\beta_{r}X_{i}(\\tau_{r})+%&#10;\\varepsilon_{i},\\qquad i=1,\\ldots,n,\" display=\"block\"><mrow><mrow><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>a</mi><mi>b</mi></msubsup><mrow><mi>\u03b2</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><msub><mi>\u03b5</mi><mi>i</mi></msub></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>n</mi></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nwhere $X_{\\epsilon,t}(s)=X(s)-\\zeta_{\\epsilon,t}(X) f_{\\epsilon,t}(s)$\nis a process which is\nuncorrelated with $\\zeta_{\\epsilon,t}(X)$. If $\\sigma_{\\epsilon,t}(\\cdot\n,\\cdot)$ denotes the\ncovariance function of $X_{\\epsilon,t}(s)$, then obviously\n\n\n\n", "itemtype": "equation", "pos": 16865, "prevtext": "\n\n\nwhere $\\varepsilon_i$, $i=1,\\ldots,n$ are i.i.d. centered real random\nvariables with\n$\\mathbb{E}(\\varepsilon_i^2)=\\sigma^2<\\infty$, which are independent of\n$X_i(t)$ for all $t$,\n$\\beta\\in L^2([a,b])$ is an unknown, bounded slope function and\n$ \\int_a^b \\beta(t) X_i(t) \\,dt$ describes a common effect of the\nwhole trajectory $X_i(\\cdot)$ on $Y_i$. In addition, the model\nincorporates an\nunknown number $S\\in\\mathbb{N}$ of ``points of impact,'' that is, \\emph{specific} time points $\\tau_1,\\ldots,\\tau_S$ with the\nproperty that the corresponding functional values\n$X_i(\\tau_1),\\ldots,X_i(\\tau_S)$ possess some significant influence on\nthe response variable\n$Y_i$. The function $\\beta(t)$, the number $S\\geq0$, as well as $\\tau\n_r$ and $\\beta_r$,\n$r=1,\\ldots,S$, are unknown and have to be estimated from the data.\nThroughout the paper, we will assume that all points of impact are in the\ninterior of the interval, $\\tau_r\\in(a,b)$, $r=1,\\ldots,S$. Standard\nfunctional linear regression with $S=0$ as well as the point impact model\nof \\citet{McKeagueSen2010}, which assumes $\\beta(t)\\equiv0$ and\n$S=1$, are special cases\nof the above model.\n\nIf $S=0$, then (\\ref{impact-model}) reduces to $Y_i= \\int_a^b\\beta\n(t)X_i(t)\\,dt +\\varepsilon_i$. This\nmodel has been studied in depth in theoretical and applied statistical\nliterature. The most\nfrequently used approach for estimating $\\beta(t)$ then is based on functional\nprincipal components regression [see, e.g., \\citet{FrankFriedman1993},\n\\citet{Bosq2000}, Cardot, Ferraty and Sarda (\\citeyear{CardotFerratySarda1999}), Cardot, Mas and Sarda (\\citeyear{CardotMasSarda2007}) or M\\\"{u}ller and Stadtm\\\"{u}ller\n(\\citeyear{MuellerStadtmueller2005}) in the context of generalized\nlinear models]. Rates of convergence of the estimates are derived in\n\\citet{HallHorowitz2007} and \\citet{CaiHall2006}. Alternative approaches and\nfurther theoretical\nresults can, for example, be found in Crambes, Kneip and Sarda (\\citeyear{CrambesKneipSarda2009}), \\citet{CardotJohannes2010}, \\citet{ComteJohannes2012} or \\citet{DelaigleHall2012}.\n\nThere are many successful applications of the standard linear\nfunctional regression\nmodel. At the same time, results are often difficult to analyze from\nthe points of\nview of model building and substantial interpretation. The underlying\nproblem is that\n$\\int_a^b\\beta(t)X_i(t)\\,dt$ is a weighted average of the whole\ntrajectory $X_i(\\cdot)$\nwhich makes it difficult to assess specific effects of local\ncharacteristics of the\nprocess. This lead James, Wang and Zhu (\\citeyear{JamesWangZhu2009}) to consider ``interpretable\nfunctional regression'' by assuming that $\\beta(t)=0$ for most points\n$t\\in[a,b]$ and\nidentifying subintervals of $[a,b]$ with nonzero $\\beta(t)$.\n\nA different approach based on impact points is proposed by Ferraty, Hall and Vieu (\\citeyear{FerratyHallVieu2010}). For a pre-specified $q\\in\\mathbb{N,}$ they aim to identify\na function $g$ as well as\nthose design points $\\tau_1,\\ldots,\\tau_q$ which are\n``most influential'' in the sense that $g(X_i(\\tau_1),\\ldots,X_i(\\tau\n_q))$ provides a best possible prediction of $Y_i$. Nonparametric\nsmoothing methods are used to estimate\n$g$, while $\\tau_1,\\ldots,\\tau_q$ are selected by a cross-validation\nprocedure. The method is applied to data from spectroscopy, where it is\nof practical interest to know\nwhich values $X_i(t)$ have greatest influence on $Y_i$.\n\nTo our knowledge, \\citet{McKeagueSen2010} are the first to explicitly\nstudy identifiability and\nestimation of a point of impact in a functional regression model. For\ncentered variables, their model takes the form\n$Y_i=\\beta X_i(\\tau)+\\varepsilon_i$ with a single point of impact $\\tau\\in\n[a,b]$. The underlying process $X$ is assumed to be a fractional\nBrownian motion with Hurst parameter $H$. The approach is motivated by\nthe analysis of\ngene expression data, where a key problem is to identify individual\ngenes associated\nwith the clinical outcome. \\citet{McKeagueSen2010} show that consistent\nestimators are obtained by\nleast squares,\nand that the estimator of $\\tau$ has the rate of convergence $n^{-{1}/{(2H)}}$. The\ncoefficient $\\beta$ can be estimated with a parametric rate of\nconvergence $n^{-{1}/{2}}$.\n\nThere also exists a link between our approach and the work of \\citet{HsingRen2009} who for a given grid $t_1,\\ldots,t_p$ of\nobservation points propose a procedure for estimating linear\ncombinations $m(X_i)=\\sum_{j=1}^p c_j X_i(t_j)$ influencing $Y_i$.\nTheir approach is based on an RKHS formulation of the inverse\nregression dimension-reduction problem which for any $k=1,2,3,\\ldots$\nallows to determine a suitable\nelement $(\\hat c_1,\\ldots,\\hat c_p)^T$ of the eigenspace spanned by\nthe eigenvectors of the $k$ leading eigenvalues\nof the empirical covariance matrix of $(X_{i}(t_1),\\ldots\n,X_{i}(t_p))^T$. They then show consistency of the resulting estimators\n$\\hat m(X_i)$ as $n,p\\rightarrow\\infty$ and then $k\\rightarrow\\infty$.\nNote that (\\ref{impact-model}) necessarily implies that\n$Y_i=m(X_i)+\\varepsilon_i$, where as $p\\rightarrow\\infty$ $m(X_i)$ may be\nwritten as a linear combination as considered by \\citet{HsingRen2009}.\nTheir method\ntherefore\noffers a way to determine consistent estimators $\\hat m(X_i)$ of\n$m(X_i)$, although the structure of the estimator will not allow a\nstraightforward identification of model components.\n\nAssuming a linear relationship between $Y$ and $X$, (\\ref\n{impact-model}) constitutes\na unified approach which incorporates the standard linear regression\nmodel as well\nas specific effects of possible point of impacts. The latter may be of\nsubstantial\ninterest in many applications.\n\nAlthough in this paper we concentrate on the case of unknown points of\nimpact, we want to emphasize that in practice also models with\npre-specified points of impact may be of potential importance. This in\nparticular applies to situations with a functional response variable\n${{\\mathcal} Y}_i(t)$, defined over the same time period $t\\in[a,b]$ as\n$X_i$. For a specified time\npoint $\\tau\\in[a,b]$, the standard approach [see, e.g., He, M{\\\"{u}}ller and Wang (\\citeyear{HeMuellerWang2000})] will then assume that $Y_i:={{\\mathcal} Y}_i(\\tau) =\\int_a^b\\beta_\\tau\n(t)X_i(t)\\,dt+\\varepsilon_i$, where $\\beta_\\tau\\in L^2([a,b])$ may vary\nwith $\\tau$. But the value\n$X_i(\\tau)$ of $X_i$ at the point $\\tau$ of interest may have a\nspecific influence, and the alternative model\n$Y_i:={{\\mathcal} Y}_i(\\tau) =\\int_a^b\\beta_\\tau(t)X_i(t)\\,dt+\\beta_1X_i(\\tau\n)+\\varepsilon_i$ with $S=1$ and a fixed point of impact may be seen as\na promising alternative. The estimation procedure proposed in Section~\\ref{sec5}\ncan also be applied in this situation, and theoretical results imply\nthat under mild conditions $\\beta_1$ as well as $\\beta_\\tau(t)$ can be\nconsistently estimated with nonparametric rates of convergence.\nA similar modification may be\napplied in the related context of functional autoregression, where\n$X_1,\\ldots,X_n$\ndenote a stationary time series of random function, and ${{\\mathcal} Y}(\\tau\n)\\equiv X_i(\\tau)$ is to be predicted from $X_{i-1}$ [see, e.g., \\citet{Bosq2000}].\n\nThe focus of our work lies on developing conditions ensuring\nidentifiability of the\ncomponents of model (\\ref{impact-model}) as well as on determining\nprocedures for estimating number and locations of points of impact,\nregression coefficients and slope parameter.\n\nThe problem of identifiability is studied in detail in Section~\\ref{sec2}. The\nkey assumption\nis that the process possesses ``specific local variation.''\nIntuitively, this means that\nat least some part of the local variation of $X(t)$ in a\nsmall neighborhood $[\\tau-\\epsilon, \\tau+\\epsilon]$ of a point $\\tau\\in\n[a,b]$ is essentially uncorrelated with the remainder of the\ntrajectories outside the interval $[\\tau-\\epsilon, \\tau+\\epsilon]$.\nModel (\\ref{impact-model}) is uniquely identified for\nall processes exhibiting specific local variation. It is also shown\nthat the condition\nof specific local variation is surprisingly weak and only requires some suitable\napproximation properties of the corresponding Karhunen--Lo\\`eve basis.\n\nIdentifiability of (\\ref{impact-model}) does not impose any restriction\non the degree of smoothness of\nthe random functions $X_i$ or of the underlying covariance function.\nThe same is true for\nthe theoretical results of Section~\\ref{sec5} which yield rates of convergence\nof coefficient estimates, provided that points of impact are known or\nthat locations can be estimated with sufficient accuracy.\n\nBut nonsmooth trajectories are advantageous when trying to identify\npoints of impact. In order\nto define a procedure for estimating number and locations of points of impact,\nwe therefore restrict attention to processes whose covariance\nfunction is nonsmooth at the diagonal. It is proved in Section~\\ref{sec3} that\nany such process has specific local variation. Prominent examples are\nthe fractional Brownian motion or the Ornstein--Uhlenbeck process. From\na practical point of view, the setting of processes with nonsmooth\ntrajectories covers a wide range of applications. Examples are given in\nSection~\\ref{sec7} and in the supplementary material [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})],\nwhere the methodology is applied to temperature curves and near\ninfrared data.\n\nAn easily implementable and computationally efficient algorithm for\nestimating number and locations of points of impact is presented in\nSection~\\ref{SEC:4}. The basic idea is to\nperform a decorrelation. Instead of regressing on $X_i(t)$, we analyze\nthe empirical correlation\nbetween $Y _i$ and a process $Z_{\\delta,i}(t):=X_i(t)-\\frac\n{1}{2}(X_i(t-\\delta)+\nX_i(t+\\delta))$ for some $\\delta>0$. For the class of processes defined\nin Section~\\ref{sec3},\n$Z_{\\delta,i}(t)$ is highly correlated with $X_i(t)$ but only possesses\nextremely\nweak correlations with $X_i(s)$ if $|t-s|$ is large. This implies that under\nmodel (\\ref{impact-model}) local maxima\n$\\widehat{\\tau}_r$ of the empirical correlation between $Y_i$ and\n$Z_{\\delta,i}(t)$\nshould be found at locations close to existing points of impact. The\nnumber $S$ is\nthen estimated by a cut-off criterion. It is proved that the resulting estimator\n$\\widehat S$ of $S$ is consistent, and we derive rates of convergence\nfor the estimators\n$\\widehat{\\tau}_r$. In the special case of a fractional Brownian\nmotion and $S=1$,\nwe retrieve the basic results of \\citet{McKeagueSen2010}.\n\nIn Section~\\ref{sec5}, we introduce least squares estimates of $\\beta(t)$ and\n$\\beta_r$, $r=1,\\ldots, S$, based on a Karhunen--Lo\\`eve decomposition.\nRates of convergence for these estimates are then derived. A simulation\nstudy is performed in Section~\\ref{sec6}, while applications to a dataset is\npresented in Section~\\ref{sec7}. The \\hyperref[app]{Appendix} is devoted to the proofs of some of\nthe main results. The remaining proofs as well as the application of\nour method to a second dataset are gathered in the supplementary material.\n\n\n\n\\section{Identifiability}\\label{sec2}\n\n\nOur setup implies that $X_1,\\ldots,X_n$ are i.i.d. random functions with\nthe same distribution as\na generic $X\\in L^2([a,b])$.\nIn the following, we will additionally assume that $X$ possesses a\ncontinuous covariance function\n$\\sigma(t,s)$, $t,s\\in[a,b]$.\n\nIn a natural way, the components of model (\\ref{impact-model}) possess\ndifferent interpretations. The linear\nfunctional $ \\int_a^b \\beta(t) X_i(t) \\,dt$ describes a \\textit{common\neffect} of the\nwhole trajectory $X_i(\\cdot)$ on $Y_i$. The additional terms $ \\sum_{r=1}^S \\beta_r X_i(\\tau_r)$\nquantify \\textit{specific effects} of\nthe functional values $X_i(\\tau_1),\\ldots,X_i(\\tau_S)$ at the points of\nimpact $\\tau_1,\\ldots,\\tau_S$.\nIdentifiability of an impact point $\\tau_r$ quite obviously requires\nthat at least some part of the\nlocal variation of $X_i(t)$ in small neighborhoods of $\\tau_r$, is\nuncorrelated with the remainder of the\ntrajectories. This idea is formalized by introducing the concept of\n``specific local variation.''\n\n\\begin{definition}\\label{de1}\nA process $X\\in L^2([a,b])$ with continuous covariance function $\\sigma\n(\\cdot,\\cdot)$ possesses\n\\textit{specific local variation} if for any $t\\in(a,b)$ and all\nsufficiently small $\\epsilon>0$ there\nexists a real random variable $\\zeta_{\\epsilon,t}(X)$ such that\nwith $f_{\\epsilon,t}(s):=\\frac{\\operatorname{cov}(X(s),\\zeta_{\\epsilon\n,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}$ the following\nconditions are satisfied:\n\n\\begin{longlist}[(iii)]\n\n\\item[(i)] $0<\\operatorname{var}(\\zeta_{\\epsilon,t}(X))<\\infty$,\n\n\\item[(ii)] $f_{\\epsilon,t}(t)>0$,\n\n\\item[(iii)] $|f_{\\epsilon,t}(s)|\\leq(1+\\epsilon)f_{\\epsilon,t}(t)$ for\nall $s\\in[a,b]$,\n\n\\item[(iv)] $|f_{\\epsilon,t}(s)|\\le\\epsilon\\cdot f_{\\epsilon,t}(t)$\nfor all $s\\in[a,b]$ with\n$s\\notin[t-\\epsilon,t+\\epsilon]$.\n\\end{longlist}\n\\end{definition}\n\n The definition of course implies that for given $t\\in(a,b)$\nand small $\\epsilon>0$ any process $X$ with specific local variation\ncan be decomposed into\n\n\n\n", "index": 3, "text": "\\begin{equation}\nX(s)=X_{\\epsilon,t}(s) + \\zeta_{\\epsilon,t}(X) f_{\\epsilon,t}(s),\\qquad s\n\\in[a,b], \\label{decompeps}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"X(s)=X_{\\epsilon,t}(s)+\\zeta_{\\epsilon,t}(X)f_{\\epsilon,t}(s),\\qquad s\\in[a,b],\" display=\"block\"><mrow><mrow><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>X</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>\u03b6</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>s</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nBy condition (iv), we can infer that for small $\\epsilon>0$ the\ncomponent $\\zeta_{\\epsilon,t}(X)\\times\\break  f_{\\epsilon,t}(s)$\nessentially quantifies local variation in a small interval around the\ngiven point $t$, since\n$\\frac{f_{\\epsilon,t}(s)^2}{f_{\\epsilon,t}(t)^2}\\leq\\epsilon^2$ for\nall $s\\notin[t-\\epsilon,t+\\epsilon]$.\nWhen $X$ is a standard Brownian motion it is easily verified that\nconditions (i)--(iv) are satisfied for $\\zeta_{\\epsilon,t}(X)=\nX(t)-\\frac{1}{2}(X(t-\\epsilon)+X(t+\\epsilon))$. Then $f_{\\epsilon\n,t}(s):=\\frac{\\operatorname{cov}(X(s),\\zeta_{\\epsilon,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}=1$\nfor $t=s$, while $f_{\\epsilon,t}(s)=0$ for all $s\\in[a,b]$ with\n$|t-s|\\geq\\epsilon$. Figure~\\ref{fig:CovBM} illustrates the\ndecomposition of $X(s)$ in $X_{\\epsilon,t}(s)$ and $\\zeta_{\\epsilon\n,t}(X) f_{\\epsilon,t}(s)$ for a trajectory of a Brownian motion.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f01.eps}\n\n\\caption{The figure illustrates the\ndecomposition of a trajectory from a Brownian motion $X$ (black line)\nin $X_{\\epsilon,t}$ (red line) and $\\zeta_{\\epsilon,t}(X) f_{\\epsilon\n,t}$ (blue line). The component $\\zeta_{\\epsilon,t}(X) f_{\\epsilon,t}$\ncan be seen to quantify the local variation of $X$ in an interval\naround $t$.}\n\\label{fig:CovBM}\n\\end{figure}\n\n\n\nThe following theorem shows that under our setup all impact points in\nmodel~(\\ref{impact-model}) are uniquely identified for any process\npossessing specific local variation. Recall that (\\ref{impact-model})\nimplies that\n\n", "itemtype": "equation", "pos": 17248, "prevtext": "\n\nwhere $X_{\\epsilon,t}(s)=X(s)-\\zeta_{\\epsilon,t}(X) f_{\\epsilon,t}(s)$\nis a process which is\nuncorrelated with $\\zeta_{\\epsilon,t}(X)$. If $\\sigma_{\\epsilon,t}(\\cdot\n,\\cdot)$ denotes the\ncovariance function of $X_{\\epsilon,t}(s)$, then obviously\n\n\n\n", "index": 5, "text": "\\begin{equation}\n\\label{decomsig} \\sigma(s,u)=\\sigma_{\\epsilon,t}(s,u)+\\operatorname{var}\\bigl(\n\\zeta_{\\epsilon,t}(X)\\bigr) f_{\\epsilon,t}(s) f_{\\epsilon,t}(u),\\qquad s,u\n\\in[a,b].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\sigma(s,u)=\\sigma_{\\epsilon,t}(s,u)+\\operatorname{var}\\bigl{(}\\zeta_{\\epsilon%&#10;,t}(X)\\bigr{)}f_{\\epsilon,t}(s)f_{\\epsilon,t}(u),\\qquad s,u\\in[a,b].\" display=\"block\"><mrow><mrow><mrow><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msub><mi>\u03c3</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\operatorname</mtext></merror><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>\u03b6</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mrow><mi>\u03f5</mi><mo>,</mo><mi>t</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mi>s</mi></mrow></mrow><mo>,</mo><mrow><mi>u</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\n\n\\begin{thmm} \\label{thmident}\nUnder our setup, assume that $X$ possesses specific local variation.\nThen, for any bounded function $\\beta^*\\in L^2([a,b])$, all $S^*\\geq\nS$, all $\\beta_1^*,\\ldots,\\beta_{S^*}^*\\in\\mathbb{R}$, and\nall $\\tau_1,\\ldots,\\tau_{S^*}\\in(a,b)$ with $\\tau_{k}\\notin\\{\\tau_1,\\ldots\n,\\tau_S\\}$, $k=S+1,\\ldots,S^*$, we obtain\n\n\n\\begin{eqnarray}\n\\mathbb{E} \\Biggl( \\Biggl(m(X)-\\int_a^b\n\\beta^*(t)X(t)\\,dt - \\sum_{r=1}^{S^*}\n\\beta_r^*X_i(\\tau_r) \\Biggr)^2\n\\Biggr)>0, \\label{eqident}\n\\end{eqnarray}\n\nwhenever $\\mathbb{E}((\\int_a^b(\\beta(t)-\\beta^*(t))X(t)\\,dt)^2)>0$,\nor $\\sup_{r=1,\\ldots,S}|\\beta_r-\\beta^*_r|>0$,\nor $\\sup_{r=S+1,\\ldots,S^*}|\\beta^*_r|>0$.\n\\end{thmm}\n\nThe question arises whether it is possible to find general conditions\nwhich ensure that a process\npossesses specific variation. From a theoretical point of view, the\nKarhunen--Lo\\`eve decomposition\nprovides a tool for analyzing this problem.\n\nFor $f,g\\in L^2([a,b])$ let $\\langle f,g \\rangle=\n\\int_a^b f(t)g(t)\\,dt$ and $\\|f\\|$ the associated norm. We will use\n$\\lambda_1\\geq\\lambda_2\\geq\\cdots$ to\ndenote the nonzero eigenvalues of the covariance operator $\\Gamma$ of\n$X$, while $\\psi_1,\\psi_2,\\ldots$\ndenote a corresponding system of orthonormal eigenfunctions.\nIt is then well known that $X$ can be decomposed\nin the form\n\n\n\n", "itemtype": "equation", "pos": 18962, "prevtext": "\n\nBy condition (iv), we can infer that for small $\\epsilon>0$ the\ncomponent $\\zeta_{\\epsilon,t}(X)\\times\\break  f_{\\epsilon,t}(s)$\nessentially quantifies local variation in a small interval around the\ngiven point $t$, since\n$\\frac{f_{\\epsilon,t}(s)^2}{f_{\\epsilon,t}(t)^2}\\leq\\epsilon^2$ for\nall $s\\notin[t-\\epsilon,t+\\epsilon]$.\nWhen $X$ is a standard Brownian motion it is easily verified that\nconditions (i)--(iv) are satisfied for $\\zeta_{\\epsilon,t}(X)=\nX(t)-\\frac{1}{2}(X(t-\\epsilon)+X(t+\\epsilon))$. Then $f_{\\epsilon\n,t}(s):=\\frac{\\operatorname{cov}(X(s),\\zeta_{\\epsilon,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}=1$\nfor $t=s$, while $f_{\\epsilon,t}(s)=0$ for all $s\\in[a,b]$ with\n$|t-s|\\geq\\epsilon$. Figure~\\ref{fig:CovBM} illustrates the\ndecomposition of $X(s)$ in $X_{\\epsilon,t}(s)$ and $\\zeta_{\\epsilon\n,t}(X) f_{\\epsilon,t}(s)$ for a trajectory of a Brownian motion.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f01.eps}\n\n\\caption{The figure illustrates the\ndecomposition of a trajectory from a Brownian motion $X$ (black line)\nin $X_{\\epsilon,t}$ (red line) and $\\zeta_{\\epsilon,t}(X) f_{\\epsilon\n,t}$ (blue line). The component $\\zeta_{\\epsilon,t}(X) f_{\\epsilon,t}$\ncan be seen to quantify the local variation of $X$ in an interval\naround $t$.}\n\\label{fig:CovBM}\n\\end{figure}\n\n\n\nThe following theorem shows that under our setup all impact points in\nmodel~(\\ref{impact-model}) are uniquely identified for any process\npossessing specific local variation. Recall that (\\ref{impact-model})\nimplies that\n\n", "index": 7, "text": "\n\\[\nm(X):=\\mathbb{E}(Y|X) = \\int_a^b\n\\beta(t)X(t)\\,dt + \\sum_{r=1}^S\\beta\n_rX(\\tau_r).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"m(X):=\\mathbb{E}(Y|X)=\\int_{a}^{b}\\beta(t)X(t)\\,dt+\\sum_{r=1}^{S}\\beta_{r}X(%&#10;\\tau_{r}).\" display=\"block\"><mrow><mi>m</mi><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow><mo>:=</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">|</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>a</mi><mi>b</mi></msubsup><mi>\u03b2</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mi>d</mi><mi>t</mi><mo>+</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><msub><mi>\u03b2</mi><mi>r</mi></msub><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nwhere $\\mathbb{E}(\\langle X,\\psi_r\\rangle^2)=\\lambda_r$, and $\\langle\nX,\\psi_r\\rangle$ is uncorrelated with\n$\\langle X,\\psi_l\\rangle$ for $l\\neq r$.\n\nThe existence of specific local variation requires that the structure\nof the process is not too simple in the sense that the realizations\n$X_i$ a.s. lie in a finite dimensional subspace of $L^2([a,b])$. Indeed,\nif $\\Gamma$ only possesses a finite number $K<\\infty$ of nonzero\neigenvalues, then model (\\ref{impact-model}) is not identifiable. This\nis easily verified:\n$X(t)=\\sum_{r=1}^K \\langle X,\\psi_r \\rangle\\psi_r(t)$ implies that\\vadjust{\\goodbreak}\n$\\int_a^b\\beta(t)X(t)\\,dt=\\sum_{r=1}^K \\alpha_r \\langle X,\\psi_r \\rangle$\nwith $\\alpha_r=\\langle\\psi_r,\\beta\\rangle$.\nHence, there are infinitely many different\ncollections of $K$ points $\\tau_1,\\ldots,\\tau_K$ and corresponding\ncoefficients $\\beta_1,\\ldots,\\beta_K$ such that\n\n", "itemtype": "equation", "pos": 20366, "prevtext": "\n\n\n\\begin{thmm} \\label{thmident}\nUnder our setup, assume that $X$ possesses specific local variation.\nThen, for any bounded function $\\beta^*\\in L^2([a,b])$, all $S^*\\geq\nS$, all $\\beta_1^*,\\ldots,\\beta_{S^*}^*\\in\\mathbb{R}$, and\nall $\\tau_1,\\ldots,\\tau_{S^*}\\in(a,b)$ with $\\tau_{k}\\notin\\{\\tau_1,\\ldots\n,\\tau_S\\}$, $k=S+1,\\ldots,S^*$, we obtain\n\n\n\\begin{eqnarray}\n\\mathbb{E} \\Biggl( \\Biggl(m(X)-\\int_a^b\n\\beta^*(t)X(t)\\,dt - \\sum_{r=1}^{S^*}\n\\beta_r^*X_i(\\tau_r) \\Biggr)^2\n\\Biggr)>0, \\label{eqident}\n\\end{eqnarray}\n\nwhenever $\\mathbb{E}((\\int_a^b(\\beta(t)-\\beta^*(t))X(t)\\,dt)^2)>0$,\nor $\\sup_{r=1,\\ldots,S}|\\beta_r-\\beta^*_r|>0$,\nor $\\sup_{r=S+1,\\ldots,S^*}|\\beta^*_r|>0$.\n\\end{thmm}\n\nThe question arises whether it is possible to find general conditions\nwhich ensure that a process\npossesses specific variation. From a theoretical point of view, the\nKarhunen--Lo\\`eve decomposition\nprovides a tool for analyzing this problem.\n\nFor $f,g\\in L^2([a,b])$ let $\\langle f,g \\rangle=\n\\int_a^b f(t)g(t)\\,dt$ and $\\|f\\|$ the associated norm. We will use\n$\\lambda_1\\geq\\lambda_2\\geq\\cdots$ to\ndenote the nonzero eigenvalues of the covariance operator $\\Gamma$ of\n$X$, while $\\psi_1,\\psi_2,\\ldots$\ndenote a corresponding system of orthonormal eigenfunctions.\nIt is then well known that $X$ can be decomposed\nin the form\n\n\n\n", "index": 9, "text": "\\begin{equation}\nX(t)=\\sum_{r=1}^\\infty\\langle X,\n\\psi_r \\rangle\\psi_r(t), \\label{karlov}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"X(t)=\\sum_{r=1}^{\\infty}\\langle X,\\psi_{r}\\rangle\\psi_{r}(t),\" display=\"block\"><mrow><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u221e</mi></munderover><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mi>X</mi><mo>,</mo><msub><mi>\u03c8</mi><mi>r</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>\u2062</mo><msub><mi>\u03c8</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nMost work in functional data analysis, however, relies on the\nassumption that $\\Gamma$ possesses infinitely many\nnonzero eigenvalues. In theoretically oriented papers, it is often\nassumed that $\\psi_1,\\psi_2,\\ldots$\nform a complete orthonormal system of $L^2([a,b])$ such that $\\Vert\\sum_{r=1}^\\infty\\langle f,\\psi_r \\rangle\n\\psi_r-f\\Vert=0$ for any function $f\\in L^2([a,b])$.\n\n The following theorem shows that\n$X$ possesses specific local variation if for a suitable class of functions\n$L^2$-convergence generalizes to $L^\\infty$-convergence.\n\nFor $t\\in(a,b)$ and $\\epsilon>0$, let ${{\\mathcal} C}(t,\\epsilon,[a,b])$\ndenote the space of all\ncontinuous functions $f\\in L^2([a,b])$ with the properties that\n$f(t)=\\sup_{s\\in[a,b]}f(s)=1$ and $f(s)=0$ for $s\\notin[t-\\epsilon\n,t+\\epsilon]$.\n\n\n\\begin{thmm} \\label{thmkarlov}\nLet $\\psi_1,\\psi_2,\\ldots$\nbe a system of orthonormal eigenfunctions corresponding to the nonzero\neigenvalues of\nthe covariance operator $\\Gamma$ of $X$. If for all $t\\in(a,b)$ there\nexists an $\\epsilon_t>0$ such\nthat\n\n\n\\begin{eqnarray}\n\\label{karlovp0} \\lim_{k\\rightarrow\\infty}\\inf_{f\\in{{\\mathcal} C}(t,\\epsilon,[a,b])}\n\\sup\n_{s\\in[a,b]} \\Biggl|f(s)-\\sum_{r=1}^k\n\\langle f,\\psi_r\\rangle \\psi_r(s)\\Biggr|=0\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\eqntext{\\mbox{for every }\n0<\\epsilon<\\epsilon_t,}\n\\end{eqnarray}\n\nthen the process\n$X$ possesses specific local variation.\n\\end{thmm}\n\nThe message of the theorem is that existence of specific local\nvariation only requires that\nthe underlying basis $\\psi_1,\\psi_2,\\ldots$ possesses suitable\napproximation properties.\nSomewhat surprisingly, the degree of smoothness of the realized\ntrajectories does not play\nany role.\n\nAs an example consider a standard Brownian motion defined on\n$[a,b]=[0,1]$. The corresponding Karhunen--Lo\\`eve decomposition\npossesses eigenvalues $\\lambda_r=\\frac{1}{(r-0.5)^2\\pi^2}$ and\neigenfunctions\\vspace*{1pt} $\\psi_r(t)=\\sqrt{2}\\sin((r-1/2)\\pi t)$, $r=1,2,\\ldots.$\nIn the Supplementary Appendix B [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})], it is verified\nthat this system of orthonormal eigenfunctions satisfies (\\ref\n{karlovp0}). Although all eigenfunctions are smooth,\nit is well known that realized trajectories of a Brownian motion are\na.s. not\ndifferentiable. This can be seen as a consequence of the fact that the\neigenvalues\n$\\lambda_r\\sim\\frac{1}{r^2}$ decrease fairly slowly, and, therefore,\nthe sequence\n$\\mathbb{E}( (\\sum_{r=1}^k \\langle X,\\psi_r \\rangle\\psi_r'(t))^2)= \\sum_{r=1}^k \\lambda_r (\\psi_r'(t))^2$ diverges as $k\\rightarrow\\infty$. At\nthe same time, another process with the same system of\neigenfunctions but exponentially decreasing eigenvalues $\\lambda\n_r^*\\sim\\exp(-r)$ will a.s.\\vadjust{\\goodbreak} show sample paths possessing an infinite\nnumber of derivatives. Theorem~\\ref{thmkarlov} states\nthat any process of this type still has specific local variation.\n\n\n\n\\section{Covariance functions which are nonsmooth at the diagonal}\\label{sec3}\n\n\nIn the following, we will concentrate on developing a theoretical\nframework which allows to define\nan efficient procedure for estimating number and locations of points of impact.\n\nAlthough specific local variation may well be present for processes\npossessing very smooth sample paths, it is clear that detection of\npoints of impact will profit from a high local\nvariability which goes along with nonsmoothness. As pointed out in the\n\\hyperref[sec1]{Introduction}, we also believe that assuming nonsmooth trajectories\nreflect the situation encountered in a number of important\napplications. \\citet{McKeagueSen2010} convincingly demonstrate that\ngenomics data lead to sample paths with fractal behavior. All important\nprocesses analyzed in economics exhibit strong random fluctuations.\nObserved temperatures\nor precipitation rates show wiggly trajectories over time, as can be\nseen in our application in Section~\\ref{sec7}. Furthermore, any growth process\nwill to some extent be influenced by random changes in environmental\nconditions. In functional data analysis, it is common practice to\nsmooth observed (discrete) sample paths and to interpret nonsmooth\ncomponents as\n``errors.'' We want to emphasize that, unless observations are\ninaccurate and there exists some important measurement error, such\ncomponents are an intrinsic part of the process. For many purposes as,\nfor example, functional principal component analysis, smoothing makes a\nlot of sense since local variation\nhas to be seen as nuisance. But in the present context local variation\nactually is a key property for identifying impact points.\n\nTherefore, further development will focus on processes with nonsmooth\nsample paths which will be\nexpressed in terms of a nonsmooth diagonal of the corresponding\ncovariance function $\\sigma(t,s)$.\nIt will be assumed that $\\sigma(t,s)$ possesses nonsmooth trajectories\nwhen passing from $\\sigma(t,t-\\Delta)$ to $\\sigma(t,t+\\Delta)$, but is twice\ncontinuously differentiable for all $(t,s)$, $t\\neq s$. An example is\nthe standard Brownian motion\nwhose covariance function $\\sigma(t,s)=\\min(t,s)$ has a kink at the\ndiagonal. Indeed, in view\nof decomposition (\\ref{decomsig}) a nonsmooth transition at diagonal\nmay be seen as a natural consequence of\npronounced specific local variation.\n\nFor a precise analysis, it will be useful to reparametrize the\ncovariance function. Obviously, the\nsymmetry of $\\sigma(t,s)$ implies that\n\n\\begin{eqnarray*}\n\\sigma(t,s)&=&\\sigma\\bigl(\\tfrac{1}{2}\\bigl(t+s+|t-s|\\bigr),\\tfrac\n{1}{2}\\bigl(t+s-|t-s|\\bigr)\n\\bigr)\\\\\n&=:&\\omega^*\\bigl(t+s,|t-s|\\bigr) \\qquad\\mbox{for all } t,s\\in[a,b].\n\\end{eqnarray*}\n\nInstead of $\\sigma(t,s)$, we may thus equivalently consider the\nfunction $\\omega^*(x,y)$ with $x=t+s$ and\n$y=|t-s|$. When passing from $s=t-\\Delta$ to $s=t+\\Delta$,\nthe degree of smoothness of $\\sigma(t,s)$ at $s=t$ is reflected by the\nbehavior of\n$\\omega^*(2t,y)$ as $y\\rightarrow0$.\n\nFirst, consider the case that $\\sigma$ is twice continuously\ndifferentiable and for fixed $x$ and $y>0$ let\n$\\frac{\\partial}{\\partial y_+}\\omega^*(x,y)|_{y=0}$ denote the right\n(partial) derivative of $\\omega^*(x,y)$ as $y\\rightarrow0$.\nIt is easy to check that in this\ncase for all $t\\in(a,b)$ we obtain\n\n\n\\begin{eqnarray}\\label{der1}\n\\frac{\\partial}{\\partial y_+}\\omega^*(2t,y)\\bigg|_{y=0} &=&\\frac{\\partial\n}{\\partial y} \\sigma\n\\biggl(t+\\frac{y}{2},t-\\frac{y}{2}\\biggr)\\bigg|_{y=0}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&=&\n\\frac{1}{2}\\biggl(\\frac{\\partial}{\\partial s} \\sigma(s,t)\\bigg|_{s=t}-\n\\frac{\\partial}{\\partial s} \\sigma(t,s)\\bigg|_{s=t}\\biggr)=0.\n\\end{eqnarray}\n\n\n\nIn contrast, any process with $\\frac{\\partial}{\\partial y_+}\\omega\n^*(x,y)|_{y=0}\\neq0$ is nonsmooth at the diagonal. If this function\nis smooth for all other points $(x,y)$, $y>0$, then the process,\nsimilar to the Brownian motion, possesses a kink at the diagonal.\nNow note that, for any process with $\\sigma(t,s)=\\omega^*(t+s,|t-s|)$\ncontinuously differentiable for $t\\neq s$ but $\\frac{\\partial}{\\partial\ny_+}\\omega^*(x,y)|_{y=0}<0$, it is possible to find a twice\ncontinuously differentiable function $\\omega(x,y,z)$ with $\\sigma\n(t,s)=\\omega(t,s,|t-s|)$ such that\n$\\frac{\\partial}{\\partial y_+}\\omega^*(t+t,y)|_{y=0}=\\frac{\\partial\n}{\\partial y}\\omega(t,t,y)|_{y=0}$.\n\nIn a still more general setup, the above ideas are formalized by\nAssumption~\\ref{assum1}\nbelow which, as will be shown in Theorem~\\ref{thmcharX}, provides\nsufficient conditions in order to guarantee that the underlying process\n$X$ possesses\nspecific variation. We will also allow for unbounded derivatives as\n$|t-s|\\rightarrow0$.\n\n\n\\begin{assumption} \\label{assum1}\nFor some open subset $\\Omega\\subset\\mathbb{R}^3$ with $[a,b]^2\\times\n[0,b-a]\\subset\\Omega$,\nthere exists a twice continuously differentiable function $\\omega\n:\\Omega\\rightarrow\n\\mathbb{R}$ as well as some $0<\\kappa<2$ such that for all $t,s\\in[a,b]$\n\n\n\n", "itemtype": "equation", "pos": 21352, "prevtext": "\n\nwhere $\\mathbb{E}(\\langle X,\\psi_r\\rangle^2)=\\lambda_r$, and $\\langle\nX,\\psi_r\\rangle$ is uncorrelated with\n$\\langle X,\\psi_l\\rangle$ for $l\\neq r$.\n\nThe existence of specific local variation requires that the structure\nof the process is not too simple in the sense that the realizations\n$X_i$ a.s. lie in a finite dimensional subspace of $L^2([a,b])$. Indeed,\nif $\\Gamma$ only possesses a finite number $K<\\infty$ of nonzero\neigenvalues, then model (\\ref{impact-model}) is not identifiable. This\nis easily verified:\n$X(t)=\\sum_{r=1}^K \\langle X,\\psi_r \\rangle\\psi_r(t)$ implies that\\vadjust{\\goodbreak}\n$\\int_a^b\\beta(t)X(t)\\,dt=\\sum_{r=1}^K \\alpha_r \\langle X,\\psi_r \\rangle$\nwith $\\alpha_r=\\langle\\psi_r,\\beta\\rangle$.\nHence, there are infinitely many different\ncollections of $K$ points $\\tau_1,\\ldots,\\tau_K$ and corresponding\ncoefficients $\\beta_1,\\ldots,\\beta_K$ such that\n\n", "index": 11, "text": "\n\\[\n\\int_a^b\\beta(t)X(t)\\,dt=\\sum\n_{s=1}^K \\alpha_s \\langle X,\n\\psi_s\\rangle= \\sum_{s=1}^K\n\\langle X,\\psi_s \\rangle \\sum_{r=1}^K\n\\beta_r \\psi_s(\\tau_r)= \\sum\n_{r=1}^K \\beta_r X(\n\\tau_r).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\int_{a}^{b}\\beta(t)X(t)\\,dt=\\sum_{s=1}^{K}\\alpha_{s}\\langle X,\\psi_{s}\\rangle%&#10;=\\sum_{s=1}^{K}\\langle X,\\psi_{s}\\rangle\\sum_{r=1}^{K}\\beta_{r}\\psi_{s}(\\tau_{%&#10;r})=\\sum_{r=1}^{K}\\beta_{r}X(\\tau_{r}).\" display=\"block\"><mrow><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>a</mi><mi>b</mi></msubsup><mrow><mi>\u03b2</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>s</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>X</mi><mo>,</mo><msub><mi>\u03c8</mi><mi>s</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mi>X</mi><mo>,</mo><msub><mi>\u03c8</mi><mi>s</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>\u03c8</mi><mi>s</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nMoreover,\n\n\n\n", "itemtype": "equation", "pos": 29409, "prevtext": "\n\nMost work in functional data analysis, however, relies on the\nassumption that $\\Gamma$ possesses infinitely many\nnonzero eigenvalues. In theoretically oriented papers, it is often\nassumed that $\\psi_1,\\psi_2,\\ldots$\nform a complete orthonormal system of $L^2([a,b])$ such that $\\Vert\\sum_{r=1}^\\infty\\langle f,\\psi_r \\rangle\n\\psi_r-f\\Vert=0$ for any function $f\\in L^2([a,b])$.\n\n The following theorem shows that\n$X$ possesses specific local variation if for a suitable class of functions\n$L^2$-convergence generalizes to $L^\\infty$-convergence.\n\nFor $t\\in(a,b)$ and $\\epsilon>0$, let ${{\\mathcal} C}(t,\\epsilon,[a,b])$\ndenote the space of all\ncontinuous functions $f\\in L^2([a,b])$ with the properties that\n$f(t)=\\sup_{s\\in[a,b]}f(s)=1$ and $f(s)=0$ for $s\\notin[t-\\epsilon\n,t+\\epsilon]$.\n\n\n\\begin{thmm} \\label{thmkarlov}\nLet $\\psi_1,\\psi_2,\\ldots$\nbe a system of orthonormal eigenfunctions corresponding to the nonzero\neigenvalues of\nthe covariance operator $\\Gamma$ of $X$. If for all $t\\in(a,b)$ there\nexists an $\\epsilon_t>0$ such\nthat\n\n\n\\begin{eqnarray}\n\\label{karlovp0} \\lim_{k\\rightarrow\\infty}\\inf_{f\\in{{\\mathcal} C}(t,\\epsilon,[a,b])}\n\\sup\n_{s\\in[a,b]} \\Biggl|f(s)-\\sum_{r=1}^k\n\\langle f,\\psi_r\\rangle \\psi_r(s)\\Biggr|=0\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\eqntext{\\mbox{for every }\n0<\\epsilon<\\epsilon_t,}\n\\end{eqnarray}\n\nthen the process\n$X$ possesses specific local variation.\n\\end{thmm}\n\nThe message of the theorem is that existence of specific local\nvariation only requires that\nthe underlying basis $\\psi_1,\\psi_2,\\ldots$ possesses suitable\napproximation properties.\nSomewhat surprisingly, the degree of smoothness of the realized\ntrajectories does not play\nany role.\n\nAs an example consider a standard Brownian motion defined on\n$[a,b]=[0,1]$. The corresponding Karhunen--Lo\\`eve decomposition\npossesses eigenvalues $\\lambda_r=\\frac{1}{(r-0.5)^2\\pi^2}$ and\neigenfunctions\\vspace*{1pt} $\\psi_r(t)=\\sqrt{2}\\sin((r-1/2)\\pi t)$, $r=1,2,\\ldots.$\nIn the Supplementary Appendix B [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})], it is verified\nthat this system of orthonormal eigenfunctions satisfies (\\ref\n{karlovp0}). Although all eigenfunctions are smooth,\nit is well known that realized trajectories of a Brownian motion are\na.s. not\ndifferentiable. This can be seen as a consequence of the fact that the\neigenvalues\n$\\lambda_r\\sim\\frac{1}{r^2}$ decrease fairly slowly, and, therefore,\nthe sequence\n$\\mathbb{E}( (\\sum_{r=1}^k \\langle X,\\psi_r \\rangle\\psi_r'(t))^2)= \\sum_{r=1}^k \\lambda_r (\\psi_r'(t))^2$ diverges as $k\\rightarrow\\infty$. At\nthe same time, another process with the same system of\neigenfunctions but exponentially decreasing eigenvalues $\\lambda\n_r^*\\sim\\exp(-r)$ will a.s.\\vadjust{\\goodbreak} show sample paths possessing an infinite\nnumber of derivatives. Theorem~\\ref{thmkarlov} states\nthat any process of this type still has specific local variation.\n\n\n\n\\section{Covariance functions which are nonsmooth at the diagonal}\\label{sec3}\n\n\nIn the following, we will concentrate on developing a theoretical\nframework which allows to define\nan efficient procedure for estimating number and locations of points of impact.\n\nAlthough specific local variation may well be present for processes\npossessing very smooth sample paths, it is clear that detection of\npoints of impact will profit from a high local\nvariability which goes along with nonsmoothness. As pointed out in the\n\\hyperref[sec1]{Introduction}, we also believe that assuming nonsmooth trajectories\nreflect the situation encountered in a number of important\napplications. \\citet{McKeagueSen2010} convincingly demonstrate that\ngenomics data lead to sample paths with fractal behavior. All important\nprocesses analyzed in economics exhibit strong random fluctuations.\nObserved temperatures\nor precipitation rates show wiggly trajectories over time, as can be\nseen in our application in Section~\\ref{sec7}. Furthermore, any growth process\nwill to some extent be influenced by random changes in environmental\nconditions. In functional data analysis, it is common practice to\nsmooth observed (discrete) sample paths and to interpret nonsmooth\ncomponents as\n``errors.'' We want to emphasize that, unless observations are\ninaccurate and there exists some important measurement error, such\ncomponents are an intrinsic part of the process. For many purposes as,\nfor example, functional principal component analysis, smoothing makes a\nlot of sense since local variation\nhas to be seen as nuisance. But in the present context local variation\nactually is a key property for identifying impact points.\n\nTherefore, further development will focus on processes with nonsmooth\nsample paths which will be\nexpressed in terms of a nonsmooth diagonal of the corresponding\ncovariance function $\\sigma(t,s)$.\nIt will be assumed that $\\sigma(t,s)$ possesses nonsmooth trajectories\nwhen passing from $\\sigma(t,t-\\Delta)$ to $\\sigma(t,t+\\Delta)$, but is twice\ncontinuously differentiable for all $(t,s)$, $t\\neq s$. An example is\nthe standard Brownian motion\nwhose covariance function $\\sigma(t,s)=\\min(t,s)$ has a kink at the\ndiagonal. Indeed, in view\nof decomposition (\\ref{decomsig}) a nonsmooth transition at diagonal\nmay be seen as a natural consequence of\npronounced specific local variation.\n\nFor a precise analysis, it will be useful to reparametrize the\ncovariance function. Obviously, the\nsymmetry of $\\sigma(t,s)$ implies that\n\n\\begin{eqnarray*}\n\\sigma(t,s)&=&\\sigma\\bigl(\\tfrac{1}{2}\\bigl(t+s+|t-s|\\bigr),\\tfrac\n{1}{2}\\bigl(t+s-|t-s|\\bigr)\n\\bigr)\\\\\n&=:&\\omega^*\\bigl(t+s,|t-s|\\bigr) \\qquad\\mbox{for all } t,s\\in[a,b].\n\\end{eqnarray*}\n\nInstead of $\\sigma(t,s)$, we may thus equivalently consider the\nfunction $\\omega^*(x,y)$ with $x=t+s$ and\n$y=|t-s|$. When passing from $s=t-\\Delta$ to $s=t+\\Delta$,\nthe degree of smoothness of $\\sigma(t,s)$ at $s=t$ is reflected by the\nbehavior of\n$\\omega^*(2t,y)$ as $y\\rightarrow0$.\n\nFirst, consider the case that $\\sigma$ is twice continuously\ndifferentiable and for fixed $x$ and $y>0$ let\n$\\frac{\\partial}{\\partial y_+}\\omega^*(x,y)|_{y=0}$ denote the right\n(partial) derivative of $\\omega^*(x,y)$ as $y\\rightarrow0$.\nIt is easy to check that in this\ncase for all $t\\in(a,b)$ we obtain\n\n\n\\begin{eqnarray}\\label{der1}\n\\frac{\\partial}{\\partial y_+}\\omega^*(2t,y)\\bigg|_{y=0} &=&\\frac{\\partial\n}{\\partial y} \\sigma\n\\biggl(t+\\frac{y}{2},t-\\frac{y}{2}\\biggr)\\bigg|_{y=0}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&=&\n\\frac{1}{2}\\biggl(\\frac{\\partial}{\\partial s} \\sigma(s,t)\\bigg|_{s=t}-\n\\frac{\\partial}{\\partial s} \\sigma(t,s)\\bigg|_{s=t}\\biggr)=0.\n\\end{eqnarray}\n\n\n\nIn contrast, any process with $\\frac{\\partial}{\\partial y_+}\\omega\n^*(x,y)|_{y=0}\\neq0$ is nonsmooth at the diagonal. If this function\nis smooth for all other points $(x,y)$, $y>0$, then the process,\nsimilar to the Brownian motion, possesses a kink at the diagonal.\nNow note that, for any process with $\\sigma(t,s)=\\omega^*(t+s,|t-s|)$\ncontinuously differentiable for $t\\neq s$ but $\\frac{\\partial}{\\partial\ny_+}\\omega^*(x,y)|_{y=0}<0$, it is possible to find a twice\ncontinuously differentiable function $\\omega(x,y,z)$ with $\\sigma\n(t,s)=\\omega(t,s,|t-s|)$ such that\n$\\frac{\\partial}{\\partial y_+}\\omega^*(t+t,y)|_{y=0}=\\frac{\\partial\n}{\\partial y}\\omega(t,t,y)|_{y=0}$.\n\nIn a still more general setup, the above ideas are formalized by\nAssumption~\\ref{assum1}\nbelow which, as will be shown in Theorem~\\ref{thmcharX}, provides\nsufficient conditions in order to guarantee that the underlying process\n$X$ possesses\nspecific variation. We will also allow for unbounded derivatives as\n$|t-s|\\rightarrow0$.\n\n\n\\begin{assumption} \\label{assum1}\nFor some open subset $\\Omega\\subset\\mathbb{R}^3$ with $[a,b]^2\\times\n[0,b-a]\\subset\\Omega$,\nthere exists a twice continuously differentiable function $\\omega\n:\\Omega\\rightarrow\n\\mathbb{R}$ as well as some $0<\\kappa<2$ such that for all $t,s\\in[a,b]$\n\n\n\n", "index": 13, "text": "\\begin{equation}\n\\sigma(t,s)=\\omega\\bigl(t,s,|t-s|^\\kappa\\bigr). \\label{deromega}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\sigma(t,s)=\\omega\\bigl{(}t,s,|t-s|^{\\kappa}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03c9</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mi>t</mi><mo>,</mo><mi>s</mi><mo>,</mo><msup><mrow><mo stretchy=\"false\">|</mo><mrow><mi>t</mi><mo>-</mo><mi>s</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mi>\u03ba</mi></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\n\\end{assumption}\n\nOne can infer from (\\ref{der1}) that for every twice continuously\ndifferentiable covariance function $\\sigma$\nthere exists some function $\\omega$ such that (\\ref{deromega}) holds\nwith $\\kappa=2$.\nBut note that formally introducing $|t-s|^\\kappa$ as an extra argument\nestablishes an easy way of capturing nonsmooth behavior as\n$|t-s|\\rightarrow0$, since $\\sigma$ is not twice differentiable at the\ndiagonal if $\\kappa<2$. In\nAssumption~\\ref{assum1}, the value of $\\kappa<2$ thus quantifies the\ndegree of smoothness of\n$\\sigma$ at the diagonal. A very small $\\kappa$ will reflect pronounced\nlocal variability and\nextremely nonsmooth sample paths.\nThere are many well-known processes satisfying this assumption.\n\n\n\n\\textit{Fractional Brownian motion} with Hurst coefficient $0<H<1$ on an\ninterval $[a,b]$, $a> 0$: The covariance function is then\ngiven by\n\n", "itemtype": "equation", "pos": 29519, "prevtext": "\n\nMoreover,\n\n\n\n", "index": 15, "text": "\\begin{equation}\n0<\\inf_{t\\in[a,b]}c(t)\\qquad \\mbox{where } c(t):=-\\frac{\\partial}{\\partial z}\n\\omega(t,t,z)\\bigg|_{z=0}. \\label{deromega2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"0&lt;\\inf_{t\\in[a,b]}c(t)\\qquad\\mbox{where }c(t):=-\\frac{\\partial}{\\partial z}%&#10;\\omega(t,t,z)\\bigg{|}_{z=0}.\" display=\"block\"><mrow><mrow><mrow><mn>0</mn><mo>&lt;</mo><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>t</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow></mrow></munder><mo>\u2061</mo><mrow><mi>c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><mrow><mtext>where\u00a0</mtext><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mo>-</mo><msub><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>z</mi></mrow></mfrac><mo>\u2062</mo><mi>\u03c9</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>t</mi><mo>,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"210%\" minsize=\"210%\">|</mo></mrow><mrow><mi>z</mi><mo>=</mo><mn>0</mn></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nIn this case, Assumption~\\ref{assum1} is satisfied with $\\kappa=2H$,\n$\\omega(t,s,z)=\n\\frac{1}{2}(t^{2H}+s^{2H}-z)$\nand $c(t)=1/2$.\n\n\n\\textit{Ornstein--Uhlenbeck process} with parameters $\\sigma_{u}^2,\\theta\n>0$: The covariance function is then defined by\n\n", "itemtype": "equation", "pos": 30545, "prevtext": "\n\n\\end{assumption}\n\nOne can infer from (\\ref{der1}) that for every twice continuously\ndifferentiable covariance function $\\sigma$\nthere exists some function $\\omega$ such that (\\ref{deromega}) holds\nwith $\\kappa=2$.\nBut note that formally introducing $|t-s|^\\kappa$ as an extra argument\nestablishes an easy way of capturing nonsmooth behavior as\n$|t-s|\\rightarrow0$, since $\\sigma$ is not twice differentiable at the\ndiagonal if $\\kappa<2$. In\nAssumption~\\ref{assum1}, the value of $\\kappa<2$ thus quantifies the\ndegree of smoothness of\n$\\sigma$ at the diagonal. A very small $\\kappa$ will reflect pronounced\nlocal variability and\nextremely nonsmooth sample paths.\nThere are many well-known processes satisfying this assumption.\n\n\n\n\\textit{Fractional Brownian motion} with Hurst coefficient $0<H<1$ on an\ninterval $[a,b]$, $a> 0$: The covariance function is then\ngiven by\n\n", "index": 17, "text": "\n\\[\n\\sigma(t,s)=\\tfrac{1}{2}\\bigl(t^{2H}+s^{2H}-|t-s|^{2H}\n\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\sigma(t,s)=\\tfrac{1}{2}\\bigl{(}t^{2H}+s^{2H}-|t-s|^{2H}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\tfrac</mtext></merror><mo>\u2062</mo><mn>12</mn><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><msup><mi>t</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>H</mi></mrow></msup><mo>+</mo><msup><mi>s</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>H</mi></mrow></msup></mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">|</mo><mrow><mi>t</mi><mo>-</mo><mi>s</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>H</mi></mrow></msup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nThen Assumption~\\ref{assum1} is satisfied with $\\kappa=1$,\n$\\omega(t,s,z)=\n\\frac{\\sigma_{u}^2}{2\\theta}(\\exp(-\\theta z)-\\break  \\exp(-\\theta(t+s)))$\nand $c(t)=\\sigma_{u}^2/2$.\n\n\nTheorem~\\ref{thmcharX} below now states that any process respecting\nAssumption~\\ref{assum1} possesses specific local variation. In Section~\\ref{sec2}, we already discussed the structure of\nan appropriate r.v. $\\zeta_{\\epsilon,t}(X)$ for the special case of a\nstandard Brownian\nmotion. The same type of functional may now be used in a more general setting.\n\nFor $\\delta>0$ and $[t-\\delta,t+\\delta]\\subset[a,b]$, define\n\n\n\n", "itemtype": "equation", "pos": 30871, "prevtext": "\n\nIn this case, Assumption~\\ref{assum1} is satisfied with $\\kappa=2H$,\n$\\omega(t,s,z)=\n\\frac{1}{2}(t^{2H}+s^{2H}-z)$\nand $c(t)=1/2$.\n\n\n\\textit{Ornstein--Uhlenbeck process} with parameters $\\sigma_{u}^2,\\theta\n>0$: The covariance function is then defined by\n\n", "index": 19, "text": "\n\\[\n\\sigma(t,s)=\\frac{\\sigma_{u}^2}{2\\theta}\\bigl(\\exp\\bigl(-\\theta|t-s|\\bigr)-\\exp\\bigl(-\\theta(t+s)\\bigr)\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\sigma(t,s)=\\frac{\\sigma_{u}^{2}}{2\\theta}\\bigl{(}\\exp\\bigl{(}-\\theta|t-s|%&#10;\\bigr{)}-\\exp\\bigl{(}-\\theta(t+s)\\bigr{)}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><msubsup><mi>\u03c3</mi><mi>u</mi><mn>2</mn></msubsup><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b8</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mo>-</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>t</mi><mo>-</mo><mi>s</mi></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mo>-</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\n\n\\begin{thmm} \\label{thmcharX}\nUnder our setup, assume that the covariance function $\\sigma$ of $X$\nsatisfies Assumption~\\ref{assum1}. Then\n$X$ possesses specific local variation, and for any $\\epsilon>0$ there\nexists a $\\delta>0$\nsuch that conditions \\textup{(i)--(iv)} of Definition~\\ref{de1} are satisfied for\n$\\zeta_{\\epsilon,t}(X)=Z_{\\delta}(X,t)$, where $Z_{\\delta}(X,t)$ is\ndefined by\n(\\ref{Zdef}).\n\\end{thmm}\n\n\n\n\\section{Estimating points of impact}\\label{SEC:4}\n\n\nWhen analyzing model (\\ref{impact-model}), a central problem is to\nestimate number and locations of\npoints of impact.\nRecall that we assume an i.i.d. sample $(X_i,Y_i)$, $i=1,\\ldots,n$,\nwhere $X_i$ possesses the\nsame distribution as a generic $X$. Furthermore, we consider the case\nthat each $X_i$ is\nevaluated at $p$ equidistant points $t_j=a+\\frac{j-1}{p-1}(b-a)$, $j=1,\n\\ldots, p$.\n\n\\begin{remark*}\nNote that all variables have been assumed to have means\nequal to zero. Any practical application of the methodology introduced below,\nhowever, should rely on centered data to be obtained from the original\ndata by subtracting sample means. Obviously, the theoretical results\ndeveloped in this section remain unchanged for this situation with\nhowever substantially longer proofs.\n\\end{remark*}\n\nDetermining $\\tau_1,\\ldots,\\tau_S$ of course constitutes a model\nselection problem. Since in practice\nthe random functions $X_i$ are observed on a discretized grid of $p$\npoints, one may tend to use\nmultivariate model selection procedures like Lasso or related methods.\nBut these procedures\nare multivariate in nature and are not well adapted to a functional\ncontext. An obvious difficulty is the linear functional\n$ \\int_a^b \\beta(t) X_i(t) \\,dt\\approx\\frac{1}{p} \\sum_{j=1}^p\n\\beta(t_j) X_i(t_j)$ which contradicts\nthe usual sparseness assumption by introducing some common effects of\nall variables.\nBut even if $ \\int_a^b \\beta(t) X_i(t) \\,dt\\equiv0$,\nresults may heavily depend on the number $p$ of observations per function.\nNote that in our functional setup for any fixed $m\\in\\mathbb{N}$ we\nnecessarily have $\\operatorname{Var}(X_i(t_j)-X_i(t_{j-m}))\\rightarrow\n0$ as $p\\rightarrow\\infty$.\nLasso theory, however, is based on the assumption that variables are\nnot too heavily correlated. For example, the results of Bickel, Ritov and Tsybakov\n(\\citeyear{Bickel2009}) indicate\nthat convergence of parameter estimates\n\\textit{at least} requires that $\\sqrt{n/\\log\np}(\\operatorname{Var}(X_i(t_j)-X_i(t_{j-1})))\\rightarrow\\infty$ as $n\\rightarrow\n\\infty$. This follows from the distribution version of the restricted\neigenvalue assumption and Theorem~5.2 of Bickel, Ritov and Tsybakov (\\citeyear{Bickel2009}) [see also\nZhou, van~de Geer and B\\\"uhlmann (\\citeyear{ZhouvandeGeerBuehlmann2009}) for a discussion on correlation assumptions for\nselection models]. As a consequence, standard multivariate model\nselection procedures cannot work unless the number\n$p$ of grid points is sufficiently small compared to $n$.\n\nIn this paper, we propose a very simple approach which is based on the\nconcepts developed in the preceding sections. The idea is to identify\npoints of impact by determining the grid points\n$t_j$, where $Z_{\\delta,i}(t_j):=Z_\\delta(X_i,t_j)$ possesses a\nparticularly high correlation with\n$Y_i$.\n\nThe motivation of this approach is easily seen when considering our\nregression model (\\ref{impact-model}) more closely. Note that $Z_{\\delta\n,i}(t)$ is strongly\ncorrelated with $X_i(t)$, but it is ``almost'' uncorrelated with\n$X_i(s)$ for\n$|t-s|\\gg\\delta$. This in turn implies that the correlation between\n$Y_i$ and\n$Z_{\\delta,i}(t)$ will be comparably high if and only if a particular\npoint $t$ is\nclose to a point of impact. More precisely, Lemmas 3 and 4 in the\nSupplementary Appendix C [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})] show\nthat\nas $\\delta\\rightarrow0$ and $\\min_{r\\neq s} |\\tau_s-\\tau_r|\\gg\\delta$\n\n\\begin{eqnarray*}\n\\mathbb{E} \\bigl(Z_{\\delta,i}(t_j)Y_i \\bigr)&=&\n\\beta_r c(\\tau_r)\\delta ^\\kappa+O\\bigl(\\max\\bigl\n\\{\\delta^{\\kappa+1},\\delta^2\\bigr\\}\\bigr)\\qquad \\mbox{if }\n|t_j-\\tau_r|\\approx0,\n\\\\\n\\mathbb{E} \\bigl(Z_{\\delta,i}(t_j)Y_i \\bigr)&=&O\n\\bigl(\\max\\bigl\\{\\delta^{\\kappa\n+1},\\delta^2\\bigr\\}\\bigr)\\qquad \\mbox{if } \\min_{r=1,\\ldots,S} |t_j-\\tau _r| \\gg\\delta.\n\\end{eqnarray*}\n\nMoreover, assuming that the process $X$ possesses a Gaussian\ndistribution, then since $\\operatorname{Var}(Z_{\\delta,i}(t_j))=O(\\delta^\\kappa)$ [see\n(\\ref{Zdelta2}) in the proof of Theorem~\\ref{thmcharX}], the\nCauchy--Schwarz inequality lead to\n$\\operatorname{Var}(Z_{\\delta,i}(t_j)Y_i)=O(\\delta^\\kappa)$, and hence\n\n", "itemtype": "equation", "pos": 31588, "prevtext": "\n\nThen Assumption~\\ref{assum1} is satisfied with $\\kappa=1$,\n$\\omega(t,s,z)=\n\\frac{\\sigma_{u}^2}{2\\theta}(\\exp(-\\theta z)-\\break  \\exp(-\\theta(t+s)))$\nand $c(t)=\\sigma_{u}^2/2$.\n\n\nTheorem~\\ref{thmcharX} below now states that any process respecting\nAssumption~\\ref{assum1} possesses specific local variation. In Section~\\ref{sec2}, we already discussed the structure of\nan appropriate r.v. $\\zeta_{\\epsilon,t}(X)$ for the special case of a\nstandard Brownian\nmotion. The same type of functional may now be used in a more general setting.\n\nFor $\\delta>0$ and $[t-\\delta,t+\\delta]\\subset[a,b]$, define\n\n\n\n", "index": 21, "text": "\\begin{equation}\n\\label{Zdef} Z_{\\delta}(X,t) = X(t) - \\tfrac{1}{2} \\bigl(X(t-\n\\delta)+X(t+\\delta ) \\bigr).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"Z_{\\delta}(X,t)=X(t)-\\tfrac{1}{2}\\bigl{(}X(t-\\delta)+X(t+\\delta)\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>Z</mi><mi>\u03b4</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\tfrac</mtext></merror><mo>\u2062</mo><mn>12</mn><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nThese arguments indicate that points of impact may be estimated by\nusing the locations of sufficiently large local maxima of $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$.\nA sensible identification will require a suitable choice of $\\delta>0$\nin dependence\nof the sample size~$n$. If $\\delta$ is too large, it will not be\npossible to distinguish\nbetween the influence of points of impact which are close to each\nother. On the other\nhand, if $\\delta$ is too small compared to $n$ (as, e.g., $\\delta^k\\sim\nn^{-1}$), then ``true'' maxima may perish in a flood of random peaks.\n\nThe situation is illustrated in Figure~\\ref{fig:1}. It shows a\nsimulated example\nof the regression model (\\ref{impact-model}) with $n=5000$, $\\beta\n(t)\\equiv0$, and $S=5$ points\nof impact. The error term is standard normal, while $X_i$ are\nindependent realizations\nof an Ornstein--Uhlenbeck process with $\\theta= 5$ and $\\sigma_u =\n3.5$, evaluated over $p=10\\mbox{,}001$ equidistant grid points in the interval\n$[0,1]$. The figure shows the behavior of $|\\frac{1}{n}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)Y_i|$ for different choices\n$\\delta=10/10\\mbox{,}001\\approx5/n$,\n$\\delta=142/10\\mbox{,}001\\approx1/\\sqrt{n}$,\n$\\delta=350/10\\mbox{,}001\\approx2.47/\\sqrt{n}$, and\n$\\delta=750/10\\mbox{,}001\\approx5.3/\\sqrt{n}$.\n\n\nIn order to consistently estimate $S$,\nour estimation procedure requires to exclude all points $t$ in an\ninterval of size $\\sqrt{\\delta}$ around the local maxima of $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ from further considerations.\nThe vertical lines in Figure~\\ref{fig:1} indicate the true location of\nthe points of impact, whereas the tick marks on the horizontal axis\nrepresent our possible candidates for $\\tau$ when applying the\nfollowing estimation procedure.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f02.eps}\n\n\\caption{The figure shows $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ for different\nchoices of $\\delta$ in a point of impact model with $5$ points of\nimpact whose locations are indicated by vertical lines. The upper left\npanel corresponds to a very small $\\delta$, where the noise level\noverlays the signal. By increasing $\\delta$ the location of the points\nof impact becomes more and more visible. \n\nBy choosing $\\delta$ too large, as in the lower right panel, we are not\nable to distinguish between the influence of points of impact in close\nvicinity anymore.}\n\\label{fig:1}\n\\end{figure}\n\n\n\n\\textit{Estimation procedure}:\nChoose some $\\delta>0$ such that there exists some $k_\\delta\\in\\mathbb\n{N}$ with $1\\leq k_\\delta<\\frac{p-1}{2}$\nand $\\delta=k_\\delta(b-a)/(p-1)$.\nIn a first step, determine for all $j\\in{{\\mathcal} J}_{0,\\delta}:=\\{\nk_\\delta+1,\\ldots,p-k_\\delta\\}$\n\n", "itemtype": "equation", "pos": 36321, "prevtext": "\n\n\n\\begin{thmm} \\label{thmcharX}\nUnder our setup, assume that the covariance function $\\sigma$ of $X$\nsatisfies Assumption~\\ref{assum1}. Then\n$X$ possesses specific local variation, and for any $\\epsilon>0$ there\nexists a $\\delta>0$\nsuch that conditions \\textup{(i)--(iv)} of Definition~\\ref{de1} are satisfied for\n$\\zeta_{\\epsilon,t}(X)=Z_{\\delta}(X,t)$, where $Z_{\\delta}(X,t)$ is\ndefined by\n(\\ref{Zdef}).\n\\end{thmm}\n\n\n\n\\section{Estimating points of impact}\\label{SEC:4}\n\n\nWhen analyzing model (\\ref{impact-model}), a central problem is to\nestimate number and locations of\npoints of impact.\nRecall that we assume an i.i.d. sample $(X_i,Y_i)$, $i=1,\\ldots,n$,\nwhere $X_i$ possesses the\nsame distribution as a generic $X$. Furthermore, we consider the case\nthat each $X_i$ is\nevaluated at $p$ equidistant points $t_j=a+\\frac{j-1}{p-1}(b-a)$, $j=1,\n\\ldots, p$.\n\n\\begin{remark*}\nNote that all variables have been assumed to have means\nequal to zero. Any practical application of the methodology introduced below,\nhowever, should rely on centered data to be obtained from the original\ndata by subtracting sample means. Obviously, the theoretical results\ndeveloped in this section remain unchanged for this situation with\nhowever substantially longer proofs.\n\\end{remark*}\n\nDetermining $\\tau_1,\\ldots,\\tau_S$ of course constitutes a model\nselection problem. Since in practice\nthe random functions $X_i$ are observed on a discretized grid of $p$\npoints, one may tend to use\nmultivariate model selection procedures like Lasso or related methods.\nBut these procedures\nare multivariate in nature and are not well adapted to a functional\ncontext. An obvious difficulty is the linear functional\n$ \\int_a^b \\beta(t) X_i(t) \\,dt\\approx\\frac{1}{p} \\sum_{j=1}^p\n\\beta(t_j) X_i(t_j)$ which contradicts\nthe usual sparseness assumption by introducing some common effects of\nall variables.\nBut even if $ \\int_a^b \\beta(t) X_i(t) \\,dt\\equiv0$,\nresults may heavily depend on the number $p$ of observations per function.\nNote that in our functional setup for any fixed $m\\in\\mathbb{N}$ we\nnecessarily have $\\operatorname{Var}(X_i(t_j)-X_i(t_{j-m}))\\rightarrow\n0$ as $p\\rightarrow\\infty$.\nLasso theory, however, is based on the assumption that variables are\nnot too heavily correlated. For example, the results of Bickel, Ritov and Tsybakov\n(\\citeyear{Bickel2009}) indicate\nthat convergence of parameter estimates\n\\textit{at least} requires that $\\sqrt{n/\\log\np}(\\operatorname{Var}(X_i(t_j)-X_i(t_{j-1})))\\rightarrow\\infty$ as $n\\rightarrow\n\\infty$. This follows from the distribution version of the restricted\neigenvalue assumption and Theorem~5.2 of Bickel, Ritov and Tsybakov (\\citeyear{Bickel2009}) [see also\nZhou, van~de Geer and B\\\"uhlmann (\\citeyear{ZhouvandeGeerBuehlmann2009}) for a discussion on correlation assumptions for\nselection models]. As a consequence, standard multivariate model\nselection procedures cannot work unless the number\n$p$ of grid points is sufficiently small compared to $n$.\n\nIn this paper, we propose a very simple approach which is based on the\nconcepts developed in the preceding sections. The idea is to identify\npoints of impact by determining the grid points\n$t_j$, where $Z_{\\delta,i}(t_j):=Z_\\delta(X_i,t_j)$ possesses a\nparticularly high correlation with\n$Y_i$.\n\nThe motivation of this approach is easily seen when considering our\nregression model (\\ref{impact-model}) more closely. Note that $Z_{\\delta\n,i}(t)$ is strongly\ncorrelated with $X_i(t)$, but it is ``almost'' uncorrelated with\n$X_i(s)$ for\n$|t-s|\\gg\\delta$. This in turn implies that the correlation between\n$Y_i$ and\n$Z_{\\delta,i}(t)$ will be comparably high if and only if a particular\npoint $t$ is\nclose to a point of impact. More precisely, Lemmas 3 and 4 in the\nSupplementary Appendix C [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})] show\nthat\nas $\\delta\\rightarrow0$ and $\\min_{r\\neq s} |\\tau_s-\\tau_r|\\gg\\delta$\n\n\\begin{eqnarray*}\n\\mathbb{E} \\bigl(Z_{\\delta,i}(t_j)Y_i \\bigr)&=&\n\\beta_r c(\\tau_r)\\delta ^\\kappa+O\\bigl(\\max\\bigl\n\\{\\delta^{\\kappa+1},\\delta^2\\bigr\\}\\bigr)\\qquad \\mbox{if }\n|t_j-\\tau_r|\\approx0,\n\\\\\n\\mathbb{E} \\bigl(Z_{\\delta,i}(t_j)Y_i \\bigr)&=&O\n\\bigl(\\max\\bigl\\{\\delta^{\\kappa\n+1},\\delta^2\\bigr\\}\\bigr)\\qquad \\mbox{if } \\min_{r=1,\\ldots,S} |t_j-\\tau _r| \\gg\\delta.\n\\end{eqnarray*}\n\nMoreover, assuming that the process $X$ possesses a Gaussian\ndistribution, then since $\\operatorname{Var}(Z_{\\delta,i}(t_j))=O(\\delta^\\kappa)$ [see\n(\\ref{Zdelta2}) in the proof of Theorem~\\ref{thmcharX}], the\nCauchy--Schwarz inequality lead to\n$\\operatorname{Var}(Z_{\\delta,i}(t_j)Y_i)=O(\\delta^\\kappa)$, and hence\n\n", "index": 23, "text": "\n\\[\n\\Biggl|\\frac{1}{n}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)Y_i-\\mathbb{E}\n\\bigl(Z_{\\delta\n,i}(t_j)Y_i\\bigr)\\Biggr|=O_P\n\\biggl(\\sqrt{\\frac{\\delta^\\kappa}{n}}\\biggr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\Biggl{|}\\frac{1}{n}\\sum_{i=1}^{n}Z_{\\delta,i}(t_{j})Y_{i}-\\mathbb{E}\\bigl{(}Z%&#10;_{\\delta,i}(t_{j})Y_{i}\\bigr{)}\\Biggr{|}=O_{P}\\biggl{(}\\sqrt{\\frac{\\delta^{%&#10;\\kappa}}{n}}\\biggr{)}.\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\" maxsize=\"260%\" minsize=\"260%\">|</mo><mrow><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>Y</mi><mi>i</mi></msub></mrow></mrow></mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>Y</mi><mi>i</mi></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"260%\" minsize=\"260%\">|</mo></mrow><mo>=</mo><mrow><msub><mi>O</mi><mi>P</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><msqrt><mfrac><msup><mi>\u03b4</mi><mi>\u03ba</mi></msup><mi>n</mi></mfrac></msqrt><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nIterate for $l=1,2,3,\\ldots:$\n\n\\begin{itemize}\n\n\\item Determine\n\n", "itemtype": "equation", "pos": 39174, "prevtext": "\n\nThese arguments indicate that points of impact may be estimated by\nusing the locations of sufficiently large local maxima of $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$.\nA sensible identification will require a suitable choice of $\\delta>0$\nin dependence\nof the sample size~$n$. If $\\delta$ is too large, it will not be\npossible to distinguish\nbetween the influence of points of impact which are close to each\nother. On the other\nhand, if $\\delta$ is too small compared to $n$ (as, e.g., $\\delta^k\\sim\nn^{-1}$), then ``true'' maxima may perish in a flood of random peaks.\n\nThe situation is illustrated in Figure~\\ref{fig:1}. It shows a\nsimulated example\nof the regression model (\\ref{impact-model}) with $n=5000$, $\\beta\n(t)\\equiv0$, and $S=5$ points\nof impact. The error term is standard normal, while $X_i$ are\nindependent realizations\nof an Ornstein--Uhlenbeck process with $\\theta= 5$ and $\\sigma_u =\n3.5$, evaluated over $p=10\\mbox{,}001$ equidistant grid points in the interval\n$[0,1]$. The figure shows the behavior of $|\\frac{1}{n}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)Y_i|$ for different choices\n$\\delta=10/10\\mbox{,}001\\approx5/n$,\n$\\delta=142/10\\mbox{,}001\\approx1/\\sqrt{n}$,\n$\\delta=350/10\\mbox{,}001\\approx2.47/\\sqrt{n}$, and\n$\\delta=750/10\\mbox{,}001\\approx5.3/\\sqrt{n}$.\n\n\nIn order to consistently estimate $S$,\nour estimation procedure requires to exclude all points $t$ in an\ninterval of size $\\sqrt{\\delta}$ around the local maxima of $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ from further considerations.\nThe vertical lines in Figure~\\ref{fig:1} indicate the true location of\nthe points of impact, whereas the tick marks on the horizontal axis\nrepresent our possible candidates for $\\tau$ when applying the\nfollowing estimation procedure.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f02.eps}\n\n\\caption{The figure shows $|\\frac\n{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ for different\nchoices of $\\delta$ in a point of impact model with $5$ points of\nimpact whose locations are indicated by vertical lines. The upper left\npanel corresponds to a very small $\\delta$, where the noise level\noverlays the signal. By increasing $\\delta$ the location of the points\nof impact becomes more and more visible. \n\nBy choosing $\\delta$ too large, as in the lower right panel, we are not\nable to distinguish between the influence of points of impact in close\nvicinity anymore.}\n\\label{fig:1}\n\\end{figure}\n\n\n\n\\textit{Estimation procedure}:\nChoose some $\\delta>0$ such that there exists some $k_\\delta\\in\\mathbb\n{N}$ with $1\\leq k_\\delta<\\frac{p-1}{2}$\nand $\\delta=k_\\delta(b-a)/(p-1)$.\nIn a first step, determine for all $j\\in{{\\mathcal} J}_{0,\\delta}:=\\{\nk_\\delta+1,\\ldots,p-k_\\delta\\}$\n\n", "index": 25, "text": "\n\\[\nZ_{\\delta,i}(t_j):=X_i(t_j)-\n\\tfrac{1}{2}\\bigl(X_i(t_j-\\delta)+X_i(t_j+\n\\delta)\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"Z_{\\delta,i}(t_{j}):=X_{i}(t_{j})-\\tfrac{1}{2}\\bigl{(}X_{i}(t_{j}-\\delta)+X_{i%&#10;}(t_{j}+\\delta)\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\tfrac</mtext></merror><mo>\u2062</mo><mn>12</mn><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>-</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>+</mo><mi>\u03b4</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nand set $\\widehat{\\tau}_l:=t_{j_l}$.\n\n\\item Set ${{\\mathcal} J}_{l,\\delta}:=\\{j\\in{{\\mathcal} J}_{l-1,\\delta}|\n|t_j-\\widehat{\\tau}_l|\\ge\\sqrt{\\delta}/2\\}$, that is, eliminate all\npoints in an interval\nof size $\\sqrt{\\delta}$ around $\\widehat{\\tau}_l$. Stop iteration if\n${{\\mathcal} J}_{l,\\delta}=\\varnothing$.\n\\end{itemize}\n\nChoose a suitable cut-off parameter $\\lambda>0$.\n\n\\begin{itemize}\n\n\\item Estimate $S$ by\n\n", "itemtype": "equation", "pos": 39333, "prevtext": "\n\nIterate for $l=1,2,3,\\ldots:$\n\n\\begin{itemize}\n\n\\item Determine\n\n", "index": 27, "text": "\n\\[\nj_l=\\arg \\max_{j\\in{{\\mathcal} J}_{l-1,\\delta}} \\Biggl|\\frac{1}{n}\\sum\n_{i=1}^n Z_{\\delta,i}(t_j)Y_i\\Biggr|\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"j_{l}=\\arg\\max_{j\\in{{\\mathcal{}}J}_{l-1,\\delta}}\\Biggl{|}\\frac{1}{n}\\sum_{i=1%&#10;}^{n}Z_{\\delta,i}(t_{j})Y_{i}\\Biggr{|}\" display=\"block\"><mrow><msub><mi>j</mi><mi>l</mi></msub><mo>=</mo><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>max</mi><mrow><mi>j</mi><mo>\u2208</mo><msub><mi>J</mi><mrow><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mi>\u03b4</mi></mrow></msub></mrow></munder><mo>\u2061</mo><mrow><mo fence=\"true\" maxsize=\"260%\" minsize=\"260%\">|</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>Y</mi><mi>i</mi></msub></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"260%\" minsize=\"260%\">|</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\n\\item $\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{\\widehat S}$ then are\nthe final estimates of the points of impact.\n\\end{itemize}\n\n\nA theoretical justification for this estimation procedure is given by\nTheorem~\\ref{poicon}.\nIts proof along with the proofs of Propositions~\\ref{poiconkappa} and \\ref{lem4} below can be\nfound in the Supplementary Appendix C.\nTheory relies on an asymptotics $n\\rightarrow\\infty$ with $p\\equiv\np_n \\geq\nL n^{1/\\kappa}$ for some constant $0<L<\\infty$.\nIt is based on the following additional assumption\non the structure of $X$ and $Y$.\n\n\n\\begin{assumption} \\label{assum2}\n\n(a) $X_1,\\ldots,X_n$ are i.i.d. random functions distributed\naccording to $X$. The process $X$ is\n\\textit{Gaussian} with covariance function $\\sigma(t,s)$.\n\n(b) The error terms $\\varepsilon_1,\\ldots,\\varepsilon_n$ are i.i.d.\n$N(0,\\sigma^2)$ r.v. which are\nindependent of~$X_i$.\n\n\\end{assumption}\n\n\n\\begin{thmm} \\label{poicon}\nUnder our setup and Assumptions \\ref{assum1} as well as \\ref{assum2}\nlet $\\delta\\equiv\\delta_n\\rightarrow0$ as $n\\rightarrow\\infty$ such that\n$\\frac{n\\delta^\\kappa}{|\\log\\delta|}\\rightarrow\\infty$ as well as\n$\\frac{\\delta^\\kappa}{n^{-\\kappa+1}}\\rightarrow0$. As $n\\rightarrow\n\\infty$ we then obtain\n\n\n\n", "itemtype": "equation", "pos": 39864, "prevtext": "\n\nand set $\\widehat{\\tau}_l:=t_{j_l}$.\n\n\\item Set ${{\\mathcal} J}_{l,\\delta}:=\\{j\\in{{\\mathcal} J}_{l-1,\\delta}|\n|t_j-\\widehat{\\tau}_l|\\ge\\sqrt{\\delta}/2\\}$, that is, eliminate all\npoints in an interval\nof size $\\sqrt{\\delta}$ around $\\widehat{\\tau}_l$. Stop iteration if\n${{\\mathcal} J}_{l,\\delta}=\\varnothing$.\n\\end{itemize}\n\nChoose a suitable cut-off parameter $\\lambda>0$.\n\n\\begin{itemize}\n\n\\item Estimate $S$ by\n\n", "index": 29, "text": "\n\\[\n\\widehat S =\\arg \\min_{l=0,1,2,\\ldots} \\biggl|\\frac{({1}/{n})\\sum_{i=1}^n\nZ_{\\delta,i}(\\widehat{\\tau}_{l+1})Y_i}{\n(({1}/{n})\\sum_{i=1}^n Z_{\\delta,i}(\\widehat{\\tau\n}_{l+1})^2)^{1/2}}\\biggr|< \\lambda.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\widehat{S}=\\arg\\min_{l=0,1,2,\\ldots}\\biggl{|}\\frac{({1}/{n})\\sum_{i=1}^{n}Z_{%&#10;\\delta,i}(\\widehat{\\tau}_{l+1})Y_{i}}{(({1}/{n})\\sum_{i=1}^{n}Z_{\\delta,i}(%&#10;\\widehat{\\tau}_{l+1})^{2})^{1/2}}\\biggr{|}&lt;\\lambda.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>S</mi><mo>^</mo></mover><mo>=</mo><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mrow><mi>l</mi><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi></mrow></mrow></munder><mo>\u2061</mo><mrow><mo fence=\"true\" maxsize=\"210%\" minsize=\"210%\">|</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>/</mo><mi>n</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>Y</mi><mi>i</mi></msub></mrow></mrow></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>/</mo><mi>n</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo fence=\"true\" maxsize=\"210%\" minsize=\"210%\">|</mo></mrow></mrow></mrow><mo>&lt;</mo><mi>\u03bb</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nAdditionally, assume that\n$\\delta^2=O(n^{-1})$ and that the algorithm is applied with cut-off parameter\n\n", "itemtype": "equation", "pos": 41299, "prevtext": "\n\n\\item $\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{\\widehat S}$ then are\nthe final estimates of the points of impact.\n\\end{itemize}\n\n\nA theoretical justification for this estimation procedure is given by\nTheorem~\\ref{poicon}.\nIts proof along with the proofs of Propositions~\\ref{poiconkappa} and \\ref{lem4} below can be\nfound in the Supplementary Appendix C.\nTheory relies on an asymptotics $n\\rightarrow\\infty$ with $p\\equiv\np_n \\geq\nL n^{1/\\kappa}$ for some constant $0<L<\\infty$.\nIt is based on the following additional assumption\non the structure of $X$ and $Y$.\n\n\n\\begin{assumption} \\label{assum2}\n\n(a) $X_1,\\ldots,X_n$ are i.i.d. random functions distributed\naccording to $X$. The process $X$ is\n\\textit{Gaussian} with covariance function $\\sigma(t,s)$.\n\n(b) The error terms $\\varepsilon_1,\\ldots,\\varepsilon_n$ are i.i.d.\n$N(0,\\sigma^2)$ r.v. which are\nindependent of~$X_i$.\n\n\\end{assumption}\n\n\n\\begin{thmm} \\label{poicon}\nUnder our setup and Assumptions \\ref{assum1} as well as \\ref{assum2}\nlet $\\delta\\equiv\\delta_n\\rightarrow0$ as $n\\rightarrow\\infty$ such that\n$\\frac{n\\delta^\\kappa}{|\\log\\delta|}\\rightarrow\\infty$ as well as\n$\\frac{\\delta^\\kappa}{n^{-\\kappa+1}}\\rightarrow0$. As $n\\rightarrow\n\\infty$ we then obtain\n\n\n\n", "index": 31, "text": "\\begin{equation}\n\\label{thmm3eq1} \\max_{r=1,\\ldots,\\widehat{S}}\\min_{s=1,\\ldots,S}|\n\\widehat{\\tau}_r-\\tau _s| = O_P\\bigl(\nn^{-{1}/{k}}\\bigr).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\max_{r=1,\\ldots,\\widehat{S}}\\min_{s=1,\\ldots,S}|\\widehat{\\tau}_{r}-\\tau_{s}|=%&#10;O_{P}\\bigl{(}n^{-{1}/{k}}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><munder><mi>max</mi><mrow><mi>r</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mover accent=\"true\"><mi>S</mi><mo>^</mo></mover></mrow></mrow></munder><mo>\u2061</mo><mrow><munder><mi>min</mi><mrow><mi>s</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>S</mi></mrow></mrow></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mrow><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>r</mi></msub><mo>-</mo><msub><mi>\u03c4</mi><mi>s</mi></msub></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>=</mo><mrow><msub><mi>O</mi><mi>P</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>n</mi><mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mi>k</mi></mrow></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nThen\n\n\n\n", "itemtype": "equation", "pos": 41561, "prevtext": "\n\nAdditionally, assume that\n$\\delta^2=O(n^{-1})$ and that the algorithm is applied with cut-off parameter\n\n", "index": 33, "text": "\n\\[\n\\lambda\\equiv\\lambda_n=A\\sqrt{ \\frac{\\operatorname{Var}(Y_i)}{n} \\log\\biggl(\n\\frac\n{b-a}{\\delta}\\biggr)} \\qquad\\mbox{where } A>\\sqrt{2}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\lambda\\equiv\\lambda_{n}=A\\sqrt{\\frac{\\operatorname{Var}(Y_{i})}{n}\\log\\biggl{%&#10;(}\\frac{b-a}{\\delta}\\biggr{)}}\\qquad\\mbox{where }A&gt;\\sqrt{2}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03bb</mi><mo>\u2261</mo><msub><mi>\u03bb</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>A</mi><mo>\u2062</mo><msqrt><mrow><mfrac><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\operatorname</mtext></merror><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mi>n</mi></mfrac><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mfrac><mrow><mi>b</mi><mo>-</mo><mi>a</mi></mrow><mi>\u03b4</mi></mfrac><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow></mrow></msqrt></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><mrow><mtext>where\u00a0</mtext><mo>\u2062</mo><mi>A</mi></mrow><mo>&gt;</mo><msqrt><mn>2</mn></msqrt></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\\end{thmm}\n\nThe theorem of course implies that the rates of convergence of\\break the\nestimated points of impact depend on $\\kappa$. If $\\kappa=1$ as, for\\break \nexample, for the Brownian motion or the Ornstein--Uhlenbeck process, then\\break \n$\\max_{r=1,\\ldots,\\widehat S} \\min_{s=1,\\ldots,S} |\\widehat{\\tau}_r-\\tau\n_s|=O_P( n^{-1})$. Arbitrarily fast rates\nof convergence can be achieved for very nonsmooth processes with\n$\\kappa\\ll1$.\n\nA suitable choice of $\\delta$ satisfying the requirements of the theorem\nfor all possible $\\kappa<2$ is $\\delta=C n^{-1/2}$ for some constant $C$.\n\nRecall that for $l>1$, our algorithm requires that $\\widehat{\\tau}_l$\nis determined\nonly from those points $t_j$ which are not in $\\sqrt{\\delta\n}/2$-neighborhoods of\nany previously selected $\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{l-1}$.\nThis implies that\nfor any $\\delta$ the number $M_\\delta$ of iteration steps is finite, and\n$M_\\delta=O(\\frac{b-a}{\\sqrt{\\delta}/2})$ is the maximal possible\nnumber of ``candidate'' impact points which can be detected for a fixed\n$n$ and $\\delta\\equiv\\delta_n$.\nThe size of these intervals\nis due to the use of the cut-off criterion for estimating $S$.\nIt can easily be seen\nfrom the proof of the theorem that in order to establish (\\ref\n{thmm3eq1}) it suffices\nto eliminate all points in $\\delta|\\log\\delta|$ neighborhoods of\n$\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{l-1}$ which is a much weaker\nrestriction.\n\nWe also want to emphasize that the cut-off value provided by the\ntheorem heavily relies\non the Gaussian assumption. A different approach that may work under\nmore general\nconditions is to consider all selected local maxima $\\widehat{\\tau\n}_1,\\ldots,\\widehat{\\tau}_{M_\\delta}$ and to estimate $S$ by usual model\nselection\ncriteria like BIC.\n\nThis is quite easily done if it can additionally be assumed that, in\nmodel (\\ref{impact-model}),\n$\\beta(t)=0$ for all $t\\in[a,b]$. One may then\napply a best subset selection by regressing $Y_i$ on all possible\nsubsets of $X_i(\\widehat{\\tau}_1),\\ldots,X_i(\\widehat{\\tau}_{M_\\delta\n})$, and by calculating\nthe residual sum of squares $\\mathit{RSS}_s$\nfor each subset of size $s$. An\nestimate $\\widehat S$ is obtained by minimizing\n\n\n\n", "itemtype": "equation", "pos": 41713, "prevtext": "\n\nThen\n\n\n\n", "index": 35, "text": "\\begin{equation}\n\\label{thmm3eq4} P(\\widehat{S}=S) \\rightarrow 1\\qquad \\mbox{as } n\\rightarrow\\infty.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"P(\\widehat{S}=S)\\rightarrow 1\\qquad\\mbox{as }n\\rightarrow\\infty.\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>S</mi><mo>^</mo></mover><mo>=</mo><mi>S</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2192</mo><mn>1</mn><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mtext>as\u00a0</mtext><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nover all possible values of $s$.\n\nIf $\\int_a^b\\beta(t)X_i(t)\\,dt\\neq0$, this approach will of course lead\nto biased\nresults, since part of the influence of this component on the response\nvariable $Y_i$\nmay be approximated by adding additional artificial ``points of impact.''\nBut\nan obvious idea is then to incorporate estimates of the linear functional\nby relying on functional principal components.\nRecall the Karhunen--Lo\\`eve decomposition already discussed in\nSection~\\ref{sec2},\nand note that $\\int_a^b\\beta(t)X_i(t)\\,dt =\\sum_{r=1}^\\infty\\alpha_r\n\\langle X,\\psi_r \\rangle$ with $\\alpha_r= \\langle\\psi_r,\\beta\\rangle\n$. For $k,S\\in\\mathbb{N}$, estimates $\\widehat{\\psi}_r$ of\n$\\psi_r$ and a subset\n$\\tilde\\tau_1,\\ldots,\\tilde\\tau_S\\in\\{\\widehat{\\tau}_1,\\ldots,\\widehat\n{\\tau}_{M_\\delta}\\}$\none may consider an approximate relationship which resembles an\n``augmented model'' as proposed\nby \\citet{KneipSarda2011} in a different context:\n\n\n\n", "itemtype": "equation", "pos": 44034, "prevtext": "\n\\end{thmm}\n\nThe theorem of course implies that the rates of convergence of\\break the\nestimated points of impact depend on $\\kappa$. If $\\kappa=1$ as, for\\break \nexample, for the Brownian motion or the Ornstein--Uhlenbeck process, then\\break \n$\\max_{r=1,\\ldots,\\widehat S} \\min_{s=1,\\ldots,S} |\\widehat{\\tau}_r-\\tau\n_s|=O_P( n^{-1})$. Arbitrarily fast rates\nof convergence can be achieved for very nonsmooth processes with\n$\\kappa\\ll1$.\n\nA suitable choice of $\\delta$ satisfying the requirements of the theorem\nfor all possible $\\kappa<2$ is $\\delta=C n^{-1/2}$ for some constant $C$.\n\nRecall that for $l>1$, our algorithm requires that $\\widehat{\\tau}_l$\nis determined\nonly from those points $t_j$ which are not in $\\sqrt{\\delta\n}/2$-neighborhoods of\nany previously selected $\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{l-1}$.\nThis implies that\nfor any $\\delta$ the number $M_\\delta$ of iteration steps is finite, and\n$M_\\delta=O(\\frac{b-a}{\\sqrt{\\delta}/2})$ is the maximal possible\nnumber of ``candidate'' impact points which can be detected for a fixed\n$n$ and $\\delta\\equiv\\delta_n$.\nThe size of these intervals\nis due to the use of the cut-off criterion for estimating $S$.\nIt can easily be seen\nfrom the proof of the theorem that in order to establish (\\ref\n{thmm3eq1}) it suffices\nto eliminate all points in $\\delta|\\log\\delta|$ neighborhoods of\n$\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{l-1}$ which is a much weaker\nrestriction.\n\nWe also want to emphasize that the cut-off value provided by the\ntheorem heavily relies\non the Gaussian assumption. A different approach that may work under\nmore general\nconditions is to consider all selected local maxima $\\widehat{\\tau\n}_1,\\ldots,\\widehat{\\tau}_{M_\\delta}$ and to estimate $S$ by usual model\nselection\ncriteria like BIC.\n\nThis is quite easily done if it can additionally be assumed that, in\nmodel (\\ref{impact-model}),\n$\\beta(t)=0$ for all $t\\in[a,b]$. One may then\napply a best subset selection by regressing $Y_i$ on all possible\nsubsets of $X_i(\\widehat{\\tau}_1),\\ldots,X_i(\\widehat{\\tau}_{M_\\delta\n})$, and by calculating\nthe residual sum of squares $\\mathit{RSS}_s$\nfor each subset of size $s$. An\nestimate $\\widehat S$ is obtained by minimizing\n\n\n\n", "index": 37, "text": "\\begin{equation}\n\\label{biccriterion} \\mathit{BIC}_s = n\\log(\\mathit{RSS}_s/n) + s \\log(n)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\mathit{BIC}_{s}=n\\log(\\mathit{RSS}_{s}/n)+s\\log(n)\" display=\"block\"><mrow><msub><mi>\ud835\udc35\ud835\udc3c\ud835\udc36</mi><mi>s</mi></msub><mo>=</mo><mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc45\ud835\udc46\ud835\udc46</mi><mi>s</mi></msub><mo>/</mo><mi>n</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><mi>s</mi><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nBased on corresponding least-squares estimates of the coefficients\n$\\alpha_r$ and $\\beta_r$,\nthe number $S$ and an optimal value of $k$ may then be estimated by\nthe BIC criterion.\n\nThis approach also offers a way to select a sensible value of $\\delta\n=C n^{-1/2}$ for\na suitable range of values $C\\in[C_{\\mathrm{min}},C_{\\mathrm{max}}]$. For finite $n$,\ndifferent choices\nof $C$ (and~$\\delta$) may of course lead to different candidate values\n$\\hat\\tau_r$, $r=1,2,\\ldots.$ A~straightforward approach is then to\nchoose the value of $\\delta$, where the respective estimates of impact\npoints lead to the best fitting augmented model (\\ref{augmentedmodel}).\nIn addition to estimating $S$ and an optimal value of $k$, BIC\nmay thus also be used to approximate an optimal value of $C$ (and\n$\\delta$).\n\nRecall that the above approach is applicable if Assumption~\\ref{assum1}\nholds for some $\\kappa<2$. In a\npractical application, one may thus want to check the applicability of\nthe theory by estimating the value\nof $\\kappa$ from the data. We have\n$\\mathbb{E}(Z_{\\delta,i}(t_j)^2)=\\delta^\\kappa (2c(t_j)-\\frac\n{2^\\kappa}{2}c(t_j) )+o(\\delta^\\kappa)$ [see (\\ref{Zdelta2}) in\nthe proof of Theorem~\\ref{thmcharX}]. Consequently, $\\frac{\\mathbb\n{E}(Z_{\\delta,i}(t_j)^2)}{\\mathbb{E}(Z_{\\delta/2,i}(t_j)^2)}=2^\\kappa\n+o(1)$ as\n$\\delta\\rightarrow0$. Without restriction assume that $k_\\delta$ is an\neven number. The\nabove arguments motivate the estimator\n\n", "itemtype": "equation", "pos": 45085, "prevtext": "\n\nover all possible values of $s$.\n\nIf $\\int_a^b\\beta(t)X_i(t)\\,dt\\neq0$, this approach will of course lead\nto biased\nresults, since part of the influence of this component on the response\nvariable $Y_i$\nmay be approximated by adding additional artificial ``points of impact.''\nBut\nan obvious idea is then to incorporate estimates of the linear functional\nby relying on functional principal components.\nRecall the Karhunen--Lo\\`eve decomposition already discussed in\nSection~\\ref{sec2},\nand note that $\\int_a^b\\beta(t)X_i(t)\\,dt =\\sum_{r=1}^\\infty\\alpha_r\n\\langle X,\\psi_r \\rangle$ with $\\alpha_r= \\langle\\psi_r,\\beta\\rangle\n$. For $k,S\\in\\mathbb{N}$, estimates $\\widehat{\\psi}_r$ of\n$\\psi_r$ and a subset\n$\\tilde\\tau_1,\\ldots,\\tilde\\tau_S\\in\\{\\widehat{\\tau}_1,\\ldots,\\widehat\n{\\tau}_{M_\\delta}\\}$\none may consider an approximate relationship which resembles an\n``augmented model'' as proposed\nby \\citet{KneipSarda2011} in a different context:\n\n\n\n", "index": 39, "text": "\\begin{equation}\n\\label{augmentedmodel} Y_i\\approx\\sum_{r=1}^k\n\\alpha_r \\langle X_i,\\widehat{\\psi}_r\n\\rangle +\\sum_{r=1}^S\\beta_r\nX_i(\\tilde\\tau_r)+\\varepsilon_i^*.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"Y_{i}\\approx\\sum_{r=1}^{k}\\alpha_{r}\\langle X_{i},\\widehat{\\psi}_{r}\\rangle+%&#10;\\sum_{r=1}^{S}\\beta_{r}X_{i}(\\tilde{\\tau}_{r})+\\varepsilon_{i}^{*}.\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>\u2248</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">~</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><msubsup><mi>\u03b5</mi><mi>i</mi><mo>*</mo></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nof $\\kappa$. In Proposition~\\ref{poiconkappa} below, it is shown that\n$\\widehat{\\kappa}$ is a consistent estimator of $\\kappa$\nas $n\\rightarrow\\infty$, $\\delta\\rightarrow0$. In practice, an\nestimate $\\widehat{\\kappa}\\ll2$ will\nindicate a process whose covariance function possesses a nonsmooth diagonal.\n\n\n\\begin{prop}\\label{poiconkappa}\nUnder the conditions of Theorem~\\ref{poicon}, we have\n\n\n\n", "itemtype": "equation", "pos": 46706, "prevtext": "\n\nBased on corresponding least-squares estimates of the coefficients\n$\\alpha_r$ and $\\beta_r$,\nthe number $S$ and an optimal value of $k$ may then be estimated by\nthe BIC criterion.\n\nThis approach also offers a way to select a sensible value of $\\delta\n=C n^{-1/2}$ for\na suitable range of values $C\\in[C_{\\mathrm{min}},C_{\\mathrm{max}}]$. For finite $n$,\ndifferent choices\nof $C$ (and~$\\delta$) may of course lead to different candidate values\n$\\hat\\tau_r$, $r=1,2,\\ldots.$ A~straightforward approach is then to\nchoose the value of $\\delta$, where the respective estimates of impact\npoints lead to the best fitting augmented model (\\ref{augmentedmodel}).\nIn addition to estimating $S$ and an optimal value of $k$, BIC\nmay thus also be used to approximate an optimal value of $C$ (and\n$\\delta$).\n\nRecall that the above approach is applicable if Assumption~\\ref{assum1}\nholds for some $\\kappa<2$. In a\npractical application, one may thus want to check the applicability of\nthe theory by estimating the value\nof $\\kappa$ from the data. We have\n$\\mathbb{E}(Z_{\\delta,i}(t_j)^2)=\\delta^\\kappa (2c(t_j)-\\frac\n{2^\\kappa}{2}c(t_j) )+o(\\delta^\\kappa)$ [see (\\ref{Zdelta2}) in\nthe proof of Theorem~\\ref{thmcharX}]. Consequently, $\\frac{\\mathbb\n{E}(Z_{\\delta,i}(t_j)^2)}{\\mathbb{E}(Z_{\\delta/2,i}(t_j)^2)}=2^\\kappa\n+o(1)$ as\n$\\delta\\rightarrow0$. Without restriction assume that $k_\\delta$ is an\neven number. The\nabove arguments motivate the estimator\n\n", "index": 41, "text": "\n\\[\n\\label{estkappa} \\widehat{\\kappa}= \\log_2 \\biggl( \\frac{({1}/{(p-2k_\\delta)})\\sum_{j\\in{{\\mathcal} J}_{0,\\delta}}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)^2}{\n({1}/{(p-2k_\\delta)})\\sum_{j\\in{{\\mathcal} J}_{0,\\delta}}\\sum_{i=1}^n\nZ_{\\delta/2,i}(t_j)^2}\n\\biggr)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\widehat{\\kappa}=\\log_{2}\\biggl{(}\\frac{({1}/{(p-2k_{\\delta})})\\sum_{j\\in{{%&#10;\\mathcal{}}J}_{0,\\delta}}\\sum_{i=1}^{n}Z_{\\delta,i}(t_{j})^{2}}{({1}/{(p-2k_{%&#10;\\delta})})\\sum_{j\\in{{\\mathcal{}}J}_{0,\\delta}}\\sum_{i=1}^{n}Z_{\\delta/2,i}(t_%&#10;{j})^{2}}\\biggr{)}\" display=\"block\"><mrow><mover accent=\"true\"><mi>\u03ba</mi><mo>^</mo></mover><mo>=</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>k</mi><mi>\u03b4</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msub><mi>J</mi><mrow><mn>0</mn><mo>,</mo><mi>\u03b4</mi></mrow></msub></mrow></msub><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>Z</mi><mrow><mi>\u03b4</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>p</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>k</mi><mi>\u03b4</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msub><mi>J</mi><mrow><mn>0</mn><mo>,</mo><mi>\u03b4</mi></mrow></msub></mrow></msub><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>Z</mi><mrow><mrow><mi>\u03b4</mi><mo>/</mo><mn>2</mn></mrow><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></mfrac><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\n\\end{prop}\n\nA final theoretical result concerns the distance between $X_i(\\widehat\n{\\tau}_r)$ and\n$X_i(\\tau_r)$. It will be of crucial importance in the next section on\nparameter estimation. Without restriction, we will in the following\nassume that points of impact are ordered\nin such a way that $\\tau_r =\\arg \\min_{s=1,\\ldots,S} |\\widehat{\\tau\n}_r-\\tau_s|$, $r=1,\\ldots,S$.\n\n\n\\begin{prop}\\label{lem4}\nUnder the assumptions of Theorem~\\ref{poicon},\nwe obtain for every $r=1,\\ldots,S$\n\n\n\n\\begin{eqnarray}\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)^2&=&O_p\\bigl(n^{-1}\n\\bigr), \\label{lem4eq1}\n\\\\\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)\\varepsilon _i&=&O_p\n\\bigl(n^{-1}\\bigr). \\label{lem4eq3}\n\\end{eqnarray}\n\n\\end{prop}\n\n\n\n\\section{Parameter estimates}\\label{sec5}\n\n\nRecall that Assumption~\\ref{assum1} is only a sufficient, not a\nnecessary condition of identifiability.\nEven if this assumption is violated and the covariance function $\\sigma\n(t,s)$ is very smooth, there may exist alternative procedures leading\nto sensible\nestimators $\\widehat{\\tau}_r$. In the following, we will thus only\nassume that the points of impacts\nare estimated by some procedure such that $P(\\widehat{S}=S)\\rightarrow\n1$ as $n\\rightarrow\\infty$ and\nsuch that (\\ref{lem4eq1}) as well as (\\ref{lem4eq3}) hold for all\n$r=1,\\ldots,S$. Note\nthat this assumption is trivially satisfied if analysis is based on\npre-specified points of impact as discussed in the \\hyperref[sec1]{Introduction}.\n\nIn situations where it can be assumed that $\\int_a^b \\beta\n(t)X_i(t)\\,dt=0$ a.s.,\nwe have $Y_i=\\sum_{r=1}^S \\beta_r X_i(\\tau_r)+\n\\varepsilon_i$, $i=1,\\ldots,n$, and the regression\ncoefficient may be obtained by least squares when replacing the\nunknown points of\nimpact $\\tau_r$ by their estimates $\\widehat{\\tau}_r$.\nMore precisely, in this\ncase an estimator $\\widehat{\\bolds{\\beta}}=(\\widehat{\\beta}_1,\\ldots\n,\\widehat{\\beta}_{\\widehat{S}})^T$\nof $\\bolds{\\beta}=(\\beta_1,\\ldots,\\beta_S)^T$ is determined by minimizing\n\n\n\n", "itemtype": "equation", "pos": 47357, "prevtext": "\n\nof $\\kappa$. In Proposition~\\ref{poiconkappa} below, it is shown that\n$\\widehat{\\kappa}$ is a consistent estimator of $\\kappa$\nas $n\\rightarrow\\infty$, $\\delta\\rightarrow0$. In practice, an\nestimate $\\widehat{\\kappa}\\ll2$ will\nindicate a process whose covariance function possesses a nonsmooth diagonal.\n\n\n\\begin{prop}\\label{poiconkappa}\nUnder the conditions of Theorem~\\ref{poicon}, we have\n\n\n\n", "index": 43, "text": "\\begin{equation}\n\\label{thmm3eq3} \\widehat{\\kappa}=\\kappa+O_P\\bigl(n^{-1/2}+\n\\delta^{\\min\\{2,2/\\kappa\\}}\\bigr).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\widehat{\\kappa}=\\kappa+O_{P}\\bigl{(}n^{-1/2}+\\delta^{\\min\\{2,2/\\kappa\\}}\\bigr%&#10;{)}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\u03ba</mi><mo>^</mo></mover><mo>=</mo><mrow><mi>\u03ba</mi><mo>+</mo><mrow><msub><mi>O</mi><mi>P</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msup><mi>n</mi><mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></mrow></msup><mo>+</mo><msup><mi>\u03b4</mi><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mn>2</mn><mo>,</mo><mrow><mn>2</mn><mo>/</mo><mi>\u03ba</mi></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></msup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nover all possible values $b_1,\\ldots,b_{\\widehat{S}}$.\n\nLet $\\mathbf{X}_i(\\bolds{\\tau}):=(X_i(\\tau_1),\\ldots,X_i(\\tau\n_S))^T$, and let\n$\\Sigma_\\tau:=\\mathbb{E}(\\mathbf{X}_i(\\bolds{\\tau})\\mathbf\n{X}_i(\\bolds{\\tau})^T)$. Note\nthat identifiability of the regression model as stated in Theorem~\\ref\n{thmident} in\nparticular implies that $\\Sigma_\\tau$ is invertible.\n\nIf $\\widehat{S}=S$, then by (\\ref{lem4eq1}) and (\\ref{lem4eq3}) the\ndifferences between $\\widehat{\\tau}_r$\nand $\\tau_r$, $r=1,\\ldots,S$ are asymptotically negligible, and the\nasymptotic distribution of $\\widehat{\\bolds{\\beta}}$\ncoincides with the asymptotic distribution the least squares estimator\nto be obtained if points of impact were known:\n\n\n\n", "itemtype": "equation", "pos": 49529, "prevtext": "\n\n\\end{prop}\n\nA final theoretical result concerns the distance between $X_i(\\widehat\n{\\tau}_r)$ and\n$X_i(\\tau_r)$. It will be of crucial importance in the next section on\nparameter estimation. Without restriction, we will in the following\nassume that points of impact are ordered\nin such a way that $\\tau_r =\\arg \\min_{s=1,\\ldots,S} |\\widehat{\\tau\n}_r-\\tau_s|$, $r=1,\\ldots,S$.\n\n\n\\begin{prop}\\label{lem4}\nUnder the assumptions of Theorem~\\ref{poicon},\nwe obtain for every $r=1,\\ldots,S$\n\n\n\n\\begin{eqnarray}\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)^2&=&O_p\\bigl(n^{-1}\n\\bigr), \\label{lem4eq1}\n\\\\\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)\\varepsilon _i&=&O_p\n\\bigl(n^{-1}\\bigr). \\label{lem4eq3}\n\\end{eqnarray}\n\n\\end{prop}\n\n\n\n\\section{Parameter estimates}\\label{sec5}\n\n\nRecall that Assumption~\\ref{assum1} is only a sufficient, not a\nnecessary condition of identifiability.\nEven if this assumption is violated and the covariance function $\\sigma\n(t,s)$ is very smooth, there may exist alternative procedures leading\nto sensible\nestimators $\\widehat{\\tau}_r$. In the following, we will thus only\nassume that the points of impacts\nare estimated by some procedure such that $P(\\widehat{S}=S)\\rightarrow\n1$ as $n\\rightarrow\\infty$ and\nsuch that (\\ref{lem4eq1}) as well as (\\ref{lem4eq3}) hold for all\n$r=1,\\ldots,S$. Note\nthat this assumption is trivially satisfied if analysis is based on\npre-specified points of impact as discussed in the \\hyperref[sec1]{Introduction}.\n\nIn situations where it can be assumed that $\\int_a^b \\beta\n(t)X_i(t)\\,dt=0$ a.s.,\nwe have $Y_i=\\sum_{r=1}^S \\beta_r X_i(\\tau_r)+\n\\varepsilon_i$, $i=1,\\ldots,n$, and the regression\ncoefficient may be obtained by least squares when replacing the\nunknown points of\nimpact $\\tau_r$ by their estimates $\\widehat{\\tau}_r$.\nMore precisely, in this\ncase an estimator $\\widehat{\\bolds{\\beta}}=(\\widehat{\\beta}_1,\\ldots\n,\\widehat{\\beta}_{\\widehat{S}})^T$\nof $\\bolds{\\beta}=(\\beta_1,\\ldots,\\beta_S)^T$ is determined by minimizing\n\n\n\n", "index": 45, "text": "\\begin{equation}\n\\label{lsbeta0} \\frac{1}{n} \\sum_{i=1}^n\n\\Biggl(Y_i-\\sum_{r=1}^{\\widehat{S}}\nb_r X_i(\\widehat {\\tau}_r)\n\\Biggr)^2\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\frac{1}{n}\\sum_{i=1}^{n}\\Biggl{(}Y_{i}-\\sum_{r=1}^{\\widehat{S}}b_{r}X_{i}(%&#10;\\widehat{\\tau}_{r})\\Biggr{)}^{2}\" display=\"block\"><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>-</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mover accent=\"true\"><mi>S</mi><mo>^</mo></mover></munderover><mrow><msub><mi>b</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nas $n\\rightarrow\\infty$. A proof is straightforward, and thus omitted.\n\nIn the general case with $\\beta(t)\\neq0$ for some $t$, we propose to\nrely on the augmented model (\\ref{augmentedmodel}). Thus, let $\\hat\n\\lambda_1\\geq\\hat\\lambda_2\\geq\\cdots$ and $\\widehat{\\psi}_1,\\widehat{\\psi\n}_2,\\ldots$ denote eigenvalues and eigenfunctions of the empirical\ncovariance operator of $X_1,\\ldots,X_n$. Given estimates\n$\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{\\widehat{S}}$ and a suitable\ncut-off parameter $k$ estimates\n$\\widehat{\\bolds{\\beta}}=(\\widehat{\\beta}_1,\\ldots,\\widehat{\\beta\n}_{\\widehat{S}})^T$\nof $\\bolds{\\beta}=(\\beta_1,\\ldots,\\beta_S)^T$ and $\\widehat{\\alpha\n}_1,\\ldots,\\widehat{\\alpha}_k$ of\n$\\alpha_1,\\ldots,\\alpha_k$ are determined by minimizing\n\n\n\n", "itemtype": "equation", "pos": 50387, "prevtext": "\n\nover all possible values $b_1,\\ldots,b_{\\widehat{S}}$.\n\nLet $\\mathbf{X}_i(\\bolds{\\tau}):=(X_i(\\tau_1),\\ldots,X_i(\\tau\n_S))^T$, and let\n$\\Sigma_\\tau:=\\mathbb{E}(\\mathbf{X}_i(\\bolds{\\tau})\\mathbf\n{X}_i(\\bolds{\\tau})^T)$. Note\nthat identifiability of the regression model as stated in Theorem~\\ref\n{thmident} in\nparticular implies that $\\Sigma_\\tau$ is invertible.\n\nIf $\\widehat{S}=S$, then by (\\ref{lem4eq1}) and (\\ref{lem4eq3}) the\ndifferences between $\\widehat{\\tau}_r$\nand $\\tau_r$, $r=1,\\ldots,S$ are asymptotically negligible, and the\nasymptotic distribution of $\\widehat{\\bolds{\\beta}}$\ncoincides with the asymptotic distribution the least squares estimator\nto be obtained if points of impact were known:\n\n\n\n", "index": 47, "text": "\\begin{equation}\n\\label{thmpNLFeq1} \\sqrt{n}(\\widehat{\\bolds{\\beta}}-\\bolds{\\beta})\n\\rightarrow_D N\\bigl(0,\\sigma^2 \\Sigma_\\tau^{-1}\n\\bigr)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\sqrt{n}(\\widehat{\\bolds{\\beta}}-\\bolds{\\beta})\\rightarrow_{D}N\\bigl{(}0,%&#10;\\sigma^{2}\\Sigma_{\\tau}^{-1}\\bigr{)}\" display=\"block\"><mrow><mrow><msqrt><mi>n</mi></msqrt><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bolds</mtext></merror><mo>\u2062</mo><mi>\u03b2</mi></mrow><mo>^</mo></mover><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\bolds</mtext></merror><mo>\u2062</mo><mi>\u03b2</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msub><mo>\u2192</mo><mi>D</mi></msub><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mn>0</mn><mo>,</mo><mrow><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>\u03c4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nover all $a_r, b_s$, $r=1,\\ldots,k$, $s=1,\\ldots,\\widehat{S}$. Based on\nthe estimated coefficients\n$\\widehat{\\alpha}_1,\\ldots,\\widehat{\\alpha}_k$, and estimator of the\nslope function $\\beta$ is then given\nby $\\widehat{\\beta}(t):=\\sum_{r=1}^k \\widehat{\\alpha}_k \\widehat{\\psi}_r(t)$.\n\nIn the following we will rely on a slight change of notation in the\nsense that $Y_i$, $X_i$ (and $\\epsilon_i$) are centered data obtained\nfor each case by subtracting sample means. As pointed out in the\nremark, we argue that theoretical results stated in Section~\\ref{SEC:4} remain\nunchanged for this situation.\nIn the context of (\\ref{augmentedLS}) centering ensures that $X_i$,\n$i=1,\\ldots,n$, can be \\textit{exactly}\nrepresented by $X_i=\\sum_{j=1}^n\\langle X_i,\\widehat{\\psi}_r \\rangle\n\\widehat{\\psi}_r$ (necessarily $\\hat\\lambda_j=0$ for $j>n$).\n\nOur theoretical analysis of the estimators defined by (\\ref\n{augmentedLS}) relies on the work of \\citet{HallHorowitz2007} who\nderive rates of convergence of the estimator $\\widehat{\\beta}(t)$ in a\nstandard functional regression model with $S=0$. Under our Assumption~\\ref{assum2} their results are additionally based on the following\nassumption on the eigendecompositions of $X$ and $\\beta$.\n\n\n\\begin{assumption} \\label{assum3}\n\n\n(a) There exist some $\\mu>1$ and some $\\sigma^2<C_0<\\infty$ such\nthat $\\lambda_j-\\lambda_{j+1}\\geq C_0^{-1} j^{-\\mu-1}$ for all\n$j\\geq1$.\n\n(b) $\\beta(t)=\\sum_{j=1}^\\infty\\alpha_j \\psi(t)$ for all $t$,\nand $|\\alpha_j|\\geq C_0 j^{-\\nu}$ for some $\\nu>1+\\frac{1}{2}\\mu$.\n\n\\end{assumption}\n\n\\citet{HallHorowitz2007} show that if $S=0$ and $k=O(n^{1/(\\mu+2\\nu\n)})$, then $\\int_a^b (\\widehat{\\beta}(t)-\\beta(t))^2\\,dt =O_p(n^{-(2\\nu\n-1)/(\\mu+2\\nu)})$. This is known to be an optimal rate\nof convergence under the standard model.\n\nWhen dealing with points of impact, some additional conditions are\nrequired. Note that\n$\\sigma(t,s)=\\sum_{j=1}^\\infty\\lambda_j \\psi_j(t)\\psi_j(s)$.\nLet $\\sigma^{[k]}(t,s):=\\sum_{j=k+1}^\\infty\\lambda_j\\times\\break  \\psi_j(t)\\psi\n_j(s)$, and let $\\mathbf{M}_k$ denote\nthe $S\\times S$ matrix with elements $\\sigma^{[k]}(\\tau_r,\\tau_s)$,\n$r,s=1,\\ldots,S$. Furthermore,\nlet $\\lambda_{\\mathrm{min}}(\\mathbf{M}_k)$ denote the smallest eigenvalue of\nthe matrix $\\mathbf{M}_k$.\n\n\n\\begin{assumption} \\label{assum4}\n\n(a) $\\sup_t \\sup_j \\psi_j(t)^2\\leq C_\\psi$ for some $C_\\psi<\\infty$.\\vspace*{-6pt}\n\n\\begin{longlist}[(b)]\n\\item[(b)] There exists some $0< C_1 <\\infty$ such that $\\lambda_j\\leq\nC_1 j^{-\\mu}$ for all $j$.\n\n\\item[(c)] There\nexists some $0<D<\\infty$ such that $\\lambda_{\\mathrm{min}}(\\mathbf\n{M}_k)\\geq D k^{-\\mu+1}$ for all $k$.\n\\end{longlist}\n\n\\end{assumption}\n\nCondition (a) is, for example, satisfied if $\\psi_1,\\psi_2,\\ldots$\ncorrespond to a Fourier-type basis.\nNote that Assumption~\\ref{assum3}(a) already implies that $\\lambda_j$\nmust not be less\nthan a constant multiple of $j^{-\\mu}$, and thus condition (b) requires\nthat $j^{-\\mu}$ is also an upper bound for the rate of convergence of\n$\\lambda_j$. This in turn implies that $\\sum_{j=k+1}^\\infty\\lambda\n_j\\leq C_2 k^{-\\mu+1}$ as well as $|\\sigma^{[k]}(t,s)| \\leq C_2C_\\psi^2\nk^{-\\mu+1}$\nfor some $ C_2<\\infty$ and all $k$. Condition (c) therefore only\nintroduces an additional regularity condition on the matrix $\\mathbf\n{M}_k$. For the Brownian motion discussed in Section~\\ref{sec3}, it is easily seen\nthat these requirements are necessarily fulfilled with $\\mu=2$.\n\nWe now obtain the following theorem.\n\n\n\\begin{thmm} \\label{parestGEN}\nUnder our setup and Assumptions \\ref{assum2}--\\ref{assum4} suppose that\n$\\widehat{S}=S$ and that\nestimators $\\widehat{\\tau}_r$ satisfy (\\ref{lem4eq1}) as well as (\\ref\n{lem4eq3}) for all $r=1,\\ldots,S$.\nIf additionally\n$k=O(n^{1/(\\mu+2\\nu)})$ and $n^{1/(\\mu+2\\nu)}=O(k)$ as $n\\rightarrow\n\\infty$, then\n\n\n\n\\begin{eqnarray}\n\\Vert\\widehat{\\bolds{\\beta}}-\\bolds{\\beta}\\Vert _2^2&=&O_p\n\\bigl(n^{-2\\nu/(\\mu+2\\nu)}\\bigr), \\label{thmpGENeq1}\n\\\\\n\\int_a^b \\bigl(\\widehat{\\beta}(t)-\\beta(t)\n\\bigr)^2\\,dt & =&O_p\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\label{thmpGENeq2}\n\\end{eqnarray}\n\n\\end{thmm}\n\nIn the presence of points of impact the slope function $\\beta(t)$ can\nthus be estimated with the same\nrate of convergence as in the standard model with $S=0$. The estimators\n$\\widehat{\\beta}_r$ of $\\beta_r$, $r=1,\\ldots,S$, achieve a slightly\nfaster rate of convergence.\n\n\n\\begin{table}\n\\tabcolsep=0pt\n\\caption{Estimation errors for different sample sizes for the\nsimulation study\n(OU-process, $\\tau_1 =0.25$, $\\tau_2=0.75$, $\\beta_1= 2$, $\\beta_2=\n1$).\nThe column containing the estimate $\\widehat{P}(\\widehat{S}=S)$\ncontains two numbers: the estimate derived from the BIC followed by its\nvalue derived from the cut-off procedure}\\label{simtab}\n\n\\begin{tabular*}{\\textwidth}{@{\\extracolsep{\\fill}}lccccccccccc@{}}\n\\hline\n\\multicolumn{2}{@{}l}{\\textbf{Sample sizes}} & \\multicolumn{10}{c@{}}{\\textbf{Parameter\nestimates}} \\[-6pt]\n\\multicolumn{2}{@{}l}{\\hrulefill} & \\multicolumn{10}{c@{}}{\\hrulefill} \\\\\n$\\bolds{p}$ & $\\bolds{n}$ & $\\bolds{|\\widehat{\\tau}_1-\\tau_1|}$ & $\\bolds{|\\widehat{\\tau}_2-\\tau_2|}$ &\n$\\bolds{|\\widehat{\\beta}_1-\\beta_1|}$ & $\\bolds{|\\widehat{\\beta}_2-\\beta_2|}$ &$\\bolds{\\widehat\n{S}} $ & $\\bolds{\\widehat{P}(\\widehat{S}=S)}$ & $\\bolds{\\widehat{k} }$ & $\\bolds{\\smallint\n(\\widehat{\\beta}-\\beta)^2}$ \n\n& \\textbf{MSE} & \\multicolumn{1}{c@{}}{$\\bolds{\\widehat{\\kappa}}$} \\\\\n\\hline\n\\multicolumn{12}{c}{Simulation results if $\\beta(t) \\equiv0$} \\\\\n\\phantom{0.}1001 & \\phantom{00}50 & 0.0130 & 0.0357 & 0.393 & 0.353 & 1.74 & 0.65/0.34 & 1.33\n& 6.82 & 1.21 & 0.89 \\\\\n& \\phantom{0}100 & 0.0069 & 0.0226 & 0.274 & 0.249 & 1.96 & 0.77/0.40 & 1.05 &\n3.43 & 1.21 & 0.94 \\\\\n& \\phantom{0}250 & 0.0027 & 0.0099 & 0.129 & 0.145 & 2.14 & 0.83/0.61 & 0.67 &\n1.11 & 1.13 & 0.97 \\\\\n& \\phantom{0}500 & 0.0012 & 0.0061 & 0.070 & 0.097 & 2.15 & 0.86/0.73 & 0.45 &\n0.51 & 1.08 & 0.98 \\\\\n& 5000 & 0.0000 & 0.0004 & 0.012 & 0.012 & 2.04 & 0.96/0.98 & 0.03 &\n0.00 & 1.00 & 1.00 \\\\\n20,001& \\phantom{00}50 & 0.0118 & 0.0333 & 0.393 & 0.350 & 1.71 & 0.64/0.35 & 1.78\n& 6.91 & 1.19 & 0.89 \\\\\n& \\phantom{0}100 & 0.0068 & 0.0246 & 0.279 & 0.276 & 1.94 & 0.76/0.46 & 1.46 &\n3.81 & 1.19 & 0.94 \\\\\n& \\phantom{0}250 & 0.0025 & 0.0108 & 0.121 & 0.144 & 2.15 & 0.83/0.62 & 0.74 &\n1.02 & 1.12 & 0.97 \\\\\n& \\phantom{0}500 & 0.0013 & 0.0063 & 0.064 & 0.092 & 2.14 & 0.88/0.75 & 0.48 &\n0.40 & 1.08 & 0.98 \\\\\n& 5000 & 0.0001 & 0.0005 & 0.013 & 0.012 & 2.06 & 0.94/0.94 & 0.04 &\n0.00 & 1.01 & 1.00 \\[3pt]\n\\multicolumn{12}{c}{Simulation results if $\\beta(t) \\neq0$} \\\\\n\\phantom{0.}1001 & \\phantom{00}50 & 0.0150 & 0.0423 & 0.465 & 0.499 & 1.54 & 0.49/0.30 & 2.10\n& 10.82 & 1.27 & 0.88 \\\\\n& \\phantom{0}100 & 0.0097 & 0.0317 & 0.376 & 0.400 & 1.86 & 0.63/0.34 & 2.06 &\n5.93 & 1.27 & 0.94 \\\\\n& \\phantom{0}250 & 0.0039 & 0.0151 & 0.206 & 0.234 & 2.25 & 0.68/0.46 & 1.83 &\n2.21 & 1.17 & 0.97 \\\\\n& \\phantom{0}500 & 0.0015 & 0.0083 & 0.107 & 0.164 & 2.30 & 0.72/0.59 & 1.69 &\n0.90 & 1.10 & 0.99 \\\\\n& 5000 & 0.0000 & 0.0006 & 0.036 & 0.027 & 2.25 & 0.79/0.97 & 2.01 &\n0.05 & 1.01 & 1.00 \\\\\n20,001& \\phantom{00}50 & 0.0166 & 0.0399 & 0.467 & 0.465 & 1.52 & 0.47/0.29 & 2.14\n& 11.19 & 1.29 & 0.89 \\\\\n& \\phantom{0}100 & 0.0099 & 0.0286 & 0.370 & 0.378 & 1.90 & 0.64/0.36 & 2.08 &\n5.95 & 1.26 & 0.94 \\\\\n& \\phantom{0}250 & 0.0037 & 0.0171 & 0.185 & 0.263 & 2.27 & 0.67/0.49 & 1.90 &\n2.19 & 1.15 & 0.97 \\\\\n& \\phantom{0}500 & 0.0018 & 0.0104 & 0.118 & 0.177 & 2.32 & 0.71/0.62 & 1.78 &\n1.11 & 1.11 & 0.99 \\\\\n& 5000 & 0.0002 & 0.0007 & 0.038 & 0.028 & 2.23 & 0.82/0.95 & 2.03 &\n0.05 & 1.02 & 1.00 \\\\\n\\hline\n\\end{tabular*}\n\\end{table}\n\n\n\n\n\\section{Simulation study}\\label{sec6}\n\nWe proceed by studying the finite sample performance of our estimation\nprocedure described in the preceding sections.\nFor different values of $n$, $p$, observations $(X_i,Y_i)$ are\ngenerated according to the points of impact model {(\\ref{{impact-model}})}\nwhere $\\varepsilon_i \\sim N(0,1)$ are independent error terms. The\nalgorithms are implemented in R, and all tables are based on 1000\nrepetitions of the simulation experiments.\nThe corresponding R-code can be obtained from the authors upon request.\n\nThe data $X_1,\\ldots,X_n$ are generated as independent\nOrnstein--Uhlenbeck processes ($\\kappa=1$) with parameters $\\theta=5$\nand $\\sigma_u=3.5$ at $p$ equidistant grid points over the interval\n$[0,1]$. Simulated trajectories are determined by using exact updating\nformulas as proposed by \\citet{Gillespie1996}.\nThe simulation study is based on $S=2$ points of impact located at\n$\\tau_1 = 0.25$ and $\\tau_2 = 0.75$ with corresponding coefficients\n$\\beta_1 = 2$ as well as\n$\\beta_2 = 1$.\nResults are reported in Table~\\ref{simtab},\nwhere the upper part of the table refers to the situation with $\\beta\n(t)\\equiv0$,\nwhile the lower part represents a model with $\\beta(t) = 3.5t^3-5.5t^2+3t+0.5$.\n\nIn both cases, estimation of the points of impact relies on setting\n$\\delta=C \\frac{1}{\\sqrt{n}}$ for $C=1$, but similar results could be\nobtained for a wide range of values $C$.\nThe results are then obtained by performing best subset selection with\nthe BIC-criterion via the R package bestglm on the augmented model\n{(\\ref{{augmentedmodel}})}\n\n\n\n", "itemtype": "equation", "pos": 51297, "prevtext": "\n\nas $n\\rightarrow\\infty$. A proof is straightforward, and thus omitted.\n\nIn the general case with $\\beta(t)\\neq0$ for some $t$, we propose to\nrely on the augmented model (\\ref{augmentedmodel}). Thus, let $\\hat\n\\lambda_1\\geq\\hat\\lambda_2\\geq\\cdots$ and $\\widehat{\\psi}_1,\\widehat{\\psi\n}_2,\\ldots$ denote eigenvalues and eigenfunctions of the empirical\ncovariance operator of $X_1,\\ldots,X_n$. Given estimates\n$\\widehat{\\tau}_1,\\ldots,\\widehat{\\tau}_{\\widehat{S}}$ and a suitable\ncut-off parameter $k$ estimates\n$\\widehat{\\bolds{\\beta}}=(\\widehat{\\beta}_1,\\ldots,\\widehat{\\beta\n}_{\\widehat{S}})^T$\nof $\\bolds{\\beta}=(\\beta_1,\\ldots,\\beta_S)^T$ and $\\widehat{\\alpha\n}_1,\\ldots,\\widehat{\\alpha}_k$ of\n$\\alpha_1,\\ldots,\\alpha_k$ are determined by minimizing\n\n\n\n", "index": 49, "text": "\\begin{equation}\n\\label{augmentedLS} \\sum_{i=1}^n \\Biggl(\nY_i-\\sum_{r=1}^k\na_r \\langle X_i,\\widehat{\\psi}_r \\rangle-\n\\sum_{r=1}^{\\widehat{S}}b_r\nX_i(\\widehat\\tau_r) \\Biggr)^2\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\sum_{i=1}^{n}\\Biggl{(}Y_{i}-\\sum_{r=1}^{k}a_{r}\\langle X_{i},\\widehat{\\psi}_{%&#10;r}\\rangle-\\sum_{r=1}^{\\widehat{S}}b_{r}X_{i}(\\widehat{\\tau}_{r})\\Biggr{)}^{2}\" display=\"block\"><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>-</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msub><mi>a</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>-</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mover accent=\"true\"><mi>S</mi><mo>^</mo></mover></munderover><mrow><msub><mi>b</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow><mn>2</mn></msup></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nHere, $\\widetilde{S}$ is the number of all possible candidates for the\npoints of impact and $k$ is initially set to $6$ principal components,\nbut tendencies remain unchanged for a broad range of values $k$.\n\n\nFor different sample sizes $n$ and $p$, Table~\\ref{simtab} provides the\naverage absolute errors of our estimates, the frequency of $\\widehat\n{S}=S$, as well as average values of $\\widehat{S}$, $\\widehat{k}$, the\nprediction error $\\mathrm{MSE} = \\frac{1}{n}\\sum_{i=1}^n(\\widehat\n{y}_i-y_i)^2$ and $\\widehat{\\kappa}$. The column containing $\\widehat\n{P}(\\widehat{S}=S)$ consists of two values. The first one being the\nfrequency of $\\widehat{S}=S$ resulting from the BIC. For the second\none, $S$ was estimated by the cut-off\nprocedure using $\\lambda=2\\sqrt{\\widehat{\\operatorname{Var}}(Y)/n \\log\n(\\frac{b-a}{\\delta} )}$,\nwhere $\\widehat{\\operatorname{Var}}(Y)$ denotes the estimated sample variance of $Y_i$.\nThe cut-off criterion yields very reliable estimates $\\widehat{S}$ of\n$S$ for $n=5000$, but showed a clear tendency to underestimate $S$ for\nsmaller sample sizes. The BIC-criterion however proves to possess a\nmuch superior behavior in this regards for small $n$ but is\noutperformed by the cut-off criterion for $n=5000$ in the case $\\beta\n(t) \\neq0$.\n\nIn order to match $\\{\\widehat{\\tau}_s\\}_{s=1,\\ldots,\\widehat{S}}$ and $\\{\n\\tau_r\\}_{r=1,2}$ the interval $ [0,1 ]$ is divided into\n$I_1= [0,\\frac{1}{2}(\\tau_{1}+\\tau_{2}) ]$ and\n$I_2 =  [\\frac{1}{2}(\\tau_{1}+\\tau_{2}),1 ]$.\nThe estimate $\\widehat{\\tau}_s$ in interval $I_r$ with the minimal\ndistance to $\\tau_r$ is then used as an estimate for $\\tau_r$. No point\nof impact candidate in interval $I_r$ results in an ``unmatched'' $\\tau\n_r$, $r=1,\\ldots,S$ and a missing value when computing averages.\n\nThe table shows that estimates of points of impact are generally quite\naccurate even for smaller sample sizes. The error decreases rapidly as\n$n$ increases, and this improvement is essentially independent of $p$.\nAs expected, since $\\beta_2<\\beta_1$, the error of the absolute\ndistance between the second point of impact and its estimate is larger\nthan the error for the first point of impact.\n\nMoreover, due to the common effect of the trajectory $X_i(\\cdot)$ on\n$Y_i$, the overall estimation\nerror in the case where $\\beta(t)\\neq0$ is slightly higher than in the\nfirst case. At a first glance, one may be puzzled by the fact that for\n$n=5000$ and $p=1001$ the average error $|\\widehat{\\tau}_r-\\tau_r|$\nis considerably smaller than the distance $\\frac{1}{p-1}=\\frac\n{1}{1000}$ between two adjacent grid points. But note that our\nsimulation design implies that $\\tau_r\\in\\{t_j| j=1,\\ldots,p\\}$,\n$r=1,\\ldots,S$, for $p=1001$ as well as $p=20\\mbox{,}001$. For medium to large\nsample sizes, there is thus a fairly high probability that $\\widehat\n{\\tau}_r=\\tau_r$. The case $p=1001$ particularly profits from this situation.\nFinally, it can be seen that estimates for $\\widehat{\\kappa}$ tend to\nslightly underestimate the true value $\\kappa=1 $ for small values of $n$.\n\n\n\n\\section{Applications to real data}\\label{sec7}\n\nIn this section, the algorithm from Section~\\ref{SEC:4} is applied to a dataset\nconsisting of Canadian weather data. In this dataset, we relate the\nmean relative humidity to hourly temperature data.\nIn the Supplementary Appendix A [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})], a further\napplication can be found. We there analyze spectral data which play an\nimportant role in spectrophotometry and different applied scientific fields.\n\nIn both examples, the algorithm is applied to centered observations and\nthe estimation procedure from Section~\\ref{SEC:4} is modified by eliminating all\npoints in an interval of size $\\delta|\\log\\delta|$ around a point of\nimpact candidate $\\widehat{\\tau}_j$, which is still sufficient to\nestablish assertion (\\ref{thmm3eq1}).\n\nAfter estimating $\\widetilde{S}$ possible candidates for the points of\nimpact, the approximate model {(\\ref{{augmentedmodel}})},\n\n", "itemtype": "equation", "pos": 60651, "prevtext": "\n\nover all $a_r, b_s$, $r=1,\\ldots,k$, $s=1,\\ldots,\\widehat{S}$. Based on\nthe estimated coefficients\n$\\widehat{\\alpha}_1,\\ldots,\\widehat{\\alpha}_k$, and estimator of the\nslope function $\\beta$ is then given\nby $\\widehat{\\beta}(t):=\\sum_{r=1}^k \\widehat{\\alpha}_k \\widehat{\\psi}_r(t)$.\n\nIn the following we will rely on a slight change of notation in the\nsense that $Y_i$, $X_i$ (and $\\epsilon_i$) are centered data obtained\nfor each case by subtracting sample means. As pointed out in the\nremark, we argue that theoretical results stated in Section~\\ref{SEC:4} remain\nunchanged for this situation.\nIn the context of (\\ref{augmentedLS}) centering ensures that $X_i$,\n$i=1,\\ldots,n$, can be \\textit{exactly}\nrepresented by $X_i=\\sum_{j=1}^n\\langle X_i,\\widehat{\\psi}_r \\rangle\n\\widehat{\\psi}_r$ (necessarily $\\hat\\lambda_j=0$ for $j>n$).\n\nOur theoretical analysis of the estimators defined by (\\ref\n{augmentedLS}) relies on the work of \\citet{HallHorowitz2007} who\nderive rates of convergence of the estimator $\\widehat{\\beta}(t)$ in a\nstandard functional regression model with $S=0$. Under our Assumption~\\ref{assum2} their results are additionally based on the following\nassumption on the eigendecompositions of $X$ and $\\beta$.\n\n\n\\begin{assumption} \\label{assum3}\n\n\n(a) There exist some $\\mu>1$ and some $\\sigma^2<C_0<\\infty$ such\nthat $\\lambda_j-\\lambda_{j+1}\\geq C_0^{-1} j^{-\\mu-1}$ for all\n$j\\geq1$.\n\n(b) $\\beta(t)=\\sum_{j=1}^\\infty\\alpha_j \\psi(t)$ for all $t$,\nand $|\\alpha_j|\\geq C_0 j^{-\\nu}$ for some $\\nu>1+\\frac{1}{2}\\mu$.\n\n\\end{assumption}\n\n\\citet{HallHorowitz2007} show that if $S=0$ and $k=O(n^{1/(\\mu+2\\nu\n)})$, then $\\int_a^b (\\widehat{\\beta}(t)-\\beta(t))^2\\,dt =O_p(n^{-(2\\nu\n-1)/(\\mu+2\\nu)})$. This is known to be an optimal rate\nof convergence under the standard model.\n\nWhen dealing with points of impact, some additional conditions are\nrequired. Note that\n$\\sigma(t,s)=\\sum_{j=1}^\\infty\\lambda_j \\psi_j(t)\\psi_j(s)$.\nLet $\\sigma^{[k]}(t,s):=\\sum_{j=k+1}^\\infty\\lambda_j\\times\\break  \\psi_j(t)\\psi\n_j(s)$, and let $\\mathbf{M}_k$ denote\nthe $S\\times S$ matrix with elements $\\sigma^{[k]}(\\tau_r,\\tau_s)$,\n$r,s=1,\\ldots,S$. Furthermore,\nlet $\\lambda_{\\mathrm{min}}(\\mathbf{M}_k)$ denote the smallest eigenvalue of\nthe matrix $\\mathbf{M}_k$.\n\n\n\\begin{assumption} \\label{assum4}\n\n(a) $\\sup_t \\sup_j \\psi_j(t)^2\\leq C_\\psi$ for some $C_\\psi<\\infty$.\\vspace*{-6pt}\n\n\\begin{longlist}[(b)]\n\\item[(b)] There exists some $0< C_1 <\\infty$ such that $\\lambda_j\\leq\nC_1 j^{-\\mu}$ for all $j$.\n\n\\item[(c)] There\nexists some $0<D<\\infty$ such that $\\lambda_{\\mathrm{min}}(\\mathbf\n{M}_k)\\geq D k^{-\\mu+1}$ for all $k$.\n\\end{longlist}\n\n\\end{assumption}\n\nCondition (a) is, for example, satisfied if $\\psi_1,\\psi_2,\\ldots$\ncorrespond to a Fourier-type basis.\nNote that Assumption~\\ref{assum3}(a) already implies that $\\lambda_j$\nmust not be less\nthan a constant multiple of $j^{-\\mu}$, and thus condition (b) requires\nthat $j^{-\\mu}$ is also an upper bound for the rate of convergence of\n$\\lambda_j$. This in turn implies that $\\sum_{j=k+1}^\\infty\\lambda\n_j\\leq C_2 k^{-\\mu+1}$ as well as $|\\sigma^{[k]}(t,s)| \\leq C_2C_\\psi^2\nk^{-\\mu+1}$\nfor some $ C_2<\\infty$ and all $k$. Condition (c) therefore only\nintroduces an additional regularity condition on the matrix $\\mathbf\n{M}_k$. For the Brownian motion discussed in Section~\\ref{sec3}, it is easily seen\nthat these requirements are necessarily fulfilled with $\\mu=2$.\n\nWe now obtain the following theorem.\n\n\n\\begin{thmm} \\label{parestGEN}\nUnder our setup and Assumptions \\ref{assum2}--\\ref{assum4} suppose that\n$\\widehat{S}=S$ and that\nestimators $\\widehat{\\tau}_r$ satisfy (\\ref{lem4eq1}) as well as (\\ref\n{lem4eq3}) for all $r=1,\\ldots,S$.\nIf additionally\n$k=O(n^{1/(\\mu+2\\nu)})$ and $n^{1/(\\mu+2\\nu)}=O(k)$ as $n\\rightarrow\n\\infty$, then\n\n\n\n\\begin{eqnarray}\n\\Vert\\widehat{\\bolds{\\beta}}-\\bolds{\\beta}\\Vert _2^2&=&O_p\n\\bigl(n^{-2\\nu/(\\mu+2\\nu)}\\bigr), \\label{thmpGENeq1}\n\\\\\n\\int_a^b \\bigl(\\widehat{\\beta}(t)-\\beta(t)\n\\bigr)^2\\,dt & =&O_p\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\label{thmpGENeq2}\n\\end{eqnarray}\n\n\\end{thmm}\n\nIn the presence of points of impact the slope function $\\beta(t)$ can\nthus be estimated with the same\nrate of convergence as in the standard model with $S=0$. The estimators\n$\\widehat{\\beta}_r$ of $\\beta_r$, $r=1,\\ldots,S$, achieve a slightly\nfaster rate of convergence.\n\n\n\\begin{table}\n\\tabcolsep=0pt\n\\caption{Estimation errors for different sample sizes for the\nsimulation study\n(OU-process, $\\tau_1 =0.25$, $\\tau_2=0.75$, $\\beta_1= 2$, $\\beta_2=\n1$).\nThe column containing the estimate $\\widehat{P}(\\widehat{S}=S)$\ncontains two numbers: the estimate derived from the BIC followed by its\nvalue derived from the cut-off procedure}\\label{simtab}\n\n\\begin{tabular*}{\\textwidth}{@{\\extracolsep{\\fill}}lccccccccccc@{}}\n\\hline\n\\multicolumn{2}{@{}l}{\\textbf{Sample sizes}} & \\multicolumn{10}{c@{}}{\\textbf{Parameter\nestimates}} \\[-6pt]\n\\multicolumn{2}{@{}l}{\\hrulefill} & \\multicolumn{10}{c@{}}{\\hrulefill} \\\\\n$\\bolds{p}$ & $\\bolds{n}$ & $\\bolds{|\\widehat{\\tau}_1-\\tau_1|}$ & $\\bolds{|\\widehat{\\tau}_2-\\tau_2|}$ &\n$\\bolds{|\\widehat{\\beta}_1-\\beta_1|}$ & $\\bolds{|\\widehat{\\beta}_2-\\beta_2|}$ &$\\bolds{\\widehat\n{S}} $ & $\\bolds{\\widehat{P}(\\widehat{S}=S)}$ & $\\bolds{\\widehat{k} }$ & $\\bolds{\\smallint\n(\\widehat{\\beta}-\\beta)^2}$ \n\n& \\textbf{MSE} & \\multicolumn{1}{c@{}}{$\\bolds{\\widehat{\\kappa}}$} \\\\\n\\hline\n\\multicolumn{12}{c}{Simulation results if $\\beta(t) \\equiv0$} \\\\\n\\phantom{0.}1001 & \\phantom{00}50 & 0.0130 & 0.0357 & 0.393 & 0.353 & 1.74 & 0.65/0.34 & 1.33\n& 6.82 & 1.21 & 0.89 \\\\\n& \\phantom{0}100 & 0.0069 & 0.0226 & 0.274 & 0.249 & 1.96 & 0.77/0.40 & 1.05 &\n3.43 & 1.21 & 0.94 \\\\\n& \\phantom{0}250 & 0.0027 & 0.0099 & 0.129 & 0.145 & 2.14 & 0.83/0.61 & 0.67 &\n1.11 & 1.13 & 0.97 \\\\\n& \\phantom{0}500 & 0.0012 & 0.0061 & 0.070 & 0.097 & 2.15 & 0.86/0.73 & 0.45 &\n0.51 & 1.08 & 0.98 \\\\\n& 5000 & 0.0000 & 0.0004 & 0.012 & 0.012 & 2.04 & 0.96/0.98 & 0.03 &\n0.00 & 1.00 & 1.00 \\\\\n20,001& \\phantom{00}50 & 0.0118 & 0.0333 & 0.393 & 0.350 & 1.71 & 0.64/0.35 & 1.78\n& 6.91 & 1.19 & 0.89 \\\\\n& \\phantom{0}100 & 0.0068 & 0.0246 & 0.279 & 0.276 & 1.94 & 0.76/0.46 & 1.46 &\n3.81 & 1.19 & 0.94 \\\\\n& \\phantom{0}250 & 0.0025 & 0.0108 & 0.121 & 0.144 & 2.15 & 0.83/0.62 & 0.74 &\n1.02 & 1.12 & 0.97 \\\\\n& \\phantom{0}500 & 0.0013 & 0.0063 & 0.064 & 0.092 & 2.14 & 0.88/0.75 & 0.48 &\n0.40 & 1.08 & 0.98 \\\\\n& 5000 & 0.0001 & 0.0005 & 0.013 & 0.012 & 2.06 & 0.94/0.94 & 0.04 &\n0.00 & 1.01 & 1.00 \\[3pt]\n\\multicolumn{12}{c}{Simulation results if $\\beta(t) \\neq0$} \\\\\n\\phantom{0.}1001 & \\phantom{00}50 & 0.0150 & 0.0423 & 0.465 & 0.499 & 1.54 & 0.49/0.30 & 2.10\n& 10.82 & 1.27 & 0.88 \\\\\n& \\phantom{0}100 & 0.0097 & 0.0317 & 0.376 & 0.400 & 1.86 & 0.63/0.34 & 2.06 &\n5.93 & 1.27 & 0.94 \\\\\n& \\phantom{0}250 & 0.0039 & 0.0151 & 0.206 & 0.234 & 2.25 & 0.68/0.46 & 1.83 &\n2.21 & 1.17 & 0.97 \\\\\n& \\phantom{0}500 & 0.0015 & 0.0083 & 0.107 & 0.164 & 2.30 & 0.72/0.59 & 1.69 &\n0.90 & 1.10 & 0.99 \\\\\n& 5000 & 0.0000 & 0.0006 & 0.036 & 0.027 & 2.25 & 0.79/0.97 & 2.01 &\n0.05 & 1.01 & 1.00 \\\\\n20,001& \\phantom{00}50 & 0.0166 & 0.0399 & 0.467 & 0.465 & 1.52 & 0.47/0.29 & 2.14\n& 11.19 & 1.29 & 0.89 \\\\\n& \\phantom{0}100 & 0.0099 & 0.0286 & 0.370 & 0.378 & 1.90 & 0.64/0.36 & 2.08 &\n5.95 & 1.26 & 0.94 \\\\\n& \\phantom{0}250 & 0.0037 & 0.0171 & 0.185 & 0.263 & 2.27 & 0.67/0.49 & 1.90 &\n2.19 & 1.15 & 0.97 \\\\\n& \\phantom{0}500 & 0.0018 & 0.0104 & 0.118 & 0.177 & 2.32 & 0.71/0.62 & 1.78 &\n1.11 & 1.11 & 0.99 \\\\\n& 5000 & 0.0002 & 0.0007 & 0.038 & 0.028 & 2.23 & 0.82/0.95 & 2.03 &\n0.05 & 1.02 & 1.00 \\\\\n\\hline\n\\end{tabular*}\n\\end{table}\n\n\n\n\n\\section{Simulation study}\\label{sec6}\n\nWe proceed by studying the finite sample performance of our estimation\nprocedure described in the preceding sections.\nFor different values of $n$, $p$, observations $(X_i,Y_i)$ are\ngenerated according to the points of impact model {(\\ref{{impact-model}})}\nwhere $\\varepsilon_i \\sim N(0,1)$ are independent error terms. The\nalgorithms are implemented in R, and all tables are based on 1000\nrepetitions of the simulation experiments.\nThe corresponding R-code can be obtained from the authors upon request.\n\nThe data $X_1,\\ldots,X_n$ are generated as independent\nOrnstein--Uhlenbeck processes ($\\kappa=1$) with parameters $\\theta=5$\nand $\\sigma_u=3.5$ at $p$ equidistant grid points over the interval\n$[0,1]$. Simulated trajectories are determined by using exact updating\nformulas as proposed by \\citet{Gillespie1996}.\nThe simulation study is based on $S=2$ points of impact located at\n$\\tau_1 = 0.25$ and $\\tau_2 = 0.75$ with corresponding coefficients\n$\\beta_1 = 2$ as well as\n$\\beta_2 = 1$.\nResults are reported in Table~\\ref{simtab},\nwhere the upper part of the table refers to the situation with $\\beta\n(t)\\equiv0$,\nwhile the lower part represents a model with $\\beta(t) = 3.5t^3-5.5t^2+3t+0.5$.\n\nIn both cases, estimation of the points of impact relies on setting\n$\\delta=C \\frac{1}{\\sqrt{n}}$ for $C=1$, but similar results could be\nobtained for a wide range of values $C$.\nThe results are then obtained by performing best subset selection with\nthe BIC-criterion via the R package bestglm on the augmented model\n{(\\ref{{augmentedmodel}})}\n\n\n\n", "index": 51, "text": "\\begin{equation}\n\\label{augmentedmodel-2} Y_i\\approx\\sum_{r=1}^k\n\\alpha_r \\langle X_i,\\widehat{\\psi}_r\n\\rangle +\\sum_{r=1}^{\\widetilde{S}}\\beta_r\nX_i(\\tilde\\tau_r)+\\varepsilon_i^*.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"Y_{i}\\approx\\sum_{r=1}^{k}\\alpha_{r}\\langle X_{i},\\widehat{\\psi}_{r}\\rangle+%&#10;\\sum_{r=1}^{\\widetilde{S}}\\beta_{r}X_{i}(\\tilde{\\tau}_{r})+\\varepsilon_{i}^{*}.\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>\u2248</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">~</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><msubsup><mi>\u03b5</mi><mi>i</mi><mo>*</mo></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nis used, where initially $k=6$ is chosen.\nOver a fine grid of different values of~$\\delta$, points of impact and\nprincipal components are selected simultaneously by best subset\nselection with the BIC-criterion and the model corresponding to the\nminimal BIC is then chosen. The maximum number of variables selected by\nthe BIC-criterion is set to $6$ and all curves have been transformed to\nbe observed over $[0,1]$ when applying the algorithm from Section~\\ref{SEC:4}.\nThe performance of the model is then measured by means of a\ncross-validated prediction error.\n\n\n\n\nIn the Canadian weather dataset, the hourly mean temperature and\nrelative humidity from the $15$ closest weather stations in an area\naround $100$ km from Montreal was obtained for each of the $31$ days in\nDecember $2013$. The data was compiled from \\url{http://climate.weather.gc.ca}.\nWeather stations with more than ten missing observations on the\ntemperature or relative humidity were discarded from the dataset. The\nremaining stations had their nonavailable observations replaced by the\nmean of their closest observed predecessor and successor. After\npreprocessing a total of $n=13$ weather stations remained and for each\nstation $p=744$ equidistant hourly observations of the temperature were\nobserved.\nThe response variable $Y_i$ was taken to be the mean over all observed\nvalues of the relatively humidity at station $i$.\n\nA cross-validated prediction error was calculated for three competing\nregression models based on {(\\ref{{augmentedmodel}})}.\nIn the first model, the mean relative humidity for each station was\nexplained by using the approximate model which combines the points of\nimpacts with a functional part.\nThe second and third model describe the cases $k = 0$ and $\\widetilde\n{S}=0$ in the approximate model, consisting only of points of impact\nand the functional part, respectively.\nFor the first two models, points of impact were determined by\nconsidering a total of $146$ equidistant values of $\\delta$ between\n$0.10$ and $0.49$. In all models BIC was used to approximate the\noptimal values of the respective tuning parameters $\\delta$, $S$ and/or\n$k$ in a first step. The mean squared prediction error $\\mathit{MSPE}=\\frac\n{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$ was then calculated by means of\na leave one out cross-validation based on the chosen points of impact\nand/or principal components from the first step. Additionally, the\nmedian of $(y_i - \\hat{y}_i)^2$, $i=1,\\ldots,n$, has been calculated as\na more robust measure of the error.\n Depicted in the upper panel of Figure~\\ref{fig:Weather2} is\nthe observed temperature trajectory for the weather station\n``McTavish,'' showing a rather rough process.\nThe lower panel of this figure shows $|\\frac{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ for the optimal value of $\\delta=\n0.18$ as obtained by the best model fit of the approximate model. While\norange lines represent the locations of the points of impact which were\nactually selected with the help of the BIC-criterion, the location of\nthe remaining candidates are indicated by black vertical lines.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f03.eps}\n\n\\caption{The upper panel of this figure shows a\ntrajectory from the observed temperature curves of the Canadian weather\ndata. The lower panel shows {$|\\frac{1}{n}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)Y_i|$} during the selection procedure. Locations of\nselected points of impact in the augmented model are indicated by\norange lines. The location of the remaining candidate is displayed by a\nblack line.}\n\\label{fig:Weather2}\n\\end{figure}\n\n\n\\begin{table}[b]\n\\caption{Estimated number of principal components $k$, points of impact\n$S$,\nprediction error and the median of $(y_i-\\hat{y}_i)^2$ for the\nCanadian weather data}\n\\label{app.tab:weather}\n\n\\begin{tabular*}{\\textwidth}{@{\\extracolsep{\\fill}}lcccc@{}}\n\\hline\n\\textbf{Model} & $\\bolds{\\widehat{k}}$ & $\\bolds{\\widehat{S}}$ & $\\mathbf{MSPE}$ & $\\bolds{\\operatorname{median}((y-\\hat{y})^2)}$\\\\\n\\hline\nAugmented & 3 & 3 & 2.314& 0.251\\\\% (12.86) \\\\\nPoints of impact & 0 & 3 & 1.714& 0.974\\\\ \nFLR & 6 & 0 & 5.346& 1.269\\\\ \n\\hline\n\\end{tabular*}\n\n\\end{table}\n\n\nTable~\\ref{app.tab:weather} provides the empirical results when fitting\nthe three competing models. In terms of the prediction error, it can\nclearly be seen from the table that the frequently applied functional\nlinear regression model is outperformed by the model consisting solely\nof points of impact as well as the augmented (approximate) model. This\nimpression is supported by the last column of the table which gives the\nmedian value of $(y_i - \\hat{y}_i)^2$, showing additionally that,\ntypically, the augmented model performs even better than the plain\npoints of impact model.\n\nAn estimate $\\widehat{\\kappa}=0.14$ for $\\kappa$ was obtained for\n$\\delta\\approx0.3$, that is, the midpoint of the chosen values of\n$\\delta$. The estimated value of $\\kappa=0.14$ corresponds to rather\nrough sample paths as shown in the upper plot of Figure~\\ref{fig:Weather2}.\n\nIn view of the small sample size results have to be interpreted with\ncare, and we therefore do not claim that this application provides\nimportant substantial insights. Its main purpose is to serve as\nillustration for classes of problems where our approach may be of\npotential importance. It clearly shows that some relevant processes\nobserved in practice are nonsmooth.\nWith contemporary technical tools temperatures can be measured very\naccurately, leading to a negligible measurement error. But\ntemperatures, especially in Canada, can vary rapidly over time. The\nrough sample paths thus must be interpreted as an intrinsic feature of\ntemperature processes and cannot be explained by any type of ``error.''\n\n\\begin{appendix}\n\n\n\\section*{Appendix: Proofs of theorems}\\label{app}\n\nThis appendix provides the\nproofs of some of the main results. Remaining proofs can be\nfound in the supplementary material. Some of them rely on results from\n\\citeauthor{vandeGeerLederer2012} (\\citeyear{vandeGeerLederer2012}),\n\\citeauthor{vanderVaartWellner2000} (\\citeyear{vanderVaartWellner2000}) as well as\n\\citeauthor{ZhouLaffertyWassermann2008} (\\citeyear{ZhouLaffertyWassermann2008}).\n\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmident}} Set $\\beta_r:=0$ for\n$r=S+1,\\ldots,S^*$, and consider an arbitrary $j\\in\\{1,\\ldots,S^*\\}$.\nChoose $0<\\epsilon<\\min_{r,s\\in\\{1,\\ldots,S^*\\},r\\neq s} |\\tau_r-\\tau\n_s|$ small enough such that conditions\n(i)--(iv) of Definition~\\ref{de1} are satisfied. Using (\\ref{decompeps}), we\nobtain a decomposition into two\nuncorrelated components $X_{\\epsilon,\\tau_j}(\\cdot)$ and $\\zeta\n_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\\cdot)$:\n\n\\begin{eqnarray*}\n&&\\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)X(t)\\,dt+\\sum_{r=1}^{S^*}\n\\bigl(\\beta_r-\\beta_r^*\\bigr)X(\\tau_r)\n\\Biggr)^2 \\Biggr)\n\\\\\n&&\\qquad= \\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)X_{\\epsilon,\\tau_j}(t)\\,dt+ \\sum\n_{r=1}^{S^*}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)X_{\\epsilon,\\tau_j}(\\tau_r)\n\\Biggr)^2 \\Biggr)\n\\\\\n&&\\quad\\qquad{} +\\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)\\zeta _{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(t)\\,dt\n\\\\\n&&\\qquad\\quad{}+ \\sum\n_{r=1}^{S^*}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)\\zeta_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\n\\tau_r) \\Biggr)^2 \\Biggr)\n\\\\\n&&\\qquad\\geq \\mathbb{E} \\biggl( \\biggl(\\int_a^b\n\\bigl(\\beta(t)-\\beta^*(t)\\bigr)\\zeta _{\\epsilon,\\tau_j}(X)\n f_{\\epsilon,\\tau_j}(t)\\,dt\\\\\n &&\\qquad\\quad{}+\n\\sum_{r\\neq j}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)\\zeta_{\\epsilon,\\tau_j}(X)f_{\\epsilon\n,\\tau_j}(\n\\tau_r) + \\bigl(\\beta_j-\\beta_j^*\\bigr)\n\\zeta_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\\tau_j)\n\\biggr)^2 \\biggr)\n\\\\\n&&\\qquad\\geq 2 \\operatorname{var}\\bigl(\\zeta_{\\epsilon,\\tau_j}(X)\\bigr) \\bigl(\n\\beta_j-\\beta_j^*\\bigr) f_{\\epsilon,\\tau_j}(\n\\tau_j)\\\\\n&&\\qquad\\quad{}\\times \\biggl( \\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr) f_{\\epsilon,\\tau_j}(t)\\,dt+\\sum\n_{r\\neq\nj}\\bigl(\\beta_r-\\beta_r^*\\bigr)\nf_{\\epsilon,\\tau_j}(\\tau_r) \\biggr)\n\\\\\n&&\\qquad\\quad{} + \\operatorname{var}\\bigl(\\zeta_{\\epsilon,\\tau_j}(X)\\bigr) \\bigl(\n\\beta_j-\\beta _j^*\\bigr)^2f_{\\epsilon,\\tau_j}(\n\\tau_j)^2.\n\\end{eqnarray*}\n\n\n\nBy condition (iv), we have\n\n", "itemtype": "equation", "pos": 64837, "prevtext": "\n\nHere, $\\widetilde{S}$ is the number of all possible candidates for the\npoints of impact and $k$ is initially set to $6$ principal components,\nbut tendencies remain unchanged for a broad range of values $k$.\n\n\nFor different sample sizes $n$ and $p$, Table~\\ref{simtab} provides the\naverage absolute errors of our estimates, the frequency of $\\widehat\n{S}=S$, as well as average values of $\\widehat{S}$, $\\widehat{k}$, the\nprediction error $\\mathrm{MSE} = \\frac{1}{n}\\sum_{i=1}^n(\\widehat\n{y}_i-y_i)^2$ and $\\widehat{\\kappa}$. The column containing $\\widehat\n{P}(\\widehat{S}=S)$ consists of two values. The first one being the\nfrequency of $\\widehat{S}=S$ resulting from the BIC. For the second\none, $S$ was estimated by the cut-off\nprocedure using $\\lambda=2\\sqrt{\\widehat{\\operatorname{Var}}(Y)/n \\log\n(\\frac{b-a}{\\delta} )}$,\nwhere $\\widehat{\\operatorname{Var}}(Y)$ denotes the estimated sample variance of $Y_i$.\nThe cut-off criterion yields very reliable estimates $\\widehat{S}$ of\n$S$ for $n=5000$, but showed a clear tendency to underestimate $S$ for\nsmaller sample sizes. The BIC-criterion however proves to possess a\nmuch superior behavior in this regards for small $n$ but is\noutperformed by the cut-off criterion for $n=5000$ in the case $\\beta\n(t) \\neq0$.\n\nIn order to match $\\{\\widehat{\\tau}_s\\}_{s=1,\\ldots,\\widehat{S}}$ and $\\{\n\\tau_r\\}_{r=1,2}$ the interval $ [0,1 ]$ is divided into\n$I_1= [0,\\frac{1}{2}(\\tau_{1}+\\tau_{2}) ]$ and\n$I_2 =  [\\frac{1}{2}(\\tau_{1}+\\tau_{2}),1 ]$.\nThe estimate $\\widehat{\\tau}_s$ in interval $I_r$ with the minimal\ndistance to $\\tau_r$ is then used as an estimate for $\\tau_r$. No point\nof impact candidate in interval $I_r$ results in an ``unmatched'' $\\tau\n_r$, $r=1,\\ldots,S$ and a missing value when computing averages.\n\nThe table shows that estimates of points of impact are generally quite\naccurate even for smaller sample sizes. The error decreases rapidly as\n$n$ increases, and this improvement is essentially independent of $p$.\nAs expected, since $\\beta_2<\\beta_1$, the error of the absolute\ndistance between the second point of impact and its estimate is larger\nthan the error for the first point of impact.\n\nMoreover, due to the common effect of the trajectory $X_i(\\cdot)$ on\n$Y_i$, the overall estimation\nerror in the case where $\\beta(t)\\neq0$ is slightly higher than in the\nfirst case. At a first glance, one may be puzzled by the fact that for\n$n=5000$ and $p=1001$ the average error $|\\widehat{\\tau}_r-\\tau_r|$\nis considerably smaller than the distance $\\frac{1}{p-1}=\\frac\n{1}{1000}$ between two adjacent grid points. But note that our\nsimulation design implies that $\\tau_r\\in\\{t_j| j=1,\\ldots,p\\}$,\n$r=1,\\ldots,S$, for $p=1001$ as well as $p=20\\mbox{,}001$. For medium to large\nsample sizes, there is thus a fairly high probability that $\\widehat\n{\\tau}_r=\\tau_r$. The case $p=1001$ particularly profits from this situation.\nFinally, it can be seen that estimates for $\\widehat{\\kappa}$ tend to\nslightly underestimate the true value $\\kappa=1 $ for small values of $n$.\n\n\n\n\\section{Applications to real data}\\label{sec7}\n\nIn this section, the algorithm from Section~\\ref{SEC:4} is applied to a dataset\nconsisting of Canadian weather data. In this dataset, we relate the\nmean relative humidity to hourly temperature data.\nIn the Supplementary Appendix A [Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})], a further\napplication can be found. We there analyze spectral data which play an\nimportant role in spectrophotometry and different applied scientific fields.\n\nIn both examples, the algorithm is applied to centered observations and\nthe estimation procedure from Section~\\ref{SEC:4} is modified by eliminating all\npoints in an interval of size $\\delta|\\log\\delta|$ around a point of\nimpact candidate $\\widehat{\\tau}_j$, which is still sufficient to\nestablish assertion (\\ref{thmm3eq1}).\n\nAfter estimating $\\widetilde{S}$ possible candidates for the points of\nimpact, the approximate model {(\\ref{{augmentedmodel}})},\n\n", "index": 53, "text": "\n\\[\nY_i\\approx\\sum_{r=1}^k\n\\alpha_r \\langle X_i,\\widehat{\\psi}_r\n\\rangle +\\sum_{r=1}^{\\widetilde{S}}\\beta_r\nX_i(\\tilde\\tau_r)+\\varepsilon_i^*,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"Y_{i}\\approx\\sum_{r=1}^{k}\\alpha_{r}\\langle X_{i},\\widehat{\\psi}_{r}\\rangle+%&#10;\\sum_{r=1}^{\\widetilde{S}}\\beta_{r}X_{i}(\\tilde{\\tau}_{r})+\\varepsilon_{i}^{*},\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>\u2248</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>r</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">~</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><msubsup><mi>\u03b5</mi><mi>i</mi><mo>*</mo></msubsup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nwhile boundedness of $\\beta(\\cdot)$ and $\\beta^*(\\cdot)$ implies that\nthere exits a constant\n$0\\leq D<\\infty$ such that for all sufficiently small $\\epsilon>0$\n\n\\begin{eqnarray*}\n\\biggl|\\int_a^b\\bigl(\\beta(t)-\\beta^*(t)\\bigr)\nf_{\\epsilon,\\tau_j}(t)\\,dt\\biggr| &\\leq&\\epsilon\\int_{[a,b]\\setminus[\\tau_j-\\epsilon,\\tau_j+\\epsilon]} D\n\\bigl|f_{\\epsilon,\\tau_j}(\\tau_j)\\bigr|\\,dt \\\\\n&&{}+\\int_{\\tau_j-\\epsilon}^{\\tau_j+\\epsilon}\n(1+\\epsilon)D \\bigl|f_{\\epsilon\n,\\tau_j}(\\tau_j)\\bigr|\\,dt\n\\\\\n&\\leq&\\epsilon\\bigl(b-a+2(1+\\epsilon)\\bigr)D \\bigl|f_{\\epsilon,\\tau_j}(\n\\tau_j)\\bigr|.\n\\end{eqnarray*}\n\nWhen combining these inequalities, we can conclude that for all\nsufficiently small $\\epsilon$ we have $\\mathbb{E}(\\int_a^b(\\beta\n(t)-\\beta^*(t))X(t)\\,dt+\\sum_{r=1}^{S^*}(\\beta_r-\\beta_r^*)X(\\tau_r))^2>0$\nif $\\beta_j-\\beta_j^*\\neq0$. Since $j\\in\\{1,\\ldots,S^*\\}$ is\narbitrary, the assertion of the theorem is an immediate consequence.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmkarlov}} Choose some arbitrary $t\\in\n(a,b)$ and some $0<\\epsilon<1$ with $\\epsilon\\leq\\epsilon_t$. By\nassumption, there exists a $k\\in\\mathbb{N}$ as well as some $f\\in{{\\mathcal}\nC}(t,\\epsilon,[a,b])$ such that\n$|\\langle f,\\psi_r \\rangle|>0$ for some $r\\in\\{1,\\ldots,k\\}$ and $\\sup_{s\\in[a,b]}|f_k(s)-f(s)|\\leq\\epsilon/3$, where $f_k(s)=\\sum_{r=1}^k\n\\langle f,\\psi_r \\rangle\\psi_r(s)$. The definition of ${{\\mathcal}\nC}(t,\\epsilon,[a,b])$ then implies\nthat $f_k(t)\\geq1-\\epsilon/3$ as well as\n\n\n\\begin{eqnarray}\n\\label{karlovp1} \\sup_{s\\in[a,b]} \\bigl|f_k(s)\\bigr|&\\leq&1+\n\\frac{\\epsilon}{3}\\leq(1+\\epsilon) \\biggl(1-\\frac{\\epsilon}{3}\\biggr)\\leq (1+\n\\epsilon)f_k(t),\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n\\sup_{s\\in[a,b],s\\notin[t-\\epsilon,t+\\epsilon]} \\bigl|f_k(s)\\bigr|&\\leq&\\frac\n{\\epsilon}{3}\\leq\n\\epsilon\\biggl(1-\\frac{\\epsilon}{3}\\biggr)\\leq\\epsilon f_k(t).\n\\end{eqnarray}\n\nNow define the functional $\\zeta_{\\epsilon,t}$ by $\\zeta_{\\epsilon\n,t}(X):=\\sum_{r=1}^k \\frac{\\langle f,\\psi_r \\rangle}{\\lambda_r} \\langle\nX,\\psi_r \\rangle$. Recall that\nthe coefficients $\\langle X,\\psi_r \\rangle$ are uncorrelated and\n$\\operatorname{var}(\\langle X,\\psi_r \\rangle)=\\lambda_r$. By (\\ref{karlov}), we\nobtain\n\n\\begin{eqnarray*}\nf_{\\epsilon,t}(s)&:=&\\frac{\\mathbb{E}(X(s)\\zeta_{\\epsilon\n,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))} \\\\\n&=&\n\\frac{\\mathbb{E} ((\\sum_{j=1}^\\infty\\langle X,\\psi_j\n\\rangle\\psi_j(s))(\\sum_{r=1}^k ({\\langle f,\\psi_r \\rangle}/{\\lambda\n_r}) \\langle X,\\psi_r\\rangle) )}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}\n\\\\\n&=&\\frac{\\sum_{r=1}^k \\langle f,\\psi_r \\rangle\\psi_r(s)}{\\operatorname{var}(\\zeta\n_{\\epsilon,t}(X))} =\\frac{f_k(s)}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}.\n\\end{eqnarray*}\n\nFurthermore,\n$\\operatorname{var}(\\zeta_{\\epsilon,t}(X))=\\sum_{r=1}^k \\frac{\\langle f,\\psi_r \\rangle\n^2}{\\lambda_r}>0$, and it thus follows from\n(\\ref{karlovp1}) that the functional $\\zeta(t,X)$ satisfies conditions\n(i)--(iv) of Definition~\\ref{de1}.\nSince $t\\in(a,b)$ and $\\epsilon$ are arbitrary, $X$ thus possesses\nspecific local variation.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmcharX}} First note that Assumption~\\ref\n{assum1} implies that the absolute values of all\nfirst and second-order partial derivatives of $\\omega(t,s,z)$ are\nuniformly bounded\\vspace*{1pt}\nby some constant $M<\\infty$ for all $(t,s,z)$ in the compact subset\n$[a,b]^2\\times[0,b-a]$\nof $\\Omega$.\n\n\nBy definition of $Z_\\delta$, it thus follows from a Taylor expansion\nof $\\omega$ that\nfor $t\\in(a,b)$, any sufficiently small $\\delta>0$ and some constant\n$M_1<\\infty$\n\n\n\\begin{eqnarray}\n\\label{Zdelta1} \\mathbb{E}\\bigl(X(t)Z_{\\delta}(X,t)\\bigr)&=&\\sigma(t,t)-\n\\frac{1}{2}\\sigma (t,t-\\delta) -\\frac{1}{2}\\sigma(t,t+\\delta)\n\\nonumber\n\\\\\n&=& \\omega(t,t,0)-\\frac{1}{2}\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\n\\bigr) -\\frac{1}{2}\\omega\\bigl(t,t+\\delta,\\delta^\\kappa\\bigr)\n\\\\\n&=& \\delta^\\kappa c(t) +R_{1;\\delta,t} \\qquad\n\\mbox{with } \\sup\n_{t\\in[a+\\delta,b-\\delta]} |R_{1;\\delta,t}|\\leq M_1\n\\delta^{\\min\\{2\\kappa,2\\}}.\\nonumber\n\\end{eqnarray}\n\nFor the variance of $Z_{\\delta}(X,t)$, we obtain by similar arguments\n\n\n\\begin{eqnarray}\n\\label{Zdelta2} \\operatorname{var}\\bigl(Z_{\\delta}(X,t)\\bigr)&=& 2\n\\omega(t,t,0)-\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\\bigr)-\\omega\\bigl(t,t+\n\\delta,\\delta ^\\kappa\\bigr)\\nonumber\\\\\n&&{} - \\frac{1}{2} \\bigl(\\omega(t,t,0)-\\omega\n\\bigl(t+\\delta,t-\\delta,(2\\delta )^\\kappa\\bigr) \\bigr)\n\\nonumber\n\\\\\n&&{} - \\frac{1}{4} \\bigl(2\\omega(t,t,0)-\\omega(t-\\delta,t-\\delta,0) -\n\\omega(t+\\delta,t+\\delta,0) \\bigr)\n\\\\\n&=&\\delta^\\kappa \\biggl(2c(t)-\\frac{2^\\kappa}{2}c(t) \\biggr)\n+R_{2;\\delta,t}\\nonumber\\\\\n\\eqntext{ \\mbox{with } \\sup_{t\\in[a+\\delta,b-\\delta]}\n|R_{2;\\delta\n,t}|<M_2\\delta^{\\min\\{2\\kappa,2\\}}}\n\\end{eqnarray}\n\nfor some constant $M_2<\\infty$.\nMoreover, for any $0<c<\\infty$ Taylor expansions of $\\omega$ yield that\nfor any sufficiently small $\\delta>0$ and all $u\\in[-c,c]$\n\n\n\n\\begin{eqnarray}\n&&\\mathbb{E} \\bigl(X(t+u\\delta)Z_{\\delta}(X,t)\\bigr)\\nonumber\\\\\n&&\\qquad=\\sigma(t+u\\delta,t)-\n\\tfrac\n{1}{2}\\sigma(t+u\\delta,t-\\delta) -\\tfrac{1}{2}\\sigma(t+u\\delta,t+\n\\delta)\n\\nonumber\n\\\\\n&&\\qquad= \\omega(t,t,0) -\\tfrac{1}{2}\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\n\\bigr) -\\tfrac{1}{2}\\omega\\bigl(t,t+\\delta,\\delta^\\kappa\\bigr)\n\\nonumber\n\\\\\n&&\\qquad\\quad{} -c(t)\\delta^\\kappa \\bigl(|u|^\\kappa -\\tfrac{1}{2}\n\\bigl(|u+1|^\\kappa-1\\bigr)-\\tfrac{1}{2}\\bigl(|u-1|^\\kappa-1\n\\bigr) \\bigr) + R_{3;c,u,\\delta,t} \\label{Zdelta3}\n\\\\\n&&\\qquad= -c(t)\\delta^\\kappa \\bigl(|u|^\\kappa -\\tfrac{1}{2}|u+1|^\\kappa-\n\\tfrac{1}{2}|u-1|^\\kappa \\bigr) + R_{4;c,u,\\delta,t}, \\label{Zdelta4}\n\\end{eqnarray}\n\nwhere for some constants $M_{3,c}<\\infty$ and $M_{4,c}<\\infty$\n\n\\begin{eqnarray*}\n\\sup_{t\\in[a+\\delta,b-\\delta]} R_{3;c,u,\\delta,t}&\\leq& M_{3,c}\n\\bigl(|u|^{1/2}\\delta\\bigr)^{\\min\\{2\\kappa,2\\}},\\\\\n \\sup_{t\\in[a+\\delta,b-\\delta]}\nR_{4;c,u,\\delta,t}&\\leq& M_{4,c}\\delta ^{\\min\\{2\\kappa,2\\}}\n\\end{eqnarray*}\n\nhold for all $u\\in[-c,c]$.\nFinally, Assumption~\\ref{assum1} implies that there exists a constant\n$M_5<\\infty$ such that\nfor all $s\\in[a,b]$ with $|t-s|\\geq\\delta$\\vspace*{-2pt}\n\n\n\n\\begin{eqnarray}\n\\label{Zdelta5}&& \\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|\\nonumber\\[-1pt]\n&&\\qquad= \\bigl| \\omega\n\\bigl(s,t,|s-t|^\\kappa\\bigr) -\\tfrac{1}{2}\\omega\\bigl(s,t-\n\\delta,|s-t+\\delta|^\\kappa\\bigr)\\nonumber\n\\[-8pt]\n\\[-8pt]\n&&\\qquad\\quad{} -\\tfrac{1}{2}\\omega\\bigl(s,t+\n\\delta,|s-t-\\delta|^\\kappa\\bigr)\\bigr|\\nonumber\n\\[-1pt]\n&&\\qquad\\leq \n\\cases{ \\displaystyle M_5 \\frac{\\delta^2}{|t-s|^{2-\\kappa}}, &\\quad $ \\mbox{if }\n\\kappa\\neq1,$\\vspace*{2pt}\n\\cr\nM_5 \\delta^2, &\\quad $\\mbox{if }\n\\kappa= 1$.}\\nonumber \n\\end{eqnarray}\n\n\nIt follows from (\\ref{Zdelta1}), (\\ref{Zdelta4}) and (\\ref{Zdelta5})\nthat for arbitrary $t\\in(a,b)$ and any $\\epsilon>0$ there exist a\n$\\delta_\\epsilon>0$ as well as a constant\n$a_\\epsilon\\geq1$ such that for all $\\delta\\leq\\delta_\\epsilon$\\vspace*{-2pt}\n\n\\begin{eqnarray*}\n\\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|&\\leq&(1+\\epsilon)\\mathbb{E}\n\\bigl(X(t)Z_{\\delta}(X,t)\\bigr)\\qquad \\mbox{for all } s\\in[a,b], s\\neq t,\n\\\\\n\\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|& \\leq&\\epsilon\\cdot\\mathbb{E}\n\\bigl(X(t)Z_{\\delta}(X,t)\\bigr) \\qquad\\mbox{for all } s\\in[a,b], |s-t|\\geq\na_\\epsilon \\delta.\n\\end{eqnarray*}\n\nTogether with (\\ref{Zdelta2}), the assertion of the theorem is an\nimmediate consequence.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{parestGEN}}\nLet $\\hat\\theta_{ij}:=\\langle X_i,\\widehat{\\psi}_j\\rangle$, $ \\theta\n_{ij}:=\\langle X_i,\\psi_j\\rangle$, and\n$\\tilde\\alpha_j:= \\langle\\beta,\\widehat{\\psi}_j\\rangle$ for all $i,j$.\nUsing empirical eigenfunctions, we obtain $X_i=\\sum_{j=1}^n \\hat\\theta\n_{ij}\\widehat{\\psi}_j$ and $\\int_a^b \\beta(t)X_i(t)\\,dt =\\sum_{j=1}^n\n\\tilde\\alpha_j\\hat\\theta_{ij}$. Therefore,\\vspace*{-2pt}\n\n\n\n", "itemtype": "equation", "pos": 73148, "prevtext": "\n\nis used, where initially $k=6$ is chosen.\nOver a fine grid of different values of~$\\delta$, points of impact and\nprincipal components are selected simultaneously by best subset\nselection with the BIC-criterion and the model corresponding to the\nminimal BIC is then chosen. The maximum number of variables selected by\nthe BIC-criterion is set to $6$ and all curves have been transformed to\nbe observed over $[0,1]$ when applying the algorithm from Section~\\ref{SEC:4}.\nThe performance of the model is then measured by means of a\ncross-validated prediction error.\n\n\n\n\nIn the Canadian weather dataset, the hourly mean temperature and\nrelative humidity from the $15$ closest weather stations in an area\naround $100$ km from Montreal was obtained for each of the $31$ days in\nDecember $2013$. The data was compiled from \\url{http://climate.weather.gc.ca}.\nWeather stations with more than ten missing observations on the\ntemperature or relative humidity were discarded from the dataset. The\nremaining stations had their nonavailable observations replaced by the\nmean of their closest observed predecessor and successor. After\npreprocessing a total of $n=13$ weather stations remained and for each\nstation $p=744$ equidistant hourly observations of the temperature were\nobserved.\nThe response variable $Y_i$ was taken to be the mean over all observed\nvalues of the relatively humidity at station $i$.\n\nA cross-validated prediction error was calculated for three competing\nregression models based on {(\\ref{{augmentedmodel}})}.\nIn the first model, the mean relative humidity for each station was\nexplained by using the approximate model which combines the points of\nimpacts with a functional part.\nThe second and third model describe the cases $k = 0$ and $\\widetilde\n{S}=0$ in the approximate model, consisting only of points of impact\nand the functional part, respectively.\nFor the first two models, points of impact were determined by\nconsidering a total of $146$ equidistant values of $\\delta$ between\n$0.10$ and $0.49$. In all models BIC was used to approximate the\noptimal values of the respective tuning parameters $\\delta$, $S$ and/or\n$k$ in a first step. The mean squared prediction error $\\mathit{MSPE}=\\frac\n{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$ was then calculated by means of\na leave one out cross-validation based on the chosen points of impact\nand/or principal components from the first step. Additionally, the\nmedian of $(y_i - \\hat{y}_i)^2$, $i=1,\\ldots,n$, has been calculated as\na more robust measure of the error.\n Depicted in the upper panel of Figure~\\ref{fig:Weather2} is\nthe observed temperature trajectory for the weather station\n``McTavish,'' showing a rather rough process.\nThe lower panel of this figure shows $|\\frac{1}{n}\\sum_{i=1}^n Z_{\\delta,i}(t_j)Y_i|$ for the optimal value of $\\delta=\n0.18$ as obtained by the best model fit of the approximate model. While\norange lines represent the locations of the points of impact which were\nactually selected with the help of the BIC-criterion, the location of\nthe remaining candidates are indicated by black vertical lines.\n\n\n\\begin{figure}\n\n\\includegraphics{1323f03.eps}\n\n\\caption{The upper panel of this figure shows a\ntrajectory from the observed temperature curves of the Canadian weather\ndata. The lower panel shows {$|\\frac{1}{n}\\sum_{i=1}^n\nZ_{\\delta,i}(t_j)Y_i|$} during the selection procedure. Locations of\nselected points of impact in the augmented model are indicated by\norange lines. The location of the remaining candidate is displayed by a\nblack line.}\n\\label{fig:Weather2}\n\\end{figure}\n\n\n\\begin{table}[b]\n\\caption{Estimated number of principal components $k$, points of impact\n$S$,\nprediction error and the median of $(y_i-\\hat{y}_i)^2$ for the\nCanadian weather data}\n\\label{app.tab:weather}\n\n\\begin{tabular*}{\\textwidth}{@{\\extracolsep{\\fill}}lcccc@{}}\n\\hline\n\\textbf{Model} & $\\bolds{\\widehat{k}}$ & $\\bolds{\\widehat{S}}$ & $\\mathbf{MSPE}$ & $\\bolds{\\operatorname{median}((y-\\hat{y})^2)}$\\\\\n\\hline\nAugmented & 3 & 3 & 2.314& 0.251\\\\% (12.86) \\\\\nPoints of impact & 0 & 3 & 1.714& 0.974\\\\ \nFLR & 6 & 0 & 5.346& 1.269\\\\ \n\\hline\n\\end{tabular*}\n\n\\end{table}\n\n\nTable~\\ref{app.tab:weather} provides the empirical results when fitting\nthe three competing models. In terms of the prediction error, it can\nclearly be seen from the table that the frequently applied functional\nlinear regression model is outperformed by the model consisting solely\nof points of impact as well as the augmented (approximate) model. This\nimpression is supported by the last column of the table which gives the\nmedian value of $(y_i - \\hat{y}_i)^2$, showing additionally that,\ntypically, the augmented model performs even better than the plain\npoints of impact model.\n\nAn estimate $\\widehat{\\kappa}=0.14$ for $\\kappa$ was obtained for\n$\\delta\\approx0.3$, that is, the midpoint of the chosen values of\n$\\delta$. The estimated value of $\\kappa=0.14$ corresponds to rather\nrough sample paths as shown in the upper plot of Figure~\\ref{fig:Weather2}.\n\nIn view of the small sample size results have to be interpreted with\ncare, and we therefore do not claim that this application provides\nimportant substantial insights. Its main purpose is to serve as\nillustration for classes of problems where our approach may be of\npotential importance. It clearly shows that some relevant processes\nobserved in practice are nonsmooth.\nWith contemporary technical tools temperatures can be measured very\naccurately, leading to a negligible measurement error. But\ntemperatures, especially in Canada, can vary rapidly over time. The\nrough sample paths thus must be interpreted as an intrinsic feature of\ntemperature processes and cannot be explained by any type of ``error.''\n\n\\begin{appendix}\n\n\n\\section*{Appendix: Proofs of theorems}\\label{app}\n\nThis appendix provides the\nproofs of some of the main results. Remaining proofs can be\nfound in the supplementary material. Some of them rely on results from\n\\citeauthor{vandeGeerLederer2012} (\\citeyear{vandeGeerLederer2012}),\n\\citeauthor{vanderVaartWellner2000} (\\citeyear{vanderVaartWellner2000}) as well as\n\\citeauthor{ZhouLaffertyWassermann2008} (\\citeyear{ZhouLaffertyWassermann2008}).\n\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmident}} Set $\\beta_r:=0$ for\n$r=S+1,\\ldots,S^*$, and consider an arbitrary $j\\in\\{1,\\ldots,S^*\\}$.\nChoose $0<\\epsilon<\\min_{r,s\\in\\{1,\\ldots,S^*\\},r\\neq s} |\\tau_r-\\tau\n_s|$ small enough such that conditions\n(i)--(iv) of Definition~\\ref{de1} are satisfied. Using (\\ref{decompeps}), we\nobtain a decomposition into two\nuncorrelated components $X_{\\epsilon,\\tau_j}(\\cdot)$ and $\\zeta\n_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\\cdot)$:\n\n\\begin{eqnarray*}\n&&\\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)X(t)\\,dt+\\sum_{r=1}^{S^*}\n\\bigl(\\beta_r-\\beta_r^*\\bigr)X(\\tau_r)\n\\Biggr)^2 \\Biggr)\n\\\\\n&&\\qquad= \\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)X_{\\epsilon,\\tau_j}(t)\\,dt+ \\sum\n_{r=1}^{S^*}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)X_{\\epsilon,\\tau_j}(\\tau_r)\n\\Biggr)^2 \\Biggr)\n\\\\\n&&\\quad\\qquad{} +\\mathbb{E} \\Biggl( \\Biggl(\\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr)\\zeta _{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(t)\\,dt\n\\\\\n&&\\qquad\\quad{}+ \\sum\n_{r=1}^{S^*}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)\\zeta_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\n\\tau_r) \\Biggr)^2 \\Biggr)\n\\\\\n&&\\qquad\\geq \\mathbb{E} \\biggl( \\biggl(\\int_a^b\n\\bigl(\\beta(t)-\\beta^*(t)\\bigr)\\zeta _{\\epsilon,\\tau_j}(X)\n f_{\\epsilon,\\tau_j}(t)\\,dt\\\\\n &&\\qquad\\quad{}+\n\\sum_{r\\neq j}\\bigl(\\beta_r-\n\\beta_r^*\\bigr)\\zeta_{\\epsilon,\\tau_j}(X)f_{\\epsilon\n,\\tau_j}(\n\\tau_r) + \\bigl(\\beta_j-\\beta_j^*\\bigr)\n\\zeta_{\\epsilon,\\tau_j}(X) f_{\\epsilon,\\tau_j}(\\tau_j)\n\\biggr)^2 \\biggr)\n\\\\\n&&\\qquad\\geq 2 \\operatorname{var}\\bigl(\\zeta_{\\epsilon,\\tau_j}(X)\\bigr) \\bigl(\n\\beta_j-\\beta_j^*\\bigr) f_{\\epsilon,\\tau_j}(\n\\tau_j)\\\\\n&&\\qquad\\quad{}\\times \\biggl( \\int_a^b\\bigl(\n\\beta(t)-\\beta^*(t)\\bigr) f_{\\epsilon,\\tau_j}(t)\\,dt+\\sum\n_{r\\neq\nj}\\bigl(\\beta_r-\\beta_r^*\\bigr)\nf_{\\epsilon,\\tau_j}(\\tau_r) \\biggr)\n\\\\\n&&\\qquad\\quad{} + \\operatorname{var}\\bigl(\\zeta_{\\epsilon,\\tau_j}(X)\\bigr) \\bigl(\n\\beta_j-\\beta _j^*\\bigr)^2f_{\\epsilon,\\tau_j}(\n\\tau_j)^2.\n\\end{eqnarray*}\n\n\n\nBy condition (iv), we have\n\n", "index": 55, "text": "\n\\[\n\\biggl|\\sum_{r\\neq j}\\bigl(\\beta_r-\n\\beta_r^*\\bigr) f_{\\epsilon,\\tau_j}(\\tau_r)\\biggr| \\leq \\epsilon\nS^* \\max_{r\\neq j}\\bigl|\\beta_r-\\beta_r^*\\bigr|\n\\bigl|f_{\\epsilon,\\tau\n_j}(\\tau_j)\\bigr|,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\biggl{|}\\sum_{r\\neq j}\\bigl{(}\\beta_{r}-\\beta_{r}^{*}\\bigr{)}f_{\\epsilon,\\tau%&#10;_{j}}(\\tau_{r})\\biggr{|}\\leq\\epsilon S^{*}\\max_{r\\neq j}\\bigl{|}\\beta_{r}-%&#10;\\beta_{r}^{*}\\bigr{|}\\bigl{|}f_{\\epsilon,\\tau_{j}}(\\tau_{j})\\bigr{|},\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\" maxsize=\"210%\" minsize=\"210%\">|</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>\u2260</mo><mi>j</mi></mrow></munder><mrow><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>-</mo><msubsup><mi>\u03b2</mi><mi>r</mi><mo>*</mo></msubsup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mrow><mi>\u03f5</mi><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"210%\" minsize=\"210%\">|</mo></mrow><mo>\u2264</mo><mrow><mi>\u03f5</mi><mo>\u2062</mo><msup><mi>S</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><munder><mi>max</mi><mrow><mi>r</mi><mo>\u2260</mo><mi>j</mi></mrow></munder><mo>\u2061</mo><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>-</mo><msubsup><mi>\u03b2</mi><mi>r</mi><mo>*</mo></msubsup></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow></mrow><mo>\u2062</mo><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msub><mi>f</mi><mrow><mi>\u03f5</mi><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nand for all possible values $b_1,\\ldots,b_S$ and all $a_1,\\ldots,a_k$\\vspace*{-2pt}\n\n\n\\begin{eqnarray}\\label{parGEN-eq2}\n&&\\sum_{j=1}^k a_j \\hat\n\\theta_{ij}+\\sum_{r=1}^S\nb_r X_i(\\widehat{\\tau}_r)\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad = \\sum\n_{j=1}^k \\Biggl( a_j +\\sum\n_{r=1}^S b_r \\widehat{\n\\psi}_j(\\widehat {\\tau}_r) \\Biggr) \\hat\n\\theta_{ij}+\\sum_{j=k+1}^n \\sum\n_{r=1}^Sb_r \\widehat{\n\\psi}_j(\\widehat{\\tau}_r)\\hat\\theta_{ij}\n\\end{eqnarray}\n\nfor all $i=1,\\ldots,n$. By definition, $\\hat\\lambda_j=\\frac{1}{n}\\sum_{i=1}^n \\hat\\theta_{ij}^2$, $j=1,\\ldots,n$, and for $j\\ne l$ the\ncoefficients $\\hat\\theta_{ij}$\nand $\\hat\\theta_{il}$ are empirically uncorrelated, that is, $\\sum_{i=1}^n \\hat\\theta_{ij}\\hat\\theta_{il}=0$. It follows that for any\ngiven values\n$b_1,\\ldots,b_S$ the values $\\hat\\alpha(\\mathbf{b})_j$, $j=1,\\ldots\n,k$, minimizing\n$\\sum_{i=1}^n  (\nY_i-\\sum_{j=1}^k a_j \\hat\\theta_{ij} - \\sum_{r=1}^{S}b_r X_i(\\widehat\n\\tau_r) )^2$ over all $a_1,\\ldots,a_k$ are given by\n\n\n\\begin{eqnarray}\\label{parGEN-eq3}\n\\hat\\alpha(\\mathbf{b})_j=\\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i+ \\sum_{r=1}^S\n\\bigl(\\beta_r \\widehat{\\psi}_j(\\tau_r)-b_r\n\\widehat{\\psi }_j(\\widehat{\\tau}_r)\\bigr),\n\\nonumber\n\\[-10pt]\n\\[-10pt]\n\\eqntext{j=1,\n\\ldots,k. }\n\\end{eqnarray}\n\nNote that $\\tilde\\alpha_j+\\hat\\lambda_j^{-1}\n\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}\\varepsilon_i$ is identical to\nthe estimate\nof $\\alpha_j$ to be obtained in a standard functional\\vadjust{\\goodbreak} linear regression\nmodel with no points of impact.\nTheorem~1 of \\citet{HallHorowitz2007} thus implies that\n\n\n\\begin{eqnarray}\\label{parGEN-eq4}\n&&\\int_a^b \\Biggl(\\beta(t)-\\sum\n_{j=1}^k\\Biggl( \\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i\\Biggr)\\widehat{\\psi }_j(t)\\,dt\n\\Biggr)^2\\,dt\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad  =O_p\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray}\n\nFurther analysis requires to analyze the differences between $\\theta\n_{ij}, \\psi_j$ and\ntheir empirical counterparts\n$\\hat\\theta_{ij}, \\widehat{\\psi}_j$.\nBy Assumptions \\ref{assum2}--\\ref{assum4} and\n$k=O(n^{1/(\\mu+2\\nu)})$,\nTheorems 1 and 2 together with equation (2.8) of \\citet{HallHosseini2006} imply that\nfor any $q=1,2,3,\\ldots$ there exists some $A_q,B_q<\\infty$ such that\n\n\n\\begin{eqnarray}\\label{parGEN-eq5}\nE \\bigl(|\\lambda_j-\\hat\\lambda_j|^q\n\\bigr)&\\leq& A_qn^{-q/2},\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n \\sup_t E\n\\bigl(\\bigl|\\widehat{\\psi}_j(t)-\\psi_j(t)\\bigr| \\bigr)&\\leq&\nB_qn^{-q/2}j^{q(\\mu\n+1)},\\qquad  j=1,\\ldots,k+1 \\vspace*{-2pt}\n\\end{eqnarray}\n\nfor all sufficiently large $n$. Let $X_i^{[k]}:= X_i-\\sum_{j=1}^k \\hat\n\\theta_{ij}\\widehat{\\psi}_j$.\nRecall that\\break $\\lambda_j=O(j^{-\\mu})$ and note that by Assumptions \\ref\n{assum3} and \\ref{assum4}, $n^{-1/2}n^{2/(\\mu+2\\nu)}=\\break o(n^{(-\\mu+1)/(\\mu\n+2\\nu)})$, while $ n^{(-\\mu+1)/(\\mu+2\\nu)}=O(\\sigma^{[k]}(\\tau_r,\\tau_r))$.\nBy (\\ref{parGEN-eq5}), we thus obtain for all $t,s\\in[a,b]$\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq6} &&\\frac{1}{n} \\sum_{i=1}^n\nX_i^{[k]}(t)X_i^{[k]}(s)\\nonumber\\[-1pt]\n&&\\qquad=\n\\frac{1}{n} \\sum_{i=1}^n\nX_i(t)X_i(s) -\\sum_{j=1}^k\n\\hat\\lambda_j \\widehat{\\psi}_j(t)\\widehat{\n\\psi}_j(s)\n\\nonumber\n\\[-1pt]\n&&\\qquad=\\sigma(t,s)-\\sum_{j=1}^k\n\\lambda_j \\psi_j(t)\\psi_j(s) +\\sum\n_{j=1}^k \\lambda_j\\bigl(\n\\psi_j(t)\\psi_j(s)-\\widehat {\\psi}_j(t)\n\\widehat{\\psi}_j(s)\\bigr)\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad\\quad{} +\\sum_{j=1}^k (\\lambda_j-\n\\hat\\lambda_j)\\widehat{\\psi }_j(t)\\widehat{\n\\psi}_j(s) +O_P\\bigl(n^{-1/2}\\bigr)\n\\nonumber\n\\[-1pt]\n&&\\qquad=\\sigma^{[k]}(t,s) +O_P\\bigl(n^{-1/2}n^{2/(\\mu+2\\nu)}\n\\bigr)\\nonumber\\[-1pt]\n&&\\qquad=\\sigma^{[k]}(t,s) +o_P\\bigl(n^{(-\\mu+1)/(\\mu+2\\nu)}\\bigr).\\nonumber\n\\end{eqnarray}\n\nAt the same time, (\\ref{lem4eq1}) leads to\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq7}&& \\frac{1}{n} \\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\tau_r)-X_i^{[k]}(\n\\widehat{\\tau }_r)\\bigr)^2\\nonumber\\\\\n&&\\qquad= \\frac{1}{n} \\sum\n_{i=1}^n \\bigl(X_i(\n\\tau_r)-X_i(\\widehat{\\tau }_r)\n\\bigr)^2 -\\sum_{j=1}^k \\hat\n\\lambda_j \\bigl(\\widehat{\\psi}_j(\\tau_r)-\n\\widehat{\\psi}_j(\\widehat{\\tau}_r)\\bigr)^2\n\\\\\n&&\\qquad\\leq \\frac{1}{n} \\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\\tau\n}_r)\\bigr)^2=O_P\\bigl(n^{-1}\n\\bigr)\\nonumber\n\\end{eqnarray}\n\nfor all $r=1,\\ldots,S$. Expressions (\\ref{parGEN-eq6}) and (\\ref\n{parGEN-eq7}) together imply that for\nall $r,s$\n\n\n\n", "itemtype": "equation", "pos": 81104, "prevtext": "\n\nwhile boundedness of $\\beta(\\cdot)$ and $\\beta^*(\\cdot)$ implies that\nthere exits a constant\n$0\\leq D<\\infty$ such that for all sufficiently small $\\epsilon>0$\n\n\\begin{eqnarray*}\n\\biggl|\\int_a^b\\bigl(\\beta(t)-\\beta^*(t)\\bigr)\nf_{\\epsilon,\\tau_j}(t)\\,dt\\biggr| &\\leq&\\epsilon\\int_{[a,b]\\setminus[\\tau_j-\\epsilon,\\tau_j+\\epsilon]} D\n\\bigl|f_{\\epsilon,\\tau_j}(\\tau_j)\\bigr|\\,dt \\\\\n&&{}+\\int_{\\tau_j-\\epsilon}^{\\tau_j+\\epsilon}\n(1+\\epsilon)D \\bigl|f_{\\epsilon\n,\\tau_j}(\\tau_j)\\bigr|\\,dt\n\\\\\n&\\leq&\\epsilon\\bigl(b-a+2(1+\\epsilon)\\bigr)D \\bigl|f_{\\epsilon,\\tau_j}(\n\\tau_j)\\bigr|.\n\\end{eqnarray*}\n\nWhen combining these inequalities, we can conclude that for all\nsufficiently small $\\epsilon$ we have $\\mathbb{E}(\\int_a^b(\\beta\n(t)-\\beta^*(t))X(t)\\,dt+\\sum_{r=1}^{S^*}(\\beta_r-\\beta_r^*)X(\\tau_r))^2>0$\nif $\\beta_j-\\beta_j^*\\neq0$. Since $j\\in\\{1,\\ldots,S^*\\}$ is\narbitrary, the assertion of the theorem is an immediate consequence.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmkarlov}} Choose some arbitrary $t\\in\n(a,b)$ and some $0<\\epsilon<1$ with $\\epsilon\\leq\\epsilon_t$. By\nassumption, there exists a $k\\in\\mathbb{N}$ as well as some $f\\in{{\\mathcal}\nC}(t,\\epsilon,[a,b])$ such that\n$|\\langle f,\\psi_r \\rangle|>0$ for some $r\\in\\{1,\\ldots,k\\}$ and $\\sup_{s\\in[a,b]}|f_k(s)-f(s)|\\leq\\epsilon/3$, where $f_k(s)=\\sum_{r=1}^k\n\\langle f,\\psi_r \\rangle\\psi_r(s)$. The definition of ${{\\mathcal}\nC}(t,\\epsilon,[a,b])$ then implies\nthat $f_k(t)\\geq1-\\epsilon/3$ as well as\n\n\n\\begin{eqnarray}\n\\label{karlovp1} \\sup_{s\\in[a,b]} \\bigl|f_k(s)\\bigr|&\\leq&1+\n\\frac{\\epsilon}{3}\\leq(1+\\epsilon) \\biggl(1-\\frac{\\epsilon}{3}\\biggr)\\leq (1+\n\\epsilon)f_k(t),\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n\\sup_{s\\in[a,b],s\\notin[t-\\epsilon,t+\\epsilon]} \\bigl|f_k(s)\\bigr|&\\leq&\\frac\n{\\epsilon}{3}\\leq\n\\epsilon\\biggl(1-\\frac{\\epsilon}{3}\\biggr)\\leq\\epsilon f_k(t).\n\\end{eqnarray}\n\nNow define the functional $\\zeta_{\\epsilon,t}$ by $\\zeta_{\\epsilon\n,t}(X):=\\sum_{r=1}^k \\frac{\\langle f,\\psi_r \\rangle}{\\lambda_r} \\langle\nX,\\psi_r \\rangle$. Recall that\nthe coefficients $\\langle X,\\psi_r \\rangle$ are uncorrelated and\n$\\operatorname{var}(\\langle X,\\psi_r \\rangle)=\\lambda_r$. By (\\ref{karlov}), we\nobtain\n\n\\begin{eqnarray*}\nf_{\\epsilon,t}(s)&:=&\\frac{\\mathbb{E}(X(s)\\zeta_{\\epsilon\n,t}(X))}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))} \\\\\n&=&\n\\frac{\\mathbb{E} ((\\sum_{j=1}^\\infty\\langle X,\\psi_j\n\\rangle\\psi_j(s))(\\sum_{r=1}^k ({\\langle f,\\psi_r \\rangle}/{\\lambda\n_r}) \\langle X,\\psi_r\\rangle) )}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}\n\\\\\n&=&\\frac{\\sum_{r=1}^k \\langle f,\\psi_r \\rangle\\psi_r(s)}{\\operatorname{var}(\\zeta\n_{\\epsilon,t}(X))} =\\frac{f_k(s)}{\\operatorname{var}(\\zeta_{\\epsilon,t}(X))}.\n\\end{eqnarray*}\n\nFurthermore,\n$\\operatorname{var}(\\zeta_{\\epsilon,t}(X))=\\sum_{r=1}^k \\frac{\\langle f,\\psi_r \\rangle\n^2}{\\lambda_r}>0$, and it thus follows from\n(\\ref{karlovp1}) that the functional $\\zeta(t,X)$ satisfies conditions\n(i)--(iv) of Definition~\\ref{de1}.\nSince $t\\in(a,b)$ and $\\epsilon$ are arbitrary, $X$ thus possesses\nspecific local variation.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{thmcharX}} First note that Assumption~\\ref\n{assum1} implies that the absolute values of all\nfirst and second-order partial derivatives of $\\omega(t,s,z)$ are\nuniformly bounded\\vspace*{1pt}\nby some constant $M<\\infty$ for all $(t,s,z)$ in the compact subset\n$[a,b]^2\\times[0,b-a]$\nof $\\Omega$.\n\n\nBy definition of $Z_\\delta$, it thus follows from a Taylor expansion\nof $\\omega$ that\nfor $t\\in(a,b)$, any sufficiently small $\\delta>0$ and some constant\n$M_1<\\infty$\n\n\n\\begin{eqnarray}\n\\label{Zdelta1} \\mathbb{E}\\bigl(X(t)Z_{\\delta}(X,t)\\bigr)&=&\\sigma(t,t)-\n\\frac{1}{2}\\sigma (t,t-\\delta) -\\frac{1}{2}\\sigma(t,t+\\delta)\n\\nonumber\n\\\\\n&=& \\omega(t,t,0)-\\frac{1}{2}\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\n\\bigr) -\\frac{1}{2}\\omega\\bigl(t,t+\\delta,\\delta^\\kappa\\bigr)\n\\\\\n&=& \\delta^\\kappa c(t) +R_{1;\\delta,t} \\qquad\n\\mbox{with } \\sup\n_{t\\in[a+\\delta,b-\\delta]} |R_{1;\\delta,t}|\\leq M_1\n\\delta^{\\min\\{2\\kappa,2\\}}.\\nonumber\n\\end{eqnarray}\n\nFor the variance of $Z_{\\delta}(X,t)$, we obtain by similar arguments\n\n\n\\begin{eqnarray}\n\\label{Zdelta2} \\operatorname{var}\\bigl(Z_{\\delta}(X,t)\\bigr)&=& 2\n\\omega(t,t,0)-\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\\bigr)-\\omega\\bigl(t,t+\n\\delta,\\delta ^\\kappa\\bigr)\\nonumber\\\\\n&&{} - \\frac{1}{2} \\bigl(\\omega(t,t,0)-\\omega\n\\bigl(t+\\delta,t-\\delta,(2\\delta )^\\kappa\\bigr) \\bigr)\n\\nonumber\n\\\\\n&&{} - \\frac{1}{4} \\bigl(2\\omega(t,t,0)-\\omega(t-\\delta,t-\\delta,0) -\n\\omega(t+\\delta,t+\\delta,0) \\bigr)\n\\\\\n&=&\\delta^\\kappa \\biggl(2c(t)-\\frac{2^\\kappa}{2}c(t) \\biggr)\n+R_{2;\\delta,t}\\nonumber\\\\\n\\eqntext{ \\mbox{with } \\sup_{t\\in[a+\\delta,b-\\delta]}\n|R_{2;\\delta\n,t}|<M_2\\delta^{\\min\\{2\\kappa,2\\}}}\n\\end{eqnarray}\n\nfor some constant $M_2<\\infty$.\nMoreover, for any $0<c<\\infty$ Taylor expansions of $\\omega$ yield that\nfor any sufficiently small $\\delta>0$ and all $u\\in[-c,c]$\n\n\n\n\\begin{eqnarray}\n&&\\mathbb{E} \\bigl(X(t+u\\delta)Z_{\\delta}(X,t)\\bigr)\\nonumber\\\\\n&&\\qquad=\\sigma(t+u\\delta,t)-\n\\tfrac\n{1}{2}\\sigma(t+u\\delta,t-\\delta) -\\tfrac{1}{2}\\sigma(t+u\\delta,t+\n\\delta)\n\\nonumber\n\\\\\n&&\\qquad= \\omega(t,t,0) -\\tfrac{1}{2}\\omega\\bigl(t,t-\\delta,\\delta^\\kappa\n\\bigr) -\\tfrac{1}{2}\\omega\\bigl(t,t+\\delta,\\delta^\\kappa\\bigr)\n\\nonumber\n\\\\\n&&\\qquad\\quad{} -c(t)\\delta^\\kappa \\bigl(|u|^\\kappa -\\tfrac{1}{2}\n\\bigl(|u+1|^\\kappa-1\\bigr)-\\tfrac{1}{2}\\bigl(|u-1|^\\kappa-1\n\\bigr) \\bigr) + R_{3;c,u,\\delta,t} \\label{Zdelta3}\n\\\\\n&&\\qquad= -c(t)\\delta^\\kappa \\bigl(|u|^\\kappa -\\tfrac{1}{2}|u+1|^\\kappa-\n\\tfrac{1}{2}|u-1|^\\kappa \\bigr) + R_{4;c,u,\\delta,t}, \\label{Zdelta4}\n\\end{eqnarray}\n\nwhere for some constants $M_{3,c}<\\infty$ and $M_{4,c}<\\infty$\n\n\\begin{eqnarray*}\n\\sup_{t\\in[a+\\delta,b-\\delta]} R_{3;c,u,\\delta,t}&\\leq& M_{3,c}\n\\bigl(|u|^{1/2}\\delta\\bigr)^{\\min\\{2\\kappa,2\\}},\\\\\n \\sup_{t\\in[a+\\delta,b-\\delta]}\nR_{4;c,u,\\delta,t}&\\leq& M_{4,c}\\delta ^{\\min\\{2\\kappa,2\\}}\n\\end{eqnarray*}\n\nhold for all $u\\in[-c,c]$.\nFinally, Assumption~\\ref{assum1} implies that there exists a constant\n$M_5<\\infty$ such that\nfor all $s\\in[a,b]$ with $|t-s|\\geq\\delta$\\vspace*{-2pt}\n\n\n\n\\begin{eqnarray}\n\\label{Zdelta5}&& \\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|\\nonumber\\[-1pt]\n&&\\qquad= \\bigl| \\omega\n\\bigl(s,t,|s-t|^\\kappa\\bigr) -\\tfrac{1}{2}\\omega\\bigl(s,t-\n\\delta,|s-t+\\delta|^\\kappa\\bigr)\\nonumber\n\\[-8pt]\n\\[-8pt]\n&&\\qquad\\quad{} -\\tfrac{1}{2}\\omega\\bigl(s,t+\n\\delta,|s-t-\\delta|^\\kappa\\bigr)\\bigr|\\nonumber\n\\[-1pt]\n&&\\qquad\\leq \n\\cases{ \\displaystyle M_5 \\frac{\\delta^2}{|t-s|^{2-\\kappa}}, &\\quad $ \\mbox{if }\n\\kappa\\neq1,$\\vspace*{2pt}\n\\cr\nM_5 \\delta^2, &\\quad $\\mbox{if }\n\\kappa= 1$.}\\nonumber \n\\end{eqnarray}\n\n\nIt follows from (\\ref{Zdelta1}), (\\ref{Zdelta4}) and (\\ref{Zdelta5})\nthat for arbitrary $t\\in(a,b)$ and any $\\epsilon>0$ there exist a\n$\\delta_\\epsilon>0$ as well as a constant\n$a_\\epsilon\\geq1$ such that for all $\\delta\\leq\\delta_\\epsilon$\\vspace*{-2pt}\n\n\\begin{eqnarray*}\n\\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|&\\leq&(1+\\epsilon)\\mathbb{E}\n\\bigl(X(t)Z_{\\delta}(X,t)\\bigr)\\qquad \\mbox{for all } s\\in[a,b], s\\neq t,\n\\\\\n\\bigl|\\mathbb{E} \\bigl(X(s)Z_{\\delta}(X,t)\\bigr)\\bigr|& \\leq&\\epsilon\\cdot\\mathbb{E}\n\\bigl(X(t)Z_{\\delta}(X,t)\\bigr) \\qquad\\mbox{for all } s\\in[a,b], |s-t|\\geq\na_\\epsilon \\delta.\n\\end{eqnarray*}\n\nTogether with (\\ref{Zdelta2}), the assertion of the theorem is an\nimmediate consequence.\n\\end{pf*}\n\n\\begin{pf*}{Proof of Theorem~\\ref{parestGEN}}\nLet $\\hat\\theta_{ij}:=\\langle X_i,\\widehat{\\psi}_j\\rangle$, $ \\theta\n_{ij}:=\\langle X_i,\\psi_j\\rangle$, and\n$\\tilde\\alpha_j:= \\langle\\beta,\\widehat{\\psi}_j\\rangle$ for all $i,j$.\nUsing empirical eigenfunctions, we obtain $X_i=\\sum_{j=1}^n \\hat\\theta\n_{ij}\\widehat{\\psi}_j$ and $\\int_a^b \\beta(t)X_i(t)\\,dt =\\sum_{j=1}^n\n\\tilde\\alpha_j\\hat\\theta_{ij}$. Therefore,\\vspace*{-2pt}\n\n\n\n", "index": 57, "text": "\\begin{equation}\nY_i=\\sum_{j=1}^n \\Biggl(\n\\tilde\\alpha_j +\\sum_{r=1}^S\n\\beta_r \\widehat {\\psi}_j(\\tau_r) \\Biggr)\n\\hat\\theta_{ij}+\\varepsilon_i, \\label{parGEN-eq1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"Y_{i}=\\sum_{j=1}^{n}\\Biggl{(}\\tilde{\\alpha}_{j}+\\sum_{r=1}^{S}\\beta_{r}%&#10;\\widehat{\\psi}_{j}(\\tau_{r})\\Biggr{)}\\hat{\\theta}_{ij}+\\varepsilon_{i},\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><msub><mover accent=\"true\"><mi>\u03b1</mi><mo stretchy=\"false\">~</mo></mover><mi>j</mi></msub><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mrow><msub><mi>\u03b2</mi><mi>r</mi></msub><mo>\u2062</mo><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow><mo>\u2062</mo><msub><mover accent=\"true\"><mi>\u03b8</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow><mo>+</mo><msub><mi>\u03b5</mi><mi>i</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nLet $\\mathbf{X}_i^{[k]}:=(X_i^{[k]}(\\widehat{\\tau}_1),\\ldots\n,X_i^{[k]}(\\widehat{\\tau}_S))^T$ and note\nthat by (\\ref{parGEN-eq8}) we have\\break  $\\frac{1}{n} \\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T$ $=\\mathbf{M}_k+\no_P(n^{(-\\mu+1)/(\\mu+2\\nu)})$.\nBy Assumption~\\ref{assum4}(b), we can conclude that with probability\ntending to 1 as $n\\rightarrow\\infty$ the matrix\n$\\frac{1}{n}\\sum_{i=1}^n \\mathbf{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T$ is\ninvertible,\n\n\n\\begin{eqnarray} \\label{parGEN-eq9}\n&&n^{(-\\mu+1)/(\\mu+2\\nu)}\\Biggl(\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf {X}_i^{[k]}\\bigl(\\mathbf{X}_i^{[k]}\n\\bigr)^T\\Biggr)^{-1}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad=n^{(-\\mu+1)/(\\mu+2\\nu\n)}(\\mathbf{M}_k)^{-1}\n+o_P(1)\n\\end{eqnarray}\n\nand hence by\n(\\ref{parGEN-eq1})--(\\ref{parGEN-eq3}) the least squares\nestimator $\\widehat{\\bolds{\\beta}}$ of $\\bolds{\\beta}$ can be\nwritten in the form\n\n\n\\begin{eqnarray}\\label{parGEN-eq10}\n\\widehat{\\bolds{\\beta}}&=&\\Biggl(\\frac{1}{n}\\sum\n_{i=1}^n \\mathbf {X}_i^{[k]}\n\\bigl(\\mathbf{X}_i^{[k]}\\bigr)^T\n\\Biggr)^{-1}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&{}\\times\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]} \\Biggl(\\sum\n_{r=1}^S \\beta_r X_i^{[k]}(\n\\tau_r) + \\sum_{j=k+1}^n \\tilde\n\\alpha_j \\hat\\theta_{ij}+\\varepsilon_i\n\\Biggr).\n\\end{eqnarray}\n\nBy (\\ref{parGEN-eq7}) and (\\ref{parGEN-eq8}), we obtain\n\n\n\\begin{eqnarray} \\label{parGEN-eq10a}\n&&\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]}\\sum_{r=1}^S\n\\beta_r X_i^{[k]}(\\tau_r)\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad=\n\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]}\\bigl(\\mathbf {X}_i^{[k]}\n\\bigr)^T\\bolds{\\beta}+ O_P\\bigl(n^{(-\\mu+1)/2(\\mu+2\\nu)}\\cdot\nn^{-1/2}\\bigr).\n\\end{eqnarray}\n\nThe results of \\citet{HallHorowitz2007} imply that $\\sum_{j=k+1}^n\n\\tilde\\alpha_j^2= \\break O_P(n^{-(2\\nu-1)/(\\mu+2\\nu)})$. The Cauchy--Schwarz\ninequality thus leads to\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq11}&& \\Biggl|\\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\widehat{\\tau}_r) \\Biggl(\\sum\n_{j=k+1}^n \\tilde\\alpha_j \\hat\n\\theta_{ij}\\Biggr)\\Biggr|\\nonumber\\\\\n&&\\qquad =\\Biggl|\\sum_{j=k+1}^n\n\\tilde\\alpha_j \\hat\\lambda_j \\widehat{\n\\psi}_j(\\widehat {\\tau}_r)\\Biggr|\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad\\leq\\sqrt{\\sum_{j=k+1}^n \\hat\n\\lambda_j \\tilde\\alpha_j^2}\\sqrt{\n\\sum_{j=k+1}^n \\hat\\lambda_j\n\\widehat{\\psi}_j(\\widehat{\\tau}_r)^2} \\leq\n\\sqrt{\\hat\\lambda_{k+1} \\sum_{j=k+1}^n\n\\tilde\\alpha_j^2}\\sqrt {\\frac{1}{n}\\sum\n_{i=1}^n X_i^{[k]}(\n\\widehat{\\tau}_r)^2}\n\\\\\n&&\\qquad =O_P\\bigl( n^{-(\\mu+2\\nu-1)/2(\\mu+2\\nu)}\\cdot\nn^{(-\\mu+1)/2(\\mu+2\\nu)}\\bigr)\\nonumber\n\\end{eqnarray}\n\nfor all $r=1,\\ldots,S$. Furthermore, $\\widehat{\\psi}_j(t)=\n\\hat\\lambda_j^{-1}\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}X_i(t)$, and hence\nthe Cauchy--Schwarz inequality yields\n\n\n\\begin{eqnarray}\\label{parGEN-eq11a}\n\\bigl|\\widehat{\\psi}_j(\\tau_r)-\\widehat{\n\\psi}_j(\\widehat{\\tau}_r)\\bigr|&=& \\Biggl|\\hat\\lambda_j^{-1}\n\\frac{1}{n}\\sum_{i=1}^n \\hat\n\\theta_{ij}\\bigl(X_i(\\tau_r)-X_i(\n\\widehat{\\tau }_r)\\bigr)\\Biggr|\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&\\leq &\\hat\\lambda_j^{-1/2}\n\\sqrt{\\frac{1}{n}\\sum_{l=1}^n\n\\bigl(X_l(\\tau _r)-X_l(\\widehat{\n\\tau}_r)\\bigr)^2}.\n\\end{eqnarray}\n\nNow note that by the\nindependence of $\\hat\\theta_{ij}$ and $\\varepsilon_i$ we have $\\hat\n\\lambda_j^{-1/2}\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}\\varepsilon\n_i=O_P(n^{-1/2})$. By\n(\\ref{lem4eq3}), it therefore follows from (\\ref{parGEN-eq11a})\nthat\n\n\\begin{eqnarray*}\n&&\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\widehat{\\tau}_r)-X_i^{[k]}(\n\\tau _r)\\bigr)\\varepsilon_i\\\\\n&&\\qquad=\\frac{1}{n}\\sum\n_{i=1}^n \\bigl(X_i(\\widehat{\n\\tau}_r)-X_i(\\tau_r)\\bigr)\n\\varepsilon_i- \\sum_{j=1}^k\n\\frac{1}{n}\\sum_{i=1}^n\\hat\n\\theta_{ij}\\varepsilon_i \\bigl(\\widehat{\n\\psi}_j(\\widehat{\\tau}_r)-\\widehat{\\psi}_j(\n\\tau_r)\\bigr)\n\\\\\n&&\\qquad=O_P\\bigl((k+1) n^{-1}\\bigr)=O_P\\bigl(\nn^{-(\\mu+2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray*}\n\nUsing (\\ref{parGEN-eq6}), it is immediately seen that\n$\\frac{1}{n}\\sum_{i=1}^n X_i^{[k]}(\\tau_r)\\varepsilon_i=\\break O_P(n^{-1/2}\nn^{(-\\mu+1)/2(\\mu+2\\nu)})$. Consequently,\n\n\n\\begin{eqnarray} \\label{parGEN-eq12}\n\\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\widehat{\\tau}_r)\n\\varepsilon_i&=& \\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\tau_r)\\varepsilon_i +\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\widehat{\\tau}_r)-X_i^{[k]}(\n\\tau _r)\\bigr)\\varepsilon_i\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&=&O_P\n\\bigl(n^{-1/2} n^{(-\\mu+1)/2(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray}\n\nBy Assumption~\\ref{assum4}(c), we can infer from (\\ref{parGEN-eq9})\nthat the maximal\neigenvalue of the matrix $(\\frac{1}{n}\\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T)^{-1}$\ncan be bounded by $\\lambda_{\\mathrm{max}} ((\\frac{1}{n}\\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}\\times\\break (\\mathbf{X}_i^{[k]})^T)^{-1})=O_P(n^{(\\mu-1)/(\\mu+2\\nu)})$.\nIt therefore follows\nfrom (\\ref{parGEN-eq10})--(\\ref{parGEN-eq12}) that\n\n\\begin{eqnarray*}\n\\widehat{\\bolds{\\beta}}&=& \\bolds{\\beta}+ O_P\\bigl(n^{(\\mu-1)/(\\mu+2\\nu)}\n\\cdot n^{(-\\mu+1)/2(\\mu+2\\nu)}\\cdot n^{-(\\mu+2\\nu-1)/2(\\mu+2\\nu)}\\bigr)\\\\\n&= &\\bolds{\\beta}+O_P\n\\bigl( n^{-\\nu/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray*}\n\nThis proves (\\ref{thmpGENeq1}). Using (\\ref{parGEN-eq3}), it follows\nthat the\nleast squares estimators $\\widehat{\\alpha}_j$ of $\\tilde\\alpha_j$ are\ngiven by\n\n\n\\begin{eqnarray}\\label{parGEN-eq13}\n\\widehat{\\alpha}_j&=&\\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i+ \\sum_{r=1}^S (\n\\beta_r-\\widehat{\\beta}_r) \\widehat{\n\\psi}_j(\\tau_r)\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&{}-\\sum_{r=1}^S\n\\widehat{\\beta}_r\\bigl( \\widehat{\\psi}_j(\\widehat{\n\\tau}_r)-\\widehat{\\psi}_j(\\tau_r)\\bigr),\\qquad\nj=1,\\ldots,k .\n\\end{eqnarray}\n\nBut (\\ref{parGEN-eq5}) and (\\ref{thmpGENeq1}) imply that\n\n\n\\begin{eqnarray} \\qquad\\hspace*{6pt}\\label{parGEN-eq14}\n\\sum_{j=1}^k \\Biggl(\\sum\n_{r=1}^S (\\beta_r-\\widehat{\n\\beta}_r) \\widehat{\\psi }_j(\\tau_r)\n\\Biggr)^2= O_P\\bigl(k n^{-2\\nu/(\\mu+2\\nu)}\n\\bigr)\n=O_P\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr),\\hspace*{-8pt}\n\\end{eqnarray}\n\nwhile by (\\ref{parGEN-eq5}) and (\\ref{parGEN-eq11a})\n\n\\begin{eqnarray*}\n\\sum_{j=1}^k\\bigl(\\widehat{\n\\psi}_j(\\tau_r)-\\widehat{\\psi}_j(\\widehat{\n\\tau}_r)\\bigr)^2 \\leq\\frac{k}{\\lambda_k}\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)^2 =O_P\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\n\\bigr),\n\\end{eqnarray*}\n\nand therefore\n\n\n\n", "itemtype": "equation", "pos": 85669, "prevtext": "\n\nand for all possible values $b_1,\\ldots,b_S$ and all $a_1,\\ldots,a_k$\\vspace*{-2pt}\n\n\n\\begin{eqnarray}\\label{parGEN-eq2}\n&&\\sum_{j=1}^k a_j \\hat\n\\theta_{ij}+\\sum_{r=1}^S\nb_r X_i(\\widehat{\\tau}_r)\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad = \\sum\n_{j=1}^k \\Biggl( a_j +\\sum\n_{r=1}^S b_r \\widehat{\n\\psi}_j(\\widehat {\\tau}_r) \\Biggr) \\hat\n\\theta_{ij}+\\sum_{j=k+1}^n \\sum\n_{r=1}^Sb_r \\widehat{\n\\psi}_j(\\widehat{\\tau}_r)\\hat\\theta_{ij}\n\\end{eqnarray}\n\nfor all $i=1,\\ldots,n$. By definition, $\\hat\\lambda_j=\\frac{1}{n}\\sum_{i=1}^n \\hat\\theta_{ij}^2$, $j=1,\\ldots,n$, and for $j\\ne l$ the\ncoefficients $\\hat\\theta_{ij}$\nand $\\hat\\theta_{il}$ are empirically uncorrelated, that is, $\\sum_{i=1}^n \\hat\\theta_{ij}\\hat\\theta_{il}=0$. It follows that for any\ngiven values\n$b_1,\\ldots,b_S$ the values $\\hat\\alpha(\\mathbf{b})_j$, $j=1,\\ldots\n,k$, minimizing\n$\\sum_{i=1}^n  (\nY_i-\\sum_{j=1}^k a_j \\hat\\theta_{ij} - \\sum_{r=1}^{S}b_r X_i(\\widehat\n\\tau_r) )^2$ over all $a_1,\\ldots,a_k$ are given by\n\n\n\\begin{eqnarray}\\label{parGEN-eq3}\n\\hat\\alpha(\\mathbf{b})_j=\\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i+ \\sum_{r=1}^S\n\\bigl(\\beta_r \\widehat{\\psi}_j(\\tau_r)-b_r\n\\widehat{\\psi }_j(\\widehat{\\tau}_r)\\bigr),\n\\nonumber\n\\[-10pt]\n\\[-10pt]\n\\eqntext{j=1,\n\\ldots,k. }\n\\end{eqnarray}\n\nNote that $\\tilde\\alpha_j+\\hat\\lambda_j^{-1}\n\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}\\varepsilon_i$ is identical to\nthe estimate\nof $\\alpha_j$ to be obtained in a standard functional\\vadjust{\\goodbreak} linear regression\nmodel with no points of impact.\nTheorem~1 of \\citet{HallHorowitz2007} thus implies that\n\n\n\\begin{eqnarray}\\label{parGEN-eq4}\n&&\\int_a^b \\Biggl(\\beta(t)-\\sum\n_{j=1}^k\\Biggl( \\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i\\Biggr)\\widehat{\\psi }_j(t)\\,dt\n\\Biggr)^2\\,dt\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad  =O_p\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray}\n\nFurther analysis requires to analyze the differences between $\\theta\n_{ij}, \\psi_j$ and\ntheir empirical counterparts\n$\\hat\\theta_{ij}, \\widehat{\\psi}_j$.\nBy Assumptions \\ref{assum2}--\\ref{assum4} and\n$k=O(n^{1/(\\mu+2\\nu)})$,\nTheorems 1 and 2 together with equation (2.8) of \\citet{HallHosseini2006} imply that\nfor any $q=1,2,3,\\ldots$ there exists some $A_q,B_q<\\infty$ such that\n\n\n\\begin{eqnarray}\\label{parGEN-eq5}\nE \\bigl(|\\lambda_j-\\hat\\lambda_j|^q\n\\bigr)&\\leq& A_qn^{-q/2},\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n \\sup_t E\n\\bigl(\\bigl|\\widehat{\\psi}_j(t)-\\psi_j(t)\\bigr| \\bigr)&\\leq&\nB_qn^{-q/2}j^{q(\\mu\n+1)},\\qquad  j=1,\\ldots,k+1 \\vspace*{-2pt}\n\\end{eqnarray}\n\nfor all sufficiently large $n$. Let $X_i^{[k]}:= X_i-\\sum_{j=1}^k \\hat\n\\theta_{ij}\\widehat{\\psi}_j$.\nRecall that\\break $\\lambda_j=O(j^{-\\mu})$ and note that by Assumptions \\ref\n{assum3} and \\ref{assum4}, $n^{-1/2}n^{2/(\\mu+2\\nu)}=\\break o(n^{(-\\mu+1)/(\\mu\n+2\\nu)})$, while $ n^{(-\\mu+1)/(\\mu+2\\nu)}=O(\\sigma^{[k]}(\\tau_r,\\tau_r))$.\nBy (\\ref{parGEN-eq5}), we thus obtain for all $t,s\\in[a,b]$\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq6} &&\\frac{1}{n} \\sum_{i=1}^n\nX_i^{[k]}(t)X_i^{[k]}(s)\\nonumber\\[-1pt]\n&&\\qquad=\n\\frac{1}{n} \\sum_{i=1}^n\nX_i(t)X_i(s) -\\sum_{j=1}^k\n\\hat\\lambda_j \\widehat{\\psi}_j(t)\\widehat{\n\\psi}_j(s)\n\\nonumber\n\\[-1pt]\n&&\\qquad=\\sigma(t,s)-\\sum_{j=1}^k\n\\lambda_j \\psi_j(t)\\psi_j(s) +\\sum\n_{j=1}^k \\lambda_j\\bigl(\n\\psi_j(t)\\psi_j(s)-\\widehat {\\psi}_j(t)\n\\widehat{\\psi}_j(s)\\bigr)\n\\nonumber\n\\[-9pt]\n\\[-9pt]\n\\nonumber\n&&\\qquad\\quad{} +\\sum_{j=1}^k (\\lambda_j-\n\\hat\\lambda_j)\\widehat{\\psi }_j(t)\\widehat{\n\\psi}_j(s) +O_P\\bigl(n^{-1/2}\\bigr)\n\\nonumber\n\\[-1pt]\n&&\\qquad=\\sigma^{[k]}(t,s) +O_P\\bigl(n^{-1/2}n^{2/(\\mu+2\\nu)}\n\\bigr)\\nonumber\\[-1pt]\n&&\\qquad=\\sigma^{[k]}(t,s) +o_P\\bigl(n^{(-\\mu+1)/(\\mu+2\\nu)}\\bigr).\\nonumber\n\\end{eqnarray}\n\nAt the same time, (\\ref{lem4eq1}) leads to\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq7}&& \\frac{1}{n} \\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\tau_r)-X_i^{[k]}(\n\\widehat{\\tau }_r)\\bigr)^2\\nonumber\\\\\n&&\\qquad= \\frac{1}{n} \\sum\n_{i=1}^n \\bigl(X_i(\n\\tau_r)-X_i(\\widehat{\\tau }_r)\n\\bigr)^2 -\\sum_{j=1}^k \\hat\n\\lambda_j \\bigl(\\widehat{\\psi}_j(\\tau_r)-\n\\widehat{\\psi}_j(\\widehat{\\tau}_r)\\bigr)^2\n\\\\\n&&\\qquad\\leq \\frac{1}{n} \\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\\tau\n}_r)\\bigr)^2=O_P\\bigl(n^{-1}\n\\bigr)\\nonumber\n\\end{eqnarray}\n\nfor all $r=1,\\ldots,S$. Expressions (\\ref{parGEN-eq6}) and (\\ref\n{parGEN-eq7}) together imply that for\nall $r,s$\n\n\n\n", "index": 59, "text": "\\begin{equation}\n\\frac{1}{n} \\sum_{i=1}^n\nX_i^{[k]}(\\widehat{\\tau}_r)\nX_i^{[k]}(\\widehat {\\tau}_s)=\n\\sigma^{[k]}(\\tau_r,\\tau_s)+o_P\n\\bigl(n^{(-\\mu+1)/(\\mu+2\\nu)}\\bigr). \\label{parGEN-eq8}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{[k]}(\\widehat{\\tau}_{r})X_{i}^{[k]}(\\widehat{%&#10;\\tau}_{s})=\\sigma^{[k]}(\\tau_{r},\\tau_{s})+o_{P}\\bigl{(}n^{(-\\mu+1)/(\\mu+2\\nu)%&#10;}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msubsup><mi>X</mi><mi>i</mi><mrow><mo stretchy=\"false\">[</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msubsup><mi>X</mi><mi>i</mi><mrow><mo stretchy=\"false\">[</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>s</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>=</mo><mrow><mrow><msup><mi>\u03c3</mi><mrow><mo stretchy=\"false\">[</mo><mi>k</mi><mo stretchy=\"false\">]</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo>,</mo><msub><mi>\u03c4</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>o</mi><mi>P</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>n</mi><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo>-</mo><mi>\u03bc</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bd</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02798.tex", "nexttext": "\n\nAssertion (\\ref{thmpGENeq2}) now is an immediate consequence of (\\ref\n{parGEN-eq4}) and\n(\\ref{parGEN-eq13})--(\\ref{parGEN-eq15}).\n\\end{pf*}\n\\end{appendix}\n\n\n\\begin{supplement}\n\n\\stitle{Supplement to ``Functional linear regression with points of\nimpact''}\n\\slink[doi]{10.1214/15-AOS1323SUPP} \n\\sdatatype{.pdf}\n\\sfilename{aos1323\\_supp.pdf}\n\\sdescription{The supplementary document by Kneip, Poss and Sarda (\\citeyear{KneipPossSarda2015})\ncontains three Appendices. An application to NIR data can be found in\nAppendix~A. In Appendix~B, it is shown that the eigenfunctions of a\nBrownian motion satisfy assertion \\ref{karlovp0} in Theorem~\\ref\n{thmkarlov}. Appendix~C provides the proofs of Theorem~\\ref{poicon} and\nPropositions~\\ref{poiconkappa} and \\ref{lem4}.}\n\\end{supplement}\n\n\n\n\\begin{thebibliography}{25}\n\n\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Bickel, Ritov and Tsybakov}{2009}]{Bickel2009}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Bickel},~\\bfnm{Peter~J.}\\binits{P.~J.}},\n\\bauthor{\\bsnm{Ritov},~\\bfnm{Ya'acov}\\binits{Y.}} \\AND\n\\bauthor{\\bsnm{Tsybakov},~\\bfnm{Alexandre~B.}\\binits{A.~B.}}\n(\\byear{2009}).\n\\btitle{Simultaneous analysis of lasso and {D}antzig selector}.\n\\bjournal{Ann. Statist.}\n\\bvolume{37}\n\\bpages{1705--1732}.\n\\bid{doi={10.1214/08-AOS620}, issn={0090-5364}, mr={2533469}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Bosq}{2000}]{Bosq2000}\n\\begin{bbook}[mr]\n\\bauthor{\\bsnm{Bosq},~\\bfnm{D.}\\binits{D.}}\n(\\byear{2000}).\n\\btitle{Linear Processes in Function Spaces: Theory and Applications}.\n\\bseries{Lecture Notes in Statistics}\n\\bvolume{149}.\n\\bpublisher{Springer},\n\\blocation{New York}.\n\\bid{doi={10.1007/978-1-4612-1154-9}, mr={1783138}}\n\\end{bbook}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Cai and Hall}{2006}]{CaiHall2006}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Cai},~\\bfnm{T.~Tony}\\binits{T.~T.}} \\AND\n\\bauthor{\\bsnm{Hall},~\\bfnm{Peter}\\binits{P.}}\n(\\byear{2006}).\n\\btitle{Prediction in functional linear regression}.\n\\bjournal{Ann. Statist.}\n\\bvolume{34}\n\\bpages{2159--2179}.\n\\bid{doi={10.1214/009053606000000830}, issn={0090-5364}, mr={2291496}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Cardot, Ferraty and Sarda}{1999}]{CardotFerratySarda1999}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Cardot},~\\bfnm{Herv{\\'e}}\\binits{H.}},\n\\bauthor{\\bsnm{Ferraty},~\\bfnm{Fr{\\'e}d{\\'e}ric}\\binits{F.}} \\AND\n\\bauthor{\\bsnm{Sarda},~\\bfnm{Pascal}\\binits{P.}}\n(\\byear{1999}).\n\\btitle{Functional linear model}.\n\\bjournal{Statist. Probab. Lett.}\n\\bvolume{45}\n\\bpages{11--22}.\n\\bid{doi={10.1016/S0167-7152(99)00036-X}, issn={0167-7152}, mr={1718346}}\n\\bptnote{check volume}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Cardot and Johannes}{2010}]{CardotJohannes2010}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Cardot},~\\bfnm{Herv{\\'e}}\\binits{H.}} \\AND\n\\bauthor{\\bsnm{Johannes},~\\bfnm{Jan}\\binits{J.}}\n(\\byear{2010}).\n\\btitle{Thresholding projection estimators in functional linear models}.\n\\bjournal{J. Multivariate Anal.}\n\\bvolume{101}\n\\bpages{395--408}.\n\\bid{doi={10.1016/j.jmva.2009.03.001}, issn={0047-259X}, mr={2564349}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Cardot, Mas and Sarda}{2007}]{CardotMasSarda2007}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Cardot},~\\bfnm{Herv{\\'e}}\\binits{H.}},\n\\bauthor{\\bsnm{Mas},~\\bfnm{Andr{\\'e}}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Sarda},~\\bfnm{Pascal}\\binits{P.}}\n(\\byear{2007}).\n\\btitle{C{LT} in functional linear regression models}.\n\\bjournal{Probab. Theory Related Fields}\n\\bvolume{138}\n\\bpages{325--361}.\n\\bid{doi={10.1007/s00440-006-0025-2}, issn={0178-8051}, mr={2299711}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Comte and Johannes}{2012}]{ComteJohannes2012}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Comte},~\\bfnm{Fabienne}\\binits{F.}} \\AND\n\\bauthor{\\bsnm{Johannes},~\\bfnm{Jan}\\binits{J.}}\n(\\byear{2012}).\n\\btitle{Adaptive functional linear regression}.\n\\bjournal{Ann. Statist.}\n\\bvolume{40}\n\\bpages{2765--2797}.\n\\bid{doi={10.1214/12-AOS1050}, issn={0090-5364}, mr={3097959}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Crambes, Kneip and Sarda}{2009}]{CrambesKneipSarda2009}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Crambes},~\\bfnm{Christophe}\\binits{C.}},\n\\bauthor{\\bsnm{Kneip},~\\bfnm{Alois}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Sarda},~\\bfnm{Pascal}\\binits{P.}}\n(\\byear{2009}).\n\\btitle{Smoothing splines estimators for functional linear regression}.\n\\bjournal{Ann. Statist.}\n\\bvolume{37}\n\\bpages{35--72}.\n\\bid{doi={10.1214/07-AOS563}, issn={0090-5364}, mr={2488344}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Delaigle and Hall}{2012}]{DelaigleHall2012}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Delaigle},~\\bfnm{Aurore}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Hall},~\\bfnm{Peter}\\binits{P.}}\n(\\byear{2012}).\n\\btitle{Methodology and theory for partial least squares applied to functional data}.\n\\bjournal{Ann. Statist.}\n\\bvolume{40}\n\\bpages{322--352}.\n\\bid{doi={10.1214/11-AOS958}, issn={0090-5364}, mr={3014309}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Ferraty, Hall and Vieu}{2010}]{FerratyHallVieu2010}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Ferraty},~\\bfnm{F.}\\binits{F.}},\n\\bauthor{\\bsnm{Hall},~\\bfnm{P.}\\binits{P.}} \\AND\n\\bauthor{\\bsnm{Vieu},~\\bfnm{P.}\\binits{P.}}\n(\\byear{2010}).\n\\btitle{Most-predictive design points for functional data predictors}.\n\\bjournal{Biometrika}\n\\bvolume{97}\n\\bpages{807--824}.\n\n\\bid{doi={10.1093/biomet/asq058}, issn={0006-3444}, mr={2746153}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Frank and Friedman}{1993}]{FrankFriedman1993}\n\\begin{barticle}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Frank},~\\bfnm{I.~E.}\\binits{I.~E.}} \\AND\n\\bauthor{\\bsnm{Friedman},~\\bfnm{J.~H.}\\binits{J.~H.}}\n(\\byear{1993}).\n\\btitle{A statistical view of some chemometrics regression tools}.\n\\bjournal{Technometrics}\n\\bvolume{35}\n\\bpages{109--135}.\n\\end{barticle}\n\n\n\\bptok{imsref}\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Gillespie}{1996}]{Gillespie1996}\n\\begin{barticle}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Gillespie},~\\bfnm{D.~T.}\\binits{D.~T.}}\n(\\byear{1996}).\n\\btitle{Exact numerical simulation of the Ornstein--Uhlenbeck process and its integral}.\n\\bjournal{Phys. Rev. E (3)}\n\\bvolume{54}\n\\bpages{2084--2091}.\n\\end{barticle}\n\n\n\\bptok{imsref}\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Hall and Horowitz}{2007}]{HallHorowitz2007}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Hall},~\\bfnm{Peter}\\binits{P.}} \\AND\n\\bauthor{\\bsnm{Horowitz},~\\bfnm{Joel~L.}\\binits{J.~L.}}\n(\\byear{2007}).\n\\btitle{Methodology and convergence rates for functional linear regression}.\n\\bjournal{Ann. Statist.}\n\\bvolume{35}\n\\bpages{70--91}.\n\\bid{doi={10.1214/009053606000000957}, issn={0090-5364}, mr={2332269}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Hall and Hosseini-Nasab}{2006}]{HallHosseini2006}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Hall},~\\bfnm{Peter}\\binits{P.}} \\AND\n\\bauthor{\\bsnm{Hosseini-Nasab},~\\bfnm{Mohammad}\\binits{M.}}\n(\\byear{2006}).\n\\btitle{On properties of functional principal components analysis}.\n\\bjournal{J. R. Stat. Soc. Ser. B. Stat. Methodol.}\n\\bvolume{68}\n\\bpages{109--126}.\n\\bid{doi={10.1111/j.1467-9868.2005.00535.x}, issn={1369-7412}, mr={2212577}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{He, M{\\\"{u}}ller and Wang}{2000}]{HeMuellerWang2000}\n\\begin{bincollection}[auto:parserefs-M02]\n\\bauthor{\\bsnm{He},~\\bfnm{G.}\\binits{G.}},\n\\bauthor{\\bsnm{M{\\\"{u}}ller},~\\bfnm{H.~G.}\\binits{H.~G.}} \\AND\n\\bauthor{\\bsnm{Wang},~\\bfnm{J.~L.}\\binits{J.~L.}}\n(\\byear{2000}).\n\\btitle{Extending correlation and regression from multivariate to functional data}.\nIn \\bbooktitle{Asymptotics in Statistics and Probability}\n\n\\bpages{301--315}.\n\\bpublisher{VSP},\n\\blocation{Leiden}.\n\\end{bincollection}\n\n\n\\bptok{imsref}\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Hsing and Ren}{2009}]{HsingRen2009}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Hsing},~\\bfnm{Tailen}\\binits{T.}} \\AND\n\\bauthor{\\bsnm{Ren},~\\bfnm{Haobo}\\binits{H.}}\n(\\byear{2009}).\n\\btitle{An RKHS formulation of the inverse regression dimension-reduction problem}.\n\\bjournal{Ann. Statist.}\n\\bvolume{37}\n\\bpages{726--755}.\n\\bid{doi={10.1214/07-AOS589}, issn={0090-5364}, mr={2502649}}\n\\bptnote{check pages}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{James, Wang and Zhu}{2009}]{JamesWangZhu2009}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{James},~\\bfnm{Gareth~M.}\\binits{G.~M.}},\n\\bauthor{\\bsnm{Wang},~\\bfnm{Jing}\\binits{J.}} \\AND\n\\bauthor{\\bsnm{Zhu},~\\bfnm{Ji}\\binits{J.}}\n(\\byear{2009}).\n\\btitle{Functional linear regression that's interpretable}.\n\\bjournal{Ann. Statist.}\n\\bvolume{37}\n\\bpages{2083--2108}.\n\\bid{doi={10.1214/08-AOS641}, issn={0090-5364}, mr={2543686}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Kneip, Poss and Sarda}{2015}]{KneipPossSarda2015}\n\\begin{bmisc}[author]\n{\\bauthor{\\bsnm{Kneip},~\\binits{A.}},\n\\bauthor{\\bsnm{Po{\\ss}},~\\binits{D.}} \\AND\n\\bauthor{\\bsnm{Sarda},~\\binits{P.}}}\n(\\byear{2015}).\n\\bhowpublished{Supplement to ``Functional linear regression with points of impact.''\nDOI:\\doiurl{10.1214/15-AOS1323SUPP}}.\n\\bptok{imsref}\n\\end{bmisc}\n\\endbibitem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Kneip and Sarda}{2011}]{KneipSarda2011}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Kneip},~\\bfnm{Alois}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Sarda},~\\bfnm{Pascal}\\binits{P.}}\n(\\byear{2011}).\n\\btitle{Factor models and variable selection in high-dimensional regression analysis}.\n\\bjournal{Ann. Statist.}\n\\bvolume{39}\n\\bpages{2410--2447}.\n\\bid{doi={10.1214/11-AOS905}, issn={0090-5364}, mr={2906873}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{McKeague and Sen}{2010}]{McKeagueSen2010}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{McKeague},~\\bfnm{Ian~W.}\\binits{I.~W.}} \\AND\n\\bauthor{\\bsnm{Sen},~\\bfnm{Bodhisattva}\\binits{B.}}\n(\\byear{2010}).\n\\btitle{Fractals with point impact in functional linear regression}.\n\\bjournal{Ann. Statist.}\n\\bvolume{38}\n\\bpages{2559--2586}.\n\\bid{doi={10.1214/10-AOS791}, issn={0090-5364}, mr={2676898}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{M{\\\"u}ller and Stadtm{\\\"u}ller}{2005}]{MuellerStadtmueller2005}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{M{\\\"u}ller},~\\bfnm{Hans-Georg}\\binits{H.-G.}} \\AND\n\\bauthor{\\bsnm{Stadtm{\\\"u}ller},~\\bfnm{Ulrich}\\binits{U.}}\n(\\byear{2005}).\n\\btitle{Generalized functional linear models}.\n\\bjournal{Ann. Statist.}\n\\bvolume{33}\n\\bpages{774--805}.\n\\bid{doi={10.1214/009053604000001156}, issn={0090-5364}, mr={2163159}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{van~de Geer and Lederer}{2013}]{vandeGeerLederer2012}\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{van~de Geer},~\\bfnm{Sara}\\binits{S.}} \\AND\n\\bauthor{\\bsnm{Lederer},~\\bfnm{Johannes}\\binits{J.}}\n(\\byear{2013}).\n\\btitle{The {B}ernstein--{O}rlicz norm and deviation inequalities}.\n\\bjournal{Probab. Theory Related Fields}\n\\bvolume{157}\n\\bpages{225--250}.\n\\bid{doi={10.1007/s00440-012-0455-y}, issn={0178-8051}, mr={3101846}}\n\\bptnote{check volume, check pages, check year}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{van~der Vaart and Wellner}{1996}]{vanderVaartWellner2000}\n\\begin{bbook}[mr]\n\\bauthor{\\bsnm{van~der Vaart},~\\bfnm{Aad~W.}\\binits{A.~W.}} \\AND\n\\bauthor{\\bsnm{Wellner},~\\bfnm{Jon~A.}\\binits{J.~A.}}\n(\\byear{1996}).\n\\btitle{Weak Convergence and Empirical Processes with Applications to Statistics}.\n\n\\bpublisher{Springer},\n\\blocation{New York}.\n\\bid{doi={10.1007/978-1-4757-2545-2}, mr={1385671}}\n\\bptnote{check year}\n\\end{bbook}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Zhou, Lafferty and Wasserman}{2008}]{ZhouLaffertyWassermann2008}\n\\begin{bmisc}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Zhou},~\\bfnm{S.}\\binits{S.}},\n\\bauthor{\\bsnm{Lafferty},~\\bfnm{J.}\\binits{J.}} \\AND\n\\bauthor{\\bsnm{Wasserman},~\\bfnm{L.}\\binits{L.}}\n(\\byear{2008}).\n\\bhowpublished{Time varying undirected graphs.\nIn \\textit{Proceedings of the $21$st Annual Conference on Computational Learning Theory (COLT 2008).}\nAvailable at \\url{http://arxiv.org/abs/0802.2758}.}\n\\end{bmisc}\n\n\n\\bptok{imsref}\n\n\n\\endbibitem\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Zhou, van~de Geer and B\\\"uhlmann}{2009}]{ZhouvandeGeerBuehlmann2009}\n\\begin{bmisc}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Zhou},~\\bfnm{S.}\\binits{S.}},\n\\bauthor{\\bsnm{van~de Geer},~\\bfnm{S.}\\binits{S.}} \\AND\n\\bauthor{\\bsnm{B\\\"uhlmann},~\\bfnm{P.}\\binits{P.}}\n(\\byear{2009}).\n\\bhowpublished{\nAdaptive lasso for high dimensional regression and Gaussian graphical modeling.\nAvailable at \\url{http://arxiv.org/abs/0903.2515}.}\n\\end{bmisc}\n\n\n\\bptok{imsref}\n\n\n\\endbibitem\n\\end{thebibliography}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\printaddresses\n\n", "itemtype": "equation", "pos": 92101, "prevtext": "\n\nLet $\\mathbf{X}_i^{[k]}:=(X_i^{[k]}(\\widehat{\\tau}_1),\\ldots\n,X_i^{[k]}(\\widehat{\\tau}_S))^T$ and note\nthat by (\\ref{parGEN-eq8}) we have\\break  $\\frac{1}{n} \\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T$ $=\\mathbf{M}_k+\no_P(n^{(-\\mu+1)/(\\mu+2\\nu)})$.\nBy Assumption~\\ref{assum4}(b), we can conclude that with probability\ntending to 1 as $n\\rightarrow\\infty$ the matrix\n$\\frac{1}{n}\\sum_{i=1}^n \\mathbf{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T$ is\ninvertible,\n\n\n\\begin{eqnarray} \\label{parGEN-eq9}\n&&n^{(-\\mu+1)/(\\mu+2\\nu)}\\Biggl(\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf {X}_i^{[k]}\\bigl(\\mathbf{X}_i^{[k]}\n\\bigr)^T\\Biggr)^{-1}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad=n^{(-\\mu+1)/(\\mu+2\\nu\n)}(\\mathbf{M}_k)^{-1}\n+o_P(1)\n\\end{eqnarray}\n\nand hence by\n(\\ref{parGEN-eq1})--(\\ref{parGEN-eq3}) the least squares\nestimator $\\widehat{\\bolds{\\beta}}$ of $\\bolds{\\beta}$ can be\nwritten in the form\n\n\n\\begin{eqnarray}\\label{parGEN-eq10}\n\\widehat{\\bolds{\\beta}}&=&\\Biggl(\\frac{1}{n}\\sum\n_{i=1}^n \\mathbf {X}_i^{[k]}\n\\bigl(\\mathbf{X}_i^{[k]}\\bigr)^T\n\\Biggr)^{-1}\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&{}\\times\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]} \\Biggl(\\sum\n_{r=1}^S \\beta_r X_i^{[k]}(\n\\tau_r) + \\sum_{j=k+1}^n \\tilde\n\\alpha_j \\hat\\theta_{ij}+\\varepsilon_i\n\\Biggr).\n\\end{eqnarray}\n\nBy (\\ref{parGEN-eq7}) and (\\ref{parGEN-eq8}), we obtain\n\n\n\\begin{eqnarray} \\label{parGEN-eq10a}\n&&\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]}\\sum_{r=1}^S\n\\beta_r X_i^{[k]}(\\tau_r)\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad=\n\\frac{1}{n}\\sum_{i=1}^n\n\\mathbf{X}_i^{[k]}\\bigl(\\mathbf {X}_i^{[k]}\n\\bigr)^T\\bolds{\\beta}+ O_P\\bigl(n^{(-\\mu+1)/2(\\mu+2\\nu)}\\cdot\nn^{-1/2}\\bigr).\n\\end{eqnarray}\n\nThe results of \\citet{HallHorowitz2007} imply that $\\sum_{j=k+1}^n\n\\tilde\\alpha_j^2= \\break O_P(n^{-(2\\nu-1)/(\\mu+2\\nu)})$. The Cauchy--Schwarz\ninequality thus leads to\n\n\n\\begin{eqnarray}\n\\label{parGEN-eq11}&& \\Biggl|\\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\widehat{\\tau}_r) \\Biggl(\\sum\n_{j=k+1}^n \\tilde\\alpha_j \\hat\n\\theta_{ij}\\Biggr)\\Biggr|\\nonumber\\\\\n&&\\qquad =\\Biggl|\\sum_{j=k+1}^n\n\\tilde\\alpha_j \\hat\\lambda_j \\widehat{\n\\psi}_j(\\widehat {\\tau}_r)\\Biggr|\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&\\qquad\\leq\\sqrt{\\sum_{j=k+1}^n \\hat\n\\lambda_j \\tilde\\alpha_j^2}\\sqrt{\n\\sum_{j=k+1}^n \\hat\\lambda_j\n\\widehat{\\psi}_j(\\widehat{\\tau}_r)^2} \\leq\n\\sqrt{\\hat\\lambda_{k+1} \\sum_{j=k+1}^n\n\\tilde\\alpha_j^2}\\sqrt {\\frac{1}{n}\\sum\n_{i=1}^n X_i^{[k]}(\n\\widehat{\\tau}_r)^2}\n\\\\\n&&\\qquad =O_P\\bigl( n^{-(\\mu+2\\nu-1)/2(\\mu+2\\nu)}\\cdot\nn^{(-\\mu+1)/2(\\mu+2\\nu)}\\bigr)\\nonumber\n\\end{eqnarray}\n\nfor all $r=1,\\ldots,S$. Furthermore, $\\widehat{\\psi}_j(t)=\n\\hat\\lambda_j^{-1}\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}X_i(t)$, and hence\nthe Cauchy--Schwarz inequality yields\n\n\n\\begin{eqnarray}\\label{parGEN-eq11a}\n\\bigl|\\widehat{\\psi}_j(\\tau_r)-\\widehat{\n\\psi}_j(\\widehat{\\tau}_r)\\bigr|&=& \\Biggl|\\hat\\lambda_j^{-1}\n\\frac{1}{n}\\sum_{i=1}^n \\hat\n\\theta_{ij}\\bigl(X_i(\\tau_r)-X_i(\n\\widehat{\\tau }_r)\\bigr)\\Biggr|\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&\\leq &\\hat\\lambda_j^{-1/2}\n\\sqrt{\\frac{1}{n}\\sum_{l=1}^n\n\\bigl(X_l(\\tau _r)-X_l(\\widehat{\n\\tau}_r)\\bigr)^2}.\n\\end{eqnarray}\n\nNow note that by the\nindependence of $\\hat\\theta_{ij}$ and $\\varepsilon_i$ we have $\\hat\n\\lambda_j^{-1/2}\\frac{1}{n}\\sum_{i=1}^n\\hat\\theta_{ij}\\varepsilon\n_i=O_P(n^{-1/2})$. By\n(\\ref{lem4eq3}), it therefore follows from (\\ref{parGEN-eq11a})\nthat\n\n\\begin{eqnarray*}\n&&\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\widehat{\\tau}_r)-X_i^{[k]}(\n\\tau _r)\\bigr)\\varepsilon_i\\\\\n&&\\qquad=\\frac{1}{n}\\sum\n_{i=1}^n \\bigl(X_i(\\widehat{\n\\tau}_r)-X_i(\\tau_r)\\bigr)\n\\varepsilon_i- \\sum_{j=1}^k\n\\frac{1}{n}\\sum_{i=1}^n\\hat\n\\theta_{ij}\\varepsilon_i \\bigl(\\widehat{\n\\psi}_j(\\widehat{\\tau}_r)-\\widehat{\\psi}_j(\n\\tau_r)\\bigr)\n\\\\\n&&\\qquad=O_P\\bigl((k+1) n^{-1}\\bigr)=O_P\\bigl(\nn^{-(\\mu+2\\nu-1)/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray*}\n\nUsing (\\ref{parGEN-eq6}), it is immediately seen that\n$\\frac{1}{n}\\sum_{i=1}^n X_i^{[k]}(\\tau_r)\\varepsilon_i=\\break O_P(n^{-1/2}\nn^{(-\\mu+1)/2(\\mu+2\\nu)})$. Consequently,\n\n\n\\begin{eqnarray} \\label{parGEN-eq12}\n\\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\widehat{\\tau}_r)\n\\varepsilon_i&=& \\frac{1}{n}\\sum_{i=1}^n\nX_i^{[k]}(\\tau_r)\\varepsilon_i +\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i^{[k]}(\\widehat{\\tau}_r)-X_i^{[k]}(\n\\tau _r)\\bigr)\\varepsilon_i\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&=&O_P\n\\bigl(n^{-1/2} n^{(-\\mu+1)/2(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray}\n\nBy Assumption~\\ref{assum4}(c), we can infer from (\\ref{parGEN-eq9})\nthat the maximal\neigenvalue of the matrix $(\\frac{1}{n}\\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}(\\mathbf{X}_i^{[k]})^T)^{-1}$\ncan be bounded by $\\lambda_{\\mathrm{max}} ((\\frac{1}{n}\\sum_{i=1}^n \\mathbf\n{X}_i^{[k]}\\times\\break (\\mathbf{X}_i^{[k]})^T)^{-1})=O_P(n^{(\\mu-1)/(\\mu+2\\nu)})$.\nIt therefore follows\nfrom (\\ref{parGEN-eq10})--(\\ref{parGEN-eq12}) that\n\n\\begin{eqnarray*}\n\\widehat{\\bolds{\\beta}}&=& \\bolds{\\beta}+ O_P\\bigl(n^{(\\mu-1)/(\\mu+2\\nu)}\n\\cdot n^{(-\\mu+1)/2(\\mu+2\\nu)}\\cdot n^{-(\\mu+2\\nu-1)/2(\\mu+2\\nu)}\\bigr)\\\\\n&= &\\bolds{\\beta}+O_P\n\\bigl( n^{-\\nu/(\\mu+2\\nu)}\\bigr).\n\\end{eqnarray*}\n\nThis proves (\\ref{thmpGENeq1}). Using (\\ref{parGEN-eq3}), it follows\nthat the\nleast squares estimators $\\widehat{\\alpha}_j$ of $\\tilde\\alpha_j$ are\ngiven by\n\n\n\\begin{eqnarray}\\label{parGEN-eq13}\n\\widehat{\\alpha}_j&=&\\tilde\\alpha_j+\\hat\n\\lambda_j^{-1} \\frac{1}{n}\\sum\n_{i=1}^n\\hat\\theta_{ij}\n\\varepsilon_i+ \\sum_{r=1}^S (\n\\beta_r-\\widehat{\\beta}_r) \\widehat{\n\\psi}_j(\\tau_r)\n\\nonumber\n\\[-8pt]\n\\[-8pt]\n\\nonumber\n&&{}-\\sum_{r=1}^S\n\\widehat{\\beta}_r\\bigl( \\widehat{\\psi}_j(\\widehat{\n\\tau}_r)-\\widehat{\\psi}_j(\\tau_r)\\bigr),\\qquad\nj=1,\\ldots,k .\n\\end{eqnarray}\n\nBut (\\ref{parGEN-eq5}) and (\\ref{thmpGENeq1}) imply that\n\n\n\\begin{eqnarray} \\qquad\\hspace*{6pt}\\label{parGEN-eq14}\n\\sum_{j=1}^k \\Biggl(\\sum\n_{r=1}^S (\\beta_r-\\widehat{\n\\beta}_r) \\widehat{\\psi }_j(\\tau_r)\n\\Biggr)^2= O_P\\bigl(k n^{-2\\nu/(\\mu+2\\nu)}\n\\bigr)\n=O_P\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr),\\hspace*{-8pt}\n\\end{eqnarray}\n\nwhile by (\\ref{parGEN-eq5}) and (\\ref{parGEN-eq11a})\n\n\\begin{eqnarray*}\n\\sum_{j=1}^k\\bigl(\\widehat{\n\\psi}_j(\\tau_r)-\\widehat{\\psi}_j(\\widehat{\n\\tau}_r)\\bigr)^2 \\leq\\frac{k}{\\lambda_k}\n\\frac{1}{n}\\sum_{i=1}^n\n\\bigl(X_i(\\tau_r)-X_i(\\widehat{\n\\tau}_r)\\bigr)^2 =O_P\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\n\\bigr),\n\\end{eqnarray*}\n\nand therefore\n\n\n\n", "index": 61, "text": "\\begin{equation}\n\\sum_{j=1}^k \\Biggl(\\sum\n_{r=1}^S\\widehat{\\beta}_r\\bigl(\n\\widehat{\\psi}_j(\\widehat{\\tau}_r)-\\widehat{\n\\psi}_j(\\tau_r)\\bigr)\\Biggr)^2=\nO_P\\bigl(n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr) \\label{parGEN-eq15}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\sum_{j=1}^{k}\\Biggl{(}\\sum_{r=1}^{S}\\widehat{\\beta}_{r}\\bigl{(}\\widehat{\\psi}%&#10;_{j}(\\widehat{\\tau}_{r})-\\widehat{\\psi}_{j}(\\tau_{r})\\bigr{)}\\Biggr{)}^{2}=O_{%&#10;P}\\bigl{(}n^{-(2\\nu-1)/(\\mu+2\\nu)}\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msup><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mrow><msub><mover accent=\"true\"><mi>\u03b2</mi><mo>^</mo></mover><mi>r</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\u03c4</mi><mo>^</mo></mover><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>\u03c8</mi><mo>^</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow><mn>2</mn></msup></mrow><mo>=</mo><mrow><msub><mi>O</mi><mi>P</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>n</mi><mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bd</mi></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03bd</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]