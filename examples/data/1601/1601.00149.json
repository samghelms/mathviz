[{"file": "1601.00149.tex", "nexttext": "\nThe block vectorizing and its opposite operation are\n\n", "itemtype": "equation", "pos": 8197, "prevtext": "\n\n\n\\title{A Submodule Clustering Method for Multi-way Data by Sparse and Low-Rank Representation}\n\n\\author{Xinglin Piao$^1$, Yongli Hu$^1$, Junbin Gao$^2$, Yanfeng Sun$^1$ and Zhouchen Lin$^3$\\\\\n{\\small $^1$College of Metropolitan Transportation, Beijing University of Technology, Beijing 100124, China}\\\\\n{\\small $^2$Business Analytics Discipline. The University of Sydney Business School, Camperdown NSW 2006, Australia}\\\\\n{\\small $^3$Key Laboratory of Machine Perception (MOE),\nSchool of EECS, Peking University,  Beijing 100871, China}\\\\\n{\\tt\\small piaoxinglin@126.com; \\{huyongli,yfsun\\}@bjut.edu.cn; junbin.gao@sydney.edu.au; zlin@pku.edu.cn}}\n\n\\maketitle\n\n\n\n\\begin{abstract}\nA new submodule clustering method via sparse and low-rank representation for multi-way data is proposed in this paper. Instead of reshaping multi-way data into vectors, this method maintains their natural orders to preserve data intrinsic structures, e.g., image data kept as matrices. To implement clustering, the multi-way data, viewed as tensors, are represented by the proposed tensor sparse and low-rank model to obtain its submodule representation, called a free module, which is finally used for spectral clustering. The proposed method extends the conventional subspace clustering method based on sparse and low-rank representation to multi-way data submodule clustering by combining  t-product  operator. The new method is tested on several public datasets, including synthetical data, video sequences and toy images. The experiments show that the new method outperforms the state-of-the-art methods, such as Sparse Subspace Clustering (SSC), Low-Rank Representation (LRR), Ordered Subspace Clustering (OSC), Robust Latent Low Rank Representation (RobustLatLRR) and Sparse Submodule Clustering method (SSmC).\n\\end{abstract}\n\n\n\\section{Introduction}\\label{Sec:I}\n\nThe clustering or segmentation problem of multi-way data, particularly images and videos, has attracted great interest in computer vision, pattern recognition and signal processing\n\\cite{ABiswas2012,SKrinidis2010,RXu2005}. In the traditional setting, data samples are assumed to be embedded in linear spaces and are in high dimensional and multi-dimensional (a.k.a. multi-way) format demanding huge amount of computation time and memory to conduct data analysis. Fortunately, it has been demonstrated that high dimensional and multi-way data often lie in lower dimensional subspaces and have intrinsic subspace structures \\cite{RVidal2011}. From this observation, one can assume that data are drawn from multiple subspaces and each datum in a subspace could be linearly represented by a smaller number of data samples from the same subspace. Thus the main goal of subspace clustering is to group data into different clusters such that data in each cluster just come from one particular subspace. Based on the aforementioned subspace hypothesis, researchers proposed many subspace clustering methods. The most representatives are Sparse Subspace Clustering (SSC) \\cite{EElhamifar2013}, Ordered Subspace Clustering (OSC) \\cite{STierney2014}, Low-Rank Representation (LRR) \\cite{GLiu2010} and Robust Latent Low Rank Representation (RobustLatLRR) \\cite{HZhang2014} . In these methods, an affinity matrix is firstly learned from sample data and the clustering results are obtained by a clustering algorithm such as K-means or Normalized Cuts (NCut) \\cite{JShi2000}.\n\nTo deal with high dimensional and multi-way data, the classic and straight way is to vectorize them as vectors which are then fed to a learning algorithm designed for vectorial data. However this vectorization procedure certainly destroys any intrinsic structure such as spatial information contained in data. For example, if we reshape or map a 2D image in size of $H\\times D$ into a vector of length $HD$, the correlation of the local area of pixels and other inherent properties such as texture will be destroyed. This leads to lose some useful intrinsic information in following-up applications, such as clustering and recognition. A better strategy to deal with multi-way data is to maintain their intrinsic structure. Many newly proposed methods take advantage of matrix structure by adopting dimensionality reduction approach or finding the best subspace to approximate the matrix data, and achieve successful performance \\cite{NHao2013,XHe2005}.\n\nObserving that the most typical clustering methods use the vector form to represent the data and ignore the multi-way data intrinsic structure, we concentrate on exploiting the tensor representation of multi-way data, especially the 2D images, and propose a new image submodule clustering method. In this method, different from the traditional clustering methods which map the matrix data to vector data, the $H\\times D$ matrix of image data are kept and modeled as a tensor form by twisting it into a third order tensor of size $H\\times 1\\times D$. Particularly, in video segmentation applications, samples of video frames are sometimes arbitrarily shifted or in some cases rotated due to camera movement or changes in the pose. Images with this kind of dynamic variation would generate a submodule \\cite{SAeron2015,EKernfeld2015}. However, the traditional scalar product is always adopted to represent the linear combination of samples in subspace but lacks of ability to describe the shifted copies in submodule. Therefore, we adopt the t-product \\cite{MEKilmer2011} based on the circular convolution to describe the dynamic character in consecutive images sequences from a submodule. By the t-product, the image data samples will be grouped into a third-order tensor and represented by the proposed tensor low-rank model in terms of the union of free submodules, in which the new affinity information will be used for the final clustering. By the t-product and factorization operations of tensor, we successfully extend the traditional LRR \\cite{GLiu2010} clustering method to the case of multi-way data. The proposed method has been evaluated on both synthetic data and real-world data and outperforms state-of-the-art methods.\n\nThe paper is organized as follows. We introduce the notations and preliminaries about t-product in Section \\ref{Sec:II} and review the related works in Section \\ref{Sec:III}. Section \\ref{Sec:IV} presents the proposed multi-way data clustering method and Section \\ref{Sec:V} is dedicated to solving the optimization problem.   Section \\ref{Sec:VI} assesses the performance of the proposed method on several databases against several state-of-the-art methods. Finally, conclusions are discussed in Section \\ref{Sec:VII}.\n\n\\section{Notations and Preliminaries}\\label{Sec:II}\nIn this section, we will introduce some notations and basic definitions for tensors, and the preliminaries of linear algebra for tensor with t-product used in the proposed method.\n\\subsection{Notations and basic definitions for tensor}\nWe use calligraphy letters for tensors, e.g. $\\mathcal{Y}$, bold lowercase letters for vectors, e.g. $\\mathbf{y}$, bold uppercase for matrices, e.g. $\\mathbf{Y}$, lowercase letters for entries, e.g. $y$, uppercase letters for dimension numbers, e.g. $H, D, L, N$. For convenience, we adopt Matlab notation to denote the elements in tensors. We use $\\mathcal{Y}(:,:,i)$, $\\mathcal{Y}(:,i,:)$ and $\\mathcal{Y}(i,:,:)$ to represent the $i$-th frontal, lateral and horizontal slice, respectively. $\\mathcal{Y}(:,i,j)$, $\\mathcal{Y}(i,:,j)$ and $\\mathcal{Y}(i,j,:)$ represent the mode-1, mode-2 and mode-3 fiber, respectively. We use $\\hat{\\mathcal{Y}}$=fft$(\\mathcal{Y},[\\;],3)$ to denote the Discrete Fourier Transform (DFT) along the third dimension for third order tensor $\\mathcal{Y}$. Also we use $\\mathbf{Y}^{(i)}$ and $\\hat{\\mathbf{Y}}^{(i)}$ to denote the $i$-th frontal slice of $\\mathcal{Y}$ and $\\hat{\\mathcal{Y}}$, respectively, and $\\vec{\\mathbf{Y}}^{(i)}$ as the $i$-th lateral slice of tensor $\\mathcal{Y}$.\n\nIt is necessary to introduce five block-based operators, i.e., bcirc, bvec, bvfold, bdiag and bdfold \\cite{MKilmer2013}. For a tensor $\\mathcal{Y}\\in\\Re^{n_1\\times n_2\\times n_3}$, the $\\mathbf{Y}^{(i)}$ could be used to form the block circulant matrix as below:\n\n", "index": 1, "text": "\\begin{equation}\n\\begin{aligned}\n\\text{bcirc}(\\mathcal{Y})=\\left[\\begin{array}{cccc}\n    \\mathbf{Y}^{(1)} & \\mathbf{Y}^{(n_3)}     & \\cdots & \\mathbf{Y}^{(2)} \\\\\n    \\mathbf{Y}^{(2)} & \\mathbf{Y}^{(1)}       & \\cdots & \\mathbf{Y}^{(3)} \\\\\n    \\vdots            & \\vdots                  & \\ddots & \\vdots            \\\\\n    \\mathbf{Y}^{(n_3)} & \\mathbf{Y}^{(n_3-1)} & \\cdots & \\mathbf{Y}^{(1)} \\\\\n  \\end{array}\\right].\n\\end{aligned}\n\\label{eqt:bcirc}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{bcirc}(\\mathcal{Y})=\\left[\\begin{array}[]{cccc}\\mathbf{Y}^{%&#10;(1)}&amp;\\mathbf{Y}^{(n_{3})}&amp;\\cdots&amp;\\mathbf{Y}^{(2)}\\\\&#10;\\mathbf{Y}^{(2)}&amp;\\mathbf{Y}^{(1)}&amp;\\cdots&amp;\\mathbf{Y}^{(3)}\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;\\mathbf{Y}^{(n_{3})}&amp;\\mathbf{Y}^{(n_{3}-1)}&amp;\\cdots&amp;\\mathbf{Y}^{(1)}\\\\&#10;\\end{array}\\right].\" display=\"inline\"><mrow><mrow><mrow><mtext>bcirc</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>n</mi><mn>3</mn></msub><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr></mtable><mo>]</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nAnd the block diagonal matrix and its opposite operation are\n\n", "itemtype": "equation", "pos": 8715, "prevtext": "\nThe block vectorizing and its opposite operation are\n\n", "index": 3, "text": "\\begin{equation}\n\\begin{aligned}\n\\text{bvec}(\\mathcal{Y})=\\left[\\begin{array}{c}\n    \\mathbf{Y}^{(1)}   \\\\\n    \\mathbf{Y}^{(2)}   \\\\\n    \\vdots              \\\\\n    \\mathbf{Y}^{(n_3)} \\\\\n  \\end{array}\\right],\n\\quad \\text{bvfold}(\\text{bvec}(\\mathcal{Y}))=\\mathcal{Y}.\n\\end{aligned}\n\\label{eqt:bvec_bvfold}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{bvec}(\\mathcal{Y})=\\left[\\begin{array}[]{c}\\mathbf{Y}^{(1)}%&#10;\\\\&#10;\\mathbf{Y}^{(2)}\\\\&#10;\\vdots\\\\&#10;\\mathbf{Y}^{(n_{3})}\\\\&#10;\\end{array}\\right],\\quad\\text{bvfold}(\\text{bvec}(\\mathcal{Y}))=\\mathcal{Y}.\" display=\"inline\"><mrow><mrow><mrow><mrow><mtext>bvec</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>[</mo><mtable rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr></mtable><mo>]</mo></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mtext>bvfold</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mtext>bvec</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\nTo develop our method, we also need some norm definitions for tensor as below:\n\\begin{myDef}\nThe Frobenius norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_F=(\\sum_{i,j,k}\\mathcal{Y}(i,j,k)^2)^{\\frac{1}{2}}$.\n\\label{def:tensor_fnorm}\n\\end{myDef}\n\\begin{myDef}\nThe F1 norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{F1}=\\sum_{i,j}\\|\\mathcal{Y}(i,j,:)\\|_F$.\n\\label{def:tensor_f1norm}\n\\end{myDef}\n\\begin{myDef}\nThe FF1 norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{FF1}=\\sum_{i}\\|\\mathcal{Y}(i,:,:)\\|_F$.\n\\label{def:tensor_ff1norm}\n\\end{myDef}\n\\begin{myDef}\nThe F-Nuclear norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{*f}=\\sum_{i}\\|\\mathcal{Y}(:,:,i)\\|_*$.\n\\label{def:tensor_fnnorm}\n\\end{myDef}\n\\begin{myDef}\nThe F-Infinite norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_\\infty=\\text{max}_{i}\\{\\|\\mathcal{Y}(:,:,i)\\|_{\\infty}\\}$.\n\\label{def:tensor_finorm}\n\\end{myDef}\nIn the above definitions, $\\|\\cdot\\|_F$, $\\|\\cdot\\|_*$ and $\\|\\cdot\\|_{\\infty}$ are matrix Frobenius norm, nuclear norm and maximal infinity norm, respectively.\n\n\\subsection{Linear algebra for tensor with t-product}\nAs described above, we orient an $H\\times D$ image data $\\mathbf{Y}$ by twisting it into the page which will change each image data as a $H\\times 1\\times D$ third order tensor as shown in Figure~\\ref{fig:twist_squeeze} instead of vectorizing from typical clustering methods.\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.29\\textwidth]{fig1}}\n\\caption{The twist and squeeze operations for matrix.}\n\\label{fig:twist_squeeze}\n\\end{figure}\n\nTherefore, an $H\\times D$ matrix image data has been changed as a vector with length of $H$ where each element is a $1\\times 1\\times D$ tube fiber and $N$ image samples will be organized as a $H\\times N\\times D$ tensor $\\mathcal{Y}$. We denote $\\mathbb{K}_D$ as the set of tube fibers with the size of $1\\times 1\\times D$ and $\\mathbb{K}_D^H$ as the set of oriented matrices of size $H\\times 1\\times D$. The first task is to find a method to multiply two tube fibers which means to ``linearly'' combine oriented matrices where the weights are tube fibers and not scalars. In the spirit of \\cite{KBraman2010}, \\textit{the set of oriented matrices could be regarded as a module over the ring $\\mathbb{K}_D$}. Therefore, we adopted the method of t-product proposed in \\cite{MEKilmer2011} to implement the fibers multiplication. It has been proved that the t-product is a useful generalization of matrix multiplication for tensors \\cite{CDMartin2013}. It is generally defined by unfolding tensors into block circulant matrices, multiplying the matrices, and folding the result back up into a three-dimensional array. For 3-way tensors, the t-product is defined as \\cite{MKilmer2013}:\\begin{myDef}\nLet $\\mathcal{X}\\in\\Re^{n_1\\times n_2\\times n_3}$ and $\\mathcal{Y}\\in\\Re^{n_2\\times n_4\\times n_3}$, then the t-product $\\mathcal{X}*\\mathcal{Y}$ is $\\mathcal{M}\\in\\Re^{n_1\\times n_4\\times n_3}$ as follows:\n\n", "itemtype": "equation", "pos": 9096, "prevtext": "\nAnd the block diagonal matrix and its opposite operation are\n\n", "index": 5, "text": "\\begin{equation}\n\\begin{aligned}\n&\\text{bdiag}(\\mathcal{Y})=\\left[\\begin{array}{cccc}\n    \\mathbf{Y}^{(1)} &&&  \\\\\n    & \\mathbf{Y}^{(2)} &&  \\\\\n    && \\ddots &  \\\\\n    &&& \\mathbf{Y}^{(n_3)} \\\\\n  \\end{array}\\right],\\\\\n&\\text{bdfold}(\\text{bdiag}(\\mathcal{Y}))=\\mathcal{Y}.\n\\end{aligned}\n\\label{eqt:bdiag_bdfold}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{bdiag}(\\mathcal{Y})=\\left[\\begin{array}[]{cccc}\\mathbf{Y}^{%&#10;(1)}&amp;&amp;&amp;\\\\&#10;&amp;\\mathbf{Y}^{(2)}&amp;&amp;\\\\&#10;&amp;&amp;\\ddots&amp;\\\\&#10;&amp;&amp;&amp;\\mathbf{Y}^{(n_{3})}\\\\&#10;\\end{array}\\right],\" display=\"inline\"><mrow><mrow><mrow><mtext>bdiag</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd/><mtd/><mtd/></mtr><mtr><mtd/><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup></mtd><mtd/><mtd/></mtr><mtr><mtd/><mtd/><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd/></mtr><mtr><mtd/><mtd/><mtd/><mtd columnalign=\"center\"><msup><mi>\ud835\udc18</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></msup></mtd></mtr></mtable><mo>]</mo></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{bdfold}(\\text{bdiag}(\\mathcal{Y}))=\\mathcal{Y}.\" display=\"inline\"><mrow><mrow><mrow><mtext>bdfold</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mtext>bdiag</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $*$ denotes the circular convolution.\n\\end{myDef}\nThe t-product is analogous to the matrix multiplication except that the circular convolution replaces the multiplication operation between the elements, which are now mode-3 fibers as follows:\n\n", "itemtype": "equation", "pos": 12374, "prevtext": "\n\nTo develop our method, we also need some norm definitions for tensor as below:\n\\begin{myDef}\nThe Frobenius norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_F=(\\sum_{i,j,k}\\mathcal{Y}(i,j,k)^2)^{\\frac{1}{2}}$.\n\\label{def:tensor_fnorm}\n\\end{myDef}\n\\begin{myDef}\nThe F1 norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{F1}=\\sum_{i,j}\\|\\mathcal{Y}(i,j,:)\\|_F$.\n\\label{def:tensor_f1norm}\n\\end{myDef}\n\\begin{myDef}\nThe FF1 norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{FF1}=\\sum_{i}\\|\\mathcal{Y}(i,:,:)\\|_F$.\n\\label{def:tensor_ff1norm}\n\\end{myDef}\n\\begin{myDef}\nThe F-Nuclear norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_{*f}=\\sum_{i}\\|\\mathcal{Y}(:,:,i)\\|_*$.\n\\label{def:tensor_fnnorm}\n\\end{myDef}\n\\begin{myDef}\nThe F-Infinite norm of a tensor $\\mathcal{Y}$ is $\\|\\mathcal{Y}\\|_\\infty=\\text{max}_{i}\\{\\|\\mathcal{Y}(:,:,i)\\|_{\\infty}\\}$.\n\\label{def:tensor_finorm}\n\\end{myDef}\nIn the above definitions, $\\|\\cdot\\|_F$, $\\|\\cdot\\|_*$ and $\\|\\cdot\\|_{\\infty}$ are matrix Frobenius norm, nuclear norm and maximal infinity norm, respectively.\n\n\\subsection{Linear algebra for tensor with t-product}\nAs described above, we orient an $H\\times D$ image data $\\mathbf{Y}$ by twisting it into the page which will change each image data as a $H\\times 1\\times D$ third order tensor as shown in Figure~\\ref{fig:twist_squeeze} instead of vectorizing from typical clustering methods.\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.29\\textwidth]{fig1}}\n\\caption{The twist and squeeze operations for matrix.}\n\\label{fig:twist_squeeze}\n\\end{figure}\n\nTherefore, an $H\\times D$ matrix image data has been changed as a vector with length of $H$ where each element is a $1\\times 1\\times D$ tube fiber and $N$ image samples will be organized as a $H\\times N\\times D$ tensor $\\mathcal{Y}$. We denote $\\mathbb{K}_D$ as the set of tube fibers with the size of $1\\times 1\\times D$ and $\\mathbb{K}_D^H$ as the set of oriented matrices of size $H\\times 1\\times D$. The first task is to find a method to multiply two tube fibers which means to ``linearly'' combine oriented matrices where the weights are tube fibers and not scalars. In the spirit of \\cite{KBraman2010}, \\textit{the set of oriented matrices could be regarded as a module over the ring $\\mathbb{K}_D$}. Therefore, we adopted the method of t-product proposed in \\cite{MEKilmer2011} to implement the fibers multiplication. It has been proved that the t-product is a useful generalization of matrix multiplication for tensors \\cite{CDMartin2013}. It is generally defined by unfolding tensors into block circulant matrices, multiplying the matrices, and folding the result back up into a three-dimensional array. For 3-way tensors, the t-product is defined as \\cite{MKilmer2013}:\\begin{myDef}\nLet $\\mathcal{X}\\in\\Re^{n_1\\times n_2\\times n_3}$ and $\\mathcal{Y}\\in\\Re^{n_2\\times n_4\\times n_3}$, then the t-product $\\mathcal{X}*\\mathcal{Y}$ is $\\mathcal{M}\\in\\Re^{n_1\\times n_4\\times n_3}$ as follows:\n\n", "index": 7, "text": "\\begin{equation}\n\\mathcal{M}=\\mathcal{X}*\\mathcal{Y}=\\rm{bvfold}(\\rm{bcirc}(\\mathcal{X})\\rm{bvec}(\\mathcal{Y})).\n\\label{eqt:tproduct}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{M}=\\mathcal{X}*\\mathcal{Y}=\\rm{bvfold}(\\rm{bcirc}(\\mathcal{X})\\rm{%&#10;bvec}(\\mathcal{Y})).\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mo>=</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi></mrow><mo>=</mo><mrow><mi>bvfold</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>bcirc</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>bvec</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nThe t-product could be efficiently computed by using the FFT \\cite{MEKilmer2011}. Therefore, the t-product in the original domain corresponds to the matrix multiplication of the frontal slices in the Fourier domain as follows:\n\n", "itemtype": "equation", "pos": 12772, "prevtext": "\nwhere $*$ denotes the circular convolution.\n\\end{myDef}\nThe t-product is analogous to the matrix multiplication except that the circular convolution replaces the multiplication operation between the elements, which are now mode-3 fibers as follows:\n\n", "index": 9, "text": "\\begin{equation}\n\\mathcal{M}(i,j,:)=\\sum_{k=1}^{n_2}\\mathcal{X}(i,k,:)*\\mathcal{Y}(k,j,:).\n\\label{eqt:tproduct1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{M}(i,j,:)=\\sum_{k=1}^{n_{2}}\\mathcal{X}(i,k,:)*\\mathcal{Y}(k,j,:).\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mn>2</mn></msub></munderover><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>k</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\rm{ifft}(\\hat{\\mathcal{M}},[\\;],3)$ denotes the inverse Fourier Transform along the third dimension of $\\hat{\\mathcal{M}}$. We denote $(\\mathbb{K}_D^H, *)$ as the $\\mathbb{K}_D^H$ equipped with the t-product $*$. Although $(\\mathbb{K}_D^H, *)$ does not form a field because there are non-zero tubes which are not invertible, it does form what is referred to as a ring with unity \\cite{MEKilmer2011}. A module over a ring could be regarded as a generalization of the concept of a vector space over a field, where the corresponding ``scalars'' are the elements of the ring \\cite{EKernfeld2015}. Therefore, the t-product is an appropriate operator to model the orient matrices and have the ``tensor linear (t-linear) combination'' for free submodule.\nThe t-linear combination means a sum of oriented matrices form $\\mathbb{K}_H^D$ multiplied by coefficients from $\\mathbb{K}_D$ shown in Figure~\\ref{fig:t_linear}.\n\\begin{figure}[t]\n\\centering {\\includegraphics[width=0.304\\textwidth]{fig2}}\n\\caption{An illustration of t-linear combination.}\n\\label{fig:t_linear}\n\\end{figure}\n\nAs shown in Figure~\\ref{fig:t_linear}, $\\vec{\\mathbf{Y}}$ represents an oriented matrix image with the size of $H\\times 1\\times D$. $\\mathcal{Y}$ represents the set of $N$ oriented matrix image samples with the size of $H\\times N\\times D$. $\\vec{\\mathbf{C}}$ represents the t-linear combination matrix with the size of $N\\times 1\\times D$ and each $1\\times 1\\times D$ tube fiber in $\\vec{\\mathbf{C}}$ represents the coefficient for oriented matrix image sample $\\vec{\\mathbf{Y}}$ with the t-product.\n\n\\section{Related Work}\\label{Sec:III}\n\nThere is little existing prior work on the submodule clustering of multi-way data, particulary 2D images. Therefore, we will provide an overview of the recent developments in subspace clustering which is closely related to the submodule clustering. Consider a 2D image set $\\mathbb{Y}=\\{\\mathbf{Y}_i\\}_{i=1}^N$, where $\\mathbf{Y}_i\\in\\Re^{H\\times D}$ and $N$ represents the number of image samples. The common preprocessing approach of typical subspace clustering methods is mapping each 2D image sample $\\mathbf{Y}_i$ to 1-D vector $\\mathbf{y}_i$ and form all samples as a matrix, i.e. $\\mathbf{Y} = [\\mathbf{y}_1,..., \\mathbf{y}_N]\\in\\Re^{L\\times N}$, where $\\mathbf{y}_i\\in\\Re^{L},\\,i=1,2,...,N$ and $L=HD$. It is assumed that all these vectors are drawn from a union of $K$ subspaces $\\{\\mathcal{S}_k\\}_{k=1}^K$. The task of subspace clustering or segmentation is to segment the sample set $\\mathbf{Y}$ according to the underlying subspaces.\n\nIn the past decade, sparse and low rank theories have been applied to subspace clustering successfully. Elhamifar and Vidal \\cite{EElhamifar2013} proposed Sparse Subspace Clustering (SSC) method. In this method, the authors aims to find the sparsest representation by using $\\ell_1$ norm. The detailed SSC model is defined as follows:\n\n", "itemtype": "equation", "pos": 13127, "prevtext": "\nThe t-product could be efficiently computed by using the FFT \\cite{MEKilmer2011}. Therefore, the t-product in the original domain corresponds to the matrix multiplication of the frontal slices in the Fourier domain as follows:\n\n", "index": 11, "text": "\\begin{equation}\n\\hat{\\mathbf{M}}^{(i)}=\\hat{\\mathbf{X}}^{(i)}\\hat{\\mathbf{Y}}^{(i)},\\;\\;\\;\\;\n\\mathcal{M}=\\rm{ifft}(\\hat{\\mathcal{M}},[\\;],3).\n\\label{eqt:tproduct_fft}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\hat{\\mathbf{M}}^{(i)}=\\hat{\\mathbf{X}}^{(i)}\\hat{\\mathbf{Y}}^{(i)},\\;\\;\\;\\;%&#10;\\mathcal{M}=\\rm{ifft}(\\hat{\\mathcal{M}},[\\;],3).\" display=\"block\"><mrow><mrow><mrow><msup><mover accent=\"true\"><mi>\ud835\udc0c</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc17</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mrow><mo rspace=\"13.7pt\">,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mo>=</mo><mrow><mi>ifft</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mrow><mo rspace=\"5.3pt\" stretchy=\"false\">[</mo><mo stretchy=\"false\">]</mo></mrow><mo>,</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathbf{Z}$ represents the Gaussian noise, $\\mathbf{E}$ is high magnitude sparse noise and $\\mathbf{C}$ represents the affinity matrix. The learned   $\\mathbf{C}$ can be used for final clustering by NCut \\cite{JShi2000}.\n\nInstead of sparse representation, Liu \\emph{et al.} \\cite{GLiu2010}  proposed LRR method for clustering by using low rank constraint or nuclear norm $\\|\\cdot\\|_*$ for the coefficient matrix. The general LRR model is shown as follows:\n\n", "itemtype": "equation", "pos": 16214, "prevtext": "\nwhere $\\rm{ifft}(\\hat{\\mathcal{M}},[\\;],3)$ denotes the inverse Fourier Transform along the third dimension of $\\hat{\\mathcal{M}}$. We denote $(\\mathbb{K}_D^H, *)$ as the $\\mathbb{K}_D^H$ equipped with the t-product $*$. Although $(\\mathbb{K}_D^H, *)$ does not form a field because there are non-zero tubes which are not invertible, it does form what is referred to as a ring with unity \\cite{MEKilmer2011}. A module over a ring could be regarded as a generalization of the concept of a vector space over a field, where the corresponding ``scalars'' are the elements of the ring \\cite{EKernfeld2015}. Therefore, the t-product is an appropriate operator to model the orient matrices and have the ``tensor linear (t-linear) combination'' for free submodule.\nThe t-linear combination means a sum of oriented matrices form $\\mathbb{K}_H^D$ multiplied by coefficients from $\\mathbb{K}_D$ shown in Figure~\\ref{fig:t_linear}.\n\\begin{figure}[t]\n\\centering {\\includegraphics[width=0.304\\textwidth]{fig2}}\n\\caption{An illustration of t-linear combination.}\n\\label{fig:t_linear}\n\\end{figure}\n\nAs shown in Figure~\\ref{fig:t_linear}, $\\vec{\\mathbf{Y}}$ represents an oriented matrix image with the size of $H\\times 1\\times D$. $\\mathcal{Y}$ represents the set of $N$ oriented matrix image samples with the size of $H\\times N\\times D$. $\\vec{\\mathbf{C}}$ represents the t-linear combination matrix with the size of $N\\times 1\\times D$ and each $1\\times 1\\times D$ tube fiber in $\\vec{\\mathbf{C}}$ represents the coefficient for oriented matrix image sample $\\vec{\\mathbf{Y}}$ with the t-product.\n\n\\section{Related Work}\\label{Sec:III}\n\nThere is little existing prior work on the submodule clustering of multi-way data, particulary 2D images. Therefore, we will provide an overview of the recent developments in subspace clustering which is closely related to the submodule clustering. Consider a 2D image set $\\mathbb{Y}=\\{\\mathbf{Y}_i\\}_{i=1}^N$, where $\\mathbf{Y}_i\\in\\Re^{H\\times D}$ and $N$ represents the number of image samples. The common preprocessing approach of typical subspace clustering methods is mapping each 2D image sample $\\mathbf{Y}_i$ to 1-D vector $\\mathbf{y}_i$ and form all samples as a matrix, i.e. $\\mathbf{Y} = [\\mathbf{y}_1,..., \\mathbf{y}_N]\\in\\Re^{L\\times N}$, where $\\mathbf{y}_i\\in\\Re^{L},\\,i=1,2,...,N$ and $L=HD$. It is assumed that all these vectors are drawn from a union of $K$ subspaces $\\{\\mathcal{S}_k\\}_{k=1}^K$. The task of subspace clustering or segmentation is to segment the sample set $\\mathbf{Y}$ according to the underlying subspaces.\n\nIn the past decade, sparse and low rank theories have been applied to subspace clustering successfully. Elhamifar and Vidal \\cite{EElhamifar2013} proposed Sparse Subspace Clustering (SSC) method. In this method, the authors aims to find the sparsest representation by using $\\ell_1$ norm. The detailed SSC model is defined as follows:\n\n", "index": 13, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathbf{C,E,Z}}\\quad&\\|\\mathbf{C}\\|_1+\\lambda_e\\|\\mathbf{E}\\|_1+\\frac{\\lambda_z}{2}\\|\\mathbf{Z}\\|_F^2,\\\\\n\\text{s.t.}\\quad&\\mathbf{Y=YC+E+Z},\\,\\text{diag}(\\mathbf{C})=\\mathbf{0}.\n\\end{aligned}\n\\label{eqt:ssc}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathbf{C,E,Z}}\" display=\"inline\"><munder><mi>min</mi><mrow><mi>\ud835\udc02</mi><mo>,</mo><mi>\ud835\udc04</mi><mo>,</mo><mi>\ud835\udc19</mi></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\|\\mathbf{C}\\|_{1}+\\lambda_{e}\\|\\mathbf{E}\\|_{1}+\\frac{\\lambda_{z%&#10;}}{2}\\|\\mathbf{Z}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mi>\ud835\udc02</mi><mo>\u2225</mo></mrow><mn>1</mn></msub><mo>+</mo><mrow><msub><mi>\u03bb</mi><mi>e</mi></msub><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi>\ud835\udc04</mi><mo>\u2225</mo></mrow><mn>1</mn></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03bb</mi><mi>z</mi></msub><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mi>\ud835\udc19</mi><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7Xa.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{Y=YC+E+Z},\\,\\text{diag}(\\mathbf{C})=\\mathbf{0}.\" display=\"inline\"><mrow><mrow><mrow><mi>\ud835\udc18</mi><mo>=</mo><mrow><mi>\ud835\udc18\ud835\udc02</mi><mo>+</mo><mi>\ud835\udc04</mi><mo>+</mo><mi>\ud835\udc19</mi></mrow></mrow><mo rspace=\"4.2pt\">,</mo><mrow><mrow><mtext>diag</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc02</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn/></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\|\\cdot\\|_{2,1}$ represents the $\\ell_{2,1}$ norm which is used to improve the robustness of the model for gross noise and data outliers. Furthermore, researchers extended SSC and LRR by introducing some other extra penalty terms to model the spatial correlation between sample data. Tierney \\emph{et al.} \\cite{STierney2014} proposed Ordered Subspace Clustering (OSC) method which provides a more robust model to deal with the sequential data clustering problem. Zhang \\emph{et al.} \\cite{HZhang2014} proposed a Robust latent low rank representation (RobustLatLRR) method for subspace clustering. After learning the coefficient matrix, we could construct an affinity matrix to simulate the similarity among data. Then the affinity matrix could be used in the followup spectral clustering.\n\nAlthough these vector subspace clustering methods have achieved lots of success, the development of multi-way representation method \\cite{KBraman2010} makes a more promised way to the multi-way data clustering. Recently, the t-product has been adopted as an advantageous generalization of matrix multiplication for third or higher order tensors \\cite{MKilmer2013,CDMartin2013}. It has also been applied in some image applications successfully, i.e. face recognition \\cite{NHao2013} and video completion \\cite{WHu2015}. Kernfeld \\emph{et al.}  \\cite{EKernfeld2015} used t-product for 2D images clustering by keeping the matrix structure and proposed a Sparse Submodule Clustering method (SSmC). This is the most related work to this study. The general SSmC model is defined as follows:\n\n", "itemtype": "equation", "pos": 16939, "prevtext": "\nwhere $\\mathbf{Z}$ represents the Gaussian noise, $\\mathbf{E}$ is high magnitude sparse noise and $\\mathbf{C}$ represents the affinity matrix. The learned   $\\mathbf{C}$ can be used for final clustering by NCut \\cite{JShi2000}.\n\nInstead of sparse representation, Liu \\emph{et al.} \\cite{GLiu2010}  proposed LRR method for clustering by using low rank constraint or nuclear norm $\\|\\cdot\\|_*$ for the coefficient matrix. The general LRR model is shown as follows:\n\n", "index": 15, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathbf{C,E}}\\quad&\\|\\mathbf{C}\\|_*+\\lambda\\|\\mathbf{E}\\|_{2,1}, \\;\\;\n\\text{s.t.}\\quad\\mathbf{Y=YC+E}.\n\\end{aligned}\n\\label{eqt:lrr}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathbf{C,E}}\" display=\"inline\"><munder><mi>min</mi><mrow><mi>\ud835\udc02</mi><mo>,</mo><mi>\ud835\udc04</mi></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\|\\mathbf{C}\\|_{*}+\\lambda\\|\\mathbf{E}\\|_{2,1},\\;\\;\\text{s.t.}%&#10;\\quad\\mathbf{Y=YC+E}.\" display=\"inline\"><mrow><mrow><mrow><mrow><msub><mrow><mo>\u2225</mo><mi>\ud835\udc02</mi><mo>\u2225</mo></mrow><mo>*</mo></msub><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi>\ud835\udc04</mi><mo>\u2225</mo></mrow><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub></mrow></mrow><mo rspace=\"8.1pt\">,</mo><mtext>s.t.</mtext><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mi>\ud835\udc18</mi></mrow><mo>=</mo><mrow><mi>\ud835\udc18\ud835\udc02</mi><mo>+</mo><mi>\ud835\udc04</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathcal{Y}$ is a tensor with 2D image samples, $\\mathcal{C}$ is affinity tensor, $*$ denotes the t-product, $\\|\\cdot\\|_{F1}$ and $\\|\\cdot\\|_{FF1}$ are the tensor sparse norms extended from matrix sparse norms as described in Section \\ref{Sec:II}. Compared with the conventional subspace clustering methods,  SSmC has\nthe most significant advantage of keeping the 2D structure\nfor images instead of mapping them to vectors and adopts t-product to multiplying two matrices instead of scalar product. However, SSmC considers the sparse structure only and ignores the inner correlation of image samples from the same submodule. To explore  such inner correlation, we extend the low-rank structure for tensors and  utilize the t-product operation\nto construct a submodule clustering method. The new method offers good clustering results as demonstrated in experiments.\n\n\\section{Submodule Clustering by Sparse and Low-Rank Representation}\\label{Sec:IV}\nIn this section, we describe the proposed method in detail. As described above, we assume all the oriented matrix data are lying on a union of disjoint free submodules instead of subspace. Our goal is to find these submodules and group the data into their respective clusters. We denote $\\mathcal{Y}$ as the 2D matrix image samples tensor with the size of $H\\times N\\times D$, which is obtained by twisting each $H\\times D$ image sample into a $H\\times 1\\times D$ tensor. Further  denote by $\\mathcal{C}$  the t-linear combination tensor of size of $N\\times N\\times D$ which is used to represent the samples tensor $\\mathcal{Y}$ itself by minimizing the error $\\|\\mathcal{Y-Y*C}\\|_F^2$. Under the t-linear combination of tensors specified in Definitions \\ref{def:tensor_fnorm} to \\ref{def:tensor_fnnorm},  we extend the sparse and low-rank representations for tensors.\nThe sparse t-linear combination model for 2D images submodule clustering, which is similar to \\cite{EKernfeld2015}, is defined as follows:\n\n", "itemtype": "equation", "pos": 18709, "prevtext": "\nwhere $\\|\\cdot\\|_{2,1}$ represents the $\\ell_{2,1}$ norm which is used to improve the robustness of the model for gross noise and data outliers. Furthermore, researchers extended SSC and LRR by introducing some other extra penalty terms to model the spatial correlation between sample data. Tierney \\emph{et al.} \\cite{STierney2014} proposed Ordered Subspace Clustering (OSC) method which provides a more robust model to deal with the sequential data clustering problem. Zhang \\emph{et al.} \\cite{HZhang2014} proposed a Robust latent low rank representation (RobustLatLRR) method for subspace clustering. After learning the coefficient matrix, we could construct an affinity matrix to simulate the similarity among data. Then the affinity matrix could be used in the followup spectral clustering.\n\nAlthough these vector subspace clustering methods have achieved lots of success, the development of multi-way representation method \\cite{KBraman2010} makes a more promised way to the multi-way data clustering. Recently, the t-product has been adopted as an advantageous generalization of matrix multiplication for third or higher order tensors \\cite{MKilmer2013,CDMartin2013}. It has also been applied in some image applications successfully, i.e. face recognition \\cite{NHao2013} and video completion \\cite{WHu2015}. Kernfeld \\emph{et al.}  \\cite{EKernfeld2015} used t-product for 2D images clustering by keeping the matrix structure and proposed a Sparse Submodule Clustering method (SSmC). This is the most related work to this study. The general SSmC model is defined as follows:\n\n", "index": 17, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathcal{C}}\\quad&\\|\\mathcal{C}\\|_{F1}+\\lambda_h\\|\\mathcal{C}\\|_{FF1}+\\lambda_g\\|\\mathcal{Y-Y*C}\\|_F^2,\\\\\n\\text{s.t.}\\quad&\\mathcal{C}(i,i,k)=0,\n\\end{aligned}\n\\label{eqt:ssmc}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathcal{C}}\" display=\"inline\"><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\|\\mathcal{C}\\|_{F1}+\\lambda_{h}\\|\\mathcal{C}\\|_{FF1}+\\lambda_{g}%&#10;\\|\\mathcal{Y-Y*C}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><msub><mi>\u03bb</mi><mi>h</mi></msub><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><msub><mi>\u03bb</mi><mi>g</mi></msub><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9Xa.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{C}(i,i,k)=0,\" display=\"inline\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\alpha$ is a tunable parameter. Under the $F1$ norm, the model enforces that each oriented 2D image matrix can be sparsely represented as a t-linear representation by all other oriented 2D images. Similar to the sparse subspace representations, the non-zero fibers in $\\mathcal{C}$ correspond to the samples from the same submodule and the zero ones from the samples from different submodules. We have an illustration of sparse t-linear combination for one sample shown in Figure~\\ref{fig:sparse_t_linear}:\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.33\\textwidth]{fig3}}\n\\caption{An illustration of sparse t-linear combination. The samples with same color in $\\mathcal{Y}$ are from the same submodule. The white tube fibers in $\\vec{\\mathbf{C}}$ represent the zeros fibers.}\n\\label{fig:sparse_t_linear}\n\\end{figure}\n\nAs demonstrated in Figure~\\ref{fig:sparse_t_linear}, model \\eqref{eqt:sparse_smc} is equivalent to a number of individual models. To further explore intrinsic correlation information among the entire dataset, inspired by the LRR \\cite{GLiu2010},  we propose the following new sparse and low-rank submodule clustering model:\n\n", "itemtype": "equation", "pos": 20903, "prevtext": "\nwhere $\\mathcal{Y}$ is a tensor with 2D image samples, $\\mathcal{C}$ is affinity tensor, $*$ denotes the t-product, $\\|\\cdot\\|_{F1}$ and $\\|\\cdot\\|_{FF1}$ are the tensor sparse norms extended from matrix sparse norms as described in Section \\ref{Sec:II}. Compared with the conventional subspace clustering methods,  SSmC has\nthe most significant advantage of keeping the 2D structure\nfor images instead of mapping them to vectors and adopts t-product to multiplying two matrices instead of scalar product. However, SSmC considers the sparse structure only and ignores the inner correlation of image samples from the same submodule. To explore  such inner correlation, we extend the low-rank structure for tensors and  utilize the t-product operation\nto construct a submodule clustering method. The new method offers good clustering results as demonstrated in experiments.\n\n\\section{Submodule Clustering by Sparse and Low-Rank Representation}\\label{Sec:IV}\nIn this section, we describe the proposed method in detail. As described above, we assume all the oriented matrix data are lying on a union of disjoint free submodules instead of subspace. Our goal is to find these submodules and group the data into their respective clusters. We denote $\\mathcal{Y}$ as the 2D matrix image samples tensor with the size of $H\\times N\\times D$, which is obtained by twisting each $H\\times D$ image sample into a $H\\times 1\\times D$ tensor. Further  denote by $\\mathcal{C}$  the t-linear combination tensor of size of $N\\times N\\times D$ which is used to represent the samples tensor $\\mathcal{Y}$ itself by minimizing the error $\\|\\mathcal{Y-Y*C}\\|_F^2$. Under the t-linear combination of tensors specified in Definitions \\ref{def:tensor_fnorm} to \\ref{def:tensor_fnnorm},  we extend the sparse and low-rank representations for tensors.\nThe sparse t-linear combination model for 2D images submodule clustering, which is similar to \\cite{EKernfeld2015}, is defined as follows:\n\n", "index": 19, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathcal{C}}\\quad&\\alpha\\|\\mathcal{C}\\|_{F1}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2.\\\\\n\\end{aligned}\n\\label{eqt:sparse_smc}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathcal{C}}\" display=\"inline\"><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\\|\\mathcal{C}\\|_{F1}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_{F}^{2}.\" display=\"inline\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\nIn this model, we adopt the $F$-nuclear norm, see Definition \\ref{def:tensor_fnnorm}, which is extended from the nuclear norm for t-linear combination. In clustering applications, the number of samples is much larger than the number of classes. So there exists high correlation within the samples. In many typical clustering methods, such as LRR and RobustLatLRR, researchers always use low-rank constraint for the representation matrix to express the inner correlation for samples. The nuclear norm is the most suitable substitute for low-rank constraint. In the case of submodule clustering, we cannot directly use the nuclear norm for t-linear representation tensor, but use the $F$-nuclear norm defined in Definition \\ref{def:tensor_fnnorm} instead. With the $F$-nuclear norm, the low-rank constraint has been adopted for each frontal slice from the representation tensor $\\mathcal{C}$. Therefore, the entries could be constrained with high correlation.\nFigure~\\ref{fig:lowrank_t_linear} illustrates low-rank t-linear combination.\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{fig4}}\n\\caption{An illustration of low-rank t-linear combination. The samples with same color in $\\mathcal{Y}$ are from the same submodule. The white tube fibers in $\\mathcal{C}$ represent the zeros fibers.}\n\\label{fig:lowrank_t_linear}\n\\end{figure}\n\nFurthermore, we should eliminate the self-correlation for each sample in the t-linear combination. Therefore, we add the zero-constraint for the diagonal fibers in the  representation tensor. Finally, we  obtain a completed sparse and low-rank submodule clustering model as follows,\n\n", "itemtype": "equation", "pos": 22237, "prevtext": "\nwhere $\\alpha$ is a tunable parameter. Under the $F1$ norm, the model enforces that each oriented 2D image matrix can be sparsely represented as a t-linear representation by all other oriented 2D images. Similar to the sparse subspace representations, the non-zero fibers in $\\mathcal{C}$ correspond to the samples from the same submodule and the zero ones from the samples from different submodules. We have an illustration of sparse t-linear combination for one sample shown in Figure~\\ref{fig:sparse_t_linear}:\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.33\\textwidth]{fig3}}\n\\caption{An illustration of sparse t-linear combination. The samples with same color in $\\mathcal{Y}$ are from the same submodule. The white tube fibers in $\\vec{\\mathbf{C}}$ represent the zeros fibers.}\n\\label{fig:sparse_t_linear}\n\\end{figure}\n\nAs demonstrated in Figure~\\ref{fig:sparse_t_linear}, model \\eqref{eqt:sparse_smc} is equivalent to a number of individual models. To further explore intrinsic correlation information among the entire dataset, inspired by the LRR \\cite{GLiu2010},  we propose the following new sparse and low-rank submodule clustering model:\n\n", "index": 21, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathcal{C}}\\quad&\\alpha\\|\\mathcal{C}\\|_{F1}+\\lambda\\|\\mathcal{C}\\|_{*f}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2.\\\\\n\\end{aligned}\n\\label{eqt:sparse_lowrank_smc}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathcal{C}}\" display=\"inline\"><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\\|\\mathcal{C}\\|_{F1}+\\lambda\\|\\mathcal{C}\\|_{*f}+\\frac{1}{2%&#10;}\\|\\mathcal{Y-Y*C}\\|_{F}^{2}.\" display=\"inline\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\nWe call \\eqref{eqt:SLRSmC} the Sparse and Low-Rank Submodule Clustering (SLRSmC) Method based on t-product. Compared with the majority of existing clustering methods, the most significant difference is that we keep the 2D matrix structure of image samples and cluster them in terms of submodules. In addition, we adopt $F1$ and $F$-nuclear norms for t-linear combination. After solving the above model and obtaining the t-linear combination tensor $\\mathcal{C}$, we build the following affinity matrix $\\mathbf{W}$\u00a3\u00ba\n\n", "itemtype": "equation", "pos": 24086, "prevtext": "\n\nIn this model, we adopt the $F$-nuclear norm, see Definition \\ref{def:tensor_fnnorm}, which is extended from the nuclear norm for t-linear combination. In clustering applications, the number of samples is much larger than the number of classes. So there exists high correlation within the samples. In many typical clustering methods, such as LRR and RobustLatLRR, researchers always use low-rank constraint for the representation matrix to express the inner correlation for samples. The nuclear norm is the most suitable substitute for low-rank constraint. In the case of submodule clustering, we cannot directly use the nuclear norm for t-linear representation tensor, but use the $F$-nuclear norm defined in Definition \\ref{def:tensor_fnnorm} instead. With the $F$-nuclear norm, the low-rank constraint has been adopted for each frontal slice from the representation tensor $\\mathcal{C}$. Therefore, the entries could be constrained with high correlation.\nFigure~\\ref{fig:lowrank_t_linear} illustrates low-rank t-linear combination.\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{fig4}}\n\\caption{An illustration of low-rank t-linear combination. The samples with same color in $\\mathcal{Y}$ are from the same submodule. The white tube fibers in $\\mathcal{C}$ represent the zeros fibers.}\n\\label{fig:lowrank_t_linear}\n\\end{figure}\n\nFurthermore, we should eliminate the self-correlation for each sample in the t-linear combination. Therefore, we add the zero-constraint for the diagonal fibers in the  representation tensor. Finally, we  obtain a completed sparse and low-rank submodule clustering model as follows,\n\n", "index": 23, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathcal{C}}\\quad&\\alpha\\|\\mathcal{C}\\|_{F1}+\\lambda\\|\\mathcal{C}\\|_{*f}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2,\\\\\n\\text{s.t.}\\quad&\\mathcal{C}(i,i,k)=0.\n\\end{aligned}\n\\label{eqt:SLRSmC}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathcal{C}}\" display=\"inline\"><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\\|\\mathcal{C}\\|_{F1}+\\lambda\\|\\mathcal{C}\\|_{*f}+\\frac{1}{2%&#10;}\\|\\mathcal{Y-Y*C}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12Xa.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{C}(i,i,k)=0.\" display=\"inline\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhich can be pipelined into the NCut to\nobtain final clustering results.\nIn the next section, we will propose an efficient algorithm to solve the optimization problem \\eqref{eqt:SLRSmC}.\n\n\\section{Optimization}\\label{Sec:V}\nTo solve problem \\eqref{eqt:SLRSmC}, we adopt an alternating direction method by dividing \\eqref{eqt:SLRSmC} into several subproblems. First, we introduce two auxiliary variables $\\mathcal{Z=C}$ and $\\mathcal{X=C}$ to   separate the first two terms in the objective   \\eqref{eqt:SLRSmC}.  The original model could be re-written as follows:\n\n", "itemtype": "equation", "pos": 24841, "prevtext": "\n\nWe call \\eqref{eqt:SLRSmC} the Sparse and Low-Rank Submodule Clustering (SLRSmC) Method based on t-product. Compared with the majority of existing clustering methods, the most significant difference is that we keep the 2D matrix structure of image samples and cluster them in terms of submodules. In addition, we adopt $F1$ and $F$-nuclear norms for t-linear combination. After solving the above model and obtaining the t-linear combination tensor $\\mathcal{C}$, we build the following affinity matrix $\\mathbf{W}$\u00a3\u00ba\n\n", "index": 25, "text": "\\begin{equation}\n\\begin{aligned}\n\\mathbf{W}(i,j)=\\|\\mathcal{C}(i,j,:)\\|_F+\\|\\mathcal{C}(j,i,:)\\|_F\n\\end{aligned}\n\\label{eqt:affinity_matrix}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{W}(i,j)=\\|\\mathcal{C}(i,j,:)\\|_{F}+\\|\\mathcal{C}(j,i,:)\\|%&#10;_{F}\" display=\"inline\"><mrow><mrow><mi>\ud835\udc16</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub><mo>+</mo><msub><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo>,</mo><mi>i</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\nWe adopt the alternating direction method of multipliers (ADMM) \\cite{ZLin2015} to solve the above problem.\nThen the Augmented Lagrangian for the two introduced constraints is\n\n", "itemtype": "equation", "pos": 25561, "prevtext": "\nwhich can be pipelined into the NCut to\nobtain final clustering results.\nIn the next section, we will propose an efficient algorithm to solve the optimization problem \\eqref{eqt:SLRSmC}.\n\n\\section{Optimization}\\label{Sec:V}\nTo solve problem \\eqref{eqt:SLRSmC}, we adopt an alternating direction method by dividing \\eqref{eqt:SLRSmC} into several subproblems. First, we introduce two auxiliary variables $\\mathcal{Z=C}$ and $\\mathcal{X=C}$ to   separate the first two terms in the objective   \\eqref{eqt:SLRSmC}.  The original model could be re-written as follows:\n\n", "index": 27, "text": "\\begin{equation}\n\\begin{aligned}\n\\min_{\\mathcal{Z, X, C}}\\quad&\\alpha\\|\\mathcal{X}\\|_{F1}+\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2,\\\\\n\\text{s.t.}\\quad&\\mathcal{X}(i,i,k)=0, \\mathcal{X=C}, \\mathcal{Z=C}.\n\\end{aligned}\\label{eqt:eq2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\min_{\\mathcal{Z,X,C}}\" display=\"inline\"><munder><mi>min</mi><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14X.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\\|\\mathcal{X}\\|_{F1}+\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{1}{2%&#10;}\\|\\mathcal{Y-Y*C}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14Xa.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{X}(i,i,k)=0,\\mathcal{X=C},\\mathcal{Z=C}.\" display=\"inline\"><mrow><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>,</mo><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\langle\\mathcal{A}, \\mathcal{B}\\rangle=\\sum_i\\text{tr}(\\mathbf{A}^{(i)^T}\\mathbf{B}^{(i)})$, $\\mathcal{G}_1$ and $\\mathcal{G}_2$ are Lagrange multipliers and $\\gamma>0$ is a penalty parameter. Therefore, the overall algorithm can be decomposed into solving three subproblems:\n\n{\\bf 1. Updating $\\mathcal{X}$ with fixed $\\mathcal{Z}$ and $\\mathcal{C}$}\n\n", "itemtype": "equation", "pos": 26007, "prevtext": "\n\nWe adopt the alternating direction method of multipliers (ADMM) \\cite{ZLin2015} to solve the above problem.\nThen the Augmented Lagrangian for the two introduced constraints is\n\n", "index": 29, "text": "\\begin{align}\n\\mathcal{L}(\\mathcal{X, Z, C})=&\\alpha\\|\\mathcal{X}\\|_{F1}+\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2\\notag\\\\\n&+\\langle\\mathcal{G}_1, \\mathcal{Z-X}\\rangle+\\langle\\mathcal{G}_2,\\mathcal{X-C}\\rangle\\notag\\\\\n&+\\frac{\\gamma}{2}(\\|\\mathcal{Z-C}\\|_F^2+\\|\\mathcal{X-C}\\|_F^2), \\notag\\\\\n\\text{s.t.}\\quad&\\mathcal{X}(i,i,k)=0.\n\\label{eqt:eq3}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{L}(\\mathcal{X,Z,C})=\" display=\"inline\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\\|\\mathcal{X}\\|_{F1}+\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{1}{2%&#10;}\\|\\mathcal{Y-Y*C}\\|_{F}^{2}\" display=\"inline\"><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\langle\\mathcal{G}_{1},\\mathcal{Z-X}\\rangle+\\langle\\mathcal{G}_{%&#10;2},\\mathcal{X-C}\\rangle\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>1</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>2</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\frac{\\gamma}{2}(\\|\\mathcal{Z-C}\\|_{F}^{2}+\\|\\mathcal{X-C}\\|_{F}%&#10;^{2}),\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{X}(i,i,k)=0.\" display=\"inline\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathcal{A}=\\mathcal{C}-\\frac{\\mathcal{G}_2}{\\gamma}$. Therefore, we could solve $\\mathcal{X}$ fiber-by-fiber from the third dimension with the constraint of $\\mathcal{X}_{iik}=0$ as follows:\n\n", "itemtype": "equation", "pos": 26746, "prevtext": "\nwhere $\\langle\\mathcal{A}, \\mathcal{B}\\rangle=\\sum_i\\text{tr}(\\mathbf{A}^{(i)^T}\\mathbf{B}^{(i)})$, $\\mathcal{G}_1$ and $\\mathcal{G}_2$ are Lagrange multipliers and $\\gamma>0$ is a penalty parameter. Therefore, the overall algorithm can be decomposed into solving three subproblems:\n\n{\\bf 1. Updating $\\mathcal{X}$ with fixed $\\mathcal{Z}$ and $\\mathcal{C}$}\n\n", "index": 31, "text": "\\begin{align}\n\\mathcal{X}^{t+1}&=\\arg\\min_{\\mathcal{X}}\\alpha\\|\\mathcal{X}\\|_{F1}+\\langle\\mathcal{G}_2,\\mathcal{X-C}\\rangle +\\frac{\\gamma}{2}\\|\\mathcal{X-C}\\|_F^2, \\notag\\\\\n&=\\arg\\min_{\\mathcal{X}}\\alpha\\|\\mathcal{X}\\|_{F1}+\\frac{\\gamma}{2}\\|\\mathcal{X}-\\mathcal{A}\\|_F^2.\n\\label{eqt:solve_x}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{X}^{t+1}\" display=\"inline\"><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\arg\\min_{\\mathcal{X}}\\alpha\\|\\mathcal{X}\\|_{F1}+\\langle\\mathcal%&#10;{G}_{2},\\mathcal{X-C}\\rangle+\\frac{\\gamma}{2}\\|\\mathcal{X-C}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi></munder><mo>\u2061</mo><mi>\u03b1</mi></mrow></mrow><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>2</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\arg\\min_{\\mathcal{X}}\\alpha\\|\\mathcal{X}\\|_{F1}+\\frac{\\gamma}{2%&#10;}\\|\\mathcal{X}-\\mathcal{A}\\|_{F}^{2}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi></munder><mo>\u2061</mo><mi>\u03b1</mi></mrow></mrow><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2225</mo></mrow><mrow><mi>F</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n{\\bf 2. Updating $\\mathcal{Z}$ with fixed $\\mathcal{X}$ and $\\mathcal{C}$}\n\n", "itemtype": "equation", "pos": 27250, "prevtext": "\nwhere $\\mathcal{A}=\\mathcal{C}-\\frac{\\mathcal{G}_2}{\\gamma}$. Therefore, we could solve $\\mathcal{X}$ fiber-by-fiber from the third dimension with the constraint of $\\mathcal{X}_{iik}=0$ as follows:\n\n", "index": 33, "text": "\\begin{equation}\n      \\mathcal{X}(i,j,:)^{t+1} =\n   \\begin{cases}\n    \\frac{\\|\\mathcal{A}(i,j,:)\\|_F-\\frac{\\alpha}{\\gamma}}{\\|\\mathcal{A}(i,j,:)\\|_F}\\mathcal{A}(i,j,:), & \\text{if } i\\neq j\\, \\text{and}\\\\ &\\|\\mathcal{A}(i,j,:)\\|_F>\\frac{\\alpha}{\\gamma},\\\\\n    0, & \\text{otherwise}.\n    \\end{cases}\n\\label{eqt:solve_xij}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{X}(i,j,:)^{t+1}=\\begin{cases}\\frac{\\|\\mathcal{A}(i,j,:)\\|_{F}-\\frac{%&#10;\\alpha}{\\gamma}}{\\|\\mathcal{A}(i,j,:)\\|_{F}}\\mathcal{A}(i,j,:),&amp;\\text{if }i%&#10;\\neq j\\,\\text{and}\\\\&#10;&amp;\\|\\mathcal{A}(i,j,:)\\|_{F}&gt;\\frac{\\alpha}{\\gamma},\\\\&#10;0,&amp;\\text{otherwise}.\\end{cases}\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mstyle displaystyle=\"false\"><mfrac><mrow><msub><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub><mo>-</mo><mfrac><mi>\u03b1</mi><mi>\u03b3</mi></mfrac></mrow><msub><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub></mfrac></mstyle><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>i</mi></mrow><mo>\u2260</mo><mrow><mpadded width=\"+1.7pt\"><mi>j</mi></mpadded><mo>\u2062</mo><mtext>and</mtext></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mi/></mtd><mtd columnalign=\"left\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mo>:</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi></msub><mo>&gt;</mo><mstyle displaystyle=\"false\"><mfrac><mi>\u03b1</mi><mi>\u03b3</mi></mfrac></mstyle></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mtext>otherwise</mtext><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathcal{B}=\\mathcal{C}-\\frac{\\mathcal{G}_1}{\\gamma}$. Therefore, we could solve $\\mathcal{Z}$ slice-by-slice from the frontal side as follows:\n\n", "itemtype": "equation", "pos": 27663, "prevtext": "\n\n{\\bf 2. Updating $\\mathcal{Z}$ with fixed $\\mathcal{X}$ and $\\mathcal{C}$}\n\n", "index": 35, "text": "\\begin{align}\n\\mathcal{Z}^{t+1}&=\\arg \\min_{\\mathcal{Z}}\\lambda\\|\\mathcal{Z}\\|_{*f}+\\langle\\mathcal{G}_1,\\mathcal{Z-C}\\rangle +\\frac{\\gamma}{2}\\|\\mathcal{Z-C}\\|_F^2,\\notag\\\\\n&=\\arg\\min_{\\mathcal{Z}}\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{\\gamma}{2}\\|\\mathcal{Z}-\\mathcal{B}\\|_F^2.\n \\label{eqt:solve_z}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{Z}^{t+1}\" display=\"inline\"><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\arg\\min_{\\mathcal{Z}}\\lambda\\|\\mathcal{Z}\\|_{*f}+\\langle%&#10;\\mathcal{G}_{1},\\mathcal{Z-C}\\rangle+\\frac{\\gamma}{2}\\|\\mathcal{Z-C}\\|_{F}^{2},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi></munder><mo>\u2061</mo><mi>\u03bb</mi></mrow></mrow><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>1</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\arg\\min_{\\mathcal{Z}}\\lambda\\|\\mathcal{Z}\\|_{*f}+\\frac{\\gamma}{%&#10;2}\\|\\mathcal{Z}-\\mathcal{B}\\|_{F}^{2}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi></munder><mo>\u2061</mo><mi>\u03bb</mi></mrow></mrow><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>\u2225</mo></mrow><mrow><mi/><mo>*</mo><mi>f</mi></mrow></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nThis problem has closed-form solution according to \\cite{JFCai2010}\n\n", "itemtype": "equation", "pos": 28122, "prevtext": "\nwhere $\\mathcal{B}=\\mathcal{C}-\\frac{\\mathcal{G}_1}{\\gamma}$. Therefore, we could solve $\\mathcal{Z}$ slice-by-slice from the frontal side as follows:\n\n", "index": 37, "text": "\\begin{equation}\n\\mathbf{Z}^{(i)^{t+1}}=\\arg\\min_{\\mathbf{Z}^{(i)}}\\lambda\\|\\mathbf{Z}^{(i)}\\|_*+\\frac{\\gamma}{2}\\|\\mathbf{Z}^{(i)}-\\mathbf{B}^{(i)}\\|_F^2.\n\\label{eqt:solve_zi}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{Z}^{(i)^{t+1}}=\\arg\\min_{\\mathbf{Z}^{(i)}}\\lambda\\|\\mathbf{Z}^{(i)}\\|_%&#10;{*}+\\frac{\\gamma}{2}\\|\\mathbf{Z}^{(i)}-\\mathbf{B}^{(i)}\\|_{F}^{2}.\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc19</mi><msup><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></msup><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><msup><mi>\ud835\udc19</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></munder><mo>\u2061</mo><mi>\u03bb</mi></mrow></mrow><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><msup><mi>\ud835\udc19</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><msup><mi>\ud835\udc19</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><msup><mi>\ud835\udc01</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathbf{U\\Sigma V}^T$ is the singular value decomposition (SVD) of $\\mathbf{B}^{(i)}$. $S_{\\frac{\\lambda}{\\gamma}}[\\cdot]$ is the soft-thresholding operator with the following definition:\n\n", "itemtype": "equation", "pos": 28382, "prevtext": "\nThis problem has closed-form solution according to \\cite{JFCai2010}\n\n", "index": 39, "text": "\\begin{equation}\n \\mathbf{Z}^{(i)^{t+1}}=\\mathbf{U}S_{\\frac{\\lambda}{\\gamma}}[\\mathbf{\\Sigma}]\\mathbf{V}^T,\n\\label{eqt:solution_zi}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{Z}^{(i)^{t+1}}=\\mathbf{U}S_{\\frac{\\lambda}{\\gamma}}[\\mathbf{\\Sigma}]%&#10;\\mathbf{V}^{T},\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc19</mi><msup><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></msup><mo>=</mo><mrow><mi>\ud835\udc14</mi><mo>\u2062</mo><msub><mi>S</mi><mfrac><mi>\u03bb</mi><mi>\u03b3</mi></mfrac></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc15</mi><mi>T</mi></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n{\\bf 3. Updating $\\mathcal{C}$ with fixed $\\mathcal{Z}$ and $\\mathcal{X}$}\n\n", "itemtype": "equation", "pos": 28724, "prevtext": "\nwhere $\\mathbf{U\\Sigma V}^T$ is the singular value decomposition (SVD) of $\\mathbf{B}^{(i)}$. $S_{\\frac{\\lambda}{\\gamma}}[\\cdot]$ is the soft-thresholding operator with the following definition:\n\n", "index": 41, "text": "\\begin{equation}\n   S_{\\frac{\\lambda}{\\gamma}}[x] = \\text{sign}(x) \\max\\{|x|-\\frac{\\lambda}{\\gamma}, 0\\}.\n\\label{eqt:soft_thresholding}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"S_{\\frac{\\lambda}{\\gamma}}[x]=\\text{sign}(x)\\max\\{|x|-\\frac{\\lambda}{\\gamma},0\\}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>S</mi><mfrac><mi>\u03bb</mi><mi>\u03b3</mi></mfrac></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mtext>sign</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mo stretchy=\"false\">|</mo></mrow><mo>-</mo><mfrac><mi>\u03bb</mi><mi>\u03b3</mi></mfrac></mrow><mo>,</mo><mn>0</mn><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathcal{P}_1=\\mathcal{Z}+\\frac{\\mathcal{G}_1}{\\gamma}$ and $\\mathcal{P}_2=\\mathcal{X}+\\frac{\\mathcal{G}_2}{\\gamma}$. According to\n\\cite{MEKilmer2011}, we can solve the problem above in Fourier domain.\n\n", "itemtype": "equation", "pos": 28951, "prevtext": "\n\n{\\bf 3. Updating $\\mathcal{C}$ with fixed $\\mathcal{Z}$ and $\\mathcal{X}$}\n\n", "index": 43, "text": "\\begin{align}\n&\\mathcal{C}^{t+1}=\\arg\\min_{\\mathcal{C}}\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2 +\\langle\\mathcal{G}_1,\\mathcal{Z-C}\\rangle\n\\label{eqt:solve_c}\\\\\n&\\;\\;\\;\\;\\;\\;+\\langle\\mathcal{G}_2,\\mathcal{X-C}\\rangle   +\\frac{\\gamma}{2}(\\|\\mathcal{Z-C}\\|_F^2+\\|\\mathcal{X-C}\\|_F^2) \\notag\\\\\n&=\\arg \\min_{\\mathcal{C}}\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_F^2+\\frac{\\gamma}{2}(\\|\\mathcal{C}-\\mathcal{P}_1\\|_F^2 +\\|\\mathcal{C}-\\mathcal{P}_2\\|_F^2). \\notag\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{C}^{t+1}=\\arg\\min_{\\mathcal{C}}\\frac{1}{2}\\|\\mathcal{Y-Y%&#10;*C}\\|_{F}^{2}+\\langle\\mathcal{G}_{1},\\mathcal{Z-C}\\rangle\" display=\"inline\"><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mrow></mrow><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>1</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\;\\;\\;\\;\\;\\;+\\langle\\mathcal{G}_{2},\\mathcal{X-C}\\rangle+\\frac{%&#10;\\gamma}{2}(\\|\\mathcal{Z-C}\\|_{F}^{2}+\\|\\mathcal{X-C}\\|_{F}^{2})\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2004</mi><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>2</mn></msub><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>-</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\arg\\min_{\\mathcal{C}}\\frac{1}{2}\\|\\mathcal{Y-Y*C}\\|_{F}^{2}+%&#10;\\frac{\\gamma}{2}(\\|\\mathcal{C}-\\mathcal{P}_{1}\\|_{F}^{2}+\\|\\mathcal{C}-%&#10;\\mathcal{P}_{2}\\|_{F}^{2}).\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mrow></mrow><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo>*</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>-</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mn>1</mn></msub></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>-</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mn>2</mn></msub></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\odot$ represents the face-product. Therefore, we can solve $\\hat{\\mathcal{C}}$ slice-by-slice from the frontal side.\n\n", "itemtype": "equation", "pos": 29612, "prevtext": "\nwhere $\\mathcal{P}_1=\\mathcal{Z}+\\frac{\\mathcal{G}_1}{\\gamma}$ and $\\mathcal{P}_2=\\mathcal{X}+\\frac{\\mathcal{G}_2}{\\gamma}$. According to\n\\cite{MEKilmer2011}, we can solve the problem above in Fourier domain.\n\n", "index": 45, "text": "\\begin{align}\n\\hat{\\mathcal{C}}^{t+1}=\\arg\\min_{\\hat{\\mathcal{C}}}&\\frac{1}{2}\\|\\hat{\\mathcal{Y}}-\\hat{\\mathcal{Y}}\\odot\\hat{\\mathcal{C}}\\|_F^2+\\frac{\\gamma}{2}(\\|\\hat{\\mathcal{C}}-\\hat{\\mathcal{P}}_1\\|_F^2 \\notag\\\\\n&+\\|\\hat{\\mathcal{C}}-\\hat{\\mathcal{P}}_2\\|_F^2). \\label{eqt:solve_c_hat}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\mathcal{C}}^{t+1}=\\arg\\min_{\\hat{\\mathcal{C}}}\" display=\"inline\"><mrow><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi><mo>\u2061</mo><munder><mi>min</mi><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover></munder></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\frac{1}{2}\\|\\hat{\\mathcal{Y}}-\\hat{\\mathcal{Y}}\\odot\\hat{%&#10;\\mathcal{C}}\\|_{F}^{2}+\\frac{\\gamma}{2}(\\|\\hat{\\mathcal{C}}-\\hat{\\mathcal{P}}_%&#10;{1}\\|_{F}^{2}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2225</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">^</mo></mover><mo>-</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2299</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover><msubsup><mo>\u2225</mo><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mrow><mo stretchy=\"false\">(</mo><mo>\u2225</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover><mo>-</mo><msub><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub><msubsup><mo>\u2225</mo><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\|\\hat{\\mathcal{C}}-\\hat{\\mathcal{P}}_{2}\\|_{F}^{2}).\" display=\"inline\"><mrow><mo>+</mo><mo>\u2225</mo><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover><mo>-</mo><msub><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><msubsup><mo>\u2225</mo><mi>F</mi><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\nLet $f(\\hat{\\mathbf{C}}^{(i)})=\\frac{1}{2}\\|\\hat{\\mathbf{Y}}^{(i)}-\\hat{\\mathbf{Y}}^{(i)}\\hat{\\mathbf{C}}^{(i)}\\|_F^2+\\frac{\\gamma}{2}(\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_1^{(i)}\\|_F^2+\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_2^{(i)}\\|_F^2)$ and set $\\frac{\\partial f}{\\partial \\hat{\\mathbf{C}}^{(i)}}=0$, we have:\n\n", "itemtype": "equation", "pos": 30039, "prevtext": "\nwhere $\\odot$ represents the face-product. Therefore, we can solve $\\hat{\\mathcal{C}}$ slice-by-slice from the frontal side.\n\n", "index": 47, "text": "\\begin{align}\n\\hat{\\mathbf{C}}^{(i)^{t+1}}=& \\arg\\min_{\\hat{\\mathbf{C}}^{(i)}} \\frac{1}{2}\\|\\hat{\\mathbf{Y}}^{(i)}-\\hat{\\mathbf{Y}}^{(i)}\\hat{\\mathbf{C}}^{(i)}\\|_F^2\\label{eqt:solve_ci_hat}\\\\\n&+\\frac{\\gamma}{2}(\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_1^{(i)}\\|_F^2+\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_2^{(i)}\\|_F^2). \\notag\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\mathbf{C}}^{(i)^{t+1}}=\" display=\"inline\"><mrow><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><msup><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></msup><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\arg\\min_{\\hat{\\mathbf{C}}^{(i)}}\\frac{1}{2}\\|\\hat{\\mathbf{Y}}^{(%&#10;i)}-\\hat{\\mathbf{Y}}^{(i)}\\hat{\\mathbf{C}}^{(i)}\\|_{F}^{2}\" display=\"inline\"><mrow><mrow><mi>arg</mi><mo>\u2061</mo><mrow><munder><mi>min</mi><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></munder><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mrow></mrow><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\frac{\\gamma}{2}(\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_{1}^{%&#10;(i)}\\|_{F}^{2}+\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_{2}^{(i)}\\|_{F}^{2}).\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b3</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc0f</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><mrow><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>-</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc0f</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\mathbf{I}$ represents identity matrix. After solving each frontal slice of $\\hat{\\mathcal{C}}$, we could get the solution of $\\mathcal{C}$ as follows,\n\n", "itemtype": "equation", "pos": 30706, "prevtext": "\n\nLet $f(\\hat{\\mathbf{C}}^{(i)})=\\frac{1}{2}\\|\\hat{\\mathbf{Y}}^{(i)}-\\hat{\\mathbf{Y}}^{(i)}\\hat{\\mathbf{C}}^{(i)}\\|_F^2+\\frac{\\gamma}{2}(\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_1^{(i)}\\|_F^2+\\|\\hat{\\mathbf{C}}^{(i)}-\\hat{\\mathbf{P}}_2^{(i)}\\|_F^2)$ and set $\\frac{\\partial f}{\\partial \\hat{\\mathbf{C}}^{(i)}}=0$, we have:\n\n", "index": 49, "text": "\\begin{equation}\n\\begin{aligned}\n\\hat{\\mathbf{C}}^{(i)^{t+1}}\n=(\\hat{\\mathbf{Y}}^{(i)T}\\hat{\\mathbf{Y}}^{(i)}+2\\gamma\\mathbf{I})^{-1}\n (\\hat{\\mathbf{Y}}^{(i)T}\\hat{\\mathbf{Y}}^{(i)}+\\gamma(\\hat{\\mathbf{P}}_1^{(i)}+\\hat{\\mathbf{P}}_2^{(i)})).\n\\end{aligned}\n\\label{eqt:solve_ci_hat2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\mathbf{C}}^{(i)^{t+1}}=(\\hat{\\mathbf{Y}}^{(i)T}\\hat{\\mathbf%&#10;{Y}}^{(i)}+2\\gamma\\mathbf{I})^{-1}(\\hat{\\mathbf{Y}}^{(i)T}\\hat{\\mathbf{Y}}^{(i%&#10;)}+\\gamma(\\hat{\\mathbf{P}}_{1}^{(i)}+\\hat{\\mathbf{P}}_{2}^{(i)})).\" display=\"inline\"><mrow><mrow><msup><mover accent=\"true\"><mi>\ud835\udc02</mi><mo stretchy=\"false\">^</mo></mover><msup><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></msup><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>T</mi></mrow></msup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b3</mi><mo>\u2062</mo><mi>\ud835\udc08</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>T</mi></mrow></msup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\ud835\udc18</mi><mo stretchy=\"false\">^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>+</mo><mrow><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mover accent=\"true\"><mi>\ud835\udc0f</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>+</mo><msubsup><mover accent=\"true\"><mi>\ud835\udc0f</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n{\\bf 4. Updating $\\mathcal{G}_1, \\mathcal{G}_2$ and $\\gamma$}\n\n", "itemtype": "equation", "pos": 31162, "prevtext": "\nwhere $\\mathbf{I}$ represents identity matrix. After solving each frontal slice of $\\hat{\\mathcal{C}}$, we could get the solution of $\\mathcal{C}$ as follows,\n\n", "index": 51, "text": "\\begin{equation}\n\\begin{aligned}\n\\mathcal{C}^{t+1}=\\rm{ifft}(\\hat{\\mathcal{C}}^{t+1},[\\;],3).\n\\end{aligned}\n\\label{eqt:solution_c}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{C}^{t+1}=\\rm{ifft}(\\hat{\\mathcal{C}}^{t+1},[\\;],3).\" display=\"inline\"><mrow><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>ifft</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>,</mo><mrow><mo rspace=\"5.3pt\" stretchy=\"false\">[</mo><mo stretchy=\"false\">]</mo></mrow><mo>,</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 31371, "prevtext": "\n\n{\\bf 4. Updating $\\mathcal{G}_1, \\mathcal{G}_2$ and $\\gamma$}\n\n", "index": 53, "text": "\\begin{equation}\n\\begin{aligned}\n\\mathcal{G}_1^{t+1}=\\mathcal{G}_1^t+\\gamma^t(\\mathcal{Z}^{t+1}-\\mathcal{C}^{t+1}).\n\\end{aligned}\n\\label{eqt:update_g1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{G}_{1}^{t+1}=\\mathcal{G}_{1}^{t}+\\gamma^{t}(\\mathcal{Z}^%&#10;{t+1}-\\mathcal{C}^{t+1}).\" display=\"inline\"><mrow><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>1</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>1</mn><mi>t</mi></msubsup><mo>+</mo><mrow><msup><mi>\u03b3</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 31538, "prevtext": "\n\n", "index": 55, "text": "\\begin{equation}\n\\begin{aligned}\n\\mathcal{G}_2^{t+1}=\\mathcal{G}_2^t+\\gamma^t(\\mathcal{X}^{t+1}-\\mathcal{C}^{t+1}).\n\\end{aligned}\n\\label{eqt:update_g2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathcal{G}_{2}^{t+1}=\\mathcal{G}_{2}^{t}+\\gamma^{t}(\\mathcal{X}^%&#10;{t+1}-\\mathcal{C}^{t+1}).\" display=\"inline\"><mrow><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>2</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mn>2</mn><mi>t</mi></msubsup><mo>+</mo><mrow><msup><mi>\u03b3</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\nwhere $\\rho>1$ is a constant and $\\gamma^{max}$ is the upper bound of $\\gamma$.\n\nThe overall algorithm is summarized in Algorithm~\\ref{alg:SLRSmC}.\n\n\\textit{Remark 1:} In the algorithm, the stopping criterion is measured by the following condition:\n\n", "itemtype": "equation", "pos": 31705, "prevtext": "\n\n", "index": 57, "text": "\\begin{equation}\n\\begin{aligned}\n\\gamma^{t+1}=\\min\\{\\rho\\gamma^t, \\gamma^{max}\\}.\n\\end{aligned}\n\\label{eqt:update_gamma}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\gamma^{t+1}=\\min\\{\\rho\\gamma^{t},\\gamma^{max}\\}.\" display=\"inline\"><mrow><mrow><msup><mi>\u03b3</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>\u03c1</mi><mo>\u2062</mo><msup><mi>\u03b3</mi><mi>t</mi></msup></mrow><mo>,</mo><msup><mi>\u03b3</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msup><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00149.tex", "nexttext": "\n\n\\textit{Remark 2:} We can make steps 4-8 in the Algorithm parallel as suggested in \\cite{ZLin2015}, then it can be proved that Algorithm~\\ref{alg:SLRSmC} is convergent, see \\cite{ZLin2015}. Our experiments show that the convergence speed is relatively high and a value of MaxIter $<100$ is sufficient for good results.\n\n\\begin{algorithm}[t]\n\\caption{The solution of SLRSmC}\n\\label{alg:SLRSmC}\n\\begin{algorithmic}[1]\n\\REQUIRE ~~\n    The image sample data tensor $\\mathcal{Y}$, and the parameters $\\lambda$, $\\alpha$\\\\\n\\STATE $\\bf{Initialize:}$ $\\mathcal{Z}^0=\\mathcal{X}^0=\\mathbf{0}\\in\\Re^{N\\times N\\times D}$, $\\mathcal{G}_1^0=\\mathcal{G}_2^1=\\mathbf{1}\\in\\Re^{N\\times N\\times D}$, $\\gamma^0=0.1$, $\\rho=1.9$, $\\gamma^{max}=10^{10}$, $\\varepsilon=10^{-5}$, the number of maximum iteration $MaxIter=500$\n\\STATE $t=0$;\n\\WHILE {not converged and $t\\leq MaxIter$}\n    \\STATE Update $\\mathcal{X}$ by \\eqref{eqt:solve_x} and \\eqref{eqt:solve_xij}; \\\\\n    \\STATE Update $\\mathcal{Z}$ by \\eqref{eqt:solve_z} and \\eqref{eqt:soft_thresholding}; \\\\\n    \\STATE Update $\\mathcal{C}$ by \\eqref{eqt:solve_c} to \\eqref{eqt:solution_c}; \\\\\n    \\STATE Update $\\mathcal{G}_1$ and $\\mathcal{G}_2$ by \\eqref{eqt:update_g1} and \\eqref{eqt:update_g2};\\\\\n    \\STATE Update $\\gamma$ by \\eqref{eqt:update_gamma};\\\\\n    \\STATE Check the convergence conditions defined as \\eqref{eqt:convergence_condition};\\\\\n    \\STATE $t=t+1$.\n\\ENDWHILE\n\\ENSURE ~~\\\\\n    The tensor $\\mathcal{Z, X, C}$.\n\\end{algorithmic}\n\\end{algorithm}\n\n\\section{Experimental Results}\\label{Sec:VI}\nTo evaluate the proposed method, we implement clustering experiments on four databases of three types: synthetic, videos and images. We aim to cluster the image data from video clips or image sequences for the purpose of video segmentation/images clustering.  The performance of the proposed method is compared with some state-of-the-art clustering algorithms, such as SSC \\cite{EElhamifar2013}, OSC \\cite{STierney2014}, LRR \\cite{GLiu2010}, RobustLatLRR \\cite{HZhang2014} and SSmC \\cite{EKernfeld2015}.\n\\subsection{Synthetic Experiment}\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{f1}}\n\\caption{Some images of the synthetic data.}\n\\label{fig:syn_data_example}\n\\end{figure}\nAs described above, all the sample data can be arranged as a set of oriented matrices which is regarded as module over the ring $\\mathbb{K}_D$. In this experiment, we design a synthetic set of ring data to evaluate the performance of the proposed method. We choose ten different scenes from a video sequence freely available from the Internet Archive\\footnote{\\url{http://archive.org/}}. For each of the ten randomly chosen frames (images), we shift the first 10 columns to the right end of the image and repeat 64 times. By this way, we synthetically produce module subspace along image rows. Finally, we obtain 10 image sequences in which each sequence consists of 64 continuously shifted images. The pre-processing of sequences includes converting color images to grayscale and down-sampling to the resolution of 90$\\times$120. The sequence examples are shown in Figure~\\ref{fig:syn_data_example}. From these 10 sequences, we randomly selected $K$= [3, 4, 5, 6, 7] sequences. Thus in total we have $64\\times K$  2D frames (images) in each clustering test. To further test the robustness of the proposed method, we add 3 different magnitudes (20\\%, 50\\%, 80\\%) of Gaussian noise into the samples. For each $K$, we conduct 20 experiments. The average results are shown in Table~\\ref{tab:results_syn_data}. The best results is in bold text and the second one is underlined. From the results, we observe that our method outperforms all other methods in most cases especially with larger magnitudes of noise. The experimental results demonstrate that our method is more efficient than others.\n\\begin{table*}[t]\n\\centering{\\small\n\\begin{tabular}{|c|c||c|c|c|c|c|c|}\n\\hline\n$K$ & Noise & SSC & OSC & LRR & RobustLatLRR & SSmC & Ours \\\\\n\\hline\n\\multirow{4}*{3}\n  & 0\\% & $\\bf{0}$ ($\\pm$0) & 54.59 ($\\pm$15.70) & 40.59 ($\\pm$19.19) & \\underline{39.86} ($\\pm$18.25) & $\\bf{0}$ ($\\pm$0) & $\\bf{0}$ ($\\pm$0)\\\\\n  & 20\\% & 32.71 ($\\pm$21.99) & 42.32 ($\\pm$12.15) & 41.24 ($\\pm$16.92) & 39.56 ($\\pm$18.31) & \\underline{0.14} ($\\pm$0.72) & $\\bf{0.03}$ ($\\pm$0.13)\\\\\n  & 50\\% & 35.12 ($\\pm$5.88)  & 43.98 ($\\pm$21.08) & 56.71 ($\\pm$10.81) & 40.26 ($\\pm$3.97)  & \\underline{4.40} ($\\pm$3.82) & $\\bf{3.13}$ ($\\pm$8.12)\\\\\n  & 80\\% & 36.88 ($\\pm$13.90) & 44.69 ($\\pm$9.73)  & 55.66 ($\\pm$3.63)  & 46.95 ($\\pm$3.27)  & \\underline{6.04} ($\\pm$10.70)& $\\bf{5.94}$ ($\\pm$10.26)\\\\\n\\hline\n\\multirow{4}*{4}\n  & 0\\% & $\\bf{0}$ ($\\pm$0) & 58.75 ($\\pm$10.76) & 48.64 ($\\pm$9.83) & \\underline{41.56} ($\\pm$7.25) & $\\bf{0}$ ($\\pm$0) & $\\bf{0}$ ($\\pm$0)\\\\\n  & 20\\% & 40.81 ($\\pm$14.28) & 54.59 ($\\pm$13.73) & 49.07 ($\\pm$4.88) & 47.26 ($\\pm$4.92) & \\underline{1.15} ($\\pm$3.73) & $\\bf{1.04}$ ($\\pm$3.76)\\\\\n  & 50\\% & 42.55 ($\\pm$15.62) & 51.62 ($\\pm$10.78) & 68.69 ($\\pm$1.67) & 54.62 ($\\pm$2.25) & \\underline{3.28} ($\\pm$5.20) & $\\bf{2.79}$ ($\\pm$4.18)\\\\\n  & 80\\% & 45.63 ($\\pm$7.66) & 54.53 ($\\pm$6.06) & 69.02 ($\\pm$8.90) & 59.56 ($\\pm$8.72) & $\\bf{6.97}$ ($\\pm$7.62) & \\underline{7.66} ($\\pm$6.75)\\\\\n\\hline\n\\multirow{4}*{5}\n  & 0\\% & $\\bf{0}$ ($\\pm$0) & 68.72 ($\\pm$8.62) & 51.25 ($\\pm$10.25) & \\underline{47.62} ($\\pm$9.13) & $\\bf{0}$ ($\\pm$0) & $\\bf{0}$ ($\\pm$0)\\\\\n  & 20\\% & 40.70 ($\\pm$10.01) & 49.34 ($\\pm$5.91) & 51.01 ($\\pm$7.49) & 47.92 ($\\pm$7.23) & \\underline{1.00} ($\\pm$3.47) & $\\bf{0.42}$ ($\\pm$0.86)\\\\\n  & 50\\% & 41.68 ($\\pm$9.79)  & 53.60 ($\\pm$6.64) & 72.66 ($\\pm$2.29) & 65.95 ($\\pm$2.46) & \\underline{6.30} ($\\pm$7.76) & $\\bf{5.36}$ ($\\pm$7.22)\\\\\n  & 80\\% & 38.13 ($\\pm$13.32) & 57.36 ($\\pm$7.68) & 71.89 ($\\pm$2.02) & 67.95 ($\\pm$2.37) & \\underline{11.28} ($\\pm$6.86)& $\\bf{8.87}$ ($\\pm$7.03)\\\\\n\\hline\n\\multirow{4}*{6}\n  & 0\\% & $\\bf{0}$ ($\\pm$0) & 69.98 ($\\pm$4.88) & 53.78 ($\\pm$6.20) & \\underline{48.56} ($\\pm$6.42) & $\\bf{0}$ ($\\pm$0) & $\\bf{0}$ ($\\pm$0)\\\\\n  & 20\\% & 42.79 ($\\pm$9.52) & 54.04 ($\\pm$7.88) & 55.70 ($\\pm$5.91) & 49.56 ($\\pm$4.23) & \\underline{0.33} ($\\pm$0.42) & $\\bf{0.29}$ ($\\pm$0.59)\\\\\n  & 50\\% & 45.34 ($\\pm$12.35) & 58.62 ($\\pm$6.79) & 69.24 ($\\pm$9.80) & 59.59 ($\\pm$8.26) & \\underline{7.29} ($\\pm$5.64) & $\\bf{6.64}$ ($\\pm$5.80)\\\\\n  & 80\\% & 47.58 ($\\pm$10.62) & 63.49 ($\\pm$5.11) & 57.58 ($\\pm$5.55) & 52.03 ($\\pm$5.21) & \\underline{12.54} ($\\pm$5.66) & $\\bf{11.04}$ ($\\pm$6.60)\\\\\n\\hline\n\\multirow{4}*{7}\n  & 0\\% & $\\bf{0}$ ($\\pm$0) & 71.94 ($\\pm$5.88) & 55.94 ($\\pm$5.78) & \\underline{49.56} ($\\pm$5.02) & $\\bf{0}$ ($\\pm$0) & $\\bf{0}$ ($\\pm$0)\\\\\n  & 20\\% & 43.05 ($\\pm$13.37) & 53.86 ($\\pm$5.10) & 58.93 ($\\pm$4.83) & 51.94 ($\\pm$3.25) & $\\bf{0.43}$ ($\\pm$0.72) & \\underline{0.45} ($\\pm$0.64)\\\\\n  & 50\\% & 45.09 ($\\pm$10.86) & 59.21 ($\\pm$5.89) & 58.21 ($\\pm$5.21) & 53.62 ($\\pm$5.02) & \\underline{7.84} ($\\pm$3.24) & $\\bf{7.68}$ ($\\pm$2.87)\\\\\n  & 80\\% & 52.87 ($\\pm$4.96)  & 66.26 ($\\pm$2.70) & 64.30 ($\\pm$4.69) & 59.87 ($\\pm$4.12) & \\underline{17.70} ($\\pm$4.11)& $\\bf{16.63}$ ($\\pm$8.15)\\\\\n\\hline\n\\end{tabular}}\n\\caption{Misclassification rates (\\%) on the synthetic data with different noise, lower is better. Numbers in brackets indicate the standard deviation in each case.}\n\\label{tab:results_syn_data}\n\\end{table*}\n\n\\subsection{UCSD dynamic scenes benchmarking datasets}\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{f2}}\n\\caption{Some images of the UCSD dynamic scenes dataset.}\n\\label{fig:UCSD example}\n\\end{figure}\n\nThis dataset\\footnote{\\url{http://www.svcl.ucsd.edu/projects/background_subtraction/}} provides a wide range of different challenges and environmental settings including occlusion, camera motion, clustered background and especially highly dynamic backgrounds such as smoke, fire, swing trees as well as water waves. We select 10 categories from the dataset, in which the background changes evidently including \\textit{birds, boats, bottle, chopper, cyclists, flock, hockey, landing, ocean, skiing}. Each category has 30 to 246 2D images. We down sampling all the images to the resolution of 90$\\times$135. The examples are shown in Figure~\\ref{fig:UCSD example}. In this set of experiments, we select $K = $[3, 4, 5, 6, 7] categories, each of which characterize certain degree of scene shifting from left to right. All the 2D images from the selected sequences are collected for clustering. We repeat the experiment 20 times for each $K$ and the average cluster results are shown in Table~\\ref{tab:results_UCSD_data}. The best results is in bold text and the second one is underlined.\n\\begin{table*}[t]\n\\centering {\\small\n\\begin{tabular}{|c||c|c|c|c|c|c|}\n\\hline\n$K$ & SSC & OSC & LRR & RobustLatLRR & SSmC & Ours \\\\\n\\hline\n3 & 28.79 ($\\pm$13.26) & 17.32 ($\\pm$16.60) & 10.14 ($\\pm$14.79) & 9.23 ($\\pm$14.21) & \\underline{9.02} ($\\pm$11.93) & $\\bf{4.50}$ ($\\pm$10.21)\\\\\n\\hline\n4 & 29.29 ($\\pm$7.92) & 21.22 ($\\pm$14.48) & 17.47 ($\\pm$14.37) & 16.25 ($\\pm$14.52) & \\underline{12.76} ($\\pm$8.40) & $\\bf{7.66}$ ($\\pm$10.82)\\\\\n\\hline\n5 & 30.41 ($\\pm$8.75) & 24.83 ($\\pm$9.12) & 24.48 ($\\pm$15.96) & 17.19 ($\\pm$15.32) & \\underline{13.65} ($\\pm$7.73) & $\\bf{12.41}$ ($\\pm$8.17)\\\\\n\\hline\n6 & 31.32 ($\\pm$7.40) & 27.57 ($\\pm$8.65) & 26.04 ($\\pm$13.49) & 20.15 ($\\pm$12.14) & \\underline{16.41} ($\\pm$8.63) & $\\bf{14.27}$ ($\\pm$8.52)\\\\\n\\hline\n7 & 33.68 ($\\pm$5.76)  & 28.48 ($\\pm$6.88)  & 30.85 ($\\pm$12.28) & 28.12 ($\\pm$12.15)& \\underline{21.01} ($\\pm$9.50) & $\\bf{19.02}$ ($\\pm$8.32)\\\\\n\\hline\n\\end{tabular}}\n\\caption{Misclassification rates (\\%) on the UCSD dynamic scenes dataset with different class numbers. The lower the better. Numbers in brackets indicate the standard deviation in each case.}\n\\label{tab:results_UCSD_data}\n\\end{table*}\n\\begin{table*}[t]\n\\centering{\\small\n\\begin{tabular}{|c||c|c|c|c|c|c|}\n\\hline\n$K$ & SSC & OSC & LRR & RobustLatLRR & SSmC & Ours \\\\\n\\hline\n2 & 27.14 ($\\pm$18.11) & 35.13 ($\\pm$11.34) & 32.84 ($\\pm$10.21) & 29.56 ($\\pm$10.46) & \\underline{12.35} ($\\pm$14.51) & $\\bf{11.57}$ ($\\pm$14.72)\\\\\n\\hline\n3 & 35.72 ($\\pm$10.46) & 48.73 ($\\pm$10.59) & 43.10 ($\\pm$5.99)  & 38.26 ($\\pm$5.72) & \\underline{20.43} ($\\pm$13.10) & $\\bf{19.65}$ ($\\pm$12.91)\\\\\n\\hline\n4 & 35.92 ($\\pm$10.92) & 47.77 ($\\pm$6.78)  & 53.51 ($\\pm$7.51) & 48.62 ($\\pm$8.21) & \\underline{33.41} ($\\pm$13.21) & $\\bf{25.11}$ ($\\pm$11.75)\\\\\n\\hline\n5 & 43.91 ($\\pm$11.26) & 47.03 ($\\pm$5.51) & 47.72 ($\\pm$4.92) & 42.68 ($\\pm$4.72) & \\underline{33.01} ($\\pm$9.11) & $\\bf{27.40}$ ($\\pm$15.81)\\\\\n\\hline\n\\end{tabular}}\n\\caption{Misclassification rates (\\%) on the Olympic Sports Dataset with different class numbers. The lower the better. Numbers in brackets indicate the standard deviation in each case.}\n\\label{tab:results_oly_data}\n\\end{table*}\n\\begin{table*}[!t]\n\\centering{\\small\n\\begin{tabular}{|c||c|c|c|c|c|}\n\\hline\n$K$ & SSC & LRR & RobustLatLRR & SSmC & Ours \\\\\n\\hline\n5 & 16.37 ($\\pm$11.64) & 18.11 ($\\pm$11.51) & 15.22 ($\\pm$12.69) & \\underline{12.56} ($\\pm$12.22) & $\\bf{11.23}$ ($\\pm$11.75)\\\\\n\\hline\n6 & 26.51 ($\\pm$10.99) & 23.46 ($\\pm$9.30) & 21.28 ($\\pm$11.20) & \\underline{16.78} ($\\pm$11.03) & $\\bf{13.46}$ ($\\pm$10.03)\\\\\n\\hline\n7 & 26.07 ($\\pm$12.28) & \\bf{15.07} ($\\pm$9.91) & 18.47 ($\\pm$8.02) & 19.87 ($\\pm$9.68) & $\\underline{17.47}$ ($\\pm$11.39)\\\\\n\\hline\n8 & 27.37 ($\\pm$11.13) & \\underline{18.83} ($\\pm$9.82) & 22.96 ($\\pm$10.14) & 20.60 ($\\pm$11.60) & $\\bf{17.56}$ ($\\pm$9.96)\\\\\n\\hline\n9 & 27.11 ($\\pm$9.38) & \\underline{21.91} ($\\pm$8.99) & 23.11 ($\\pm$9.20) & 24.08 ($\\pm$7.77) & $\\bf{20.47}$ ($\\pm$7.93)\\\\\n\\hline\n10 & 27.88 ($\\pm$9.77) & 25.59 ($\\pm$8.03) & \\underline{25.17} ($\\pm$7.62) & 26.36 ($\\pm$11.29) & $\\bf{21.64}$ ($\\pm$8.90)\\\\\n\\hline\n11 & 30.48 ($\\pm$11.02) & 28.25 ($\\pm$8.13) & \\underline{26.01} ($\\pm$8.33) & 30.56 ($\\pm$13.58) & $\\bf{22.15}$ ($\\pm$6.90)\\\\\n\\hline\n\\end{tabular}}\n\\caption{Misclassification rates (\\%) on the COIL20 Image Database with different class numbers, lower is better. Numbers in brackets indicate the standard deviation in each case.}\n\\label{tab:results_coil20_data}\n\\end{table*}\n\nIt shows that the proposed SLRSmC method has superior performance against others though the performance degrades with the increasing number of class.\n\\subsection{Olympic Sports Dataset}\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{f3}}\n\\caption{Some images of the Olympic Sports Dataset.}\n\\label{fig:oly_example}\n\\end{figure}\nThe Olympic Sports Dataset \\cite{olympicsports} contains videos of athletes practicing different sports obtained from YouTube and annotated using Amazon Mechanical Turk. There are 16 sports actions among a total of 783 video sequences. We choose six scenes with slightly larger change including \\textit{high-jump, long-jump,  pole-vault, basketball lay-up, javelin and vault}. For each class, we down-sample all the images at the resolution of 90$\\times$120. The examples are shown in Figure~\\ref{fig:oly_example}. In this set of experiments, we set the cluster number $K$ to [2, 3, 4, 5], then collect the frames for clustering. Similarly we repeat the experiment 20 times for each $K$ and the average results are reported in Table~\\ref{tab:results_oly_data}.\n\nIt can be observed that our method outperforms all the other methods in all cases. This demonstrates that the introduced method enhances the clustering performance due to the t-linear combination.\n\\subsection{COIL20 Image Database}\n\\begin{figure}[h]\n\\centering {\\includegraphics[width=0.47\\textwidth]{f4}}\n\\caption{Some images of the COIL20 Image Database.}\n\\label{fig:coil20 example}\n\\end{figure}\nFinally we test the clustering performance of our method on the COIL image database \\cite{coil20} for image clustering. The database contains 20 objects viewed from varying angels, as demonstrated in Figure~\\ref{fig:coil20 example}. In this experiment, similarly we consider $K = $ [5, 6, 7, 8, 9, 10, 11] objects and pick up 36 images from each class for clustering. Each image sample is down-sampled to the resolution of 32$\\times$32. As there is no special order specified for image samples, the OSC method is not suitable for this experiment. The experiment has been repeated 20 times for each $K$. Table~\\ref{tab:results_coil20_data} reports the overall results, which\nindicate that our SLRSmC consistently outperforms all the other methods in most cases.\n\n\\section{Conclusion}\\label{Sec:VII}\n\nIn this paper, we proposed a new image submodule clustering method by combining sparse representation, low-rank representation and t-product. Different from other typical clustering methods, we keep the 2D structure of image data without vectorizing them. The data affinity information is learned by exploring the embedded submodule structure by using the sparse and  low-rank representation over tensors with t-product operation. Our experiment results have demonstrated that the t-product assisted low-rank representation does facilitate clustering based on submodule information, evidenced by the better clustering results.\n\n\n\n\n\n\n\n\n\n\n\n{\\small\n\\begin{thebibliography}{1}\n\n\\bibitem{RXu2005}\nR.~Xu and D.~Wunsch, ``Survey of clustering algorithms,'' \\emph{IEEE TNN}, vol. 16, no. 3, pp. 645--678, 2005.\n\n\\bibitem{SKrinidis2010}\nS.~Krinidis and V.~Chatzis, ``A robust fuzzy local information c-means clustering algorithm,'' \\emph{IEEE TIP}, vol. 19, no. 5, pp. 1328--1337, 2010.\n\n\\bibitem{ABiswas2012}\nA.~Biswas and D.~Jacobs, ``Active image clustering: Seeking constraints from humans to complement algorithms,'' in \\emph{CVPR}, 2012. pp. 2152--2159.\n\n\\bibitem{RVidal2011}\nR.~Vidal. `` A tutorial on subspace clustering,'' \\emph{IEEE Signal Proc. Mag.}, vol. 28, no. 2, pp. 52--68, 2011.\n\n\\bibitem{EElhamifar2013}\nE.~Elhamifar and R.~Vidal, ``Sparse subspace clustering: Algorithm, theory, and applications,'' \\emph{IEEE TPAMI}, vol. 35, no. 1, pp. 2765--2781, 2013.\n\n\\bibitem{STierney2014}\nS.~Tierney, J.~Gao, and Y.~Guo, ``Subspace clustering for sequential data,'' in \\emph{CVPR}, 2014, pp. 1019-1026.\n\n\\bibitem{GLiu2010}\nG.~Liu, Z.~Lin, and Y.~Yu, ``Robust subspace segmentation by low-rank representation,'' in \\emph{ICML}, 2010. pp. 663--670.\n\n\\bibitem{HZhang2014}\nH.~Zhang, Z.~Lin, C.~Zhang, and J.~Gao, ``Robust latent low rank representation for subspace clustering.'' \\emph{Neurocomputing}, vol. 145, pp. 369--373, Dec. 2014.\n\n\\bibitem{JShi2000}\nJ.~Shi and J.~Malik, ``Normalized cuts and image segmentation,'' \\emph{IEEE TPAMI}, vol. 22, no. 1, pp. 888--905, 2000.\n\n\\bibitem{XHe2005}\nX.~He, D.~Cai, and P.~Niyogi, ``Tensor subspace analysis,'' in \\emph{NIPS}, 2005. pp. 499--506.\n\n\\bibitem{NHao2013}\nN.~Hao, M.~Kilmer, K.~Braman, and R.~Hoover. ``Facial recognition using tensor-tensor decompositions,'' \\emph{SIAM J on Imaging Sciences,} vol. 6, no. 1, pp. 437--463, 2013.\n\n\\bibitem{EKernfeld2015}\nE.~Kernfeld, S.~Aeron, and M.~Kilmer, ``Clustering multi-way data: a novel algebraic approach,'' \\emph{arXiv preprint arXiv:1412.7056.}, 2015.\n\n\\bibitem{SAeron2015}\nS.~Aeron and E.~Kernfeld, ``Group-Invariant subspace clustering,'' in \\emph{arXiv preprint arXiv:1510.04356}, 2015.\n\n\\bibitem{MEKilmer2011}\nM.~E.~Kilmer and C.~D.~Martin, ``Factorization strategies for third-order tensors,'' \\emph{Lin. Alg. and its Appls}, vol. 435, no. 3, pp. 641--658, 2011.\n\n\\bibitem{MKilmer2013}\nM.~Kilmer, K.~Braman, N.~Hao, and R.~Hoover, ``Third-order tensors as operators on matrices: A theoretical and computational framework with applications in imaging,'' \\emph{SIAM J Matr Anal and Appls}, vol. 34, no. 1, pp. 148--172, 2013.\n\n\\bibitem{KBraman2010}\nK.~Braman, ``Third-order tensors as linear operators on a space of matrices,'' \\emph{Lin  Alg  and its Appls}, vol. 433, no. 7, pp. 1241--1253, 2010.\n\n\\bibitem{CDMartin2013}\nC.~D.~Martin, R.~Shafer, B.~LaRue, ``An order-p tensor factorization with applications in imaging,'' \\emph{SIAM J on Sci Comp}, vol. 35, no. 1, pp. A474--A490, 2013.\n\n\\bibitem{WHu2015}\nW.~Hu, D.~Tao, W.~Zhang, Y.~Xie, and Y.~Yang, ``A New Low-Rank Tensor Model for Video Completion,'' \\emph{arXiv preprint arXiv:1509.02027.}, 2015.\n\n\n\n\n\\bibitem{ZLin2015}\nZ.~Lin, R.~Liu, and H.~Li, ``Linearized alternating direction method with parallel splitting and adaptive penalty for separable convex programs in machine learning,'' \\emph{Machine Learning,}, vol. 99, no. 2, pp. 287--325, 2015.\n\n\\bibitem{JFCai2010}\nJ.~F.~Cai, E.~J.~Cand\\`{e}s, Z.~Shen, ``A singular value thresholding algorithm for matrix completion,'' \\emph{SIAM J on Opt.}, vol. 20, no. 4, pp. 1956--1982, 2010.\n\n\\bibitem{coil20}\nS.~A.~Nene, S.~K.~Nayar, and H.~Murase, ``Columbia object image library (COIL-20),'' \\emph{Technical Report CUCS-005-96}, Feb. 1996.\n\n\\bibitem{olympicsports}\nJ.~C.~Niebles, C.-W.~Chen, and L.~Fei-Fei, ``Modeling temporal structure of decomposable motion segments for activity classification,'' in \\emph{ECCV}, 2010. pp. 392--405.\n\n\\end{thebibliography}\n}\n\n\n", "itemtype": "equation", "pos": 32090, "prevtext": "\nwhere $\\rho>1$ is a constant and $\\gamma^{max}$ is the upper bound of $\\gamma$.\n\nThe overall algorithm is summarized in Algorithm~\\ref{alg:SLRSmC}.\n\n\\textit{Remark 1:} In the algorithm, the stopping criterion is measured by the following condition:\n\n", "index": 59, "text": "\\begin{equation}\n\\begin{aligned}\n\\rm{max}\\left\\{\n  \\begin{array}{c}\n    \\|\\mathcal{Z}^{t+1}-\\mathcal{C}^{t+1}\\|_{\\infty},\\|\\mathcal{X}^{t+1}-\\mathcal{C}^{t+1}\\|_{\\infty},\\\\\n\\|\\mathcal{Z}^{t+1}-\\mathcal{Z}^{t}\\|_{\\infty},\\|\\mathcal{X}^{t+1}-\\mathcal{X}^{t}\\|_{\\infty},\\\\\n\\|\\mathcal{C}^{t+1}-\\mathcal{C}^{t}\\|_{\\infty}\n  \\end{array}\n\\right\\}\\leq\\varepsilon.\n\\end{aligned}\n\\label{eqt:convergence_condition}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\rm{max}\\left\\{\\begin{array}[]{c}\\|\\mathcal{Z}^{t+1}-\\mathcal{C}^%&#10;{t+1}\\|_{\\infty},\\|\\mathcal{X}^{t+1}-\\mathcal{C}^{t+1}\\|_{\\infty},\\\\&#10;\\|\\mathcal{Z}^{t+1}-\\mathcal{Z}^{t}\\|_{\\infty},\\|\\mathcal{X}^{t+1}-\\mathcal{X}%&#10;^{t}\\|_{\\infty},\\\\&#10;\\|\\mathcal{C}^{t+1}-\\mathcal{C}^{t}\\|_{\\infty}\\end{array}\\right\\}\\leq\\varepsilon.\" display=\"inline\"><mrow><mrow><mrow><mi>max</mi><mo>\u2062</mo><mrow><mo>{</mo><mtable rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo>\u2225</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub><mo>,</mo><msub><mrow><mo>\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo>\u2225</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb5</mi><mi mathvariant=\"normal\">t</mi></msup></mrow><mo>\u2225</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub><mo>,</mo><msub><mrow><mo>\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mi mathvariant=\"normal\">t</mi></msup></mrow><mo>\u2225</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mrow><mo>\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi mathvariant=\"normal\">t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mi mathvariant=\"normal\">t</mi></msup></mrow><mo>\u2225</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub></mtd></mtr></mtable><mo>}</mo></mrow></mrow><mo>\u2264</mo><mi>\u03b5</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}]