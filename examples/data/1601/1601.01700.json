[{"file": "1601.01700.tex", "nexttext": "\n\\end{definition}\nfor all sequential times $t_{0},t_{1} \\in T$ such that $t_{1} \\in T_{0}$.\n\n\\subsection{Elementary Properties for a Specific Choice of Y}\n\\label{specific}\n\nLet $T$ be defined as in section $(\\ref{prop})$.  For $t \\in T$, let $\\epsilon_{t}$ define a sequence of independent, identically, normally distributed random variables, with $0$-mean and common, constant variance, $\\sigma^{2}$.  Given $t_{1} \\in T_{0}$, define a specific choice of the measureable function $Y_{t_{1}}$ to be such that\n\n", "itemtype": "equation", "pos": 1840, "prevtext": "\n\n\\begin{frontmatter}\n\n\n\\title{A Predictive Model using the Markov Property}\n\\runtitle{SIFM}\n\n\\author{\\fnms{Robert A.} \\snm{Murphy, \nPh.D.}\\ead[label=e1]{robert.a.murphy@wustl.edu}}\n\\address{\\printead{e1}}\n\n\\runauthor{Murphy}\n\n\\begin{abstract}\nGiven a data set of numerical values which are sampled from some unknown probability distribution, we will show how to check if the data set exhibits the Markov property and we will show how to use the Markov property to predict future values from the same distribution, with probability 1.\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\\begin{keyword}\n\\kwd{markov property}\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\n\n\n\n\n\n\n\n\n\\section{The Problem}\n\\label{app}\n\n\\subsection{Problem Statement}\n\nGiven a data set consisting of numerical values which are sampled from some unknown probability distribution, we want to show how to easily check if the data set exhibits the Markov property, which is stated as a sequence of dependent observations from a distribution such that each successive observation only depends upon the most recent previous one.  In doing so, we will present a method for predicting bounds on future values from the same distribution, with probability 1.\n\n\\subsection{Markov Property}\n\\label{prop}\n\n\nLet $I \\subseteq \\mathbb{R}$ be any subset of the real numbers and let $T \\subseteq I$ consist of \\textit{times} at which a numerical distribution of data is randomly sampled.  Denote the random samples by a sequence of random variables $\\{X_{t}\\}_{t \\in T}$ taking values in $\\mathbb{R}$.  Fix $t_{0} \\in T$ and define $T_{0} = \\{t \\in T : t > t_{0}\\}$ to be the subset of times in $T$ that are greater than $t_{0}$.  Let $t_{1} \\in T_{0}$.\n\n\\begin{definition}\nThe sequence $\\{X_{t}\\}_{t \\in T}$ is said to exhibit the \\textbf{Markov Property}, if there exists a measureable function $Y_{t_{1}}$ such that\n\n", "index": 1, "text": "\\begin{equation}\n\\label{XY}\nX_{t_{1}} = Y_{t_{1}}(X_{t_{0}})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"X_{t_{1}}=Y_{t_{1}}(X_{t_{0}})\" display=\"block\"><mrow><msub><mi>X</mi><msub><mi>t</mi><mn>1</mn></msub></msub><mo>=</mo><mrow><msub><mi>Y</mi><msub><mi>t</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\n\nExtending the setup in section $(\\ref{prop})$, let $t_{2} < ... < t_{k} < t_{k+1} < ...$ be a sequence of times in $T$ with corresponding subsets $T_{1} \\supseteq T_{2} \\supseteq ... \\supseteq T_{k} \\supseteq T_{k+1} \\supseteq ...$, where $t_{0} < t_{1} < t_{2}$ and $T_{0} \\supseteq T_{1}$ such that\n\n", "itemtype": "equation", "pos": 2424, "prevtext": "\n\\end{definition}\nfor all sequential times $t_{0},t_{1} \\in T$ such that $t_{1} \\in T_{0}$.\n\n\\subsection{Elementary Properties for a Specific Choice of Y}\n\\label{specific}\n\nLet $T$ be defined as in section $(\\ref{prop})$.  For $t \\in T$, let $\\epsilon_{t}$ define a sequence of independent, identically, normally distributed random variables, with $0$-mean and common, constant variance, $\\sigma^{2}$.  Given $t_{1} \\in T_{0}$, define a specific choice of the measureable function $Y_{t_{1}}$ to be such that\n\n", "index": 3, "text": "\\begin{equation}\n\\label{YX}\nY_{t_{1}}(X_{t_{0}}) = X_{t_{0}} + \\epsilon_{t_{1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"Y_{t_{1}}(X_{t_{0}})=X_{t_{0}}+\\epsilon_{t_{1}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>Y</mi><msub><mi>t</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo>+</mo><msub><mi>\u03f5</mi><msub><mi>t</mi><mn>1</mn></msub></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\n\n\\begin{lemma}\n\\label{Z}\nFix finite $K \\ge 1$ and let $T = \\{t_{0},t_{1},...,t_{K}\\}$ be restricted to being a finite set.  Then, for $k \\in \\{1,...,K\\}$, it is true that\n\n", "itemtype": "equation", "pos": 2822, "prevtext": "\n\nExtending the setup in section $(\\ref{prop})$, let $t_{2} < ... < t_{k} < t_{k+1} < ...$ be a sequence of times in $T$ with corresponding subsets $T_{1} \\supseteq T_{2} \\supseteq ... \\supseteq T_{k} \\supseteq T_{k+1} \\supseteq ...$, where $t_{0} < t_{1} < t_{2}$ and $T_{0} \\supseteq T_{1}$ such that\n\n", "index": 5, "text": "\\begin{equation}\n\\label{eYX}\nY_{t_{k+1}}(X_{t_{k}}) = X_{t_{k}} + \\epsilon_{t_{k+1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"Y_{t_{k+1}}(X_{t_{k}})=X_{t_{k}}+\\epsilon_{t_{k+1}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>Y</mi><msub><mi>t</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>+</mo><msub><mi>\u03f5</mi><msub><mi>t</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\n\\end{lemma}\nwhere $Z_{k}$ is a normally distributed random variable, with $0$-mean and variance, $k\\sigma^{2}$.\n\n\\begin{proof}\nFor each $k \\in \\{1,...,K\\}$, successive application of eq. $(\\ref{eYX})$ yields\n\n", "itemtype": "equation", "pos": 3094, "prevtext": "\n\n\\begin{lemma}\n\\label{Z}\nFix finite $K \\ge 1$ and let $T = \\{t_{0},t_{1},...,t_{K}\\}$ be restricted to being a finite set.  Then, for $k \\in \\{1,...,K\\}$, it is true that\n\n", "index": 7, "text": "\\begin{equation}\n\\label{X1}\nX_{t_{k}} = X_{t_{0}} + Z_{k},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"X_{t_{k}}=X_{t_{0}}+Z_{k},\" display=\"block\"><mrow><mrow><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>=</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo>+</mo><msub><mi>Z</mi><mi>k</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nSince $\\epsilon_{t_{j}}$ are independent for all $j \\in \\{1,...,k\\}$, then the random variable\n\n", "itemtype": "equation", "pos": 3376, "prevtext": "\n\\end{lemma}\nwhere $Z_{k}$ is a normally distributed random variable, with $0$-mean and variance, $k\\sigma^{2}$.\n\n\\begin{proof}\nFor each $k \\in \\{1,...,K\\}$, successive application of eq. $(\\ref{eYX})$ yields\n\n", "index": 9, "text": "\\begin{equation}\n\\label{X2}\nX_{t_{k}} = X_{t_{0}} + \\sum_{j=1}^{k}\\epsilon_{t_{j}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"X_{t_{k}}=X_{t_{0}}+\\sum_{j=1}^{k}\\epsilon_{t_{j}}.\" display=\"block\"><mrow><mrow><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>=</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>\u03f5</mi><msub><mi>t</mi><mi>j</mi></msub></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nis easily shown to be normally distributed, with $0$-mean and variance, $k\\sigma^{2}$, by the method of characteristics $\\cite{Hogg}$.\\qed\n\\end{proof}\n\n\\begin{remark}\n\\label{error}\nBy lemma $(\\ref{Z})$, if we have a set of $K$ ordered, historical values, its error sequence $\\{\\epsilon_{k}\\}_{k = 1}^{K}$ is estimated by $\\epsilon_{k} = X_{t_{k}} - X_{t_{k-1}}$ for all $k \\in \\{1,...,K\\}$.\n\\end{remark}\n\n\\begin{remark}\nAlso by lemma $(\\ref{Z})$,  if the sampling times are re-labeled so that the last value in the ordering is re-labeled as $x_{0}$ corresponding to time $t_{0}$, then future values at times $k \\ge 1$ are the sum of $x_{0}$ and $k$ independent, white noise (Gaussian) disturbances.  Thought of as a random walk, each new step in the \\textit{``walk''} is simply a white noise disturbance.\n\\end{remark}\n\n\\begin{corollary}\n\\label{growth}\nLet $\\Omega$ be the sample space consisting of future values sampled from the probability distribution, $P$, such that $|\\Omega| = H$.  Then, $P\\bigg(|X_{t_{k}} - X_{t_{0}}| \\le \\sqrt{k}\\sigma\\bigg) = 1$ on $\\Omega$, for all $k \\in \\{1,...,H\\}$. \n\\end{corollary}\n\n\\begin{proof}\nLet $Var(X)$ denote the variance of the random variable, $X$.  Recalling that $\\sigma^{2}$ is the variance of the historical error sequence and noting that the random variable $X_{t_{k}}-X_{t_{0}}$ is $0$-mean by lemma $(\\ref{Z})$, then from eqs. $(\\ref{X1})$, $(\\ref{X2})$ and $(\\ref{Z1})$, we have\n\\begin{eqnarray}\n\\int_{\\Omega}(X_{t_{k}}-X_{t_{0}})^{2}dP &=& Var(X_{t_{k}}-X_{t_{0}}) \\nonumber \\\\ &=& Var(Z_{k}) \\nonumber \\\\ &=& k\\sigma^{2}.\n\\end{eqnarray}\nSince $(X_{t_{k}}-X_{t_{0}})^{2}$ is a non-negative random variable, then from Shiryaev $\\cite{Shiryaev}$, we know that with probability 1,\n\n", "itemtype": "equation", "pos": 3570, "prevtext": "\nSince $\\epsilon_{t_{j}}$ are independent for all $j \\in \\{1,...,k\\}$, then the random variable\n\n", "index": 11, "text": "\\begin{equation}\n\\label{Z1}\nZ_{k} = \\sum_{j=1}^{k}\\epsilon_{t_{j}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"Z_{k}=\\sum_{j=1}^{k}\\epsilon_{t_{j}}\" display=\"block\"><mrow><msub><mi>Z</mi><mi>k</mi></msub><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>\u03f5</mi><msub><mi>t</mi><mi>j</mi></msub></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\non $\\Omega$.  Now, since $\\{|X_{t_{k}}-X_{t_{0}}| \\le \\sqrt{k}\\sigma\\} = \\{(X_{t_{k}}-X_{t_{0}})^{2} \\le k\\sigma^{2}\\}$, then\n\n", "itemtype": "equation", "pos": 5382, "prevtext": "\nis easily shown to be normally distributed, with $0$-mean and variance, $k\\sigma^{2}$, by the method of characteristics $\\cite{Hogg}$.\\qed\n\\end{proof}\n\n\\begin{remark}\n\\label{error}\nBy lemma $(\\ref{Z})$, if we have a set of $K$ ordered, historical values, its error sequence $\\{\\epsilon_{k}\\}_{k = 1}^{K}$ is estimated by $\\epsilon_{k} = X_{t_{k}} - X_{t_{k-1}}$ for all $k \\in \\{1,...,K\\}$.\n\\end{remark}\n\n\\begin{remark}\nAlso by lemma $(\\ref{Z})$,  if the sampling times are re-labeled so that the last value in the ordering is re-labeled as $x_{0}$ corresponding to time $t_{0}$, then future values at times $k \\ge 1$ are the sum of $x_{0}$ and $k$ independent, white noise (Gaussian) disturbances.  Thought of as a random walk, each new step in the \\textit{``walk''} is simply a white noise disturbance.\n\\end{remark}\n\n\\begin{corollary}\n\\label{growth}\nLet $\\Omega$ be the sample space consisting of future values sampled from the probability distribution, $P$, such that $|\\Omega| = H$.  Then, $P\\bigg(|X_{t_{k}} - X_{t_{0}}| \\le \\sqrt{k}\\sigma\\bigg) = 1$ on $\\Omega$, for all $k \\in \\{1,...,H\\}$. \n\\end{corollary}\n\n\\begin{proof}\nLet $Var(X)$ denote the variance of the random variable, $X$.  Recalling that $\\sigma^{2}$ is the variance of the historical error sequence and noting that the random variable $X_{t_{k}}-X_{t_{0}}$ is $0$-mean by lemma $(\\ref{Z})$, then from eqs. $(\\ref{X1})$, $(\\ref{X2})$ and $(\\ref{Z1})$, we have\n\\begin{eqnarray}\n\\int_{\\Omega}(X_{t_{k}}-X_{t_{0}})^{2}dP &=& Var(X_{t_{k}}-X_{t_{0}}) \\nonumber \\\\ &=& Var(Z_{k}) \\nonumber \\\\ &=& k\\sigma^{2}.\n\\end{eqnarray}\nSince $(X_{t_{k}}-X_{t_{0}})^{2}$ is a non-negative random variable, then from Shiryaev $\\cite{Shiryaev}$, we know that with probability 1,\n\n", "index": 13, "text": "\\begin{equation}\n(X_{t_{k}}-X_{t_{0}})^{2} \\le \\int_{\\Omega}(X_{t_{k}}-X_{t_{0}})^{2}dP = k\\sigma^{2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"(X_{t_{k}}-X_{t_{0}})^{2}\\leq\\int_{\\Omega}(X_{t_{k}}-X_{t_{0}})^{2}dP=k\\sigma^%&#10;{2}\" display=\"block\"><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>-</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2264</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi mathvariant=\"normal\">\u03a9</mi></msub><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>-</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>P</mi></mrow></mrow></mrow><mo>=</mo><mrow><mi>k</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nfor all $k \\in \\{1,...,H\\}$.\\qed\n\\end{proof}\n\n\\begin{remark}\n\\label{shiryaev}\nFrom Shiryaev $\\cite{Shiryaev}$, if the chain $\\{X_{t_{k}}\\}_{k = 1}^{H}$ exhibits the Markov property, then it is independent of the start, $X_{t_{0}}=x_{0}$.\n\\end{remark}\n\n\\begin{remark}\nIf we run the Markov chain until a certain point, which we designate $X_{t_{0}} = x_{0}$, and sample $H$ times from the future, then by corollary $(\\ref{growth})$, with probability $1$, we will not see growth beyond $x_{0} + \\sqrt{H}\\sigma$ nor will we see a decline below $x_{0} - \\sqrt{H}\\sigma$.\n\\end{remark}\n\n\\subsection{Check for the Markov Property}\n\nThe historical errors $\\epsilon_{t_{k}}$ are assumed to be normally distributed for all $k \\in \\{1,...,K\\}$.  Likewise, by the independence of each $\\epsilon_{t_{k}}$ from each $\\epsilon_{t_{j}}$, for all $k,j \\in \\{1,...,K\\}$, when $k \\ne j$, then the variance of the sum of the errors is just $K\\sigma^{2}$.  Therefore, by remark $(\\ref{error})$, we only need to show that $X_{t_{k}}-X_{t_{k-1}}$ is normally distributed, with $0$-mean and constant variance $\\sigma^{2}$, for all $k \\in \\{1,...,K\\}$, in order to show that the sequence of data measurements $\\{X_{t_{k}}\\}_{k=1}^{K}$ is Markovian, with respect to the chosen random model, $Y_{t_{k}}$, given in section $(\\ref{specific})$.\n\nDefine a test statistic $W$ as\n\n", "itemtype": "equation", "pos": 5625, "prevtext": "\non $\\Omega$.  Now, since $\\{|X_{t_{k}}-X_{t_{0}}| \\le \\sqrt{k}\\sigma\\} = \\{(X_{t_{k}}-X_{t_{0}})^{2} \\le k\\sigma^{2}\\}$, then\n\n", "index": 15, "text": "\\begin{equation}\nP\\bigg(|X_{t_{k}}-X_{t_{0}}| \\le \\sqrt{k}\\sigma\\bigg) = P\\bigg((X_{t_{k}}-X_{t_{0}})^{2} \\le k\\sigma^{2}\\bigg) = 1\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"P\\bigg{(}|X_{t_{k}}-X_{t_{0}}|\\leq\\sqrt{k}\\sigma\\bigg{)}=P\\bigg{(}(X_{t_{k}}-X%&#10;_{t_{0}})^{2}\\leq k\\sigma^{2}\\bigg{)}=1\" display=\"block\"><mrow><mi>P</mi><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mo stretchy=\"false\">|</mo><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>-</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msqrt><mi>k</mi></msqrt><mi>\u03c3</mi><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><msub><mi>t</mi><mi>k</mi></msub></msub><mo>-</mo><msub><mi>X</mi><msub><mi>t</mi><mn>0</mn></msub></msub><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>\u2264</mo><mi>k</mi><msup><mi>\u03c3</mi><mn>2</mn></msup><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow><mo>=</mo><mn>1</mn></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nwhere $x_{(k)}$ and $\\overline{x}$ are the $k^{th}$ element in an ordering of $\\{x_{k}\\}_{k = 1}^{K}$ and its sample mean, respectively, and $(a_{1},...,a_{K})$ is computed as\n\n", "itemtype": "equation", "pos": 7118, "prevtext": "\nfor all $k \\in \\{1,...,H\\}$.\\qed\n\\end{proof}\n\n\\begin{remark}\n\\label{shiryaev}\nFrom Shiryaev $\\cite{Shiryaev}$, if the chain $\\{X_{t_{k}}\\}_{k = 1}^{H}$ exhibits the Markov property, then it is independent of the start, $X_{t_{0}}=x_{0}$.\n\\end{remark}\n\n\\begin{remark}\nIf we run the Markov chain until a certain point, which we designate $X_{t_{0}} = x_{0}$, and sample $H$ times from the future, then by corollary $(\\ref{growth})$, with probability $1$, we will not see growth beyond $x_{0} + \\sqrt{H}\\sigma$ nor will we see a decline below $x_{0} - \\sqrt{H}\\sigma$.\n\\end{remark}\n\n\\subsection{Check for the Markov Property}\n\nThe historical errors $\\epsilon_{t_{k}}$ are assumed to be normally distributed for all $k \\in \\{1,...,K\\}$.  Likewise, by the independence of each $\\epsilon_{t_{k}}$ from each $\\epsilon_{t_{j}}$, for all $k,j \\in \\{1,...,K\\}$, when $k \\ne j$, then the variance of the sum of the errors is just $K\\sigma^{2}$.  Therefore, by remark $(\\ref{error})$, we only need to show that $X_{t_{k}}-X_{t_{k-1}}$ is normally distributed, with $0$-mean and constant variance $\\sigma^{2}$, for all $k \\in \\{1,...,K\\}$, in order to show that the sequence of data measurements $\\{X_{t_{k}}\\}_{k=1}^{K}$ is Markovian, with respect to the chosen random model, $Y_{t_{k}}$, given in section $(\\ref{specific})$.\n\nDefine a test statistic $W$ as\n\n", "index": 17, "text": "\\begin{equation}\nW = \\frac{\\bigg(\\sum_{k=1}^{K}a_{k}x_{(k)}\\bigg)^{2}}{\\sum_{i=1}^{K}(x_{i}-\\overline{x})^{2}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"W=\\frac{\\bigg{(}\\sum_{k=1}^{K}a_{k}x_{(k)}\\bigg{)}^{2}}{\\sum_{i=1}^{K}(x_{i}-%&#10;\\overline{x})^{2}},\" display=\"block\"><mrow><mrow><mi>W</mi><mo>=</mo><mfrac><msup><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><msub><mi>a</mi><mi>k</mi></msub><mo>\u2062</mo><msub><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msub></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow><mn>2</mn></msup><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mover accent=\"true\"><mi>x</mi><mo>\u00af</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nsuch that $m = (m_{1},...,m_{K})$ is a vector of expected values of the order statistics used to give the ordering $\\{x_{(k)}\\}_{k=1}^{K}$ and $V$ is the covariance matrix of the order statistics.\n\n\\begin{definition}\n\\label{SW}\nThe \\textbf{Shapiro-Wilk Test of Normality} is the test statistic $W$, such that, if a level of significance ($p$-value) is assigned in a hypothesis test, where the null hypothesis is that the sample was drawn from a normal distribution, then a value of $W$ which exceeds the probability $(1-2p)$ affirms the null hypothesis.\n\\end{definition}\n\n\\noindent\nThe Shapiro-Wilk test now provides a sufficient condition for testing if the sequence of errors $\\{\\epsilon_{t_{k}}\\}_{k = 1}^{K}$, defined in our Markov model $\\{Y_{t_{k}}\\}_{k = 1}^{K}$, is normally distributed, which amounts to $\\{X_{t_{k}}\\}_{k=1}^{K}$ forming a Markov chain with respect to the model $\\{Y_{t_{k}}\\}_{k = 1}^{K}$.\n\n\\section{Airline Schedule Interruption Counts Exhibit the Markov Property}\n\n\\subsection{Problem Statement}\n\nTo a manufacturer of large airliners, a schedule interruption is any event that causes an airliner to be more than 15 minutes late on its scheduled departure time from an airport or more than 15 minutes late arriving into an airport due to mechanical or electrical failure of a part, subsystem or system on said aircraft.  Given a data set containing a $K$-month period of historical schedule interruption counts, we will present a calculation of bounds on the number of schedule interruptions in the following $H$-month future period, after which, we want to be able to calculate bounds on the total cost impact.\n\n\\subsection{Bounds on Schedule Interruption Counts}\n\\label{bounds}\n\nUsing def. $(\\ref{SW})$, the errors obtained from a proprietary schedule interruptions data set gives a value of $W \\approx 0.90$, which is right at the level of significance when we set $p = 0.05$.  We accept the null hypothesis and conclude that the sequence of errors was drawn from a normal distribution so that the original data set is Markovian, according to the model of $Y_{t_{k}}$ given by eq. $(\\ref{YX})$.  Therefore, by remark $(\\ref{shiryaev})$, we can run the chain up to the end and label this point $x_{0}$.  Then, with probability $1$, future schedule interruption counts will not increase beyond $x_{0} + \\sqrt{H}\\sigma$ nor decrease below $x_{0} - \\sqrt{H}\\sigma$, where $H$ is the number of future data points and $\\sigma^{2}$ is the variance of the past data points, up to $x_{0}$.\n\n\\subsection{Model of Cost Impact Due to Schedule Interruptions}\n\nUsing lemma $(\\ref{X1})$ and eq. $(\\ref{X2})$ in section $(\\ref{app})$, we see that the future interruption counts are the sum of the last interruption count plus $0$-mean, white noise with variance, $H\\sigma^{2}$, obtained in section $(\\ref{bounds})$.  By the Markov property, also shown in section $(\\ref{bounds})$, noise associated with future schedule interruption counts is $0$-mean with respect to $x_{0}$, so that we have a normal distribution with mean given by a horizontal line extending from $x_{0}$, of length exactly $H$ months.  To complete the future data space, we have the familiar ``bell'' shape with standard deviation $\\sqrt{k}\\sigma$, for $k \\in \\{1,2,...,H\\}$ corresponding to each month in the $H$-month future time span, which extends beyond the end of the historical data set.\n\n\\subsubsection{Average Monthly Cost Per Schedule Interruption}\n\\label{avgcost}\n\nWith an application of the Central Limit Theorem, we can make the assumption of an approximately normal distribution for the total cost impact due only to delays $(D)$, cancellations $(C)$, diversions $(d)$ and air-turn-backs $(A)$.  Hence, using a maximum likelihood technique, we see that the best estimate of the true mean of the distribution is given by the average cost impact for the sum of the historical counts of the different delay classes. As such, we first calculate the \\textbf{delay class average monthly cost impact (ADC)} per interruption for a $K$-month historical period as\n\n\n", "itemtype": "equation", "pos": 7421, "prevtext": "\nwhere $x_{(k)}$ and $\\overline{x}$ are the $k^{th}$ element in an ordering of $\\{x_{k}\\}_{k = 1}^{K}$ and its sample mean, respectively, and $(a_{1},...,a_{K})$ is computed as\n\n", "index": 19, "text": "\\begin{equation}\n(a_{1},...,a_{K}) = \\frac{m^{T}V^{-1}}{m^{T}V^{-1}V^{-1}m},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"(a_{1},...,a_{K})=\\frac{m^{T}V^{-1}}{m^{T}V^{-1}V^{-1}m},\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>a</mi><mi>K</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi>m</mi><mi>T</mi></msup><mo>\u2062</mo><msup><mi>V</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mrow><msup><mi>m</mi><mi>T</mi></msup><mo>\u2062</mo><msup><mi>V</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mi>V</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>m</mi></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nwhere $C_{D}$, $C_{C}$, $C_{d}$ and $C_{A}$ are the average costs associated with delays, cancellations, diversions and air-turn-backs.\n\nMaking another appeal to the Central Limit Theorem for the distribution of total cost impact due only to spares replacements $(S)$, we next calculate an estimate of the mean of the distribution as\n\n\n", "itemtype": "equation", "pos": 11567, "prevtext": "\nsuch that $m = (m_{1},...,m_{K})$ is a vector of expected values of the order statistics used to give the ordering $\\{x_{(k)}\\}_{k=1}^{K}$ and $V$ is the covariance matrix of the order statistics.\n\n\\begin{definition}\n\\label{SW}\nThe \\textbf{Shapiro-Wilk Test of Normality} is the test statistic $W$, such that, if a level of significance ($p$-value) is assigned in a hypothesis test, where the null hypothesis is that the sample was drawn from a normal distribution, then a value of $W$ which exceeds the probability $(1-2p)$ affirms the null hypothesis.\n\\end{definition}\n\n\\noindent\nThe Shapiro-Wilk test now provides a sufficient condition for testing if the sequence of errors $\\{\\epsilon_{t_{k}}\\}_{k = 1}^{K}$, defined in our Markov model $\\{Y_{t_{k}}\\}_{k = 1}^{K}$, is normally distributed, which amounts to $\\{X_{t_{k}}\\}_{k=1}^{K}$ forming a Markov chain with respect to the model $\\{Y_{t_{k}}\\}_{k = 1}^{K}$.\n\n\\section{Airline Schedule Interruption Counts Exhibit the Markov Property}\n\n\\subsection{Problem Statement}\n\nTo a manufacturer of large airliners, a schedule interruption is any event that causes an airliner to be more than 15 minutes late on its scheduled departure time from an airport or more than 15 minutes late arriving into an airport due to mechanical or electrical failure of a part, subsystem or system on said aircraft.  Given a data set containing a $K$-month period of historical schedule interruption counts, we will present a calculation of bounds on the number of schedule interruptions in the following $H$-month future period, after which, we want to be able to calculate bounds on the total cost impact.\n\n\\subsection{Bounds on Schedule Interruption Counts}\n\\label{bounds}\n\nUsing def. $(\\ref{SW})$, the errors obtained from a proprietary schedule interruptions data set gives a value of $W \\approx 0.90$, which is right at the level of significance when we set $p = 0.05$.  We accept the null hypothesis and conclude that the sequence of errors was drawn from a normal distribution so that the original data set is Markovian, according to the model of $Y_{t_{k}}$ given by eq. $(\\ref{YX})$.  Therefore, by remark $(\\ref{shiryaev})$, we can run the chain up to the end and label this point $x_{0}$.  Then, with probability $1$, future schedule interruption counts will not increase beyond $x_{0} + \\sqrt{H}\\sigma$ nor decrease below $x_{0} - \\sqrt{H}\\sigma$, where $H$ is the number of future data points and $\\sigma^{2}$ is the variance of the past data points, up to $x_{0}$.\n\n\\subsection{Model of Cost Impact Due to Schedule Interruptions}\n\nUsing lemma $(\\ref{X1})$ and eq. $(\\ref{X2})$ in section $(\\ref{app})$, we see that the future interruption counts are the sum of the last interruption count plus $0$-mean, white noise with variance, $H\\sigma^{2}$, obtained in section $(\\ref{bounds})$.  By the Markov property, also shown in section $(\\ref{bounds})$, noise associated with future schedule interruption counts is $0$-mean with respect to $x_{0}$, so that we have a normal distribution with mean given by a horizontal line extending from $x_{0}$, of length exactly $H$ months.  To complete the future data space, we have the familiar ``bell'' shape with standard deviation $\\sqrt{k}\\sigma$, for $k \\in \\{1,2,...,H\\}$ corresponding to each month in the $H$-month future time span, which extends beyond the end of the historical data set.\n\n\\subsubsection{Average Monthly Cost Per Schedule Interruption}\n\\label{avgcost}\n\nWith an application of the Central Limit Theorem, we can make the assumption of an approximately normal distribution for the total cost impact due only to delays $(D)$, cancellations $(C)$, diversions $(d)$ and air-turn-backs $(A)$.  Hence, using a maximum likelihood technique, we see that the best estimate of the true mean of the distribution is given by the average cost impact for the sum of the historical counts of the different delay classes. As such, we first calculate the \\textbf{delay class average monthly cost impact (ADC)} per interruption for a $K$-month historical period as\n\n\n", "index": 21, "text": "\\begin{equation}\nADC = \\frac{\\sum_{k=1}^{K}\\bigg((C_{D}D_{k} + C_{C}C_{k} + C_{d}d_{k} + C_{A}A_{k})/(D_{k}+C_{k}+d_{k}+A_{k})\\bigg)}{K},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"ADC=\\frac{\\sum_{k=1}^{K}\\bigg{(}(C_{D}D_{k}+C_{C}C_{k}+C_{d}d_{k}+C_{A}A_{k})/%&#10;(D_{k}+C_{k}+d_{k}+A_{k})\\bigg{)}}{K},\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mo>\u2062</mo><mi>D</mi><mo>\u2062</mo><mi>C</mi></mrow><mo>=</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>C</mi><mi>D</mi></msub><mo>\u2062</mo><msub><mi>D</mi><mi>k</mi></msub></mrow><mo>+</mo><mrow><msub><mi>C</mi><mi>C</mi></msub><mo>\u2062</mo><msub><mi>C</mi><mi>k</mi></msub></mrow><mo>+</mo><mrow><msub><mi>C</mi><mi>d</mi></msub><mo>\u2062</mo><msub><mi>d</mi><mi>k</mi></msub></mrow><mo>+</mo><mrow><msub><mi>C</mi><mi>A</mi></msub><mo>\u2062</mo><msub><mi>A</mi><mi>k</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>D</mi><mi>k</mi></msub><mo>+</mo><msub><mi>C</mi><mi>k</mi></msub><mo>+</mo><msub><mi>d</mi><mi>k</mi></msub><mo>+</mo><msub><mi>A</mi><mi>k</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow><mi>K</mi></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01700.tex", "nexttext": "\nwhere $ASC$ is the \\textbf{average monthly spares cost} per interruption.  Thus, our average monthly costs per schedule interruption in the $K$-month period is estimated to be the sum $ADC+ASC$.  Now, by corollary $(\\ref{growth})$, for each month in the $H$-month period beyond the end of the historical data set, our \\textbf{future average cost impact} due to schedule interruptions is bounded below by $(x_{0}-\\sqrt{k}\\sigma)*(ADC+ASC)$ and bounded above by $(x_{0}+\\sqrt{k}\\sigma)*(ADC+ASC)$ for each $k \\in \\{1,2,...,H\\}$.  By corollary $(\\ref{growth})$, with probability 1, these costs bound our future, $H$-month total cost impact to provide the familiar ``bell'' shape of our normally distributed future data set, by lemma $(\\ref{Z})$.\n\n\\subsubsection{Cost Prediction of Schedule Interruption Counts}\n\nNow that we have our average schedule interruption costs bounded with probability 1, as stated in section $(\\ref{avgcost})$, a prediction of future average costs per schedule interruption can be obtained by sampling from the normal distribution whose mean and variance are given by $x_{0}*(ADC+ASC)$ and $k\\sigma^{2}*(ADC+ASC)$, respectively, for each $k \\in \\{1,...,H\\}$.\n\n\\begin{thebibliography}{99}\n\n\\bibitem{Hogg}\nHogg, R.V., McKean, J., Craig, A.T. (2012),\n{\\it Introduction to Mathematical Statistics ($7^{th}$ Edition)},\nPearson.\n\n\\bibitem{Shapiro}\nShapiro, S.S., Wilk, M.B. (1965),\n{\\it An Analysis of Variance Test for Normality (Complete Samples)},\n{\\it Biometrika, Volume 52, pp. 591 - 611, 1965}\n\n\\bibitem{Shiryaev}\nShiryaev, A.N. (1996),\n{\\it Probability},\nSpringer.\n\n\\end{thebibliography}\n\n\n", "itemtype": "equation", "pos": 12055, "prevtext": "\nwhere $C_{D}$, $C_{C}$, $C_{d}$ and $C_{A}$ are the average costs associated with delays, cancellations, diversions and air-turn-backs.\n\nMaking another appeal to the Central Limit Theorem for the distribution of total cost impact due only to spares replacements $(S)$, we next calculate an estimate of the mean of the distribution as\n\n\n", "index": 23, "text": "\\begin{equation}\nASC = \\frac{\\sum_{k=1}^{K}\\bigg(C_{S}S_{k}/(D_{k}+C_{k}+d_{k}+A_{k})\\bigg)}{K},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"ASC=\\frac{\\sum_{k=1}^{K}\\bigg{(}C_{S}S_{k}/(D_{k}+C_{k}+d_{k}+A_{k})\\bigg{)}}{%&#10;K},\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>C</mi></mrow><mo>=</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><mrow><msub><mi>C</mi><mi>S</mi></msub><mo>\u2062</mo><msub><mi>S</mi><mi>k</mi></msub></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>D</mi><mi>k</mi></msub><mo>+</mo><msub><mi>C</mi><mi>k</mi></msub><mo>+</mo><msub><mi>d</mi><mi>k</mi></msub><mo>+</mo><msub><mi>A</mi><mi>k</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow><mi>K</mi></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}]