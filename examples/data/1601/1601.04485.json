[{"file": "1601.04485.tex", "nexttext": "\n  with\n  \n", "itemtype": "equation", "pos": 16582, "prevtext": "\n\n\\title{TDOA Matrices: Algebraic Properties and their Application to Robust Denoising with Missing Data}\n\\author{Jose~Velasco,\\thanks{J.~Velasco, D.~Pizarro, and J.~Macias-Guarasa are with the Department of Electronics, Escuela Polit\u00e9cnica\n    Superior, University of Alcal\u00e1, 28805 Alcal\u00e1 de Henares, Spain.}\n  Daniel~Pizarro,\nJavier~Macias-Guarasa\nand~Afsaneh~Asaei,\\thanks{A.~Asaei is\n  with Idiap Research Institute, Martigny, Switzerland.}\n\\thanks{E-mails: \\{jose.velasco, pizarro, macias\\}@depeca.uah.es,\n  \\nobreak afsaneh.asaei@idiap.ch).}\n\\thanks{Manuscript received Month Day, 2015; revised Month Day, 2015.}}\n\n\n\\maketitle\n\n\n\n\\begin{abstract}\n  Measuring the Time delay of Arrival (TDOA) between a set of sensors\n  is the basic setup for many applications, such as localization or\n  signal beamforming. This paper presents the set of TDOA matrices,\n  which are built from noise-free TDOA measurements, not requiring\n  knowledge of the sensor array geometry. We prove that TDOA matrices\n  are rank-two and have a special SVD decomposition that leads to a\n  compact linear parametric representation. Properties of TDOA\n  matrices are applied in this paper to perform denoising, by finding\n  the TDOA matrix closest to the matrix composed with noisy\n  measurements.  The paper shows that this problem admits a\n  closed-form solution for TDOA measurements contaminated with\n  Gaussian noise which extends to the case of having missing data. The\n  paper also proposes a novel robust denoising method resistant to\n  outliers, missing data and inspired in recent advances in robust\n  low-rank estimation. Experiments in synthetic and real datasets show\n  significant improvements of the proposed denoising algorithms in\n  TDOA-based localization, both in terms of TDOA accuracy estimation\n  and localization error.\n\\end{abstract}\n\n\n\\section{Introduction}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\IEEEPARstart{T}{ime} delay of arrival (TDOA) estimation is an\nessential pre-processing step for multiple applications in the context\nof sensor array processing, such as multi-channel source\nlocalization~\\cite{Sheng2005MaximumLikelihood},\nself-calibration~\\cite{kuang2013stratified} and\nbeamforming~\\cite{anguera2007acoustic}. In all cases, performance is\ndirectly related to the accuracy of the estimated TDOAs\n\\cite{brandstein01}.\n\nEstimating TDOA in noisy environments has been subject of study during\nthe last two decades \\cite{carter1981special, chen2006time,\n  ho2012bias}, and is still an active area of research, benefiting\nfrom current advances in signal processing and optimization\nstrategies~\\cite{alameda2014geometric, compagnoni2014comprehensive,\n  nouvellet2014slowness, huang2015tdoa}. \n\nTypically, the TDOA between a single pair of sensors is obtained by\nmeasuring the peak of the generalized cross-correlation (GCC) of the\nreceived signals on each sensor~\\cite{dibiase2001robust}, which are\nassumed to be generated from a single source. Many factors, such as the\nspectral content of the signal, multipath propagation, and noise\ncontribute to errors in the estimation of the TDOA. \n\nGiven a set of sensors, TDOA measurements can be obtained for every\npossible pair of sensors. This is commonly known as the \\emph{full TDOA\n  set} or \\emph{spherical set}~\\cite{yang2006theoretical}. This paper\nstudies how to reduce noise and errors from the full TDOA set. The\nintuition behind this denoising is to exploit redundancy of the full\nTDOA set. For $n$ sensors, the full set of $n(n-1)/2$ measurements can\nbe represented by $n-1$ values, which are referred to as the\n\\emph{non-redundant set}.  This problem has been studied in the past,\nshowing that one can optimally obtain the non-redundant set when TDOA\nmeasurements are contaminated with additive Gaussian noise. This is\nknown as the Gauss-Markov estimator~\\cite{hahn73optimun}. However, in\nmore realistic scenarios errors are not Gaussian and some of the TDOA\nmeasurements may contain outliers. In these cases the Gauss-Markov\nestimator performs poorly.\n\nThis paper presents the TDOA matrix, which is created by the\narrangement of the full TDOA set inside a skew-symmetric matrix, and\nstudies the algebraic properties of this matrix, showing that it has\nrank $2$ and a SVD decomposition with $n-1$ degrees of freedom. Such\nmatrices have been previously defined in the\nliterature~\\cite{Zhu2011}, but their properties and applications have\nnot been studied until now.\n\nThese algebraic properties are used in this paper to perform denoising\nunder different scenarios, which include the presence of missing TDOA\nmeasurements and outliers. These denoising algorithms are tested in\nthe context of speaker localization with microphone arrays, using\nsynthetic and publicly available real datasets.  Our denoising\nalgorithms are able to recover accurate TDOA values for high rates of\nmissing data and outliers, significantly outperforming the\nGauss-Markov estimator in those cases. All the proposed methods don't\nrequire knowledge of the sensor positions, so that they can also be\nused for calibration~\\cite{kuang2013stratified}.\n\n\n\nThe main contributions of this work are threefold: \\emph{i)} Definition\nof the algebraic properties of TDOA matrices. \\emph{ii)} A closed-form\nsolution for TDOA denoising for Gaussian noise and the presence of\nmissing data. \\emph{iii)} Novel robust-denoising methods for handling\nadditive correlated noise, outliers and missing data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Notation}\n\nReal scalar values are represented by lowercase letters ({e.g.~}\n$\\delta$). Vectors are by default arranged column-wise and are\nrepresented by lowercase bold letters ({e.g.~} ${\\mathbf}{x}$). Matrices are\nrepresented by uppercase bold letters ({e.g.~} ${\\mathbf}{M}$). Lower-case\nletters are reserved to define vector and set sizes ({e.g.~} vector\n${\\mathbf}{x}=(x_1,\\cdots,x_n)^\\top$ is of size $n$), and ${\\mathbf}{x}^\\top$\ndenotes transpose of vector ${\\mathbf}{x}$. Calligraphic fonts are reserved\nto represent generic sets (e.g. $\\mathcal{G}$) or functions applied to\nmatrices (e.g. $\\mathcal{P}({\\mathbf}{X})$). The $l_2$ norm $\\|\\cdot\\|_2$\nwill be written by default as $\\|\\cdot\\|$ for simplicity, and\n$\\|\\cdot\\|_F$ is the Frobenius norm, while $|\\cdot|$ is reserved to\nrepresent absolute values of scalars. The $l_0$ norm of a matrix, written\n$\\|\\cdot\\|_0$, is defined as the number of non-zero\nelements of the matrix. ${\\mathbf}{A}{\\,\\circ\\,}{\\mathbf}{B}$ is the hadamard product between\n${\\mathbf}{A}$ and ${\\mathbf}{B}$, defined as the entrywise multiplication of\nthe corresponding matrices. ${\\operatorname{tr}}(\\cdot)$ is the trace function.\n\nWe also define the normalized unitary vector ${\\mathbf}{\\hat{1}}$ as\n${\\mathbf}{\\hat{1}}=\\nobreak \\left( 1, \\dotsc, 1 \\right)^\\top/\\sqrt{n}$, and\nthe null vector ${\\mathbf}{\\hat{0}}$ as ${\\mathbf}{\\hat{0}}=\\nobreak \\left( 0,\n\\dotsc, 0 \\right)^\\top$, both of them having size $n$. Finally,\n$\\mathds{1}=n~{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top$ is a $n\\times n$\nmatrix with all elements equal to $1$, ${\\mathbf}{D_x}$ is a $n\\times n$\ndiagonal matrix where its main diagonal is the vector ${\\mathbf}{x}$, and\n${\\mathbf}{I}$ is the identity matrix.\n\n\\subsection{Paper Structure}\n\nThe rest of the paper is distributed as\nfollows. Section~\\ref{sec:related-work} describes related work and\nSection~\\ref{sec:problem-statement} the problem statement. In\nsection~\\ref{sec:DefTDOA} TDOA matrices are described along with a\nderivation of their properties. TDOA denoising in the Gaussian noise\ncase is addressed in section~\\ref{sec:denoising}, also providing a\nclosed-form solution. In sections~\\ref{sec:robust-denoising}\nand~\\ref{sec:missing-data} we propose novel algorithms for robust\nhandling of noise and missing data, respectively, and in\nsection~\\ref{sec:robust-missing} we combine them. We also provide an\nextensive experimentation to validate the proposed algorithms using both\nsynthetic (Section~\\ref{sec:synthetic-data}) and real data\n(Section~\\ref{sec:real-data}). Finally, conclusions are drawn in\nsection~\\ref{sec:conclusions}.\n\n\n\\section{Related Work}\n\\label{sec:related-work}\n\nTDOA estimation is an essential first step for multiple applications\nrelated to localization, self-calibration and beamforming, among others.\n\nTDOA based localization is widely used in radar, sonar and acoustics,\nsince no synchronization between the source and sensor is needed. The\nTDOA information is combined with knowledge of the sensors' positions to\ngenerate a Maximum Likelihood spatial estimator made from hyperbolas\nintersected in some optimal sense. A linear closed-form solution of the\nformer problem, valid when the TDOA estimation errors are small, is\ngiven in \\cite{chan1994simple}.\n\nSince knowing the position of sensors is mandatory for localization\ntechniques, some strategies have been also proposed in order to\ncalibrate them using only TDOA measurements. In\n\\cite{pollefeys2008direct, kuang2013stratified}, the TDOA problem\nis converted in a Time of Arrival (TOA) problem estimating the departure\ntime of signals. Then, self-calibration techniques for TOA can be\nemployed. The main drawback of this approach is that the conversion step\nfrom TDOA to TOA is very sensitive to outliers and correlated noise.\n\nA precise TDOA estimation is also critical for beamforming techniques\nand its applications. In \\cite{anguera2007acoustic}, for example,\nadditional steps are proposed for selecting the appropriate TDOA value\namong the correlation peaks, and also dealing with TDOA outliers. These\nsteps include a Viterbi decoding based algorithm which maximizes the\ncontinuity of the estimation in several frames, but their approach is\nmainly empirical, not attempting to benefit from the redundancy of the\nTDOA measurements.\n\nHence, an accurate estimation of TDOA is essential for a good\nperformance of any of the former applications based in these\nmeasurements. \n\nTypically, when only two sensors are employed, the peak of the\ngeneralized cross-correlation (GCC) function of the signals of two\nsensors is a good estimator for the TDOA, for reasonable noise and\nreverberation levels~\\cite{dibiase2001robust}. \n\nWhen more than two sensors are used ($n>2$), there are $n(n-1)/2$\ndifferent TDOA measurements from all possible pairs of sensors, forming\nthe \\emph{full TDOA set} or \\emph{spherical\n  set}~\\cite{yang2006theoretical}.  However, all those TDOA measurements\nare redundant. In fact, usually one sensor is considered the reference\nsensor, and only the subset of $n-1$ TDOA measurements which involve\nthat sensor are considered. That \\emph{non-redundant set} is the\nset of measurement used by the majority of TDOA-based positioning\nalgorithms proposed in the literature~\\cite{smith1987closed,\n  chan1994simple, gillette2008linear, weng2011total, lin2013new,\n  jamali2013sparsity}. Nevertheless, an optimal (denoised) version of\nthe non-redundant set can be estimated from the redundant set using a\nBayesian Linear Unbiased Estimator (BLUE), also known as the\nGauss-Markov estimator \\cite{hahn73optimun}.\n\nA closed-form solution for the BLUE estimator is provided in\n\\cite{so2008closed}, also proving that it is equal to the standard least\nsquares estimator, and that it reaches the Cramer-Rao lower bound for\npositioning estimation. However, all the results in that work are based\non the assumption of additive Gaussian noise, which is unrealistic in\nmany practical applications~\\cite{renaux2007unconditional}, and doesn't\nyield good results when correlated noise is present as a consequence, for\ninstance, of multipath propagation. Additionally, the experimental\nresults shown in their work are only applied to synthetic data, thus\nseverely limiting its application in real scenarios.\n\nSince periodicity in correlated signals, coherent noise and multi-path\ndue to reverberation are the major sources of non-Gaussian error in TDOA\nestimation, different approaches have been proposed to deal with them. A\nbasic method consists in making the GCC function more robust,\nde-emphasizing the frequency-dependent weighting. The Phase Transform\n(PHAT)~\\cite{knapp1976GCC} is one example of this procedure which has\nreceived considerable attention as the basis of acoustic source\nlocalization systems due to its robustness in real world\nscenarios~\\cite{Zhang2008PHAT, velasco2014}. Other approaches are based\nin blind estimation of multi-path (room impulse response)\n\\cite{benesty2000adaptive} but they need a good initialization to\nperform well. \n\nSome previous works have also proposed more complicated structures in\norder to represent TDOA redundancy, while not imposing strong\nassumptions on the noise\ndistribution. In~\\cite{scheuing2008disambiguation} a representation\nbased in graphs allows to disambiguate if a peak in correlation was\ngenerated by the direct path or by reverberation applying an efficient\nsearch algorithm among all possible combinations. However, they do not\nexplicitly attempt to provide improved TDOA estimations by exploiting\ntheir redundancy. On the other hand, \\cite{schmidt1996least} presents\nand studies a structure based in multivectors, with a tensor notation\nthat allow them to also denoise TDOA estimations. Unfortunately, they\nstill keep the Gaussian noise assumption and the experimental analysis\nis only based on simulated data. Additionaly, those works do not face\nthe problem of outliers and missing measurements in the TDOA values.\n\n\n\n\n\n\n\n\nAlso different matrix representations have been used in the bibliography\nregarding TDOA formulation. For example \\cite{annibale2013tdoa} uses a\nrepresentation slightly different to the TDOA matrices we describe here,\nbut such representation does not have the algebraic properties that TDOA\nmatrices have, and their authors do not address an study in this sense.\n\n\nSo, to the best of our knowledge, there are no previous reported work\ndealing with improving TDOA estimations by exploiting their redundancy,\nwhile not imposing Gaussian noise restrictions, and being able to deal\nwith the presence of outliers and missing measurements (errors that will\nseverely impact the performance of applications based in TDOA\nmeasurements). In this paper we show that TDOA matrices are a powerful\ntool that combined with recent advances in robust low-rank estimation,\nare able to generate novel solutions for these problems.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Problem Statement}\n\\label{sec:problem-statement}\n\nHereafter, we assume only one source located at the position\n${\\mathbf}{r}=(r_x,r_y,r_z)^\\top$, and ${n}$ sensors synchronized\nbetween them and placed in different positions\n${{\\mathbf}{s}_i =\\nobreak (s_{ix}, s_{iy},\n  s_{iz})^\\top},\\,i\\in\\nobreak[1,{n}]$.\n\nGiven this setup, we will assume that the source is emitting an unknown\nsignal $x(t)$. Then, the signal received by the sensor~$i$, $x_i(t)$, is\nwithout loss of generality, a delayed and attenuated version of $x(t)$\n(direct propagation) in addition to a signal $g_i(t)$ which summarizes\nall the adverse effects, i.e. noise, interference, multipath, etc. Thus,\n$x_i(t)=\\nobreak x(t-\\nobreak \\tau_i)+\\nobreak g_i(t)$, where $\\tau_i=\\|{\\mathbf}{r}-{\\mathbf}{s}_i\\|_2/c$ is\nthe time of arrival (TOA) of the signal $x(t)$ at the sensor\n${\\mathbf}{s}_i$, being $c$ the propagation speed.\n\nAssuming that TOA cannot be estimated directly, the time delay of\narrival (TDOA) between the sensors $i$ and $j$ is estimated by\ncorrelating the received signals $x_i(t)$ and $x_j(t)$ (typically\nusing the Generalized Cross-Correlation\nGCC~\\cite{knapp1976GCC}).\n\n\n\\section{TDOA matrices}\n\\label{sec:DefTDOA}\n\nIn this section we define TDOA matrices, and develop their main\nproperties. In a nutshell, given any TDOA matrix ${\\mathbf}{M}$, we show\nthat: \\emph{i)} ${\\mathbf}{M}$ is rank $2$ (Theorem~\\ref{th:rank}) and\n\\emph{ii)}~${\\mathbf}{M}$ can be decomposed as ${\\mathbf}{M}=\\nobreak\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)$\nwith ${\\mathbf}{x}={\\mathbf}{M} {\\,} {\\mathbf}{\\hat{1}}$ (Theorem~\\ref{th:subspace}).\n\nThese properties are the foundations of the denoising algorithms that we\npresent in sections~\\ref{sec:denoising} and~\\ref{sec:robust-denoising},\nand the missing data recovery proposal described in\nsection~\\ref{sec:missing-data}, plus their combination described in\nsection~\\ref{sec:robust-missing}.\n\n\\subsection{Definition of TDOA matrices}\n\\label{sec:defin-tdoa-matr}\n\n\\begin{definition} A TDOA matrix ${\\mathbf}{M}$, is a\n  $(n \\times n)$ skew-symmetric matrix where the element\n  $(i,j)$\n  is the time difference of arrival (TDOA) between the signals arriving\n  at sensor $i$ and sensor $j$:\n  \n", "index": 1, "text": "\\begin{equation}\n    \\label{eq:M_definition}\n    {\\mathbf}{M} =\\left\\{\\Delta\\tau_{ij}\\right\\}=\\begin{pmatrix}\n      0 & \\Delta\\tau_{12} & \\cdots & \\Delta\\tau_{1n} \\\\\n      \\Delta\\tau_{21} & 0 & \\cdots & \\Delta\\tau_{2n}\\\\\n      \\vdots & \\vdots & \\ddots & \\vdots  \\\\\n      \\Delta\\tau_{n1} & \\Delta\\tau_{n2} & \\cdots & 0\n    \\end{pmatrix}\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\left\\{\\Delta\\tau_{ij}\\right\\}=\\begin{pmatrix}0&amp;\\Delta\\tau_{12}%&#10;&amp;\\cdots&amp;\\Delta\\tau_{1n}\\\\&#10;\\Delta\\tau_{21}&amp;0&amp;\\cdots&amp;\\Delta\\tau_{2n}\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;\\Delta\\tau_{n1}&amp;\\Delta\\tau_{n2}&amp;\\cdots&amp;0\\end{pmatrix}\" display=\"block\"><mrow><mi>M</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>}</mo></mrow><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mn>12</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>n</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mn>21</mn></msub></mrow></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>n</mi><mo>\u2062</mo><mn>1</mn></mrow></msub></mrow></mtd><mtd columnalign=\"center\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>n</mi><mo>\u2062</mo><mn>2</mn></mrow></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  where $\\tau_i$ is the time of arrival of the signal $x(t)$ at the\n  sensor ${\\mathbf}{s}_i$. \n\\end{definition}\n\nWe will also express ${\\mathbf}{M}$ in terms of its columns as ${\\mathbf}{M} = \\nobreak \\left( {\\mathbf}{m}_1, {\\mathbf}{m}_2,\n    \\cdots , {\\mathbf}{m}_n \\right)$, being ${\\mathbf}{m}_i = \\nobreak \\left(\n\\Delta\\tau_{1i}, \\Delta\\tau_{2i}, \\ldots, \\Delta\\tau_{ni}\n\\right)^\\top$.\n\nWe denote as ${\\mathcal{M}_{T}(n)}$ to the set of TDOA matrices of size $n \\times n$. \n\nNotice that there is a bijection between the full TDOA set and the\ncorresponding TDOA matrix. Nevertheless expressing TDOA measurements\nas a matrix has important advantages, that we will discover throughout\nthis article. \n\nNote also that in the former definition, knowing the sensor array\ngeometry is not required. For a given geometry, all the feasible TDOA\nmatrices (those that are consistent with that particular geometry) are\na subset of ${\\mathcal{M}_{T}(n)}$. Studying the properties of such subset is out\nof the scope of this paper and the interested reader can refer\nto~\\cite{alameda2014geometric,compagnoni2014comprehensive,compagnoni2015denoising}\nfor further details.\n\n\\subsection{Algebraic properties of TDOA matrices}\n\\label{sec:TDOA_properties}\n\n\\subsubsection{Rank Properties}\n\n\\begin{theorem}\n  \\label{th:rank}\n  Let ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, then ${\\mathbf}{M}$ is rank 2.\n\\end{theorem}\n\\begin{IEEEproof}\n  The matrix ${\\mathbf}{M}$ can be expressed as:\n  \n", "itemtype": "equation", "pos": 16944, "prevtext": "\n  with\n  \n", "index": 3, "text": "\\begin{equation}\n    \\label{eq:tau}\n    \\Delta\\tau_{ij}=\\nobreak\\left(\\tau_i-\\tau_j\\right),\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\Delta\\tau_{ij}=\\nobreak\\left(\\tau_{i}-\\tau_{j}\\right),\" display=\"block\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>-</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  where ${\\mathbf}{T}$ is a rank 1 matrix defined as:\n  \n", "itemtype": "equation", "pos": 18522, "prevtext": "\n  where $\\tau_i$ is the time of arrival of the signal $x(t)$ at the\n  sensor ${\\mathbf}{s}_i$. \n\\end{definition}\n\nWe will also express ${\\mathbf}{M}$ in terms of its columns as ${\\mathbf}{M} = \\nobreak \\left( {\\mathbf}{m}_1, {\\mathbf}{m}_2,\n    \\cdots , {\\mathbf}{m}_n \\right)$, being ${\\mathbf}{m}_i = \\nobreak \\left(\n\\Delta\\tau_{1i}, \\Delta\\tau_{2i}, \\ldots, \\Delta\\tau_{ni}\n\\right)^\\top$.\n\nWe denote as ${\\mathcal{M}_{T}(n)}$ to the set of TDOA matrices of size $n \\times n$. \n\nNotice that there is a bijection between the full TDOA set and the\ncorresponding TDOA matrix. Nevertheless expressing TDOA measurements\nas a matrix has important advantages, that we will discover throughout\nthis article. \n\nNote also that in the former definition, knowing the sensor array\ngeometry is not required. For a given geometry, all the feasible TDOA\nmatrices (those that are consistent with that particular geometry) are\na subset of ${\\mathcal{M}_{T}(n)}$. Studying the properties of such subset is out\nof the scope of this paper and the interested reader can refer\nto~\\cite{alameda2014geometric,compagnoni2014comprehensive,compagnoni2015denoising}\nfor further details.\n\n\\subsection{Algebraic properties of TDOA matrices}\n\\label{sec:TDOA_properties}\n\n\\subsubsection{Rank Properties}\n\n\\begin{theorem}\n  \\label{th:rank}\n  Let ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, then ${\\mathbf}{M}$ is rank 2.\n\\end{theorem}\n\\begin{IEEEproof}\n  The matrix ${\\mathbf}{M}$ can be expressed as:\n  \n", "index": 5, "text": "\\begin{equation}\n    {\\mathbf}{M} ={\\mathbf}{T}-{\\mathbf}{T}^\\top,\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}={\\mathbf{}}{T}-{\\mathbf{}}{T}^{\\top},\" display=\"block\"><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mi>T</mi><mo>-</mo><msup><mi>T</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  Applying the well known inequality:\n  \n", "itemtype": "equation", "pos": 18662, "prevtext": "\n  where ${\\mathbf}{T}$ is a rank 1 matrix defined as:\n  \n", "index": 7, "text": "\\begin{equation}\n    \\label{eq:T_definition}\n    {\\mathbf}{T}=\\begin{pmatrix}\n      \\tau_1 & \\cdots & \\tau_1 \\\\\n      \\vdots  & \\ddots & \\vdots  \\\\\n      \\tau_n & \\cdots & \\tau_n\n    \\end{pmatrix}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{T}=\\begin{pmatrix}\\tau_{1}&amp;\\cdots&amp;\\tau_{1}\\\\&#10;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;\\tau_{n}&amp;\\cdots&amp;\\tau_{n}\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mi>T</mi><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>\u03c4</mi><mn>1</mn></msub></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msub><mi>\u03c4</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>\u03c4</mi><mi>n</mi></msub></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msub><mi>\u03c4</mi><mi>n</mi></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  we can deduce that ${\\operatorname{rank}}({\\mathbf}{M})\\leq2$.  \n\n  Moreover, since the rank of any skew-symmetric matrix must be even,\n  rank 1 is not feasible. So we can conclude that, excepting the case\n  that ${\\mathbf}{M}$ is the zero matrix (trivial case), the rank of\n  ${\\mathbf}{M}$ is 2. This completes the proof.\n\\end{IEEEproof}\n\nRank deficiency of TDOA matrices means that their rows and columns are\nlinearly dependent. That is consistent with the fact that, in the\nnoise-free case, the full TDOA set can be generated from the\nnon-redundant set using linear equations \\cite{so2008closed}. In fact,\nin a TDOA matrix, the column $j$ is the TDOA non-redundant set when\nthe sensor $j$ is the reference for TDOA measurements. Hereafter, and\nwithout loss of generality, we will consider the first sensor as the\nreference for the non redundant-set.\n\n\n\n\n\n\\begin{lemma}\n  \\label{lemma:1}\n  The normalized unitary vector ${\\mathbf}{\\hat{1}}$ can be expressed as a\n  linear combination of any two column vectors of ${\\mathbf}{M} \\in\\nobreak \n  {\\mathcal{M}_{T}(n)}$.\n\\end{lemma}\n\\begin{IEEEproof}\nIndeed, from (\\ref{eq:M_definition}) and (\\ref{eq:tau}), given any two column vectors of ${\\mathbf}{M}$, namely ${\\mathbf}{m}_i$ and ${\\mathbf}{m}_j$ with $i\\neq j$, the\nrelation:\n\n", "itemtype": "equation", "pos": 18917, "prevtext": "\n  Applying the well known inequality:\n  \n", "index": 9, "text": "\\begin{equation}\n    \\label{eq:rank_ineq}\n    {\\operatorname{rank}}({\\mathbf}{A}+{\\mathbf}{B})\\leq{\\operatorname{rank}}({\\mathbf}{A})+{\\operatorname{rank}}({\\mathbf}{B}),\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"{\\operatorname{rank}}({\\mathbf{}}{A}+{\\mathbf{}}{B})\\leq{\\operatorname{rank}}(%&#10;{\\mathbf{}}{A})+{\\operatorname{rank}}({\\mathbf{}}{B}),\" display=\"block\"><mrow><mrow><mrow><mo>rank</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>+</mo><mi>B</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mo>rank</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mo>rank</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nis satisfied. This completes the proof.\n\\end{IEEEproof}\n\n\\subsubsection{Singular Value Decomposition}\n\\label{sec:svd}\n\n\nBecause ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ is a skew-symmetric matrix of rank 2, it has the following singular value decomposition (SVD)~\\cite[Supplementary\nmaterial]{ye2012robust}:\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 20385, "prevtext": "\n  we can deduce that ${\\operatorname{rank}}({\\mathbf}{M})\\leq2$.  \n\n  Moreover, since the rank of any skew-symmetric matrix must be even,\n  rank 1 is not feasible. So we can conclude that, excepting the case\n  that ${\\mathbf}{M}$ is the zero matrix (trivial case), the rank of\n  ${\\mathbf}{M}$ is 2. This completes the proof.\n\\end{IEEEproof}\n\nRank deficiency of TDOA matrices means that their rows and columns are\nlinearly dependent. That is consistent with the fact that, in the\nnoise-free case, the full TDOA set can be generated from the\nnon-redundant set using linear equations \\cite{so2008closed}. In fact,\nin a TDOA matrix, the column $j$ is the TDOA non-redundant set when\nthe sensor $j$ is the reference for TDOA measurements. Hereafter, and\nwithout loss of generality, we will consider the first sensor as the\nreference for the non redundant-set.\n\n\n\n\n\n\\begin{lemma}\n  \\label{lemma:1}\n  The normalized unitary vector ${\\mathbf}{\\hat{1}}$ can be expressed as a\n  linear combination of any two column vectors of ${\\mathbf}{M} \\in\\nobreak \n  {\\mathcal{M}_{T}(n)}$.\n\\end{lemma}\n\\begin{IEEEproof}\nIndeed, from (\\ref{eq:M_definition}) and (\\ref{eq:tau}), given any two column vectors of ${\\mathbf}{M}$, namely ${\\mathbf}{m}_i$ and ${\\mathbf}{m}_j$ with $i\\neq j$, the\nrelation:\n\n", "index": 11, "text": "\\begin{equation}\n  \\label{eq:col_relation}\n  \\frac{{\\mathbf}{m}_i-{\\mathbf}{m}_j}{\\left(\\tau_j-\\tau_i\\right)\\,\\sqrt{n}}=\\nobreak{\\mathbf}{\\hat{1}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\frac{{\\mathbf{}}{m}_{i}-{\\mathbf{}}{m}_{j}}{\\left(\\tau_{j}-\\tau_{i}\\right)\\,%&#10;\\sqrt{n}}=\\nobreak{\\mathbf{}}{\\hat{1}}\" display=\"block\"><mrow><mfrac><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>-</mo><msub><mi>m</mi><mi>j</mi></msub></mrow><mrow><mrow><mo>(</mo><mrow><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>-</mo><msub><mi>\u03c4</mi><mi>i</mi></msub></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><msqrt><mi>n</mi></msqrt></mrow></mfrac><mo>=</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n\n\n\n\n\n\n\n\n\nwhere ${\\mathbf}{\\hat{u}}_1$ and ${\\mathbf}{\\hat{u}}_2$ are orthonormal vectors and $\\sigma\\geq 0$. Note that the SVD decomposition of $\\mathbf{M}$ is not unique. Given any orthogonal $2\\times 2$ matrix ${\\mathbf}{R}$, the vectors $\\left({\\mathbf}{\\hat{v}}_1,{\\mathbf}{\\hat{v}}_2\\right)=\\left({\\mathbf}{\\hat{u}}_1,{\\mathbf}{\\hat{u}}_2\\right){\\,}{\\mathbf}{R}$ represent also a valid SVD decomposition:\n\n", "itemtype": "equation", "pos": 20859, "prevtext": "\nis satisfied. This completes the proof.\n\\end{IEEEproof}\n\n\\subsubsection{Singular Value Decomposition}\n\\label{sec:svd}\n\n\nBecause ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ is a skew-symmetric matrix of rank 2, it has the following singular value decomposition (SVD)~\\cite[Supplementary\nmaterial]{ye2012robust}:\n\n\n\n\n\n\n", "index": 13, "text": "\\begin{equation}\n  \\label{eq:TDOA_svd}\n  {\\mathbf}{M} =\\left({\\mathbf}{\\hat{u}}_2,\n    -{\\mathbf}{\\hat{u}}_1\\right) \\begin{pmatrix}\\sigma&0\\\\0&\\sigma\\end{pmatrix}\\left({\\mathbf}{\\hat{u}}_1,\n    {\\mathbf}{\\hat{u}}_2\\right)^\\top=\\sigma  \\left({\\mathbf}{\\hat{u}}_2,\n    -{\\mathbf}{\\hat{u}}_1\\right) \\left({\\mathbf}{\\hat{u}}_1, {\\mathbf}{\\hat{u}}_2\\right)^\\top,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\left({\\mathbf{}}{\\hat{u}}_{2},-{\\mathbf{}}{\\hat{u}}_{1}\\right)%&#10;\\begin{pmatrix}\\sigma&amp;0\\\\&#10;0&amp;\\sigma\\end{pmatrix}\\left({\\mathbf{}}{\\hat{u}}_{1},{\\mathbf{}}{\\hat{u}}_{2}%&#10;\\right)^{\\top}=\\sigma\\left({\\mathbf{}}{\\hat{u}}_{2},-{\\mathbf{}}{\\hat{u}}_{1}%&#10;\\right)\\left({\\mathbf{}}{\\hat{u}}_{1},{\\mathbf{}}{\\hat{u}}_{2}\\right)^{\\top},\" display=\"block\"><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>,</mo><mrow><mo>-</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\u03c3</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi>\u03c3</mi></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow><mo>=</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>,</mo><mrow><mo>-</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nAmong all possible SVD decompositions of ${\\mathbf}{M}$ we show next that\nthere always exists one where ${\\mathbf}{\\hat{u}}_1={\\mathbf}{\\hat{1}}$. This\nleads to a parametric representation of ${\\mathbf}{M}$ that has important\nproperties that we will exploit later for TDOA denoising.\n\n\\begin{theorem}\n  \\label{th:subspace}\n  \n  \n\n  \n\n\n  Given ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, it admits the following SVD decomposition: \n  \n", "itemtype": "equation", "pos": 21643, "prevtext": "\n\n\n\n\n\n\n\n\n\n\nwhere ${\\mathbf}{\\hat{u}}_1$ and ${\\mathbf}{\\hat{u}}_2$ are orthonormal vectors and $\\sigma\\geq 0$. Note that the SVD decomposition of $\\mathbf{M}$ is not unique. Given any orthogonal $2\\times 2$ matrix ${\\mathbf}{R}$, the vectors $\\left({\\mathbf}{\\hat{v}}_1,{\\mathbf}{\\hat{v}}_2\\right)=\\left({\\mathbf}{\\hat{u}}_1,{\\mathbf}{\\hat{u}}_2\\right){\\,}{\\mathbf}{R}$ represent also a valid SVD decomposition:\n\n", "index": 15, "text": "\\begin{equation}\n  \\label{eq:TDOA_svdunique}\n  {\\mathbf}{M} =\\sigma\\left({\\mathbf}{\\hat{v}}_2,-{\\mathbf}{\\hat{v}}_1\\right)\\left({\\mathbf}{\\hat{v}}_1,{\\mathbf}{\\hat{v}}_2\\right)^\\top=\\sigma\\left({\\mathbf}{\\hat{u}}_2,-{\\mathbf}{\\hat{u}}_1\\right)\\left({\\mathbf}{\\hat{u}}_1,{\\mathbf}{\\hat{u}}_2\\right)^\\top.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\sigma\\left({\\mathbf{}}{\\hat{v}}_{2},-{\\mathbf{}}{\\hat{v}}_{1}%&#10;\\right)\\left({\\mathbf{}}{\\hat{v}}_{1},{\\mathbf{}}{\\hat{v}}_{2}\\right)^{\\top}=%&#10;\\sigma\\left({\\mathbf{}}{\\hat{u}}_{2},-{\\mathbf{}}{\\hat{u}}_{1}\\right)\\left({%&#10;\\mathbf{}}{\\hat{u}}_{1},{\\mathbf{}}{\\hat{u}}_{2}\\right)^{\\top}.\" display=\"block\"><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>v</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>,</mo><mrow><mo>-</mo><msub><mover accent=\"true\"><mi>v</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>v</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>v</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow><mo>=</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>,</mo><mrow><mo>-</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msub><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\\end{theorem}\n\n\n\n\n\n\n \\begin{IEEEproof}\n   According to Theorem~\\ref{th:rank}, the column space of\n   ${\\mathbf}{M}$, lies in a linear subspace of rank 2. Besides, lemma\n   \\ref{lemma:1} states that vector ${\\mathbf}{\\hat{1}}$ belongs to such\n   subspace. Therefore, an orthonormal basis of two vectors\n   $\\left\\{{\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\right\\}$ must exist for the\n   column space of ${\\mathbf}{M}$. The vector\n   ${\\mathbf}{\\hat{u}}=\\nobreak{\\mathbf}{u}/\\left\\|{\\mathbf}{u}\\right\\|$ can be\n   calculated by selecting any column, ${\\mathbf}{m}_i$ with $i=1,\\dots,n$,\n   and applying Gram-Schmidt as follows:\n  \n", "itemtype": "equation", "pos": 22392, "prevtext": "\nAmong all possible SVD decompositions of ${\\mathbf}{M}$ we show next that\nthere always exists one where ${\\mathbf}{\\hat{u}}_1={\\mathbf}{\\hat{1}}$. This\nleads to a parametric representation of ${\\mathbf}{M}$ that has important\nproperties that we will exploit later for TDOA denoising.\n\n\\begin{theorem}\n  \\label{th:subspace}\n  \n  \n\n  \n\n\n  Given ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, it admits the following SVD decomposition: \n  \n", "index": 17, "text": "\\begin{equation}\n    \\label{eq:decomp}\n    \\mathbf{M}=\\sigma\\left({\\mathbf}{\\hat{u}},-{\\mathbf}{\\hat{1}}\\right)\\left({\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\right)^\\top \\quad \\text{with} \\quad {\\mathbf}{\\hat{u}}=\\dfrac{{\\mathbf}{M} {\\,} {\\mathbf}{\\hat{1}}}{\\|{\\mathbf}{M} {\\,} {\\mathbf}{\\hat{1}}\\|} \\quad \\sigma=\\|{\\mathbf}{M} {\\,} {\\mathbf}{\\hat{1}}\\|\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{M}=\\sigma\\left({\\mathbf{}}{\\hat{u}},-{\\mathbf{}}{\\hat{1}}\\right)\\left(%&#10;{\\mathbf{}}{\\hat{1}},{\\mathbf{}}{\\hat{u}}\\right)^{\\top}\\quad\\text{with}\\quad{%&#10;\\mathbf{}}{\\hat{u}}=\\dfrac{{\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{1}}}{\\|{\\mathbf{%&#10;}}{M}{\\,}{\\mathbf{}}{\\hat{1}}\\|}\\quad\\sigma=\\|{\\mathbf{}}{M}{\\,}{\\mathbf{}}{%&#10;\\hat{1}}\\|\" display=\"block\"><mrow><mrow><mi>\ud835\udc0c</mi><mo>=</mo><mrow><mrow><mi>\u03c3</mi><mo>\u2062</mo><mrow><mo>(</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mrow><mo>-</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>with</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mfrac><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2225</mo></mrow></mfrac></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mi>\u03c3</mi><mo>=</mo><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2225</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nOperating, we get ${\\mathbf}{u}=\\nobreak\\left( u_1,\\cdots,u_n \\right)^\\top$, with\n  \n", "itemtype": "equation", "pos": 23384, "prevtext": "\n\\end{theorem}\n\n\n\n\n\n\n \\begin{IEEEproof}\n   According to Theorem~\\ref{th:rank}, the column space of\n   ${\\mathbf}{M}$, lies in a linear subspace of rank 2. Besides, lemma\n   \\ref{lemma:1} states that vector ${\\mathbf}{\\hat{1}}$ belongs to such\n   subspace. Therefore, an orthonormal basis of two vectors\n   $\\left\\{{\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\right\\}$ must exist for the\n   column space of ${\\mathbf}{M}$. The vector\n   ${\\mathbf}{\\hat{u}}=\\nobreak{\\mathbf}{u}/\\left\\|{\\mathbf}{u}\\right\\|$ can be\n   calculated by selecting any column, ${\\mathbf}{m}_i$ with $i=1,\\dots,n$,\n   and applying Gram-Schmidt as follows:\n  \n", "index": 19, "text": "\\begin{equation}\n    \\label{eq:gram-schmidt}\n    {\\mathbf}{u}={\\mathbf}{m}_i-({\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{m}_i){\\mathbf}{\\hat{1}}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{u}={\\mathbf{}}{m}_{i}-({\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{%&#10;m}_{i}){\\mathbf{}}{\\hat{1}}.\" display=\"block\"><mrow><mrow><mi>u</mi><mo>=</mo><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n Note that ${\\mathbf}{u}$ has the same value independently of the column chosen in (\\ref{eq:gram-schmidt}). \n\nAs $\\{{\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\}$ is a basis of the column space of ${\\mathbf}{M}$, there exist two vectors ${\\mathbf}{c}_1$, ${\\mathbf}{c}_2$ such that:\n\n", "itemtype": "equation", "pos": 23625, "prevtext": "\nOperating, we get ${\\mathbf}{u}=\\nobreak\\left( u_1,\\cdots,u_n \\right)^\\top$, with\n  \n", "index": 21, "text": "\\begin{equation}\n    \\label{eq:x_Def}\n  u_i=\\nobreak \\tau_i-\\bar{\\tau} \\quad \\text{and} \\quad  \\bar{\\tau}=\\sum_{j=1}^{n}{\\tau_j}/n.    \n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"u_{i}=\\nobreak\\tau_{i}-\\bar{\\tau}\\quad\\text{and}\\quad\\bar{\\tau}=\\sum_{j=1}^{n}%&#10;{\\tau_{j}}/n.\" display=\"block\"><mrow><mrow><mrow><msub><mi>u</mi><mi>i</mi></msub><mo>=</mo><mrow><mrow><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>-</mo><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mover accent=\"true\"><mi>\u03c4</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>/</mo><mi>n</mi></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n By substituting (\\ref{eq:x_Def}) and (\\ref{eq:M_definition}) into (\\ref{eq:coeffs}), we verify that: \n\n\n", "itemtype": "equation", "pos": 24055, "prevtext": "\n Note that ${\\mathbf}{u}$ has the same value independently of the column chosen in (\\ref{eq:gram-schmidt}). \n\nAs $\\{{\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\}$ is a basis of the column space of ${\\mathbf}{M}$, there exist two vectors ${\\mathbf}{c}_1$, ${\\mathbf}{c}_2$ such that:\n\n", "index": 23, "text": "\\begin{equation}\n  \\label{eq:coeffs}\n {\\mathbf}{M} =\\left({\\mathbf}{c}_1,{\\mathbf}{c}_2 \\right)\\left({\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\right)^\\top, \\quad \\text{with} \\quad {\\mathbf}{c}_1={\\mathbf}{M} {\\,} {\\mathbf}{\\hat{1}} \\quad {\\mathbf}{c}_2={\\mathbf}{M} {\\,} {\\mathbf}{\\hat{u}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\left({\\mathbf{}}{c}_{1},{\\mathbf{}}{c}_{2}\\right)\\left({%&#10;\\mathbf{}}{\\hat{1}},{\\mathbf{}}{\\hat{u}}\\right)^{\\top},\\quad\\text{with}\\quad{%&#10;\\mathbf{}}{c}_{1}={\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{1}}\\quad{\\mathbf{}}{c}_{2%&#10;}={\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{u}}.\" display=\"block\"><mrow><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mrow><mrow><mo>(</mo><msub><mi>c</mi><mn>1</mn></msub><mo>,</mo><msub><mi>c</mi><mn>2</mn></msub><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow><mo rspace=\"12.5pt\">,</mo><mtext>with</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>=</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>=</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nAs a consequence of (\\ref{eq:coeffs2}) we express ${\\mathbf}{M}$ as:\n    \n", "itemtype": "equation", "pos": 24461, "prevtext": "\n By substituting (\\ref{eq:x_Def}) and (\\ref{eq:M_definition}) into (\\ref{eq:coeffs}), we verify that: \n\n\n", "index": 25, "text": "\\begin{equation}\n  \\label{eq:coeffs2}\n  {\\mathbf}{c}_1=\\sqrt{n}~\\|{\\mathbf}{u}\\|~{\\mathbf}{\\hat{u}} \\quad \\text{and} \\quad {\\mathbf}{c}_2=-\\sqrt{n}~\\|{\\mathbf}{u}\\|~{\\mathbf}{\\hat{1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{c}_{1}=\\sqrt{n}~{}\\|{\\mathbf{}}{u}\\|~{}{\\mathbf{}}{\\hat{u}}\\quad%&#10;\\text{and}\\quad{\\mathbf{}}{c}_{2}=-\\sqrt{n}~{}\\|{\\mathbf{}}{u}\\|~{}{\\mathbf{}}%&#10;{\\hat{1}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>=</mo><mrow><mrow><mpadded width=\"+3.3pt\"><msqrt><mi>n</mi></msqrt></mpadded><mo>\u2062</mo><mrow><mo>\u2225</mo><mi>u</mi><mo rspace=\"5.8pt\">\u2225</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>=</mo><mrow><mo>-</mo><mrow><mpadded width=\"+3.3pt\"><msqrt><mi>n</mi></msqrt></mpadded><mo>\u2062</mo><mrow><mo>\u2225</mo><mi>u</mi><mo rspace=\"5.8pt\">\u2225</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": " \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTherefore, from (\\ref{eq:M_decomposition}) we have:\n  \n", "itemtype": "equation", "pos": -1, "prevtext": "\nAs a consequence of (\\ref{eq:coeffs2}) we express ${\\mathbf}{M}$ as:\n    \n", "index": 27, "text": "\\begin{equation}\n    \\label{eq:M_decomposition}\n    {\\mathbf}{M} =\\sqrt{n}~\\left\\|{\\mathbf}{u}\\right\\|\\left({\\mathbf}{\\hat{u}},-{\\mathbf}{\\hat{1}}\\right)\\left({\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{u}}\\right)^\\top.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\sqrt{n}~{}\\left\\|{\\mathbf{}}{u}\\right\\|\\left({\\mathbf{}}{\\hat{%&#10;u}},-{\\mathbf{}}{\\hat{1}}\\right)\\left({\\mathbf{}}{\\hat{1}},{\\mathbf{}}{\\hat{u}%&#10;}\\right)^{\\top}.\" display=\"block\"><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mpadded width=\"+3.3pt\"><msqrt><mi>n</mi></msqrt></mpadded><mo>\u2062</mo><mrow><mo>\u2225</mo><mi>u</mi><mo>\u2225</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mrow><mo>-</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nfrom which it follows (\\ref{eq:decomp}). This completes the proof.\n\n\n\\end{IEEEproof}\n\\begin{coro}\n   \\label{th:TDOA_decom}\n   Any ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ can be expressed as:\n   \n", "itemtype": "equation", "pos": 25102, "prevtext": " \n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTherefore, from (\\ref{eq:M_decomposition}) we have:\n  \n", "index": 29, "text": "\\begin{equation}\n    \\label{eq:relationships}\n    {\\mathbf}{\\hat{u}}=\\frac{{\\mathbf}{M} {\\,}{\\mathbf}{\\hat{1}}}{\\left\\|{{\\mathbf}{M} {\\,}{\\mathbf}{\\hat{1}}}\\right\\|}, \\qquad \\sigma=\\sqrt{n}~\\|{\\mathbf}{u}\\|=\\left\\|{\\mathbf}{M} {\\,}{\\mathbf}{\\hat{1}}\\right\\|,\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{\\hat{u}}=\\frac{{\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{1}}}{\\left\\|{{%&#10;\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{1}}}\\right\\|},\\qquad\\sigma=\\sqrt{n}~{}\\|{%&#10;\\mathbf{}}{u}\\|=\\left\\|{\\mathbf{}}{M}{\\,}{\\mathbf{}}{\\hat{1}}\\right\\|,\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>u</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mfrac><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2225</mo></mrow></mfrac></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>\u03c3</mi><mo>=</mo><mrow><mpadded width=\"+3.3pt\"><msqrt><mi>n</mi></msqrt></mpadded><mo>\u2062</mo><mrow><mo>\u2225</mo><mi>u</mi><mo>\u2225</mo></mrow></mrow><mo>=</mo><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>M</mi></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2225</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\\end{coro}\nThe derivation of (\\ref{eq:TDOA_decom}) follows by substitution of\n${\\mathbf}{x}=\\sigma{\\mathbf}{\\hat{u}}$ in (\\ref{eq:M_decomposition}). Note also\nthat according to~\\eqref{eq:relationships} ${\\mathbf}{x}$ can be derived\ndirectly from ${\\mathbf}{M}$ since ${\\mathbf}{x}={\\mathbf}{M} {\\,}{\\mathbf}{\\hat{1}}$.\n\\begin{coro}\n\\label{cor:alter_decomp}\n${\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}$ can also be expressed as:\n\n\n", "itemtype": "equation", "pos": 25572, "prevtext": "\nfrom which it follows (\\ref{eq:decomp}). This completes the proof.\n\n\n\\end{IEEEproof}\n\\begin{coro}\n   \\label{th:TDOA_decom}\n   Any ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ can be expressed as:\n   \n", "index": 31, "text": "\\begin{equation}\n   \\label{eq:TDOA_decom}\n   {\\mathbf}{M} =\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)\\quad,~~\\,{\\mathbf}{x}\\perp{\\mathbf}{\\hat{1}} \n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\left({\\mathbf{}}{x}{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}-{\\mathbf{}}%&#10;{\\hat{1}}{\\,}{\\mathbf{}}{x}^{\\top}\\right)\\quad,~{}~{}\\,{\\mathbf{}}{x}\\perp{%&#10;\\mathbf{}}{\\hat{1}}\" display=\"block\"><mrow><mi>M</mi><mo>=</mo><mrow><mo>(</mo><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>-</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><msup><mi>x</mi><mo>\u22a4</mo></msup><mo>)</mo></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mo rspace=\"10.8pt\">,</mo><mi>x</mi><mo>\u27c2</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nsince ${\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top={\\mathbf}{D_x}{\\,}\\mathds{1}/\\sqrt{n}$\nand ${\\mathbf}{\\hat{1}}{\\,}\\nobreak{\\mathbf}{x}^\\top=\\nobreak\\mathds{1}{\\,}\\nobreak{\\mathbf}{D_x}/\\sqrt{n}$,\n\\end{coro}\n\n\n\n\\section{TDOA Denoising}\n\\label{sec:denoising}\n\nIn this section we propose a denoising strategy to deal with Gaussian\nnoise in the estimated TDOA measurements, deriving a closed form\nsolution for the proposed optimization problem. This solution is also\ncompared with the Gauss-Markov Estimator.\n\n\\subsection{Denoising Strategy}\n\\label{sec:denoising-strategy}\n\n\nWe assume now that each TDOA measurement is contaminated with\nuncorrelated Gaussian noise $n_{ij}=-n_{ji}$, such that\n$\\Delta\\tilde{\\tau}_{ij}=\\Delta\\tau_{ij}+n_{ij}$. Therefore, the\nmeasured TDOA matrix\n$\\tilde{{\\mathbf}{M}}=\\left\\{\\Delta\\tilde{\\tau}_{ij}\\right\\}$ \nis also a skew-symmetric matrix, sum of a noise-free ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ and a\nskew-symmetric matrix containing noise ${\\mathbf}{N}=\\left\\{n_{ij} \\right\\}$:\n\n", "itemtype": "equation", "pos": 26208, "prevtext": "\n\\end{coro}\nThe derivation of (\\ref{eq:TDOA_decom}) follows by substitution of\n${\\mathbf}{x}=\\sigma{\\mathbf}{\\hat{u}}$ in (\\ref{eq:M_decomposition}). Note also\nthat according to~\\eqref{eq:relationships} ${\\mathbf}{x}$ can be derived\ndirectly from ${\\mathbf}{M}$ since ${\\mathbf}{x}={\\mathbf}{M} {\\,}{\\mathbf}{\\hat{1}}$.\n\\begin{coro}\n\\label{cor:alter_decomp}\n${\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}$ can also be expressed as:\n\n\n", "index": 33, "text": "\\begin{equation}\n  \\label{eq:TDOA_alter_decomp} \n  {\\mathbf}{M} =\\frac{1}{\\sqrt{n}}\\left({\\mathbf}{D_x}{\\,}\\mathds{1}-\\mathds{1}{\\,}{\\mathbf}{D_x}\\right)\\quad,\\,{\\mathbf}{\\hat{1}}\\perp{\\mathbf}{\\hat{x}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}=\\frac{1}{\\sqrt{n}}\\left({\\mathbf{}}{D_{x}}{\\,}\\mathds{1}-%&#10;\\mathds{1}{\\,}{\\mathbf{}}{D_{x}}\\right)\\quad,\\,{\\mathbf{}}{\\hat{1}}\\perp{%&#10;\\mathbf{}}{\\hat{x}},\" display=\"block\"><mrow><mi>M</mi><mo>=</mo><mfrac><mn>1</mn><msqrt><mi>n</mi></msqrt></mfrac><mrow><mo>(</mo><msub><mi>D</mi><mi>x</mi></msub><mn mathvariant=\"double-struck\">\u20091</mn><mo>-</mo><mpadded width=\"+1.7pt\"><mn>\ud835\udfd9</mn></mpadded><msub><mi>D</mi><mi>x</mi></msub><mo>)</mo></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mo rspace=\"4.2pt\">,</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u27c2</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">^</mo></mover><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nBecause of the noise, $\\tilde{{\\mathbf}{M}} \\notin {\\mathcal{M}_{T}(n)}$ and thus\nTheorem~\\ref{th:rank} is no longer satisfied. Consequently, the rank of\n$\\tilde{{\\mathbf}{M}}$ may be higher than two. Nevertheless, we will show\nthat we can take advantage of the structure of TDOA matrices in order to\ndenoise the measured data.\n\nFor denoising, we propose finding the closest ${\\mathbf}{M}^{\\ast}\n\\in\\nobreak {\\mathcal{M}_{T}(n)}$, to the measured matrix $\\tilde{{\\mathbf}{M}}$, in\nthe sense of the Frobenius norm. This approach yields the following\noptimization problem:\n\n", "itemtype": "equation", "pos": 27441, "prevtext": "\nsince ${\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top={\\mathbf}{D_x}{\\,}\\mathds{1}/\\sqrt{n}$\nand ${\\mathbf}{\\hat{1}}{\\,}\\nobreak{\\mathbf}{x}^\\top=\\nobreak\\mathds{1}{\\,}\\nobreak{\\mathbf}{D_x}/\\sqrt{n}$,\n\\end{coro}\n\n\n\n\\section{TDOA Denoising}\n\\label{sec:denoising}\n\nIn this section we propose a denoising strategy to deal with Gaussian\nnoise in the estimated TDOA measurements, deriving a closed form\nsolution for the proposed optimization problem. This solution is also\ncompared with the Gauss-Markov Estimator.\n\n\\subsection{Denoising Strategy}\n\\label{sec:denoising-strategy}\n\n\nWe assume now that each TDOA measurement is contaminated with\nuncorrelated Gaussian noise $n_{ij}=-n_{ji}$, such that\n$\\Delta\\tilde{\\tau}_{ij}=\\Delta\\tau_{ij}+n_{ij}$. Therefore, the\nmeasured TDOA matrix\n$\\tilde{{\\mathbf}{M}}=\\left\\{\\Delta\\tilde{\\tau}_{ij}\\right\\}$ \nis also a skew-symmetric matrix, sum of a noise-free ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$ and a\nskew-symmetric matrix containing noise ${\\mathbf}{N}=\\left\\{n_{ij} \\right\\}$:\n\n", "index": 35, "text": "\\begin{equation}\n  \\label{eq:noisy_M}\n  \\tilde{{\\mathbf}{M}}={\\mathbf}{M} +{\\mathbf}{N}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\tilde{{\\mathbf{}}{M}}={\\mathbf{}}{M}+{\\mathbf{}}{N}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>=</mo><mrow><mi>M</mi><mo>+</mo><mi>N</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n\\subsection{Closed-Form Solution}\n\\label{sec:closed-form}\n\\begin{theorem}\n  \\label{th:closed-form}\n  Problem~\\eqref{eq:denoising} has the following closed form solution: $ {\\mathbf}{M}^\\ast=(\\tilde{{\\mathbf}{M}}{\\,}\\mathds{1}+\\mathds{1}{\\,}\\tilde{{\\mathbf}{M}})/n$\n\\end{theorem}\n\\begin{IEEEproof}\n  From Corollary \\ref{th:TDOA_decom}, the denoising problem\n  \\eqref{eq:denoising} is equivalent to the following constrained\n  convex optimization problem:\n  \n", "itemtype": "equation", "pos": 28116, "prevtext": "\nBecause of the noise, $\\tilde{{\\mathbf}{M}} \\notin {\\mathcal{M}_{T}(n)}$ and thus\nTheorem~\\ref{th:rank} is no longer satisfied. Consequently, the rank of\n$\\tilde{{\\mathbf}{M}}$ may be higher than two. Nevertheless, we will show\nthat we can take advantage of the structure of TDOA matrices in order to\ndenoise the measured data.\n\nFor denoising, we propose finding the closest ${\\mathbf}{M}^{\\ast}\n\\in\\nobreak {\\mathcal{M}_{T}(n)}$, to the measured matrix $\\tilde{{\\mathbf}{M}}$, in\nthe sense of the Frobenius norm. This approach yields the following\noptimization problem:\n\n", "index": 37, "text": "\\begin{equation}\n  \\label{eq:denoising}\n  {\\mathbf}{M}^{\\ast}= \\underset{{\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}\n  }{\\operatorname{arg\\,min}}\\quad\\left\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M} \\right\\|_F^2.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}^{\\ast}=\\underset{{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}}{%&#10;\\operatorname{arg\\,min}}\\quad\\left\\|\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{M}%&#10;\\right\\|_{F}^{2}.\" display=\"block\"><mrow><mrow><msup><mi>M</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n Using the definition of Frobenius norm \n  $\\|{\\mathbf}{A}\\|_F^2={\\operatorname{tr}}({\\mathbf}{A} {\\mathbf}{A}^\\top)$, and trace properties\n  ${\\operatorname{tr}}({\\mathbf}{A} {\\mathbf}{B})={\\operatorname{tr}}({\\mathbf}{B} {\\mathbf}{A})$ and\n  ${\\operatorname{tr}}({\\mathbf}{A})={\\operatorname{tr}}({\\mathbf}{A}^\\top)$ we rewrite the cost as:\n\n  \n", "itemtype": "equation", "pos": 28787, "prevtext": "\n\n\\subsection{Closed-Form Solution}\n\\label{sec:closed-form}\n\\begin{theorem}\n  \\label{th:closed-form}\n  Problem~\\eqref{eq:denoising} has the following closed form solution: $ {\\mathbf}{M}^\\ast=(\\tilde{{\\mathbf}{M}}{\\,}\\mathds{1}+\\mathds{1}{\\,}\\tilde{{\\mathbf}{M}})/n$\n\\end{theorem}\n\\begin{IEEEproof}\n  From Corollary \\ref{th:TDOA_decom}, the denoising problem\n  \\eqref{eq:denoising} is equivalent to the following constrained\n  convex optimization problem:\n  \n", "index": 39, "text": "\\begin{equation}\n    \\label{eq:fobenius-min}\n    \\begin{aligned}\n      & \\underset{{\\mathbf}{x}}{\\operatorname{minimize}} & &\n      \\left\\|\\tilde{{\\mathbf}{M}}-\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)\\right\\|_F^2 \\\\\n      & \\operatorname{subject\\;to} & &  {\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}=0.\n    \\end{aligned}\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\mathbf{}}{x}}{\\operatorname{minimize}}\" display=\"inline\"><munder accentunder=\"true\"><mo>minimize</mo><mo>\ud835\udc65</mo></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}-\\left({\\mathbf{}}{x}{\\,}{\\mathbf{}}%&#10;{\\hat{1}}^{\\top}-{\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{}}{x}^{\\top}\\right)\\right\\|_%&#10;{F}^{2}\" display=\"inline\"><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mrow><mo>(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\operatorname{subject\\;to}\" display=\"inline\"><mrow><mpadded width=\"+2.8pt\"><mi>subject</mi></mpadded><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}=0.\" display=\"inline\"><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n  To solve the constrained problem \\eqref{eq:fobenius-min} we use the method of Lagrange multipliers, resulting in the following unconstrained equivalent: \n\n\n  \n", "itemtype": "equation", "pos": 29519, "prevtext": "\n Using the definition of Frobenius norm \n  $\\|{\\mathbf}{A}\\|_F^2={\\operatorname{tr}}({\\mathbf}{A} {\\mathbf}{A}^\\top)$, and trace properties\n  ${\\operatorname{tr}}({\\mathbf}{A} {\\mathbf}{B})={\\operatorname{tr}}({\\mathbf}{B} {\\mathbf}{A})$ and\n  ${\\operatorname{tr}}({\\mathbf}{A})={\\operatorname{tr}}({\\mathbf}{A}^\\top)$ we rewrite the cost as:\n\n  \n", "index": 41, "text": "\\begin{multline}\n    \\label{eq:frob_equiv}\n    \\left\\|\\tilde{{\\mathbf}{M}}-\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)\\right\\|_F^2= \\\\\n    ={\\operatorname{tr}}\\left(\\left[\\tilde{{\\mathbf}{M}}-\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)\\right]\\left[\\tilde{{\\mathbf}{M}}-\\left({\\mathbf}{x}{\\,}{\\mathbf}{\\hat{1}}^\\top-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{x}^\\top\\right)\\right]^\\top\\right)\\\\\n    =2\\left({\\mathbf}{x}^\\top{\\,}{\\mathbf}{x} -{\\mathbf}{x}^\\top{\\,}{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}\n      -{\\mathbf}{\\hat{1}}^\\top{\\,}\\tilde{{\\mathbf}{M}}^\\top{\\,}{\\mathbf}{x}\n      +{\\mathbf}{\\hat{1}}^\\top{\\,}\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{x}\n    \\right)+\\\\\n    + {\\operatorname{tr}}{\\left(\\tilde{{\\mathbf}{M}}{\\,}\\tilde{{\\mathbf}{M}}^\\top\\right)=f\\left({\\mathbf}{x};\\tilde{{\\mathbf}{M}}\\right)}.\n  \\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}-\\left({\\mathbf{}}{x}{\\,}{\\mathbf{}}%&#10;{\\hat{1}}^{\\top}-{\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{}}{x}^{\\top}\\right)\\right\\|_%&#10;{F}^{2}=\\\\&#10;\\displaystyle={\\operatorname{tr}}\\left(\\left[\\tilde{{\\mathbf{}}{M}}-\\left({%&#10;\\mathbf{}}{x}{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}-{\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{%&#10;}}{x}^{\\top}\\right)\\right]\\left[\\tilde{{\\mathbf{}}{M}}-\\left({\\mathbf{}}{x}{\\,%&#10;}{\\mathbf{}}{\\hat{1}}^{\\top}-{\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{}}{x}^{\\top}%&#10;\\right)\\right]^{\\top}\\right)\\\\&#10;\\displaystyle=2\\left({\\mathbf{}}{x}^{\\top}{\\,}{\\mathbf{}}{x}-{\\mathbf{}}{x}^{%&#10;\\top}{\\,}{\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}%&#10;-{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\tilde{{\\mathbf{}}{M}}^{\\top}{\\,}{\\mathbf{}}{x%&#10;}+{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\tilde{{\\mathbf{}}{M}}{\\,}{\\mathbf{}}{x}%&#10;\\right)+\\\\&#10;\\displaystyle+{\\operatorname{tr}}{\\left(\\tilde{{\\mathbf{}}{M}}{\\,}\\tilde{{%&#10;\\mathbf{}}{M}}^{\\top}\\right)=f\\left({\\mathbf{}}{x};\\tilde{{\\mathbf{}}{M}}%&#10;\\right)}.\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mrow><mo>(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>=</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mi/><mo>=</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mrow><mo>(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mo>\u2062</mo><msup><mrow><mo>[</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mrow><mo>(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>+</mo><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>)</mo></mrow></mrow><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mrow><mo>+</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  where $\\lambda$ is the Lagrange multiplier and\n  \n", "itemtype": "equation", "pos": 30609, "prevtext": "\n\n  To solve the constrained problem \\eqref{eq:fobenius-min} we use the method of Lagrange multipliers, resulting in the following unconstrained equivalent: \n\n\n  \n", "index": 43, "text": "\\begin{equation}\n    \\label{eq:denoising_dualproblem}\n    {\\mathbf}{x}^\\ast\\,=\\,\\underset{{\\mathbf}{x},\\lambda}{\\operatorname{arg\\,min}}\\,\\left[\\Lambda\\left({\\mathbf}{x};\\lambda\\right)\\right],\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{x}^{\\ast}\\,=\\,\\underset{{\\mathbf{}}{x},\\lambda}{\\operatorname{arg%&#10;\\,min}}\\,\\left[\\Lambda\\left({\\mathbf{}}{x};\\lambda\\right)\\right],\" display=\"block\"><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u2217</mo></msup></mpadded><mo rspace=\"4.2pt\">=</mo><mrow><mpadded width=\"+1.7pt\"><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>x</mi><mo>,</mo><mi>\u03bb</mi></mrow></munder></mpadded><mo>\u2062</mo><mrow><mo>[</mo><mrow><mi mathvariant=\"normal\">\u039b</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mi>\u03bb</mi><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n We find extrema in \\eqref{eq:def_optfun} by taking first derivatives with respect to both ${\\mathbf}{x}$ and $\\lambda$ and solving the following system:\n   \n \n", "itemtype": "equation", "pos": 30870, "prevtext": "\n  where $\\lambda$ is the Lagrange multiplier and\n  \n", "index": 45, "text": "\\begin{equation}\n    \\label{eq:def_optfun}\n    \\Lambda\\left({\\mathbf}{x};\\lambda\\right)=f\\left({\\mathbf}{x};\\tilde{{\\mathbf}{M}}\\right)+\\lambda{\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\Lambda\\left({\\mathbf{}}{x};\\lambda\\right)=f\\left({\\mathbf{}}{x};\\tilde{{%&#10;\\mathbf{}}{M}}\\right)+\\lambda{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}.\" display=\"block\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u039b</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mi>\u03bb</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 31231, "prevtext": "\n\n We find extrema in \\eqref{eq:def_optfun} by taking first derivatives with respect to both ${\\mathbf}{x}$ and $\\lambda$ and solving the following system:\n   \n \n", "index": 47, "text": "\\begin{multline*}\n   \\nabla\\Lambda\\left({\\mathbf}{x};\\lambda\\right)={\\mathbf}{\\hat{0}}\\,\\Rightarrow\\\\\n\\begin{cases} 2{\\mathbf}{x}^\\top\\left( {\\mathbf}{I}-{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top\\right)+{\\mathbf}{\\hat{1}}^\\top\\left(\\tilde{{\\mathbf}{M}}-\\tilde{{\\mathbf}{M}}^\\top\\right)+\\lambda{\\mathbf}{\\hat{1}}^\\top={\\mathbf}{\\hat{0}}^\\top\\\\ {\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}=0\\\\\n\\end{cases}\n \\end{multline*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"p24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\nabla\\Lambda\\left({\\mathbf{}}{x};\\lambda\\right)={\\mathbf{}}{\\hat%&#10;{0}}\\,\\Rightarrow\\\\&#10;\\displaystyle\\begin{cases}2{\\mathbf{}}{x}^{\\top}\\left({\\mathbf{}}{I}-{\\mathbf{%&#10;}}{\\hat{1}}{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}\\right)+{\\mathbf{}}{\\hat{1}}^{\\top}%&#10;\\left(\\tilde{{\\mathbf{}}{M}}-\\tilde{{\\mathbf{}}{M}}^{\\top}\\right)+\\lambda{%&#10;\\mathbf{}}{\\hat{1}}^{\\top}={\\mathbf{}}{\\hat{0}}^{\\top}\\\\&#10;{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}=0\\\\&#10;\\end{cases}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi mathvariant=\"normal\">\u039b</mi></mrow><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mi>\u03bb</mi><mo>)</mo></mrow></mrow><mo>=</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>0</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u21d2</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>I</mi><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow></mrow><mo>=</mo><msup><mover accent=\"true\"><mn>0</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mn>0</mn></mrow></mtd><mtd/></mtr></mtable></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nSince $\\tilde{{\\mathbf}{M}}$ is skew-symmetric $(\\tilde{{\\mathbf}{M}}-\\tilde{{\\mathbf}{M}}^\\top)=2\\tilde{{\\mathbf}{M}}$. Therefore, \\eqref{eq:pre_denoising} becomes:\n\\begin{subequations}\n\n", "itemtype": "equation", "pos": 31651, "prevtext": "\n\n", "index": 49, "text": "\\begin{align}\n        {\\mathbf}{x}^\\ast&=\\frac{\\left(\\tilde{{\\mathbf}{M}}-\\tilde{{\\mathbf}{M}}^\\top\\right){\\mathbf}{\\hat{1}}-\\lambda{\\mathbf}{\\hat{1}}}{2}\\nonumber\\\\\n        \\lambda^\\ast&=\\frac{{\\mathbf}{\\hat{1}}^\\top\\left(\\tilde{{\\mathbf}{M}}-\\tilde{{\\mathbf}{M}}^\\top\\right){\\mathbf}{\\hat{1}}}{2{\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{\\hat{1}}}.\n\\label{eq:pre_denoising}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{x}^{\\ast}\" display=\"inline\"><msup><mi>x</mi><mo>\u2217</mo></msup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{\\left(\\tilde{{\\mathbf{}}{M}}-\\tilde{{\\mathbf{}}{M}}^{\\top}%&#10;\\right){\\mathbf{}}{\\hat{1}}-\\lambda{\\mathbf{}}{\\hat{1}}}{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mn>2</mn></mfrac></mstyle></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda^{\\ast}\" display=\"inline\"><msup><mi>\u03bb</mi><mo>\u2217</mo></msup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{{\\mathbf{}}{\\hat{1}}^{\\top}\\left(\\tilde{{\\mathbf{}}{M}}-%&#10;\\tilde{{\\mathbf{}}{M}}^{\\top}\\right){\\mathbf{}}{\\hat{1}}}{2{\\mathbf{}}{\\hat{1}%&#10;}^{\\top}{\\,}{\\mathbf{}}{\\hat{1}}}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mrow><mn>2</mn><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mfrac></mstyle></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\\end{subequations}\nIn \\eqref{eq:denoising_lambda} we use the fact that ${\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{A}{\\,}{\\mathbf}{\\hat{1}}=0$ for ${\\mathbf}{A}$ being a skew-symmetric matrix.  Also, it is interesting to note from \\eqref{eq:denoising_x} that ${\\mathbf}{x}^\\ast$ follows the same expression as the one stated in Corollary \\ref{th:TDOA_decom} for ${\\mathbf}{x}$ in the noise-free case.\n\nA compact expression for ${\\mathbf}{M}^\\ast$ can be easily derived from\n\\eqref{eq:denoising_x} via \\eqref{eq:TDOA_decom}:\n\n", "itemtype": "equation", "pos": 32221, "prevtext": "\n\nSince $\\tilde{{\\mathbf}{M}}$ is skew-symmetric $(\\tilde{{\\mathbf}{M}}-\\tilde{{\\mathbf}{M}}^\\top)=2\\tilde{{\\mathbf}{M}}$. Therefore, \\eqref{eq:pre_denoising} becomes:\n\\begin{subequations}\n\n", "index": 51, "text": "\\begin{align}\n        {\\mathbf}{x}^\\ast&=\\frac{2\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}-\\lambda{\\mathbf}{\\hat{1}}}{2}=\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}\\label{eq:denoising_x}\\\\\n        \\lambda&=\\frac{2{\\mathbf}{\\hat{1}}^\\top{\\,}\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}}{2{\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{\\hat{1}}}=2{\\mathbf}{\\hat{1}}^\\top{\\,}\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}=0.\\label{eq:denoising_lambda}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{x}^{\\ast}\" display=\"inline\"><msup><mi>x</mi><mo>\u2217</mo></msup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{2\\tilde{{\\mathbf{}}{M}}{\\,}{\\mathbf{}}{\\hat{1}}-\\lambda{%&#10;\\mathbf{}}{\\hat{1}}}{2}=\\tilde{{\\mathbf{}}{M}}{\\,}{\\mathbf{}}{\\hat{1}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mn>2</mn><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mn>2</mn></mfrac></mstyle><mo>=</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda\" display=\"inline\"><mi>\u03bb</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{2{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\tilde{{\\mathbf{}}{M}}{\\,}%&#10;{\\mathbf{}}{\\hat{1}}}{2{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{\\hat{1}}}=2{%&#10;\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\tilde{{\\mathbf{}}{M}}{\\,}{\\mathbf{}}{\\hat{1}}=0.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mrow><mn>2</mn><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mfrac></mstyle><mo>=</mo><mrow><mn>2</mn><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nThis completes the proof.\n\\end{IEEEproof}\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Equivalence with the Gauss-Markov Estimator} \n\\label{sec:equiv-GaussMarkov}\n\nBy operating in \\eqref{eq:closed-form}, each element $(i,j)$ of the denoised matrix ${\\mathbf}{M}^\\ast$ is obtained as follows:\n\n", "itemtype": "equation", "pos": 33183, "prevtext": "\n\\end{subequations}\nIn \\eqref{eq:denoising_lambda} we use the fact that ${\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{A}{\\,}{\\mathbf}{\\hat{1}}=0$ for ${\\mathbf}{A}$ being a skew-symmetric matrix.  Also, it is interesting to note from \\eqref{eq:denoising_x} that ${\\mathbf}{x}^\\ast$ follows the same expression as the one stated in Corollary \\ref{th:TDOA_decom} for ${\\mathbf}{x}$ in the noise-free case.\n\nA compact expression for ${\\mathbf}{M}^\\ast$ can be easily derived from\n\\eqref{eq:denoising_x} via \\eqref{eq:TDOA_decom}:\n\n", "index": 53, "text": "\\begin{multline}\n  \\label{eq:closed-form}\n  {\\mathbf}{M}^\\ast=\\left({\\mathbf}{\\hat{1}},\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}\\right)\\left(-\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}},{\\mathbf}{\\hat{1}}\\right)^\\top=\\tilde{{\\mathbf}{M}}{\\,}{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top+{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top{\\,}\\tilde{{\\mathbf}{M}}=\\\\\n=(\\tilde{{\\mathbf}{M}}{\\,}\\mathds{1}+\\mathds{1}{\\,}\\tilde{{\\mathbf}{M}})/n.\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{M}^{\\ast}=\\left({\\mathbf{}}{\\hat{1}},\\tilde{{\\mathbf{%&#10;}}{M}}{\\,}{\\mathbf{}}{\\hat{1}}\\right)\\left(-\\tilde{{\\mathbf{}}{M}}{\\,}{\\mathbf%&#10;{}}{\\hat{1}},{\\mathbf{}}{\\hat{1}}\\right)^{\\top}=\\tilde{{\\mathbf{}}{M}}{\\,}{%&#10;\\mathbf{}}{\\hat{1}}{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}+{\\mathbf{}}{\\hat{1}}{\\,}{%&#10;\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\tilde{{\\mathbf{}}{M}}=\\\\&#10;\\displaystyle=(\\tilde{{\\mathbf{}}{M}}{\\,}\\mathds{1}+\\mathds{1}{\\,}\\tilde{{%&#10;\\mathbf{}}{M}})/n.\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msup><mi>M</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><mrow><mo>(</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo>,</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>)</mo></mrow><mo>\u22a4</mo></msup></mrow><mo>=</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>+</mo><mrow><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mrow></mrow><mo>=</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mn mathvariant=\"double-struck\">\u20091</mn></mrow><mo>+</mo><mrow><mpadded width=\"+1.7pt\"><mn>\ud835\udfd9</mn></mpadded><mo>\u2062</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mi>n</mi></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nThe closed-form in \\eqref{eq:denoised-element} is identical to the one\nreported in \\cite[eq.(14)]{so2008closed} as the Gauss-Markov estimator of\nthe TDOA measurements, so that all the properties there can be\nextrapolated to this work.\n\n\n\n\n\n\n\n\\section{Robust TDOA Denoising}\n\\label{sec:robust-denoising}\n\nIn some application scenarios, the assumption of uncorrelated white\nnoise made in section~\\ref{sec:denoising} is fully unrealistic.\n\n\n\n\n\n\n\n\n\n\nIn such cases where noise is correlated and measurements are prone to contain outliers in the TDOA measurements, a better model for the\nmeasured matrix is:\n\n", "itemtype": "equation", "pos": 33911, "prevtext": "\nThis completes the proof.\n\\end{IEEEproof}\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Equivalence with the Gauss-Markov Estimator} \n\\label{sec:equiv-GaussMarkov}\n\nBy operating in \\eqref{eq:closed-form}, each element $(i,j)$ of the denoised matrix ${\\mathbf}{M}^\\ast$ is obtained as follows:\n\n", "index": 55, "text": "\\begin{equation}\n  \\label{eq:denoised-element}\n  {\\mathbf}{M}^\\ast=\\{\\Delta\\tau_{ij}^\\ast\\}=\\left\\{\\frac{1}{N}\\left(\\sum_{k=1}^n{\\Delta\\tau_{ik}+\\Delta\\tau_{kj}}\\right)\\right\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}^{\\ast}=\\{\\Delta\\tau_{ij}^{\\ast}\\}=\\left\\{\\frac{1}{N}\\left(\\sum_%&#10;{k=1}^{n}{\\Delta\\tau_{ik}+\\Delta\\tau_{kj}}\\right)\\right\\}.\" display=\"block\"><mrow><mrow><msup><mi>M</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msubsup><mi>\u03c4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2217</mo></msubsup></mrow><mo stretchy=\"false\">}</mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow></mrow><mo>+</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>\u03c4</mi><mrow><mi>k</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow><mo>)</mo></mrow></mrow><mo>}</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nwhere ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, ${\\mathbf}{N}$ is a skew-symmetric matrix\ncontaining Gaussian noise, much like in \\eqref{eq:noisy_M}, and the new\nmatrix ${\\mathbf}{S}$ models the addition of all the outliers. Since the\nnumber of outliers is usually small as compared with the number of\nmeasurements, we will assume ${\\mathbf}{S}$ to be sparse and unknown.\n\nIn order to denoise $\\tilde{{\\mathbf}{M}}$, we propose solving the\nfollowing optimization problem, finding both matrices ${\\mathbf}{M}$ and\n${\\mathbf}{S}$:\n\n", "itemtype": "equation", "pos": 34707, "prevtext": "\n\nThe closed-form in \\eqref{eq:denoised-element} is identical to the one\nreported in \\cite[eq.(14)]{so2008closed} as the Gauss-Markov estimator of\nthe TDOA measurements, so that all the properties there can be\nextrapolated to this work.\n\n\n\n\n\n\n\n\\section{Robust TDOA Denoising}\n\\label{sec:robust-denoising}\n\nIn some application scenarios, the assumption of uncorrelated white\nnoise made in section~\\ref{sec:denoising} is fully unrealistic.\n\n\n\n\n\n\n\n\n\n\nIn such cases where noise is correlated and measurements are prone to contain outliers in the TDOA measurements, a better model for the\nmeasured matrix is:\n\n", "index": 57, "text": "\\begin{equation}\n  \\label{eq:nongaussian_M}\n  \\tilde{{\\mathbf}{M}}={\\mathbf}{M}+{\\mathbf}{N}+{\\mathbf}{S},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"\\tilde{{\\mathbf{}}{M}}={\\mathbf{}}{M}+{\\mathbf{}}{N}+{\\mathbf{}}{S},\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>=</mo><mrow><mi>M</mi><mo>+</mo><mi>N</mi><mo>+</mo><mi>S</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nwhere $k$ is the maximum number of outliers supposed to be present in\nthe TDOA measurements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust denoising in \\eqref{eq:robust-denoising} is a non-convex optimization problem with constraints that are not even differentiable. This kind of optimization problems have been explored in Robust PCA (RPCA)~\\cite{candes2011robust} or robust low-rank factorizations such in GoDec~\\cite{zhou2011godec}. Despite TDOA matrices are low-rank, these algorithms are not well suited here as they do not include all the algebraic constraints in TDOA matrices. \n\nIn order to solve \\eqref{eq:robust-denoising}, we propose an iterative\nalgorithm, inspired in GoDec. It consists of an alternation method in\nwhich ${\\mathbf}{M}$ and ${\\mathbf}{S}$ are obtained in turns, with close-form\nsolutions for these two steps (we use a subindex $t$ to denote the\niteration count):\n\n", "itemtype": "equation", "pos": 35357, "prevtext": "\nwhere ${\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}$, ${\\mathbf}{N}$ is a skew-symmetric matrix\ncontaining Gaussian noise, much like in \\eqref{eq:noisy_M}, and the new\nmatrix ${\\mathbf}{S}$ models the addition of all the outliers. Since the\nnumber of outliers is usually small as compared with the number of\nmeasurements, we will assume ${\\mathbf}{S}$ to be sparse and unknown.\n\nIn order to denoise $\\tilde{{\\mathbf}{M}}$, we propose solving the\nfollowing optimization problem, finding both matrices ${\\mathbf}{M}$ and\n${\\mathbf}{S}$:\n\n", "index": 59, "text": "\\begin{equation}\n  \\label{eq:robust-denoising}\n  \\begin{aligned}\n    & \\underset{{\\mathbf}{M},{\\mathbf}{S}}{\\operatorname{minimize}} & &\n    \\left\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}-{\\mathbf}{S}\\right\\|_F^2 \\\\\n    & \\operatorname{subject\\;to} & & {\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}\\\\\n    & & & \\|{\\mathbf}{S}\\|_0 < 2k,\n  \\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\mathbf{}}{M},{\\mathbf{}}{S}}{\\operatorname{minimize}}\" display=\"inline\"><munder accentunder=\"true\"><mo>minimize</mo><mrow><mi>M</mi><mo>,</mo><mi>S</mi></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{M}-{\\mathbf{}}{S}\\right%&#10;\\|_{F}^{2}\" display=\"inline\"><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi><mo>-</mo><mi>S</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\operatorname{subject\\;to}\" display=\"inline\"><mrow><mpadded width=\"+2.8pt\"><mi>subject</mi></mpadded><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}\" display=\"inline\"><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30Xb.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\|{\\mathbf{}}{S}\\|_{0}&lt;2k,\" display=\"inline\"><mrow><mrow><msub><mrow><mo>\u2225</mo><mi>S</mi><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>&lt;</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>k</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nThe first sub-problem of \\eqref{eq:modified_godec} is the same as our\ndenoising problem in \\eqref{eq:denoising}, therefore ${\\mathbf}{M}_t$ can be updated via\n\\eqref{eq:closed-form}. Then, ${\\mathbf}{S}_t$ is updated via entry-wise\nhard thresholding of $\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t$. Thus:\n\n\n", "itemtype": "equation", "pos": 36580, "prevtext": "\nwhere $k$ is the maximum number of outliers supposed to be present in\nthe TDOA measurements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRobust denoising in \\eqref{eq:robust-denoising} is a non-convex optimization problem with constraints that are not even differentiable. This kind of optimization problems have been explored in Robust PCA (RPCA)~\\cite{candes2011robust} or robust low-rank factorizations such in GoDec~\\cite{zhou2011godec}. Despite TDOA matrices are low-rank, these algorithms are not well suited here as they do not include all the algebraic constraints in TDOA matrices. \n\nIn order to solve \\eqref{eq:robust-denoising}, we propose an iterative\nalgorithm, inspired in GoDec. It consists of an alternation method in\nwhich ${\\mathbf}{M}$ and ${\\mathbf}{S}$ are obtained in turns, with close-form\nsolutions for these two steps (we use a subindex $t$ to denote the\niteration count):\n\n", "index": 61, "text": "\\begin{equation}\n  \\label{eq:modified_godec}\n  \\left\\{\n    \\begin{aligned}\n      {\\mathbf}{M}_t &= \\underset{{\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}}{\\operatorname{arg\\,min}}\\quad\n      \\left\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}-{\\mathbf}{S}_{t-1}\\right\\|_F^2\\\\\n      {\\mathbf}{S}_t &= \\underset{\\|{\\mathbf}{S}\\|_0<2k}{\\operatorname{arg\\,min}}\\quad\n      \\left\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t-{\\mathbf}{S}\\right\\|_F^2\\\\\n    \\end{aligned}\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\left\\{\\begin{aligned} \\displaystyle{\\mathbf{}}{M}_{t}&amp;\\displaystyle=\\underset%&#10;{{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}}{\\operatorname{arg\\,min}}\\quad\\left\\|%&#10;\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{M}-{\\mathbf{}}{S}_{t-1}\\right\\|_{F}^{2}\\\\&#10;\\displaystyle{\\mathbf{}}{S}_{t}&amp;\\displaystyle=\\underset{\\|{\\mathbf{}}{S}\\|_{0}%&#10;&lt;2k}{\\operatorname{arg\\,min}}\\quad\\left\\|\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{M}%&#10;_{t}-{\\mathbf{}}{S}\\right\\|_{F}^{2}\\\\&#10;\\end{aligned}\\right.\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><msub><mi>M</mi><mi>t</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></munder><mo mathsize=\"70%\" separator=\"true\" stretchy=\"false\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><msub><mi>S</mi><mi>t</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><msub><mrow><mo>\u2225</mo><mi>S</mi><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>&lt;</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>k</mi></mrow></mrow></munder><mo mathsize=\"70%\" separator=\"true\" stretchy=\"false\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msub><mi>M</mi><mi>t</mi></msub><mo>-</mo><mi>S</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nwhere $\\mathcal{P}_{l}({\\mathbf}{X})$ is an function which generates a\nmatrix with the same size of ${\\mathbf}{X}$, preserving the $l$ elements of\n${\\mathbf}{X}$ with the largest absolute value, and making the rest of\nelements zero. Note that, since ${\\mathbf}{X}$ is skew symmetric in our\napplication, the result provided by $\\mathcal{P}_{2k}(\\cdot)$ is also\nskew symmetric. \nThe convergence to a local minimum of this algorithm is guaranteed in similar circumstances as GoDec~\\cite{zhou2011godec}, as the solutions to both sub-problems in \\eqref{eq:modified_godec2} are solved globally. \n\n\n\nSo, the proposed robust denoising algorithm is shown in Alg.~\\ref{alg:roden}.\n\n\n\n\n\n\n\n  \\begin{algorithm}[H]\n  \\caption{Robust denoising.}\\label{alg:roden}\n  \\textbf{Require:} $\\tilde{{\\mathbf}{M}}$, $k$, $\\epsilon$ \n  \n  \\textbf{Ensure:} ${\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}$, $\\|{\\mathbf}{S}\\|_0<2k$, \n  \n  $\\enspace$\\footnotesize{1:}$\\enspace$\\normalsize ${\\mathbf}{M}_0=\\tilde{{\\mathbf}{M}}$ ; ${\\mathbf}{S}_0=0$ ; $t=0$\n  \n  $\\enspace$\\footnotesize{2:}$\\enspace$\\normalsize \\textbf{while} $\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t-{\\mathbf}{S}_t\\|_F^2/\\|\\tilde{{\\mathbf}{M}}\\|_F^2>\\epsilon$ \\textbf{do}\n  \n  $\\enspace$\\footnotesize{3:}$\\enspace$\\normalsize $\\quad$ $t=t+1$\n  \n  $\\enspace$\\footnotesize{4:}$\\enspace$\\normalsize $\\quad$ ${\\mathbf}{M}_t=(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1}){\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top+{\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1})$\n  \n  $\\enspace$\\footnotesize{5:}$\\enspace$\\normalsize $\\quad$ ${\\mathbf}{S}_t=\\mathcal{P}_{2k}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t)$ \n  \n  $\\enspace$\\footnotesize{6:}$\\enspace$\\normalsize \\textbf{end while}\n  \n  $\\enspace$\\footnotesize{7:}$\\enspace$\\normalsize \\textbf{return} ${\\mathbf}{M}_t$, ${\\mathbf}{S}_t$\n\\end{algorithm}\n\n\n\n\\ifthenelse{\\equal{{true}}{true}}\n{\nFrom now on, we will refer to this algorithm as {\\texttt{Robust DeN}}.\n}\n\n\n\n\n\\section{Missing Data Recovery}\n\\label{sec:missing-data}\n\n\\subsection{Recovery Strategy}\n\\label{sec:recovery-strategy}\n\nIn real scenarios, there may be situations where some of the elements\nof ${\\mathbf}{\\tilde{M}}$ might not be available (for instance, due to\ncommunications failure) or even when they are available,\nthere are reasons to avoid using them (for example, due to a priori\nknowledge of unreliable measurements, or when calculating the whole\nredundant set is computationally too\ndemanding)~\\cite{compagnoni2015denoising}.\n\n\n\n\nIn such cases, we want to be able to avoid some\nmeasurements, thus performing estimations when part of the values in\n${\\mathbf}{\\tilde{M}}$ are missing. \n\n\n\nIn this section, we address the TDOA matrix completion problem. We\nassume that in a measured TDOA matrix ${\\mathbf}{\\tilde{M}}$, some of\nits elements are unknown, an the rest are contaminated with additive\nGaussian noise. We take advantage of the redundancy present in TDOA\nmatrices to estimate a complete denoised TDOA matrix including the\nmissing entries.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe matrix completion problem is stated as follows:\n\n\n", "itemtype": "equation", "pos": 37341, "prevtext": "\n\nThe first sub-problem of \\eqref{eq:modified_godec} is the same as our\ndenoising problem in \\eqref{eq:denoising}, therefore ${\\mathbf}{M}_t$ can be updated via\n\\eqref{eq:closed-form}. Then, ${\\mathbf}{S}_t$ is updated via entry-wise\nhard thresholding of $\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t$. Thus:\n\n\n", "index": 63, "text": "\\begin{equation}\n  \\label{eq:modified_godec2}\n  \\left\\{\n    \\begin{aligned}\n      {\\mathbf}{M}_t &= \\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1}\\right)\\,{\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top+{\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1}\\right)\\\\\n      {\\mathbf}{S}_t &= \\mathcal{P}_{2k}\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t\\right)\n    \\end{aligned}\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"\\left\\{\\begin{aligned} \\displaystyle{\\mathbf{}}{M}_{t}&amp;\\displaystyle=\\left(%&#10;\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{S}_{t-1}\\right)\\,{\\mathbf{}}{\\hat{1}}{%&#10;\\mathbf{}}{\\hat{1}}^{\\top}+{\\mathbf{}}{\\hat{1}}{\\mathbf{}}{\\hat{1}}^{\\top}%&#10;\\left(\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{S}_{t-1}\\right)\\\\&#10;\\displaystyle{\\mathbf{}}{S}_{t}&amp;\\displaystyle=\\mathcal{P}_{2k}\\left(\\tilde{{%&#10;\\mathbf{}}{M}}-{\\mathbf{}}{M}_{t}\\right)\\end{aligned}\\right.\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><msub><mi>M</mi><mi>t</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow><mo>+</mo><mrow><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><msub><mi>S</mi><mi>t</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msub><mi>M</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n  where ${\\mathbf}{L}$ is a symmetric binary matrix whose element $(i,j)$ is\n  $1$ if the TDOA between the sensor $i$ and $j$ is known, being $0$\n  otherwise. For convenience and without loss of generality, the\n  elements on the main diagonal of ${\\mathbf}{L}$ will be set to $1$.\n\n  Solving \\eqref{eq:matrix_completion} is equivalent to finding the full\n  TDOA matrix whose elements best fit the available elements of\n  ${\\mathbf}{\\tilde{M}}$.  Note that,\n  ${\\mathbf}{L}{\\,\\circ\\,}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M})=(\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-{\\mathbf}{L}{\\,\\circ\\,}{\\mathbf}{M})$,\n  where\n  $\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}=({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}})$ is\n  the result of setting the unknown elements of ${\\mathbf}{\\tilde{M}}$ to\n  zero.\n\n\\subsection{Closed-Form Solution}\n\\label{sec:closed-form-completion}\n\n\\begin{theorem}\n  \\label{th:closed-form-completion}\n  The problem~\\eqref{eq:matrix_completion} has the following closed form solution: $ {\\mathbf}{M}^\\ast=\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\,\\mathds{1}+\\mathds{1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}$\nwhere ${\\mathbf}{D_\\beta}=\\left({\\mathbf}{I}{\\,\\circ\\,}{\\mathbf}{L}{\\mathbf}{L}^\\top\\right)$ is a $n\\times n$\ndiagonal matrix with $\\pmb{\\beta}=\\left( n-\\bar{\\beta}_1,\\cdots,n-\\bar{\\beta}_n\\right)^\\top=\\sqrt{n}{\\,}{\\mathbf}{L}{\\,}{\\mathbf}{\\hat{1}}$ as its\nmain diagonal. $\\bar{\\beta}_i$ is the number of missing measurements\nwith the sensor $i$.\n\\end{theorem}\n\\begin{IEEEproof}\n Using Corollary \\ref{cor:alter_decomp}, problem \\eqref{eq:matrix_completion} is rewritten as\n  \n", "itemtype": "equation", "pos": 40853, "prevtext": "\nwhere $\\mathcal{P}_{l}({\\mathbf}{X})$ is an function which generates a\nmatrix with the same size of ${\\mathbf}{X}$, preserving the $l$ elements of\n${\\mathbf}{X}$ with the largest absolute value, and making the rest of\nelements zero. Note that, since ${\\mathbf}{X}$ is skew symmetric in our\napplication, the result provided by $\\mathcal{P}_{2k}(\\cdot)$ is also\nskew symmetric. \nThe convergence to a local minimum of this algorithm is guaranteed in similar circumstances as GoDec~\\cite{zhou2011godec}, as the solutions to both sub-problems in \\eqref{eq:modified_godec2} are solved globally. \n\n\n\nSo, the proposed robust denoising algorithm is shown in Alg.~\\ref{alg:roden}.\n\n\n\n\n\n\n\n  \\begin{algorithm}[H]\n  \\caption{Robust denoising.}\\label{alg:roden}\n  \\textbf{Require:} $\\tilde{{\\mathbf}{M}}$, $k$, $\\epsilon$ \n  \n  \\textbf{Ensure:} ${\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}$, $\\|{\\mathbf}{S}\\|_0<2k$, \n  \n  $\\enspace$\\footnotesize{1:}$\\enspace$\\normalsize ${\\mathbf}{M}_0=\\tilde{{\\mathbf}{M}}$ ; ${\\mathbf}{S}_0=0$ ; $t=0$\n  \n  $\\enspace$\\footnotesize{2:}$\\enspace$\\normalsize \\textbf{while} $\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t-{\\mathbf}{S}_t\\|_F^2/\\|\\tilde{{\\mathbf}{M}}\\|_F^2>\\epsilon$ \\textbf{do}\n  \n  $\\enspace$\\footnotesize{3:}$\\enspace$\\normalsize $\\quad$ $t=t+1$\n  \n  $\\enspace$\\footnotesize{4:}$\\enspace$\\normalsize $\\quad$ ${\\mathbf}{M}_t=(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1}){\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top+{\\mathbf}{\\hat{1}}{\\mathbf}{\\hat{1}}^\\top(\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1})$\n  \n  $\\enspace$\\footnotesize{5:}$\\enspace$\\normalsize $\\quad$ ${\\mathbf}{S}_t=\\mathcal{P}_{2k}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t)$ \n  \n  $\\enspace$\\footnotesize{6:}$\\enspace$\\normalsize \\textbf{end while}\n  \n  $\\enspace$\\footnotesize{7:}$\\enspace$\\normalsize \\textbf{return} ${\\mathbf}{M}_t$, ${\\mathbf}{S}_t$\n\\end{algorithm}\n\n\n\n\\ifthenelse{\\equal{{true}}{true}}\n{\nFrom now on, we will refer to this algorithm as {\\texttt{Robust DeN}}.\n}\n\n\n\n\n\\section{Missing Data Recovery}\n\\label{sec:missing-data}\n\n\\subsection{Recovery Strategy}\n\\label{sec:recovery-strategy}\n\nIn real scenarios, there may be situations where some of the elements\nof ${\\mathbf}{\\tilde{M}}$ might not be available (for instance, due to\ncommunications failure) or even when they are available,\nthere are reasons to avoid using them (for example, due to a priori\nknowledge of unreliable measurements, or when calculating the whole\nredundant set is computationally too\ndemanding)~\\cite{compagnoni2015denoising}.\n\n\n\n\nIn such cases, we want to be able to avoid some\nmeasurements, thus performing estimations when part of the values in\n${\\mathbf}{\\tilde{M}}$ are missing. \n\n\n\nIn this section, we address the TDOA matrix completion problem. We\nassume that in a measured TDOA matrix ${\\mathbf}{\\tilde{M}}$, some of\nits elements are unknown, an the rest are contaminated with additive\nGaussian noise. We take advantage of the redundancy present in TDOA\nmatrices to estimate a complete denoised TDOA matrix including the\nmissing entries.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe matrix completion problem is stated as follows:\n\n\n", "index": 65, "text": "\\begin{equation}\n    \\label{eq:matrix_completion}\n   {\\mathbf}{M}^{\\ast}= \\underset{{\\mathbf}{M} \\in {\\mathcal{M}_{T}(n)}}{\\operatorname{arg\\,min}}\\quad\\left\\|{\\mathbf}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}\\right)\\right\\|_F^2,\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{M}^{\\ast}=\\underset{{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}}{%&#10;\\operatorname{arg\\,min}}\\quad\\left\\|{\\mathbf{}}{L}{\\,\\circ\\,}\\left(\\tilde{{%&#10;\\mathbf{}}{M}}-{\\mathbf{}}{M}\\right)\\right\\|_{F}^{2},\" display=\"block\"><mrow><mrow><msup><mi>M</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi></mrow><mo>)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n Since $\\mathds{1}$ is the identity element of the hadamard product and\n  ${\\mathbf}{D_x}$ is a diagonal matrix, we can rewrite\n  \\eqref{eq:completion_equiv} as:\n  \n", "itemtype": "equation", "pos": 42792, "prevtext": "\n  where ${\\mathbf}{L}$ is a symmetric binary matrix whose element $(i,j)$ is\n  $1$ if the TDOA between the sensor $i$ and $j$ is known, being $0$\n  otherwise. For convenience and without loss of generality, the\n  elements on the main diagonal of ${\\mathbf}{L}$ will be set to $1$.\n\n  Solving \\eqref{eq:matrix_completion} is equivalent to finding the full\n  TDOA matrix whose elements best fit the available elements of\n  ${\\mathbf}{\\tilde{M}}$.  Note that,\n  ${\\mathbf}{L}{\\,\\circ\\,}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M})=(\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-{\\mathbf}{L}{\\,\\circ\\,}{\\mathbf}{M})$,\n  where\n  $\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}=({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}})$ is\n  the result of setting the unknown elements of ${\\mathbf}{\\tilde{M}}$ to\n  zero.\n\n\\subsection{Closed-Form Solution}\n\\label{sec:closed-form-completion}\n\n\\begin{theorem}\n  \\label{th:closed-form-completion}\n  The problem~\\eqref{eq:matrix_completion} has the following closed form solution: $ {\\mathbf}{M}^\\ast=\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\,\\mathds{1}+\\mathds{1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}$\nwhere ${\\mathbf}{D_\\beta}=\\left({\\mathbf}{I}{\\,\\circ\\,}{\\mathbf}{L}{\\mathbf}{L}^\\top\\right)$ is a $n\\times n$\ndiagonal matrix with $\\pmb{\\beta}=\\left( n-\\bar{\\beta}_1,\\cdots,n-\\bar{\\beta}_n\\right)^\\top=\\sqrt{n}{\\,}{\\mathbf}{L}{\\,}{\\mathbf}{\\hat{1}}$ as its\nmain diagonal. $\\bar{\\beta}_i$ is the number of missing measurements\nwith the sensor $i$.\n\\end{theorem}\n\\begin{IEEEproof}\n Using Corollary \\ref{cor:alter_decomp}, problem \\eqref{eq:matrix_completion} is rewritten as\n  \n", "index": 67, "text": "\\begin{equation}\n    \\label{eq:completion_equiv}\n        \\begin{aligned}\n      & \\underset{{\\mathbf}{x}}{\\operatorname{minimize}} & &\n      \\left\\|\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\frac{{\\mathbf}{L}{\\,\\circ\\,}\\left({\\mathbf}{D_x}\\mathds{1}-\\mathds{1}{\\mathbf}{D_x}\\right)}{\\sqrt{n}}\\right\\|_F^2 \\\\\n      & \\operatorname{subject\\;to} & &  {\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}=0.\n    \\end{aligned}\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\mathbf{}}{x}}{\\operatorname{minimize}}\" display=\"inline\"><munder accentunder=\"true\"><mo>minimize</mo><mo>\ud835\udc65</mo></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\frac{{\\mathbf{}}{L}%&#10;{\\,\\circ\\,}\\left({\\mathbf{}}{D_{x}}\\mathds{1}-\\mathds{1}{\\mathbf{}}{D_{x}}%&#10;\\right)}{\\sqrt{n}}\\right\\|_{F}^{2}\" display=\"inline\"><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mrow><mo>(</mo><mrow><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mn>\ud835\udfd9</mn></mrow><mo>-</mo><mrow><mn>\ud835\udfd9</mn><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></mrow><mo>)</mo></mrow></mrow><msqrt><mi>n</mi></msqrt></mfrac></mstyle></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\operatorname{subject\\;to}\" display=\"inline\"><mrow><mpadded width=\"+2.8pt\"><mi>subject</mi></mpadded><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}=0.\" display=\"inline\"><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nOperating in a similar manner to \\eqref{eq:frob_equiv} we get:\n\n", "itemtype": "equation", "pos": 43373, "prevtext": "\n Since $\\mathds{1}$ is the identity element of the hadamard product and\n  ${\\mathbf}{D_x}$ is a diagonal matrix, we can rewrite\n  \\eqref{eq:completion_equiv} as:\n  \n", "index": 69, "text": "\\begin{equation}\n    \\label{eq:completion_equiv2}\n        \\begin{aligned}\n      & \\underset{{\\mathbf}{x}}{\\operatorname{minimize}} & &\n      \\left\\|\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\frac{\\left({\\mathbf}{D_x}{\\mathbf}{L}-{\\mathbf}{L}{\\mathbf}{D_x}\\right)}{\\sqrt{n}}\\right\\|_F^2 \\\\\n      & \\operatorname{subject\\;to} & &  {\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}=0.\n    \\end{aligned}\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\mathbf{}}{x}}{\\operatorname{minimize}}\" display=\"inline\"><munder accentunder=\"true\"><mo>minimize</mo><mo>\ud835\udc65</mo></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\frac{\\left({\\mathbf%&#10;{}}{D_{x}}{\\mathbf{}}{L}-{\\mathbf{}}{L}{\\mathbf{}}{D_{x}}\\right)}{\\sqrt{n}}%&#10;\\right\\|_{F}^{2}\" display=\"inline\"><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>(</mo><mrow><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></mrow><mo>)</mo></mrow><msqrt><mi>n</mi></msqrt></mfrac></mstyle></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\operatorname{subject\\;to}\" display=\"inline\"><mrow><mpadded width=\"+2.8pt\"><mi>subject</mi></mpadded><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{\\mathbf{}}{x}=0.\" display=\"inline\"><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nUsing the identity\n${\\mathbf}{x}^\\ast\\left({\\mathbf}{A}{\\,\\circ\\,}{\\mathbf}{B}\\right){\\mathbf}{y}={\\operatorname{tr}}\\left({\\mathbf}{D_x}^\\ast{\\mathbf}{A}{\\mathbf}{D_y}{\\mathbf}{B}^\\top\\right)$ we get:\n\n", "itemtype": "equation", "pos": 43835, "prevtext": "\nOperating in a similar manner to \\eqref{eq:frob_equiv} we get:\n\n", "index": 71, "text": "\\begin{multline}\n  \\label{eq:completion_trace}\n  \\left\\|\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\frac{\\left({\\mathbf}{D_x}{\\mathbf}{L}-{\\mathbf}{L}{\\mathbf}{D_x}\\right)}{\\sqrt{n}}\\right\\|_F^2=\\frac{2}{n}{\\operatorname{tr}}\\left({\\mathbf}{D_x}{\\mathbf}{L}{\\mathbf}{L}^\\top{\\mathbf}{D_x}\\right)-\\\\\n  -\n  \\frac{2}{n}{\\operatorname{tr}}\\left({\\mathbf}{D_x}{\\mathbf}{L}{\\mathbf}{D_x}{\\mathbf}{L}\\right)+\\frac{2}{\\sqrt{n}}{\\operatorname{tr}}\\left(\\left[\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right]{\\mathbf}{D_x}{\\mathbf}{L}\\right)+\\\\\n  +{\\operatorname{tr}}\\left(\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right).\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\frac{\\left({\\mathbf%&#10;{}}{D_{x}}{\\mathbf{}}{L}-{\\mathbf{}}{L}{\\mathbf{}}{D_{x}}\\right)}{\\sqrt{n}}%&#10;\\right\\|_{F}^{2}=\\frac{2}{n}{\\operatorname{tr}}\\left({\\mathbf{}}{D_{x}}{%&#10;\\mathbf{}}{L}{\\mathbf{}}{L}^{\\top}{\\mathbf{}}{D_{x}}\\right)-\\\\&#10;\\displaystyle-\\frac{2}{n}{\\operatorname{tr}}\\left({\\mathbf{}}{D_{x}}{\\mathbf{}%&#10;}{L}{\\mathbf{}}{D_{x}}{\\mathbf{}}{L}\\right)+\\frac{2}{\\sqrt{n}}{\\operatorname{%&#10;tr}}\\left(\\left[\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\tilde{{\\mathbf{}}{M}}_{%&#10;\\mathbf{}}{L}^{\\top}\\right]{\\mathbf{}}{D_{x}}{\\mathbf{}}{L}\\right)+\\\\&#10;\\displaystyle+{\\operatorname{tr}}\\left(\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}%&#10;\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}^{\\top}\\right).\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mfrac><mrow><mo>(</mo><mrow><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></mrow><mo>)</mo></mrow><msqrt><mi>n</mi></msqrt></mfrac></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>=</mo><mrow><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow><mo>-</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>-</mo><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mrow><mfrac><mn>2</mn><msqrt><mi>n</mi></msqrt></mfrac><mo>\u2062</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow></mrow><mo>]</mo></mrow><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>)</mo></mrow></mrow></mrow><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>+</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nand finally:\n\n", "itemtype": "equation", "pos": 44717, "prevtext": "\nUsing the identity\n${\\mathbf}{x}^\\ast\\left({\\mathbf}{A}{\\,\\circ\\,}{\\mathbf}{B}\\right){\\mathbf}{y}={\\operatorname{tr}}\\left({\\mathbf}{D_x}^\\ast{\\mathbf}{A}{\\mathbf}{D_y}{\\mathbf}{B}^\\top\\right)$ we get:\n\n", "index": 73, "text": "\\begin{multline}\n  \\label{eq:completion_prev_final}\n  \\left\\|\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\frac{\\left({\\mathbf}{D_x}{\\mathbf}{L}-{\\mathbf}{L}{\\mathbf}{D_x}\\right)}{\\sqrt{n}}\\right\\|_F^2=\\frac{2}{n}{\\mathbf}{x}^\\top{\\,}\\left({\\mathbf}{I}{\\,\\circ\\,}{\\mathbf}{L}{\\mathbf}{L}^\\top\\right){\\,}{\\mathbf}{x}\\\\\n  -\\frac{2}{n}{\\mathbf}{x}^\\top{\\,}\\left({\\mathbf}{L}{\\,\\circ\\,}{\\mathbf}{L}^\\top\\right){\\,}{\\mathbf}{x} +2{\\,}{\\mathbf}{\\hat{1}}^\\top{\\,}\\left(\\left[\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right]{\\,\\circ\\,} L^\\top\\right){\\,}{\\mathbf}{x} +\\\\\n + {\\operatorname{tr}}\\left(\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right) =g\\left({\\mathbf}{x};\\tilde{{\\mathbf}{M}},\\,{\\mathbf}{L}\\right)\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\frac{\\left({\\mathbf%&#10;{}}{D_{x}}{\\mathbf{}}{L}-{\\mathbf{}}{L}{\\mathbf{}}{D_{x}}\\right)}{\\sqrt{n}}%&#10;\\right\\|_{F}^{2}=\\frac{2}{n}{\\mathbf{}}{x}^{\\top}{\\,}\\left({\\mathbf{}}{I}{\\,%&#10;\\circ\\,}{\\mathbf{}}{L}{\\mathbf{}}{L}^{\\top}\\right){\\,}{\\mathbf{}}{x}\\\\&#10;\\displaystyle-\\frac{2}{n}{\\mathbf{}}{x}^{\\top}{\\,}\\left({\\mathbf{}}{L}{\\,\\circ%&#10;\\,}{\\mathbf{}}{L}^{\\top}\\right){\\,}{\\mathbf{}}{x}+2{\\,}{\\mathbf{}}{\\hat{1}}^{%&#10;\\top}{\\,}\\left(\\left[\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\tilde{{\\mathbf{}}{%&#10;M}}_{\\mathbf{}}{L}^{\\top}\\right]{\\,\\circ\\,}L^{\\top}\\right){\\,}{\\mathbf{}}{x}+%&#10;\\\\&#10;\\displaystyle+{\\operatorname{tr}}\\left(\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}%&#10;\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}^{\\top}\\right)=g\\left({\\mathbf{}}{x};%&#10;\\tilde{{\\mathbf{}}{M}},\\,{\\mathbf{}}{L}\\right)\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mfrac><mrow><mo>(</mo><mrow><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></mrow><mo>)</mo></mrow><msqrt><mi>n</mi></msqrt></mfrac></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>=</mo><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>I</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mi>L</mi></mrow><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>-</mo><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>+</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mn>2</mn></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow></mrow><mo rspace=\"4.2pt\">]</mo></mrow><mo rspace=\"4.2pt\">\u2218</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>+</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo rspace=\"4.2pt\">,</mo><mi>L</mi><mo>)</mo></mrow></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nIt is important to note that equations \\eqref{eq:frob_equiv} and\n\\eqref{eq:completion_final} are identical when there is no missing data in $\\tilde{{\\mathbf}{M}}$ (i.e\n${\\mathbf}{L}=\\mathds{1}=n{\\,}{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top$ and\n${\\mathbf}{D_\\beta}=n{\\,}{\\mathbf}{I}$). \n\nWe use the method of Lagrange multipliers to express\n\\eqref{eq:completion_equiv} as the following unconstrained optimization\nproblem:\n\n\n\n\n \n \n", "itemtype": "equation", "pos": 45498, "prevtext": "\nand finally:\n\n", "index": 75, "text": "\\begin{multline}\n  \\label{eq:completion_final}\n  \\left\\|\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\frac{\\left({\\mathbf}{D_x}{\\mathbf}{L}-{\\mathbf}{L}{\\mathbf}{D_x}\\right)}{\\sqrt{n}}\\right\\|_F^2=\\\\\n\\frac{2}{n}\\left({\\mathbf}{x}^\\top{\\,}{\\mathbf}{D_\\beta}{\\,}{\\mathbf}{x}-{\\mathbf}{x}^\\top{\\,}{\\mathbf}{L}{\\,}{\\mathbf}{x} + n{\\,}{\\mathbf}{\\hat{1}}^\\top{\\,}\\left(\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}-\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right){\\,}{\\mathbf}{x}\\right) + \\\\\n+{\\operatorname{tr}}\\left(\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}\\tilde{{\\mathbf}{M}}_{\\mathbf}{L}^\\top\\right)=g({\\mathbf}{x};\\tilde{{\\mathbf}{M}},\\,{\\mathbf}{L}).\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-\\frac{\\left({\\mathbf%&#10;{}}{D_{x}}{\\mathbf{}}{L}-{\\mathbf{}}{L}{\\mathbf{}}{D_{x}}\\right)}{\\sqrt{n}}%&#10;\\right\\|_{F}^{2}=\\\\&#10;\\displaystyle\\frac{2}{n}\\left({\\mathbf{}}{x}^{\\top}{\\,}{\\mathbf{}}{D_{\\beta}}{%&#10;\\,}{\\mathbf{}}{x}-{\\mathbf{}}{x}^{\\top}{\\,}{\\mathbf{}}{L}{\\,}{\\mathbf{}}{x}+n{%&#10;\\,}{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}\\left(\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}-%&#10;\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}^{\\top}\\right){\\,}{\\mathbf{}}{x}\\right)+%&#10;\\\\&#10;\\displaystyle+{\\operatorname{tr}}\\left(\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}%&#10;\\tilde{{\\mathbf{}}{M}}_{\\mathbf{}}{L}^{\\top}\\right)=g({\\mathbf{}}{x};\\tilde{{%&#10;\\mathbf{}}{M}},\\,{\\mathbf{}}{L}).\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mfrac><mrow><mo>(</mo><mrow><mrow><msub><mi>D</mi><mi>x</mi></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><msub><mi>D</mi><mi>x</mi></msub></mrow></mrow><mo>)</mo></mrow><msqrt><mi>n</mi></msqrt></mfrac></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>=</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msub><mi>D</mi><mi>\u03b2</mi></msub></mpadded><mo>\u2062</mo><mi>x</mi></mrow><mo>-</mo><mrow><mpadded width=\"+1.7pt\"><msup><mi>x</mi><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>+</mo><mrow><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi></mrow><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow></mrow><mo rspace=\"4.2pt\">)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>)</mo></mrow></mrow><mo>+</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mrow><mo>+</mo><mrow><mo>tr</mo><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi/></msub><mo>\u2062</mo><msup><mi>L</mi><mo>\u22a4</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>;</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo rspace=\"4.2pt\">,</mo><mi>L</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n By taking derivatives we obtain the following system:\n \n", "itemtype": "equation", "pos": 46565, "prevtext": "\n\nIt is important to note that equations \\eqref{eq:frob_equiv} and\n\\eqref{eq:completion_final} are identical when there is no missing data in $\\tilde{{\\mathbf}{M}}$ (i.e\n${\\mathbf}{L}=\\mathds{1}=n{\\,}{\\mathbf}{\\hat{1}}{\\,}{\\mathbf}{\\hat{1}}^\\top$ and\n${\\mathbf}{D_\\beta}=n{\\,}{\\mathbf}{I}$). \n\nWe use the method of Lagrange multipliers to express\n\\eqref{eq:completion_equiv} as the following unconstrained optimization\nproblem:\n\n\n\n\n \n \n", "index": 77, "text": "\\begin{equation}\n    \\label{eq:def_optfun2}\n    \\Lambda\\left({\\mathbf}{x};\\lambda\\right)=g\\left({\\mathbf}{x};\\tilde{{\\mathbf}{M}},\\,{\\mathbf}{L}\\right)+\\lambda{\\mathbf}{\\hat{1}}^\\top{\\,}{\\mathbf}{x}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m1\" class=\"ltx_Math\" alttext=\"\\Lambda\\left({\\mathbf{}}{x};\\lambda\\right)=g\\left({\\mathbf{}}{x};\\tilde{{%&#10;\\mathbf{}}{M}},\\,{\\mathbf{}}{L}\\right)+\\lambda{\\mathbf{}}{\\hat{1}}^{\\top}{\\,}{%&#10;\\mathbf{}}{x}.\" display=\"block\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u039b</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mi>\u03bb</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo rspace=\"4.2pt\">,</mo><mi>L</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n\n\n\n\n\n \n Since  ${\\mathbf}{\\hat{1}}^\\top{\\mathbf}{x}=0$ implies that $\\mathds{1}{\\mathbf}{x}={\\mathbf}{\\hat{0}}$, we\n substitute in \\eqref{eq:gradient_completion} obtaining:\n\n", "itemtype": "equation", "pos": 46838, "prevtext": "\n By taking derivatives we obtain the following system:\n \n", "index": 79, "text": "\\begin{multline}\n \\label{eq:gradient_completion}\n   \\nabla\\Lambda\\left({\\mathbf}{x};\\lambda\\right)={\\mathbf}{\\hat{0}}\\,\\Rightarrow\\\\\n\\begin{cases}\\frac{2}{n}{\\mathbf}{x}^\\top\\left({\\mathbf}{D_\\beta}-{\\mathbf}{L}\\right)+{\\mathbf}{\\hat{1}}^\\top\\left(\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}^\\top\\right)+\\lambda{\\mathbf}{\\hat{1}}^\\top={\\mathbf}{\\hat{0}}\\\\\n{\\mathbf}{\\hat{1}}^\\top{\\mathbf}{x}=0.\n\\end{cases}\n \\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E40.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\nabla\\Lambda\\left({\\mathbf{}}{x};\\lambda\\right)={\\mathbf{}}{\\hat%&#10;{0}}\\,\\Rightarrow\\\\&#10;\\displaystyle\\begin{cases}\\frac{2}{n}{\\mathbf{}}{x}^{\\top}\\left({\\mathbf{}}{D_%&#10;{\\beta}}-{\\mathbf{}}{L}\\right)+{\\mathbf{}}{\\hat{1}}^{\\top}\\left(\\tilde{{%&#10;\\mathbf{}}{M}}_{{\\mathbf{}}{L}}-\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}^{\\top}%&#10;\\right)+\\lambda{\\mathbf{}}{\\hat{1}}^{\\top}={\\mathbf{}}{\\hat{0}}\\\\&#10;{\\mathbf{}}{\\hat{1}}^{\\top}{\\mathbf{}}{x}=0.\\end{cases}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi mathvariant=\"normal\">\u039b</mi></mrow><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>;</mo><mi>\u03bb</mi><mo>)</mo></mrow></mrow><mo>=</mo><mpadded width=\"+1.7pt\"><mover accent=\"true\"><mn>0</mn><mo stretchy=\"false\">^</mo></mover></mpadded><mo>\u21d2</mo><mi/></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mstyle displaystyle=\"false\"><mfrac><mn>2</mn><mi>n</mi></mfrac></mstyle><mo>\u2062</mo><msup><mi>x</mi><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>-</mo><mi>L</mi></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>-</mo><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi><mo>\u22a4</mo></msubsup></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup></mrow></mrow><mo>=</mo><mover accent=\"true\"><mn>0</mn><mo stretchy=\"false\">^</mo></mover></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></mtd><mtd/></mtr></mtable></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nwhere $\\left({\\mathbf}{\\bar{L}}=\\mathds{1}-{\\mathbf}{L}\\right)$ (logical not operator over all elements of ${\\mathbf}{L}$). Note that: $({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ is symmetric and, furthermore, ${\\mathbf}{\\hat{1}}$ is one of its eigenvectors.\n\n", "itemtype": "equation", "pos": 47463, "prevtext": "\n\n\n\n\n\n\n \n Since  ${\\mathbf}{\\hat{1}}^\\top{\\mathbf}{x}=0$ implies that $\\mathds{1}{\\mathbf}{x}={\\mathbf}{\\hat{0}}$, we\n substitute in \\eqref{eq:gradient_completion} obtaining:\n\n", "index": 81, "text": "\\begin{equation}\n  \\label{eq:solution1_completion}\n  \\frac{2}{n}\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right){\\mathbf}{x}=\\left(\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}^\\top\\right){\\mathbf}{\\hat{1}}-\\lambda{\\mathbf}{\\hat{1}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E41.m1\" class=\"ltx_Math\" alttext=\"\\frac{2}{n}\\left({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}}{\\bar{L}}\\right){\\mathbf{}}%&#10;{x}=\\left(\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}-\\tilde{{\\mathbf{}}{M}}_{{%&#10;\\mathbf{}}{L}}^{\\top}\\right){\\mathbf{}}{\\hat{1}}-\\lambda{\\mathbf{}}{\\hat{1}},\" display=\"block\"><mrow><mrow><mrow><mfrac><mn>2</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mrow><mrow><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>-</mo><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi><mo>\u22a4</mo></msubsup></mrow><mo>)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>-</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nTherefore, if the two terms of \\eqref{eq:solution1_completion} are\nmultiplied on the right by ${\\mathbf}{\\hat{1}}^\\top$ we get:\n\n", "itemtype": "equation", "pos": 47997, "prevtext": "\nwhere $\\left({\\mathbf}{\\bar{L}}=\\mathds{1}-{\\mathbf}{L}\\right)$ (logical not operator over all elements of ${\\mathbf}{L}$). Note that: $({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ is symmetric and, furthermore, ${\\mathbf}{\\hat{1}}$ is one of its eigenvectors.\n\n", "index": 83, "text": "\\begin{equation}\n  \\label{eq:eigenvector}\n  \\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right){\\mathbf}{\\hat{1}}=\\frac{\\pmb{\\beta}+\\pmb{\\bar{\\beta}}}{\\sqrt{n}}=n{\\mathbf}{\\hat{1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E42.m1\" class=\"ltx_Math\" alttext=\"\\left({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}}{\\bar{L}}\\right){\\mathbf{}}{\\hat{1}}=%&#10;\\frac{\\boldsymbol{\\beta}+\\boldsymbol{\\bar{\\beta}}}{\\sqrt{n}}=n{\\mathbf{}}{\\hat%&#10;{1}}.\" display=\"block\"><mrow><mrow><mrow><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>=</mo><mfrac><mrow><mi>\ud835\udf37</mi><mo>+</mo><mover accent=\"true\"><mi>\ud835\udf37</mi><mo mathvariant=\"bold\" stretchy=\"false\">\u00af</mo></mover></mrow><msqrt><mi>n</mi></msqrt></mfrac><mo>=</mo><mrow><mi>n</mi><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nThen applying to \\eqref{eq:lambda_completion} the fact that \n\n", "itemtype": "equation", "pos": 48321, "prevtext": "\nTherefore, if the two terms of \\eqref{eq:solution1_completion} are\nmultiplied on the right by ${\\mathbf}{\\hat{1}}^\\top$ we get:\n\n", "index": 85, "text": "\\begin{equation}\n  \\label{eq:lambda_completion}\n  2 {\\,} {\\mathbf}{\\hat{1}}^\\top{\\mathbf}{x}={\\mathbf}{\\hat{1}}^\\top\\left(\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}^\\top\\right){\\mathbf}{\\hat{1}}-\\lambda.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E43.m1\" class=\"ltx_Math\" alttext=\"2{\\,}{\\mathbf{}}{\\hat{1}}^{\\top}{\\mathbf{}}{x}={\\mathbf{}}{\\hat{1}}^{\\top}%&#10;\\left(\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}-\\tilde{{\\mathbf{}}{M}}_{{\\mathbf%&#10;{}}{L}}^{\\top}\\right){\\mathbf{}}{\\hat{1}}-\\lambda.\" display=\"block\"><mrow><mrow><mrow><mpadded width=\"+1.7pt\"><mn>2</mn></mpadded><mo>\u2062</mo><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mrow><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>-</mo><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi><mo>\u22a4</mo></msubsup></mrow><mo>)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>-</mo><mi>\u03bb</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nwe can conclude that $\\lambda=0$. Thus, the solution of \\eqref{eq:completion_equiv} is:\n\n\n", "itemtype": "equation", "pos": 48630, "prevtext": "\nThen applying to \\eqref{eq:lambda_completion} the fact that \n\n", "index": 87, "text": "\\begin{equation}\n  \\label{eq:tmp}\n  {\\mathbf}{\\hat{1}}^\\top{\\mathbf}{x}=0 \\quad \\text{and} \\quad {\\mathbf}{\\hat{1}}^\\top (\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}-\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}^\\top) {\\mathbf}{\\hat{1}}=0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E44.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{\\hat{1}}^{\\top}{\\mathbf{}}{x}=0\\quad\\text{and}\\quad{\\mathbf{}}{%&#10;\\hat{1}}^{\\top}(\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}-\\tilde{{\\mathbf{}}{M}}%&#10;_{{\\mathbf{}}{L}}^{\\top}){\\mathbf{}}{\\hat{1}}=0,\" display=\"block\"><mrow><mrow><mrow><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mi>x</mi></mrow><mo>=</mo><mrow><mn>0</mn><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><msup><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover><mo>\u22a4</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>-</mo><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi><mo>\u22a4</mo></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow><mo>=</mo><mn>0</mn></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nFinally, the solution of problem \\eqref{eq:matrix_completion} can be\ncalculated from \\eqref{eq:solution_completion} using\n\\eqref{eq:TDOA_decom}:\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 48956, "prevtext": "\nwe can conclude that $\\lambda=0$. Thus, the solution of \\eqref{eq:completion_equiv} is:\n\n\n", "index": 89, "text": "\\begin{equation}\n  \\label{eq:solution_completion}\n  {\\mathbf}{x}^{\\ast}=n\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}{\\mathbf}{\\hat{1}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E45.m1\" class=\"ltx_Math\" alttext=\"{\\mathbf{}}{x}^{\\ast}=n\\left({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}}{\\bar{L}}\\right%&#10;)^{-1}\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}{\\mathbf{}}{\\hat{1}}.\" display=\"block\"><mrow><mrow><msup><mi>x</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><mi>n</mi><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>\u2062</mo><mover accent=\"true\"><mn>1</mn><mo stretchy=\"false\">^</mo></mover></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\n\nThis completes the proof.\n\\end{IEEEproof}\n\n\\ifthenelse{\\equal{{true}}{true}}\n{\nFrom now on, we will refer to this algorithm as {\\texttt{MC}}.\n}\n\nIt is noteworthy to comment that the matrix\n$({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ contains important information about the\nrecoverability of missing data: if it is full-rank, then the solution of\n\\eqref{eq:matrix_completion} is unique and if\n$({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ is rank-deficient, missing data is not recoverable uniquely without any further assumption.\n\nFurthermore, in the absence of missing data,\n$n({\\mathbf}{D_\\beta}+\\nobreak{\\mathbf}{\\bar{L}})^{-1}=\\nobreak{\\mathbf}{I}$, hence the matrix\ncompletion solution in \\eqref{eq:closed-form-completion} becomes the\nsolution of the denoising problem stated in \\eqref{eq:closed-form}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Robust TDOA Denoising with Missing Data}\n\\label{sec:robust-missing}\n\nIn this section we aim to combine the results of\nsections~\\ref{sec:robust-denoising} and~\\ref{sec:missing-data},\naddressing the more general case in which both outliers and missing data\nare considered. Therefore, the problem is a combination of\n\\eqref{eq:robust-denoising} and \\eqref{eq:matrix_completion} defined as:\n \n", "itemtype": "equation", "pos": 49305, "prevtext": "\n\nFinally, the solution of problem \\eqref{eq:matrix_completion} can be\ncalculated from \\eqref{eq:solution_completion} using\n\\eqref{eq:TDOA_decom}:\n\n\n\n\n\n\n", "index": 91, "text": "\\begin{multline}\n  \\label{eq:closed-form-completion}\n  {\\mathbf}{M}^\\ast=\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\,\\mathds{1}+\\mathds{1}\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}\\left({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}}\\right)^{-1}\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E46.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{M}^{\\ast}=\\left({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}}{%&#10;\\bar{L}}\\right)^{-1}\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}\\,\\mathds{1}+%&#10;\\mathds{1}\\tilde{{\\mathbf{}}{M}}_{{\\mathbf{}}{L}}\\left({\\mathbf{}}{D_{\\beta}}+%&#10;{\\mathbf{}}{\\bar{L}}\\right)^{-1}\" display=\"block\"><mtable displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><msup><mi>M</mi><mo>\u2217</mo></msup><mo>=</mo><mrow><mrow><msup><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>\u2062</mo><mn mathvariant=\"double-struck\">\u20091</mn></mrow><mo>+</mo><mrow><mn>\ud835\udfd9</mn><mo>\u2062</mo><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mi>L</mi></msub><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\nIn the same way as in section~\\ref{sec:robust-denoising},\n(\\ref{eq:robust-missing}) can be solved by alternatively solving the\nfollowing two subproblems until convergence:\n\n\\begin{subequations}\n  \\label{eq:robust-missing-godec}\n    \n", "itemtype": "equation", "pos": 50833, "prevtext": "\n\n\nThis completes the proof.\n\\end{IEEEproof}\n\n\\ifthenelse{\\equal{{true}}{true}}\n{\nFrom now on, we will refer to this algorithm as {\\texttt{MC}}.\n}\n\nIt is noteworthy to comment that the matrix\n$({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ contains important information about the\nrecoverability of missing data: if it is full-rank, then the solution of\n\\eqref{eq:matrix_completion} is unique and if\n$({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})$ is rank-deficient, missing data is not recoverable uniquely without any further assumption.\n\nFurthermore, in the absence of missing data,\n$n({\\mathbf}{D_\\beta}+\\nobreak{\\mathbf}{\\bar{L}})^{-1}=\\nobreak{\\mathbf}{I}$, hence the matrix\ncompletion solution in \\eqref{eq:closed-form-completion} becomes the\nsolution of the denoising problem stated in \\eqref{eq:closed-form}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Robust TDOA Denoising with Missing Data}\n\\label{sec:robust-missing}\n\nIn this section we aim to combine the results of\nsections~\\ref{sec:robust-denoising} and~\\ref{sec:missing-data},\naddressing the more general case in which both outliers and missing data\nare considered. Therefore, the problem is a combination of\n\\eqref{eq:robust-denoising} and \\eqref{eq:matrix_completion} defined as:\n \n", "index": 93, "text": "\\begin{equation}\n  \\label{eq:robust-missing}\n  \\begin{aligned}\n    & \\underset{{\\mathbf}{M},{\\mathbf}{S}}{\\operatorname{minimize}} & &\n    \\left\\|{\\mathbf}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}-{\\mathbf}{S}\\right)\\right\\|_F^2 \\\\\n    & \\operatorname{subject\\;to} & & {\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}\\\\\n    & & & \\|{\\mathbf}{S}\\|_0 < 2k\\\\\n    & & & {\\mathbf}{S} = {\\mathbf}{L}{\\,\\circ\\,}{\\mathbf}{S}.\n  \\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\mathbf{}}{M},{\\mathbf{}}{S}}{\\operatorname{minimize}}\" display=\"inline\"><munder accentunder=\"true\"><mo>minimize</mo><mrow><mi>M</mi><mo>,</mo><mi>S</mi></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\|{\\mathbf{}}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf{}}{M}}-{%&#10;\\mathbf{}}{M}-{\\mathbf{}}{S}\\right)\\right\\|_{F}^{2}\" display=\"inline\"><msubsup><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi><mo>-</mo><mi>S</mi></mrow><mo>)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\operatorname{subject\\;to}\" display=\"inline\"><mrow><mpadded width=\"+2.8pt\"><mi>subject</mi></mpadded><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}\" display=\"inline\"><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47Xb.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\|{\\mathbf{}}{S}\\|_{0}&lt;2k\" display=\"inline\"><mrow><msub><mrow><mo>\u2225</mo><mi>S</mi><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>&lt;</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>k</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47Xc.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{S}={\\mathbf{}}{L}{\\,\\circ\\,}{\\mathbf{}}{S}.\" display=\"inline\"><mrow><mrow><mi>S</mi><mo>=</mo><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mi>S</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\n\\end{subequations}\nThe subproblem \\eqref{eq:robust-missing-godec1} is equivalent to the\nmissing data problem solved in section~\\ref{sec:missing-data} but\nconsidering\n$\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}=\\nobreak({{\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}}-\\nobreak{\\mathbf}{S}_{t-1})$. Therefore,\naccording to theorem~\\ref{th:closed-form-completion}, it has a closed\nform solution:\n  \n", "itemtype": "equation", "pos": 51514, "prevtext": "\n\nIn the same way as in section~\\ref{sec:robust-denoising},\n(\\ref{eq:robust-missing}) can be solved by alternatively solving the\nfollowing two subproblems until convergence:\n\n\\begin{subequations}\n  \\label{eq:robust-missing-godec}\n    \n", "index": 95, "text": "\\begin{align}\n      {\\mathbf}{M}_t &= \\underset{{\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}}{\\operatorname{arg\\,min}}\\quad\n      \\left\\|{\\mathbf}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}-{\\mathbf}{S}_{t-1}\\right)\\right\\|_F^2\\label{eq:robust-missing-godec1}\\\\\n      {\\mathbf}{S}_t &= \\underset{\\|{\\mathbf}{S}\\|_0<2k}{\\operatorname{arg\\,min}}\\quad\n      \\left\\|{\\mathbf}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t\\right)-{\\mathbf}{S}\\right\\|_F^2.\\label{eq:robust-missing-godec2}\n    \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{M}_{t}\" display=\"inline\"><msub><mi>M</mi><mi>t</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\underset{{\\mathbf{}}{M}\\in{\\mathcal{M}_{T}(n)}}{\\operatorname{%&#10;arg\\,min}}\\quad\\left\\|{\\mathbf{}}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf{}}{M}}-{%&#10;\\mathbf{}}{M}-{\\mathbf{}}{S}_{t-1}\\right)\\right\\|_{F}^{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><mi>M</mi><mo>\u2208</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mi>T</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><mi>M</mi><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>)</mo></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\mathbf{}}{S}_{t}\" display=\"inline\"><msub><mi>S</mi><mi>t</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\underset{\\|{\\mathbf{}}{S}\\|_{0}&lt;2k}{\\operatorname{arg\\,min}}%&#10;\\quad\\left\\|{\\mathbf{}}{L}{\\,\\circ\\,}\\left(\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{%&#10;M}_{t}\\right)-{\\mathbf{}}{S}\\right\\|_{F}^{2}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mrow><msub><mrow><mo>\u2225</mo><mi>S</mi><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>&lt;</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>k</mi></mrow></mrow></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><msubsup><mrow><mo>\u2225</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mo>-</mo><msub><mi>M</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>-</mo><mi>S</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04485.tex", "nexttext": "\nSince \\eqref{eq:robust-missing-godec2} is of the same form as the second\nsubproblem in \\eqref{eq:modified_godec}, it can also be solved by\nentry-wise hard thresholding of\n${\\mathbf}{L}{\\,\\circ\\,}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t)$.\n\nThe pseudocode shown in Alg.~\\ref{alg:rodenmis} summarizes the proposed\nalgorithm for the general case.\n\n\n\\begin{algorithm}[H]\n  \\caption{Robust denoising with missing data.}\\label{alg:rodenmis}\n  \\textbf{Require:} $\\tilde{{\\mathbf}{M}}$, ${\\mathbf}{L}$, $k$, $\\epsilon$ \n\n  \\textbf{Ensure:} ${\\mathbf}{M}\\in{\\mathcal{M}_{T}(n)}$, $\\|{\\mathbf}{S}\\|_0<2k$, \n\n  $\\enspace$\\footnotesize{1:}$\\enspace$\\normalsize  ${\\mathbf}{D_\\beta}={\\mathbf}{I}{\\,\\circ\\,}{\\mathbf}{L}{\\mathbf}{L}^\\top$\n\n  $\\enspace$\\footnotesize{2:}$\\enspace$\\normalsize  ${\\mathbf}{Q}=({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})^{-1}$ \\label{lin:pre-cal}\n\n  $\\enspace$\\footnotesize{3:}$\\enspace$\\normalsize  ${\\mathbf}{M}_0=\\tilde{{\\mathbf}{M}}$ ; ${\\mathbf}{S}_0=0$ ; $t=0$\n\n  $\\enspace$\\footnotesize{4:}$\\enspace$\\normalsize  \\textbf{while} $\\|\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t-{\\mathbf}{S}_t\\|_F^2/\\|\\tilde{{\\mathbf}{M}}\\|_F^2<\\epsilon$ \\textbf{do}\n\n  $\\enspace$\\footnotesize{5:}$\\enspace$\\normalsize $\\quad$  $t=t+1$\n \n\n  $\\enspace$\\footnotesize{6:}$\\enspace$\\normalsize $\\quad$  ${\\mathbf}{M}_t={\\mathbf}{Q}({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1})\\,\\mathds{1}+\\mathds{1}({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1}){\\mathbf}{Q}$\n\n  $\\enspace$\\footnotesize{7:}$\\enspace$\\normalsize $\\quad$  ${\\mathbf}{S}_t=\\mathcal{P}_{2k}(\\tilde{{\\mathbf}{M}}-{\\mathbf}{M}_t)$ \n\n  $\\enspace$\\footnotesize{8:}$\\enspace$\\normalsize \\textbf{end while}\n\n  $\\enspace$\\footnotesize{9:}$\\enspace$\\normalsize \\textbf{return} ${\\mathbf}{M}_t$, ${\\mathbf}{S}_t$\n\\end{algorithm}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that in line~\\ref{lin:pre-cal} the matrix\n${\\mathbf}{Q}=({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})^{-1}$ can be precalculated in\norder to get an efficient implementation of the algorithm.\n\n\\ifthenelse{\\equal{{true}}{true}}\n{\nFrom now on, we will refer to this algorithm as {\\texttt{Robust DeN}}+{\\texttt{MC}}.\n}\n\n\\section{Experiments with Synthetic Data}\n\\label{sec:synthetic-data}\n\nIn this section computer simulations will be used to compare the\nproposed algorithms with some of the alternatives existing in the state\nof the art. \n\n\n\n\nFor evaluating the proposed algorithms (robust TDOA denoising and TDOA matrix\ncompletion), two different metrics will be used: \n\n\\begin{itemize}\n\\item The Signal-to-Noise-Ratio SNR [dB] of the non-redundant set\n  referenced to the first sensor\n  ($10\\log(\\sum_{i=1}^n{\\|\\Delta\\tau_{i1}\\|^2/\\sum_{i=1}^n{\\|\\Delta{\\tau}_{i1}^\\ast-\\Delta\\tau_{i1}\\|^2}})$). This\n  is an application independent metric (where $\\Delta{\\tau}_{i1}^\\ast$\n  is the estimation of $\\Delta\\tau_{i1}$), that will allow assessing\n  the proposal improvements in the TDOA measurements \\emph{per se}.\n\\item The localization error, measured as the average distance between\n  the source ground truth position and the position estimated using\n  any given localization algorithm based on TDOA estimations (such as\n  \\cite{chan1994simple} in our case). This is an application dependent\n  metric, that will allow assessing the actual benefits of the\n  proposal in an example of a real task. Note that our proposal is not\n  restricted to localization and can be used in other applications\n  that could benefit from denoised TDOAs (such as self-calibration or\n  beamforming).\n\\end{itemize}\n\n\\subsection{Experimental setup}\n\\label{sec:experimental-setup-syn}\n\nFor all the synthetic data experiments, a set of 10 sensors and 1 source\nwere randomly located. Therefore, 45 different TDOA measurements were\ngenerated per experiment, with additive independent Gaussian noise and\nthe same variance for all of them.\n\nThe sensor locations were uniformly distributed in a cube of 1 meter\nside, and the source positions were uniformly distributed in a 2 meter\nside cube. The propagation speed of the signal was set to 343.313\nm/s. In all the experiments where it's required, $\\epsilon$ is set to\n$10^{-10}$. To increase the statistical significance of the results, they\n  are provided as averages of 20 independent runs.\n\n\n\\subsection{Evaluation of Robust TDOA Denoising}\n\\label{sec:synth-denoising}\n\nIn this first experiment to evaluate the performance of the algorithm\nproposed in section~\\ref{sec:robust-denoising}, we also imposed that\nsome TDOA values were outliers. To simulate this, we randomly chose some\nmeasurements (between 0 and 10) and replaced them with a zero-mean\nGaussian distributed noise, with a standard deviation of 0.1 ms. It is\nworth mentioning that the outlier values calculated that way are not\nrelated at all to the real TDOAs, thus being \\emph{true} outliers.  The\nparameter $k$ of the proposed algorithm, which fixes the maximum number\nof identifiable outliers, was set to 8.\n\n\\subsubsection{SNR Improvements Evaluation}\n\\label{sec:snr-impr-eval}\n\nFig.~\\ref{fig:MapSNR_synthetic_dn_10mics}a shows the SNR values for the\nproposed robust denoising algorithm when modifying the noise standard deviation\nand the number of outliers, compared with that obtained by the Gauss-Markov\nestimator (Fig.~\\ref{fig:MapSNR_synthetic_dn_10mics}b), and also when\nonly the non redundant set is used, i.e. not using he redundancy\nof TDOA measurements (Fig.~\\ref{fig:MapSNR_synthetic_dn_10mics}c).\n\n\\begin{figure}[!t]\n  \\centering\n  \\includegraphics[width=0.49\\textwidth]{MapSNR_synthetic_dn_ALL_10mics.eps}\n  \\caption{Robust denoising in synthetic data: SNR in dB, higher is better.}\n  \\label{fig:MapSNR_synthetic_dn_10mics}\n\\end{figure}\n\n\nAs predicted in section~\\ref{sec:denoising}, when no outliers are\npresent, the performance of the proposed algorithm is the same as\nGauss-Markov (see the first row in\nFigs.~\\ref{fig:MapSNR_synthetic_dn_10mics}a\nand~\\ref{fig:MapSNR_synthetic_dn_10mics}b), hence it reaches the\nCramer-Rao Bound \\cite{so2008closed}, while being much better than using\nno redundancy.  Nevertheless, the proposed algorithm clearly outperforms\nthe other two approaches when outliers are present in the measurements\n(rows 1 through 10 in the graphics of\nFig.~\\ref{fig:MapSNR_synthetic_dn_10mics}).\n\n\n\\subsubsection{Source Localization Improvements Evaluation}\n\\label{sec:source-local-impr}\n\nThe optimized non redundant set provided by the algorithms applied in\nSection~\\ref{sec:snr-impr-eval} were used in a localization algorithm\nusing \\cite{chan1994simple}. The average localization errors (in mm) are\nshown in Fig.~\\ref{fig:MapCHAN_synthetic_dn_10mics}. Again, the proposed\nrobust denoising algorithm performs as Gauss-Markov when there are no\noutliers, but is clearly superior when  outliers are present.\n\nIt is also worth mentioning that the behaviour of the robust denoising\nkeeps the improvements at roughly the same level for increasing number\nof outliers present, thus validating the ability of the algorithm to\npinpoint and eliminate their presence.\n\n\n\\begin{figure}[!t]\n  \\centering\n  \\includegraphics[width=0.48\\textwidth]{MapCHAN_synthetic_dn_ALL_10mics.eps}\n  \\caption{Robust denoising in synthetic data: Localization error in mm (using\n    \\cite{chan1994simple}), lower is better.}\n  \\label{fig:MapCHAN_synthetic_dn_10mics}\n\\end{figure}\n\n\n\\subsection{Evaluation of Missing Data Recovery}\n\\label{sec:synth-completion}\n\nIn this second experiment, we evaluated the capability of the algorithm\nproposed in section~\\ref{sec:missing-data} to recover missing\nvalues. For our purposes, the missing TDOA measurements were also chosen\nrandomly but, in contrast to the previous experiment, the matrix\npositions of the missing measurements were known.\n\n\n\n\nFig.~\\ref{fig:MapSNR_synthetic_comp_10mics} and\nFig.~\\ref{fig:MapCHAN_synthetic_comp_10mics} show, respectively, the SNR\nvalues, and the localization error for the proposed matrix completion\nalgorithm, when modifying the noise standard deviation and the\npercentage of missing TDOA values in the TDOA matrix, as compared with\nusing only the non-redundant set (missing values were set to zero).\n\n\\begin{figure}[!t]\n  \\centering \n   \\includegraphics[width=0.48\\textwidth]{MapSNR_synthetic_comp_ALL_10mics}\n  \\caption{Missing data recovery in synthetic data: SNR in dB, higher\n    is better.}\n  \\label{fig:MapSNR_synthetic_comp_10mics}\n\\end{figure}\n\n\n\n\n\\begin{figure}[!t]\n  \\centering \n   \\includegraphics[width=0.48\\textwidth]{MapCHAN_synthetic_comp_ALL_10mics}\n  \\caption{Missing data recovery in synthetic data: Localization error\n    in mm (using \\cite{chan1994simple}), lower is better.}\n  \\label{fig:MapCHAN_synthetic_comp_10mics}\n\\end{figure}\n\nFrom the figures, it can be clearly seen that the proposed algorithm can\ntake advantage of the knowledge about which measurements were missing,\nachieving even better results than when the positions of the outliers\nwere unknown. For example, removing 50\\% of the TDOA measurements\nimplies 24 missing values, much more than the maximum of 10 outliers\nevaluated in Fig.~\\ref{fig:MapSNR_synthetic_dn_10mics}, while keeping\ngood performance.\n\n\n\\subsection{Evaluation of Robust TDOA Denoising with Missing Data}\n\nIn this third experiment, we evaluated the capability of the algorithm\nproposed in section~\\ref{sec:robust-missing} to face both outliers and\nrecover missing values. \n\nTo provide a wide range of evaluation scenarios, we defined: \\emph{i)} Two conditions related to noise, namely \\emph{low} and \\emph{high}. The former corresponds to a standard deviation of $10^{-3}$ ms., and the latter to $0.2$ ms. \\emph{ii)} Two conditions related to the presence of outliers, imposing 2 or 6. \\emph{iii)} A variable number of missing TDOA measurements, defined as a\n  percentage of missing TDOA values in the TDOA matrix.\n\nFig.~\\ref{fig:SNR_comparative_synth}\nand Fig.~\\ref{fig:Error_comparative_synth} show, respectively, the SNR\nvalues, and the localization error for different algorithms, and for\ndifferent evaluation scenarios.\n\n\\begin{figure*}[!t]\n  \\centering \n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{SNR_synthetic_comparative_sigma001_noutliers2_10mics}\n    \\caption{SNR with low noise and 2 outliers}\n    \\label{fig:SNR_synth_low_few}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{SNR_synthetic_comparative_sigma001_noutliers6_10mics}\n    \\caption{SNR with low noise and 6 outliers}\n    \\label{fig:SNR_synth_low_many}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{SNR_synthetic_comparative_sigma200_noutliers2_10mics}\n    \\caption{SNR with high noise and 2 outliers}\n    \\label{fig:SNR_synth_high_few}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{SNR_synthetic_comparative_sigma200_noutliers6_10mics}\n    \\caption{SNR with high noise and 6 outliers}\n    \\label{fig:SNR_synth_high_many}\n  \\end{subfigure}\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{legend}\n  \\end{subfigure}\n\n  \\caption{Algorithm evaluation in synthetic data: SNR in dB.}\n  \\label{fig:SNR_comparative_synth}\n\\end{figure*}\n\n\\begin{figure*}[!t]\n  \\centering \n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{Error_synthetic_comparative_sigma001_noutliers2_10mics}\n    \\caption{Localization error with low noise and 2 outliers}\n    \\label{fig:Error_synth_low_few}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{Error_synthetic_comparative_sigma001_noutliers6_10mics}\n    \\caption{Localization error with low noise and 6 outliers}\n    \\label{fig:Error_synth_low_many}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{Error_synthetic_comparative_sigma200_noutliers2_10mics}\n    \\caption{Localization error with high noise and 2 outliers}\n    \\label{fig:Error_synth_high_few}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{Error_synthetic_comparative_sigma200_noutliers6_10mics}\n    \\caption{Localization error with high noise and 6 outliers}\n    \\label{fig:Error_synth_high_many}\n  \\end{subfigure}\n\\;\n  \\begin{subfigure}[t]{0.18\\textwidth}\n    \\includegraphics[width=\\textwidth]{legend}\n  \\end{subfigure}\n\n  \\caption{Algorithm evaluation in synthetic data: Localization error in\n    mm (\\cite{chan1994simple} is used for\n    source position estimation from the optimized TDOA values).}\n  \\label{fig:Error_comparative_synth}\n\\end{figure*}\n\n\nAs it can be seen in Fig.~\\ref{fig:SNR_synth_low_few},\n\\ref{fig:Error_synth_low_few}, \\ref{fig:SNR_synth_high_few} and\n\\ref{fig:Error_synth_high_few} when there are a low number of outliers\n(2 in this case), the best results are obtained for lower $k$ values.\nHowever, when the number of outliers increase,\n(Fig.~\\ref{fig:SNR_synth_low_many}, \\ref{fig:SNR_synth_high_many},\n\\ref{fig:Error_synth_low_many} and \\ref{fig:Error_synth_high_many}, low\n$k$ values perform worse. So, we can conclude that $k$ must be a number\nas low as possible, but higher than the number of actual outliers.\n\nNevertheless, it is worth to observe the behaviour of\nFig.~\\ref{fig:SNR_synth_low_many}, \\ref{fig:SNR_synth_high_many},\n\\ref{fig:Error_synth_low_many} and \\ref{fig:Error_synth_high_many} (with\nmore outliers) when the percentage of missing data increases. It can be\nclearly seen that the lines corresponding to different values of $k$ are\ncrossing among them. This seems to indicate that as the missing data\npercentage increases, the number of outliers that we are able to detect\ndecreases.\n\nAnyway, the results obtained by the\n{\\texttt{Robust DeN}}+{\\texttt{MC}}{} algorithm outperforms the\nGauss-Markov estimator, asymptotically approaching it when the noise is\nvery high. Note also that for high values of noise, the noise and the\noutliers are practically indistinguishable.\n\n\n\\section{Experiments with Real Data}\n\\label{sec:real-data}\n\nThe aim of this section is to evaluate whether the improvements obtained in\nsection~\\ref{sec:synthetic-data} using synthetic data are actually found\nin real environments.\n \n\n\n\n\\subsection{Experimental Setup}\n\\label{sec:experimental-setup-realdata}\n\n\nThe proposed algorithms have been evaluated using audio recordings from\nthe AV16.3 database~\\cite{lathoud2005av16}, an audio-visual corpus\nrecorded in the \\emph{Smart Meeting Room} of the IDIAP research\ninstitute, in Switzerland.\n\n\\begin{figure}\n  \\centering\n  \\begin{subfigure}[t]{0.24\\textwidth}\n    \\includegraphics[width=0.8\\textwidth]{roomlayout2}\n    \\caption{IDIAP room layout showing the centered table, and the\n      microphones arranged in two circular arrays.}\n    \\label{fig:RoomLayout}\n  \\end{subfigure}\n\\qquad\n \n  \n  \\begin{subfigure}[t]{0.17\\textwidth}\n    \\includegraphics[width=\\textwidth]{positions1-short-improved-revised-new}\n    \\caption{Positions evaluated in the real data experiments. Only the\n      relevant room section is shown.}\n    \\label{fig:real_positions_short}\n  \\end{subfigure}\n  \\caption{IDIAP Smart Meeting Room: experimental details.}\n  \\label{fig:LIdiapRoom}\n\\end{figure}\n\n\nThe IDIAP Meeting Room (shown in Fig.~\\ref{fig:LIdiapRoom}) is a\n$8.2m \\times \\nobreak 3.6m \\times 2.4m$ rectangular space containing a\ncentrally located $4.8m \\times 1.2m$ rectangular table, on top of\nwhich two circular microphone arrays of $10 cm$ radius are located,\neach of them composed by 8 microphones. The centers of the two arrays\nare separated by $80 cm$ and the origin of coordinates is located in\nthe middle point between the two arrays. A detailed description of the\nmeeting room can be found in~\\cite{moore2002}.\n\nThe audio recordings are synchronously sampled at $16~KHz$, and the\ncomplete database along with the corresponding annotation files\ncontaining the recordings ground truth (3D coordinates of the speaker's\nmouth) is fully accessible on-line at~\\cite{av163}. It is composed by\nseveral sequences from which we are using sequence 01, with a single\nmale speaker generating digit strings in 16 positions (which can be seen\nas small circles in Fig.~\\ref{fig:real_positions_short}), distributed\nalong the room. The sequence duration accounts for 208 seconds in total,\nwith 823 ground truth frames.\n\nThe TDOA measurements $\\Delta\\tilde{\\tau}_{ij}$, from which the measured\nTDOA matrix ${\\mathbf}{\\tilde{M}}$ is built, where estimated using the\nhighest peak of the GCC-PHAT function\\cite{knapp1976GCC}.\n\nAs in a real scenario outliers are common but difficult to anticipate or\nenforce, the sweep over noise levels and the number of outliers that we\nperformed with synthetic data are not feasible. Therefore, in our\nexperiments with real data, we will only provide the SNR values and\nlocalization errors obtained after using each algorithm.\n\n\n\n\n\n\\subsection{Evaluation of Robust TDOA Denoising}\n\\label{sec:source-local-impr2}\n\nIn this experiment, \\textit{all} the microphone pairs have been\nconsidered, hence 120 TDOA values have been computed for each frame.\n\nIn table~\\ref{tab:results-real-data} we show an example of the results\nfor the {\\texttt{Robust DeN}}{} with $k=10$ (the election of this\nparameter is not critical as shown in figure~\\ref{fig:comparative_real},\nwhere significant improvements are obtained for different $k$\nvalues). As it also happened with synthetic data, in this case the\nproposed algorithm outperforms the Gauss-Markov estimator, yielding\ngreat improvements in both SNR and localization precision.\n\n\\begin{table}[t!]\n  \\caption{Robust denoising performance in real data}\n  \\label{tab:results-real-data}\n  \\centering\n  \\begin{tabular}{l c c}\n    \\hline\n    &SNR (dB)&Average Localization error (mm)\\\\\n    \\hline\n    {\\texttt{Robust DeN}}{} & 27.46  &354\\\\\n    Gauss-Markov& 23.19 &515\\\\\n    Only non-redundant set&17.83 &858\n  \\end{tabular}.\n\\end{table}\n\nThese results are the baseline for the experiments with missing data\ndescribed in the next subsection.\n\n\n\\subsection{Evaluation of Robust TDOA Denoising with Missing Data}\n\\label{sec:deno-with-miss}\n\nIn the second experiment with real data, we randomly remove a set of\nTDOA measurements. Fig.~\\ref{fig:comparative_real} shows the obtained\nresults.  The doted lines correspond to the performance (SNR and\nlocalization error) achieved by the Gauss-Markov estimator when there\nare no missing measurements. The solid lines with circular marks are the\nresults obtained by the matrix completion algorithm\n({\\texttt{MC}}) described in section~\\ref{sec:missing-data}.\n\nOn the other hand, the solid lines with squared/triangular/diamond\nmarks correspond with the results of the\n{\\texttt{Robust DeN}}+{\\texttt{MC}}{} algorithm presented in\nsection~\\ref{sec:robust-missing}. The different colors/shapes indicate\ndifferent values of the hyperparameter $k$.\n\n\\begin{figure}[!t]\n  \\centering \n  \\begin{subfigure}[t]{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{SNR_real_comparative_16mics.eps}\n    \\caption{SNR in dB}\n    \\label{fig:Error_real}\n  \\end{subfigure}\n\n  \\begin{subfigure}[t]{0.24\\textwidth}\n    \\includegraphics[width=\\textwidth]{Error_real_comparative_16mics.eps}\n    \\caption{Localization error in mm (using  \\cite{chan1994simple})}\n    \\label{fig:SNR_real}\n  \\end{subfigure}\n\n  \\caption{Results for real data with missing TDOA measurements.}\n  \\label{fig:comparative_real}\n\\end{figure}\n\nFig.~\\ref{fig:comparative_real} highlights the relevance of the\nproposed robust-denoising algorithm in real-scenarios, with important\nimprovements over the non robust version of our algorithm: higher than\n4dB absolute improvement in terms of SNR, and around 30\\% relative\nimprovement (15 cm absolute) in terms of localization precision.\n\nWe again observe that as the percentage of missing data increases, the\nlines corresponding to different values of $k$ are crossing among\nthem. This behaviour is very similar to that found in the synthetic\nexperiments above (refer to Fig.~\\ref{fig:SNR_comparative_synth}\nand Fig.~\\ref{fig:Error_comparative_synth}) for a high number of outliers,\nwhat suggests that this is the case in the real experiment, also\nserving as a validation for our simulation conclusions.\n\nIt is also noteworthy that, in order to get the better result, the\nmaximum number of outliers $k$ should be decreased when the number of\nmissing measurements increases.\n\n\n\\section{Conclusions}\n\\label{sec:conclusions}\n\nThis paper has studied the properties of TDOA matrices, showing that\nthey can be effectively used for solving TDOA denoising problems. In\nparticular, the paper has investigated challenging scenarios where the\nTDOA matrix is contaminated with Gaussian noise, outliers and where a\npercentage of the measurements are missing. The paper shows that\ndenoising in the presence of Gaussian noise and missing data can be\nsolved in closed-form. This result is important, as it is the basis of\nan iterative algorithm that can also cope with outliers. The paper has\ntested the proposed algorithms in the context of acoustic localization\nusing microphone arrays. The experimental results, both on real and\nsynthetic data have shown that our algorithms successfully perform\ndenoising (up to 30\\% of improvement in localization accuracy) with a\nhigh rate of missing data (up to 50\\%) and outliers. Interestingly, in\nreal datasets our robust denoising algorithm is systematically better\nthan the Gauss-Markov estimator even when there is no missing data and\nno large outliers are, in principle, contaminating the data. This is an\nimportant result as it proves that the assumption of Gaussian noise does\nnot hold in real cases, while our robust model is capable of\nautomatically discard erroneous measurements. As for future work, we\nplan to further test our denoising algorithms in applications where the\nposition of the sensors is unknown in advance, such in self-localization\nand beamforming.\n\n\n\\section*{Acknowledgements}\n\\label{sec:acknowledgements}\n\nThis work has been supported by the Spanish Ministry of Economy and\nCompetitiveness under project SPACES-UAH (TIN2013-47630-C2-1-R), and by\nthe University of Alcal\u00e1 under projects DETECTOR and ARMIS.\n\n\n\\bibliographystyle{IEEEtran}\n\\bibliography{Sparse_SRP,TDOA_Denoising,calibration}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 52409, "prevtext": "\n\\end{subequations}\nThe subproblem \\eqref{eq:robust-missing-godec1} is equivalent to the\nmissing data problem solved in section~\\ref{sec:missing-data} but\nconsidering\n$\\tilde{{\\mathbf}{M}}_{{\\mathbf}{L}}=\\nobreak({{\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}}-\\nobreak{\\mathbf}{S}_{t-1})$. Therefore,\naccording to theorem~\\ref{th:closed-form-completion}, it has a closed\nform solution:\n  \n", "index": 97, "text": "\\begin{multline}\n\n  \\label{eq:robust-missing-sol1}\n  {\\mathbf}{M}_t^{\\ast}=({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})^{-1}({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1})\\,\\mathds{1}+\\\\+\\mathds{1}({\\mathbf}{L}{\\,\\circ\\,}\\tilde{{\\mathbf}{M}}-{\\mathbf}{S}_{t-1})({\\mathbf}{D_\\beta}+{\\mathbf}{\\bar{L}})^{-1}.\n\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E50.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\par&#10;{\\mathbf{}}{M}_{t}^{\\ast}=({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}%&#10;}{\\bar{L}})^{-1}({\\mathbf{}}{L}{\\,\\circ\\,}\\tilde{{\\mathbf{}}{M}}-{\\mathbf{}}{S%&#10;}_{t-1})\\,\\mathds{1}+\\\\&#10;\\displaystyle+\\mathds{1}({\\mathbf{}}{L}{\\,\\circ\\,}\\tilde{{\\mathbf{}}{M}}-{%&#10;\\mathbf{}}{S}_{t-1})({\\mathbf{}}{D_{\\beta}}+{\\mathbf{}}{\\bar{L}})^{-1}.\\par&#10;\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mi>M</mi><mi>t</mi><mo>\u2217</mo></msubsup><mo>=</mo><mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mrow><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mn mathvariant=\"double-struck\">\u20091</mn></mrow><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>+</mo><mrow><mn>\ud835\udfd9</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mpadded width=\"+1.7pt\"><mi>L</mi></mpadded><mo rspace=\"4.2pt\">\u2218</mo><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover></mrow><mo>-</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>D</mi><mi>\u03b2</mi></msub><mo>+</mo><mover accent=\"true\"><mi>L</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}]