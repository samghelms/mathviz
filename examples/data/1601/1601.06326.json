[{"file": "1601.06326.tex", "nexttext": "\nwhere the system state $x(t) \\in {X}$, the system output $y(t) \\in {Y}$, the control $u(t) \\in {U}$, for all $t, x_{0} \\in {X}$, and $f$ and $h$ are smooth (continuously differentiable) functions describing the time evolution of the system dynamics. Let ${\\mathcal{X}}$ denote the set of all essentially bounded measurable functions mapped from $[0,T]$ to ${X}$ for any $T \\in {\\mathbb{R}}_{>0}$ and define ${\\mathcal{Y}}$ and ${\\mathcal{U}}$ similarly. The functions in ${\\mathcal{X}}$, ${\\mathcal{Y}}$, and ${\\mathcal{U}}$ are called \\textit{state trajectories}, \\textit{output trajectories}, and \\textit{controls}, respectively. \n\nLet ${X_{\\mathrm{obs}}}$ and ${X_{\\mathrm{goal}}}$, called the \\textit{obstacle space} and the \\textit{goal region}, be open subsets of ${X}$. Let ${X_{\\mathrm{free}}}$, also called the \\textit{free space}, denote the set defined as ${X} \\setminus {X_{\\mathrm{obs}}}$.\n\nThe smooth function $h$ describes the output $y$ that we wish to control. Loosely speaking, we are particularly interested in the class of control problems in which we wish to track a time-varying reference trajectory $r(t)$.  called the \\textit{trajectory-generation} problem. We assume that given a desired output value $y^{\\prime} \\in {Y}$, and a current output value $y \\in {Y}$ of the system, the control law $\\phi: (y^{\\prime},y) \\mapsto u \\in {U}$ computes a control input such that the closed-loop simulation of the system yields a good tracking performance as time evolves.\n\n\\subsection{Problem Statement}\n\n\n\n\n\n\n\nGiven the state space ${X}$, obstacle region ${X_{\\mathrm{obs}}}$, goal region ${X_{\\mathrm{goal}}}$, and smooth functions $f$ and $h$ that describe the system dynamics, find a reference trajectory $r \\in {\\mathcal{Y}}$ with domain $[0,T]$ for some $T \\in {\\mathbb{R}}_{>0}$ such that the corresponding unique state trajectory $x \\in {\\mathcal{X}}$, output trajectory $y \\in {\\mathcal{Y}}$, and control $u \\in {\\mathcal{U}}$ that are computed by closed-loop simulation,\n\\begin{itemize}\n\\item obeys the differential constraints, \n\n", "itemtype": "equation", "pos": 6491, "prevtext": "\n\n\n\n\\maketitle\n\\thispagestyle{empty}\n\\pagestyle{empty}\n\n\n\n\\begin{abstract}\n\nMotion planning under differential constraints, \\textit{kinodynamic motion planning}, is one of the canonical problems in robotics. Currently, state-of-the-art methods evolve around kinodynamic variants of popular sampling-based algorithms, such as Rapidly-exploring Random Trees (RRTs). However, there are still challenges remaining, for example, how to include complex dynamics while guaranteeing optimality. If the open-loop dynamics are unstable, exploration by random sampling in control space becomes inefficient. \nWe describe a new sampling-based algorithm, called ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$, which leverages ideas from the ${\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}$ algorithm and a variant of the ${\\ensuremath{{\\mathrm{RRT}}}}$ algorithm that generates trajectories using closed-loop prediction. The idea of planning with closed-loop prediction allows us to handle complex unstable dynamics and avoids the need to find computationally hard steering procedures. The search technique presented in the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithm allows us to improve the solution quality by searching over alternative reference trajectories. Numerical simulations using a nonholonomic system demonstrate the benefits of the proposed approach.\n\n\\end{abstract}\n\n\\section{Introduction} \\label{section:introduction}\n\n\nMotion planning is ubiquitous in many applications where different levels of autonomy is desired.  Loosely speaking, given a system that is subject to a set of differential constraints, an initial state, a final state, a set of obstacles, and a goal region, the \\textit{motion-planning problem} is to find a control input that drives the system from its initial state to the goal region. This problem is computationally hard to solve \\cite{reif1979complexity}.\n\nOne approach to solve the motion-planning problems is to divide the problem into two subproblems: path planning and path tracking. The main drawback of this approach is lack of dynamic feasibility guarantees. Still, it has been successfully applied to robotic applications in which the underlying system has redundant control authority (e.g., robotic manipulators). \n Another  class of algorithms is randomized planners, which solve  the motion-planning problem in a single step. Notably, the kinodynamic version of  Rapidly-Exploring Random Tree ({\\ensuremath{{\\mathrm{RRT}}}}{})  incrementally grows a tree of trajectories in the state space by sampling  control inputs and simulating the motion of the system with these random control inputs over a time horizon~\\cite{lavalle2006planning,lavalle2001randomizedkin}. Hence, the trajectories that are generated by  {\\ensuremath{{\\mathrm{RRT}}}}{}  are dynamically feasible by construction. Recently,  {\\ensuremath{{\\mathrm{RRT}}}}{}  and its variants were successfully applied to  robotic systems~\\cite{kuffner2002dynamically,leonard2008perception} and different classes of stochastic problems~\\cite{arslan2014information}. Unlike standard {\\ensuremath{{\\mathrm{RRT}}}}{}, these variants were usually implemented  to compute a solution quickly and improve it in the remaining time until the execution of the motion plan. However, {\\ensuremath{{\\mathrm{RRT}}}}{}  computes suboptimal solutions~\\cite{KaramanFra2011}.\n\nOne drawback with kinodynamic {\\ensuremath{{\\mathrm{RRT}}}}{} is that exploration via random selection of control inputs is  inefficient when the dynamics are complex and/or unstable. To remedy this, \\cite{kuwata2008motion} proposed  {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}}}}{}, which uses closed-loop prediction for trajectory generation. Instead of sampling in the control space, the proposed approach grows a tree in the reference space. Each path of the tree represents a reference trajectory that acts as an input to the closed-loop system. The desired behaviors of the system are prescribed as specifications for a  controller that is used to track a given reference trajectory. Each edge of the tree is associated with a segment of a reference trajectory and a state trajectory of the system, computed by closed-loop prediction. \n\nSeveral papers address the   suboptimality of {\\ensuremath{{\\mathrm{RRT}}}}{}. In~\\cite{KaramanFra2011}, an algorithm with asymptotic optimality guarantee, {\\ensuremath{{\\mathrm{RRT}^*}}}{}, was developed.   {\\ensuremath{{\\mathrm{RRT}^*}}}{}  has been extended to solve motion planning problems under differential constraints~\\cite{karaman2011anytime,karaman2010optimal}. The proposed algorithms are asymptotically optimal when a steering procedure that satisfies certain conditions is provided. However, developing efficient steering procedures that solve point-to-point motion planning, essentially  a two-point boundary value problem, is generally hard \\cite{vinter2010optimal}. \n\n\nHere, we propose a new asymptotically optimal motion-planning algorithm,  {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{}, by leveraging ideas from the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}}}}{}~\\cite{kuwata2008motion} and the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithms~\\cite{arslan2013useofrelaxation,arslan2015dynamic,arslan2015dp}. To handle differential constraints, instead of sampling  in the control space, our approach samples in the output space and incrementally grows a graph whose edges correspond to segments of reference trajectories. The algorithm also keeps another graph to store state trajectories of the closed-loop system when it is inputed with a certain path in the graph of reference trajectories. Hence, we avoid the need for complicated steering procedures and the resulting trajectory satisfies the differential constraints by construction. To improve the solution quality,  {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{}  searches among alternative paths of the graph of reference trajectories. The proposed algorithm checks different reference trajectories and simulates the system  forward in time, as needed. Finally, the algorithm provides the segments of reference trajectories that yield the lowest-cost state trajectory of the closed-loop system. \n\n\n\n\\section{Problem Formulation}\\label{section:problem_formulation}\n\n\n\nLet ${X} \\subseteq {\\mathbb{R}}^{n}$, ${Y} \\subseteq {\\mathbb{R}}^{p}$ and ${U} \\subseteq {\\mathbb{R}}^{m}$ be compact sets. We assume that the system dynamics can be described by a nonlinear differential equation of the form\n\n", "index": 1, "text": "\\begin{align}\n\\dot{x}(t) =& f(x(t),u(t)), \\quad\tx(0) = x_{0}, \\nonumber\\\\\ny(t) =& h(x(t),u(t)),\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\dot{x}(t)=\" display=\"inline\"><mrow><mrow><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle f(x(t),u(t)),\\quad x(0)=x_{0},\" display=\"inline\"><mrow><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>u</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle y(t)=\" display=\"inline\"><mrow><mrow><mi>y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle h(x(t),u(t)),\" display=\"inline\"><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>u</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06326.tex", "nexttext": "\n\n\\item avoids the obstacles, i.e., $x(t) \\in {X_{\\mathrm{free}}}$ for all $t \\in [0,T]$,\n\\item reaches the goal region, i.e., $x(T) \\in {X_{\\mathrm{goal}}}$,\n\\item and minimizes ${}J(x,u,r) = \\int_{0}^{T} g(x(t),u(t), r(t))\\, \\mathrm{d}t$\n\\end{itemize}\n\n\n\n\n\n\n\\subsection{Primitive Procedures}\n\nFollowing are the definitions of the primitive procedures used by the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm (for details, see~\\cite{KaramanFra2011}).\n\n\n\\textit{Sampling:} ${\\mathtt{Sample}} : \\omega \\mapsto  \\left\\{ {\\mathtt{Sample}}_{i}(\\omega) \\right\\}_{i \\in {\\mathbb{N}}_{0}} \\subset {Y_\\mathrm{free}}$ returns independent and identically distributed (i.i.d.) samples ${\\mathtt{Sample}}_{i}, \\, i \\in {\\mathbb{N}}_{0\t}$ from ${Y_\\mathrm{free}}$. \n\n\\textit{Nearest Neighbor:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}}, {E_{y}})$, where ${V_{y}} \\in {Y}$, a point ${y} \\in {Y}$, the function ${\\mathtt{Nearest}}: ({\\mathcal{G}_{y}}, {y}) \\mapsto {v_{y}} \\in {V_{y}}$ returns the node in ${V_{y}}$ that is ``closest'' to ${y}$ in terms of a given distance function. We use the  Euclidean distance. \n\n\\textit{Near Neighbors:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}}, {E_{y}})$, where ${V_{y}} \\in {Y}$, a point ${y} \\in {Y}$, and a positive real number $d \\in {\\mathbb{R}}_{>0}$, the function ${\\mathtt{Nearest}}: ({\\mathcal{G}_{y}}, {y}, d) \\mapsto {v_{y}} \\in {V_{y}}^{\\prime} \\subset {V_{y}}$ returns the nodes in ${V_{y}}$ that are contained in a ball of radius $d$ centered at ${y}$. \n\n\n\n\n\n\\textit{Steering:} Given two points ${y_{\\mathrm{from}}}, {y_{\\mathrm{to}}} \\in {Y}$, the function ${\\mathtt{Steer}}: ({y_{\\mathrm{from}}}, {y_{\\mathrm{to}}}) \\mapsto {y^{\\prime}}$ returns a point ${y^{\\prime}} \\in {Y}$ such that ${y^{\\prime}}$ is ``closer'' to ${y_{\\mathrm{to}}}$ than ${y_{\\mathrm{from}}}$ is. In this work, the point ${y^{\\prime}}$ returned by the function ${\\mathtt{Steer}}$ will be such that ${y^{\\prime}}$ minimizes $\\|{y^{\\prime}} - {y_{\\mathrm{to}}}\\|$ while at the same time maintaining $\\|{y^{\\prime}} - {y_{\\mathrm{from}}}\\| \\leq \\eta$, for a predefined $\\eta > 0$. \n\n\n\n\n\\textit{Closed-loop Prediction:} Given a state ${x} \\in {X_{\\mathrm{free}}}$, and an output trajectory ${\\sigma_{y}} \\in {\\mathcal{Y}}$, the function $\\fPropagate : ({x},{\\sigma_{y}}) \\mapsto {\\sigma_{x}} \\in {\\mathcal{X}}$ returns the state trajectory that is computed by simulating the system dynamics forward in time with the initial state ${x}$, and the reference trajectory ${\\sigma_{y}}$.\n\n\\textit{Collision Test:} Given two points ${y_{\\mathrm{from}}}, {y_{\\mathrm{to}}} \\in {\\mathcal{G}_{y}}$, the Boolean function ${\\mathtt{ObstacleFree}}({y_{\\mathrm{from}}}, {y_{\\mathrm{to}}})$ returns ${\\tt True}$ if the line segment between ${y_{\\mathrm{from}}}$ and ${y_{\\mathrm{to}}}$ lies in ${Y_\\mathrm{free}}$ \nand ${\\tt False}$ otherwise.\n\n\n\\textit{Cost-to-come Values:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}},{E_{y}})$, let ${\\mathtt{g^{*}}}$ denote the optimal cost-to-come value of the node ${v_{y}} \\in {V_{y}}$ that can be achieved in ${\\mathcal{G}_{y}}$. Each node ${v_{y}} \\in {V_{y}}$ is associated with two estimates of the optimal cost-to-come value~(see~\\cite{arslan2013useofrelaxation,koenig2004lifelongplanning}). The $g$-value of ${v_{y}}$ is the cost of the path to ${v_{y}}$ from a given initial state ${y_{\\mathrm{init}}} \\in {Y_\\mathrm{free}}$. The one step look-ahead $g$-value of ${v_{y}}$ is denoted with ${\\mathtt{\\bar{g}}}$ and defined as \n\n", "itemtype": "equation", "pos": 8654, "prevtext": "\nwhere the system state $x(t) \\in {X}$, the system output $y(t) \\in {Y}$, the control $u(t) \\in {U}$, for all $t, x_{0} \\in {X}$, and $f$ and $h$ are smooth (continuously differentiable) functions describing the time evolution of the system dynamics. Let ${\\mathcal{X}}$ denote the set of all essentially bounded measurable functions mapped from $[0,T]$ to ${X}$ for any $T \\in {\\mathbb{R}}_{>0}$ and define ${\\mathcal{Y}}$ and ${\\mathcal{U}}$ similarly. The functions in ${\\mathcal{X}}$, ${\\mathcal{Y}}$, and ${\\mathcal{U}}$ are called \\textit{state trajectories}, \\textit{output trajectories}, and \\textit{controls}, respectively. \n\nLet ${X_{\\mathrm{obs}}}$ and ${X_{\\mathrm{goal}}}$, called the \\textit{obstacle space} and the \\textit{goal region}, be open subsets of ${X}$. Let ${X_{\\mathrm{free}}}$, also called the \\textit{free space}, denote the set defined as ${X} \\setminus {X_{\\mathrm{obs}}}$.\n\nThe smooth function $h$ describes the output $y$ that we wish to control. Loosely speaking, we are particularly interested in the class of control problems in which we wish to track a time-varying reference trajectory $r(t)$.  called the \\textit{trajectory-generation} problem. We assume that given a desired output value $y^{\\prime} \\in {Y}$, and a current output value $y \\in {Y}$ of the system, the control law $\\phi: (y^{\\prime},y) \\mapsto u \\in {U}$ computes a control input such that the closed-loop simulation of the system yields a good tracking performance as time evolves.\n\n\\subsection{Problem Statement}\n\n\n\n\n\n\n\nGiven the state space ${X}$, obstacle region ${X_{\\mathrm{obs}}}$, goal region ${X_{\\mathrm{goal}}}$, and smooth functions $f$ and $h$ that describe the system dynamics, find a reference trajectory $r \\in {\\mathcal{Y}}$ with domain $[0,T]$ for some $T \\in {\\mathbb{R}}_{>0}$ such that the corresponding unique state trajectory $x \\in {\\mathcal{X}}$, output trajectory $y \\in {\\mathcal{Y}}$, and control $u \\in {\\mathcal{U}}$ that are computed by closed-loop simulation,\n\\begin{itemize}\n\\item obeys the differential constraints, \n\n", "index": 3, "text": "\\begin{align*}\n\\dot{x}(t) &= f(x(t),u(t)) \\quad\tx(0) = x_{0},\\\\\n y(t) &= h(x(t),u(t)) \\text{~for all~} t \\in [0,T],\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\dot{x}(t)\" display=\"inline\"><mrow><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=f(x(t),u(t))\\quad x(0)=x_{0},\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>u</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle y(t)\" display=\"inline\"><mrow><mi>y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=h(x(t),u(t))\\text{~{}for all~{}}t\\in[0,T],\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>u</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mtext>\u00a0for all\u00a0</mtext><mo>\u2062</mo><mi>t</mi></mrow><mo>\u2208</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mi>T</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.06326.tex", "nexttext": "\nwhere ${E_{y,\\mathrm{pred}}} = {\\mathtt{incoming}}({\\mathcal{G}_{y}},{v_{y}})$, ${v_{y,\\mathrm{pred}}} = {e_{y}}.{\\mathtt{tail}}$, and ${\\sigma}$ is the state trajectory that is computed via closed-loop prediction, i.e., the dynamical system is simulated forward in time with the initial state ${v_{y,\\mathrm{pred}}}.{\\mathtt{p}_{\\sigma}}.\\fBack()$ and the reference trajectory ${e_{y}}.{\\sigma}$. \n\n\\textit{Heuristic Value:} Given a node ${v_{y}} \\in {V_{y}}$, and an output goal region ${Y_{\\mathrm{goal}}}$, the function $\\fComputeHeuristic : ({v_{y}},{Y_{\\mathrm{goal}}}) \\mapsto r$ returns an estimate $r$ of the optimal cost from ${v_{y}}$ to ${Y_{\\mathrm{goal}}}$; it return zero if ${v_{y}} \\in {Y_{\\mathrm{goal}}}$. \n In this paper, we always assume that $\\fComputeHeuristic $ computes an admissible heuristic, that is, it never overestimates the actual cost of reaching ${Y_{\\mathrm{goal}}}$. \n\n\\textit{Queue Operations:} Nodes of the computed graphs are associated with some keys and priority queues are used to sort these nodes based on the precedence relation between keys. The following functions are implemented to maintain a given priority queue ${\\mathcal{Q}}$:\n\n\\begin{itemize}\n\\item ${\\mathcal{Q}}.{\\mathtt{top\\_key}}()$ returns the highest priority of all nodes in the priority queue ${\\mathcal{Q}}$ with the smallest key value if the queue is not empty. If ${\\mathcal{Q}}$ is empty, then ${\\mathcal{Q}}.{\\mathtt{top\\_key}}()$ returns a key value of $k = [\\infty; \\infty]$.\n\n\n\n\\item ${\\mathcal{Q}}.{\\mathtt{pop}}()$ deletes the node with the highest priority in the priority queue ${\\mathcal{Q}}$ and returns a reference to the node.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{update}}({v_{y}}, k)$ sets the key value of the node ${v_{y}}$ to $k$ and reorders the priority queue ${\\mathcal{Q}}$.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{insert}}({v_{y}}, k)$ inserts the node ${v_{y}}$ into the priority queue ${\\mathcal{Q}}$ with the key value $k$.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{remove}}({v_{y}})$ removes the node ${v_{y}}$ from the priority queue ${\\mathcal{Q}}$.\n\\end{itemize} \n\n\n\\textit{Initialization:} Given an initial point ${x_{\\mathrm{init}}} \\in {X}$, a goal region in the output space ${Y_{\\mathrm{goal}}} \\subset {Y}$, the function ${\\mathtt{Initialize}}: ({x_{\\mathrm{init}}}, {Y_{\\mathrm{goal}}}) \\mapsto ({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$ returns a graph ${\\mathcal{G}_{y}}$ that has only node ${v_{y}}$, whose output point is ${v_{y}}.{y} = {\\mathtt{OutputMap}}({x_{\\mathrm{init}}})$, a graph ${\\mathcal{G}_{\\sigma}}$ that has the only node ${v_{\\sigma}}$, whose trajectory is a single point ${v_{\\sigma}}.{\\sigma} = {x_{\\mathrm{init}}}$, and empty priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ that are used for ordering of nongoal and goal nodes, which represent points in ${Y}$, respectively.  \n\n\n\\textit{Exploration:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$, where ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are graphs whose nodes represent points in ${Y}$ and trajectories in ${\\mathcal{X}}$, respectively, and ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are priority queues that are used for ordering of nongoal and goal nodes that represent points in ${Y}$, a goal region in the output space ${Y_{\\mathrm{goal}}} \\subset {Y}$, and a point ${y} \\in {Y}$, the function ${\\mathtt{Extend}} : ({\\mathcal{S}}, {Y_{\\mathrm{goal}}}, {y}) \\mapsto  {\\mathcal{S}}^{\\prime} = ({\\mathcal{G}_{y}}^{\\prime},{\\mathcal{G}_{\\sigma}}^{\\prime},{\\mathcal{Q}}^{\\prime}, {\\mathcal{Q}_{\\mathrm{goal}}}^{\\prime})$ includes a new node, multiple edges to ${\\mathcal{G}_{y}}$ and multiple nodes, edges to ${\\mathcal{G}_{\\sigma}}$, updates the priorities of nodes in ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ and returns an updated tuple ${\\mathcal{S}}^{\\prime}$.\n\n\n\\textit{Exploitation:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$, where ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are graphs whose nodes represent points in ${Y}$ and trajectories in ${\\mathcal{X}}$, respectively, and ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are priority queues that are used for ordering of nongoal and goal nodes that represent points in ${Y}$, the function ${\\mathtt{Replan}} : {\\mathcal{S}} \\mapsto  {\\mathcal{S}}^{\\prime} = ({\\mathcal{G}_{y}}^{\\prime},{\\mathcal{G}_{\\sigma}}^{\\prime},{\\mathcal{Q}}^{\\prime}, {\\mathcal{Q}_{\\mathrm{goal}}}^{\\prime})$ rewires the parent node of the nodes in ${\\mathcal{G}_{y}}$ based on their cost-to-come values, includes new nodes and edges in ${\\mathcal{G}_{\\sigma}}$ if necessary, that is, propagating dynamics of the system for new sequence of reference trajectories, and returns an updated tuple ${\\mathcal{S}}^{\\prime}$.\n\n\\textit{Construction of Solution:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$,\nthe function ${\\mathtt{ConstrSolution}} : {\\mathcal{S}} \\mapsto {\\mathcal{T}_{x}}$ returns a tree whose edges and nodes represent simulated trajectories in ${\\mathcal{X}}$ and the corresponding internal states of the nodes of ${\\mathcal{G}_{y}}$. These trajectories are computed by propagating the dynamics with reference trajectories that are encoded in a tree of ${\\mathcal{G}_{y}}$, which is formed by the edges between nodes of ${\\mathcal{G}_{y}}$ and their parent nodes.\n\n\\textit{Graph and List Operations:} The following functions are used in the ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$ algorithm.\n\n\\begin{itemize}\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{succ}} : ({\\mathcal{{G}}}, v) \\mapsto V^{\\prime} \\subseteq V$ returns the nodes in $V$ that are the heads of the edges emanating from $v$, that is, $\n{\\mathtt{succ}}({\\mathcal{{G}}}, v) :=  \\left\\{ v^{\\prime} \\in V: e.{\\mathtt{tail}} = v \\text{~and~} e.{\\mathtt{head}} = v^{\\prime}, \\, e \\in E \\right\\}.$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{pred}} : ({\\mathcal{{G}}}, v) \\mapsto V^{\\prime} \\subseteq V$ returns the nodes in $V$ that are the tails of the edges going into $v$, that is, $\n{\\mathtt{pred}}({\\mathcal{{G}}}, v) := \\left\\{ v^{\\prime} \\in V: e.{\\mathtt{tail}} = v^{\\prime} \\text{~and~} e.{\\mathtt{head}} = v, \\, e \\in E \\right\\}.\n$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{outgoing}} : ({\\mathcal{{G}}}, v) \\mapsto E^{\\prime} \\subseteq E$ returns the edges in $E$ whose tail is $v$, that is, ${\\mathtt{outgoing}}({\\mathcal{{G}}}, v) := \\left\\{ e \\in E: e.{\\mathtt{tail}} = v \\right\\}.$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{incoming}} : ({\\mathcal{{G}}}, v) \\mapsto E^{\\prime} \\subseteq E$ returns the edges in $E$ whose head is $v$, that is, ${\\mathtt{incoming}}({\\mathcal{{G}}}, v) := \\left\\{ e \\in E: e.{\\mathtt{head}} = v \\right\\}.$\n\\end{itemize}\n\n\n\n\n\\begin{itemize}\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, and a point ${z} \\in {Z}$, the function $\\fFind : ({V_{z}},{z}) \\mapsto {v_{z}} \\in {V_{z}}$ returns the node in ${V_{z}}$ that satisfies ${v_{z}}.{z} = {z}$ if there exists any such node, null  otherwise. \n\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, the function $\\fBack$ returns a reference to the last node in the list if it is not empty, and null  otherwise.\n\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, the function $\\fFront$ returns a reference to the first node in the list if it is not empty, and null  otherwise.\n\\end{itemize}\n\n\n\n\n\n\\section{The {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}} Algorithm}\\label{section:closed_loop_rrtsharp_algorithm}\n\n\\subsection{Details of Data Structures}\nEach node ${v_{y}}$ in the graph ${\\mathcal{G}_{y}}$ is an $\\fInitOutputNode$ data structure, summarized in Table~\\ref{table:reference_node_edge_structure}. Each node ${v_{y}}$ is associated with a reference point $y \\in {\\mathbb{R}}^{m}$. It contains two estimates of the optimal cost-to-come value between the initial reference point and $y$, namely, cost-to-come value ${\\mathtt{g}}$ and one step look-ahead $g$-value ${\\mathtt{\\bar{g}}}$. It also keeps a heuristic value ${\\mathtt{h}}$, which is an underestimate of the optimal cost value between $y$ and ${Y_{\\mathrm{goal}}}$, to guide and reduce the search effort. Whenever ${\\mathtt{\\bar{g}}}$ is updated during the replanning procedure, the reference node that yields the corresponding minimum cost-to-come value is stored in the parent reference node ${\\mathtt{p}_{y}}$. Lastly, ${\\mathtt{p}_{\\sigma}}$ is the trajectory that is computed  by closed-loop prediction when the system is simulated with the reference trajectory between the nodes ${\\mathtt{p}_{y}}$ and ${v_{y}}$. Its terminal state represents the internal state associated with ${v_{y}}$.\n\n\\begin{table}\n\\centering\n\\caption{{\\small The node (${\\mathtt{OutNode}}$) and edge (${\\mathtt{OutEdge}}$) data structures for points and trajectories in output space, respectively}}\\label{table:reference_node_edge_structure}\n\n\\begin{tabular}{c|l|p{5.1cm}}\n{\\bf field}    & {\\bf type}\t& {\\bf description}       \\\\ \n\\hline\n\\hline\n$y$\t&   vector $\\in \\mathbb{R}^{p}$     & output point associated with this node \\\\\n${\\mathtt{g}}$    &  real  $\\in \\mathbb{R}$        & cost-to-come value              \\\\\n${\\mathtt{\\bar{g}}}$    & real    $\\in \\mathbb{R}$       & one step look-ahead $g$-value         \\\\\n${\\mathtt{h}}$    &   real $\\in \\mathbb{R}$        & heuristic value for the cost between $y$ and $\\mathcal{Y}_{\\mathrm{goal}}$ \\\\\n\n${\\mathtt{p}_{y}}$    & $\\fInitOutputNode$ & reference to the parent output node        \\\\\n${\\mathtt{p}_{\\sigma}}$     & $\\fInitTrajectoryNode$   & reference to the parent trajectory node       \\\\\n\n\n\n\\hline\n${r}$          &   trajectory $\\in {\\mathcal{Y}}$        \t& output trajectory associated with this edge                       \\\\\n${\\mathtt{tail}}$          &    $\\fInitOutputNode$      \t& reference to the tail output node         \\\\\n${\\mathtt{head}}$          &  $\\fInitOutputNode$          & reference to the head output node    \\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\nEach edge ${e_{y}}$ in the graph ${\\mathcal{G}_{y}}$ is an $\\fInitOutputEdge$ data structure, summarized in Table~\\ref{table:reference_node_edge_structure}. Each edge ${e_{y}}$ is associated with a trajectory  $r \\in {\\mathcal{Y}}$. It also contains two output nodes, namely, ${\\mathtt{tail}}$ and ${\\mathtt{head}}$, which represent the tail and the head output nodes of ${e_{y}}$, respectively.\n\n\nEach node ${v_{\\sigma}}$ in the graph ${\\mathcal{G}_{\\sigma}}$ is a $\\fInitTrajectoryNode$ data structure, summarized in Table~\\ref{table:trajectory_node_edge_structure}. Each node ${v_{\\sigma}}$ is associated with a trajectory $\\sigma \\in {\\mathcal{X}}$. It contains an output edge ${e_{y}}$, which corresponds to the reference trajectory that yields $\\sigma$ as the closed-loop prediction. It also keeps a list of outgoing output edges ${\\mathtt{outgoing}}$, and this list is used to compute outgoing trajectory nodes emanating from the terminal state of $\\sigma$. \n\n\n\\begin{table}\n\\centering\n\\caption{{\\small The node (${\\mathtt{TrajNode}}$) and edge (${\\mathtt{TrajEdge}}$) data structures for trajectories in state space} }\\label{table:trajectory_node_edge_structure}\n\n\\begin{tabular}{c|l|p{0.53\\columnwidth}}\n{\\bf field} & {\\bf type} & {\\bf description}       \\\\ \n\\hline\n\\hline\n$\\sigma$          &    trajectory $\\in {\\mathcal{X}}$     \t& state trajectory associated with this node    \\\\\n\n\n$e_{y}$           &   $\\fInitOutputEdge$         & reference to the output edge \n\\\\\n\n\n${\\mathtt{outgoing}}$\t\t   &   $\\fInitOutputEdge$ array        & list of outgoing output edges   \\\\\n\\hline\n$\\sigma$          &    trajectory $\\in {\\mathcal{X}}$     \t& state trajectory associated with this edge                      \\\\\n${\\mathtt{tail}}$          &    $\\fInitTrajectoryNode$     \t&  reference to the tail trajectory node          \\\\\n${\\mathtt{head}}$           &   $\\fInitTrajectoryNode$        & reference to the head trajectory node     \\\\ \n\\hline          \n\\end{tabular}\n\n\\end{table}\n\nEach edge ${e_{\\sigma}}$ in the graph ${\\mathcal{G}_{\\sigma}}$ is a $\\fInitTrajectoryEdge$ data structure, summarized in Table~\\ref{table:trajectory_node_edge_structure}. Each edge ${e_{\\sigma}}$ is associated with a trajectory  $\\sigma \\in {\\mathcal{X}}$. It contains two trajectory nodes, namely, ${\\mathtt{tail}}$ and ${\\mathtt{head}}$ which represent the tail and the head trajectory nodes of ${e_{\\sigma}}$, respectively.   \n\n\n\n\\subsection{Details of the Procedures}\n\nAlgorithm~\\ref{alg:body_closed_loop_rrtsharp} gives the body of the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm. First, the algorithm initializes the tuple of data structures ${\\mathcal{S}}$ that is incrementally grown and updated as exploration and exploitation are performed (Line 3). The tuple ${\\mathcal{S}}$ contains the graphs ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$, which are used to store output nodes and state trajectory nodes, respectively, and the priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$. The details of  ${\\mathtt{Initialize}}$  are given in Algorithm~\\ref{alg:initialize_closed_loop_rrtsharp}.\nThe graph ${\\mathcal{G}_{\\sigma}}$ is created with no edges and ${v_{\\sigma}}$ as its only node. This node represents a state trajectory that contains only the initial state ${x_{\\mathrm{init}}}$. Then, likewise, the graph ${\\mathcal{G}_{y}}$ is initialized with no edges and ${v_{y}}$ as its only node that represents ${y_{\\mathrm{init}}}$. The $g$- and $\\bar{g}$-values of ${v_{y}}$ are set with zero cost value.\nThe parent trajectory node of ${v_{y}}$ is set with the reference to the node ${v_{\\sigma}}$.\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \\SetKwData{vCVR}{$V_{r}$}\n    \n    \n    \n    \\SetKwData{vEPrime}{$E^{\\prime}$}\n    \\SetKwData{xinit}{$x_{\\mathrm{init}}$}\n    \\SetKwData{vI}{$k$}\n    \\SetKwData{xRand}{$x_{\\mathrm{rand}}$}\n    \\SetKwData{yrand}{$y_{\\mathrm{rand}}$}\n    \\SetKwData{vRRand}{$r_{\\mathrm{rand}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n   \n    \n    \\SetKwData{XGoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{YGoal}{$Y_{\\mathrm{goal}}$}\n   \n    \\SetKwData{x}{$x$}\n    \n    \n\n    \n    \\SetKwData{X}{$X$}\n    \n    \\SetKwData{xParent}{$x_{\\mathrm{parent}}$}\n    \n    \\SetKwData{vCEX}{$E_{x}$}\n\t\\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n        \n    \n    \\SetKwData{vxParent}{$v_{x,\\mathrm{parent}}$}\n    \n    \n    \n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\\SetKwData{cS}{$\\mathcal{S}$}\n\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fRRTsharp{$\\xinit,\\XGoal,\\X$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\YGoal \\coloneqq \\fOutputMap{\\XGoal}$;\n\t    \n\t\t$\\cS \\leftarrow \\fInitialize{\\xinit,\\YGoal}$;\n\t\t\n        \\For{$\\vI = 1$ to $N$ \\label{line:rrtsharp_itbegin}}\n        {\n            $\\yrand \\leftarrow \\fSample{\\vI}$;\n\n            $\\cS \\leftarrow \\fExtend{\\cS,\\YGoal,\\yrand}$;\n\n\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({a0}) {};}$\\S \\leftarrow \\fReplan{\\cS}$;{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({a1}) {};}\\label{line:rrtsharp_itend}\n\t\t}\n\n\t\t${\\mathcal{T}_{x}} \\leftarrow \\fConstructSolution{\\cS}$;\n\t\t\n        \\Return{${\\mathcal{T}_{x}}$};\n    }\n    \n\\caption{{\\small The ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$ Algorithm}}\\label{alg:body_closed_loop_rrtsharp}\n\n\n\\end{algorithm}\n\\DecMargin{2em}\n\n\n\n\n\n\n\n}\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \n    \\SetKwData{vy}{$v_{y}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n        \n    \\SetKwData{Vsigma}{$V_{\\sigma}$}\n    \\SetKwData{Esigma}{$E_{\\sigma}$}    \n    \\SetKwData{vEPrime}{$E^{\\prime}$}\n    \\SetKwData{xinit}{$x_{\\mathrm{init}}$}\n    \\SetKwData{vI}{$k$}\n    \\SetKwData{vXRand}{$x_{\\mathrm{rand}}$}\n    \\SetKwData{yrand}{$y_{\\mathrm{rand}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vClXGoal}{$\\mathcal{X}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n\n  \n    \n    \n\n    \n   \n    \n    \\SetKwData{vXParent}{$x_{\\mathrm{parent}}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n    \\SetKwData{vCEX}{$E_{x}$}\n\t\\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n        \n    \n    \n    \n    \\SetKwData{vVX}{$v_{x}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n\n    \\SetKwData{Vsigma}{$v_{\\sigma}$}\n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n    \\SetKwData{vEX}{$e_{x}$}\n\n\t\n\t\\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n\t\\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n\t\\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{vRInit}{$r_{\\mathrm{init}}$}\n\t\\SetKwData{yinit}{$y_{\\mathrm{init}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\\SetKwData{Qc}{$\\mathcal{Q}$}\n\n\t\\SetKwData{ssigma}{$\\sigma$}\n\t\\SetKwData{vNull}{$\\varnothing$}\n\t\\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\t\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fInitialize{$\\xinit,\\Ygoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\sigma \\leftarrow \\{\\xinit\\}$;\n    \t\t\n    \t$\\Vsigma \\leftarrow \\fInitTrajectoryNode{\\ssigma,\\vNull,\\vNull}$;\n\t\t\t\t\t    \t  \n\t\t$\\yinit \\leftarrow \\fOutputMap{\\xinit}$;\n\t\t\n\t\t$\\vy \\leftarrow \\fInitOutputNode{\\yinit}$;\n\t\t\n\t\t$\\vy.\\gvalue \\leftarrow 0$;\n\t\t$\\vy.\\gbarvalue  \\leftarrow 0$;\n\t\t\n\t\t$\\vy.\\hvalue  \\leftarrow \\fComputeHeuristic{\\yinit,\\Ygoal}$;\n\t\t\n\t\t$\\vy.\\psigma \\leftarrow \\Vsigma$;\n\t\t\n\t\t$\\Vy \\leftarrow \\{\\vy\\}$;\n\t\t$\\Ey \\leftarrow \\varnothing$;\n\t\t\n\t\t$\\vCVSigma \\leftarrow \\{\\Vsigma\\}$;\n\t\t$\\vCESigma \\leftarrow \\varnothing$;\n\t\t\n\t\t$\\Gy \\leftarrow (\\Vy,\\Ey)$;\n\t\t$\\Gsigma \\leftarrow (\\vCVSigma,\\vCESigma)$;\n\t\t\t\t\n\t\t$\\Qc \\leftarrow \\varnothing$;\n\t\t$\\Qgoal \\leftarrow \\varnothing$;\n\t\t\n\t\t\\Return{$\\Sc \\leftarrow (\\Gy,\\Gsigma,\\Qc,\\Qgoal)$};\n\t}\n\t\n\\caption{{\\small The ${\\mathtt{Initialize}}$ Procedure}} \\label{alg:initialize_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em}\n\n\n\n\n\n\n}\n\n\nThe algorithm iteratively builds a graph of collision-free reference trajectories ${\\mathcal{G}_{y}}$ by first sampling an output point ${y_{\\mathrm{rand}}}$ from the obstacle-free output space ${Y_\\mathrm{free}}$ (Line 5) and then extending the graph towards this sample (Line 6), at each iteration. The cost of the unique trajectory from the root node to a given node ${v_{y}}$ is denoted as $\\fCostValue({v_{y}})$. It also builds another graph ${\\mathcal{G}_{\\sigma}}$, to store the state trajectories computed by simulation of the closed-loop dynamics when a reference trajectory is tracked. \nOnce a new node is added to ${\\mathcal{G}_{y}}$ after  ${\\mathtt{Extend}}$,  ${\\mathtt{Replan}}$ is called to improve the existing solution by propagating the new information (Line 7). The dynamic system is simulated for different reference trajectories as needed during the search process. The computed state trajectories are added to the graph ${\\mathcal{G}_{\\sigma}}$ as new nodes along with the corresponding controls information. \n\nFinally, when a predetermined maximum number of iterations is reached,  ${\\mathtt{ConstrSolution}}$ extracts the spanning tree of ${\\mathcal{G}_{y}}$ that contains the lowest-cost reference trajectories (Line 8). Algorithm~\\ref{alg:construct_solution_closed_loop_rrtsharp} gives the details of ${\\mathtt{ConstrSolution}}$.\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \\SetKwData{vy}{$v_{y}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n \n \n\n\n    \\SetKwData{vI}{$k$}\n    \n    \n    \\SetKwData{vT}{$\\mathcal{T}$}\n  \n  \n   \n \n  \n    \n    \n\n    \n    \\SetKwData{vcapx}{$X$}\n    \n    \\SetKwData{vXParent}{$x_{\\mathrm{parent}}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n    \\SetKwData{vCEX}{$E_{x}$}\n    \n    \\SetKwData{vVXParent}{$v_{x,\\mathrm{parent}}$}\n  \n    \\SetKwData{vVX}{$v_{x}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n\n\n \n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n    \\SetKwData{vEX}{$e_{x}$}\n\t\n\t\n\t\\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n\t\\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n\t\\SetKwData{vFrontier}{$\\mathcal{Q}$}\n\t\\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\n\t\n\t\\SetKwData{sigmav}{$\\sigma$}\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \n    \n    \\fConstructSolution{$\\Sc$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Sc$;\n\t    \n        $(\\Vy,\\Ey) \\leftarrow \\Gy$;\n\t\t$\\vcapx \\leftarrow \\varnothing$;\n\t\t\n        \\ForEach{$\\vy \\in \\Vy$}\n        {\n\n\t        $\\sigma \\leftarrow \\vy.\\psigma.\\sigmav$;\n\n\t        $\\vVX \\leftarrow \\fInitStateNode{\\sigmav.\\fBack{}}$;\n\t        \n\t        $\\vCVX \\leftarrow \\vCVX \\cup \\{\\vVX\\}$;\n\t        \n\t        $\\vVXParent \\leftarrow \\fFind{\\vCVX,\\sigmav.\\fFront{}}$;\n\t        \n\t        \\If{$\\vVXParent = \\varnothing$}\n  \t        {\n  \t\t        $\\vVXParent \\leftarrow \\fInitStateNode{\\sigmav.\\fFront{}}$;\n  \t\t        \n  \t\t        $\\vCVX \\leftarrow \\vCVX \\cup \\{\\vVXParent\\}$;\n  \t        }\n  \t        \n   \t        $\\vEX \\leftarrow \\fInitStateEdge{\\vVXParent, \\vVX, \\sigmav}$;\n   \t        \n            $\\vCEX \\leftarrow \\vCEX \\cup \\{\\vEX\\}$;\n              \n            $\\vcapx \\leftarrow \\vcapx \\cup \\{\\sigma.\\fBack{}\\}$;\t        \n\t        \t        \n        }\n\n        \\Return{$\\Tx = (\\vCVX,\\vCEX)$};\n    }\n\n\\caption{{\\small The ${\\mathtt{ConstrSolution}}$ Solution Procedure}}\n\\label{alg:construct_solution_closed_loop_rrtsharp}\n\\end{algorithm}\n\\DecMargin{0.7em}\n\n\n\n\n\n\n}\n\n\n\\subsubsection{The ${\\mathtt{Extend}}$ Procedure}\nThe ${\\mathtt{Extend}}$ procedure is given in Algorithm~\\ref{alg:extend_closed_loop_rrtsharp}. It first extends the nearest output node ${v_{y,\\mathrm{nearest}}}$ to the output sample ${y}$ (Lines 4-5). The output trajectory that extends the nearest output node ${v_{y,\\mathrm{nearest}}}$ towards the output sample ${y}$ is denoted as ${r_{\\mathrm{new}}}$. The final output point on the output trajectory ${r_{\\mathrm{new}}}$ is denoted as ${y_{\\mathrm{new}}}$. If ${r_{\\mathrm{new}}}$ is collision-free, then a new output node ${v_{y,\\mathrm{new}}}$ is created to represent the new output point ${y_{\\mathrm{new}}}$ (Line 8), and the following changes in the vicinity of ${v_{y,\\mathrm{new}}}$ on both graphs are shown in Fig.~\\ref{figure:cl_rrtsharp_extension}. The initial node is shown as a square box, the obstacles are shown in red color, and the graphs ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are  shown in orange and green colors.\n\n\\begin{figure}\n\t\\centering\n\t\\includegraphics[scale=0.3]{fig_cl_rrtsharp_extension}\n\t\n\t\\caption{Extension of the graphs computed by the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm. Trajectories in the output and state spaces are shown in orange and green colors, respectively. Whenever a new node in the output space is added, then several incoming and outgoing edges are included to the graph in the vicinity of the new node, i.e., region colored with cyan.}\\label{figure:cl_rrtsharp_extension}\n\t\\vspace*{-15pt}\n\\end{figure}\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\t\n    \n    \\small\n    \n    \n\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n    \n\n    \n\n    \n    \n\n    \n\n    \n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n    \\SetKwData{Ty}{$\\mathcal{T}_{y}$}\n    \\SetKwData{Gx}{$\\mathcal{G}_{x}$}\n    \n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n    \\SetKwData{xalg}{$x$}\n    \\SetKwData{xgoal}{$x_{\\mathrm{goal}}$}\n    \\SetKwData{vGRX}{$V_{x}$}\n    \\SetKwData{vEX}{$E_{x}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n    \n    \\SetKwData{vFrontier}{$\\mathcal{Q}$}\n    \\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n           \n    \n    \n    \\SetKwData{vESigmaPrime}{$E_{\\sigma}^{\\prime}$}    \n    \\SetKwData{vXNearest}{$x_{\\mathrm{nearest}}$}\n    \\SetKwData{vXNew}{$x_{\\mathrm{new}}$}\n    \\SetKwData{vCXNear}{$\\mathcal{X}_{\\mathrm{near}}$}\n    \\SetKwData{vXNear}{$x_{\\mathrm{near}}$}\n\t\\SetKwData{xpred}{$x_{\\mathrm{pred}}$}\n\n\t\n\t\\SetKwData{vSigmaNear}{$\\sigma_{\\mathrm{near}}$}\n\t\\SetKwData{ynew}{$y_{\\mathrm{new}}$}\n\t\\SetKwData{vYNewPrime}{$y^{\\prime}_{\\mathrm{new}}$}\n\t\t\n\t\\SetKwData{yalg}{$y$}\n\t\\SetKwData{vCYNear}{$\\mathcal{R}_{\\mathrm{near}}$}\n    \\SetKwData{vYNearest}{$r_{\\mathrm{nearest}}$}\n    \\SetKwData{vYNear}{$r_{\\mathrm{near}}$}\n    \\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n    \n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \n    \\SetKwData{vypred}{$v_{y,\\mathrm{pred}}$}\n    \\SetKwData{vCVPred2}{$V_{\\mathrm{pred}}$}\n    \\SetKwData{vCEPred}{$E_{y,\\mathrm{pred}}$}\n\n    \\SetKwData{vCVSucc}{$V_{\\mathrm{succ}}$}\n    \\SetKwData{vCESucc}{$E_{y,\\mathrm{succ}}$}\n        \n\t\\SetKwData{vV2}{$y$}\n\t\\SetKwData{vCVNear2}{$V_{\\mathrm{near}}$}\n\t\\SetKwData{vynearest}{$v_{y,\\mathrm{nearest}}$}\n\t\\SetKwData{vynew}{$v_{y,\\mathrm{new}}$}\n\t\\SetKwData{vynear}{$v_{y,\\mathrm{near}}$}\n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\n\n   \n     \n    \n    \\SetKwData{ey}{$e_{y}$}\n    \\SetKwData{esigma}{$e_{\\sigma}$}\n    \n    \\SetKwData{vCVSigmaPrime}{$V^{\\prime}_{\\sigma}$}\n    \\SetKwData{vCESigmaPrime}{$E^{\\prime}_{\\sigma}$}\n    \n    \\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n    \n  \n    \\SetKwData{vsigmapred}{$v_{\\sigma,\\mathrm{pred}}$}\n    \\SetKwData{vsigmanear}{$v_{\\sigma,\\mathrm{near}}$}\n    \\SetKwData{vsigmanew}{$v_{\\sigma,\\mathrm{new}}$}\n    \\SetKwData{rnew}{$r_{\\mathrm{new}}$}\n    \n\t\n\t\\SetKwData{bargvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{pyref}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\\SetKwData{vCostValue}{$\\mathtt{c}$} \n\t\n\t\\SetKwData{tthead}{$\\mathtt{head}$}\n\t\n\t\\SetKwData{ralg}{$r$}\n\t\\SetKwData{gvalc}{$\\mathtt{g}$}\n\t\\SetKwData{hvalueext}{$\\mathtt{h}$}\n\t\\SetKwData{Scval}{$\\mathcal{S}$}\n\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n\n\n\n    \n\n    \\SetFuncSty{textbf}\n    \n    \\fExtend{$\\Scval,\\Xgoal,\\yalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t\t$(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Scval$;\n\t\t\n        $(\\Vy,\\Ey) \\leftarrow \\Gy$;\n        $(\\vCVSigma,\\vCESigma) \\leftarrow \\Gsigma$;\n        \n        $\\vynearest \\leftarrow \\fNearest{\\Gy,\\yalg}$;\n\n        $\\rnew \\leftarrow \\fSteer{\\vynearest.\\yalg,\\yalg}$;\n\n        \\If{$\\fObstacleFree{\\rnew}$}\n        {\n            $\\ynew \\leftarrow \\rnew.\\fBack{}$;\n            \n            $\\vynew \\leftarrow \\fInitOutputNode{\\ynew}$;\n            \n            $\\vynew.\\hvalueext \\leftarrow \\fComputeHeuristic{\\ynew,\\Ygoal}$;\n            \n            $\\vCVNear2 \\leftarrow \\fNear{\\Gy,\\ynew,\\ensuremath{|\\Vy|}} \\cup \\{ \\vynearest \\}$;\n\n\t\t\t$\\vCESucc \\leftarrow \\varnothing$;\n\t\t\t$\\vCEPred \\leftarrow \\varnothing$;\n\t\t\t\n\t\t\t\\ForEach{$\\vynear \\in \\vCVNear2$}\n            {\n\t            $\\ralg \\leftarrow \\fSteer{\\ynew,\\vynear.\\yalg}$;\n\t            \n                \\If{$\\fObstacleFree{\\ralg}$}\n                {\n\t                $\\ey \\leftarrow \\fInitOutputEdge{\\vynew,\\vynear,\\ralg}$;\n\t                \n\t                $\\vCESucc \\leftarrow \\vCESucc \\cup \\{ \\ey \\}$;\n                }\n                \n\t            $\\ralg \\leftarrow \\fSteer{\\vynear.\\yalg,\\ynew}$;\n\t           \n                \\If{$\\fObstacleFree{\\ralg}$}\n                {\n\t                $\\ey \\leftarrow \\fInitOutputEdge{\\vynear,\\vynew,\\ralg}$;\n\t               \n\t                $\\vCEPred \\leftarrow \\vCEPred \\cup \\{ \\ey \\}$;\n                }\n            }\n            \n            $\\vCVSigmaPrime \\leftarrow \\varnothing$;\n            $\\vCESigmaPrime \\leftarrow \\varnothing$;\n            \n            \\ForEach{$\\ey \\in \\vCEPred$}\n            {\n\t            $\\vypred \\leftarrow \\ey.{\\mathtt{tail}}$;\n\t            \n\t            $\\vsigmapred \\leftarrow \\vypred.\\psigma$;\n\t              \n\t            $\\xpred \\leftarrow \\vsigmapred.\\sigma.\\fBack{}$; \n\t              \n\t            $\\sigma \\leftarrow \\fPropagate{\\xpred,\\ey.\\ralg}$;\n\t             \n\t            \\If{$\\fObstacleFree{\\sigmaalg}$} \n\t            { \n\t\t            $\\vsigmanew \\leftarrow \\fInitTrajectoryNode{\\sigmaalg,\\ey,\\vCESucc}$;\n\t             \n\t\t            $\\esigma \\leftarrow \\fInitTrajectoryEdge{\\vsigmapred,\\vsigmanew,\\sigmaalg}$;\n\t            \n\t\t            $\\vCVSigmaPrime \\leftarrow \\vCVSigmaPrime \\cup \\{ \\vsigmanew \\}$;\n\t\t            \n\t\t            $\\vCESigmaPrime \\leftarrow \\vCESigmaPrime\\cup \\{ \\esigma \\}$;\n\t                  \n\t\t            \\If{$\\vynew.\\bargvalue >  \\vypred.\\gvalc + \\fCostValue{\\sigmaalg}$}\n\t\t            {\n\t\t\t         \t$\\vynew.\\bargvalue \\leftarrow  \\vypred.\\gvalc + \\fCostValue{\\sigmaalg}$;\n\t                      \n\t\t                $\\vynew.\\pyref \\leftarrow \\vypred$;\n\t                  \n\t\t                $\\vynew.\\psigma \\leftarrow \\vsigmanew$;\n\t\n\t\t            }\n\t\n                }\n\t         } \n\n            $\\Vy \\leftarrow \\Vy \\cup \\{ \\vynew \\}$;\n            $\\Ey \\leftarrow \\Ey \\cup \\vCESucc \\cup \\vCEPred$;\n            \n            $\\vCVSigma \\leftarrow \\vCVSigma \\cup \\vCVSigmaPrime$;\n            $\\vCESigma \\leftarrow \\vCESigma \\cup \\vCESigmaPrime$;\n\n            $\\Gy \\leftarrow (\\Vy,\\Ey)$;\n            $\\Gsigma \\leftarrow (\\vCVSigma,\\vCESigma)$;\n            \n            $\\vFrontier \\leftarrow \\fUpdateQueue{\\vFrontier,\\vynew}$;\n                                \n            $\\Qgoal \\leftarrow \\fUpdateGoal{\\Qgoal,\\vynew,\\Xgoal}$;\n                        \n        }\n        \n        \\Return{$\\Scval \\leftarrow (\\Gy,\\Gsigma,\\vFrontier,\\Qgoal)$};\n    }\n\n\n\\caption{{\\small The ${\\tt Extend}$ Procedure}{\\color{white}$^\\#$}}\\label{alg:extend_closed_loop_rrtsharp}\n\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n\n}\n\n The members of the node ${v_{y,\\mathrm{new}}}$ are set as follows. First,  ${\\mathtt{Near}}$ finds the set of neighbor output nodes ${V_{\\mathrm{near}}}$ in the neighborhood of the new output point ${y_{\\mathrm{new}}}$ (Line 9). Then, the set of incoming edges ${E_{y,\\mathrm{pred}}}$ and outgoing edges ${E_{y,\\mathrm{succ}}}$ of the new output node ${v_{y,\\mathrm{new}}}$ are computed by using the information of the neighbor output nodes (Lines 10-19). \n \n Once the new output node ${v_{y,\\mathrm{new}}}$ is created together with the set of incoming edges ${E_{y,\\mathrm{pred}}}$ and outgoing edges ${E_{y,\\mathrm{succ}}}$ connecting it to its neighbor output nodes ${V_{\\mathrm{near}}}$,  ${\\mathtt{Extend}}$  attempts to find the best incoming edge that yields a segment of a reference trajectory which incurs minimum cost to get to ${v_{y,\\mathrm{new}}}$ among all incoming edges in ${E_{y,\\mathrm{pred}}}$ (Lines 20-34). That is, for any incoming edge ${e_{y}}$ in ${E_{y,\\mathrm{pred}}}$, the algorithm first gets the information of the predecessor output node ${v_{y,\\mathrm{pred}}}$ and its internal state ${x_\\mathrm{pred}}$ by using the information of the parent state trajectory node ${v_{\\sigma,\\mathrm{pred}}}$ (Lines 22-24). Then, it simulates the system  forward in time with the state ${x_\\mathrm{pred}}$ being the initial state and ${e_{y}}.{r}$ being the reference trajectory to be tracked, (Line 25). If the state trajectory ${\\sigma}$ computed by closed-loop prediction is collision-free, a new trajectory node ${v_{\\sigma,\\mathrm{new}}}$ is created together with its list of outgoing output trajectories being initialized with ${E_{y,\\mathrm{succ}}}$ (Line 27). When a new trajectory node ${v_{\\sigma,\\mathrm{new}}}$ is created, the outgoing state trajectories emanating from the final state of the state trajectory ${v_{\\sigma,\\mathrm{new}}}.{\\sigma}$ via closed-loop prediction are not immediately computed, for the sake of efficiency. Instead, the algorithm keeps the set of candidate outgoing output trajectories, that is, the edges in ${E_{y,\\mathrm{succ}}}$, in a list ${v_{\\sigma,\\mathrm{new}}}.{\\mathtt{outgoing}}$, and the simulation of the system  for these output trajectories is postponed until the head output node of the output edge ${v_{\\sigma,\\mathrm{new}}}.{e_{y}}$ is selected for the Bellman update during the ${\\mathtt{Replan}}$ procedure. Once the new state trajectory node ${v_{\\sigma,\\mathrm{new}}}$ and the edge between the predecessor state trajectory node ${v_{\\sigma,\\mathrm{pred}}}$ and itself are created (Lines 27-28), they are added to the set of nodes and edges of the graph ${\\mathcal{G}_{\\sigma}}$, respectively (Lines 29-30). If the incoming output edge ${e_{y}}$ between the predecessor output node ${v_{y,\\mathrm{pred}}}$ and the new output node ${v_{y,\\mathrm{new}}}$ yields a collision-free state trajectory ${\\sigma}$ that incurs cost less than the current cost of ${v_{y,\\mathrm{new}}}$, then, the ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{new}}}$ is set with new lower cost, ${v_{y,\\mathrm{pred}}}$ and ${v_{\\sigma,\\mathrm{new}}}$ are made the new parent output node and the new parent state trajectory node of ${v_{y,\\mathrm{new}}}$ (Lines 31-34). \n \n After successful creation of the new output node ${v_{y,\\mathrm{new}}}$, it is added to the graph ${\\mathcal{G}_{y}}$ together with all of its collision-free output edges (Line 36). Likewise, all trajectory nodes and edges created during the simulation of the system dynamics are added to the graph ${\\mathcal{G}_{\\sigma}}$ (Line 37). Lastly, the priority queues, ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are updated accordingly by using the information of the new output node ${v_{y,\\mathrm{new}}}$, that is, reordering of the priorities after insertion of ${v_{y,\\mathrm{new}}}$ to the queue ${\\mathcal{Q}}$ and reordering the goal output nodes in ${\\mathcal{Q}_{\\mathrm{goal}}}$ if ${v_{y,\\mathrm{new}}}$ happens to be a goal output node (Lines 38-39).\n\\subsubsection{The ${\\mathtt{Replan}}$ Procedure}\nThe ${\\mathtt{Replan}}$ procedure is given in Algorithm~\\ref{alg:replan_closed_loop_rrtsharp} (see~\\cite{arslan2013useofrelaxation}). It improves cost-to-come values of output nodes by operating on the nonstationary and promising nodes of the graph ${\\mathcal{G}_{y}}$. It  pops the most promising nonstationary node from the priority queue ${\\mathcal{Q}}$, if there are any, and this  node is made stationary by assigning its ${\\mathtt{\\bar{g}}}$-value to its ${\\mathtt{g}}$-value (Lines 5-6). Then, the ${\\mathtt{g}}$-value of the output node ${v_{y}}$ is used to improve the ${\\mathtt{\\bar{g}}}$-values of its neighbor output nodes. Before this, the algorithm computes the set of all outgoing state trajectories emanating from internal state of the output node ${v}$ (Lines 9-16). To do so, the algorithm first gets the information of the internal state ${x}$ by using the parent state trajectory node of ${v_{y}}$ (Lines 7-8). For any outgoing edge ${e_{y}}$ in ${v_{\\sigma}}.{\\mathtt{outgoing}}$, the algorithm first gets the information of the successor output node ${v_{y,\\mathrm{succ}}}$ by using the output edge ${e_{y}}$ (Line 10). Then, it simulates the system  forward in time with the state ${x}$ being the initial state and ${e_{y}}.{r}$ being the reference trajectory to be tracked (Line 11). If the state trajectory ${\\sigma}$ computed by closed-loop prediction is collision-free, a new trajectory node ${v_{\\sigma,\\mathrm{succ}}}$ is created together with its list of outgoing output trajectories being initialized with the set of outgoing output edges of ${v_{y,\\mathrm{succ}}}$ (Line 13). Also, a state trajectory edge between ${v_{\\sigma}}$ and ${v_{\\sigma,\\mathrm{succ}}}$ is created (Line 14). Then, the new state trajectory node and edge are tentatively added to the set of nodes and edges of the graph ${\\mathcal{G}_{\\sigma}}$ (Lines 15-16). This  continues until all candidate outgoing output trajectories are processed in the closed-loop simulation, then the list ${v_{y}}.{\\mathtt{outgoing}}$ is cleared up (Line 17). All newly computed state trajectory nodes and edges are added to the graph ${\\mathcal{G}_{\\sigma}}$ (Line 18).\n\n For each outgoing state trajectory ${\\sigma}$, ${\\mathtt{Replan}}$ adds up its cost, incurred by reaching to the successor output node ${v_{y,\\mathrm{succ}}}$ to the ${\\mathtt{g}}$-value of ${v_{y}}$, and compare it with the current ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{succ}}}$ (Line 22). If the outgoing state trajectory edge ${\\sigma}$ yields a lower cost than ${v_{y,\\mathrm{succ}}}$,  the ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{succ}}}$ is set with new lower cost, and ${v_{y}}$ and ${v_{\\sigma,\\mathrm{succ}}}$ are made the new parent output node and the new parent state trajectory node of ${v_{y,\\mathrm{succ}}}$, respectively (Lines 23-25). Last, the priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are updated  by using the update information of the successor output node ${v_{y,\\mathrm{succ}}}$, that is, reordering of the priorities after updating the key value of ${v_{y,\\mathrm{succ}}}$ to the queue ${\\mathcal{Q}}$ and reordering the goal output nodes in ${\\mathcal{Q}_{\\mathrm{goal}}}$ if ${v_{y,\\mathrm{succ}}}$ happens to be a goal output node (Lines 26-27). These steps are repeated until there is no promising nonstationary output node left in the priority queue ${\\mathcal{Q}}$, that is,  ${\\mathcal{Q}}.\\fTopKey() \\succeq {\\mathcal{Q}_{\\mathrm{goal}}}.\\fTopKey()$.\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \n    \\SetKwData{Valg}{$V$}\n    \n    \\SetKwData{vFrontier}{$\\mathcal{Q}$}\n    \\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{xgoal}{$x_{\\mathrm{goal}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n   \n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{vXminGoal}{$v^{*}_{\\mathrm{goal}}$}\n    \\SetKwData{vVminGoal}{$v^{*}_{\\mathrm{goal}}$}\n    \\SetKwData{xalg}{$x$}\n  \n\n\t\\SetKwData{pyalg}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\n\n\t\\SetKwData{vysucc}{$v_{y,\\mathrm{succ}}$}\n\t\\SetKwData{vy}{$v_{y}$}\n\t\\SetKwData{bargvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{gvalue}{$\\mathtt{g}$}\n\n\t\\SetKwData{vCostValue}{$\\mathtt{c}$} \n\t\\SetKwData{ralg}{$r$} \n\t\\SetKwData{sigmaalg}{$\\sigma$} \n\t\t\n\t\\SetKwData{ey}{$e_{y}$}\n\t\\SetKwData{outgoingalg}{$\\mathtt{outgoing}$} \n\t\\SetKwData{vsigma}{$v_{\\sigma}$} \n\t\\SetKwData{vsigmasucc}{$v_{\\sigma,\\mathrm{succ}}$} \n\t\\SetKwData{esigma}{$e_{\\sigma}$} \n\n   \n \n    \\SetKwData{Vsigma}{$V_{\\sigma}$}\n    \\SetKwData{Esigma}{$E_{\\sigma}$}   \n    \\SetKwData{headalg}{$\\mathtt{head}$}  \n \n\n\n\t\\SetKwData{vVYFrom}{$v_{y,\\mathrm{from}}$} \n\t\\SetKwData{vVYTo}{$v_{y,\\mathrm{to}}$} \n\t\\SetKwData{vVMinRGoal}{$v^{*}_{r,\\mathrm{goal}}$} \n\t\\SetKwData{vCVYGoal}{$V_{y,\\mathrm{goal}}$} \n\t\\SetKwData{vCVGoal}{$V_{\\mathrm{goal}}$} \n\t\\SetKwData{vKey}{$\\mathtt{key}$}  \n\t\\SetKwData{vVSigmaPrime}{$v^{\\prime}_{\\sigma}$} \n\t\\SetKwData{vVRPrime}{$v^{\\prime}_{r}$} \n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fReplan{$\\Sc, \\Xgoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Sc$;\n\n        $(\\Vsigma,\\Esigma) \\leftarrow \\Gsigma$;\n\n        {\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p6st}) {};}\\While{$\\vFrontier.\\fTopKey{} \\prec \\Qgoal.\\fTopKey{}$}\n        {\n            \n\t\t\t\n\t\t\t$\\vy \\leftarrow \\vFrontier.\\fPop{}$;\n\t\t\t\t          \n\t\t\t$\\vy.\\gvalue\\leftarrow \\vy.\\bargvalue$; \n\t\t\t\t            \n\t\t\t$\\vsigma \\leftarrow \\vy.\\psigma$;\n\t\t\t              \n\t\t\t$\\xalg \\leftarrow \\vsigma.{\\sigma}.\\fBack{}$;\n\t\t\t              \n\t\t\t\\ForEach{$\\ey \\in \\vsigma.\\outgoingalg$}\n\t\t\t{\n\t\t\t\t$\\vysucc \\leftarrow \\ey.\\headalg$;\n\t\t\t\n\t\t\t\t$\\sigmaalg \\leftarrow \\fPropagate{\\xalg,\\ey.\\ralg}$;\n\t\t\t\n\t\t\t\t\\If{$\\fObstacleFree{\\sigmaalg}$}\n\t\t\t\t{\n\t\t\t\t\t$\\vsigmasucc \\leftarrow \\fInitTrajectoryNode{\\sigmaalg,\\ey,\\fOutgoing{\\Gy,\\vysucc}}$;\n\n\t\t\t\t\t$\\esigma \\leftarrow \\fInitTrajectoryEdge{\\vsigma,\\vsigmasucc,\\sigmaalg}$;\n\t\t\t\n\t\t\t\t\t$\\Vsigma \\leftarrow \\Vsigma \\cup \\{ \\vsigmasucc \\}$;\n\t\t\t\t  \n\t\t\t\t\t$\\Esigma \\leftarrow \\Esigma \\cup \\{ \\esigma \\}$;\n\t\t\t\t}\n\t\t\t}\t\n\t\t\t              \n\t\t\t$\\vsigma.\\outgoingalg \\leftarrow \\varnothing$;\n\t\t\t\n\t\t\t$\\Gsigma \\leftarrow (\\Vsigma,\\Esigma)$;\n\t\t\t\t  \t\t\n\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p8st}) {};}\\ForEach{$\\vsigmasucc \\in \\fSuccessor{\\Gsigma,\\vsigma}$}\n\t\t\t{\n\t\t\t\t$\\sigmaalg \\leftarrow \\vsigmasucc.\\sigmaalg$;\n\t\t\t\n\t\t\t\t$\\vysucc \\leftarrow \\vsigmasucc.\\ey.\\headalg$;\n\t\t\t\n\t\t\t\t\\If{$\\vysucc.\\bargvalue > \\vy.\\gvalue + \\fCostValue{\\sigmaalg}$}\n\t\t\t\t{\n\t\t\t\n\t\t\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p9st}) {};}$\\vysucc.\\bargvalue \\leftarrow \\vy.\\gvalue + \\fCostValue{\\sigmaalg}$; \n\t\t\t\n\t\t\t\t\t$\\vysucc.\\pyalg \\leftarrow \\vy$;\n\t\t\t\n\t\t\t\t\t$\\vysucc.\\psigma \\leftarrow \\vsigmasucc$;\n\t\t\t\t\t\t\n\t\t\t\t\t$\\vFrontier \\leftarrow \\fUpdateQueue{\\vFrontier,\\vysucc}$;\n\t\t\t\n\t\t\t\t\t$\\Qgoal \\leftarrow \\fUpdateGoal{\\Qgoal,\\vysucc,\\Xgoal}$;{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p6en}) {};}\n\t\t\t\n\t\t\t\t}\n\t\t\t}\t\t\t            \t\n\t\t\t            \t\t\t\t       \n        }\n\n        \\Return{$\\Sc \\leftarrow (\\Gy,\\Gsigma, \\vFrontier, \\Qgoal)$};\n   }\n\n\\caption{ {\\small ${\\mathtt{Replan}}$ Procedure}{\\color{white}$^\\#$}} \\label{alg:replan_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n}\n\nThe auxiliary procedures  in  ${\\mathtt{Extend}}$ and ${\\mathtt{Replan}}$  are shown in Algorithm~\\ref{alg:auxiliary_procedures_closed_loop_rrtsharp}.  $\\fUpdateQueue$  maintains the priority queue ${\\mathcal{Q}}$ whenever a new output node is created or key value of an output node that is already in the queue is updated. During a call to  $\\fUpdateQueue$  with the priority queue ${\\mathcal{Q}}$ and the output node ${v_{y}}$, there are three possible cases. First, if ${v_{y}}$ is a nonstationary output node, that is, ${v_{y}}.{\\mathtt{g}} \\neq {v_{y}}.{\\mathtt{\\bar{g}}}$, key value of ${v_{y}}$ is updated and priorities in the queue are reordered  (Line 3). Second, if ${v_{y}}$ is a nonstationary output node and it is not in the queue, then it is inserted to the queue ${\\mathcal{Q}}$ with its key value (Line 5). Third, if ${v_{y}}$  is a stationary output node, that is, ${v_{y}}.{\\mathtt{g}} = {v_{y}}.{\\mathtt{\\bar{g}}}$, and it is in the queue ${\\mathcal{Q}}$, then, it is removed from the queue ${\\mathcal{Q}}$ (Line 7).\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Valg}{$V$}\n \n   \n  \n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n    \\SetKwData{vClXGoal}{$\\mathcal{X}_{\\mathrm{goal}}$}\n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{xalg}{$x$}\n   \n \n    \\SetKwData{vK}{$k$}\n    \n    \n\t\\SetKwData{yalg}{$y$}\n\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n \n \n   \n\n\n    \\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\t\\SetKwData{vFrontier}{$\\mathcal{Q}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{Ygoal}{$\\mathcal{Y}_{\\mathrm{goal}}$}\n\n\n\n\n\n\n\n\t\\SetKwData{vyalg}{$v_{y}$}\n\t\\SetKwData{vsigma}{$v_{\\sigma}$}\n\n\n    \n\n   \n    \\SetFuncSty{textbf}\n    \\fUpdateQueue{$\\vFrontier,\\vyalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n         \\If{$\\vyalg.\\gvalue  \\neq \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\in \\vFrontier$}\n         {\n            $\\vFrontier.\\fUpdate{\\vyalg,\\fKey{\\vyalg}}$;\n         }\n         \\ElseIf{$\\vyalg.\\gvalue  \\neq \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\notin \\vFrontier$}\n         {\n            $\\vFrontier.\\fInsert{\\vyalg,\\fKey{\\vyalg}}$;\n         }\n         \\ElseIf{$\\vyalg.\\gvalue  = \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\in \\vFrontier$}\n         {\n            $\\vFrontier.\\fRemove{\\vyalg}$;\n         }\n         \n         \\Return{$\\vFrontier$};\n    }\n\n\n\t\\SetFuncSty{textbf}\n    \\fUpdateGoal{$\\Qgoal,\\vyalg,\\Ygoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vsigma \\leftarrow \\vyalg.{\\mathtt{p}_{\\sigma}}$;\n\t    \n\t    $\\xalg \\leftarrow \\vsigma.\\sigmaalg.\\fBack{}$;\n\t    \n\t    \\If{$\\xalg \\in \\Xgoal$}\n\t    {\n\t\t    \\If{$\\vyalg \\in \\Qgoal$}\n\t        {\n\t\t        $\\Qgoal.\\fUpdate{\\vyalg,\\fKey{\\vyalg}}$;\n\t         }\n\t        \\Else\n\t        {\n\t\t        $\\Qgoal.\\fInsert{\\vyalg,\\fKey{\\vyalg}}$;\n\t        }\n\t    }\n        \\Return{$\\Qgoal$};\n    }\n    \n    \\SetKwFunction{fH}{h}\n    \n\n\n    \\SetKwData{vGPrime}{$g^{\\prime}$}\n    \\SetKwData{vGMin}{$g_{\\min}$}\n    \\SetKwData{vF}{$f$}\n    \\SetKwData{vKey}{$key$}\n\n    \\SetFuncSty{textbf}\n    \\fKey{$\\vyalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n        \\Return{$\\vK = (\\vyalg.\\gbarvalue+ \\vyalg.\\hvalue, \\vyalg.\\hvalue)$};\n    }\n\n\\caption{{\\small Auxiliary Procedures}{\\color{white}$^\\#$}} \\label{alg:auxiliary_procedures_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n}\n\nAlgorithm~\\ref{alg:constructor_procedures_closed_loop_rrtsharp} gives constructor procedures for node and edge data structures used in the ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$.\n\n{\n\\setlength{\\intextsep}{1pt}\n\n\n\n\\IncMargin{0.5em}\n\n\n\n\\begin{algorithm}[h]\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Valg}{$V$}\n    \\SetKwData{Ey}{$E_{y}$}\n   \n \n   \n  \n   \n \n  \n \n    \\SetKwData{xalg}{$x$}\n \n  \n  \n    \n    \n\t\\SetKwData{yalg}{$y$}\n\t\\SetKwData{ralg}{$r$}\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n\n    \\SetKwData{vx}{$v_{x}$}\n    \\SetKwData{ey}{$e_{y}$}\n\n\n    \\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\n\n\n\t\\SetKwData{vVYFrom}{$v_{y,\\mathrm{from}}$}\n\t\\SetKwData{vVYTo}{$v_{y,\\mathrm{to}}$}\n\t\\SetKwData{vVXFrom}{$v_{x,\\mathrm{from}}$}\n\t\\SetKwData{vVXTo}{$v_{x,\\mathrm{to}}$}\n\t\\SetKwData{vVSigmaFrom}{$v_{\\sigma,\\mathrm{from}}$}\n\t\\SetKwData{vVSigmaTo}{$v_{\\sigma,\\mathrm{to}}$}\n\t\\SetKwData{vEX}{$e_{x}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\\SetKwData{py}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{vy}{$v_{y}$}\n\t\\SetKwData{vsigma}{$v_{\\sigma}$}\n\t\\SetKwData{ey}{$e_{y}$}\n\t\\SetKwData{esigma}{$e_{\\sigma}$}\n\t\\SetKwData{tailalg}{$\\mathtt{tail}$}\n\t\\SetKwData{headalg}{$\\mathtt{head}$}\n\t\\SetKwData{outgoingalg}{$\\mathtt{outgoing}$}\n\t\n\n    \n    \\setlength{\\columnsep}{2mm}\n\t\\begin{multicols*}{2}\n\t\\vspace*{-4mm}\n\t\\SetFuncSty{textbf}\n    \n    \n    \\fInitOutputNode{$\\yalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vy.\\yalg \\leftarrow \\yalg$;\n\t    \n\t    $\\vy.\\gvalue \\leftarrow \\infty$;\n\t    $\\vy.\\gbarvalue  \\leftarrow \\infty$;\n\t    \n\t    \n\t    $\\vy.\\hvalue  \\leftarrow 0$;\n\t    \n\t    \n\n\t    \n\t    \n\t\t\n\t    \n\t    \n\t\t$\\vy.\\py \\leftarrow \\varnothing$;\n\t    $\\vy.\\psigma \\leftarrow \\varnothing$;\n\t            \n\t    \n        \n\n    \t\n    \t\n\t    \n    \t\n    \t\n    \t\\Return{$\\vy$};\n    }\n\n    \\SetFuncSty{textbf}\n    \n    \n    \\fInitOutputEdge{$\\vVYFrom,\\vVYTo,\\ralg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\ey.\\tailalg \\leftarrow \\vVYFrom$;\n\t    \n\t    $\\ey.\\headalg \\leftarrow \\vVYTo$;\n\t    \t\n\t    $\\ey.\\ralg \\leftarrow \\ralg$;\n\t            \n    \t\\Return{$\\ey$};\n    }\n    \n    \\SetFuncSty{textbf}\n    \\fInitTrajectoryNode{$\\sigmaalg,\\ey, \\Ey$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vsigma.\\sigmaalg \\leftarrow \\sigmaalg$;\n\t    \n\t    $\\vsigma.\\ey \\leftarrow \\ey$;\n\t    \n\t    $\\vsigma.\\outgoingalg \\leftarrow \\Ey$;\n\t    \n\t    \n\t    \n\t    \n\n\t            \n\t    \n        \n\n    \t\n    \t\n\t    \n    \t\n    \t\n    \t\\Return{$\\vsigma$};\n    }\n    \n    \\vspace*{-4mm}\n    \\SetFuncSty{textbf}\n    \\fInitTrajectoryEdge{$\\vVSigmaFrom,\\vVSigmaTo, \\sigmaalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\esigma.\\tailalg \\leftarrow \\vVSigmaFrom$;\n\t    \n\t    $\\esigma.\\headalg \\leftarrow \\vVSigmaTo$;\n\t    \n\t    $\\esigma.\\sigmaalg \\leftarrow \\sigmaalg$;\n\t    \n       \t\\Return{$\\esigma$};\n    }\n        \n    \\SetFuncSty{textbf}\n    \\fInitStateNode{$\\xalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vx.\\xalg \\leftarrow \\xalg$;\n       \t\n       \t\\Return{$\\vx$};\n    }\n    \n    \\SetFuncSty{textbf}\n    \\fInitStateEdge{$\\vVXFrom,\\vVXTo,\\sigmaalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vEX.\\tailalg \\leftarrow \\vVXFrom$;\n    \n\t    $\\vEX.\\headalg \\leftarrow \\vVXTo$;\n\t    \n\t    $\\vEX.\\sigmaalg \\leftarrow \\sigmaalg$;\n          \t\n        \\Return{$\\vEX$};\n    }\n    \n\t\\end{multicols*}\n\t\\vspace*{2mm}\n\\caption{{\\small Node and Edge Constructor Procedures}{\\color{white}$^\\#$}} \\label{alg:constructor_procedures_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.5em} \n\n\n\\vspace*{-5pt}\n}\n\n\\subsection{Properties of the Algorithm}\n\nThe {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm provides both dynamic feasibility guarantees, that is, the lowest-cost reference trajectory computed by the algorithm can be tracked by the low-level controller, and asymptotic optimality guarantees, that is, the lowest-cost reference trajectory computed by the algorithm converges to the optimal reference trajectory almost surely. The former property is an immediate result of using closed-loop prediction during the search phase. During the extension of the graph ${\\mathcal{G}_{y}}$, if some segments of a reference trajectory can not be tracked, that is, is not dynamically feasible, the corresponding state trajectory is not stored in the graph ${\\mathcal{G}_{\\sigma}}$ constructed by the algorithm. The former property is due to the asymptotic optimality property of the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithm~\\cite{arslan2013useofrelaxation}. The proposed algorithm incrementally grows a graph ${\\mathcal{G}_{y}}$ in the output space in a similar fashion as the {\\ensuremath{{\\mathrm{RRG}}}}{} algorithm does~\\cite{karaman2010optimal}. Therefore, the lowest-cost path encoded in ${\\mathcal{G}_{y}}$ converges to the optimal output trajectory in the output space almost surely. In addition, the lowest-cost output trajectory encoded in the graph ${\\mathcal{G}_{y}}$ is extracted at the end of each iteration in a similar fashion as the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithm does. Given the cost function that associates each edge in ${\\mathcal{G}_{y}}$ with a non-negative cost values being \\textit{monotonic} and \\textit{bounded}, the proposed algorithm is asymptotically optimal.\n\n\n\n\n\\section{Numerical Study}\\label{section:numerical_simulations}\nThe proposed algorithm is evaluated on two scenarios where a nonholonomic, wheeled vehicle, modeled as a unicycle, travels along a track. The motion equations are\n\n", "itemtype": "equation", "pos": 12275, "prevtext": "\n\n\\item avoids the obstacles, i.e., $x(t) \\in {X_{\\mathrm{free}}}$ for all $t \\in [0,T]$,\n\\item reaches the goal region, i.e., $x(T) \\in {X_{\\mathrm{goal}}}$,\n\\item and minimizes ${}J(x,u,r) = \\int_{0}^{T} g(x(t),u(t), r(t))\\, \\mathrm{d}t$\n\\end{itemize}\n\n\n\n\n\n\n\\subsection{Primitive Procedures}\n\nFollowing are the definitions of the primitive procedures used by the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm (for details, see~\\cite{KaramanFra2011}).\n\n\n\\textit{Sampling:} ${\\mathtt{Sample}} : \\omega \\mapsto  \\left\\{ {\\mathtt{Sample}}_{i}(\\omega) \\right\\}_{i \\in {\\mathbb{N}}_{0}} \\subset {Y_\\mathrm{free}}$ returns independent and identically distributed (i.i.d.) samples ${\\mathtt{Sample}}_{i}, \\, i \\in {\\mathbb{N}}_{0\t}$ from ${Y_\\mathrm{free}}$. \n\n\\textit{Nearest Neighbor:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}}, {E_{y}})$, where ${V_{y}} \\in {Y}$, a point ${y} \\in {Y}$, the function ${\\mathtt{Nearest}}: ({\\mathcal{G}_{y}}, {y}) \\mapsto {v_{y}} \\in {V_{y}}$ returns the node in ${V_{y}}$ that is ``closest'' to ${y}$ in terms of a given distance function. We use the  Euclidean distance. \n\n\\textit{Near Neighbors:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}}, {E_{y}})$, where ${V_{y}} \\in {Y}$, a point ${y} \\in {Y}$, and a positive real number $d \\in {\\mathbb{R}}_{>0}$, the function ${\\mathtt{Nearest}}: ({\\mathcal{G}_{y}}, {y}, d) \\mapsto {v_{y}} \\in {V_{y}}^{\\prime} \\subset {V_{y}}$ returns the nodes in ${V_{y}}$ that are contained in a ball of radius $d$ centered at ${y}$. \n\n\n\n\n\n\\textit{Steering:} Given two points ${y_{\\mathrm{from}}}, {y_{\\mathrm{to}}} \\in {Y}$, the function ${\\mathtt{Steer}}: ({y_{\\mathrm{from}}}, {y_{\\mathrm{to}}}) \\mapsto {y^{\\prime}}$ returns a point ${y^{\\prime}} \\in {Y}$ such that ${y^{\\prime}}$ is ``closer'' to ${y_{\\mathrm{to}}}$ than ${y_{\\mathrm{from}}}$ is. In this work, the point ${y^{\\prime}}$ returned by the function ${\\mathtt{Steer}}$ will be such that ${y^{\\prime}}$ minimizes $\\|{y^{\\prime}} - {y_{\\mathrm{to}}}\\|$ while at the same time maintaining $\\|{y^{\\prime}} - {y_{\\mathrm{from}}}\\| \\leq \\eta$, for a predefined $\\eta > 0$. \n\n\n\n\n\\textit{Closed-loop Prediction:} Given a state ${x} \\in {X_{\\mathrm{free}}}$, and an output trajectory ${\\sigma_{y}} \\in {\\mathcal{Y}}$, the function $\\fPropagate : ({x},{\\sigma_{y}}) \\mapsto {\\sigma_{x}} \\in {\\mathcal{X}}$ returns the state trajectory that is computed by simulating the system dynamics forward in time with the initial state ${x}$, and the reference trajectory ${\\sigma_{y}}$.\n\n\\textit{Collision Test:} Given two points ${y_{\\mathrm{from}}}, {y_{\\mathrm{to}}} \\in {\\mathcal{G}_{y}}$, the Boolean function ${\\mathtt{ObstacleFree}}({y_{\\mathrm{from}}}, {y_{\\mathrm{to}}})$ returns ${\\tt True}$ if the line segment between ${y_{\\mathrm{from}}}$ and ${y_{\\mathrm{to}}}$ lies in ${Y_\\mathrm{free}}$ \nand ${\\tt False}$ otherwise.\n\n\n\\textit{Cost-to-come Values:} Given a graph ${\\mathcal{G}_{y}} = ({V_{y}},{E_{y}})$, let ${\\mathtt{g^{*}}}$ denote the optimal cost-to-come value of the node ${v_{y}} \\in {V_{y}}$ that can be achieved in ${\\mathcal{G}_{y}}$. Each node ${v_{y}} \\in {V_{y}}$ is associated with two estimates of the optimal cost-to-come value~(see~\\cite{arslan2013useofrelaxation,koenig2004lifelongplanning}). The $g$-value of ${v_{y}}$ is the cost of the path to ${v_{y}}$ from a given initial state ${y_{\\mathrm{init}}} \\in {Y_\\mathrm{free}}$. The one step look-ahead $g$-value of ${v_{y}}$ is denoted with ${\\mathtt{\\bar{g}}}$ and defined as \n\n", "index": 5, "text": "$$\n {v_{y}}.{\\mathtt{\\bar{g}}} = \n  \\begin{cases} \n      0,   & \\text{if~}{v_{y}}.{y} = {y_{\\mathrm{init}}}, \\\\\n\t\\min\\limits_{{e_{y}} \\in {E_{y,\\mathrm{pred}}}} \\left( {v_{y,\\mathrm{pred}}}.{\\mathtt{g}} + \\fCostValue({\\sigma})\\right), & \\text{otherwise}, \\\\\n  \\end{cases}\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"{v_{y}}.{\\mathtt{\\bar{g}}}=\\begin{cases}0,&amp;\\text{if~{}}{v_{y}}.{y}={y_{\\mathrm%&#10;{init}}},\\\\&#10;\\min\\limits_{{e_{y}}\\in{E_{y,\\mathrm{pred}}}}\\left({v_{y,\\mathrm{pred}}}.{%&#10;\\mathtt{g}}+\\fCostValue({\\sigma})\\right),&amp;\\text{otherwise},\\\\&#10;\\end{cases}\" display=\"block\"><mrow><msub><mi>v</mi><mi>y</mi></msub><mo>.</mo><mrow><mover accent=\"true\"><mi>\ud835\ude90</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><msub><mi>v</mi><mi>y</mi></msub></mrow><mo>.</mo><mrow><mi>y</mi><mo>=</mo><msub><mi>y</mi><mi>init</mi></msub></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><munder><mi>min</mi><mrow><msub><mi>e</mi><mi>y</mi></msub><mo>\u2208</mo><msub><mi>E</mi><mrow><mi>y</mi><mo>,</mo><mi>pred</mi></mrow></msub></mrow></munder><mrow><mo>(</mo><msub><mi>v</mi><mrow><mi>y</mi><mo>,</mo><mi>pred</mi></mrow></msub><mo>.</mo><mi>\ud835\ude90</mi><mo>+</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\fCostValue</mtext></merror><mrow><mo stretchy=\"false\">(</mo><mi>\u03c3</mi><mo stretchy=\"false\">)</mo></mrow><mo>)</mo></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mtext>otherwise</mtext><mo>,</mo></mrow></mtd></mtr></mtable></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06326.tex", "nexttext": "\nwhere $x_{1}$, $x_{2}$ are the Cartesian coordinates  of the vehicle, $x_{3}$ is the  heading angle, $x_{4}$ is the translational velocity , and $u_{1}$, $u_{2}$ are the controls for the angular and translational velocity. Each control input takes values in an interval, that is, $u_{i} \\in [u^{l}_{i}, u^{u}_{i}]$. A pure-pursuit controller  tracks a given reference path~\\cite{Amidi1990229}. The heading command is generated by following a look-ahead point on a given reference path. The speed command is given as a desired  speed $v_{\\mathrm{crs}}$, which  is tracked by a proportional controller.\n\nFirst, the objective is point-to-point navigation in the counter-clockwise direction on a race track, while minimizing the Euclidean path length. The track size is (100m$\\times$100m) and the origin is located at its center.  {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}  executed for 1,500 iterations. Fig.~\\ref{figure:sim_pt1} shows the resulting tree at different stages. Initially, the vehicle is at $(-25,-45)$, with zero heading angle and  zero speed (yellow square at bottom-left). The task is to move to  $(48,33)$ (red square at top-right). As seen in Figs.~\\ref{figure:sim_pt1}\\subref{figure:pt1_reference_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_reference_closed_loop_rrtsharp_it01500}, the algorithm incrementally grows a graph in the output space $(x_{1},x_{2})$. Each path in the graph corresponds to a  reference path, used as an input to the closed-loop system.  {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}  quickly computes a long reference path. Then, it seeks alternative paths of the graph as more information is explored and improves the existing solution if closed-loop simulation of a new reference path yields lower cost. The nodes and edges of the graph correspond to waypoints and straight line segments. The lowest-cost path is shown in yellow. The value is 127.2. Figs.~\\ref{figure:sim_pt1}\\subref{figure:pt1_state_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_state_closed_loop_rrtsharp_it01500} shows the  state trajectories, computed during closed-loop simulation in {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}. \n\n\n\n\\begin{figure*}\n\\centering\n\t\\mbox{\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_reference_00050.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00050}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_reference_00100.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00100}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_reference_00500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00500}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_reference_01500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it01500}}\n }\n\n\t\\mbox{\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_trajectory_00050.pdf}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00050}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_trajectory_00100.pdf}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00100}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_trajectory_00500.pdf}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00500}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt1_fig_trajectory_01500.png}} \\label{figure:pt1_state_closed_loop_rrtsharp_it01500}}\n    }\n\n    \\caption{The evolution of the solution trees for reference paths and state trajectories computed by {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} are shown in  \\subref{figure:pt1_reference_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_reference_closed_loop_rrtsharp_it01500} and \\subref{figure:pt1_state_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_state_closed_loop_rrtsharp_it01500}, respectively. The trees \\subref{figure:pt1_reference_closed_loop_rrtsharp_it00050}, \\subref{figure:pt1_state_closed_loop_rrtsharp_it00050} are at 50 iterations, \\subref{figure:pt1_reference_closed_loop_rrtsharp_it00100}, \\subref{figure:pt1_state_closed_loop_rrtsharp_it00100} are at 100 iterations, \\subref{figure:pt1_reference_closed_loop_rrtsharp_it00500}, \\subref{figure:pt1_state_closed_loop_rrtsharp_it00500} are at 500 iterations,\n     and \\subref{figure:pt1_reference_closed_loop_rrtsharp_it01500}, \\subref{figure:pt1_state_closed_loop_rrtsharp_it01500} are at 1500 iterations.\n}\n     \\label{figure:sim_pt1}\n     \n\\end{figure*}\n\n\n\nIn the second scenario, the goal is to recursively navigate the vehicle on the race track. The vehicle is tasked to navigate sequentially to a set of waypoints, presumably coming from a high-level navigator. In each stage, the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}} algorithm was executed for 1,500 iterations to find a motion plan from the current state of the vehicle to a desired next waypoint. Each next waypoint is sent to the motion planner as the vehicle gets close to the current waypoint, similar to \\cite{kuwata2008motion}. In this simulation, the vehicle is tasked to navigate four waypoints sequentially. The solution trees of reference paths and corresponding state trajectories for each step are shown in Fig.~\\ref{figure:sim_pt2}. As seen during simulations, leveraging the dynamics information of the vehicle during the search phase allows to construct dynamically feasible paths and avoid shortest paths that pass close to the boundary of the track. \n\n\n\n\n\\begin{figure*}\n\\centering\n\t\\mbox{\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part1_fig_reference_01500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00050}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part2_fig_reference_01500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00100}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part3_fig_reference_01500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it00500}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part4_fig_reference_01500.pdf}} \\label{figure:pt1_reference_closed_loop_rrtsharp_it01500}}\n }\n\n\t\\mbox{\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part1_fig_trajectory_01500.png}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00050}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part2_fig_trajectory_01500.png}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00100}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part3_fig_trajectory_01500.png}} \\label{figure:pt1_state_closed_loop_rrtsharp_it00500}}\n    \\subfigure[]{\\scalebox{0.3}{\\includegraphics[trim = 4.0cm 6.937cm 3.587cm 7.0cm, clip =\n          true]{pt2_part4_fig_trajectory_01500.png}} \\label{figure:pt1_state_closed_loop_rrtsharp_it01500}}\n    }\n\n    \\caption{Results from a simulation where the vehicle navigates four consecutive waypoints, given by a high-level navigator. The evolution of the trees for reference paths and state trajectories computed by {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} are shown in  \\subref{figure:pt1_reference_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_reference_closed_loop_rrtsharp_it01500} and \\subref{figure:pt1_state_closed_loop_rrtsharp_it00050}-\\subref{figure:pt1_state_closed_loop_rrtsharp_it01500}, respectively. In each stage, 1,500 iterations are made. As the vehicle gets close to the current waypoint, the next waypoint is sent to the motion planner, similar to \\cite{kuwata2008motion}.}\n     \\label{figure:sim_pt2}\n\\end{figure*}\n\n\n\n\n\n\\section{Conclusion}\\label{section:conclusion}\n\nWe presented  a new asymptotically optimal motion-planning algorithm, called {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{}, using closed-loop prediction for trajectory generation. The approach is a hybrid of the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}}}}{} and the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithms. It incrementally grows a graph of reference trajectories, used as inputs to a low-level tracking controller, and chooses the one that yields the lowest-cost state trajectory of the closed-loop system. {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} provides dynamic feasibility by construction and ensures asymptotic optimality, that is, it finds the optimal reference trajectory given controller. Simulation results on a nonholonomic system showed the efficacy of the approach. \n\n\n\n\n\\bibliography{arxiv}\n\\bibliographystyle{plain}\n\n\n\n\n\n", "itemtype": "equation", "pos": 64377, "prevtext": "\nwhere ${E_{y,\\mathrm{pred}}} = {\\mathtt{incoming}}({\\mathcal{G}_{y}},{v_{y}})$, ${v_{y,\\mathrm{pred}}} = {e_{y}}.{\\mathtt{tail}}$, and ${\\sigma}$ is the state trajectory that is computed via closed-loop prediction, i.e., the dynamical system is simulated forward in time with the initial state ${v_{y,\\mathrm{pred}}}.{\\mathtt{p}_{\\sigma}}.\\fBack()$ and the reference trajectory ${e_{y}}.{\\sigma}$. \n\n\\textit{Heuristic Value:} Given a node ${v_{y}} \\in {V_{y}}$, and an output goal region ${Y_{\\mathrm{goal}}}$, the function $\\fComputeHeuristic : ({v_{y}},{Y_{\\mathrm{goal}}}) \\mapsto r$ returns an estimate $r$ of the optimal cost from ${v_{y}}$ to ${Y_{\\mathrm{goal}}}$; it return zero if ${v_{y}} \\in {Y_{\\mathrm{goal}}}$. \n In this paper, we always assume that $\\fComputeHeuristic $ computes an admissible heuristic, that is, it never overestimates the actual cost of reaching ${Y_{\\mathrm{goal}}}$. \n\n\\textit{Queue Operations:} Nodes of the computed graphs are associated with some keys and priority queues are used to sort these nodes based on the precedence relation between keys. The following functions are implemented to maintain a given priority queue ${\\mathcal{Q}}$:\n\n\\begin{itemize}\n\\item ${\\mathcal{Q}}.{\\mathtt{top\\_key}}()$ returns the highest priority of all nodes in the priority queue ${\\mathcal{Q}}$ with the smallest key value if the queue is not empty. If ${\\mathcal{Q}}$ is empty, then ${\\mathcal{Q}}.{\\mathtt{top\\_key}}()$ returns a key value of $k = [\\infty; \\infty]$.\n\n\n\n\\item ${\\mathcal{Q}}.{\\mathtt{pop}}()$ deletes the node with the highest priority in the priority queue ${\\mathcal{Q}}$ and returns a reference to the node.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{update}}({v_{y}}, k)$ sets the key value of the node ${v_{y}}$ to $k$ and reorders the priority queue ${\\mathcal{Q}}$.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{insert}}({v_{y}}, k)$ inserts the node ${v_{y}}$ into the priority queue ${\\mathcal{Q}}$ with the key value $k$.\n\n\\item ${\\mathcal{Q}}.{\\mathtt{remove}}({v_{y}})$ removes the node ${v_{y}}$ from the priority queue ${\\mathcal{Q}}$.\n\\end{itemize} \n\n\n\\textit{Initialization:} Given an initial point ${x_{\\mathrm{init}}} \\in {X}$, a goal region in the output space ${Y_{\\mathrm{goal}}} \\subset {Y}$, the function ${\\mathtt{Initialize}}: ({x_{\\mathrm{init}}}, {Y_{\\mathrm{goal}}}) \\mapsto ({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$ returns a graph ${\\mathcal{G}_{y}}$ that has only node ${v_{y}}$, whose output point is ${v_{y}}.{y} = {\\mathtt{OutputMap}}({x_{\\mathrm{init}}})$, a graph ${\\mathcal{G}_{\\sigma}}$ that has the only node ${v_{\\sigma}}$, whose trajectory is a single point ${v_{\\sigma}}.{\\sigma} = {x_{\\mathrm{init}}}$, and empty priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ that are used for ordering of nongoal and goal nodes, which represent points in ${Y}$, respectively.  \n\n\n\\textit{Exploration:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$, where ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are graphs whose nodes represent points in ${Y}$ and trajectories in ${\\mathcal{X}}$, respectively, and ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are priority queues that are used for ordering of nongoal and goal nodes that represent points in ${Y}$, a goal region in the output space ${Y_{\\mathrm{goal}}} \\subset {Y}$, and a point ${y} \\in {Y}$, the function ${\\mathtt{Extend}} : ({\\mathcal{S}}, {Y_{\\mathrm{goal}}}, {y}) \\mapsto  {\\mathcal{S}}^{\\prime} = ({\\mathcal{G}_{y}}^{\\prime},{\\mathcal{G}_{\\sigma}}^{\\prime},{\\mathcal{Q}}^{\\prime}, {\\mathcal{Q}_{\\mathrm{goal}}}^{\\prime})$ includes a new node, multiple edges to ${\\mathcal{G}_{y}}$ and multiple nodes, edges to ${\\mathcal{G}_{\\sigma}}$, updates the priorities of nodes in ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ and returns an updated tuple ${\\mathcal{S}}^{\\prime}$.\n\n\n\\textit{Exploitation:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$, where ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are graphs whose nodes represent points in ${Y}$ and trajectories in ${\\mathcal{X}}$, respectively, and ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are priority queues that are used for ordering of nongoal and goal nodes that represent points in ${Y}$, the function ${\\mathtt{Replan}} : {\\mathcal{S}} \\mapsto  {\\mathcal{S}}^{\\prime} = ({\\mathcal{G}_{y}}^{\\prime},{\\mathcal{G}_{\\sigma}}^{\\prime},{\\mathcal{Q}}^{\\prime}, {\\mathcal{Q}_{\\mathrm{goal}}}^{\\prime})$ rewires the parent node of the nodes in ${\\mathcal{G}_{y}}$ based on their cost-to-come values, includes new nodes and edges in ${\\mathcal{G}_{\\sigma}}$ if necessary, that is, propagating dynamics of the system for new sequence of reference trajectories, and returns an updated tuple ${\\mathcal{S}}^{\\prime}$.\n\n\\textit{Construction of Solution:} Given a tuple of data structures ${\\mathcal{S}} =({\\mathcal{G}_{y}},{\\mathcal{G}_{\\sigma}},{\\mathcal{Q}}, {\\mathcal{Q}_{\\mathrm{goal}}})$,\nthe function ${\\mathtt{ConstrSolution}} : {\\mathcal{S}} \\mapsto {\\mathcal{T}_{x}}$ returns a tree whose edges and nodes represent simulated trajectories in ${\\mathcal{X}}$ and the corresponding internal states of the nodes of ${\\mathcal{G}_{y}}$. These trajectories are computed by propagating the dynamics with reference trajectories that are encoded in a tree of ${\\mathcal{G}_{y}}$, which is formed by the edges between nodes of ${\\mathcal{G}_{y}}$ and their parent nodes.\n\n\\textit{Graph and List Operations:} The following functions are used in the ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$ algorithm.\n\n\\begin{itemize}\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{succ}} : ({\\mathcal{{G}}}, v) \\mapsto V^{\\prime} \\subseteq V$ returns the nodes in $V$ that are the heads of the edges emanating from $v$, that is, $\n{\\mathtt{succ}}({\\mathcal{{G}}}, v) :=  \\left\\{ v^{\\prime} \\in V: e.{\\mathtt{tail}} = v \\text{~and~} e.{\\mathtt{head}} = v^{\\prime}, \\, e \\in E \\right\\}.$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{pred}} : ({\\mathcal{{G}}}, v) \\mapsto V^{\\prime} \\subseteq V$ returns the nodes in $V$ that are the tails of the edges going into $v$, that is, $\n{\\mathtt{pred}}({\\mathcal{{G}}}, v) := \\left\\{ v^{\\prime} \\in V: e.{\\mathtt{tail}} = v^{\\prime} \\text{~and~} e.{\\mathtt{head}} = v, \\, e \\in E \\right\\}.\n$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{outgoing}} : ({\\mathcal{{G}}}, v) \\mapsto E^{\\prime} \\subseteq E$ returns the edges in $E$ whose tail is $v$, that is, ${\\mathtt{outgoing}}({\\mathcal{{G}}}, v) := \\left\\{ e \\in E: e.{\\mathtt{tail}} = v \\right\\}.$\n\n\\item Given a node $v \\in V$ in a directed graph ${\\mathcal{{G}}}=(V,E)$, the set-valued function ${\\mathtt{incoming}} : ({\\mathcal{{G}}}, v) \\mapsto E^{\\prime} \\subseteq E$ returns the edges in $E$ whose head is $v$, that is, ${\\mathtt{incoming}}({\\mathcal{{G}}}, v) := \\left\\{ e \\in E: e.{\\mathtt{head}} = v \\right\\}.$\n\\end{itemize}\n\n\n\n\n\\begin{itemize}\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, and a point ${z} \\in {Z}$, the function $\\fFind : ({V_{z}},{z}) \\mapsto {v_{z}} \\in {V_{z}}$ returns the node in ${V_{z}}$ that satisfies ${v_{z}}.{z} = {z}$ if there exists any such node, null  otherwise. \n\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, the function $\\fBack$ returns a reference to the last node in the list if it is not empty, and null  otherwise.\n\n\\item Given a list of nodes ${V_{z}}$, where its nodes represent points in ${Z}$, the function $\\fFront$ returns a reference to the first node in the list if it is not empty, and null  otherwise.\n\\end{itemize}\n\n\n\n\n\n\\section{The {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}} Algorithm}\\label{section:closed_loop_rrtsharp_algorithm}\n\n\\subsection{Details of Data Structures}\nEach node ${v_{y}}$ in the graph ${\\mathcal{G}_{y}}$ is an $\\fInitOutputNode$ data structure, summarized in Table~\\ref{table:reference_node_edge_structure}. Each node ${v_{y}}$ is associated with a reference point $y \\in {\\mathbb{R}}^{m}$. It contains two estimates of the optimal cost-to-come value between the initial reference point and $y$, namely, cost-to-come value ${\\mathtt{g}}$ and one step look-ahead $g$-value ${\\mathtt{\\bar{g}}}$. It also keeps a heuristic value ${\\mathtt{h}}$, which is an underestimate of the optimal cost value between $y$ and ${Y_{\\mathrm{goal}}}$, to guide and reduce the search effort. Whenever ${\\mathtt{\\bar{g}}}$ is updated during the replanning procedure, the reference node that yields the corresponding minimum cost-to-come value is stored in the parent reference node ${\\mathtt{p}_{y}}$. Lastly, ${\\mathtt{p}_{\\sigma}}$ is the trajectory that is computed  by closed-loop prediction when the system is simulated with the reference trajectory between the nodes ${\\mathtt{p}_{y}}$ and ${v_{y}}$. Its terminal state represents the internal state associated with ${v_{y}}$.\n\n\\begin{table}\n\\centering\n\\caption{{\\small The node (${\\mathtt{OutNode}}$) and edge (${\\mathtt{OutEdge}}$) data structures for points and trajectories in output space, respectively}}\\label{table:reference_node_edge_structure}\n\n\\begin{tabular}{c|l|p{5.1cm}}\n{\\bf field}    & {\\bf type}\t& {\\bf description}       \\\\ \n\\hline\n\\hline\n$y$\t&   vector $\\in \\mathbb{R}^{p}$     & output point associated with this node \\\\\n${\\mathtt{g}}$    &  real  $\\in \\mathbb{R}$        & cost-to-come value              \\\\\n${\\mathtt{\\bar{g}}}$    & real    $\\in \\mathbb{R}$       & one step look-ahead $g$-value         \\\\\n${\\mathtt{h}}$    &   real $\\in \\mathbb{R}$        & heuristic value for the cost between $y$ and $\\mathcal{Y}_{\\mathrm{goal}}$ \\\\\n\n${\\mathtt{p}_{y}}$    & $\\fInitOutputNode$ & reference to the parent output node        \\\\\n${\\mathtt{p}_{\\sigma}}$     & $\\fInitTrajectoryNode$   & reference to the parent trajectory node       \\\\\n\n\n\n\\hline\n${r}$          &   trajectory $\\in {\\mathcal{Y}}$        \t& output trajectory associated with this edge                       \\\\\n${\\mathtt{tail}}$          &    $\\fInitOutputNode$      \t& reference to the tail output node         \\\\\n${\\mathtt{head}}$          &  $\\fInitOutputNode$          & reference to the head output node    \\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\nEach edge ${e_{y}}$ in the graph ${\\mathcal{G}_{y}}$ is an $\\fInitOutputEdge$ data structure, summarized in Table~\\ref{table:reference_node_edge_structure}. Each edge ${e_{y}}$ is associated with a trajectory  $r \\in {\\mathcal{Y}}$. It also contains two output nodes, namely, ${\\mathtt{tail}}$ and ${\\mathtt{head}}$, which represent the tail and the head output nodes of ${e_{y}}$, respectively.\n\n\nEach node ${v_{\\sigma}}$ in the graph ${\\mathcal{G}_{\\sigma}}$ is a $\\fInitTrajectoryNode$ data structure, summarized in Table~\\ref{table:trajectory_node_edge_structure}. Each node ${v_{\\sigma}}$ is associated with a trajectory $\\sigma \\in {\\mathcal{X}}$. It contains an output edge ${e_{y}}$, which corresponds to the reference trajectory that yields $\\sigma$ as the closed-loop prediction. It also keeps a list of outgoing output edges ${\\mathtt{outgoing}}$, and this list is used to compute outgoing trajectory nodes emanating from the terminal state of $\\sigma$. \n\n\n\\begin{table}\n\\centering\n\\caption{{\\small The node (${\\mathtt{TrajNode}}$) and edge (${\\mathtt{TrajEdge}}$) data structures for trajectories in state space} }\\label{table:trajectory_node_edge_structure}\n\n\\begin{tabular}{c|l|p{0.53\\columnwidth}}\n{\\bf field} & {\\bf type} & {\\bf description}       \\\\ \n\\hline\n\\hline\n$\\sigma$          &    trajectory $\\in {\\mathcal{X}}$     \t& state trajectory associated with this node    \\\\\n\n\n$e_{y}$           &   $\\fInitOutputEdge$         & reference to the output edge \n\\\\\n\n\n${\\mathtt{outgoing}}$\t\t   &   $\\fInitOutputEdge$ array        & list of outgoing output edges   \\\\\n\\hline\n$\\sigma$          &    trajectory $\\in {\\mathcal{X}}$     \t& state trajectory associated with this edge                      \\\\\n${\\mathtt{tail}}$          &    $\\fInitTrajectoryNode$     \t&  reference to the tail trajectory node          \\\\\n${\\mathtt{head}}$           &   $\\fInitTrajectoryNode$        & reference to the head trajectory node     \\\\ \n\\hline          \n\\end{tabular}\n\n\\end{table}\n\nEach edge ${e_{\\sigma}}$ in the graph ${\\mathcal{G}_{\\sigma}}$ is a $\\fInitTrajectoryEdge$ data structure, summarized in Table~\\ref{table:trajectory_node_edge_structure}. Each edge ${e_{\\sigma}}$ is associated with a trajectory  $\\sigma \\in {\\mathcal{X}}$. It contains two trajectory nodes, namely, ${\\mathtt{tail}}$ and ${\\mathtt{head}}$ which represent the tail and the head trajectory nodes of ${e_{\\sigma}}$, respectively.   \n\n\n\n\\subsection{Details of the Procedures}\n\nAlgorithm~\\ref{alg:body_closed_loop_rrtsharp} gives the body of the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm. First, the algorithm initializes the tuple of data structures ${\\mathcal{S}}$ that is incrementally grown and updated as exploration and exploitation are performed (Line 3). The tuple ${\\mathcal{S}}$ contains the graphs ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$, which are used to store output nodes and state trajectory nodes, respectively, and the priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$. The details of  ${\\mathtt{Initialize}}$  are given in Algorithm~\\ref{alg:initialize_closed_loop_rrtsharp}.\nThe graph ${\\mathcal{G}_{\\sigma}}$ is created with no edges and ${v_{\\sigma}}$ as its only node. This node represents a state trajectory that contains only the initial state ${x_{\\mathrm{init}}}$. Then, likewise, the graph ${\\mathcal{G}_{y}}$ is initialized with no edges and ${v_{y}}$ as its only node that represents ${y_{\\mathrm{init}}}$. The $g$- and $\\bar{g}$-values of ${v_{y}}$ are set with zero cost value.\nThe parent trajectory node of ${v_{y}}$ is set with the reference to the node ${v_{\\sigma}}$.\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \\SetKwData{vCVR}{$V_{r}$}\n    \n    \n    \n    \\SetKwData{vEPrime}{$E^{\\prime}$}\n    \\SetKwData{xinit}{$x_{\\mathrm{init}}$}\n    \\SetKwData{vI}{$k$}\n    \\SetKwData{xRand}{$x_{\\mathrm{rand}}$}\n    \\SetKwData{yrand}{$y_{\\mathrm{rand}}$}\n    \\SetKwData{vRRand}{$r_{\\mathrm{rand}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n   \n    \n    \\SetKwData{XGoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{YGoal}{$Y_{\\mathrm{goal}}$}\n   \n    \\SetKwData{x}{$x$}\n    \n    \n\n    \n    \\SetKwData{X}{$X$}\n    \n    \\SetKwData{xParent}{$x_{\\mathrm{parent}}$}\n    \n    \\SetKwData{vCEX}{$E_{x}$}\n\t\\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n        \n    \n    \\SetKwData{vxParent}{$v_{x,\\mathrm{parent}}$}\n    \n    \n    \n\n\n\n\n\n\n\n\n\t\n\t\n\t\n\t\\SetKwData{cS}{$\\mathcal{S}$}\n\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fRRTsharp{$\\xinit,\\XGoal,\\X$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\YGoal \\coloneqq \\fOutputMap{\\XGoal}$;\n\t    \n\t\t$\\cS \\leftarrow \\fInitialize{\\xinit,\\YGoal}$;\n\t\t\n        \\For{$\\vI = 1$ to $N$ \\label{line:rrtsharp_itbegin}}\n        {\n            $\\yrand \\leftarrow \\fSample{\\vI}$;\n\n            $\\cS \\leftarrow \\fExtend{\\cS,\\YGoal,\\yrand}$;\n\n\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({a0}) {};}$\\S \\leftarrow \\fReplan{\\cS}$;{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({a1}) {};}\\label{line:rrtsharp_itend}\n\t\t}\n\n\t\t${\\mathcal{T}_{x}} \\leftarrow \\fConstructSolution{\\cS}$;\n\t\t\n        \\Return{${\\mathcal{T}_{x}}$};\n    }\n    \n\\caption{{\\small The ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$ Algorithm}}\\label{alg:body_closed_loop_rrtsharp}\n\n\n\\end{algorithm}\n\\DecMargin{2em}\n\n\n\n\n\n\n\n}\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \n    \\SetKwData{vy}{$v_{y}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n        \n    \\SetKwData{Vsigma}{$V_{\\sigma}$}\n    \\SetKwData{Esigma}{$E_{\\sigma}$}    \n    \\SetKwData{vEPrime}{$E^{\\prime}$}\n    \\SetKwData{xinit}{$x_{\\mathrm{init}}$}\n    \\SetKwData{vI}{$k$}\n    \\SetKwData{vXRand}{$x_{\\mathrm{rand}}$}\n    \\SetKwData{yrand}{$y_{\\mathrm{rand}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vClXGoal}{$\\mathcal{X}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n\n  \n    \n    \n\n    \n   \n    \n    \\SetKwData{vXParent}{$x_{\\mathrm{parent}}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n    \\SetKwData{vCEX}{$E_{x}$}\n\t\\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n        \n    \n    \n    \n    \\SetKwData{vVX}{$v_{x}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n\n    \\SetKwData{Vsigma}{$v_{\\sigma}$}\n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n    \\SetKwData{vEX}{$e_{x}$}\n\n\t\n\t\\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n\t\\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n\t\\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{vRInit}{$r_{\\mathrm{init}}$}\n\t\\SetKwData{yinit}{$y_{\\mathrm{init}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\\SetKwData{Qc}{$\\mathcal{Q}$}\n\n\t\\SetKwData{ssigma}{$\\sigma$}\n\t\\SetKwData{vNull}{$\\varnothing$}\n\t\\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\t\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fInitialize{$\\xinit,\\Ygoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\sigma \\leftarrow \\{\\xinit\\}$;\n    \t\t\n    \t$\\Vsigma \\leftarrow \\fInitTrajectoryNode{\\ssigma,\\vNull,\\vNull}$;\n\t\t\t\t\t    \t  \n\t\t$\\yinit \\leftarrow \\fOutputMap{\\xinit}$;\n\t\t\n\t\t$\\vy \\leftarrow \\fInitOutputNode{\\yinit}$;\n\t\t\n\t\t$\\vy.\\gvalue \\leftarrow 0$;\n\t\t$\\vy.\\gbarvalue  \\leftarrow 0$;\n\t\t\n\t\t$\\vy.\\hvalue  \\leftarrow \\fComputeHeuristic{\\yinit,\\Ygoal}$;\n\t\t\n\t\t$\\vy.\\psigma \\leftarrow \\Vsigma$;\n\t\t\n\t\t$\\Vy \\leftarrow \\{\\vy\\}$;\n\t\t$\\Ey \\leftarrow \\varnothing$;\n\t\t\n\t\t$\\vCVSigma \\leftarrow \\{\\Vsigma\\}$;\n\t\t$\\vCESigma \\leftarrow \\varnothing$;\n\t\t\n\t\t$\\Gy \\leftarrow (\\Vy,\\Ey)$;\n\t\t$\\Gsigma \\leftarrow (\\vCVSigma,\\vCESigma)$;\n\t\t\t\t\n\t\t$\\Qc \\leftarrow \\varnothing$;\n\t\t$\\Qgoal \\leftarrow \\varnothing$;\n\t\t\n\t\t\\Return{$\\Sc \\leftarrow (\\Gy,\\Gsigma,\\Qc,\\Qgoal)$};\n\t}\n\t\n\\caption{{\\small The ${\\mathtt{Initialize}}$ Procedure}} \\label{alg:initialize_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em}\n\n\n\n\n\n\n}\n\n\nThe algorithm iteratively builds a graph of collision-free reference trajectories ${\\mathcal{G}_{y}}$ by first sampling an output point ${y_{\\mathrm{rand}}}$ from the obstacle-free output space ${Y_\\mathrm{free}}$ (Line 5) and then extending the graph towards this sample (Line 6), at each iteration. The cost of the unique trajectory from the root node to a given node ${v_{y}}$ is denoted as $\\fCostValue({v_{y}})$. It also builds another graph ${\\mathcal{G}_{\\sigma}}$, to store the state trajectories computed by simulation of the closed-loop dynamics when a reference trajectory is tracked. \nOnce a new node is added to ${\\mathcal{G}_{y}}$ after  ${\\mathtt{Extend}}$,  ${\\mathtt{Replan}}$ is called to improve the existing solution by propagating the new information (Line 7). The dynamic system is simulated for different reference trajectories as needed during the search process. The computed state trajectories are added to the graph ${\\mathcal{G}_{\\sigma}}$ as new nodes along with the corresponding controls information. \n\nFinally, when a predetermined maximum number of iterations is reached,  ${\\mathtt{ConstrSolution}}$ extracts the spanning tree of ${\\mathcal{G}_{y}}$ that contains the lowest-cost reference trajectories (Line 8). Algorithm~\\ref{alg:construct_solution_closed_loop_rrtsharp} gives the details of ${\\mathtt{ConstrSolution}}$.\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n\n\n    \n\t\n\t\n \t\n \t\n \t\\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \\SetKwData{vy}{$v_{y}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n \n \n\n\n    \\SetKwData{vI}{$k$}\n    \n    \n    \\SetKwData{vT}{$\\mathcal{T}$}\n  \n  \n   \n \n  \n    \n    \n\n    \n    \\SetKwData{vcapx}{$X$}\n    \n    \\SetKwData{vXParent}{$x_{\\mathrm{parent}}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n    \\SetKwData{vCEX}{$E_{x}$}\n    \n    \\SetKwData{vVXParent}{$v_{x,\\mathrm{parent}}$}\n  \n    \\SetKwData{vVX}{$v_{x}$}\n    \\SetKwData{vCVX}{$V_{x}$}\n\n\n \n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n    \\SetKwData{vEX}{$e_{x}$}\n\t\n\t\n\t\\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n\t\\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n\t\\SetKwData{vFrontier}{$\\mathcal{Q}$}\n\t\\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\n\t\n\t\\SetKwData{sigmav}{$\\sigma$}\n    \n\n\n    \n\n    \\SetFuncSty{textbf}\n    \n    \n    \\fConstructSolution{$\\Sc$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Sc$;\n\t    \n        $(\\Vy,\\Ey) \\leftarrow \\Gy$;\n\t\t$\\vcapx \\leftarrow \\varnothing$;\n\t\t\n        \\ForEach{$\\vy \\in \\Vy$}\n        {\n\n\t        $\\sigma \\leftarrow \\vy.\\psigma.\\sigmav$;\n\n\t        $\\vVX \\leftarrow \\fInitStateNode{\\sigmav.\\fBack{}}$;\n\t        \n\t        $\\vCVX \\leftarrow \\vCVX \\cup \\{\\vVX\\}$;\n\t        \n\t        $\\vVXParent \\leftarrow \\fFind{\\vCVX,\\sigmav.\\fFront{}}$;\n\t        \n\t        \\If{$\\vVXParent = \\varnothing$}\n  \t        {\n  \t\t        $\\vVXParent \\leftarrow \\fInitStateNode{\\sigmav.\\fFront{}}$;\n  \t\t        \n  \t\t        $\\vCVX \\leftarrow \\vCVX \\cup \\{\\vVXParent\\}$;\n  \t        }\n  \t        \n   \t        $\\vEX \\leftarrow \\fInitStateEdge{\\vVXParent, \\vVX, \\sigmav}$;\n   \t        \n            $\\vCEX \\leftarrow \\vCEX \\cup \\{\\vEX\\}$;\n              \n            $\\vcapx \\leftarrow \\vcapx \\cup \\{\\sigma.\\fBack{}\\}$;\t        \n\t        \t        \n        }\n\n        \\Return{$\\Tx = (\\vCVX,\\vCEX)$};\n    }\n\n\\caption{{\\small The ${\\mathtt{ConstrSolution}}$ Solution Procedure}}\n\\label{alg:construct_solution_closed_loop_rrtsharp}\n\\end{algorithm}\n\\DecMargin{0.7em}\n\n\n\n\n\n\n}\n\n\n\\subsubsection{The ${\\mathtt{Extend}}$ Procedure}\nThe ${\\mathtt{Extend}}$ procedure is given in Algorithm~\\ref{alg:extend_closed_loop_rrtsharp}. It first extends the nearest output node ${v_{y,\\mathrm{nearest}}}$ to the output sample ${y}$ (Lines 4-5). The output trajectory that extends the nearest output node ${v_{y,\\mathrm{nearest}}}$ towards the output sample ${y}$ is denoted as ${r_{\\mathrm{new}}}$. The final output point on the output trajectory ${r_{\\mathrm{new}}}$ is denoted as ${y_{\\mathrm{new}}}$. If ${r_{\\mathrm{new}}}$ is collision-free, then a new output node ${v_{y,\\mathrm{new}}}$ is created to represent the new output point ${y_{\\mathrm{new}}}$ (Line 8), and the following changes in the vicinity of ${v_{y,\\mathrm{new}}}$ on both graphs are shown in Fig.~\\ref{figure:cl_rrtsharp_extension}. The initial node is shown as a square box, the obstacles are shown in red color, and the graphs ${\\mathcal{G}_{y}}$ and ${\\mathcal{G}_{\\sigma}}$ are  shown in orange and green colors.\n\n\\begin{figure}\n\t\\centering\n\t\\includegraphics[scale=0.3]{fig_cl_rrtsharp_extension}\n\t\n\t\\caption{Extension of the graphs computed by the {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm. Trajectories in the output and state spaces are shown in orange and green colors, respectively. Whenever a new node in the output space is added, then several incoming and outgoing edges are included to the graph in the vicinity of the new node, i.e., region colored with cyan.}\\label{figure:cl_rrtsharp_extension}\n\t\\vspace*{-15pt}\n\\end{figure}\n{\n\t\\setlength{\\intextsep}{1pt}\n\t\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\t\n    \n    \\small\n    \n    \n\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n    \n\n    \n\n    \n    \n\n    \n\n    \n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{Tx}{$\\mathcal{T}_{x}$}\n    \\SetKwData{Ty}{$\\mathcal{T}_{y}$}\n    \\SetKwData{Gx}{$\\mathcal{G}_{x}$}\n    \n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n    \\SetKwData{xalg}{$x$}\n    \\SetKwData{xgoal}{$x_{\\mathrm{goal}}$}\n    \\SetKwData{vGRX}{$V_{x}$}\n    \\SetKwData{vEX}{$E_{x}$}\n    \\SetKwData{Vy}{$V_{y}$}\n    \\SetKwData{Ey}{$E_{y}$}\n    \n    \\SetKwData{vFrontier}{$\\mathcal{Q}$}\n    \\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n           \n    \n    \n    \\SetKwData{vESigmaPrime}{$E_{\\sigma}^{\\prime}$}    \n    \\SetKwData{vXNearest}{$x_{\\mathrm{nearest}}$}\n    \\SetKwData{vXNew}{$x_{\\mathrm{new}}$}\n    \\SetKwData{vCXNear}{$\\mathcal{X}_{\\mathrm{near}}$}\n    \\SetKwData{vXNear}{$x_{\\mathrm{near}}$}\n\t\\SetKwData{xpred}{$x_{\\mathrm{pred}}$}\n\n\t\n\t\\SetKwData{vSigmaNear}{$\\sigma_{\\mathrm{near}}$}\n\t\\SetKwData{ynew}{$y_{\\mathrm{new}}$}\n\t\\SetKwData{vYNewPrime}{$y^{\\prime}_{\\mathrm{new}}$}\n\t\t\n\t\\SetKwData{yalg}{$y$}\n\t\\SetKwData{vCYNear}{$\\mathcal{R}_{\\mathrm{near}}$}\n    \\SetKwData{vYNearest}{$r_{\\mathrm{nearest}}$}\n    \\SetKwData{vYNear}{$r_{\\mathrm{near}}$}\n    \\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n    \n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \n    \\SetKwData{vypred}{$v_{y,\\mathrm{pred}}$}\n    \\SetKwData{vCVPred2}{$V_{\\mathrm{pred}}$}\n    \\SetKwData{vCEPred}{$E_{y,\\mathrm{pred}}$}\n\n    \\SetKwData{vCVSucc}{$V_{\\mathrm{succ}}$}\n    \\SetKwData{vCESucc}{$E_{y,\\mathrm{succ}}$}\n        \n\t\\SetKwData{vV2}{$y$}\n\t\\SetKwData{vCVNear2}{$V_{\\mathrm{near}}$}\n\t\\SetKwData{vynearest}{$v_{y,\\mathrm{nearest}}$}\n\t\\SetKwData{vynew}{$v_{y,\\mathrm{new}}$}\n\t\\SetKwData{vynear}{$v_{y,\\mathrm{near}}$}\n    \\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\n\n   \n     \n    \n    \\SetKwData{ey}{$e_{y}$}\n    \\SetKwData{esigma}{$e_{\\sigma}$}\n    \n    \\SetKwData{vCVSigmaPrime}{$V^{\\prime}_{\\sigma}$}\n    \\SetKwData{vCESigmaPrime}{$E^{\\prime}_{\\sigma}$}\n    \n    \\SetKwData{vCVSigma}{$V_{\\sigma}$}\n    \\SetKwData{vCESigma}{$E_{\\sigma}$}\n    \n  \n    \\SetKwData{vsigmapred}{$v_{\\sigma,\\mathrm{pred}}$}\n    \\SetKwData{vsigmanear}{$v_{\\sigma,\\mathrm{near}}$}\n    \\SetKwData{vsigmanew}{$v_{\\sigma,\\mathrm{new}}$}\n    \\SetKwData{rnew}{$r_{\\mathrm{new}}$}\n    \n\t\n\t\\SetKwData{bargvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{pyref}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\\SetKwData{vCostValue}{$\\mathtt{c}$} \n\t\n\t\\SetKwData{tthead}{$\\mathtt{head}$}\n\t\n\t\\SetKwData{ralg}{$r$}\n\t\\SetKwData{gvalc}{$\\mathtt{g}$}\n\t\\SetKwData{hvalueext}{$\\mathtt{h}$}\n\t\\SetKwData{Scval}{$\\mathcal{S}$}\n\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n\n\n\n    \n\n    \\SetFuncSty{textbf}\n    \n    \\fExtend{$\\Scval,\\Xgoal,\\yalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t\t$(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Scval$;\n\t\t\n        $(\\Vy,\\Ey) \\leftarrow \\Gy$;\n        $(\\vCVSigma,\\vCESigma) \\leftarrow \\Gsigma$;\n        \n        $\\vynearest \\leftarrow \\fNearest{\\Gy,\\yalg}$;\n\n        $\\rnew \\leftarrow \\fSteer{\\vynearest.\\yalg,\\yalg}$;\n\n        \\If{$\\fObstacleFree{\\rnew}$}\n        {\n            $\\ynew \\leftarrow \\rnew.\\fBack{}$;\n            \n            $\\vynew \\leftarrow \\fInitOutputNode{\\ynew}$;\n            \n            $\\vynew.\\hvalueext \\leftarrow \\fComputeHeuristic{\\ynew,\\Ygoal}$;\n            \n            $\\vCVNear2 \\leftarrow \\fNear{\\Gy,\\ynew,\\ensuremath{|\\Vy|}} \\cup \\{ \\vynearest \\}$;\n\n\t\t\t$\\vCESucc \\leftarrow \\varnothing$;\n\t\t\t$\\vCEPred \\leftarrow \\varnothing$;\n\t\t\t\n\t\t\t\\ForEach{$\\vynear \\in \\vCVNear2$}\n            {\n\t            $\\ralg \\leftarrow \\fSteer{\\ynew,\\vynear.\\yalg}$;\n\t            \n                \\If{$\\fObstacleFree{\\ralg}$}\n                {\n\t                $\\ey \\leftarrow \\fInitOutputEdge{\\vynew,\\vynear,\\ralg}$;\n\t                \n\t                $\\vCESucc \\leftarrow \\vCESucc \\cup \\{ \\ey \\}$;\n                }\n                \n\t            $\\ralg \\leftarrow \\fSteer{\\vynear.\\yalg,\\ynew}$;\n\t           \n                \\If{$\\fObstacleFree{\\ralg}$}\n                {\n\t                $\\ey \\leftarrow \\fInitOutputEdge{\\vynear,\\vynew,\\ralg}$;\n\t               \n\t                $\\vCEPred \\leftarrow \\vCEPred \\cup \\{ \\ey \\}$;\n                }\n            }\n            \n            $\\vCVSigmaPrime \\leftarrow \\varnothing$;\n            $\\vCESigmaPrime \\leftarrow \\varnothing$;\n            \n            \\ForEach{$\\ey \\in \\vCEPred$}\n            {\n\t            $\\vypred \\leftarrow \\ey.{\\mathtt{tail}}$;\n\t            \n\t            $\\vsigmapred \\leftarrow \\vypred.\\psigma$;\n\t              \n\t            $\\xpred \\leftarrow \\vsigmapred.\\sigma.\\fBack{}$; \n\t              \n\t            $\\sigma \\leftarrow \\fPropagate{\\xpred,\\ey.\\ralg}$;\n\t             \n\t            \\If{$\\fObstacleFree{\\sigmaalg}$} \n\t            { \n\t\t            $\\vsigmanew \\leftarrow \\fInitTrajectoryNode{\\sigmaalg,\\ey,\\vCESucc}$;\n\t             \n\t\t            $\\esigma \\leftarrow \\fInitTrajectoryEdge{\\vsigmapred,\\vsigmanew,\\sigmaalg}$;\n\t            \n\t\t            $\\vCVSigmaPrime \\leftarrow \\vCVSigmaPrime \\cup \\{ \\vsigmanew \\}$;\n\t\t            \n\t\t            $\\vCESigmaPrime \\leftarrow \\vCESigmaPrime\\cup \\{ \\esigma \\}$;\n\t                  \n\t\t            \\If{$\\vynew.\\bargvalue >  \\vypred.\\gvalc + \\fCostValue{\\sigmaalg}$}\n\t\t            {\n\t\t\t         \t$\\vynew.\\bargvalue \\leftarrow  \\vypred.\\gvalc + \\fCostValue{\\sigmaalg}$;\n\t                      \n\t\t                $\\vynew.\\pyref \\leftarrow \\vypred$;\n\t                  \n\t\t                $\\vynew.\\psigma \\leftarrow \\vsigmanew$;\n\t\n\t\t            }\n\t\n                }\n\t         } \n\n            $\\Vy \\leftarrow \\Vy \\cup \\{ \\vynew \\}$;\n            $\\Ey \\leftarrow \\Ey \\cup \\vCESucc \\cup \\vCEPred$;\n            \n            $\\vCVSigma \\leftarrow \\vCVSigma \\cup \\vCVSigmaPrime$;\n            $\\vCESigma \\leftarrow \\vCESigma \\cup \\vCESigmaPrime$;\n\n            $\\Gy \\leftarrow (\\Vy,\\Ey)$;\n            $\\Gsigma \\leftarrow (\\vCVSigma,\\vCESigma)$;\n            \n            $\\vFrontier \\leftarrow \\fUpdateQueue{\\vFrontier,\\vynew}$;\n                                \n            $\\Qgoal \\leftarrow \\fUpdateGoal{\\Qgoal,\\vynew,\\Xgoal}$;\n                        \n        }\n        \n        \\Return{$\\Scval \\leftarrow (\\Gy,\\Gsigma,\\vFrontier,\\Qgoal)$};\n    }\n\n\n\\caption{{\\small The ${\\tt Extend}$ Procedure}{\\color{white}$^\\#$}}\\label{alg:extend_closed_loop_rrtsharp}\n\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n\n}\n\n The members of the node ${v_{y,\\mathrm{new}}}$ are set as follows. First,  ${\\mathtt{Near}}$ finds the set of neighbor output nodes ${V_{\\mathrm{near}}}$ in the neighborhood of the new output point ${y_{\\mathrm{new}}}$ (Line 9). Then, the set of incoming edges ${E_{y,\\mathrm{pred}}}$ and outgoing edges ${E_{y,\\mathrm{succ}}}$ of the new output node ${v_{y,\\mathrm{new}}}$ are computed by using the information of the neighbor output nodes (Lines 10-19). \n \n Once the new output node ${v_{y,\\mathrm{new}}}$ is created together with the set of incoming edges ${E_{y,\\mathrm{pred}}}$ and outgoing edges ${E_{y,\\mathrm{succ}}}$ connecting it to its neighbor output nodes ${V_{\\mathrm{near}}}$,  ${\\mathtt{Extend}}$  attempts to find the best incoming edge that yields a segment of a reference trajectory which incurs minimum cost to get to ${v_{y,\\mathrm{new}}}$ among all incoming edges in ${E_{y,\\mathrm{pred}}}$ (Lines 20-34). That is, for any incoming edge ${e_{y}}$ in ${E_{y,\\mathrm{pred}}}$, the algorithm first gets the information of the predecessor output node ${v_{y,\\mathrm{pred}}}$ and its internal state ${x_\\mathrm{pred}}$ by using the information of the parent state trajectory node ${v_{\\sigma,\\mathrm{pred}}}$ (Lines 22-24). Then, it simulates the system  forward in time with the state ${x_\\mathrm{pred}}$ being the initial state and ${e_{y}}.{r}$ being the reference trajectory to be tracked, (Line 25). If the state trajectory ${\\sigma}$ computed by closed-loop prediction is collision-free, a new trajectory node ${v_{\\sigma,\\mathrm{new}}}$ is created together with its list of outgoing output trajectories being initialized with ${E_{y,\\mathrm{succ}}}$ (Line 27). When a new trajectory node ${v_{\\sigma,\\mathrm{new}}}$ is created, the outgoing state trajectories emanating from the final state of the state trajectory ${v_{\\sigma,\\mathrm{new}}}.{\\sigma}$ via closed-loop prediction are not immediately computed, for the sake of efficiency. Instead, the algorithm keeps the set of candidate outgoing output trajectories, that is, the edges in ${E_{y,\\mathrm{succ}}}$, in a list ${v_{\\sigma,\\mathrm{new}}}.{\\mathtt{outgoing}}$, and the simulation of the system  for these output trajectories is postponed until the head output node of the output edge ${v_{\\sigma,\\mathrm{new}}}.{e_{y}}$ is selected for the Bellman update during the ${\\mathtt{Replan}}$ procedure. Once the new state trajectory node ${v_{\\sigma,\\mathrm{new}}}$ and the edge between the predecessor state trajectory node ${v_{\\sigma,\\mathrm{pred}}}$ and itself are created (Lines 27-28), they are added to the set of nodes and edges of the graph ${\\mathcal{G}_{\\sigma}}$, respectively (Lines 29-30). If the incoming output edge ${e_{y}}$ between the predecessor output node ${v_{y,\\mathrm{pred}}}$ and the new output node ${v_{y,\\mathrm{new}}}$ yields a collision-free state trajectory ${\\sigma}$ that incurs cost less than the current cost of ${v_{y,\\mathrm{new}}}$, then, the ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{new}}}$ is set with new lower cost, ${v_{y,\\mathrm{pred}}}$ and ${v_{\\sigma,\\mathrm{new}}}$ are made the new parent output node and the new parent state trajectory node of ${v_{y,\\mathrm{new}}}$ (Lines 31-34). \n \n After successful creation of the new output node ${v_{y,\\mathrm{new}}}$, it is added to the graph ${\\mathcal{G}_{y}}$ together with all of its collision-free output edges (Line 36). Likewise, all trajectory nodes and edges created during the simulation of the system dynamics are added to the graph ${\\mathcal{G}_{\\sigma}}$ (Line 37). Lastly, the priority queues, ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are updated accordingly by using the information of the new output node ${v_{y,\\mathrm{new}}}$, that is, reordering of the priorities after insertion of ${v_{y,\\mathrm{new}}}$ to the queue ${\\mathcal{Q}}$ and reordering the goal output nodes in ${\\mathcal{Q}_{\\mathrm{goal}}}$ if ${v_{y,\\mathrm{new}}}$ happens to be a goal output node (Lines 38-39).\n\\subsubsection{The ${\\mathtt{Replan}}$ Procedure}\nThe ${\\mathtt{Replan}}$ procedure is given in Algorithm~\\ref{alg:replan_closed_loop_rrtsharp} (see~\\cite{arslan2013useofrelaxation}). It improves cost-to-come values of output nodes by operating on the nonstationary and promising nodes of the graph ${\\mathcal{G}_{y}}$. It  pops the most promising nonstationary node from the priority queue ${\\mathcal{Q}}$, if there are any, and this  node is made stationary by assigning its ${\\mathtt{\\bar{g}}}$-value to its ${\\mathtt{g}}$-value (Lines 5-6). Then, the ${\\mathtt{g}}$-value of the output node ${v_{y}}$ is used to improve the ${\\mathtt{\\bar{g}}}$-values of its neighbor output nodes. Before this, the algorithm computes the set of all outgoing state trajectories emanating from internal state of the output node ${v}$ (Lines 9-16). To do so, the algorithm first gets the information of the internal state ${x}$ by using the parent state trajectory node of ${v_{y}}$ (Lines 7-8). For any outgoing edge ${e_{y}}$ in ${v_{\\sigma}}.{\\mathtt{outgoing}}$, the algorithm first gets the information of the successor output node ${v_{y,\\mathrm{succ}}}$ by using the output edge ${e_{y}}$ (Line 10). Then, it simulates the system  forward in time with the state ${x}$ being the initial state and ${e_{y}}.{r}$ being the reference trajectory to be tracked (Line 11). If the state trajectory ${\\sigma}$ computed by closed-loop prediction is collision-free, a new trajectory node ${v_{\\sigma,\\mathrm{succ}}}$ is created together with its list of outgoing output trajectories being initialized with the set of outgoing output edges of ${v_{y,\\mathrm{succ}}}$ (Line 13). Also, a state trajectory edge between ${v_{\\sigma}}$ and ${v_{\\sigma,\\mathrm{succ}}}$ is created (Line 14). Then, the new state trajectory node and edge are tentatively added to the set of nodes and edges of the graph ${\\mathcal{G}_{\\sigma}}$ (Lines 15-16). This  continues until all candidate outgoing output trajectories are processed in the closed-loop simulation, then the list ${v_{y}}.{\\mathtt{outgoing}}$ is cleared up (Line 17). All newly computed state trajectory nodes and edges are added to the graph ${\\mathcal{G}_{\\sigma}}$ (Line 18).\n\n For each outgoing state trajectory ${\\sigma}$, ${\\mathtt{Replan}}$ adds up its cost, incurred by reaching to the successor output node ${v_{y,\\mathrm{succ}}}$ to the ${\\mathtt{g}}$-value of ${v_{y}}$, and compare it with the current ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{succ}}}$ (Line 22). If the outgoing state trajectory edge ${\\sigma}$ yields a lower cost than ${v_{y,\\mathrm{succ}}}$,  the ${\\mathtt{\\bar{g}}}$-value of ${v_{y,\\mathrm{succ}}}$ is set with new lower cost, and ${v_{y}}$ and ${v_{\\sigma,\\mathrm{succ}}}$ are made the new parent output node and the new parent state trajectory node of ${v_{y,\\mathrm{succ}}}$, respectively (Lines 23-25). Last, the priority queues ${\\mathcal{Q}}$ and ${\\mathcal{Q}_{\\mathrm{goal}}}$ are updated  by using the update information of the successor output node ${v_{y,\\mathrm{succ}}}$, that is, reordering of the priorities after updating the key value of ${v_{y,\\mathrm{succ}}}$ to the queue ${\\mathcal{Q}}$ and reordering the goal output nodes in ${\\mathcal{Q}_{\\mathrm{goal}}}$ if ${v_{y,\\mathrm{succ}}}$ happens to be a goal output node (Lines 26-27). These steps are repeated until there is no promising nonstationary output node left in the priority queue ${\\mathcal{Q}}$, that is,  ${\\mathcal{Q}}.\\fTopKey() \\succeq {\\mathcal{Q}_{\\mathrm{goal}}}.\\fTopKey()$.\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Gsigma}{$\\mathcal{G}_{\\sigma}$}\n    \\SetKwData{Gy}{$\\mathcal{G}_{y}$}\n    \n    \\SetKwData{Valg}{$V$}\n    \n    \\SetKwData{vFrontier}{$\\mathcal{Q}$}\n    \\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{xgoal}{$x_{\\mathrm{goal}}$}\n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n   \n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{vXminGoal}{$v^{*}_{\\mathrm{goal}}$}\n    \\SetKwData{vVminGoal}{$v^{*}_{\\mathrm{goal}}$}\n    \\SetKwData{xalg}{$x$}\n  \n\n\t\\SetKwData{pyalg}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\n\n\t\\SetKwData{vysucc}{$v_{y,\\mathrm{succ}}$}\n\t\\SetKwData{vy}{$v_{y}$}\n\t\\SetKwData{bargvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{gvalue}{$\\mathtt{g}$}\n\n\t\\SetKwData{vCostValue}{$\\mathtt{c}$} \n\t\\SetKwData{ralg}{$r$} \n\t\\SetKwData{sigmaalg}{$\\sigma$} \n\t\t\n\t\\SetKwData{ey}{$e_{y}$}\n\t\\SetKwData{outgoingalg}{$\\mathtt{outgoing}$} \n\t\\SetKwData{vsigma}{$v_{\\sigma}$} \n\t\\SetKwData{vsigmasucc}{$v_{\\sigma,\\mathrm{succ}}$} \n\t\\SetKwData{esigma}{$e_{\\sigma}$} \n\n   \n \n    \\SetKwData{Vsigma}{$V_{\\sigma}$}\n    \\SetKwData{Esigma}{$E_{\\sigma}$}   \n    \\SetKwData{headalg}{$\\mathtt{head}$}  \n \n\n\n\t\\SetKwData{vVYFrom}{$v_{y,\\mathrm{from}}$} \n\t\\SetKwData{vVYTo}{$v_{y,\\mathrm{to}}$} \n\t\\SetKwData{vVMinRGoal}{$v^{*}_{r,\\mathrm{goal}}$} \n\t\\SetKwData{vCVYGoal}{$V_{y,\\mathrm{goal}}$} \n\t\\SetKwData{vCVGoal}{$V_{\\mathrm{goal}}$} \n\t\\SetKwData{vKey}{$\\mathtt{key}$}  \n\t\\SetKwData{vVSigmaPrime}{$v^{\\prime}_{\\sigma}$} \n\t\\SetKwData{vVRPrime}{$v^{\\prime}_{r}$} \n\t\\SetKwData{Sc}{$\\mathcal{S}$}\n\t\n\n    \n\n    \\SetFuncSty{textbf}\n    \\fReplan{$\\Sc, \\Xgoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $(\\Gy,\\Gsigma,\\vFrontier,\\Qgoal) \\leftarrow \\Sc$;\n\n        $(\\Vsigma,\\Esigma) \\leftarrow \\Gsigma$;\n\n        {\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p6st}) {};}\\While{$\\vFrontier.\\fTopKey{} \\prec \\Qgoal.\\fTopKey{}$}\n        {\n            \n\t\t\t\n\t\t\t$\\vy \\leftarrow \\vFrontier.\\fPop{}$;\n\t\t\t\t          \n\t\t\t$\\vy.\\gvalue\\leftarrow \\vy.\\bargvalue$; \n\t\t\t\t            \n\t\t\t$\\vsigma \\leftarrow \\vy.\\psigma$;\n\t\t\t              \n\t\t\t$\\xalg \\leftarrow \\vsigma.{\\sigma}.\\fBack{}$;\n\t\t\t              \n\t\t\t\\ForEach{$\\ey \\in \\vsigma.\\outgoingalg$}\n\t\t\t{\n\t\t\t\t$\\vysucc \\leftarrow \\ey.\\headalg$;\n\t\t\t\n\t\t\t\t$\\sigmaalg \\leftarrow \\fPropagate{\\xalg,\\ey.\\ralg}$;\n\t\t\t\n\t\t\t\t\\If{$\\fObstacleFree{\\sigmaalg}$}\n\t\t\t\t{\n\t\t\t\t\t$\\vsigmasucc \\leftarrow \\fInitTrajectoryNode{\\sigmaalg,\\ey,\\fOutgoing{\\Gy,\\vysucc}}$;\n\n\t\t\t\t\t$\\esigma \\leftarrow \\fInitTrajectoryEdge{\\vsigma,\\vsigmasucc,\\sigmaalg}$;\n\t\t\t\n\t\t\t\t\t$\\Vsigma \\leftarrow \\Vsigma \\cup \\{ \\vsigmasucc \\}$;\n\t\t\t\t  \n\t\t\t\t\t$\\Esigma \\leftarrow \\Esigma \\cup \\{ \\esigma \\}$;\n\t\t\t\t}\n\t\t\t}\t\n\t\t\t              \n\t\t\t$\\vsigma.\\outgoingalg \\leftarrow \\varnothing$;\n\t\t\t\n\t\t\t$\\Gsigma \\leftarrow (\\Vsigma,\\Esigma)$;\n\t\t\t\t  \t\t\n\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p8st}) {};}\\ForEach{$\\vsigmasucc \\in \\fSuccessor{\\Gsigma,\\vsigma}$}\n\t\t\t{\n\t\t\t\t$\\sigmaalg \\leftarrow \\vsigmasucc.\\sigmaalg$;\n\t\t\t\n\t\t\t\t$\\vysucc \\leftarrow \\vsigmasucc.\\ey.\\headalg$;\n\t\t\t\n\t\t\t\t\\If{$\\vysucc.\\bargvalue > \\vy.\\gvalue + \\fCostValue{\\sigmaalg}$}\n\t\t\t\t{\n\t\t\t\n\t\t\t\t\t{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p9st}) {};}$\\vysucc.\\bargvalue \\leftarrow \\vy.\\gvalue + \\fCostValue{\\sigmaalg}$; \n\t\t\t\n\t\t\t\t\t$\\vysucc.\\pyalg \\leftarrow \\vy$;\n\t\t\t\n\t\t\t\t\t$\\vysucc.\\psigma \\leftarrow \\vsigmasucc$;\n\t\t\t\t\t\t\n\t\t\t\t\t$\\vFrontier \\leftarrow \\fUpdateQueue{\\vFrontier,\\vysucc}$;\n\t\t\t\n\t\t\t\t\t$\\Qgoal \\leftarrow \\fUpdateGoal{\\Qgoal,\\vysucc,\\Xgoal}$;{\\tikz[overlay,remember picture,baseline] \\node [anchor=base] ({p6en}) {};}\n\t\t\t\n\t\t\t\t}\n\t\t\t}\t\t\t            \t\n\t\t\t            \t\t\t\t       \n        }\n\n        \\Return{$\\Sc \\leftarrow (\\Gy,\\Gsigma, \\vFrontier, \\Qgoal)$};\n   }\n\n\\caption{ {\\small ${\\mathtt{Replan}}$ Procedure}{\\color{white}$^\\#$}} \\label{alg:replan_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n}\n\nThe auxiliary procedures  in  ${\\mathtt{Extend}}$ and ${\\mathtt{Replan}}$  are shown in Algorithm~\\ref{alg:auxiliary_procedures_closed_loop_rrtsharp}.  $\\fUpdateQueue$  maintains the priority queue ${\\mathcal{Q}}$ whenever a new output node is created or key value of an output node that is already in the queue is updated. During a call to  $\\fUpdateQueue$  with the priority queue ${\\mathcal{Q}}$ and the output node ${v_{y}}$, there are three possible cases. First, if ${v_{y}}$ is a nonstationary output node, that is, ${v_{y}}.{\\mathtt{g}} \\neq {v_{y}}.{\\mathtt{\\bar{g}}}$, key value of ${v_{y}}$ is updated and priorities in the queue are reordered  (Line 3). Second, if ${v_{y}}$ is a nonstationary output node and it is not in the queue, then it is inserted to the queue ${\\mathcal{Q}}$ with its key value (Line 5). Third, if ${v_{y}}$  is a stationary output node, that is, ${v_{y}}.{\\mathtt{g}} = {v_{y}}.{\\mathtt{\\bar{g}}}$, and it is in the queue ${\\mathcal{Q}}$, then, it is removed from the queue ${\\mathcal{Q}}$ (Line 7).\n{\n\\setlength{\\intextsep}{1pt}\n\\IncMargin{0.7em}\n\n\\begin{algorithm}[h]\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Valg}{$V$}\n \n   \n  \n    \\SetKwData{vT}{$\\mathcal{T}$}\n    \\SetKwData{vG}{$\\mathcal{G}$}\n    \\SetKwData{vTPrime}{$\\mathcal{T}^{\\prime}$}\n    \\SetKwData{vGPrime}{$\\mathcal{G}^{\\prime}$}\n    \\SetKwData{vClXGoal}{$\\mathcal{X}_{\\mathrm{goal}}$}\n    \\SetKwData{Xgoal}{$X_{\\mathrm{goal}}$}\n    \\SetKwData{Ygoal}{$Y_{\\mathrm{goal}}$}\n    \\SetKwData{xalg}{$x$}\n   \n \n    \\SetKwData{vK}{$k$}\n    \n    \n\t\\SetKwData{yalg}{$y$}\n\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n \n \n   \n\n\n    \\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\t\\SetKwData{vFrontier}{$\\mathcal{Q}$}\n\t\\SetKwData{Qgoal}{$\\mathcal{Q}_{\\mathrm{goal}}$}\n\t\\SetKwData{Ygoal}{$\\mathcal{Y}_{\\mathrm{goal}}$}\n\n\n\n\n\n\n\n\t\\SetKwData{vyalg}{$v_{y}$}\n\t\\SetKwData{vsigma}{$v_{\\sigma}$}\n\n\n    \n\n   \n    \\SetFuncSty{textbf}\n    \\fUpdateQueue{$\\vFrontier,\\vyalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n         \\If{$\\vyalg.\\gvalue  \\neq \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\in \\vFrontier$}\n         {\n            $\\vFrontier.\\fUpdate{\\vyalg,\\fKey{\\vyalg}}$;\n         }\n         \\ElseIf{$\\vyalg.\\gvalue  \\neq \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\notin \\vFrontier$}\n         {\n            $\\vFrontier.\\fInsert{\\vyalg,\\fKey{\\vyalg}}$;\n         }\n         \\ElseIf{$\\vyalg.\\gvalue  = \\vyalg.\\gbarvalue \\text{~and~} \\vyalg \\in \\vFrontier$}\n         {\n            $\\vFrontier.\\fRemove{\\vyalg}$;\n         }\n         \n         \\Return{$\\vFrontier$};\n    }\n\n\n\t\\SetFuncSty{textbf}\n    \\fUpdateGoal{$\\Qgoal,\\vyalg,\\Ygoal$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vsigma \\leftarrow \\vyalg.{\\mathtt{p}_{\\sigma}}$;\n\t    \n\t    $\\xalg \\leftarrow \\vsigma.\\sigmaalg.\\fBack{}$;\n\t    \n\t    \\If{$\\xalg \\in \\Xgoal$}\n\t    {\n\t\t    \\If{$\\vyalg \\in \\Qgoal$}\n\t        {\n\t\t        $\\Qgoal.\\fUpdate{\\vyalg,\\fKey{\\vyalg}}$;\n\t         }\n\t        \\Else\n\t        {\n\t\t        $\\Qgoal.\\fInsert{\\vyalg,\\fKey{\\vyalg}}$;\n\t        }\n\t    }\n        \\Return{$\\Qgoal$};\n    }\n    \n    \\SetKwFunction{fH}{h}\n    \n\n\n    \\SetKwData{vGPrime}{$g^{\\prime}$}\n    \\SetKwData{vGMin}{$g_{\\min}$}\n    \\SetKwData{vF}{$f$}\n    \\SetKwData{vKey}{$key$}\n\n    \\SetFuncSty{textbf}\n    \\fKey{$\\vyalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n        \\Return{$\\vK = (\\vyalg.\\gbarvalue+ \\vyalg.\\hvalue, \\vyalg.\\hvalue)$};\n    }\n\n\\caption{{\\small Auxiliary Procedures}{\\color{white}$^\\#$}} \\label{alg:auxiliary_procedures_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.7em} \n}\n\nAlgorithm~\\ref{alg:constructor_procedures_closed_loop_rrtsharp} gives constructor procedures for node and edge data structures used in the ${\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}$.\n\n{\n\\setlength{\\intextsep}{1pt}\n\n\n\n\\IncMargin{0.5em}\n\n\n\n\\begin{algorithm}[h]\n    \n    \\small\n    \\DontPrintSemicolon\n    \\SetKwInOut{Input}{input}\n    \\SetKwInOut{Output}{output}\n    \\SetKwBlock{NoBegin}{}{end}\n\n\t\n    \n\n    \n\n    \n\n    \n\n    \n    \n    \n    \\SetKwData{Valg}{$V$}\n    \\SetKwData{Ey}{$E_{y}$}\n   \n \n   \n  \n   \n \n  \n \n    \\SetKwData{xalg}{$x$}\n \n  \n  \n    \n    \n\t\\SetKwData{yalg}{$y$}\n\t\\SetKwData{ralg}{$r$}\n\t\\SetKwData{sigmaalg}{$\\sigma$}\n\n    \\SetKwData{vx}{$v_{x}$}\n    \\SetKwData{ey}{$e_{y}$}\n\n\n    \\SetKwData{gvalue}{$\\mathtt{g}$}\n\t\\SetKwData{gbarvalue}{$\\mathtt{\\bar{g}}$}\n\t\\SetKwData{hvalue}{$\\mathtt{h}$}\n\n\n\n\t\\SetKwData{vVYFrom}{$v_{y,\\mathrm{from}}$}\n\t\\SetKwData{vVYTo}{$v_{y,\\mathrm{to}}$}\n\t\\SetKwData{vVXFrom}{$v_{x,\\mathrm{from}}$}\n\t\\SetKwData{vVXTo}{$v_{x,\\mathrm{to}}$}\n\t\\SetKwData{vVSigmaFrom}{$v_{\\sigma,\\mathrm{from}}$}\n\t\\SetKwData{vVSigmaTo}{$v_{\\sigma,\\mathrm{to}}$}\n\t\\SetKwData{vEX}{$e_{x}$}\n\t\\SetKwData{psigma}{$\\mathtt{p}_{\\sigma}$}\n\t\\SetKwData{py}{$\\mathtt{p}_{y}$}\n\t\\SetKwData{vy}{$v_{y}$}\n\t\\SetKwData{vsigma}{$v_{\\sigma}$}\n\t\\SetKwData{ey}{$e_{y}$}\n\t\\SetKwData{esigma}{$e_{\\sigma}$}\n\t\\SetKwData{tailalg}{$\\mathtt{tail}$}\n\t\\SetKwData{headalg}{$\\mathtt{head}$}\n\t\\SetKwData{outgoingalg}{$\\mathtt{outgoing}$}\n\t\n\n    \n    \\setlength{\\columnsep}{2mm}\n\t\\begin{multicols*}{2}\n\t\\vspace*{-4mm}\n\t\\SetFuncSty{textbf}\n    \n    \n    \\fInitOutputNode{$\\yalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vy.\\yalg \\leftarrow \\yalg$;\n\t    \n\t    $\\vy.\\gvalue \\leftarrow \\infty$;\n\t    $\\vy.\\gbarvalue  \\leftarrow \\infty$;\n\t    \n\t    \n\t    $\\vy.\\hvalue  \\leftarrow 0$;\n\t    \n\t    \n\n\t    \n\t    \n\t\t\n\t    \n\t    \n\t\t$\\vy.\\py \\leftarrow \\varnothing$;\n\t    $\\vy.\\psigma \\leftarrow \\varnothing$;\n\t            \n\t    \n        \n\n    \t\n    \t\n\t    \n    \t\n    \t\n    \t\\Return{$\\vy$};\n    }\n\n    \\SetFuncSty{textbf}\n    \n    \n    \\fInitOutputEdge{$\\vVYFrom,\\vVYTo,\\ralg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\ey.\\tailalg \\leftarrow \\vVYFrom$;\n\t    \n\t    $\\ey.\\headalg \\leftarrow \\vVYTo$;\n\t    \t\n\t    $\\ey.\\ralg \\leftarrow \\ralg$;\n\t            \n    \t\\Return{$\\ey$};\n    }\n    \n    \\SetFuncSty{textbf}\n    \\fInitTrajectoryNode{$\\sigmaalg,\\ey, \\Ey$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vsigma.\\sigmaalg \\leftarrow \\sigmaalg$;\n\t    \n\t    $\\vsigma.\\ey \\leftarrow \\ey$;\n\t    \n\t    $\\vsigma.\\outgoingalg \\leftarrow \\Ey$;\n\t    \n\t    \n\t    \n\t    \n\n\t            \n\t    \n        \n\n    \t\n    \t\n\t    \n    \t\n    \t\n    \t\\Return{$\\vsigma$};\n    }\n    \n    \\vspace*{-4mm}\n    \\SetFuncSty{textbf}\n    \\fInitTrajectoryEdge{$\\vVSigmaFrom,\\vVSigmaTo, \\sigmaalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\esigma.\\tailalg \\leftarrow \\vVSigmaFrom$;\n\t    \n\t    $\\esigma.\\headalg \\leftarrow \\vVSigmaTo$;\n\t    \n\t    $\\esigma.\\sigmaalg \\leftarrow \\sigmaalg$;\n\t    \n       \t\\Return{$\\esigma$};\n    }\n        \n    \\SetFuncSty{textbf}\n    \\fInitStateNode{$\\xalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vx.\\xalg \\leftarrow \\xalg$;\n       \t\n       \t\\Return{$\\vx$};\n    }\n    \n    \\SetFuncSty{textbf}\n    \\fInitStateEdge{$\\vVXFrom,\\vVXTo,\\sigmaalg$}\n    \\SetFuncSty{texttt}\n    \\NoBegin\n    {\n\t    $\\vEX.\\tailalg \\leftarrow \\vVXFrom$;\n    \n\t    $\\vEX.\\headalg \\leftarrow \\vVXTo$;\n\t    \n\t    $\\vEX.\\sigmaalg \\leftarrow \\sigmaalg$;\n          \t\n        \\Return{$\\vEX$};\n    }\n    \n\t\\end{multicols*}\n\t\\vspace*{2mm}\n\\caption{{\\small Node and Edge Constructor Procedures}{\\color{white}$^\\#$}} \\label{alg:constructor_procedures_closed_loop_rrtsharp}\n\n\\end{algorithm}\n\\DecMargin{0.5em} \n\n\n\\vspace*{-5pt}\n}\n\n\\subsection{Properties of the Algorithm}\n\nThe {\\ensuremath{{\\mathrm{CL\\textbf{-}RRT}^{\\tiny \\#}}}}{} algorithm provides both dynamic feasibility guarantees, that is, the lowest-cost reference trajectory computed by the algorithm can be tracked by the low-level controller, and asymptotic optimality guarantees, that is, the lowest-cost reference trajectory computed by the algorithm converges to the optimal reference trajectory almost surely. The former property is an immediate result of using closed-loop prediction during the search phase. During the extension of the graph ${\\mathcal{G}_{y}}$, if some segments of a reference trajectory can not be tracked, that is, is not dynamically feasible, the corresponding state trajectory is not stored in the graph ${\\mathcal{G}_{\\sigma}}$ constructed by the algorithm. The former property is due to the asymptotic optimality property of the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithm~\\cite{arslan2013useofrelaxation}. The proposed algorithm incrementally grows a graph ${\\mathcal{G}_{y}}$ in the output space in a similar fashion as the {\\ensuremath{{\\mathrm{RRG}}}}{} algorithm does~\\cite{karaman2010optimal}. Therefore, the lowest-cost path encoded in ${\\mathcal{G}_{y}}$ converges to the optimal output trajectory in the output space almost surely. In addition, the lowest-cost output trajectory encoded in the graph ${\\mathcal{G}_{y}}$ is extracted at the end of each iteration in a similar fashion as the {\\ensuremath{{\\mathrm{RRT}^{\\tiny \\#}}}}{} algorithm does. Given the cost function that associates each edge in ${\\mathcal{G}_{y}}$ with a non-negative cost values being \\textit{monotonic} and \\textit{bounded}, the proposed algorithm is asymptotically optimal.\n\n\n\n\n\\section{Numerical Study}\\label{section:numerical_simulations}\nThe proposed algorithm is evaluated on two scenarios where a nonholonomic, wheeled vehicle, modeled as a unicycle, travels along a track. The motion equations are\n\n", "index": 7, "text": "\\begin{align*}\n\\dot{x}_{1} &= x_{4} \\sin (x_{3}), \\;\n\\dot{x}_{2} = x_{4} \\cos (x_{3}),\\;\n\\dot{x}_{3} = u_{1}, \\;\n\\dot{x}_{4} = u_{2},   \\\\\ny_{1} &= x_{1}, \\; \ny_{2} = x_{2},\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\dot{x}_{1}\" display=\"inline\"><msub><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mn>1</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=x_{4}\\sin(x_{3}),\\;\\dot{x}_{2}=x_{4}\\cos(x_{3}),\\;\\dot{x}_{3}=u_%&#10;{1},\\;\\dot{x}_{4}=u_{2},\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><mrow><msub><mi>x</mi><mn>4</mn></msub><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mn>2</mn></msub><mo>=</mo><mrow><msub><mi>x</mi><mn>4</mn></msub><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mn>3</mn></msub><mo>=</mo><msub><mi>u</mi><mn>1</mn></msub></mrow><mo rspace=\"5.3pt\">,</mo><mrow><msub><mover accent=\"true\"><mi>x</mi><mo>\u02d9</mo></mover><mn>4</mn></msub><mo>=</mo><msub><mi>u</mi><mn>2</mn></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle y_{1}\" display=\"inline\"><msub><mi>y</mi><mn>1</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=x_{1},\\;y_{2}=x_{2},\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo rspace=\"5.3pt\">,</mo><mrow><msub><mi>y</mi><mn>2</mn></msub><mo>=</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}]