[{"file": "1601.04233.tex", "nexttext": "\n\n\\begin{algorithm}\n\\label{alg:alg1}\n\\caption{Subroutine for Computing $S_p$ given $\\widetilde{S}_p$ with success probability 2/3}\\label{unbiased-algo}\n\\begin{algorithmic}[1]\n\\Procedure{Unbiased-Estimate}{$\\widetilde{S}_p, \\epsilon$}\n\t\\State{$k \\gets 36m\\,/\\,p \\epsilon^2\\widetilde{S}_p^{1/p}$}\n\t\\For {$i = 1$ to $k$}\n        \\State{$v \\gets $ weighted sampled vertex obtained from a random edge query}\n    \t  \\State{$d \\gets \\deg(v)$ obtained from a degree query}\n    \t  \\State{$Y_i \\gets \\frac{2m}{d} {d \\choose p}$}\n\t\\EndFor\n    \\State{ $\\bar{Y} \\gets \\frac{1}{k} \\sum_{i=1}^{k} Y_i$}\n    \\State{ \\textbf{return} $\\bar{Y} $}\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\nClearly, the output $\\bar{Y}$ of Algorithm~\\ref{unbiased-algo} satisfies $E[\\bar{Y}]=S_p$.\nWe claim that the number of samples $k$ in Algorithm \\ref{unbiased-algo} is sufficient to provide two desired properties:\nthe algorithm returns an $(1\\pm\\epsilon)$-approximation of $S_p$ if $\\widetilde{S}_p$ is in the correct range;\nor, if $\\widetilde{S}_p$ is too large, the anomaly will be evident as the output $\\bar{Y}$ will be much smaller than $\\widetilde{S}_p$.\nIn particular, we may distinguish between these two cases by comparing $\\bar{Y}$ against $(1-{\\epsilon})\\tilde{S}_p$, as specified through the following lemma. \n\n\n\\begin{restatable}{lem}{gwc} \\label{good-when-crude} \\label{found-when-fault}\nFor $0 < {\\epsilon} \\leq 1/2$, with probability at least 2/3:\n\\begin{enumerate}[noitemsep,nolistsep]\n\\item If $\\frac{1}{2}S_p \\leq \\widetilde{S}_p \\leq 6S_p$, then Algorithm \\ref{unbiased-algo} outputs $\\bar{Y}$ such that $(1-\\epsilon)S_p \\leq \\bar{Y} \\leq (1+\\epsilon)S_p$;\\\\\nmoreover, if $S_p < \\tilde{S}_p$ then $\\bar{Y} \\geq (1-\\epsilon)\\widetilde{S}_p$.\n\\item If $\\widetilde{S}_p > 6S_p$, then Algorithm \\ref{unbiased-algo} outputs $\\bar{Y}$ such that $\\bar{Y} < \\frac{1}{2}\\widetilde{S}_p \\leq (1-\\epsilon)\\widetilde{S}_p$.\n\\end{enumerate}\n\\end{restatable}\n\nThe first item of Lemma~\\ref{good-when-crude} can be proved by bounding the variance of $Y$ using various Chebyshev's Inequality and identities of binomial coefficients,\nwhile the second item is a simple application of Markov's Inequality.\nDetailed proofs for these statements can be found in Appendix~\\ref{upunpr}.\n\n\n\\subsection{Full Algorithm}\n\nOur full algorithm proceeds by first setting $\\widetilde{S}_p$ to $n{{n-1} \\choose p}$, the maximum possible value of $S_p$ given by the complete graph.\nWe then use Algorithm \\ref{unbiased-algo} to check if $\\widetilde{S}_p > 6S_p$; if this is the case, we reduce $\\widetilde{S}_p$ then proceed to the next iteration.\nOtherwise, Algorithm \\ref{unbiased-algo} should already give an $(1\\pm\\epsilon)$-approximation to $S_p$ (with constant probability).\nWe note that if $\\epsilon > 1/2$, we may replace it with $1/2$ without increasing the asymptotic complexity.\n\nSince the process above may take up to ${\\rm O}(\\log n)$ iterations,\nwe must amplify the success probability of Algorithm \\ref{unbiased-algo} so that the overall success probability is still at least $2/3$.\nTo do so, we simply make $\\ell = {\\rm O}(\\log \\log n)$ multiple calls to Algorithm \\ref{unbiased-algo} then take the median of the returned values.\nOur full algorithm can be described as Algorithm \\ref{full-algo} below.\n\n\\begin{algorithm}\n\\caption{Algorithm for Approximating $S_p$}\\label{full-algo}\n\\begin{algorithmic}[1]\n\\Procedure{Count-Stars}{$\\epsilon$}\n\t\\State{$\\widetilde{S}_p \\gets n{{n-1} \\choose p}, \\; \\ell \\gets 40(\\log p + \\log \\log n)$}\n\t\\Loop\n\t\\For {$i = 1$ to $\\ell$}\n        \\State{$Z_i \\gets \\textsc{Unbiased-Estimate}(\\widetilde{S}_p,\\epsilon)$}\n    \t\\EndFor\n    \t\\State{$Z \\gets \\textrm{median}\\{Z_1,\\cdots,Z_\\ell\\}$}\n        \\If {$Z \\geq (1-\\epsilon)\\widetilde{S}_p$}\n        \t\\State {$\\hat{S}_p \\gets Z$}\n            \\State {\\textbf{return} $\\hat{S}_p$}\n        \\EndIf\n\n\t\\State{$\\widetilde{S}_p \\gets \\widetilde{S}_p/2$}\n  \\EndLoop\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n\\begin{thm} \\label{upper-m}\nAlgorithm \\ref{full-algo} outputs $\\hat{S}_p$ such that $(1-\\epsilon)S_p \\leq \\hat{S}_p \\leq (1+\\epsilon)S_p$ with probability at least $2/3$. The query complexity of Algorithm \\ref{full-algo} is ${\\rm O}\\left(\\frac{m \\log n \\log \\log n}{\\epsilon^2 S_p^{1/p}}\\right)$.\n\\end{thm}\n\\begin{ourproof}\nIf we assume that the events from Lemma \\ref{good-when-crude} hold,\nthen the algorithm will take at most $\\lceil\\log \\left(n{{n-1} \\choose p}\\right)\\rceil \\leq (p+1) \\log n$ iterations.\nBy choosing $\\ell = 40(\\log p + \\log \\log n)$, Chernoff bound (Theorem \\ref{chernoff}) implies that excepted for probability $1/3(p+1) \\log n$,\nmore than half of the return values of Algorithm \\ref{unbiased-algo} satisfy the desired property, and so does the median $Z$.\nBy the union bound, the total failure probability is at most 1/3.\n\nNow it is safe to assume that the events from the two lemmas hold.\nIn case $\\widetilde{S}_p > 6S_p$, our algorithm will detect this event because $Z \\leq (1-\\epsilon)\\widetilde{S}_p$,\nimplying that we never stop and return an inaccurate approximation.\nOn the other hand, if $\\widetilde{S}_p < S_p$, our algorithm computes $Z \\geq  (1-\\epsilon)\\widetilde{S}_p$ and must terminate.\nSince we only halve $\\widetilde{S}_p$ on each iteration, when $\\widetilde{S}_p < S_p$ first occurs, we have $\\widetilde{S}_p \\geq \\frac{1}{2}S_p$.\nAs a result, our algorithm must terminate with the desired approximation before the value $\\widetilde{S}_p$ is halved again.\nThus, Algorithm \\ref{full-algo} returns $\\hat{S}_p$ satisfying $(1-\\epsilon)S_p \\leq \\hat{S}_p \\leq (1+\\epsilon)S_p$ with probability at least $2/3$, as desired.\n\nRecall that the number of samples required by Algorithm \\ref{unbiased-algo} may only increase when $\\widetilde{S}_p$ decreases.\nThus we may use the number of samples in the last round of Algorithm \\ref{full-algo}, where $\\widetilde{S}_p = \\Theta(S_p)$, as the upper bound for each previous iteration.\nTherefore, each of the ${\\rm O}(\\log n)$ iterations takes ${\\rm O}(m \\log \\log n \\,/\\, \\epsilon^2 S_p^{1/p})$ samples, achieving the claimed query complexity.\n\\end{ourproof}\n\n\\subsection{Removing the Dependence on $m$}\n\nAs described above, Algorithm \\ref{unbiased-algo} picks the value $k$ and defines the unbiased estimator based on $m$, the number of edges.\nNonetheless, it is possible to remove this assumption of having prior knowledge of $m$ by instead computing its approximation.\nFurthermore, we will bound $m$ in terms of $n$ and $S_p$, so that we can also relate the performance of our algorithm to previous studies on this problem such as \\cite{gonen2011counting}, as done in Table \\ref{undirected-results}.\n\n\\subsubsection{Approximating $m$} \\label{approx-m}\n\nWe briefly discuss how to apply our algorithm when $m$ is unknown by first computing an approximation of $m$.\nUsing weighted vertex sampling, we may simulate the algorithm from \\cite{motwani2007estimating} or \\cite{batu2009sublinear} that computes an $(1\\pm\\epsilon)$-approximation to the sum of degrees using $\\tilde{{\\rm O}}(\\sqrt{n})$ weighted samples.\nMore specifically, we cite the following theorem:\n\\begin{thm} (\\cite{motwani2007estimating})\nLet $x_1, \\ldots, x_n$ be $n$ variables,\nand define a distribution $\\mathcal{D}$ that returns $(i, x_i)$ with probability $x_i / \\sum_{i=1}^{n} x_j$.\nThere exists an algorithm that\ncomputes a $(1\\pm\\epsilon)$-approximation of $S = \\sum_{i=1}^{n} x_i$ using $\\tilde{\\rm O}(\\sqrt{n})$ samples from $\\mathcal{D}$.\n\\end{thm}\nThus, we simulate the sampling process from $\\mathcal{D}$ by drawing a weighted vertex sample $v$, querying its degree, and feeding $(v, \\deg(v))$ to this algorithm.\nWe will need to decrease $\\epsilon$ used in this algorithm and our algorithm by a constant factor to account for the additional error.\nBelow we show that our complexities are at least $\\tilde{{\\rm O}}(n^{1-1/p})$ which is already $\\tilde{{\\rm O}}(\\sqrt{n})$ for $p = 2$, and thus this extra step does not affect our algorithm's performance asymptotically.\n\n\\subsubsection{Comparing $m$ to $n$ and $S_p$}\n\nFor comparison of performances, we will now show some bounds relating $m$ to $n$ and $S_p$.\nNotice that the function ${\\deg(v) \\choose p}$ is convex with respect to $\\deg(v)$.\\footnote{We may use the binomial coefficients ${x \\choose y}$ for non-integral value $x$ in the inequalities.\nThese can be interpreted through alternative formulations of binomial coefficients using falling factorials or analytic functions.}\nThen by applying Jensen's inequality (Theorem \\ref{jensen}) to this function, we obtai\n", "itemtype": "equation", "pos": 25273, "prevtext": "\n\n\\ifnum{0}=0\n\\begin{titlepage}\n\\fi\n\n\n\\maketitle\n\n\n\n\n\\ifnum{0}=0\n\n\n\n\n\n\n\n\n\\thispagestyle{empty}\n\\fi\n\n\\begin{abstract}\nWe study the problem of estimating the value of sums of the form $S_p \\triangleq \\sum \\binom{x_i}{p}$ when one has the ability to sample $x_i \\geq 0$ with probability proportional to its magnitude. When $p=2$, this problem is equivalent to estimating the selectivity of a self-join query in database systems when one can sample rows randomly. We also study the special case when $\\{x_i\\}$ is the degree sequence of a graph, which corresponds to counting the number of $p$-stars in a graph when one has the ability to sample edges randomly.\n\nOur algorithm for a $(1 \\pm \\varepsilon)$-multiplicative approximation of $S_p$ has query and time complexities ${\\rm O}(\\frac{m \\log \\log n}{\\epsilon^2 S_p^{1/p}})$. \nHere, $m=\\sum x_i/2$ is the number of edges in the graph, or equivalently, half the number of records in the database table. Similarly, $n$ is the number of vertices in the graph and the number of unique values in the database table. We also provide tight lower bounds (up to polylogarithmic factors) in almost all cases, even when $\\{x_i\\}$ is a degree sequence and one is allowed to use the structure of the graph to try to get a better estimate. We are not aware of any prior lower bounds on the problem of join selectivity estimation.\n\nFor the graph problem, prior work which assumed the ability to sample only \\emph{vertices} uniformly gave algorithms with matching lower bounds [Gonen, Ron, and Shavitt. \\textit{SIAM J. Comput.}, 25 (2011), pp. 1365-1411]. With the ability to sample edges randomly, we show that one can achieve faster algorithms for approximating the number of star subgraphs, bypassing the lower bounds in this prior work. For example, in the regime where $S_p\\leq n$, and $p=2$, our upper bound is $\\tilde{O}(n/S_p^{1/2})$, in contrast to their $\\Omega(n/S_p^{1/3})$ lower bound when no random edge queries are available.\n\nIn addition, we consider the problem of counting the number of directed paths of length two when the graph is directed. This problem is equivalent to estimating the selectivity of a join query between two distinct tables.\nWe prove that the general version of this problem cannot be solved in sublinear time. However, when the ratio between in-degree and out-degree is bounded---or equivalently, when the ratio between the number of occurrences of values in the two columns being joined is bounded---we give a sublinear time algorithm via a reduction to the undirected case.\n\\end{abstract}\n\n\t\n\\ifnum{0}=0\n\\end{titlepage}\n\\fi\n\n\n\n\\section{Introduction}\nWe study the problem of approximately estimating $S_p \\triangleq \\sum_{i=1}^n {x_i \\choose p}$ when one has the ability to sample $x_i \\geq 0$ with probability proportional to its magnitude. To solve this problem we design \\emph{sublinear-time algorithms}, which compute such an approximation while only looking at an extremely tiny fraction of the input, rather than having to scan the entire data set in order to determine this value.\n\nWe consider two primary motivations for this problem. The first is that in undirected graphs, if $x_i$ is the degree of vertex $i$ then $S_p$ counts the number of $p$-stars in the graph. Thus, estimating $S_p$ when one has the ability to sample $x_i$ with probability proportional to its magnitude corresponds to estimating the number of $p$-stars when one has the ability to sample vertices with probability proportional to their degrees (which is equivalent to having the ability to sample edges uniformly). This problem is an instance of the more general \\emph{subgraph counting problem} in which one wishes to estimate the number of occurrences of a subgraph $H$ in a graph $G$. The subgraph counting problem has applications in many different fields, including the study of biological, internet and database systems.\nFor example, detecting and counting subgraphs in protein interaction networks is used to study molecular pathways and cellular processes across species \\cite{scott2006efficient}.\n\nThe second application of interest is that the problem of estimating $S_2$ corresponds to estimating the selectivity of join and self-join operations in databases when one has the ability to sample rows of the tables uniformly. For example, note that if we set $x_i$ as the number of occurrences of value $i$ in the column being joined, then $S_2$ is precisely the number of records in the join of the table with itself on that column. When performing a query in a database, a program called a \\emph{query optimizer} is used to determine the most efficient way of performing the database query. In order to make this determination, it is useful for the query optimizer to know basic statistics about the database and about the query being performed. For example, queries that return a very larger number of records are usually serviced most efficiently by doing simple linear scans over the data whereas queries that return a smaller number of records may be better serviced by using an index \\cite{haas2009discovering}. As such, being able to estimate \\emph{selectivity} (number of records returned compared to the maximum possible number) of a query can be useful information for a query optimizer to have. In the more general case of estimating the selectivity of a join between two different tables (which can be modeled with a directed graph), the query optimizer can use this information to decide on the most efficient order to execute a sequence of joins which is a common task.\n\nIn the ``typical'' regime in which we wish to estimate $S_2$ given that $n \\leq S_2 \\leq n^2$, our algorithm has a running time of $\\tilde{O}(\\sqrt{n})$ which is very small compared to than the total amount of data. Furthermore, in the case of selectivity estimation, this number can be much less than the number of distinct values in the column being joined on, which results in an even smaller number of queries than would be necessary if one were using an index to compute the selectivity.\n\nWe believe that our query-based framework can be realized in many systems.\n\nOne possible way to implement random edge queries is as follows: because edges normally take most of the space for storing graphs, an access to a random memory location where the adjacency list is stored, would readily give a random edge.\nRandom edge queries allow us to implement a source of {\\em weighted\nvertex samples}, where a vertex is output with probability proportional to its weight (magnitude).\n\nWeighted sampling is used in \\cite{motwani2007estimating,batu2009sublinear} to find sublinear algorithms for approximating the sum of $n$ numbers (allowing only uniform sampling, results in a linear lower bound). We later use this as a subroutine in our algorithm.\n\nThroughout the rest of the paper, we will mostly use graph terminology when discussing this problem. However, we emphasize that all our results are fully general and apply to the problem of estimating $S_p$ even when one does not assume that the input is a graph.\n\n\\subsection{Our Contribution}\n\nPrior theoretical work on this problem only considered the version of this problem on graphs and assumed the ability to sample vertices uniformly rather than edges. \nSpecifically, prior studies of sublinear-time algorithms for graph problems usually consider the model where\nthe algorithm is allowed to query the adjacency list representation of the graph:\nit may make \\emph{neighbor queries} (by asking ``what is the $i^{\\textrm{th}}$ neighbor of a vertex $v$'') and \\emph{degree queries} (by asking ``what is the degree of vertex $v$'').\n\n\n\n\nWe propose a stronger model of sublinear-time algorithms for graph problems which allows random edge queries.\nNext, for undirected graphs, we construct an algorithm which uses only degree queries and random edge queries. This algorithm and its analysis is discussed in Section~\\ref{upper-undirected}.\nFor the problem of computing an approximation $\\hat{S}_p$ satisfying $(1-\\epsilon)S_p \\leq \\hat{S}_p \\leq (1+\\epsilon)S_p$, our algorithm has query and time complexities ${\\rm O}(m \\log \\log n / \\epsilon^2 S_p^{1/p})$. \n\nAlthough our algorithm is described in terms of graphs, it also applies to the more general case when one wants to estimate $S_p = \\sum_i \\binom{x_i}{p}$ without any assumptions about graph structure. Thus, it also applies to the problem of self-join selectivity estimation.\n\nWe then establish some relationships between $m$ and other parameters so that we may compare the performance of this algorithm\nto a related work by Gonen et al.~more directly (\\cite{gonen2011counting}).\nWe also provide lower bounds for our proposed model in Section~\\ref{lower-undirected-section}, which are mostly tight up to polylogarithmic factors.\nThis comparison is given in Table \\ref{undirected-results}. We emphasize that even though these lower bounds are stated for graphs, they also apply to the problem of self-join selectivity estimation.\n\nTo understand this table, first note that these algorithms require more samples when $S_p$ is small (i.e., stars are rare).\nAs $S_p$ increases, the complexity of each algorithm decreases until---at some point---the number of required samples drops to $\\tilde{{\\rm O}}(n^{1-1/p})$.\nOur algorithm is able to obtain this better complexity of $\\tilde{{\\rm O}}(n^{1-1/p})$ for a larger range of values of $S_p$ than that of the algorithm given in \\cite{gonen2011counting}. Specifically, our algorithm is more efficient \nfor $S_p \\leq n^{1+1/p}$, and has the same asymptotic bound for $S_p$ up to $n^p$. \nOnce $S_p > n^p$, it is unknown whether the degree and random edge queries alone can provide the same query complexity. \n\nNonetheless, if we have access to all three types of queries, we may combine the two algorithms to obtain the best of both cases as illustrated in the last column.\n\n{\\renewcommand{\\arraystretch}{1.4}\n\\begin{table}[ht]\n\\centering\n   \\begin{tabular}{|c|c|c|c|} \n\t\\hline\n\t\\multirow{3}{*}{range of $S_p$} & \\multicolumn{3}{ c| }{permitted types of queries}  \\\\ \\cline{2-4}\n\t& neighbor, degree  & degree, random edge & all types of queries \\\\\n\t& (\\cite{gonen2011counting}) & (this paper) & (this paper) \\\\\n\t\\hline\n\t$S_p \\leq n$ & \\multirow{2}{*}{$\\widetilde{\\Theta}\\left(\\frac{n}{S_p^{1/(p+1)}}\\right)$} & $\\widetilde{\\Theta}\\left(\\frac{n}{S_p^{1/p}}\\right)$ & $\\widetilde{\\Theta}\\left(\\frac{n}{S_p^{1/p}}\\right)$ \\\\ \\cline{1-1}\\cline{3-4}\n\t$n < S_p \\leq n^{1+1/p}$ & & \\multirow{2}{*}{$\\widetilde{\\Theta}\\left(n^{1-1/p}\\right)$} & \\multirow{2}{*}{$\\widetilde{\\Theta}\\left(n^{1-1/p}\\right)$} \\\\ \\cline{1-2}\n\t$n^{1+1/p} < S_p \\leq n^p$ & $\\widetilde{\\Theta}\\left(n^{1-1/p}\\right)$ & & \\\\ \\hline\n\t$ n^p < S_p$ & $\\widetilde{\\Theta}\\left(\\frac{n^{p-1/p}}{S_p^{1-1/p}}\\right)$ & $\\Omega \\left(\\frac{n^{p-1/p}}{S_p^{1-1/p}}\\right), \\widetilde{{\\rm O}}\\left(n^{1-1/p}\\right)$ & $\\widetilde{\\Theta}\\left(\\frac{n^{p-1/p}}{S_p^{1-1/p}}\\right)$ \\\\ \\hline\n  \\end{tabular}\n\\caption{Summary of the query and time complexities for counting $p$-stars on undirected graphs, given a different set of allowed queries. $\\epsilon$ is assumed to be constant. Adjacent cells in the same column with the same contents have been merged.}\\label{undirected-results}\n\\end{table}\n}\n\nWe also consider a variant of the counting stars problem on directed graphs in Appendix~\\ref{shortdir}.\nIf one only needs to count ``stars'' where all edges are either pointing into or away from the center, this is essentially still the undirected case.\nWe then consider counting directed paths of length two, and discover that allowing random edge queries does not provide an efficient algorithm in this case.\nIn particular, we show that any constant factor multiplicative approximation of $S_p$ requires $\\Omega(n)$ queries even when all three types of queries are allowed.\nHowever, when the ratio between the in-degree and the out-degree on every vertex is bounded, we solve this special case in sublinear time via a reduction to the undirected case where degree queries and random edge queries are allowed.\n\nThis variant of the counting stars problem can also be used for approximating join selectivity.\nFor a directed graph, we aim at estimating the quantity $\\sum_{v \\in V(G)} \\deg^-(v)\\cdot\\deg^+(v)$.\nOn the other hand in the database context, we wish to compute the quantity $\\sum_{i=1}^n x_i \\cdot y_i$,\nwhere $x_i$ and $y_i$ denote the number of occurrences of a label $i$ in the column we join on,\nfrom the first and the second table, respectively.\nThus, applying simple changes in variables,\nthe algorithms from Appendix~\\ref{shortdir} can be applied to the problem of estimating join selectivity as well.\n\n\\subsection{Our Approaches}\n\nIn order to approximate the number of stars in the undirected case, we convert the random edge queries into weighted vertex sampling,\nwhere the probability of sampling a particular vertex is proportional to its degree.\nWe then construct an unbiased estimator that approximates the number of stars using the degree of the sampled vertex as a parameter.\nThe analysis of this part is roughly based on the variance bounding method used in \\cite{alon1996space}, which aims to approximate the frequency moment in a streaming model.\nThe number of samples required by this algorithm depends on $S_p$, which is not known in advance.\nThus we create a guessed value of $S_p$ and iteratively update this parameter until it becomes accurate.\n\nTo demonstrate lower bounds in the undirected case, we construct new instances to prove\ntight bounds for the case in which our model is more powerful than the traditional model.\nIn other cases, we provide a new proof to show that the ability to sample uniformly random edges does not necessarily allow better performance in counting stars.\nOur proof is based on applying Yao's principle and providing an explicit construction of the hard instances,\nwhich unifies multiple cases together and greatly simplifies the approach of \\cite{gonen2011counting}.\\footnote{One useful technique for giving lower bounds on sublinear time algorithms,\npioneered by \\cite{blais2012property}, is to make use of a connection between\nlower bounds in communication complexity and lower bounds on sublinear\ntime algorithms.   More specifically,  by giving a reduction from a communication\ncomplexity problem to the problem we want to solve,  a lower bound\non the communication complexity problem yields a lower\nbound on our problem.  In the past, this approach has led to simpler and cleaner sublinear time lower bounds for many problems.  Attempts at such an approach for reducing the set-disjointness problem in communication complexity  to our estimation problem on graphs run into the following difficulties:\nFirst, as explained in \\cite{DBLP:journals/eccc/Goldreich13a}, the straightforward reduction adds a logarithmic overhead, thereby weakening\nthe lower bound by the same factor.  Second, the reduction seems to work only in the case of sparse graphs. Although it is not clear if these difficulties are insurmountable, it seems that it will not give a  simpler argument than the approach that we present in this work.}\n\nFor the directed case, we prove the lower bound using a standard construction and Yao's principle.\nAs for the upper bound when the in-degree and out-degree ratios are bounded,\nwe use rejection sampling to adjust the sampling probabilities so that we may apply the unbiased estimator method from the undirected case. \n\n\\subsection{Related Work}\n\nMotivated by applications in a variety of areas, the subgraph detection and counting problem and its variations have been studied in many different works,\noften under different terminology such as network motif counting or pathway querying (e.g., \\cite{milo2002network,prvzulj2004modeling,wernicke2006efficient,scott2006efficient,shlomi2006qpath,grochow2007network,hormozdiari2007not,hales2008motifs,alon2008biomolecular}).\nAs this problem is NP-hard in general, many approaches have been developed to efficiently count subgraphs more efficiently\nfor certain families of subgraphs or input graphs (e.g., \\cite{duke1995fast,alon1997finding,flum2004parameterized,kashtan2004efficient,alon2008biomolecular,alon2009balanced,vassilevska2009finding,williams2009finding,gonen2009approximating,kolountzakis2010efficient,ahn2012graph,amini2012counting,fomin2012faster}).\nAs for applications to database systems, the problem of approximating the size of the resulting table of a join query or a self-join query in various contexts has been studied in \\cite{swami1994estimation,haas1996selectivity,alon1999tracking}. Selectivity and query optimization have been considered, e.g., in \\cite{poosala1997selectivity,lee1999multi,getoor2001selectivity,markl2007consistent,haas2009discovering}.\n\nOther works that study sublinear-time algorithms for counting stars are \\cite{gonen2011counting} that aims to approximate the number of stars,\nand \\cite{feige2006sums,goldreich2008approximating} that aim to approximate the number of edges (or equivalently, the average degree).\nNote that \\cite{gonen2011counting} also shows impossibility results for approximating triangles and paths of length three in sublinear time when given uniform edge sampling, limiting us from studying more sophisticated subgraphs. Recent work by Eden, Levi and Ron (\\cite{eden2015approximately}) and Seshadhri (\\cite{seshadhri2015simpler}) provide sublinear time algorithms to approximate the number of triangles in a graph. However, their model uses adjacency matrix queries and neighbor queries.\nThe problem of counting subgraphs has also been studied in the streaming model (e.g., \\cite{bar2002reductions,buriol2006counting,becchetti2008efficient,manjunath2011approximate,kane2012counting}).\nThere is also a body of work on sublinear-time algorithms for approximating various graph parameters (e.g., \\cite{parnas2007approximating,nguyen2008constant,yoshida2009improved,hassidim2009local,onak2012near}).\n\nAbstracting away the graphical context of counting stars, we may view our problem as finding a parameter of a distribution:\nedge or vertex sampling can be treated as sampling according to some distribution. In vertex sampling, we have a uniform distribution and in edge sampling, the probabilities are proportional to the degree. The number of stars can be written as a function of the degrees.\nAside from our work, there are a number of other studies that make use of combined query types for estimating a parameter of a distribution.\nWeighted and uniform sampling are considered in \\cite{motwani2007estimating,batu2009sublinear}.\nTheir algorithms may be adapted to approximate the number of edges in the context of approximating graph parameters when given weighted vertex sampling, which we will later use in this paper.\nA closely related problem in the context of distributions, is the task of approximating frequency moments, mainly studied in the streaming model (e.g., \\cite{alon1996space,coppersmith2004improved,indyk2005optimal,bhuvanagiri2006simpler}).\nOn the other hand, the combination of weighted sampling and probability distribution queries is also considered (e.g., \\cite{canonne2014testing}).\n\n\n\\section{Preliminaries} \\label{prelim}\n\nIn this paper, we construct algorithms to approximate the number of stars in a graph under different types of query access to the input graph.\nAs we focus on the case of simple undirected graphs, we explain this model here and defer the description for the directed case to Appendix~\\ref{shortdir}.\n\n\n\\subsection{Graph Specification}\n\nLet $G=(V,E)$ be the input graph, assumed to be simple and undirected.\nLet $n$ and $m$ denote the number of vertices and edges, respectively.\n\nThe value $n$ is known to the algorithm.\nEach vertex $v\\in V$ is associated with a unique ID from $[n]{\\stackrel{\\rm def}{=}}\\{1,\\ldots,n\\}$.\nLet $\\deg(v)$ denote the degree of $v$.\n\nLet $p\\geq 2$ be a constant integer.\nA \\emph{$p$-star} is a subgraph of size $p+1$,\nwhere one vertex, called the \\emph{center}, is adjacent to the other $p$ vertices.\nFor example, a $2$-star is an undirected path of length 2.\nNote that a vertex may be a center for many stars, and a set of $p+1$ vertices may form multiple stars.\nLet $S_p$ denote the number of occurrences of distinct stars in the graph.\n\nOur goal is to construct a randomized algorithm that outputs a value that is within a $(1\\pm\\epsilon)$-multiplicative factor of the actual number of stars $S_p$.\nMore specifically, given a parameter $\\epsilon > 0$, the algorithm must give an approximated value $\\widehat{S}_p$ satisfying the inequality $(1-\\epsilon)S_p \\leq \\widehat{S}_p \\leq (1+\\epsilon)S_p$\nwith success probability at least $2/3$.\n\n\n\\subsection{Query Access} \\label{sampling}\n\nThe algorithm may access the input graph by querying the \\emph{graph oracle}, which answers for the following types of queries.\nFirst, the \\emph{neighbor queries}: given a vertex $v\\in V$ and an index $1 \\leq i < n$, the $i^{\\rm th}$ neighbor of $v$ is returned if $i \\leq \\deg (v)$; otherwise, $\\bot$ is returned.\nSecond, the \\emph{degree queries}: given a vertex $v \\in V$, its degree $\\deg(v)$ is returned.\n\nLastly, the \\emph{random edge queries}: a uniformly random edge $\\{u,v\\} \\in E$ is returned.\n\nThe \\emph{query complexity} of an algorithm is the total number of queries of any type that the algorithm makes throughout the process of computing its answer.\n\nCombining these queries, we may implement various useful sampling processes.\nWe may perform a \\emph{uniform edge sampling} using a random edge query, and a \\emph{uniform vertex sampling} by simply picking a random index from $[n]$.\nWe may also perform a \\emph{weighted vertex sampling} where each vertex is obtained with probability proportional to its degree as follows:\nuniformly sample a random edge, then randomly choose one of the endpoints with probability $1/2$ each.\nSince any vertex $v$ is incident with $\\deg(v)$ edges, then the probability that $v$ is chosen is exactly $\\deg(v)/2m$, as desired.\n\n\\subsection{Queries in the Database Model}\nNow we explain how the above queries in our graph model have direct interpretations in the database model.\nConsider the column we wish to join on.\nFor each valid label $i$, let $x_i$ be the number of rows containing this label.\nWe assume the ability to sample rows uniformly at random.\nThis gives us a label $i$ with probability proportional to $x_i$, which is a weighted sample from the distribution of labels.\nWe also assume that we can also quickly compute the number of other rows sharing the same label with a given row\n(analogous to making a degree query). For example, this could be done quickly using an index on the column. Note that if one has an index that is augmented with appropriate information, one can compute the selectivity of a self-join query exactly in time roughly $O(k \\log n)$ where $k$ is the number of distinct elements in the column. However, our methods can give runtimes that are asymptotically much smaller than this.\n\n\\section{Upper Bounds for Counting Stars in Undirected Graphs} \\label{upper-undirected}\n\nIn this section we establish an algorithm for approximating the number of stars, $S_p$, of an undirected input graph.\nWe focus on the case where only degree queries and random edge queries are allowed.\nThis illustrates that even without utilizing the underlying structure of the input graph,\nwe are still able to construct a sublinear approximation algorithm that outperforms other algorithms under the traditional model in certain cases.\n\n\\subsection{Unbiased Estimator Subroutine}  \\label{unbiased-sec}\n\nOur algorithm uses weighted vertex sampling to find stars.\nIntuitively, the number of samples required by the algorithms should be larger when stars are rare because it takes more queries to find them.\nWhile the query complexity of the algorithm depends on the actual value of $S_p$, our algorithm does not know this value in advance.\nIn order to overcome this issue, we devise a subroutine which---given a guess $\\widetilde{S}_p$ for the value of $S_p$---will give a $(1\\pm \\epsilon)$ approximation of $S_p$ if $\\widetilde{S}_p$ is close enough to $S_p$ or tell us that $\\widetilde{S}_p$ is much larger than $S_p$. Then, we start with the maximum possible value of $S_p$ and guess multiplicatively smaller and smaller values for it until we find one that is close enough to $S_p$, so that our subroutine is able to correctly output a $(1 \\pm \\epsilon)$ approximation.\n\nOur subroutine works by computing the average value of an unbiased estimator to $S_p$ after drawing enough weighted vertex samples.\nTo construct the unbiased estimator, notice first that the number of $p$-stars centered at a vertex $v$ is ${\\deg(v) \\choose p}$.\\footnote{For our counting purpose, if $x < y$ then we define ${x \\choose y} = 0$.}\nThus, $S_p = \\sum_{v\\in V} {\\deg(v) \\choose p}$.\n\nNext, we define the unbiased estimator and give the corresponding algorithm.\nFirst, let $X$ be the random variable representing the degree of a random vertex obtained through weighted vertex sampling, as explained in Section~\\ref{sampling}.\nRecall that a vertex $v$ is sampled with probability $\\deg(v)/2m$.\nWe define the random variable $Y = \\frac{2m}{X} {X \\choose p}$ so that $Y$ is an unbiased estimator for $S_p$; that is,\n", "index": 1, "text": "\n\\[E[Y]=\\sum_{v\\in V} \\frac{\\deg(v)}{2m}\\left(\\frac{2m}{\\deg(v)} {\\deg(v) \\choose p}\\right) = \\sum_{v\\in V} {\\deg(v) \\choose p} = S_p.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"E[Y]=\\sum_{v\\in V}\\frac{\\deg(v)}{2m}\\left(\\frac{2m}{\\deg(v)}{\\deg(v)\\choose p}%&#10;\\right)=\\sum_{v\\in V}{\\deg(v)\\choose p}=S_{p}.\" display=\"block\"><mrow><mrow><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>Y</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder><mrow><mfrac><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow><mo>=</mo><msub><mi>S</mi><mi>p</mi></msub></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\nFirst, let us consider the case where the stars are very rare, namely when $S_p \\leq n$.\nThe inequality above implies that $m \\leq np/2$. Substituting this formula back into the bound from Theorem \\ref{upper-m} yields the query complexity $\\tilde{{\\rm O}}(n\\,/\\,{\\epsilon^2 S_p^{1/p}})$.\n\nNow we consider the remaining case where $S_p > n$.\nIf $m < np/2 = {\\rm O}(n)$, then the query complexity from Theorem \\ref{upper-m} becomes $\\tilde{{\\rm O}}(n^{1-1/p}\\,/\\,{\\epsilon^2})$.\nOtherwise we have $2m/n \\geq p$, which allows us to apply the following bound on our binomial coefficient:\n", "itemtype": "equation", "pos": 33950, "prevtext": "\n\n\\begin{algorithm}\n\\label{alg:alg1}\n\\caption{Subroutine for Computing $S_p$ given $\\widetilde{S}_p$ with success probability 2/3}\\label{unbiased-algo}\n\\begin{algorithmic}[1]\n\\Procedure{Unbiased-Estimate}{$\\widetilde{S}_p, \\epsilon$}\n\t\\State{$k \\gets 36m\\,/\\,p \\epsilon^2\\widetilde{S}_p^{1/p}$}\n\t\\For {$i = 1$ to $k$}\n        \\State{$v \\gets $ weighted sampled vertex obtained from a random edge query}\n    \t  \\State{$d \\gets \\deg(v)$ obtained from a degree query}\n    \t  \\State{$Y_i \\gets \\frac{2m}{d} {d \\choose p}$}\n\t\\EndFor\n    \\State{ $\\bar{Y} \\gets \\frac{1}{k} \\sum_{i=1}^{k} Y_i$}\n    \\State{ \\textbf{return} $\\bar{Y} $}\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\nClearly, the output $\\bar{Y}$ of Algorithm~\\ref{unbiased-algo} satisfies $E[\\bar{Y}]=S_p$.\nWe claim that the number of samples $k$ in Algorithm \\ref{unbiased-algo} is sufficient to provide two desired properties:\nthe algorithm returns an $(1\\pm\\epsilon)$-approximation of $S_p$ if $\\widetilde{S}_p$ is in the correct range;\nor, if $\\widetilde{S}_p$ is too large, the anomaly will be evident as the output $\\bar{Y}$ will be much smaller than $\\widetilde{S}_p$.\nIn particular, we may distinguish between these two cases by comparing $\\bar{Y}$ against $(1-{\\epsilon})\\tilde{S}_p$, as specified through the following lemma. \n\n\n\\begin{restatable}{lem}{gwc} \\label{good-when-crude} \\label{found-when-fault}\nFor $0 < {\\epsilon} \\leq 1/2$, with probability at least 2/3:\n\\begin{enumerate}[noitemsep,nolistsep]\n\\item If $\\frac{1}{2}S_p \\leq \\widetilde{S}_p \\leq 6S_p$, then Algorithm \\ref{unbiased-algo} outputs $\\bar{Y}$ such that $(1-\\epsilon)S_p \\leq \\bar{Y} \\leq (1+\\epsilon)S_p$;\\\\\nmoreover, if $S_p < \\tilde{S}_p$ then $\\bar{Y} \\geq (1-\\epsilon)\\widetilde{S}_p$.\n\\item If $\\widetilde{S}_p > 6S_p$, then Algorithm \\ref{unbiased-algo} outputs $\\bar{Y}$ such that $\\bar{Y} < \\frac{1}{2}\\widetilde{S}_p \\leq (1-\\epsilon)\\widetilde{S}_p$.\n\\end{enumerate}\n\\end{restatable}\n\nThe first item of Lemma~\\ref{good-when-crude} can be proved by bounding the variance of $Y$ using various Chebyshev's Inequality and identities of binomial coefficients,\nwhile the second item is a simple application of Markov's Inequality.\nDetailed proofs for these statements can be found in Appendix~\\ref{upunpr}.\n\n\n\\subsection{Full Algorithm}\n\nOur full algorithm proceeds by first setting $\\widetilde{S}_p$ to $n{{n-1} \\choose p}$, the maximum possible value of $S_p$ given by the complete graph.\nWe then use Algorithm \\ref{unbiased-algo} to check if $\\widetilde{S}_p > 6S_p$; if this is the case, we reduce $\\widetilde{S}_p$ then proceed to the next iteration.\nOtherwise, Algorithm \\ref{unbiased-algo} should already give an $(1\\pm\\epsilon)$-approximation to $S_p$ (with constant probability).\nWe note that if $\\epsilon > 1/2$, we may replace it with $1/2$ without increasing the asymptotic complexity.\n\nSince the process above may take up to ${\\rm O}(\\log n)$ iterations,\nwe must amplify the success probability of Algorithm \\ref{unbiased-algo} so that the overall success probability is still at least $2/3$.\nTo do so, we simply make $\\ell = {\\rm O}(\\log \\log n)$ multiple calls to Algorithm \\ref{unbiased-algo} then take the median of the returned values.\nOur full algorithm can be described as Algorithm \\ref{full-algo} below.\n\n\\begin{algorithm}\n\\caption{Algorithm for Approximating $S_p$}\\label{full-algo}\n\\begin{algorithmic}[1]\n\\Procedure{Count-Stars}{$\\epsilon$}\n\t\\State{$\\widetilde{S}_p \\gets n{{n-1} \\choose p}, \\; \\ell \\gets 40(\\log p + \\log \\log n)$}\n\t\\Loop\n\t\\For {$i = 1$ to $\\ell$}\n        \\State{$Z_i \\gets \\textsc{Unbiased-Estimate}(\\widetilde{S}_p,\\epsilon)$}\n    \t\\EndFor\n    \t\\State{$Z \\gets \\textrm{median}\\{Z_1,\\cdots,Z_\\ell\\}$}\n        \\If {$Z \\geq (1-\\epsilon)\\widetilde{S}_p$}\n        \t\\State {$\\hat{S}_p \\gets Z$}\n            \\State {\\textbf{return} $\\hat{S}_p$}\n        \\EndIf\n\n\t\\State{$\\widetilde{S}_p \\gets \\widetilde{S}_p/2$}\n  \\EndLoop\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n\\begin{thm} \\label{upper-m}\nAlgorithm \\ref{full-algo} outputs $\\hat{S}_p$ such that $(1-\\epsilon)S_p \\leq \\hat{S}_p \\leq (1+\\epsilon)S_p$ with probability at least $2/3$. The query complexity of Algorithm \\ref{full-algo} is ${\\rm O}\\left(\\frac{m \\log n \\log \\log n}{\\epsilon^2 S_p^{1/p}}\\right)$.\n\\end{thm}\n\\begin{ourproof}\nIf we assume that the events from Lemma \\ref{good-when-crude} hold,\nthen the algorithm will take at most $\\lceil\\log \\left(n{{n-1} \\choose p}\\right)\\rceil \\leq (p+1) \\log n$ iterations.\nBy choosing $\\ell = 40(\\log p + \\log \\log n)$, Chernoff bound (Theorem \\ref{chernoff}) implies that excepted for probability $1/3(p+1) \\log n$,\nmore than half of the return values of Algorithm \\ref{unbiased-algo} satisfy the desired property, and so does the median $Z$.\nBy the union bound, the total failure probability is at most 1/3.\n\nNow it is safe to assume that the events from the two lemmas hold.\nIn case $\\widetilde{S}_p > 6S_p$, our algorithm will detect this event because $Z \\leq (1-\\epsilon)\\widetilde{S}_p$,\nimplying that we never stop and return an inaccurate approximation.\nOn the other hand, if $\\widetilde{S}_p < S_p$, our algorithm computes $Z \\geq  (1-\\epsilon)\\widetilde{S}_p$ and must terminate.\nSince we only halve $\\widetilde{S}_p$ on each iteration, when $\\widetilde{S}_p < S_p$ first occurs, we have $\\widetilde{S}_p \\geq \\frac{1}{2}S_p$.\nAs a result, our algorithm must terminate with the desired approximation before the value $\\widetilde{S}_p$ is halved again.\nThus, Algorithm \\ref{full-algo} returns $\\hat{S}_p$ satisfying $(1-\\epsilon)S_p \\leq \\hat{S}_p \\leq (1+\\epsilon)S_p$ with probability at least $2/3$, as desired.\n\nRecall that the number of samples required by Algorithm \\ref{unbiased-algo} may only increase when $\\widetilde{S}_p$ decreases.\nThus we may use the number of samples in the last round of Algorithm \\ref{full-algo}, where $\\widetilde{S}_p = \\Theta(S_p)$, as the upper bound for each previous iteration.\nTherefore, each of the ${\\rm O}(\\log n)$ iterations takes ${\\rm O}(m \\log \\log n \\,/\\, \\epsilon^2 S_p^{1/p})$ samples, achieving the claimed query complexity.\n\\end{ourproof}\n\n\\subsection{Removing the Dependence on $m$}\n\nAs described above, Algorithm \\ref{unbiased-algo} picks the value $k$ and defines the unbiased estimator based on $m$, the number of edges.\nNonetheless, it is possible to remove this assumption of having prior knowledge of $m$ by instead computing its approximation.\nFurthermore, we will bound $m$ in terms of $n$ and $S_p$, so that we can also relate the performance of our algorithm to previous studies on this problem such as \\cite{gonen2011counting}, as done in Table \\ref{undirected-results}.\n\n\\subsubsection{Approximating $m$} \\label{approx-m}\n\nWe briefly discuss how to apply our algorithm when $m$ is unknown by first computing an approximation of $m$.\nUsing weighted vertex sampling, we may simulate the algorithm from \\cite{motwani2007estimating} or \\cite{batu2009sublinear} that computes an $(1\\pm\\epsilon)$-approximation to the sum of degrees using $\\tilde{{\\rm O}}(\\sqrt{n})$ weighted samples.\nMore specifically, we cite the following theorem:\n\\begin{thm} (\\cite{motwani2007estimating})\nLet $x_1, \\ldots, x_n$ be $n$ variables,\nand define a distribution $\\mathcal{D}$ that returns $(i, x_i)$ with probability $x_i / \\sum_{i=1}^{n} x_j$.\nThere exists an algorithm that\ncomputes a $(1\\pm\\epsilon)$-approximation of $S = \\sum_{i=1}^{n} x_i$ using $\\tilde{\\rm O}(\\sqrt{n})$ samples from $\\mathcal{D}$.\n\\end{thm}\nThus, we simulate the sampling process from $\\mathcal{D}$ by drawing a weighted vertex sample $v$, querying its degree, and feeding $(v, \\deg(v))$ to this algorithm.\nWe will need to decrease $\\epsilon$ used in this algorithm and our algorithm by a constant factor to account for the additional error.\nBelow we show that our complexities are at least $\\tilde{{\\rm O}}(n^{1-1/p})$ which is already $\\tilde{{\\rm O}}(\\sqrt{n})$ for $p = 2$, and thus this extra step does not affect our algorithm's performance asymptotically.\n\n\\subsubsection{Comparing $m$ to $n$ and $S_p$}\n\nFor comparison of performances, we will now show some bounds relating $m$ to $n$ and $S_p$.\nNotice that the function ${\\deg(v) \\choose p}$ is convex with respect to $\\deg(v)$.\\footnote{We may use the binomial coefficients ${x \\choose y}$ for non-integral value $x$ in the inequalities.\nThese can be interpreted through alternative formulations of binomial coefficients using falling factorials or analytic functions.}\nThen by applying Jensen's inequality (Theorem \\ref{jensen}) to this function, we obtai\n", "index": 3, "text": "\\[S_p = \\sum_{v\\in V} {\\deg(v) \\choose p} \\geq n {{\\sum_{v\\in V} \\deg(v) / n } \\choose p} = n{2m/n\\choose p}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"S_{p}=\\sum_{v\\in V}{\\deg(v)\\choose p}\\geq n{{\\sum_{v\\in V}\\deg(v)/n}\\choose p}%&#10;=n{2m/n\\choose p}.\" display=\"block\"><mrow><mrow><msub><mi>S</mi><mi>p</mi></msub><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder><mrow><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><mi>n</mi></mrow></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>/</mo><mi>n</mi></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nThis inequality implies that $m \\leq pn^{1-1/p}S_p^{1/p}/2$, also yielding the query complexity $\\tilde{{\\rm O}}(n^{1-1/p}\\,/\\,{\\epsilon^2})$.\n\nCompared to \\cite{gonen2011counting}, our algorithm achieves a better query complexity when $S_p \\leq n^{1+1/p}$,\nwhere the rare stars are more likely to be found via edge sampling rather than uniform vertex sampling or traversing the graph.\nOur algorithm also performs no worse than their algorithm does for any $S_p$ as large as $n^p$.\nMoreover, due to the simplicity of our algorithm, the dependence on $\\epsilon$ of our query complexity is only $1/\\epsilon^2$ for any value of $S_p$,\nwhile that of their algorithm is as large as $1/\\epsilon^{10}$ in certain cases.\nThis dependence on $\\epsilon$ may be of interest to some applications, especially when stars are rare whilst an accurate approximation of $S_p$ is crucial.\n\n\\subsection{Allowing Neighbor Queries}\n\nWe now briefly discuss how we may improve our algorithm when neighbor queries are allowed (in addition to degree queries and random edge queries).\nFor the case when $S_p > n^p$, it is unknown whether our algorithm alone achieves better performance than \\cite{gonen2011counting} (see table \\ref{undirected-results}).\nHowever, their algorithm has the same basic framework as ours, namely that it also starts by setting $\\widetilde{S}_p$ to the maximum possible number of stars,\nthen iteratively halves this value until it is in the correct range, allowing the subroutine to correctly compute a $(1\\pm\\epsilon)$-approximation of $S_p$.\nAs a result, we may achieve the same performance as them in this regime by simply letting Algorithm \\ref{full-algo} call the subroutine from \\cite{gonen2011counting} when $S_p \\geq n^p$.\nWe will later show tight lower bounds (up to polylogarithmic factors)\nto the case where all three types of queries are allowed,\nwhich is a stronger model than the one previously studied in their work.\n\n\nIn this section, we establish the lower bounds summarized in the last two columns of Table \\ref{undirected-results}.\n We give lower bounds that apply even when the algorithm is permitted to sample random edges.\nOur first lower bound is proved in Section \\ref{smallcase};\nWhile this is the simplest case, it provides useful intuition for the proofs of subsequent bounds.\nIn order to overcome the new obstacle of powerful queries in our model, for larger values of $S_p$\nwe create an explicit scheme for constructing families of graphs that are hard to distinguish by any algorithm even when these queries are present.\n\n\nUsing this construction scheme, our approach obtains the bounds for all remaining ranges for $S_p$ as special cases of a more general bound,\nand the general bound is proved via the straightforward application of Yao's principle and a coupling argument.\n\nOur lower bounds are tight (up to polylogarithmic factors) for all cases except for the bottom middle cell in Table \\ref{undirected-results}.\n\n\\subsection{Lower Bound for $S_p \\leq n$} \\label{smallcase}\n\n\n\\begin{thm} \\label{thm-small-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega(n/S_p^{1/p})$ total number of queries for any $S_p \\leq n^p$.\n\\end{thm}\n\n\n\\begin{ourproof}\nWe now construct two families of graphs, namely $\\mathcal{F}_1$ and $\\mathcal{F}_2$, such that any $G_1$ and $G_2$ drawn from each respective family satisfy $S_p(G_1)=0$ and $S_p(G_2)=\\Theta(s)$ for some parameter $s > (p+1)^p = O(1)$.\nWe construct $G_1$ as follows:\nfor a subset $S \\subseteq V$ of size $\\lceil s^{1/p} \\rceil +1$,\nwe create a union of a $(p-1)$-regular graph on $S$ and a $(p-1)$-regular graph on $V \\setminus S$, and add the resulting graph $G_1$ to $\\mathcal{F}_1$. To construct all graphs in $\\mathcal{F}_1$, we repeat this process for every subset $S$ of size $\\lceil s^{1/p} \\rceil +1$.\n$\\mathcal{F}_2$ is constructed a little differently:\nrather than using a $(p-1)$-regular graph on $S$, we use a star of size $\\lceil s^{1/p} \\rceil$ on this set instead.\nWe add a union between a star on $S$ and a $(p-1)$-regular graph on $V \\setminus S$ of any possible combination to $\\mathcal{F}_2$.\n\n\nBy construction, every $G_1\\in\\mathcal{F}_1$ contains no $p$-stars, whereas every $G_2\\in\\mathcal{F}_2$ has ${{{\\rm O}(s^{1/p})} \\choose {p} } = \\Theta(s)$ $p$-stars.\nFor any algorithm to distinguish between $\\mathcal{F}_1$ and $\\mathcal{F}_2$, when given a graph $G_2 \\in \\mathcal{F}_2$,\nit must be able to detect some vertex in $S$ with probability at least $2/3$.\nOtherwise, if we randomly generate a small induced subgraph according to the uniform distribution in $\\mathcal{F}_2$ conditional on not having any vertex or edge in $S$, the distribution would be identical to the uniform in $\\mathcal{F}_1$.\n\n\nFurthermore, notice that $S$ cannot be reached via traversal using neighbor queries as it is disconnected from $V\\setminus S$.\nThe probability of sampling such vertex or edge from each query is ${\\rm O}(s^{1/p}/n)$.\nThus, $\\Omega(n/s^{1/p})$ samples are required to achieve a constant factor approximation with probability 2/3.\n\\end{ourproof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Overview of the Lower Bound Proof for $S_p > n$} \\label{largeboundsec}\n\nSince graphs with large $S_p$ contain many edges, we must modify our approach above to allow graphs from the first family to contain stars.\nWe construct two families of graphs $\\mathcal{F}_1$ and $\\mathcal{F}_2$ such that the number of stars of graphs from these families differ by some multiplicative factor $c>1$;\nany algorithm aiming to approximate $S_p$ within a multiplicative factor of $\\sqrt{c}$ must distinguish between these two families with probability at least $2/3$.\nWe create \\emph{representations} of graphs that explicitly specify their adjacency list structure.\nEach $G_1 \\in \\mathcal{F}_1$ contains $n_1$ vertices of degree $d_1$, while the remaining $n_2 = n-n_1$ vertices are isolated.\nFor each $G_2\\in \\mathcal{F}_2$, we modify our representation from $\\mathcal{F}_1$ by connecting each of the remaining $n_2$ vertices to $d_2 \\gg d_1$ neighbors, so that these vertices contribute sufficient stars to establish the desired difference in $S_p$.\nWe hide these additional edges in carefully chosen random locations while ensuring minimal disturbance to the original graph representation; our representations are still so similar that any algorithm may not detect them without making sufficiently many queries.\nMoreover, we define a coupling for answering random edge queries so that the same edges are likely to be returned regardless of the underlying graph. \n\nWhile the proof of \\cite{gonen2011counting} also uses similar families of graphs, our proof analysis greatly deviates from their proof as follows.\nFirstly, we apply Yao's principle which allows us to prove the lower bounds on randomized algorithms\nby instead showing the lower bound on deterministic algorithms on our carefully chosen distribution of input instances.\\footnote{See e.g., \\cite{motwani2010randomized} for more information on Yao's principle.}\nSecondly, rather than constructing two families of graphs via random processes,\nwe construct our graphs with adjacency list representations explicitly, satisfying the above conditions for each lower bound we aim to prove.\n\n\nThis allows us to avoid the difficulties in \\cite{gonen2011counting} regarding the generation of potential multiple edges and self-loops in the input instances.\nThirdly, we define the distribution of our instances based on the permutation of the representations of these two graphs, and the location we place the edges in $G_2$ that are absent in $G_1$.\nWe also apply the coupling argument, so that the distribution of these permutations we apply on these graphs, as well as the answers to random edge queries, are as similar as possible.\nAs long as the small difference between these graphs is not discovered, the interaction between the algorithm and our oracle must be exactly the same.\nWe show that with probability $1 - o(1)$, the algorithm and our oracle behave in exactly the same way whether the input instance corresponds to $G_1$ or $G_2$.\nSimplifying the arguments from \\cite{gonen2011counting}, we completely bypass the algorithm's ability to make use of graph structures.\nOur proof only requires some conditions on the parameters $n_1, d_1, n_2, d_2$;\nthis allows us to show the lower bounds for multiple ranges of $S_p$ simply by choosing appropriate parameters.\n\nWe provide the full details in Section ~\\ref{lowerproof}.\nThe main results of our constructions are given as the following theorems.\nWe note that lower bounds apply when only subsets of these three types of queries are provided. This concludes all of our lower bounds in Table \\ref{undirected-results}.\n\n\\begin{thm} \\label{thm-medium-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries  with probability of success at least $2/3$ requires $\\Omega(n^{1-1/p})$ total number of queries for any $S_p = {\\rm O}(n^p)$.\n\\end{thm} \n\\begin{thm} \\label{thm-large-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega\\left(\\frac{n^{p-1/p}}{S_p^{1-1/p}}\\right)$ total number of queries for any $S_p=\\Omega(n^p)$.  \n\\end{thm}\n\n\n\n\n\n\n\n\\section{Acknowledgements}\n\nThis material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No.~CCF-1217423, CCF-1065125, CCF-1420692, and CCF-1122374.\nAny opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.\nWe thank Peter Haas and Samuel Madden for helpful discussions.\n\n\\ifnum{0}=0\n\\bibliographystyle{alpha}\n\\else\n\\bibliographystyle{plain}\n\\fi\n\n\\bibliography{bib}\n\n\\appendix\n\\section{Useful Inequalities}\n\nThis section provides standard equalities that we use throughout our paper. These inequalities exist in many variations, but here we only present the formulations which are most convenient for our purposes.\n\n\\begin{thm} \\label{chebyshev} (Chebyshev's Inequality)\nFor any random variable $X$ and $a > 0$,\n", "itemtype": "equation", "pos": 34646, "prevtext": "\n\nFirst, let us consider the case where the stars are very rare, namely when $S_p \\leq n$.\nThe inequality above implies that $m \\leq np/2$. Substituting this formula back into the bound from Theorem \\ref{upper-m} yields the query complexity $\\tilde{{\\rm O}}(n\\,/\\,{\\epsilon^2 S_p^{1/p}})$.\n\nNow we consider the remaining case where $S_p > n$.\nIf $m < np/2 = {\\rm O}(n)$, then the query complexity from Theorem \\ref{upper-m} becomes $\\tilde{{\\rm O}}(n^{1-1/p}\\,/\\,{\\epsilon^2})$.\nOtherwise we have $2m/n \\geq p$, which allows us to apply the following bound on our binomial coefficient:\n", "index": 5, "text": "\n\\[S_p  \\geq n{2m/n\\choose p} \\geq n\\left(\\frac{2m}{np}\\right)^p.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"S_{p}\\geq n{2m/n\\choose p}\\geq n\\left(\\frac{2m}{np}\\right)^{p}.\" display=\"block\"><mrow><mrow><msub><mi>S</mi><mi>p</mi></msub><mo>\u2265</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>/</mo><mi>n</mi></mrow><mi>p</mi></mfrac><mo>)</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>n</mi><mo>\u2062</mo><msup><mrow><mo>(</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>n</mi><mo>\u2062</mo><mi>p</mi></mrow></mfrac><mo>)</mo></mrow><mi>p</mi></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\\end{thm}\n\n\\begin{thm} \\label{markov} (Markov's Inequality)\nFor any non-negative random variable $X$ and $a > 0$,\n", "itemtype": "equation", "pos": 45221, "prevtext": "\nThis inequality implies that $m \\leq pn^{1-1/p}S_p^{1/p}/2$, also yielding the query complexity $\\tilde{{\\rm O}}(n^{1-1/p}\\,/\\,{\\epsilon^2})$.\n\nCompared to \\cite{gonen2011counting}, our algorithm achieves a better query complexity when $S_p \\leq n^{1+1/p}$,\nwhere the rare stars are more likely to be found via edge sampling rather than uniform vertex sampling or traversing the graph.\nOur algorithm also performs no worse than their algorithm does for any $S_p$ as large as $n^p$.\nMoreover, due to the simplicity of our algorithm, the dependence on $\\epsilon$ of our query complexity is only $1/\\epsilon^2$ for any value of $S_p$,\nwhile that of their algorithm is as large as $1/\\epsilon^{10}$ in certain cases.\nThis dependence on $\\epsilon$ may be of interest to some applications, especially when stars are rare whilst an accurate approximation of $S_p$ is crucial.\n\n\\subsection{Allowing Neighbor Queries}\n\nWe now briefly discuss how we may improve our algorithm when neighbor queries are allowed (in addition to degree queries and random edge queries).\nFor the case when $S_p > n^p$, it is unknown whether our algorithm alone achieves better performance than \\cite{gonen2011counting} (see table \\ref{undirected-results}).\nHowever, their algorithm has the same basic framework as ours, namely that it also starts by setting $\\widetilde{S}_p$ to the maximum possible number of stars,\nthen iteratively halves this value until it is in the correct range, allowing the subroutine to correctly compute a $(1\\pm\\epsilon)$-approximation of $S_p$.\nAs a result, we may achieve the same performance as them in this regime by simply letting Algorithm \\ref{full-algo} call the subroutine from \\cite{gonen2011counting} when $S_p \\geq n^p$.\nWe will later show tight lower bounds (up to polylogarithmic factors)\nto the case where all three types of queries are allowed,\nwhich is a stronger model than the one previously studied in their work.\n\n\nIn this section, we establish the lower bounds summarized in the last two columns of Table \\ref{undirected-results}.\n We give lower bounds that apply even when the algorithm is permitted to sample random edges.\nOur first lower bound is proved in Section \\ref{smallcase};\nWhile this is the simplest case, it provides useful intuition for the proofs of subsequent bounds.\nIn order to overcome the new obstacle of powerful queries in our model, for larger values of $S_p$\nwe create an explicit scheme for constructing families of graphs that are hard to distinguish by any algorithm even when these queries are present.\n\n\nUsing this construction scheme, our approach obtains the bounds for all remaining ranges for $S_p$ as special cases of a more general bound,\nand the general bound is proved via the straightforward application of Yao's principle and a coupling argument.\n\nOur lower bounds are tight (up to polylogarithmic factors) for all cases except for the bottom middle cell in Table \\ref{undirected-results}.\n\n\\subsection{Lower Bound for $S_p \\leq n$} \\label{smallcase}\n\n\n\\begin{thm} \\label{thm-small-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega(n/S_p^{1/p})$ total number of queries for any $S_p \\leq n^p$.\n\\end{thm}\n\n\n\\begin{ourproof}\nWe now construct two families of graphs, namely $\\mathcal{F}_1$ and $\\mathcal{F}_2$, such that any $G_1$ and $G_2$ drawn from each respective family satisfy $S_p(G_1)=0$ and $S_p(G_2)=\\Theta(s)$ for some parameter $s > (p+1)^p = O(1)$.\nWe construct $G_1$ as follows:\nfor a subset $S \\subseteq V$ of size $\\lceil s^{1/p} \\rceil +1$,\nwe create a union of a $(p-1)$-regular graph on $S$ and a $(p-1)$-regular graph on $V \\setminus S$, and add the resulting graph $G_1$ to $\\mathcal{F}_1$. To construct all graphs in $\\mathcal{F}_1$, we repeat this process for every subset $S$ of size $\\lceil s^{1/p} \\rceil +1$.\n$\\mathcal{F}_2$ is constructed a little differently:\nrather than using a $(p-1)$-regular graph on $S$, we use a star of size $\\lceil s^{1/p} \\rceil$ on this set instead.\nWe add a union between a star on $S$ and a $(p-1)$-regular graph on $V \\setminus S$ of any possible combination to $\\mathcal{F}_2$.\n\n\nBy construction, every $G_1\\in\\mathcal{F}_1$ contains no $p$-stars, whereas every $G_2\\in\\mathcal{F}_2$ has ${{{\\rm O}(s^{1/p})} \\choose {p} } = \\Theta(s)$ $p$-stars.\nFor any algorithm to distinguish between $\\mathcal{F}_1$ and $\\mathcal{F}_2$, when given a graph $G_2 \\in \\mathcal{F}_2$,\nit must be able to detect some vertex in $S$ with probability at least $2/3$.\nOtherwise, if we randomly generate a small induced subgraph according to the uniform distribution in $\\mathcal{F}_2$ conditional on not having any vertex or edge in $S$, the distribution would be identical to the uniform in $\\mathcal{F}_1$.\n\n\nFurthermore, notice that $S$ cannot be reached via traversal using neighbor queries as it is disconnected from $V\\setminus S$.\nThe probability of sampling such vertex or edge from each query is ${\\rm O}(s^{1/p}/n)$.\nThus, $\\Omega(n/s^{1/p})$ samples are required to achieve a constant factor approximation with probability 2/3.\n\\end{ourproof}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Overview of the Lower Bound Proof for $S_p > n$} \\label{largeboundsec}\n\nSince graphs with large $S_p$ contain many edges, we must modify our approach above to allow graphs from the first family to contain stars.\nWe construct two families of graphs $\\mathcal{F}_1$ and $\\mathcal{F}_2$ such that the number of stars of graphs from these families differ by some multiplicative factor $c>1$;\nany algorithm aiming to approximate $S_p$ within a multiplicative factor of $\\sqrt{c}$ must distinguish between these two families with probability at least $2/3$.\nWe create \\emph{representations} of graphs that explicitly specify their adjacency list structure.\nEach $G_1 \\in \\mathcal{F}_1$ contains $n_1$ vertices of degree $d_1$, while the remaining $n_2 = n-n_1$ vertices are isolated.\nFor each $G_2\\in \\mathcal{F}_2$, we modify our representation from $\\mathcal{F}_1$ by connecting each of the remaining $n_2$ vertices to $d_2 \\gg d_1$ neighbors, so that these vertices contribute sufficient stars to establish the desired difference in $S_p$.\nWe hide these additional edges in carefully chosen random locations while ensuring minimal disturbance to the original graph representation; our representations are still so similar that any algorithm may not detect them without making sufficiently many queries.\nMoreover, we define a coupling for answering random edge queries so that the same edges are likely to be returned regardless of the underlying graph. \n\nWhile the proof of \\cite{gonen2011counting} also uses similar families of graphs, our proof analysis greatly deviates from their proof as follows.\nFirstly, we apply Yao's principle which allows us to prove the lower bounds on randomized algorithms\nby instead showing the lower bound on deterministic algorithms on our carefully chosen distribution of input instances.\\footnote{See e.g., \\cite{motwani2010randomized} for more information on Yao's principle.}\nSecondly, rather than constructing two families of graphs via random processes,\nwe construct our graphs with adjacency list representations explicitly, satisfying the above conditions for each lower bound we aim to prove.\n\n\nThis allows us to avoid the difficulties in \\cite{gonen2011counting} regarding the generation of potential multiple edges and self-loops in the input instances.\nThirdly, we define the distribution of our instances based on the permutation of the representations of these two graphs, and the location we place the edges in $G_2$ that are absent in $G_1$.\nWe also apply the coupling argument, so that the distribution of these permutations we apply on these graphs, as well as the answers to random edge queries, are as similar as possible.\nAs long as the small difference between these graphs is not discovered, the interaction between the algorithm and our oracle must be exactly the same.\nWe show that with probability $1 - o(1)$, the algorithm and our oracle behave in exactly the same way whether the input instance corresponds to $G_1$ or $G_2$.\nSimplifying the arguments from \\cite{gonen2011counting}, we completely bypass the algorithm's ability to make use of graph structures.\nOur proof only requires some conditions on the parameters $n_1, d_1, n_2, d_2$;\nthis allows us to show the lower bounds for multiple ranges of $S_p$ simply by choosing appropriate parameters.\n\nWe provide the full details in Section ~\\ref{lowerproof}.\nThe main results of our constructions are given as the following theorems.\nWe note that lower bounds apply when only subsets of these three types of queries are provided. This concludes all of our lower bounds in Table \\ref{undirected-results}.\n\n\\begin{thm} \\label{thm-medium-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries  with probability of success at least $2/3$ requires $\\Omega(n^{1-1/p})$ total number of queries for any $S_p = {\\rm O}(n^p)$.\n\\end{thm} \n\\begin{thm} \\label{thm-large-bound}\nFor any constant $p \\geq 2$, any (randomized) algorithm for approximating $S_p$ to a multiplicative factor via neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega\\left(\\frac{n^{p-1/p}}{S_p^{1-1/p}}\\right)$ total number of queries for any $S_p=\\Omega(n^p)$.  \n\\end{thm}\n\n\n\n\n\n\n\n\\section{Acknowledgements}\n\nThis material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No.~CCF-1217423, CCF-1065125, CCF-1420692, and CCF-1122374.\nAny opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.\nWe thank Peter Haas and Samuel Madden for helpful discussions.\n\n\\ifnum{0}=0\n\\bibliographystyle{alpha}\n\\else\n\\bibliographystyle{plain}\n\\fi\n\n\\bibliography{bib}\n\n\\appendix\n\\section{Useful Inequalities}\n\nThis section provides standard equalities that we use throughout our paper. These inequalities exist in many variations, but here we only present the formulations which are most convenient for our purposes.\n\n\\begin{thm} \\label{chebyshev} (Chebyshev's Inequality)\nFor any random variable $X$ and $a > 0$,\n", "index": 7, "text": "\n\\[{\\rm P}[|X - {\\rm E}[X]| \\geq a] \\leq \\frac{{\\mbox{\\bf\\rm Var}}[X]}{a^2}\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"{\\rm P}[|X-{\\rm E}[X]|\\geq a]\\leq\\frac{{\\mbox{\\bf\\rm Var}}[X]}{a^{2}}\" display=\"block\"><mrow><mi mathvariant=\"normal\">P</mi><mrow><mo stretchy=\"false\">[</mo><mo stretchy=\"false\">|</mo><mi>X</mi><mo>-</mo><mi mathvariant=\"normal\">E</mi><mrow><mo stretchy=\"false\">[</mo><mi>X</mi><mo stretchy=\"false\">]</mo></mrow><mo stretchy=\"false\">|</mo><mo>\u2265</mo><mi>a</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2264</mo><mfrac><mrow><mtext>Var</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>X</mi><mo stretchy=\"false\">]</mo></mrow></mrow><msup><mi>a</mi><mn>2</mn></msup></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\\end{thm}\n\n\\begin{thm} \\label{chernoff} (Chernoff Bound)\nLet $X_1, \\cdots, X_n$ be independent Poisson random variables such that ${\\rm P}[X_i = 1] = p$ for all $i \\in [n]$, and let $X = \\frac{1}{n}\\sum_{i=1}^{n} X_i$.\nThen for any $0 < \\delta \\leq 1$,\n", "itemtype": "equation", "pos": 45412, "prevtext": "\n\\end{thm}\n\n\\begin{thm} \\label{markov} (Markov's Inequality)\nFor any non-negative random variable $X$ and $a > 0$,\n", "index": 9, "text": "\n\\[{\\rm P}[X \\geq  a] \\leq \\frac{{\\rm E}[X]}{a}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"{\\rm P}[X\\geq a]\\leq\\frac{{\\rm E}[X]}{a}.\" display=\"block\"><mrow><mi mathvariant=\"normal\">P</mi><mrow><mo stretchy=\"false\">[</mo><mi>X</mi><mo>\u2265</mo><mi>a</mi><mo stretchy=\"false\">]</mo></mrow><mo>\u2264</mo><mfrac><mrow><mi mathvariant=\"normal\">E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>X</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mi>a</mi></mfrac><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\\end{thm}\n\n\\begin{thm} \\label{jensen} (Jensen's Inequality)\nFor any real convex function $f$ with $x_1, \\cdots, x_n$ in its domain,\n", "itemtype": "equation", "pos": 45715, "prevtext": "\n\\end{thm}\n\n\\begin{thm} \\label{chernoff} (Chernoff Bound)\nLet $X_1, \\cdots, X_n$ be independent Poisson random variables such that ${\\rm P}[X_i = 1] = p$ for all $i \\in [n]$, and let $X = \\frac{1}{n}\\sum_{i=1}^{n} X_i$.\nThen for any $0 < \\delta \\leq 1$,\n", "index": 11, "text": "\n\\[{\\rm P}[X > (1+\\delta) p] < e^{-\\delta^2pn/3}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"{\\rm P}[X&gt;(1+\\delta)p]&lt;e^{-\\delta^{2}pn/3}.\" display=\"block\"><mrow><mi mathvariant=\"normal\">P</mi><mrow><mo stretchy=\"false\">[</mo><mi>X</mi><mo>&gt;</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mi>\u03b4</mi><mo stretchy=\"false\">)</mo></mrow><mi>p</mi><mo stretchy=\"false\">]</mo></mrow><mo>&lt;</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mrow><msup><mi>\u03b4</mi><mn>2</mn></msup><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>n</mi></mrow><mo>/</mo><mn>3</mn></mrow></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\\end{thm}\n\n\\section{Proof of Lemma~\\ref{good-when-crude}} \\label{upunpr}\n\n\\gwc*\n\\begin{ourproof}\nLet us first consider the first item.\nSince ${\\mbox{\\bf\\rm Var}}[Y] \\leq {\\rm E}[Y^2]$, we will focus on establishing an upper bound of ${\\rm E}[Y^2]$.\nWe compute\n\n", "itemtype": "equation", "pos": 45898, "prevtext": "\n\\end{thm}\n\n\\begin{thm} \\label{jensen} (Jensen's Inequality)\nFor any real convex function $f$ with $x_1, \\cdots, x_n$ in its domain,\n", "index": 13, "text": "\n\\[\\sum_{i=1}^n f(x_i) \\geq n f\\left(\\sum_{i=1}^n x_i\\right)\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\sum_{i=1}^{n}f(x_{i})\\geq nf\\left(\\sum_{i=1}^{n}x_{i}\\right)\" display=\"block\"><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2265</mo><mrow><mi>n</mi><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nwhere the first inequality holds because $(\\deg(v))^p \\geq {\\deg(v) \\choose p}$.\nRearranging the terms, we have the following relationship:\n", "itemtype": "equation", "pos": 46221, "prevtext": "\n\\end{thm}\n\n\\section{Proof of Lemma~\\ref{good-when-crude}} \\label{upunpr}\n\n\\gwc*\n\\begin{ourproof}\nLet us first consider the first item.\nSince ${\\mbox{\\bf\\rm Var}}[Y] \\leq {\\rm E}[Y^2]$, we will focus on establishing an upper bound of ${\\rm E}[Y^2]$.\nWe compute\n\n", "index": 15, "text": "\\begin{align*}\n {\\rm E}[Y^2] &= \\sum_{v\\in V} \\frac{\\deg(v)}{2m}\\left(\\frac{2m}{\\deg(v)} {\\deg(v) \\choose p}\\right)^2  \n = 2m \\sum_{v\\in V} \\frac{1}{\\deg(v)} {\\deg(v) \\choose p}^2\\\\\n&\\leq 2m \\sum_{v\\in V} {\\deg(v) \\choose p}^{2-1/p}\n\\leq 2m \\left( \\sum_{v\\in V} {\\deg(v) \\choose p} \\right)^{2-1/p}\n= 2m S_p^{2-1/p},\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm E}[Y^{2}]\" display=\"inline\"><mrow><mi mathvariant=\"normal\">E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msup><mi>Y</mi><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{v\\in V}\\frac{\\deg(v)}{2m}\\left(\\frac{2m}{\\deg(v)}{\\deg(v)%&#10;\\choose p}\\right)^{2}=2m\\sum_{v\\in V}\\frac{1}{\\deg(v)}{\\deg(v)\\choose p}^{2}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>=</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><msup><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac></mstyle><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq 2m\\sum_{v\\in V}{\\deg(v)\\choose p}^{2-1/p}\\leq 2m\\left(\\sum_{%&#10;v\\in V}{\\deg(v)\\choose p}\\right)^{2-1/p}=2mS_{p}^{2-1/p},\" display=\"inline\"><mrow><mrow><mi/><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder></mstyle><msup><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac></mstyle><mo>)</mo></mrow><mrow><mn>2</mn><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></mrow></msup></mrow></mrow><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>v</mi><mo>\u2208</mo><mi>V</mi></mrow></munder></mstyle><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mrow><mi>deg</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>p</mi></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mrow><mn>2</mn><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></mrow></msup></mrow><mo>=</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><msubsup><mi>S</mi><mi>p</mi><mrow><mn>2</mn><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></mrow></msubsup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\nNow let us consider our average $\\bar{Y}$.\nSince $Y_i$ are identically distributed, we have\n", "itemtype": "equation", "pos": 46689, "prevtext": "\nwhere the first inequality holds because $(\\deg(v))^p \\geq {\\deg(v) \\choose p}$.\nRearranging the terms, we have the following relationship:\n", "index": 17, "text": "\n\\[\\frac{{\\rm E}[Y^2]}{S_p^{2}}\n\\leq \\frac{2m}{p S_p^{1/p}}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\frac{{\\rm E}[Y^{2}]}{S_{p}^{2}}\\leq\\frac{2m}{pS_{p}^{1/p}}.\" display=\"block\"><mrow><mrow><mfrac><mrow><mi mathvariant=\"normal\">E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msup><mi>Y</mi><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow></mrow><msubsup><mi>S</mi><mi>p</mi><mn>2</mn></msubsup></mfrac><mo>\u2264</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>p</mi><mo>\u2062</mo><msubsup><mi>S</mi><mi>p</mi><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msubsup></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nBy Chebyshev's inequality (Theorem \\ref{chebyshev}), we have\n", "itemtype": "equation", "pos": 46844, "prevtext": "\n\nNow let us consider our average $\\bar{Y}$.\nSince $Y_i$ are identically distributed, we have\n", "index": 19, "text": "\n\\[{\\mbox{\\bf\\rm Var}}[\\bar{Y}]\n={\\mbox{\\bf\\rm Var}}\\left[\\frac{1}{k}\\sum_{i=1}^{k}Y_i\\right]\n=\\frac{1}{k^2}{\\mbox{\\bf\\rm Var}}\\left[\\sum_{i=1}^{k}Y_i\\right]\n=\\frac{1}{k}{\\mbox{\\bf\\rm Var}}[Y]\\leq\\frac{1}{k}{\\rm E}[Y^2].\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"{\\mbox{\\bf\\rm Var}}[\\bar{Y}]={\\mbox{\\bf\\rm Var}}\\left[\\frac{1}{k}\\sum_{i=1}^{k%&#10;}Y_{i}\\right]=\\frac{1}{k^{2}}{\\mbox{\\bf\\rm Var}}\\left[\\sum_{i=1}^{k}Y_{i}%&#10;\\right]=\\frac{1}{k}{\\mbox{\\bf\\rm Var}}[Y]\\leq\\frac{1}{k}{\\rm E}[Y^{2}].\" display=\"block\"><mrow><mrow><mrow><mtext>Var</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>Y</mi><mo stretchy=\"false\">\u00af</mo></mover><mo stretchy=\"false\">]</mo></mrow></mrow><mo>=</mo><mrow><mtext>Var</mtext><mo>\u2062</mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>Y</mi><mi>i</mi></msub></mrow></mrow><mo>]</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msup><mi>k</mi><mn>2</mn></msup></mfrac><mo>\u2062</mo><mtext>Var</mtext><mo>\u2062</mo><mrow><mo>[</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>Y</mi><mi>i</mi></msub></mrow><mo>]</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mtext>Var</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>Y</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>\u2264</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mi mathvariant=\"normal\">E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msup><mi>Y</mi><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nIn order to achieve the desired value $\\bar{Y}$ such that $(1-\\epsilon)S_p \\leq \\bar{Y} \\leq (1+\\epsilon)S_p$ with error probability $1/3$, it is sufficient to take $6m\\,/\\,{p \\epsilon^2 S_p^{1/p}}$\nsamples.\nRecall the assumption that $\\widetilde{S}_p$ satisfying $\\frac{1}{2}S_p \\leq \\widetilde{S}_p \\leq 6S_p$.\nThus, the number of required samples to achieve such bound with probability $1/3$ is \n", "itemtype": "equation", "pos": 47127, "prevtext": "\nBy Chebyshev's inequality (Theorem \\ref{chebyshev}), we have\n", "index": 21, "text": "\n\\[{\\rm Pr}[|\\bar{Y}-{\\rm E}[\\bar{Y}]|\\geq\\epsilon S_p]\n\\leq\\frac{{\\mbox{\\bf\\rm Var}}[\\bar{Y}]}{\\epsilon^2 S_p^2}\n\\leq \\frac{1}{k}\\cdot\\frac{2m}{p \\epsilon^2 S_p^{1/p}}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"{\\rm Pr}[|\\bar{Y}-{\\rm E}[\\bar{Y}]|\\geq\\epsilon S_{p}]\\leq\\frac{{\\mbox{\\bf\\rm&#10;Var%&#10;}}[\\bar{Y}]}{\\epsilon^{2}S_{p}^{2}}\\leq\\frac{1}{k}\\cdot\\frac{2m}{p\\epsilon^{2}%&#10;S_{p}^{1/p}}.\" display=\"block\"><mrow><mi>Pr</mi><mrow><mo stretchy=\"false\">[</mo><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>Y</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>-</mo><mi mathvariant=\"normal\">E</mi><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>Y</mi><mo stretchy=\"false\">\u00af</mo></mover><mo stretchy=\"false\">]</mo></mrow><mo stretchy=\"false\">|</mo><mo>\u2265</mo><mi>\u03f5</mi><msub><mi>S</mi><mi>p</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2264</mo><mfrac><mrow><mtext>Var</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>Y</mi><mo stretchy=\"false\">\u00af</mo></mover><mo stretchy=\"false\">]</mo></mrow></mrow><mrow><msup><mi>\u03f5</mi><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi>S</mi><mi>p</mi><mn>2</mn></msubsup></mrow></mfrac><mo>\u2264</mo><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u22c5</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>p</mi><mo>\u2062</mo><msup><mi>\u03f5</mi><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi>S</mi><mi>p</mi><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msubsup></mrow></mfrac><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nFor the second item, we apply Markov's Inequality (Theorem \\ref{markov}) to the given condition to obtain\n", "itemtype": "equation", "pos": 47697, "prevtext": "\nIn order to achieve the desired value $\\bar{Y}$ such that $(1-\\epsilon)S_p \\leq \\bar{Y} \\leq (1+\\epsilon)S_p$ with error probability $1/3$, it is sufficient to take $6m\\,/\\,{p \\epsilon^2 S_p^{1/p}}$\nsamples.\nRecall the assumption that $\\widetilde{S}_p$ satisfying $\\frac{1}{2}S_p \\leq \\widetilde{S}_p \\leq 6S_p$.\nThus, the number of required samples to achieve such bound with probability $1/3$ is \n", "index": 23, "text": "\n\\[k = \\frac{36m}{p \\epsilon^2 \\widetilde{S}_p^{1/p}}.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"k=\\frac{36m}{p\\epsilon^{2}\\widetilde{S}_{p}^{1/p}}.\" display=\"block\"><mrow><mrow><mi>k</mi><mo>=</mo><mfrac><mrow><mn>36</mn><mo>\u2062</mo><mi>m</mi></mrow><mrow><mi>p</mi><mo>\u2062</mo><msup><mi>\u03f5</mi><mn>2</mn></msup><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msubsup></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\nimplying the desired success probability.\n\nLastly, we substitute ${\\epsilon} < 1/2$ to obtain the relationship between $\\bar{Y}$ and $(1-{\\epsilon})\\tilde{S}_p$,\nwhich establishes the condition for deciding whether the given $\\tilde{S}_p$ is much larger than $S_p$, as desired.\n\\end{ourproof}\n\n\\section{Proof of Lower Bounds for Undirected Graphs with $S_p > n$} \\label{lowerproof}\n\nIn this section we provide the proof of lower bounds claimed in Section~\\ref{largeboundsec}.\nFirstly, to properly describe the adjacency list representation of the input graphs, we introduce the notion of graph representation.\nNext, we state a main lemma (Lemma~\\ref{detlem}) that establishes the constraints of parameters $n_1, d_1, n_2, d_2$ that allows us to create hard instances.\nWe then move on to describe our constructions, including both the distribution for applying Yao's principle, and the implementation of the oracle for answering random edge queries.\nWe prove our main lemma for our construction, and lastly, we give the appropriate parameters that complete the proof of our lower bounds.\n\n\\subsection{Graph Representations}\n\nConsider the following \\emph{representation} $L$ of an adjacency list for an undirected graph $G$.\nLet us say that each vertex $v_i$ has $\\deg(v_i)$ ports numbered $1, \\ldots, \\deg(v)$ attached, where the $j^{\\rm th}$ port of vertex $v_i$ is identify as a pair $(i,j)$, which is used as an index for $L$.\n$L$ imposes a perfect matching between these ports; namely, $L(i_1,j_1) = (i_2, j_2)$ indicates that ports $(i_1,j_1)$ and $(i_2, j_2)$ are matched to each other, and this implies $L(i_2,j_2) = (i_1, j_1)$ as well.\nWe use $L$ to define the adjacency list of our graph; that is, if $L(i_1, j_1) = (i_2, j_2)$ then the $j_1^{\\rm th}$ neighbor of $v_{i_1}$ is $v_{i_2}$ (and vice versa).\nNote that there can be many such representations of $G$, and some perfect matchings between ports may yield graphs parallel edges or self-loops.\nFurthermore, each edge $e$ is associated with a unique pair of matched cells.\n\n\\subsection{Main Lemma}\n\nOur proof proceeds in two steps.\nFirst, we show the following lemma that applies to certain parameters of graphs.\n\n\\begin{lem} \\label{detlem}\nLet $n_1, d_1, n_2, d_2$ be positive parameters satisfying the following properties: $d_1$ and $n_2$ are even, $n_2 \\leq d_1 \\leq 2d_2$ and $d_1 + 2d_2 < n_1$.\nLet $n = n_1+n_2$, and define the following two families of graphs on $n$ vertices:\n\\begin{itemize}[noitemsep,nolistsep]\n\\item $\\mathcal{F}_1$: all graphs containing $n_1$ vertices of degree $d_1$ and $n_2$ isolated vertices;\n\\item $\\mathcal{F}_2$: all graphs containing $n_1$ vertices of degree $d_1$ and $n_2$ vertices of degree $d_2$.\n\\end{itemize}\nLet $r = \\frac{(d_1+d_2) n_2}{d_1 n_1}$ and $q = o(1/r)$.\nThen, there exists a distribution $\\mathcal{D}$ of representations of graphs from $\\mathcal{F}_1 \\cup \\mathcal{F}_2$ such that\nfor any deterministic algorithm $\\mathcal{A}$ that makes at most $q$ total neighbor queries, degree queries and random edge queries,\non the graph representation randomly drawn from $\\mathcal{D}$,\n$\\mathcal{A}$ cannot correctly identify whether the given representation is of a graph from $\\mathcal{F}_1$ or $\\mathcal{F}_2$ with probability at least $2/3$.\n\\end{lem}\n\nBy applying Yao's principle, the following corollary is implied.\n\n\\begin{cor} \\label{randlem}\nLet $n_1, d_1, n_2, d_2$ be parameters satisfying the properties specified in Lemma~\\ref{detlem}.\nLet $s_1 = n_1 {d_1 \\choose p}$ and $s_2 = n_1 {d_1 \\choose p} + n_2 {d_2 \\choose p}$.\nIf $s_1 = \\Theta(f(n,p))$ and $s_2 \\geq c \\cdot s_1$ for some constant $c > 1$, then any (randomized) algorithm for approximating $S_p$ to a multiplicative factor\nvia neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega(q)$ queries for $S_p = \\Theta(f(n,p))$.\n\\end{cor}\n\nAs a second step, we propose a few sets of parameters for different ranges of $S_p$.\nApplying Corollary~\\ref{randlem}, this yields lower bounds for the remaining ranges of $S_p$.\n\n\\subsection{Our Constructions}\n\n\\subsubsection{Construction of $\\mathcal{D}$}\n\nWe prove this lemma by explicitly constructing the distribution.\n\n\\noindent\\textbf{Construction of graph representations for $\\mathcal{F}_1$.}\nWe now define the representation $L_1$ for the graph $G_1 \\in \\mathcal{F}_1$ as follows.\nWe let $v_1, \\ldots, v_{n_1}$ be the vertices with degree $d_1$.\nLet us refer to the $j^\\textrm{th}$ pair of consecutive columns (with indices $2j-1$ and $2j$) as the $j^\\textrm{th}$ slab.\nThen, in the $j^\\textrm{th}$ slab, we match each cell on the left column with the cell at distance $j$ below on the right column.\nFigure~\\ref{fig:table1firstcols} illustrates the matching of cells in the first few columns of $L_1$.\nMore formally, for each integer $i \\in [n_1]$ and $j \\in [d_1/2]$, we match the cells $(i, 2j-1)$ and $(i+j \\text{ mod } n_1, 2j)$ in $L_1$.\n\nSince $d_1$ is even, this construction fills the entire table of $L_1$. We wish to claim that we do not create any parallel edges with this construction. Clearly, this is true within a slab. For different slabs,\nrecall that we map cells in the $j^\\textrm{th}$ slab with those at vertical distance $j$ away.\nThus, it suffices to note that no pair of slabs uses the same distance mod $n_1$. Equivalently, we can note that  as the maximum distance is $d_1/2$ and $d_1/2 < n_1/2$ by our assumption, the set of distances $\\{j, n_1-j\\}$ for $j\\in[d_1/2]$ are all disjoint.\nThat is, our construction creates no parallel edges or self-loops.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.4\\textwidth]{table1firstcols}\n        \\caption{first few columns of $L_1$}\n        \\label{fig:table1firstcols}\n\\end{figure}\n\n\\noindent\\textbf{Construction of graph representations for $\\mathcal{F}_2$.}\nNext, for each integer $x \\in [n_1]$ and $y \\in [d/2]$, we define a graph $G_2^{x, y}$ with corresponding representation $L_2^{x,y}$ by modifying $L_1$ as follows.\nFirst, recall that we need to add neighbors to the previously isolated vertices $v_{n_1+1}, \\ldots, v_{n}$.\nThese neighbors are represented as a table of size $n_2 \\times d_2$ in $L_2^{x,y}$;\nin Figure~\\ref{fig:comparetables}, it is represented as the green rectangle in Figure $L_2^{x,y}$ (a) which is not present in $L_1$.\nWe match the cells in this new table to a subtable of size $d_2 \\times n_2$, which is shown as the yellow rectangle in Figure $L_2^{x,y}$ (a).\nThe top-left cell of this subtable corresponds to the index $(x, 2y-1)$ in $L_2^{x,y}$,\nand note that if $x+d_2 > n_1$ or $2y + n_2 > d_1$, this subtable may wrap around as shown in Figure $L_2^{x,y}$ (b).\nSince $n_2 \\leq d_1$ and $d_2 < n_1$, the dimensions of this yellow rectangle does not exceed the original table in $L_1$.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.8\\textwidth]{comparetables}\n        \\caption{Comparison between tables $L_1$ and $L_2$.  $L_2^{x,y}$ (a) and (b) show two different possibilities for  $L_2^{x,y}$ depending on the values of $x$ and $y$.}\n        \\label{fig:comparetables}\n\\end{figure}\n\nNow we explain how we match the cells.\nBetween the yellow and green subtables, we map them in a transposed fashion.\nThat is, the cell with index $(i, j)$ (relative to the green table) is mapped to the yellow cell with index $(j, i)$ (relative to the yellow subtable),\nas shown in Figure~\\ref{fig:modifiedmatch} (a).\nThis method guarantees that no two rows contain two pair of matched cells between them.\nAs a result, we do not create any parallel edges or self-loops.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.7\\textwidth]{modifiedmatch2}\n        \\caption{matchings in $L_2^{x,y}$}\n        \\label{fig:modifiedmatch}\n\\end{figure}\n\nAs we place the yellow subtable, some edges originally in $L_1$ may now have only one endpoint in the yellow subtable. We refer to the cells in the table that correspond to such edges as \\emph{unmatched}.\nSince $n_2$ is even and we set our offset to $(x, 2y-1)$, then every slab either does not overlap with the yellow subtable, or overlaps in the exact same rows for both columns of the slab.\nThus, the only edges that have one endpoint in the yellow subtable are those that go from a cell above it to one in it. Roughly speaking, we still map the cells in the same way but ignore the distance it takes to skip over the yellow subtable. More formally, in the $j^\\textrm{th}$ slab, we pair each unmatched cell from the left and right respectively that are at vertical distance $j+d_2$ away (instead of $j$), as shown with the red edges in Figure~\\ref{fig:modifiedmatch} (b).\n\nNow the set of distances between the cells corresponding to an edge in the $j^\\textrm{th}$ slab are $\\{j, j+d_2, n_1-j, n_1-(j+d_2)\\}$, since distances can be measured both by going down and by going up and looping around.\nFrom our assumption, $d_1/2 \\leq d_2$ and $d_1/2 + d_2 < n_1/2$, and thus no distance is shared by multiple slabs, and thus there are no parallel edges or self-loops.\n\n\\noindent\\textbf{Permutation of graph representations.}\nLet $\\pi$ be a permutation over $[n]$.\\footnote{A permutation $\\pi$ over $[n]$ is a bijection $\\pi : [n] \\rightarrow [n]$.}\nGiven a graph representation $L$, we define $\\pi(L)$ as a new presentation of the same underlying graph, such that the indices of the vertices are permuted according to $\\pi$.\nWe may consider this operation as an interface to the original oracle.\nNamely, any query made on a vertex index $i$ is translated into a query for index $\\pi(j)$ to the original oracle.\nIf a vertex index $j$ is an answer from the oracle, then we return $\\pi^{-1}(j)$ instead.\n\n\\noindent\\textbf{The distribution $\\mathcal{D}$.}\nLet $\\mathcal{S}_n$ denote the set of all $n!$ permutations over $[n]$.\nWe define $\\mathcal{D}$ formally as follows:\nfor any permutation $\\pi \\in \\mathcal{S}_n$, the representation $\\pi(L_1)$ corresponding to $G_1$ is drawn from $\\mathcal{D}$ with probability $1/(2n!)$,\nand each representation $\\pi(L_2^{x,y})$ corresponding to $G_2^{x,y}$ is drawn with probability $1/(n_1d_1n!)$ for every $(x,y) \\in [n_1]\\times[d_1/2]$.\nIn other words, to draw a random instance from $\\mathcal{D}$, we flip an unbiased coin to choose between families $\\mathcal{F}_1$ and $\\mathcal{F}_2$.\nWe obtain a representation $L_1$ if we choose $\\mathcal{F}_1$; otherwise we pick a random representation $L_2^{x,y}$ for $\\mathcal{F}_2$.\nLastly, we apply a random permutation $\\pi$ to such representation.\n\n\\subsubsection{Answering Random Edge Queries} \\label{randedgeoracle}\n\nNotice that Yao's principle allows us to remove randomness used by the algorithm, but the randomness of the oracle remains for the random edge queries.\nFor any representation we draw from $\\mathcal{D}$, the oracle must return an edge uniformly at random for each random edge query.\nNonetheless, we may choose our own implementation of the oracle as long as this condition is ensured.\nWe apply a coupling argument that imposes dependencies between the behaviors of our oracle between when the underlying graph is from $\\mathcal{F}_1$ or $\\mathcal{F}_2$.\nLet $m_1 = d_1 n_1 /2$ and $m_2 = (d_1 n_1 + d_2 n_2)/2$ denote the number of edges of graphs from $\\mathcal{F}_1$ and $\\mathcal{F}_2$, respectively.\n\nOur oracle works differently depending on which family the graph comes from.\nThe following describes the behavior of our oracle for a single query, and note that all queries should be evaluated independently.\n\n\\noindent\\textbf{Query to $L_1$.}\nWe simply return an edge chosen uniformly at random.\nThat is, we pick a random matched pair of cells in $L_1$, and return the vertices corresponding to the rows of those cells.\n\n\\noindent\\textbf{Query to $L_2^{x,y}$.}\nLet $m_s^{x,y}$ denote the number of edges shared by both $L_1$ and $L_2^{x,y}$.\nWith probability $m_s^{x,y}/m_2$, we return the same edge we choose for $L_1$.\nOtherwise, we return an edge chosen uniformly at random from the set of edges in $L_2^{x,y}$ but not in $L_1$.\n\nOur oracle clearly returns an edge chosen uniformly at random from the corresponding representation.\nThe benefit of using this coupling oracle is that we increase the probability that the same edge is returned to $m_s^{x,y}/m_2$.\nBy our construction, the cells in $L_1$ that are modified to obtain $L_2^{x,y}$ are fully contained within the subtable of size $(d_1 + d_2) n_2$\nobtained by extending the yellow subtable to include $d_1/2$ more rows above and below.\n$m_s^{x,y} \\geq (d_1 n_1 - (d_1 + d_2) n_2)/2$.\nThus, our oracle may only return a different edge with probability \n", "itemtype": "equation", "pos": 47859, "prevtext": "\nFor the second item, we apply Markov's Inequality (Theorem \\ref{markov}) to the given condition to obtain\n", "index": 25, "text": "\n\\[{\\rm P}\\left[\\overline{Y} \\geq \\frac{1}{2}\\widetilde{S}_p\\right] \\leq \\frac{{\\rm E}[\\overline{Y}]}{\\frac{1}{2}\\widetilde{S}_p} = \\frac{S_p}{\\frac{1}{2}\\widetilde{S}_p} < \\frac{\\frac{1}{6}\\widetilde{S}_p}{\\frac{1}{2}\\widetilde{S}_p} = \\frac{1}{3},\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"{\\rm P}\\left[\\overline{Y}\\geq\\frac{1}{2}\\widetilde{S}_{p}\\right]\\leq\\frac{{\\rm&#10;E%&#10;}[\\overline{Y}]}{\\frac{1}{2}\\widetilde{S}_{p}}=\\frac{S_{p}}{\\frac{1}{2}%&#10;\\widetilde{S}_{p}}&lt;\\frac{\\frac{1}{6}\\widetilde{S}_{p}}{\\frac{1}{2}\\widetilde{S%&#10;}_{p}}=\\frac{1}{3},\" display=\"block\"><mrow><mi mathvariant=\"normal\">P</mi><mrow><mo>[</mo><mover accent=\"true\"><mi>Y</mi><mo>\u00af</mo></mover><mo>\u2265</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi></msub><mo>]</mo></mrow><mo>\u2264</mo><mfrac><mrow><mi mathvariant=\"normal\">E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>Y</mi><mo>\u00af</mo></mover><mo stretchy=\"false\">]</mo></mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><msub><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi></msub></mrow></mfrac><mo>=</mo><mfrac><msub><mi>S</mi><mi>p</mi></msub><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><msub><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi></msub></mrow></mfrac><mo>&lt;</mo><mfrac><mrow><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>\u2062</mo><msub><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi></msub></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><msub><mover accent=\"true\"><mi>S</mi><mo>~</mo></mover><mi>p</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\n\\subsection{Proof of Lemma~\\ref{detlem}}\n\nRecall that we consider a deterministic algorithm $\\mathcal{A}$ that makes at most $q = o(1/r)$ queries.\nWe may describe the behavior between $\\mathcal{A}$ and the oracle with its \\emph{query-answer history}.\nNotice that since $\\mathcal{A}$ is deterministic, if every answer that $\\mathcal{A}$ receives from the oracle is the same,\nthen $\\mathcal{A}$ must return the same answer, regardless of the underlying graph.\nOur general approach is to show that for most permutations $\\pi$, running $\\mathcal{A}$ with instance $\\pi(L_1)$\nwill result in the same query-answer history as running with $\\pi(L_2^{x,y})$ for most random parameters $\\pi$ and $(x,y)$.\nIf these histories are equivalent, then $\\mathcal{A}$ may answer correctly for only roughly half of the distribution.\n\nThroughout this section, we refer to our indices before applying $\\pi$ to the representation.\nWe bound the probability that the query-answer histories are different using an inductive argument as follows.\nSuppose that at some point during the execution of $\\mathcal{A}$, the history only contains vertices of indices from $[n_1]$,\nand all cells in the history are matched in the same way in both $L_1$ and $L_2^{x,y}$.\nThis inductive hypothesis restricts the possible parameters $\\pi$ and $(x,y)$ to those that yield same history up to this point.\nWe now consider the probability that the next query-answer pair differs, and aim to bound this probability by $O(r)$.\n\nFirstly, we consider a degree query.\nBy our hypothesis, for a vertex of index outside $[n_1]$ to be queried, $\\mathcal{A}$ must specify a vertex it has not chosen before.\nNotice that $\\mathcal{A}$ may learn about up to 2 vertices from each query-answer pair, so at least $n-2q$ vertices have never appeared in the history.\nSince we pick a random permutation $\\pi$ for our construction, the probability that the queried vertex has index outside $[n_1]$ is $n_2/(n-2q)$.\nAs $r \\geq n_2/n_1 \\geq 1/n_1$, we have $q = o(n_1)$ and our probability simplifies to at most\n", "itemtype": "equation", "pos": 60687, "prevtext": "\nimplying the desired success probability.\n\nLastly, we substitute ${\\epsilon} < 1/2$ to obtain the relationship between $\\bar{Y}$ and $(1-{\\epsilon})\\tilde{S}_p$,\nwhich establishes the condition for deciding whether the given $\\tilde{S}_p$ is much larger than $S_p$, as desired.\n\\end{ourproof}\n\n\\section{Proof of Lower Bounds for Undirected Graphs with $S_p > n$} \\label{lowerproof}\n\nIn this section we provide the proof of lower bounds claimed in Section~\\ref{largeboundsec}.\nFirstly, to properly describe the adjacency list representation of the input graphs, we introduce the notion of graph representation.\nNext, we state a main lemma (Lemma~\\ref{detlem}) that establishes the constraints of parameters $n_1, d_1, n_2, d_2$ that allows us to create hard instances.\nWe then move on to describe our constructions, including both the distribution for applying Yao's principle, and the implementation of the oracle for answering random edge queries.\nWe prove our main lemma for our construction, and lastly, we give the appropriate parameters that complete the proof of our lower bounds.\n\n\\subsection{Graph Representations}\n\nConsider the following \\emph{representation} $L$ of an adjacency list for an undirected graph $G$.\nLet us say that each vertex $v_i$ has $\\deg(v_i)$ ports numbered $1, \\ldots, \\deg(v)$ attached, where the $j^{\\rm th}$ port of vertex $v_i$ is identify as a pair $(i,j)$, which is used as an index for $L$.\n$L$ imposes a perfect matching between these ports; namely, $L(i_1,j_1) = (i_2, j_2)$ indicates that ports $(i_1,j_1)$ and $(i_2, j_2)$ are matched to each other, and this implies $L(i_2,j_2) = (i_1, j_1)$ as well.\nWe use $L$ to define the adjacency list of our graph; that is, if $L(i_1, j_1) = (i_2, j_2)$ then the $j_1^{\\rm th}$ neighbor of $v_{i_1}$ is $v_{i_2}$ (and vice versa).\nNote that there can be many such representations of $G$, and some perfect matchings between ports may yield graphs parallel edges or self-loops.\nFurthermore, each edge $e$ is associated with a unique pair of matched cells.\n\n\\subsection{Main Lemma}\n\nOur proof proceeds in two steps.\nFirst, we show the following lemma that applies to certain parameters of graphs.\n\n\\begin{lem} \\label{detlem}\nLet $n_1, d_1, n_2, d_2$ be positive parameters satisfying the following properties: $d_1$ and $n_2$ are even, $n_2 \\leq d_1 \\leq 2d_2$ and $d_1 + 2d_2 < n_1$.\nLet $n = n_1+n_2$, and define the following two families of graphs on $n$ vertices:\n\\begin{itemize}[noitemsep,nolistsep]\n\\item $\\mathcal{F}_1$: all graphs containing $n_1$ vertices of degree $d_1$ and $n_2$ isolated vertices;\n\\item $\\mathcal{F}_2$: all graphs containing $n_1$ vertices of degree $d_1$ and $n_2$ vertices of degree $d_2$.\n\\end{itemize}\nLet $r = \\frac{(d_1+d_2) n_2}{d_1 n_1}$ and $q = o(1/r)$.\nThen, there exists a distribution $\\mathcal{D}$ of representations of graphs from $\\mathcal{F}_1 \\cup \\mathcal{F}_2$ such that\nfor any deterministic algorithm $\\mathcal{A}$ that makes at most $q$ total neighbor queries, degree queries and random edge queries,\non the graph representation randomly drawn from $\\mathcal{D}$,\n$\\mathcal{A}$ cannot correctly identify whether the given representation is of a graph from $\\mathcal{F}_1$ or $\\mathcal{F}_2$ with probability at least $2/3$.\n\\end{lem}\n\nBy applying Yao's principle, the following corollary is implied.\n\n\\begin{cor} \\label{randlem}\nLet $n_1, d_1, n_2, d_2$ be parameters satisfying the properties specified in Lemma~\\ref{detlem}.\nLet $s_1 = n_1 {d_1 \\choose p}$ and $s_2 = n_1 {d_1 \\choose p} + n_2 {d_2 \\choose p}$.\nIf $s_1 = \\Theta(f(n,p))$ and $s_2 \\geq c \\cdot s_1$ for some constant $c > 1$, then any (randomized) algorithm for approximating $S_p$ to a multiplicative factor\nvia neighbor queries, degree queries and random edge queries with probability of success at least $2/3$ requires $\\Omega(q)$ queries for $S_p = \\Theta(f(n,p))$.\n\\end{cor}\n\nAs a second step, we propose a few sets of parameters for different ranges of $S_p$.\nApplying Corollary~\\ref{randlem}, this yields lower bounds for the remaining ranges of $S_p$.\n\n\\subsection{Our Constructions}\n\n\\subsubsection{Construction of $\\mathcal{D}$}\n\nWe prove this lemma by explicitly constructing the distribution.\n\n\\noindent\\textbf{Construction of graph representations for $\\mathcal{F}_1$.}\nWe now define the representation $L_1$ for the graph $G_1 \\in \\mathcal{F}_1$ as follows.\nWe let $v_1, \\ldots, v_{n_1}$ be the vertices with degree $d_1$.\nLet us refer to the $j^\\textrm{th}$ pair of consecutive columns (with indices $2j-1$ and $2j$) as the $j^\\textrm{th}$ slab.\nThen, in the $j^\\textrm{th}$ slab, we match each cell on the left column with the cell at distance $j$ below on the right column.\nFigure~\\ref{fig:table1firstcols} illustrates the matching of cells in the first few columns of $L_1$.\nMore formally, for each integer $i \\in [n_1]$ and $j \\in [d_1/2]$, we match the cells $(i, 2j-1)$ and $(i+j \\text{ mod } n_1, 2j)$ in $L_1$.\n\nSince $d_1$ is even, this construction fills the entire table of $L_1$. We wish to claim that we do not create any parallel edges with this construction. Clearly, this is true within a slab. For different slabs,\nrecall that we map cells in the $j^\\textrm{th}$ slab with those at vertical distance $j$ away.\nThus, it suffices to note that no pair of slabs uses the same distance mod $n_1$. Equivalently, we can note that  as the maximum distance is $d_1/2$ and $d_1/2 < n_1/2$ by our assumption, the set of distances $\\{j, n_1-j\\}$ for $j\\in[d_1/2]$ are all disjoint.\nThat is, our construction creates no parallel edges or self-loops.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.4\\textwidth]{table1firstcols}\n        \\caption{first few columns of $L_1$}\n        \\label{fig:table1firstcols}\n\\end{figure}\n\n\\noindent\\textbf{Construction of graph representations for $\\mathcal{F}_2$.}\nNext, for each integer $x \\in [n_1]$ and $y \\in [d/2]$, we define a graph $G_2^{x, y}$ with corresponding representation $L_2^{x,y}$ by modifying $L_1$ as follows.\nFirst, recall that we need to add neighbors to the previously isolated vertices $v_{n_1+1}, \\ldots, v_{n}$.\nThese neighbors are represented as a table of size $n_2 \\times d_2$ in $L_2^{x,y}$;\nin Figure~\\ref{fig:comparetables}, it is represented as the green rectangle in Figure $L_2^{x,y}$ (a) which is not present in $L_1$.\nWe match the cells in this new table to a subtable of size $d_2 \\times n_2$, which is shown as the yellow rectangle in Figure $L_2^{x,y}$ (a).\nThe top-left cell of this subtable corresponds to the index $(x, 2y-1)$ in $L_2^{x,y}$,\nand note that if $x+d_2 > n_1$ or $2y + n_2 > d_1$, this subtable may wrap around as shown in Figure $L_2^{x,y}$ (b).\nSince $n_2 \\leq d_1$ and $d_2 < n_1$, the dimensions of this yellow rectangle does not exceed the original table in $L_1$.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.8\\textwidth]{comparetables}\n        \\caption{Comparison between tables $L_1$ and $L_2$.  $L_2^{x,y}$ (a) and (b) show two different possibilities for  $L_2^{x,y}$ depending on the values of $x$ and $y$.}\n        \\label{fig:comparetables}\n\\end{figure}\n\nNow we explain how we match the cells.\nBetween the yellow and green subtables, we map them in a transposed fashion.\nThat is, the cell with index $(i, j)$ (relative to the green table) is mapped to the yellow cell with index $(j, i)$ (relative to the yellow subtable),\nas shown in Figure~\\ref{fig:modifiedmatch} (a).\nThis method guarantees that no two rows contain two pair of matched cells between them.\nAs a result, we do not create any parallel edges or self-loops.\n\n\\begin{figure}\n        \\centering\n\t\\includegraphics[width=0.7\\textwidth]{modifiedmatch2}\n        \\caption{matchings in $L_2^{x,y}$}\n        \\label{fig:modifiedmatch}\n\\end{figure}\n\nAs we place the yellow subtable, some edges originally in $L_1$ may now have only one endpoint in the yellow subtable. We refer to the cells in the table that correspond to such edges as \\emph{unmatched}.\nSince $n_2$ is even and we set our offset to $(x, 2y-1)$, then every slab either does not overlap with the yellow subtable, or overlaps in the exact same rows for both columns of the slab.\nThus, the only edges that have one endpoint in the yellow subtable are those that go from a cell above it to one in it. Roughly speaking, we still map the cells in the same way but ignore the distance it takes to skip over the yellow subtable. More formally, in the $j^\\textrm{th}$ slab, we pair each unmatched cell from the left and right respectively that are at vertical distance $j+d_2$ away (instead of $j$), as shown with the red edges in Figure~\\ref{fig:modifiedmatch} (b).\n\nNow the set of distances between the cells corresponding to an edge in the $j^\\textrm{th}$ slab are $\\{j, j+d_2, n_1-j, n_1-(j+d_2)\\}$, since distances can be measured both by going down and by going up and looping around.\nFrom our assumption, $d_1/2 \\leq d_2$ and $d_1/2 + d_2 < n_1/2$, and thus no distance is shared by multiple slabs, and thus there are no parallel edges or self-loops.\n\n\\noindent\\textbf{Permutation of graph representations.}\nLet $\\pi$ be a permutation over $[n]$.\\footnote{A permutation $\\pi$ over $[n]$ is a bijection $\\pi : [n] \\rightarrow [n]$.}\nGiven a graph representation $L$, we define $\\pi(L)$ as a new presentation of the same underlying graph, such that the indices of the vertices are permuted according to $\\pi$.\nWe may consider this operation as an interface to the original oracle.\nNamely, any query made on a vertex index $i$ is translated into a query for index $\\pi(j)$ to the original oracle.\nIf a vertex index $j$ is an answer from the oracle, then we return $\\pi^{-1}(j)$ instead.\n\n\\noindent\\textbf{The distribution $\\mathcal{D}$.}\nLet $\\mathcal{S}_n$ denote the set of all $n!$ permutations over $[n]$.\nWe define $\\mathcal{D}$ formally as follows:\nfor any permutation $\\pi \\in \\mathcal{S}_n$, the representation $\\pi(L_1)$ corresponding to $G_1$ is drawn from $\\mathcal{D}$ with probability $1/(2n!)$,\nand each representation $\\pi(L_2^{x,y})$ corresponding to $G_2^{x,y}$ is drawn with probability $1/(n_1d_1n!)$ for every $(x,y) \\in [n_1]\\times[d_1/2]$.\nIn other words, to draw a random instance from $\\mathcal{D}$, we flip an unbiased coin to choose between families $\\mathcal{F}_1$ and $\\mathcal{F}_2$.\nWe obtain a representation $L_1$ if we choose $\\mathcal{F}_1$; otherwise we pick a random representation $L_2^{x,y}$ for $\\mathcal{F}_2$.\nLastly, we apply a random permutation $\\pi$ to such representation.\n\n\\subsubsection{Answering Random Edge Queries} \\label{randedgeoracle}\n\nNotice that Yao's principle allows us to remove randomness used by the algorithm, but the randomness of the oracle remains for the random edge queries.\nFor any representation we draw from $\\mathcal{D}$, the oracle must return an edge uniformly at random for each random edge query.\nNonetheless, we may choose our own implementation of the oracle as long as this condition is ensured.\nWe apply a coupling argument that imposes dependencies between the behaviors of our oracle between when the underlying graph is from $\\mathcal{F}_1$ or $\\mathcal{F}_2$.\nLet $m_1 = d_1 n_1 /2$ and $m_2 = (d_1 n_1 + d_2 n_2)/2$ denote the number of edges of graphs from $\\mathcal{F}_1$ and $\\mathcal{F}_2$, respectively.\n\nOur oracle works differently depending on which family the graph comes from.\nThe following describes the behavior of our oracle for a single query, and note that all queries should be evaluated independently.\n\n\\noindent\\textbf{Query to $L_1$.}\nWe simply return an edge chosen uniformly at random.\nThat is, we pick a random matched pair of cells in $L_1$, and return the vertices corresponding to the rows of those cells.\n\n\\noindent\\textbf{Query to $L_2^{x,y}$.}\nLet $m_s^{x,y}$ denote the number of edges shared by both $L_1$ and $L_2^{x,y}$.\nWith probability $m_s^{x,y}/m_2$, we return the same edge we choose for $L_1$.\nOtherwise, we return an edge chosen uniformly at random from the set of edges in $L_2^{x,y}$ but not in $L_1$.\n\nOur oracle clearly returns an edge chosen uniformly at random from the corresponding representation.\nThe benefit of using this coupling oracle is that we increase the probability that the same edge is returned to $m_s^{x,y}/m_2$.\nBy our construction, the cells in $L_1$ that are modified to obtain $L_2^{x,y}$ are fully contained within the subtable of size $(d_1 + d_2) n_2$\nobtained by extending the yellow subtable to include $d_1/2$ more rows above and below.\n$m_s^{x,y} \\geq (d_1 n_1 - (d_1 + d_2) n_2)/2$.\nThus, our oracle may only return a different edge with probability \n", "index": 27, "text": "\n\\[1-\\frac{m_s^{x,y}}{m_2} = 1-\\frac{d_1 n_1 - (d_1 + d_2) n_2}{d_1 n_1 + d_2 n_2} = \\frac{d_1 n_2}{d_1 n_1 + d_2 n_2} \\leq r.\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"1-\\frac{m_{s}^{x,y}}{m_{2}}=1-\\frac{d_{1}n_{1}-(d_{1}+d_{2})n_{2}}{d_{1}n_{1}+%&#10;d_{2}n_{2}}=\\frac{d_{1}n_{2}}{d_{1}n_{1}+d_{2}n_{2}}\\leq r.\" display=\"block\"><mrow><mrow><mrow><mn>1</mn><mo>-</mo><mfrac><msubsup><mi>m</mi><mi>s</mi><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msubsup><msub><mi>m</mi><mn>2</mn></msub></mfrac></mrow><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>+</mo><msub><mi>d</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow></mrow><mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><mo>+</mo><mrow><msub><mi>d</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow></mrow></mfrac></mrow><mo>=</mo><mfrac><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><mo>+</mo><mrow><msub><mi>d</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow></mrow></mfrac><mo>\u2264</mo><mi>r</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\nNext, we consider a neighbor query.\nFrom the argument above, with probability $1-O(r)$, the queried vertex given by $\\mathcal{A}$ has an index from $[n_1]$.\nSimilarly, $\\mathcal{A}$ may learn about up to $2$ cells from each query-answer pair.\nNotice that there are  $(d_1 + d_2) n_2$ different possible $(x, y)$  for which each of these cells could be located in the yellow subtable or the two $(d_1/2) \\times n_2$ strips above and below it.\nAs a result, out of $d_1 n_1 - ((d_1 + d_2) n_2) q$ remaining possible locations for the yellow subtable,\nthe queried cell and the corresponding answer may be in at most $2 (d_1 + d_2) n_2$ of them.\nAs $(x, y)$ is randomly chosen, the probability that this next query-answer pair is different is at most\n", "itemtype": "equation", "pos": 62861, "prevtext": "\n\n\\subsection{Proof of Lemma~\\ref{detlem}}\n\nRecall that we consider a deterministic algorithm $\\mathcal{A}$ that makes at most $q = o(1/r)$ queries.\nWe may describe the behavior between $\\mathcal{A}$ and the oracle with its \\emph{query-answer history}.\nNotice that since $\\mathcal{A}$ is deterministic, if every answer that $\\mathcal{A}$ receives from the oracle is the same,\nthen $\\mathcal{A}$ must return the same answer, regardless of the underlying graph.\nOur general approach is to show that for most permutations $\\pi$, running $\\mathcal{A}$ with instance $\\pi(L_1)$\nwill result in the same query-answer history as running with $\\pi(L_2^{x,y})$ for most random parameters $\\pi$ and $(x,y)$.\nIf these histories are equivalent, then $\\mathcal{A}$ may answer correctly for only roughly half of the distribution.\n\nThroughout this section, we refer to our indices before applying $\\pi$ to the representation.\nWe bound the probability that the query-answer histories are different using an inductive argument as follows.\nSuppose that at some point during the execution of $\\mathcal{A}$, the history only contains vertices of indices from $[n_1]$,\nand all cells in the history are matched in the same way in both $L_1$ and $L_2^{x,y}$.\nThis inductive hypothesis restricts the possible parameters $\\pi$ and $(x,y)$ to those that yield same history up to this point.\nWe now consider the probability that the next query-answer pair differs, and aim to bound this probability by $O(r)$.\n\nFirstly, we consider a degree query.\nBy our hypothesis, for a vertex of index outside $[n_1]$ to be queried, $\\mathcal{A}$ must specify a vertex it has not chosen before.\nNotice that $\\mathcal{A}$ may learn about up to 2 vertices from each query-answer pair, so at least $n-2q$ vertices have never appeared in the history.\nSince we pick a random permutation $\\pi$ for our construction, the probability that the queried vertex has index outside $[n_1]$ is $n_2/(n-2q)$.\nAs $r \\geq n_2/n_1 \\geq 1/n_1$, we have $q = o(n_1)$ and our probability simplifies to at most\n", "index": 29, "text": "\n\\[\\frac{n_2}{n-2q} = \\frac{n_2}{(n_1+n_2)-2\\cdot o(n_1)} \\leq \\frac{n_2}{n_1(1-o(1))} = O(r).\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\frac{n_{2}}{n-2q}=\\frac{n_{2}}{(n_{1}+n_{2})-2\\cdot o(n_{1})}\\leq\\frac{n_{2}}%&#10;{n_{1}(1-o(1))}=O(r).\" display=\"block\"><mrow><mrow><mfrac><msub><mi>n</mi><mn>2</mn></msub><mrow><mi>n</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>q</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><msub><mi>n</mi><mn>2</mn></msub><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>+</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mrow><mrow><mn>2</mn><mo>\u22c5</mo><mi>o</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>n</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac><mo>\u2264</mo><mfrac><msub><mi>n</mi><mn>2</mn></msub><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>o</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mrow><mi>O</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04233.tex", "nexttext": "\n\nLastly, we consider a random edge query.\nFrom the construction in Section~\\ref{randedgeoracle} above, the probability that the returned random edge differs is $O(r)$, regardless of the parameters.\n\nFrom this inductive argument, the probability that the history differs at each step is at most $O(r)$.\nAs $\\mathcal{A}$ only make $q$ queries, the probability that the history differs is at most $q\\cdot O(r) = o(1)$.\nThus with probability $1-o(1)$, it is impossible for $\\mathcal{A}$ to distinguish whether the underlying graph is from $\\mathcal{F}_1$ or $\\mathcal{F}_2$.\nSince each family is included in $\\mathcal{D}$ with probability density $1/2$,\nas $\\mathcal{A}$ is deterministic, the answer given by $\\mathcal{A}$ for these cases is correct for only half of them.\nThus, the probability of $\\mathcal{A}$ correctly distinguish between the two graph families is only $1-\\frac{1}{2}(1-o(1)) = \\frac{1}{2} + o(1)$, as required.\n\n\\subsection{Establishing Lower Bounds}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we propose the feasible asymptotic parameters according to Lemma~\\ref{detlem} and Lemma~\\ref{randlem} in order to establish our lower bounds through the following claim.\n\n\\begin{clm}\nThere exists parameters $n_1, d_1, n_2, d_2$ satisfying the properties specified in Lemma~\\ref{detlem}, yielding values $s_1, s_2$ satisfying the properties in Lemma~\\ref{randlem}, for each of the following cases:\n\\begin{enumerate}[nolistsep,noitemsep]\n\\item $n_1 = \\Theta(n), d_1 = \\Theta((s/n)^{1/p}), n_2 = \\Theta(1), d_2 = \\Theta(s^{1/p})$ for $f(n,p) =  {\\rm O}(n^p)$\n\\item $n_1 = \\Theta(n), d_1 = \\Theta((s/n)^{1/p}), n_2 = \\Theta(s/n^p), d_2 = \\Theta(n)$ for $f(n,p) =  \\Omega(n^p)$\n\\end{enumerate}\n\\end{clm}\n\nWe omit the proof of this claim; our proof only requires straightforward calculation, and a very similar analysis can be found in \\cite{gonen2011counting}.\nBy computing the value $r$ for each case and applying Lemma~\\ref{randlem}, we obtain Theorem~\\ref{thm-medium-bound} and Theorem~\\ref{thm-large-bound}, respectively.\n\\section{Extension to Directed Graphs} \\label{shortdir}\n\nIn this section, we extend our model to the directed case. \n\n\nFirstly, we formally give the specification of this new model.\nSince most of the specification from the undirected graph model given in Section~\\ref{prelim} still applies to the directed case, we only explain the differences between these models.\nWe assume separate adjacency lists for in-neighbors and out-neighbors, allowing for a neighbor about either type of neighbor.\nSimilarly, a degree query may ask for either of the in-degree or the out-degree.\nRandom edge queries now return directed edges $(u, v)$; the algorithm knows both the endpoints and the direction.\nWe focus on the simplest case of stars with mixed directions: approximately counting the number of paths of length two.\n\nNotice the number of stars where all edges point inward or outward can be computed easily by modifying the weighted vertex sampling to sample using in-degree or out-degree respectively\nand then applying the algorithm from Section \\ref{upper-undirected}.\nThis works because the numbers of such stars only depend on the in-degrees and the out-degrees, respectively.\nThus, we turn to the problem of counting directed paths of length two as the next simplest case.\n\n\\subsection{Lower Bound}\nBy constructing hard instances similar to those of Lemma~\\ref{smallcase}, we obtain a lower bound of $\\Omega(n)$.\nMore formally, letting $L(G)$ denote the number of paths of length two in the directed graph $G$, we prove the following theorem.\n\n\\begin{restatable}{thm}{directlow}\n\\label{directed-bound}\nAny (randomized) algorithm for approximating $L(G)$ to a multiplicative factor via neighbor queries, degree queries and random edge queries requires $\\Omega(n)$ total number of queries.\nIn particular, this number of queries is necessary to distinguish the case where $L(G) = 0$ and the case where $L(G) = n$ with probability 2/3.\n\\end{restatable}\n\n\\begin{ourproof}\nWithout loss of generality, we assume $n$ is even. Now, we partition the vertex set $V$ into $S$ and $T$ such that $|S| = |T| = n/2$.\nLet $\\mathcal{G}_1$ be the family of graphs that contains only $G_1$, the complete bipartite graph where every vertex in $S$ has an edge pointing to every vertex in $T$.\nLet $\\mathcal{G}_2$ be the family of graphs $G_{(t,s)}$ constructed by taking the graph from $\\mathcal{G}_1$ and adding one extra back edge $(t, s) \\in T \\times S$.\nNotice that there can be many adjacency list representations of each graph, and this affect the answers to neighbor queries.\nWe associate each possible adjacency list representation to each graph, and include all possible such representations in the family.\n\nClearly, $L(G_1) = 0$, whereas $L(G_{(t,s)}) = n$ for every $G_{(t,s)} \\in \\mathcal{G}_2$.\nFor any algorithm to distinguish between $\\mathcal{G}_1$ and $\\mathcal{G}_2$, when given a graph $G_{(t,s)}$ from $\\mathcal{G}_2$,\nit must be able to detect the vertex $s$ or $t$, the endpoints of the extra edge, with probability at least 2/3.\nOtherwise, if neither $s$ nor $t$ is discovered, the subgraph induced by vertices that the algorithm sees from both families would be exactly the same.\nThe probability of sampling vertices $s$ or $t$ from a vertex sampling, as well as their incident edges from an edge sampling, is ${\\rm O}(1/n)$.\nSimilarly, in order to reach $s$ or $t$ from one of their neighbors,\nthe algorithm must provide the index of $s$ or $t$ in order to make such neighbor query, which may only succeed with probability ${\\rm O}(1/n)$.\nThus, $\\Omega(n)$ samples are required in order to find $s$ or $t$ with probability 2/3, which establishes our lower bound.\n\\end{ourproof}\n\n\\subsection{Upper Bound}\n\nFor each $v \\in V$, define $l(v) = \\deg^-(v)\\cdot\\deg^+(v)$, which represents the number of length two paths whose middle vertex is $v$.\nThus the number of paths of length two, which we aim to approximate, can be written as $L = \\sum_{v\\in V} l(v)$.\nNotice that $2n$ degree queries suffice for exactly computing the number of such paths, already matching the lower bound.\nWe explore this problem further by making an assumption in attempt to obtain an algorithm that requires $o(n)$ queries.\nTo this end, we restrict to direct graphs such that there exists a bound on the ratio of in-degree to out-degree.\nMore specifically, we assume that there exists a value $r \\geq 1$ such that $\\frac{1}{r} \\leq \\frac{\\deg^-(v)}{\\deg^+(v)} \\leq r$,\nlimiting the ratio between the in-degree and the out-degree of any vertex in $G$.\n\nUnder this additional assumption, we obtain a sublinear time algorithm by reduction to what is essentially the undirected case.\nOur approach is to modify the weighted vertex sampling process via rejection sampling so that\nthe probability of sampling a vertex $v$ becomes proportional to $\\sqrt{l(v)}$,\nbringing the sampling probability of each vertex closer to the number of paths centered at that vertex by the rejection sampling method.\nThen we use Algorithm \\ref{full-algo} to approximate $\\sum_{v\\in V} (\\sqrt{l(v)})^2$, which requires some modification to the algorithm, explained later.\nFirst, we explain the details of our rejection sampling method.\n\n\\begin{clm}\nIn the directed graph model, given weighted vertex sampling and degree queries,\nwe may generate a random vertex such that each vertex $v$ is returned with probability $\\sqrt{l(v)}/\\sum_{v'\\in V}\\sqrt{l(v')}$\nby making ${\\rm O}(r)$ queries in expectation given the aforementioned assumption.\n\\end{clm}\n\\begin{ourproof}\nWe draw a random edge sample $(u, v)$, and query for $u$'s in-degree and out-degree.\nWe return $u$ with probability $\\frac{1}{\\sqrt{r}}\\sqrt{\\frac{\\deg^-(u)}{\\deg^+(u)}}$.\nOtherwise, discard $u$ and repeat the process.\n\nEach vertex $u$ is chosen from a random edge sampling is proportional to its in-degree, $\\deg^-(u)$.\nWe only keep $u$ with probability $\\frac{1}{\\sqrt{r}}\\sqrt{\\frac{\\deg^-(u)}{\\deg^+(u)}}$, so the probability that any vertex $u$ is actually returned is proportional to\n$\\deg^+(u) \\cdot \\sqrt{\\frac{\\deg^-(u)}{\\deg^+(u)}} = \\sqrt{l(u)}$, as desired.\nSince $\\frac{1}{r} \\leq \\frac{\\deg^-(v)}{\\deg^+(v)} \\leq r$, we have that $\\frac{1}{r} \\leq \\frac{1}{\\sqrt{r}}\\sqrt{\\frac{\\deg^-(v)}{\\deg^+(v)}} \\leq 1$.\nThus, ${\\rm O}(r)$ queries are required to generate one such sample.\n\\end{ourproof}\n\nDefine $L' = \\sum_{v\\in V} \\sqrt{l(v)}$.\nWe now have a method to sample a vertex $v$ with probability $\\sqrt{l(v)} / L'$ by increasing the time or query complexities only asymptotically by a factor of $r$.\nNow we make the following changes to Algorithm \\ref{unbiased-algo} so that it approximates $L$.\nFirst, the algorithm should draw random vertices from the new distribution given above.\nSecond, we redefine $X = \\sqrt{l(v)}$ and $Y = X \\cdot L' = \\sqrt{l(v)} \\cdot L'$, so that ${\\rm E}[Y]=L$.\nNote that the value $L'$ can be approximated via essentially the same method as in Section \\ref{approx-m}.\nThe proof of the variance bound (Lemma \\ref{good-when-crude}) can be subsequently modified to obtain ${\\mbox{\\bf\\rm Var}}[Y] = {\\rm O}(\\sqrt{n}L^2)$.\n(This is essentially the problem of approximating the second frequency moment: see \\cite{alon1996space} for more details.)\nThat is, ${\\rm O}(\\sqrt{n})$ samples from this new distribution, or equivalently ${\\rm O}(r\\sqrt{n})$ queries, suffice to obtain a $(1\\pm\\epsilon)$-approximation of $L$.\nThis concludes the proof of the following theorem.\n\\begin{thm} \\label{directedup}\nAssuming there exists some value $r$ such that $\\frac{1}{r} \\leq \\frac{\\deg^-(v)}{\\deg^+(v)} \\leq r$ for every $v \\in V$ in the directed graph $G$,\nthen there exists an algorithm that,\nusing degree queries and random edge queries,\ncomputes a $(1\\pm\\epsilon)$-approximation of the number of paths of length two in $G$ with success probability 2/3\nusing ${\\rm O}(r\\sqrt{n})$ queries.\n\\end{thm}\n\\begin{cor}\nAssuming that the ratio between the in-degree and the out-degree of every vertex in the directed graph $G$ is bounded above and below by a constant, then there exists an algorithm that,\nusing degree queries and random edge queries,\ncomputes a $(1\\pm\\epsilon)$-approximation of the number of paths of length two in $G$ with success probability 2/3\nusing ${\\rm O}(\\sqrt{n})$ queries.\n\\end{cor}\n\n\n\n\n", "itemtype": "equation", "pos": 63704, "prevtext": "\n\nNext, we consider a neighbor query.\nFrom the argument above, with probability $1-O(r)$, the queried vertex given by $\\mathcal{A}$ has an index from $[n_1]$.\nSimilarly, $\\mathcal{A}$ may learn about up to $2$ cells from each query-answer pair.\nNotice that there are  $(d_1 + d_2) n_2$ different possible $(x, y)$  for which each of these cells could be located in the yellow subtable or the two $(d_1/2) \\times n_2$ strips above and below it.\nAs a result, out of $d_1 n_1 - ((d_1 + d_2) n_2) q$ remaining possible locations for the yellow subtable,\nthe queried cell and the corresponding answer may be in at most $2 (d_1 + d_2) n_2$ of them.\nAs $(x, y)$ is randomly chosen, the probability that this next query-answer pair is different is at most\n", "index": 31, "text": "\n\\[\\frac{2(d_1 + d_2) n_2}{d_1 n_1 - ((d_1 + d_2) n_2) q} = \\frac{2r}{1-rq} = \\frac{2r}{1-o(1)} = O(r).\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\frac{2(d_{1}+d_{2})n_{2}}{d_{1}n_{1}-((d_{1}+d_{2})n_{2})q}=\\frac{2r}{1-rq}=%&#10;\\frac{2r}{1-o(1)}=O(r).\" display=\"block\"><mrow><mrow><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>+</mo><msub><mi>d</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>n</mi><mn>1</mn></msub></mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>+</mo><msub><mi>d</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>q</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow><mrow><mn>1</mn><mo>-</mo><mrow><mi>r</mi><mo>\u2062</mo><mi>q</mi></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>r</mi></mrow><mrow><mn>1</mn><mo>-</mo><mrow><mi>o</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac><mo>=</mo><mrow><mi>O</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]