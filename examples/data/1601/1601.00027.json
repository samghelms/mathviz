[{"file": "1601.00027.tex", "nexttext": "\nFor each rectangle the intensities of the underlying gray scale image\nare summed up and normalized by the area of the rectangle.  The\nfeature $f(s,R_1,R_2)$ evaluates to a boolean value by comparing these\nquantities:\n\n", "itemtype": "equation", "pos": 37823, "prevtext": "\n\n\\begin{frontmatter}\n\t\n\\title{Computational Pathology: Challenges and Promises for Tissue Analysis}\n\t\n\\author[label1,label2]{Thomas J. Fuchs}\n\\author[label1,label2]{Joachim M. Buhmann}\n\\address[label1]{Department of Computer Science, ETH Zurich,\n         Universitaetstrasse 6, CH-8092 Zurich, Switzerland} \n\\address[label2]{Competence Center for Systems Physiology and\n         Metabolic Diseases, ETH Zurich, Schafmattstr. 18, CH-8093\n         Zurich, Switzerland} \n\t\n\\begin{abstract}\n  The histological assessment of human tissue has emerged as the key\n  challenge for detection and treatment of cancer. A plethora of\n  different data sources ranging from tissue microarray data to gene\n  expression, proteomics or metabolomics data provide a detailed\n  overview of the health status of a patient. Medical\n  doctors need to assess these information sources and they rely on\n  data driven automatic analysis tools. Methods for classification,\n  grouping and segmentation of heterogeneous data sources as well as\n  regression of noisy dependencies and estimation of survival\n  probabilities enter the processing workflow of a pathology diagnosis\n  system at various stages. This paper reports on state-of-the-art of\n  the design and effectiveness of computational pathology workflows\n  and it discusses future research directions in this emergent field\n  of medical informatics and diagnostic machine learning.\n\\end{abstract}\n\t\n\t\n\\begin{keyword}\nComputational Pathology \\sep Machine Learning \\sep Medical Imaging\n\\sep Survival Statistics \\sep Cancer Research  \n\\end{keyword}\n\t\n\t\n\\end{frontmatter}\n\t\n\n\n\n\n\\footnotesize\n\\setcounter{tocdepth}{1}\n\\tableofcontents\n\\normalsize\n\n\n\n\n\\section{Computational Pathology: The systems view} \n  \\label{sec:comp.path.def} \t\n\\thispagestyle{fancy}\t\nModern pathology studies of biopsy tissue encompass multiple stainings\nof histological material, genomics and proteomics analyses as well as\ncomparative statistical analyses of patient data. Pathology lays\nnot only a scientific foundation for clinical medicine but also serves\nas a bridge between the fundamental sciences in natural science,\nmedicine and patient care.  Therefore, it can be viewed as one of the\nkey hubs for translational research in the health and life sciences,\nsubsequently facilitating translational medicine. In particular, the\nabundance of heterogeneous data sources with a substantial amount of\nrandomness and noise poses challenging problems for statistics and\nmachine learning. Automatic processing of this wealth of data promises\na standardized and hopefully more objective diagnosis of the disease\nstate of a patient than manual inspection can provide today. An\nautomatic computational pathology pipeline also enables the medical\nuser to quantitatively benchmark the processing pipeline and to\nidentify error sensitive processing steps which can substantially\ndegrade the final prediction of survival times.\n\n\t\n\\subsection{Definition}\\label{ssec:definition}\n\nComputational Pathology as well as the medical discipline Pathology is\na wide and diverse field which encompass scientific research\nas well as day-to-day work in medical clinics. The following definition\nis an attempt for a concise and practical description of this novel\nfield:\n\t\n\\begin{quote}\n  Computational Pathology investigates a complete probabilistic\n  treatment of scientific and clinical workflows in general pathology,\n  i.e. it combines experimental design, statistical pattern\n  recognition and survival analysis to an unified framework for\n  answering scientific and clinical questions in pathology.\n\t\n\\end{quote}\n\t\t\n\nFigure \\ref{fig:comppath} depicts a schematic overview of the\nfield and the three major parts it consists of: data generation,\nimage analysis and medical statistics.\n\n\\begin{figure*}[htbp]\n  \\begin{center}\t\t\t\t\t\n    \\includegraphics[width=1\\linewidth]{images/comppath.png}\n  \\end{center}\t\t\t\n  \\caption{Schematic overview of the workflow in computational pathology \n    \t\t  comprising of three major parts: \n    \t\t  (i) the covariate data $X$ is acquired via \n    \t\t  microscopy and the target data $Y$ is generated in\n    \t\t  extensive labeling experiments;\n    \t\t  (ii) image analysis in terms of nuclei detection,\n    \t\t  cell segmentation or texture classification \n    \t\t  provides detailed information about the tissue;\n  \t\t\t  (iii) medical statistics, i.e. survival regression\n  \t\t\t  and mixture of expert models are used to investigate\n  \t\t\t  the clinical end point of interesting using data\n  \t\t\t  from the previous two parts. \n  \t\t\t  The aim is to build a complete probabilistic\n  \t\t\t  workflow comprising all three parts.\n  \t\t\t  (The corresponding sections of the paper are noted \n  \t\t\t  in addition.)\n    \\label{fig:comppath}\n  }\n\\end{figure*}\n\n\n\\section{Data: Tissue and Ground Truth}\\label{sec:ground.truth}\t\t\n\t\n\\subsection{Clear Cell Renal Cell Carcinoma}\\label{subsec:introRCC}\nThroughout this review we use Renal cell carcinoma (RCC) as a \ndisease case to design and optimize a computational pathology framework\nbecause it exhibits a number of properties which are highly relevant\nfor computational pathology. \n\t\t\t\nRenal cell carcinoma figures as one of the ten most frequent\nmalignancies in the statistics of Western societies\n\\cite{Grignon04}. The prognosis of renal cancer is poor since many\npatients suffer already from metastases at the time of first\ndiagnosis. The identification of biomarkers for prediction of\nprognosis (prognostic marker) or response to therapy (predictive\nmarker) is therefore of utmost importance to improve patient prognosis\n\\cite{Tannapfel96}. Various prognostic markers have been suggested in\nthe past \\cite{Moch99, Sudarshan06}, but estimates of conventional\nmorphological parameters still provide most valuable information for\ntherapeutical decisions.\n\t\t\t\nClear cell RCC (ccRCC) emerged as the most common subtype of renal\ncancer and it is composed of cells with clear cytoplasm and typical\nvessel architecture. ccRCC exhibits an architecturally diverse\nhistological structure, with solid, alveolar and acinar patterns. The\ncarcinomas typically contain a regular network of small thin-walled\nblood vessels, a diagnostically helpful characteristic of this\ntumor. Most ccRCC show areas with hemorrhage or necrosis\n(Fig. \\ref{fig:rcc}d), whereas an inflammatory response is\ninfrequently observed.  Nuclei tend to be round and uniform with\nfinely granular and evenly distributed chromatin. Depending upon the\ngrade of malignancy, nucleoli may be inconspicuous and small, or large\nand prominent, with possibly very large nuclei or bizarre nuclei\noccurring \\cite{Grignon04}.\n\t\t\t\t\t\nThe prognosis for patients with RCC depends mainly on the pathological\nstage and the grade of the tumor at the time of surgery. Other\nprognostic parameters include proliferation rate of tumor cells and\ndifferent gene expression patterns. Tannapfel et\nal. \\cite{Tannapfel96} have shown that cellular proliferation\npotentially serves as another measure for predicting biological\naggressiveness and, therefore, for estimating the\nprognosis. Immunohistochemical assessment of the MIB-1 (Ki-67) antigen\nindicates that MIB-1 immunostaining (Fig. \\ref{fig:rcc}d) is an\nadditional prognostic parameter for patient outcome. TMAs were highly\nrepresentative of proliferation index and histological grade using\nbladder cancer tissue \\cite{Nocito01}.\n\t\t\t\t\t\nThe TNM staging system specifies the local extension of the primary tumour\n(T), the involvement of regional lymph nodes (N), and the presence of distant\nmetastases (M) as indicators of the disease state.\n\\cite{Wild09} focuses on reassessing the current TNM staging system\nfor RCC and concludes that outcome prediction for RCC remains\ncontroversial. Although many parameters have been tested for\nprognostic significance, only a few have achieved general acceptance\nin clinical practice. An especially interesting observation of\n\\cite{Wild09} is that multivariate Cox proportional hazards regression\nmodels including multiple clinical and pathologic covariates were more\naccurate in predicting patient outcome than the TNM staging system.\nOn one hand this finding demonstrates the substantial difficulty of the\ntask and on the other hand it is a motivation for research in\ncomputational pathology to develop robust machine learning frameworks\nfor reliable and objective prediction of disease progression.\n\t\t\n\t\n\\subsection{Tissue Microarrays}\n\t\t\t\nThe tissue microarray (TMA) technology significantly accelerated\nstudies seeking for associations between molecular changes and\nclinical endpoints \\cite{Kononen98}. In this technology, $0.6 mm$\ntissue cylinders are extracted from primary tumor material \nof hundreds of different patients and these\ncylinders are subsequently embedded into a recipient tissue block.\nSections from such array blocks can then be used for simultaneous in\nsitu analysis of hundreds or thousands of primary tumors on DNA, RNA,\nand protein level (cf. \\ref{fig:rcc}). These results can then be\nintegrated with expression profile data which is expected to enhance\nthe diagnosis and prognosis of ccRCC \\cite{Takahashi01, Moch99,\n  Young01}. The high speed of arraying, the lack of a significant \ndamage to donor blocks, and the regular arrangement of arrayed\nspecimens substantially facilitates automated analysis.\n\t\t      \t\t\t\n\\begin{figure*}[tb]\n  \\begin{center}\n    \\begin{tabular}{ccccc}\n\t\\includegraphics[height=1.46in] {images/ccRCC.jpg} &\n\t  \\includegraphics[height=1.46in] {images/TMABlock.jpg} &\n\t  \\includegraphics[height=1.46in] {images/TMAoverview.jpg} &\t                           \n\t\\includegraphics[height=1.46in] {images/spot_mib.png} &\n\t\\includegraphics[height=1.46in] {images/spot_mib_zoom.png} \\\\\n\t  (a) & (b) & (c) & (d) & (e)\\\\\n     \\end{tabular}\n     \\caption{ Tissue Microarray Analysis (TMA): Primary tissue\n       samples are taken from a cancerous kidney (a).  Then $0.6 mm$\n       tissue cylinders are extracted from the primary tumor material of\n       different patients and arrayed in a recipient paraffin block\n       (b).  Slices of $0.6\\mu m$ are cut off the paraffin block and\n       are immunohistochemically stained (c).  These slices are\n       scanned and each spot, represents a different patient. Image\n       (d) depicts a TMA spot of clear cell renal cell carcinoma\n       stained with MIB-1 (Ki-67) antigen. (e) shows details of the\n       same spot containing stained and non-stained nuclei of normal\n       as well as abnormal cells.}\n     \\label{fig:rcc}\n  \\end{center}\n\\end{figure*}\n\n\\begin{figure}[tb]\n  \\begin{center}\t     \t          \t\n    \\includegraphics[width=0.7\\linewidth] {images/progs_alone_v.pdf}\n    \\caption{Tablet PC labeling applications for (i) global staining estimation\n\t(ii) nuclei detection and (iii) nuclei classification (from\n      top to bottom).} \n    \\label{fig:software}\n  \\end{center}\n\\end{figure}\n\t\t\t\nAlthough the production of tissue microarrays is an almost routine\ntask for most laboratories, the evaluation of stained tissue\nmicroarray slides remains tedious human annotation work, it is time\nconsuming and prone to error. Furthermore, the significant\nintratumoral heterogeneity of RCC results in high interobserver\nvariability. The variable architecture of RCC also results in a\ndifficult assessment of prognostic parameters. Current image analysis\nsoftware requires extensive user interaction to properly identify cell\npopulations, to select regions of interest for scoring, to optimize\nanalysis parameters and to organize the resulting raw data. Because of\nthese drawbacks in current software, pathologists typically collect\ntissue microarray data by manually assigning a composite staining\nscore for each spot - often during multiple microscopy sessions over a\nperiod of days. Such manual scoring can result in serious\ninconsistencies between data collected during different microscopy\nsessions. Manual scoring also introduces a significant bottleneck that\nhinders the use of tissue microarrays in high-throughput analysis.\n\t\t\n\\subsection{Analyzing Pathologists}\\label{ssec:labelingex}\nTo assess the inter and intra variability of pathologists we designed\nthree different labeling experiments for the major tasks involved in\nTMA analysis.  To facilitate the labeling process for trained\npathologists we developed software suite which allows the user to view\nsingle TMA spots and which provides zooming and scrolling\ncapabilities.  The expert can annotate the image with vectorial data\nin SVG (support vector graphics) format and he/she can mark cell nuclei,\nvessels and other biological structures. In addition each structure\ncan be labeled with a class which is encoded  by its color.  To\nincrease usability and the adoption in hospitals we specifically\ndesigned the software for tablet PC so that a pathologist can perform\nall operations with a pen alone in a simple and efficient manner.\nFigure \\ref{fig:software} depicts the graphical user interfaces of the\nthree applications.\n\n\t\n\\begin{figure}[tb]\n  \\begin{center}\t          \t       \n    \\begin{tabular}{cc}     \t                 \n      \\includegraphics[height=1.4in] {images/detections_spot_1.png} &\n      \\includegraphics[height=1.4in] {images/detections_spot_2.png} \\\\\n      (a) & (b) \\\\\n      \\includegraphics[width=1.4in] {images/detections_all.png} &\n      \\includegraphics[width=1.4in] {images/detections_diff.png} \\\\\n      (c) & (d) \\\\\n    \\end{tabular}\t\n    \\caption{(a) A quarter of an RCC TMA spot used for the nuclei detection experiment.\n      (b) Annotations of one expert, indicating abnormal nuclei in black and normal ones in red.\n      (c) Overlay of detected nuclei from expert one (blue circles)\n      and expert two (red crosses). \n      (d) Disagreement between the two domain experts regarding the\n      detection task. Nuclei which were labeled only by pathologist\n      one are shown in blue and the nuclei found only by expert two\n      are depicted in red.\n    } \n    \\label{fig:detectionvar}\n  \\end{center}\n\\end{figure}\n\t\t\t\t\n\\textbf{Nuclei Detection:} The most tedious labeling task is the\ndetection of cell nuclei.  In this experiment two experts on renal\ncell carcinoma exhaustively labeled a quarter of each of the 9 spots\nfrom the previous experiment.  Overall each expert independently\nmarked the center, the approximate radius and the class of more than\n2000 nuclei.  Again a tablet PC was used so it was possible to split\nup the work into several sessions and the experts could use the\nmachine at their convenience. \nThe user detects nuclei by marking the location with the pen on the\ntablet and indicates the diameter by moving the pen. \nA circular semi-transparent polygon is then drawn to mark the\nnucleus. The final step consists of choosing a class for the nucleus.\nIn this setting it was either black for cancerous nuclei or red for\nnormal ones.  This task has to be repeated for each nucleus on each\nspot. Finally it is possible to show and hide the annotation to gain\nan overview over the original tissue.  Figure \\ref{fig:detectionvar}\ndepicts a quarter of one of the RCC TMA spots together with the\nannotation and the inter expert disagreement.\n\t\t\t\t \t\t\t\t\nThe average precision of one pathologist compared to the other is\n$0.92$ and the average recall amounts to $0.91$.  These performance\nnumbers show that even detecting nuclei on an histological slide is by\nfar not an easy or undisputed task.\n\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\n\\textbf{Nuclei Classification:} The third experiment was designed to\nevaluate the inter and intra pathologist variability for nuclei\nclassification, i.e. determining if a nucleus is normal/benign or\nabnormal/malignant. This step crucially influences the final outcome due to\nthe fact that the percentage of staining is only estimated on the\nsubset of cancerous nuclei. In the experiment, $180$ randomly selected\nnuclei are sequentially presented in three different views of varying\nzoom stage. \nThe query nucleus is indicated in each view with a red cross and the\narea which comprises the next zoom view is marked with a red bounding\nbox (cf. Figure \\ref{fig:software}).  During the setup phase the user\ncan adjust these views to simulate his usual workflow as good\nas possible. During the experiment the expert has to select a class\nfor each nucleus and rate his confidence. Thus, he has the choice\nbetween six buttons: tumor certainly, tumor probably, tumor maybe,\nbenign certainly, benign probably and benign maybe. After classifying\nall nuclei, which have been classified as tumor, are displayed again\nand the pathologist has to estimate if the nucleus is stained or\nnot. Again he has to rate his confidence in his own decision on a\nscale of three levels.  To test the intra pathologist's variability a\nsubset of nuclei was queried twice but the images were flipped and\nrotated by 90 degree at the second display to hamper recognition.\n\t\t\t\n\\begin{figure*}[tb]\n  \\begin{center}\n    \\begin{tabular}{cccc}\n      \\includegraphics[height=1.25in] {images/classification_var.png} &\n      \\includegraphics[height=1.25in] {images/allpaths_total.pdf} &\n      \\includegraphics[height=1.25in] {images/allpaths_p1.pdf} &\n      \\includegraphics[height=1.25in] {images/allpaths_p2.pdf} \\\\\n      (a) & (b) & (c) & (d)\\\\\n    \\end{tabular}\n    \\caption{(a) Inter-pathologist classification variability based on\n      $180$ nuclei labeled by five domain experts. The experts agree\n      on $105$ out of $180$ nuclei (blue bars: $24$ normal, $81$\n      cancerous).  (b-d) Confusion matrices including reader\n      confidence for intra-observer variability in nuclei\n      classification: (b) The combined result of all five experts\n      yields a intra pathologist classification error of $21.2\\%$.\n      (c) Example of an extremely self-confident pathologist with\n      $30\\%$ error.  (d) A very cautions pathologist with a\n      misclassification error of $18\\%$.}\n    \\label{fig:baloonPathos}\n  \\end{center}\n\\end{figure*}\n\t\t\t\t\nThe results for inter-pathologist variability for the binary\nclassification task are plotted in Figure \\ref{fig:baloonPathos}a. Out\nof $180$ nuclei all five experts agreed on $24$ nuclei to be normal\nand $81$ nuclei to be ab-normal, respectively cancerous. For the\nother $75$ nuclei ($42\\%$) the pathologists disagreed.\n\t\t\t\t\nThe analysis of the intra-pathologist error is shown in Figure\n\\ref{fig:baloonPathos}b. The overall intra classification error is\n$21.2\\%$ This means that every fifth nucleus was classified by an\nexpert first as cancerous and the second time as normal or vice versa.\nThe self-assessment of confidence allows us also to analyze single\npathologists.  For example Figure \\ref{fig:baloonPathos}c shows the\nresults of a very self-confident pathologist who is always very\ncertain of his decisions but ends up with an error of $30\\%$ in the\nreplication experiment. Figure \\ref{fig:baloonPathos}d on the other\nhand is the result of a very cautious expert who is rather unsure of\nhis decision, but with a misclassification error of $18\\%$ he performs\nsignificantly better than the previous one.  The important lesson\nlearned is, that self-assessment is not a reliable information \nto learn from. The intuitive notion, to use only training samples\nwhich were classified with high confidence by domain experts is not\nvalid.\n\t\t\t\t\nIn defense of human pathologist it has to be mentioned that these\nexperiments represent the most general way to conduct a TMA analysis\nand analogous studies in radiology report similar results\n\\cite{Saur2009,Saur2010}. In practice, domain experts focus only on\nregions of TMA spots which are very well processed, which have no\nstaining artifacts or which are not blurred. The nuclei analyzed in\nthis experiment were randomly sampled from the whole set of detected\nnuclei to mimic the same precondition which an algorithm would\nencounter in routine work. Reducing the analysis to perfectly\nprocesses regions would most probably decrease the intra-pathologist\nerror.\n\n\\textbf{Staining Estimation:} The most common task in manual TMA\nanalysis requires to estimate the staining. To this end a domain expert\nviews the spot of a patients for several seconds and estimates the\nnumber of stained abnormal cells without resorting to actual nuclei\ncounting. This procedure is iterated for each spot on a TMA-slide to\nget an estimate for each patient in the study.\n\t\t\t\t\nIt is important to note that, due to the lack of competitive\nalgorithms, the results of nearly all TMA studies are based on this\nkind of subjective estimations.\n\t\t\t\t\n\\begin{figure*}[htb]\n  \\begin{center}\t          \t       \n    \\begin{tabular}{cc}     \t                 \n      \\includegraphics[height=2.5in] {images/staining_estimation_nice.png} &\n      \\includegraphics[height=2in] {images/staining_estimation_sd_nice.png} \\\\\n      (a) & (b) \\\\\n    \\end{tabular}\t\n    \\caption{(a) Results for 4 TMA spots from the labeling experiment\n      conducted to investigate the inter pathologist variability for\n      estimating nuclear staining. 14 trained pathologists estimated\n      MIB-1 staining on 9 TMA spots.  The boxplots show a large\n      disagreement between pathologist on spots with an averages\n      staining of more than $10\\%$.  The absolute estimated percentage\n      is plotted on the y-axis. Spot 1 for example, yields a standard\n      deviation of more than $20\\%$. (b) The standard\n      deviation grows linearly with the average estimated staining.  \n    }\n    \\label{fig:stainingvar}\n  \\end{center}\n\\end{figure*}\n\t\t\t\t\t\nTo investigate estimation consistency we presented 9 randomly selected\nTMA spots to 14 trained pathologists of the University Hospital\nZurich.\n\nThe estimations of the experts varied by up to $20\\%$ as shown in\nFigure \\ref{fig:stainingvar}b.  As depicted in Figure\n\\ref{fig:stainingvar}b the standard deviation between the experts\ngrows linearly with the average estimated amount of staining.  The\nhigh variability demonstrates the subjectivity of the estimation\nprocess. This uncertainty is especially critical for types of cancer\nfor which the clinician chooses the therapy based on the estimated\nstaining percentage.  This result not only motivates but emphasizes\nthe need for more objective estimation procedures than current\npractice. Our research is stimulated by the hope, that computational\npathology approaches do not only automated such estimation processes\nbut also produce better reproduceable and more objective results than\nhuman judgment.\n\t\t\t\t\t\n\t\n\\subsection{Expert Variability in Fluorescence Microscopy}\nComplementary to immunohistochemical TMA analysis, fluorescence\nmicroscopy is applied \noften for high-throughput screening of molecular phenotypes. A\ncomprehensive study evaluating the performance of domain experts\nregarding the detection of lymphocytes is presented by\n\\cite{Nattkemper03}.  In a best case, a medium-skilled expert needs on\naverage one hour for analyzing a fluorescence micrograph.  Each\nmicrograph contains between 100 and 400 cells and is of size $658\n\\times 517$ pixel.  Four exemplary micrographs were blindly evaluated\nby five experts.  To evaluate the inter-observer variability\nnattkemper et al. \n\\cite{Nattkemper03} define a gold standard comprising all cell\npositions in a micrograph that were detected by at least two experts.\n\t\t\nAveraged over of CD3, CD4, CD7 and CD8 the sensitivity of the four\nbiomedical experts is varying between $67.5\\%$ and $91.2\\%$ and the\npositive predictive value (PPV) between $75\\%$ and $100\\%$. Thus the\naverage detection error over all biomedical experts and micrographs is\napproximately $17\\%$.  Although fluorescence images appear to be\neasier to analyze due to their homogeneous background, this high\ndetection error indicates the difficulty of this analysis task. These\nresults corroborates the findings in the ccRCC detection experiment\ndescribed in Section \\ref{subsec:introRCC}.\n\t\t\t\t\t\t\n\t\t\t\t\n\\subsection{Generating a Gold Standard}\\label{ssec:goldstandard}\nThe main benefit of labeling experiments like the ones described\nbefore, is not to point out the high inter and intra variability\nbetween pathologists, but to generate a gold standard.  In absence of\nan objective ground truth measurement process, a gold standard is\ncrucial for the use of statistical learning,  first for learning a\nclassifier or regressor and second for validating the statistical\nmodel.\n\nSection \\ref{sec:view} shows an example how the information gathered\nin the experiments of Section \\ref{ssec:labelingex} can be used to\ntrain a computational pathology system.\n\nBesides labeling application which are developed for specific\nscenarios as the one described in Section \\ref{ssec:labelingex}\nseveral other possibilities exist to acquire data in pathology in a\nstructured manner.  Although software for tablet PCs is the most\nconvenient approach to gather information directly in the hospital it\nis limited by the low number of test subjects which can complete an\nexperiment. To overcome this limitation the number of labelers can be\nextended significantly by the use of web-based technologies.\n\nCrowd-sourcing services like Amazon Mechanical Turk can be used to\ngather large numbers of labels at a low cost.  Applications in\npathology suffer from the main problem, that the labelers are all\nnon-experts.  While crowd-sourcing works well for task based on\nnatural images \\cite{Welinder10}, it poses a considerable problems in\npathology where for example the decision if a nucleus is normal or\ncancerous is based on complicated criteria \\cite{WHO04} which require\nmedical training and knowledge. Likewise the recognition of some\nsupercellular morphological structures requires years of training and\nsupervision.  Nevertheless crowd-sourcing could be useful in simple\ndetection tasks like finding nuclei in histological slides.\n\t\n\n\\subsection{Multiple Expert Learning}\t\t\t\t\t\t\t\nIn classical supervised learning, a set of training data\n$\\{(x_i,y_i)\\}_{i=1,\\ldots,n}$ is available which consists of objects\n$x_i$ and their corresponding labels $y_i$. The task is to predict the\nlabel $y$ for a new test object $x$.  This approach is valid as long\nas the target variable $Y=\\{y_1,\\ldots,y_n\\}$ denotes\nthe ground truth of the application. If this condition is met, $Y$ and\n$X=\\{x_1,\\ldots,x_n\\}$ can be used for classifier learning and\nevaluation.\n\nUnfortunately, for a large number of real word application ground\ntruth is either not available or very expensive to acquire. In\npractice, as a last resort, one would ask several domain experts for\ntheir opinion about each object $x_i$ in question to generate a gold\nstandard as described in Section \\ref{ssec:goldstandard}. Depending on\nthe difficulty of the task and the experience of the experts this\nquestioning often results in an ambiguous labeling due to disagreement\nbetween experts. In pathology, very challenging scenarios, like\nassessing the malignancy of a cell, not only the inter, but also the\nintra expert variability is quite large (cf. Section\n\\ref{ssec:labelingex}).  Moreover, restricting the dataset to the\nsubset of consistently labeled samples results in loss of the majority\nof data in these scenarios.\n\nConsequently, \nsuch a data acquisition procedure poses a fundamental problem for\nsupervised learning.  Especially in computational pathology there is\nclearly a need for novel algorithms to address the labeling problem and\nto provide methods to validate models under such circumstances.\n\n\n\\begin{figure}[tb]\n  \\begin{center}\n    \\begin{tabular}{cc}\n      (a) & \\includegraphics[width=2.75in] {images/labeling_matrix_1.png} \\\\\n      (b) & \\includegraphics[width=2.75in] {images/labeling_matrix_2.png} \\\\\n    \\end{tabular}\n    \\caption{Labeling matrix with majority vote (a) and confidence matrix with \n    \tconfidence average (b) of five domain experts classifying $180$ ccRCC nuclei\n    \tinto cancerous (red) and benign (green).} \n    \\label{fig:labelingmatrices}\n  \\end{center}\n\\end{figure}\n\t\t\nMore formally, each $y_i$ is replaced by a $D$ dimensional vector\n$\\bar{y_i}=\\{y_i^1,\\ldots,y_i^D\\}$, where $y_i^d$ represents the\n$i$-th label of domain expert $d$. To this end one is interested in\nlearning a classifier $\\Phi(X,\\bar{Y})$ from the design matrix $X$ and\nthe labeling matrix $\\bar{Y}$.  To date it is an open research\nquestion, how such classifier $\\Phi(X,\\bar{Y})$ should be formulated.\n\t\t\nRecently \\cite{Smyth94, Raykar09} presented promising results based on\nexpectation maximization where the hidden ground truth is estimated in\nturn with the confidence in the experts.  Also along this lines\n\\cite{Whitehill09} introduced a probabilistic model to simultaneously\ninfer the label of images, the expertise of each labeler, and the\ndifficulty of each image. An application for diabetes especially for\ndetecting hard exudates in eye fundus images was published by\n\\cite{Kauppi09}.\n\t\t\t\t\t\nAlthough a number of theoretical results exist \\cite{Lugosi92,\n  Smyth96, Dekel09}, empirical evidence is still lacking to establish\nthat these approaches are able to improve over simple majority voting\n\\cite{Tullock59, Downs61} in real world applications.\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\nA further, promising line of research investigates the question if\nsuch a classifier $\\Phi(X,\\bar{Y})$ can be learned in an on-line\nfashion, especially when the new labels come from a different domain\nexpert. An affirmative answer\nwould show a high impact in domains where specific models can be\ntrained for years by a large number of experts, e.g. medical decision\nsupport.\n\t\t\t\t\t\nIn summary, extending supervised learning to handle domain expert\nvariability is an exciting challenge and promises direct impact on\napplications not only in pathology but in a variety of computer vision\ntasks where generating a gold standard poses a highly non trivial\nchallenge.\n\n\t\t\t\t\t\t\t\n\\subsection{Public Datasets with Labeling Information}\n\t\t\nThe available of public datasets with labeling information is crucial\nfor the advance of an empirical science.  Although a comprehensive\narchive like the UCI machine learning repository \\cite{Frank10} does\nnot exist for computational pathology, there are a number of datasets\nand initiatives which disseminate various kinds of data.\n\t\t\n\t\t\n\\textbf{Immunohistochemistry:} The most comprehensive database for\nantibodies and human tissue is by far the Human Protein Atlas\n\\cite{Berglund08, Ponten08}. Comprising spots from tissue micro arrays\nof $45$ normal human tissue types, it contains anywhere from $0-6$\nimages for each protein in each tissue type. The images are roughly \n$3000 \\times 3000$ pixels in size, with each pixel approximately\nrepresenting a $0.5 \\times 0.5 \\mu m$ region on the microscopy slide.\n\nA segmentation benchmark for various tissue types in bioimaging was\ncompiled by \\cite{Manjunath09}, including 58 histopathological H\\&E\nstained images of breast cancer. The dataset provides labels from a\nsingle expert for the tasks of segmentation and cell counting.\n\n\n\\textbf{Cytology:} Automation in cytology is the oldest and most\nadvanced branch in the field of image processing in pathology. Reason\ntherefore are that digital imaging is rather straightforward and that\nsingle cells on a homogeneous background are more easily detected and\nsegmented than in tissue.  As a result commercial solutions are\navailable since decades.  Nevertheless especially the classification\nof detected and segmented nuclei still poses large difficulties for\ncomputational approaches.  \\cite{Lezoray02} published ten color\nmicroscopic images from serous cytology with hand segmentation\nlabels.\\\\ For bronchial cytology \\cite{Meurie05} provide eight color\nmicroscopic images.  Ground truth information for three classes\n(nucleus, cytoplasm, and background pixels) is also available for each\nimage.  Pixels have a label specifying their classes (2: nucleus, 1:\ncytoplasm, 0: background).\\\\ A dataset of $3900$ cells has been\nextracted from microscopical image (serous cytology) by\n\\cite{Lezoray03}. This database has been classified into $18$ cellular\ncategories by experts. \n\n\t\t\t\n\\textbf{Fluorescence Microscopy:} A hand-segmented set of 97\nfluorescence microscopy images with a total of 4009 cells has been\npublished by \\cite{Murphy09}.  For fluorescence microscopy, the\nsimulation of cell population images is an interesting addition to\nvalidation with manual labels of domain experts.  \\cite{Nattkemper03,\n  Lehmussola07} present simulation frameworks for synthetically\ngenerated cell population images. The advantage of these techniques is\nthe possibility to control parameters like cell density, illumination\nand the probability of cells clustering together.  \\cite{Lehmussola07}\nsupports also the simulation of various cell textures and different\nerror sources.  The obvious disadvantage are (i) that the model can\nonly simulate what it knows and therefore can not represent the whole\nvariability of biological cell images and (ii) that these methods can\nonly simulate cell cultures without morphological structure. The later\ndisadvantage also prevents their use in tissue analysis.  Although the\nthought of simulated tissue images in light microscopy is appealing,\ncurrently there does not exist methods which could even remotely\nachieve that goal.\n\t\t\t\n\n\n\n\\section{Imaging: From Classical Image Processing to Statistical Pattern Recognition}\\label{sec:imaging} \n\n\nIn recent years, a shift from rule based expert system towards learned\nstatistical models could be observed in medical information\nsystems. The substantial influence that machine learning had on the computer\nvision community is also reflecting more and more on medical imaging\nin general and histopathology in special. Classifiers for object\ndetection and texture description in conjunction with various kinds of\nMarkov random fields are continuously replacing traditional watershed\nbased segmentation approaches and handcrafted rule-sets.\nJust recently \\cite{Monaco10} successfully demonstrated the use of\npairwise Markov models for high-throughput detection of prostate cancer \nin histological sections.\nAn excellent review of state-of-the-art histopathological image analysis \nmethodology was compiled by \\cite{Gurcan09}.\n\t\t\nAs with most cutting edge technologies, commercial imaging solutions\nlag behind in development but the same trend is evident. \\cite{Rojo09}\nreview commercial solutions for quantitative immunohistochemistry in\nthe pathology daily practice.\n\t\nDespite the general trend towards probabilistic models, very classical\napproaches like mathematical morphology \\cite{Soille03} are still used\nwith great success. Recently, \\cite{Lezoray09} presented a framework\nfor segmentation based on morphological clustering of bivariate color\nhistograms and \\cite{FuchsDAGM2008} devised an iterative morphological\nalgorithm for nuclei segmentation.\n\t\t\nBesides common computer vision tasks like object detection,\nsegmentation and recognition, histopathological imaging poses domain\nspecific problems such as estimating staining of nuclei conglomerates\n\\cite{Grabe09} and differentiation nuclei by their shape \\cite{Arif07}.\n\n\n\n\\subsection{Preprocessing vs. Algorithmic Invariance}\\label{ssec:invariance}\n\nBrightfield microscopic imaging often produces large differences of\nillumination within single slides or TMA spots. These variations are\ncaused by the varying thickness of the slide or by imperfect\nstaining. Such problems can be overcome either by preprocessing the\nimage data or by designing and integrating invariance into the\nalgorithmic processing to compensate for these variations.\n\nInconsistencies in the preparation of histology slides render it\ndifficult to perform a quantitative analysis on their results.\nAn normalization approach based on optical density and SVD projection\nis proposed by \\cite{Macenko09} for overcoming some of the\nknown inconsistencies in the staining process. Slides which were \nprocessed or stored under very different conditions are projected \ninto a common, normalized space to enable improved quantitative analysis.\n\nPreprocessing and normalization methods usually not only reduce noise\ninduced differences between samples but often also eliminate the\nbiological signal of interest. As an alternative to such an\nirreparable information loss during data acquisition, algorithms with\nillumination invariance or with compensation of staining artifacts are\ndesigned which are robust to these uncontrollable experimental\nvariations. \n\t\t\nRelational Detection Forests \\cite{FuchsISVC2009} provide one possibility\nto overcome this problem of information loss. \nEspecially designed for detection of cell nuclei\nin histological slides, they are based on the concept of randomized\ntrees \\cite{Breiman01}. The features, which are selected for this\nframework center around the idea that relation between features are\nmore robust than thresholds on single features. A similar idea was\napplied by \\cite{Geman04} to gene chip analysis where similar problems\noccur, due to the background noise of different labs.  Contrary to the\nabsolute values the relation between DNA expression is rather robust.\n\nObject detection is commonly solved by training a classifier on\npatches centered at the objects of interest \\cite{Viola01}, e.g., the\ncell nuclei in medical image processing of histological slides.\nConsidering only the relation between rectangles within these patches\nresults in illumination invariant features which give the same\nresponse for high and low contrast patches as long as the shape of the\nobject is preserved. It has to be noted, that due to the\ndirectionality of the relation they fail if the image is inverted. In\ngeneral, illumination invariance speeds up the whole analysis process\nbecause neither image normalization nor histogram equalization are\nrequired.\n\t\t\nThe feature base proposed in \\cite{FuchsISVC2009} is defined as\nfollows:  The coordinates of two rectangles $R_1$ and $R_2$ are\nsampled uniformly within a predefined window size $w$:\n", "index": 1, "text": "\n\\[ \nR_i=\\{c_{x1},c_{y1},c_{x2},c_{y2}\\},\\quad c_i \\sim  U(x|0,w)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"R_{i}=\\{c_{x1},c_{y1},c_{x2},c_{y2}\\},\\quad c_{i}\\sim U(x|0,w)\" display=\"block\"><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>c</mi><mrow><mi>x</mi><mo>\u2062</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>c</mi><mrow><mi>y</mi><mo>\u2062</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>c</mi><mrow><mi>x</mi><mo>\u2062</mo><mn>2</mn></mrow></msub><mo>,</mo><msub><mi>c</mi><mrow><mi>y</mi><mo>\u2062</mo><mn>2</mn></mrow></msub><mo stretchy=\"false\">}</mo></mrow><mo rspace=\"12.5pt\">,</mo><msub><mi>c</mi><mi>i</mi></msub><mo>\u223c</mo><mi>U</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">|</mo><mn>0</mn><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $x_i$ is the gray value intensity of pixel $i$ of sample\n$s=\\{x_1,x_2,\\ldots,x_n\\}$ and \n$n_1,n_2$ denote the number of samples in $R_1, R_2$, respectively.\nFrom a general point of view this definition is similar to generalized\nHaar features but there are two main differences: (i) the quantity of\ninterest is not the continuous difference between the rectangles but\nthe boolean relation between them and hence (ii) it is not necessary\nto learn a threshold on the difference to binarize the feature.\n\t\t\t\t\t\t\nFor example, in the validation experiments a window size of\n$65\\times65$ pixels was chosen.  Taking into account that rectangles\nare flipping invariant, this results in\n$\\left((64^4)/4\\right)^2 \\approx 2\\cdot10^{13}$ possible\nfeatures.\\\\ Putting this into perspective, the restriction of the\ndetector to windows of size $24\\times 24$ leads to $\\sim6.9\\cdot10^9$\nfeatures which are significantly more than the $45,396$ Haar features\nfrom classical object detection approaches \\cite{Viola01}.\n\t\t\nFor such huge feature spaces it is currently not possible to\nexhaustively evaluate all features while training a\nclassifier. Approaches like AdaBoost \\cite{freund96} which yield very\ngood results for up to hundreds of thousands of features are not\napplicable any more.  These problems can be overcome by employing\nrandomized algorithms \\cite{FuchsISVC2009, Geurts06} where features\nare sampled randomly for learning classifiers on these random\nprojections.\n\n\\subsection{Inter-Active and Online Learning for Clinical\n  Application}\\label{ssec:interactive} \n\nDay-to-day clinical application of computational pathology algorithms\nrequire adaptivity to a large variety of scenarios. \nNot only that staining protocols and slide\nscanners are constantly updated and changed but common algorithms like\nthe quantification of proliferation factors have to work robustly on\nvarious tissue types.  The detection of multiple objects like nuclei\nin noisy images without an explicit model is still one of the most\nchallenging tasks in computer vision.  Methods which can be applied in\nan plug-and-play \nmanner are not available to date.\n\n\\cite{FuchsOLCV2009} present an inter-active ensemble learning\nalgorithm based on randomized trees, which can be employed to learn an\nobject detector in an inter-active fashion. In addition this learning\nmethod can cope with high dimensional feature spaces in an efficient\nmanner and in contrast to classical approaches, subspaces are not\nsplit based on thresholds but by learning relations between features.\n\nIncorporating the knowledge of domain experts into the process of\nlearning statistical models poses one of the main challenges in machine\nlearning \\cite{Vapnik98} and computer vision.  Data analysis applications in\npathology share properties \nof online and active learning which can be termed inter-active\nlearning. The domain expert interferes with the learning process by\ncorrecting falsely classified samples.  Algorithm\n\\ref{alg_interactive} sketches an overview of the inter-active\nlearning process.\n\t\t \nIn recent years online learning has been of major interest to a large\nvariety of scientific fields.  From the viewpoint of machine learning\n\\cite{Blum96} summarizes a comprehensive overview of existing methods and\nopen challenges. In computer vision online boosting has been\nsuccessfully applied to car detection \\cite{Nguyen07}, video\nsurveillance \\cite{celik08} and visual tracking \\cite{Grabner08}.  One\nof the first inter-active frameworks was developed by \\cite{roth08}\nand applied to pedestrian detection.\n\t\t\nEnsemble methods like boosting \\cite{freund96} and random forests\n\\cite{Amit97, Breiman01} celebrated success\nin a large variety of tasks in statistical learning but in most cases\nthey are only applied offline. Lately, online ensemble learning for\nboosting and bagging was investigated by \\cite{oza01} and\n\\cite{Fern03}.  The online random forest as proposed by\n\\cite{Elgawi08} incrementally adopts new features. Updating decision\ntrees with new samples was described by \\cite{utgoff89,utgoff94} and\nextended by \\cite{kalles96,PfahringerHK07}. Update schemes for pools\nof experts like the WINNOW and Weighted Majority Algorithm were\nintroduced by \\cite{Littlestone88,Littlestone89} and successfully\nemployed since then.\n\t\t\nIn many, not only medical domains, accurate and robust object\ndetection specifies a crucial step in data analysis pipelines. In\npathology for example, the detection of cell nuclei on histological\nslides serves as the basis for a larger number of tasks such as\nimmunohistochemical staining estimation and morphological grading.\nResults of medical interest such as survival prediction are\nsensitively influenced by the accuracy of the object detection\nalgorithm. The diagnosis of the pathologist in turn leads to different\ntreatment strategies and hence directly affects the patient.  For most\nof these medical procedures the ground truth is not known (see Section\n\\ref{sec:ground.truth}) and for most problems biomedical science lacks\northogonal methods which could verify a considered\nhypotheses. Therefore, the subjective opinion of the medical doctor is\nthe only gold standard available for training such decision support\nsystems.\n\n\n\\begin{algorithm}[htbp]\n  \\SetAlgoInsideSkip{medskip}\n  \\vspace{0.3cm}\n  \\KwData{Unlabeled Instances $U = \\{u_1,\\ldots,u_n\\}$ }\t \\%(e.g. image)\n  \\KwIn{Domain Expert $E$}\n  \\KwOut{Ensemble Classifier $C$}\t\t\n  \\caption{Schematic workflow of an inter-active ensemble learning framework. \n    The domain expert interacts with the algorithm\n    to produce a classifier (object detector) which satisfies the conditions \n    based on the experts domain knowledge. }\n  \n  \\vspace{0.3cm}\n  \\While{(expert is unsatisfied with current result)}\n\t{\n\t  classify all samples $u_i$\\;\n\t  \\While{(expert corrects falsely predicted sample $u_i$ with label $l_i$)}\n\t\t{\t\t\t\t\t\n\t\t  update weights of the base classifiers\\\\\n\t\t  learn new base classifiers\n\t\t}\t\t\t\t\t\t\n\t}\n\treturn $C$\n\t\n\t\\label{alg_interactive}\n\\end{algorithm}\t\n\t\t\t\n\t\t\nIn such scenarios the subjective influence of a single human can be\nmitigated by combining the opinions of a larger number of experts. In\npractice consolidating expert judgments is a cumbersome and expensive\nprocess and often additional experts are not available at a given\ntime. To overcome these problems online learning algorithms are\ncapable of incorporating additional knowledge, so-called\nside-information, when it is available.\n\t\t\nIn an ideal clinical setting, a specialized algorithm for cell nuclei\ndetection should be available for each subtype of cancer. By using and\ncorrecting the algorithm several domain experts as its users\ncontinuously train and update the method. Thereby, the combined knowledge of a\nlarge number of experts and repeated training over a longer period of\ntime yields more accurate and more robust classifiers than batch\nlearning techniques.\n\t\t\nThe described setting differs from the conventional views of online\nlearning and active learning insofar that new samples are neither\nchosen at random nor proposed for labeling by the algorithm itself. In\naddition, the adversary is not considered malicious but also not\ncompletely trustworthy. The domain expert reacts to the classification\nof unlabeled data and corrects wrongly classified instances.  These\npreconditions lead to the success or failure of different combination rules.\n\t\t\nIt has to be noted, that these kind of machine learning approaches are\nin sharp contrast to classical rule bases expert systems\n\\cite{Hayes83} which are still used by a number of commercial medical\nimaging companies.  For these applications the user has to be an image\nprocessing experts who chooses dozens of features and thresholds by\nhand to create a rule set adapted to the data.  Contrary to that\nstrategy, in an inter-active learning framework the user has to be a\ndomain expert, in our case a trained pathologists. Feature extraction\nand learning of statistical models is performed by the algorithms so\nthat the expert can concentrate on the biomedical problem at hand.\nInter-active learning frameworks like \\cite{Nguyen07, FuchsOLCV2009}\nshow promising results, but further research especially on long term\nlearning and robustness is mandatory to estimate the reliability of\nthese methods prior to an application in clinical practice.\n\n\n\\subsection{Multispectral Imaging and Source Separation}\n\t\t\nMultispectral imaging \\cite{Levenson2006, Loos08} for\nimmunohistochemically stained tissue and brightfield microscopy seems\nto be a promising technology although a number of limitations have to\nbe kept in mind.\n\t\t\t\nTo date, double- or triple-staining of tissue samples on a single\nslide in brightfield (non-fluorescence) microscopy poses still a major\nchallenge. \nTraditionally, double staining relied on chromogens, which have been\nselected to provide maximum color contrast for observation with the\nunaided eye.  For visually good color combinations, however,\ntechnically feasible choices always include at least one diffuse\nchromogen, due to the lack of appropriate chromogen colors.\nAdditional problems arise from spatial overlapping and from unclear\nmixing of colors.  Currently, these problem are addressed by cutting\nserial sections and by staining each one with a different antibody and\na single colored label. Unfortunately, localized information on a\ncell-by-cell basis is lost with this approach. In the absence of\nlarger structures like glands, registration of sequential slices\nproved to be highly unreliable and often not feasible at all.\nMultispectral imaging yield single-cell-level multiplexed imaging of\nstandard Immunohistochemistry in the same cellular compartment. This\ntechnique even works in the presence of a counterstain and each label\ncan be unmixed into separate channels without bleed-through.\n\t\t\t\t\t\t\nComputational pathology algorithms would profit from multispectral\nimaging also is experiments with single stains, due to the possibility\nto accurately separate the specific label signals from the background\ncounterstain.\n\t\t\t\nPractical suggestions for immunoenzyme double staining procedures for\nfrequently encountered antibody combinations like rabbit\u00e2\u0080\u0093mouse,\ngoat\u00e2\u0080\u0093mouse, mouse\u00e2\u0080\u0093mouse, and rabbit\u00e2\u0080\u0093rabbit are discussed in\n\\cite{Loos08}. The suggested protocols are all suitable for a\nclassical red-brown color combination plus blue nuclear\ncounterstain. Although the red and brown chromogens do not contrast\nvery well visually, they both show a crisp localization and can be\nunmixed by spectral imaging.\n\nDetection an segmentation of nuclei, glands or other structures\nconstitute a crucial steps in various computational pathology\nframeworks. With the use of supervised machine learning techniques\nthese tasks are often performed by trained classifiers which assign\nlabels to single pixels. Naturally one can ask if MSI could improve\nthis classification process and if the additional spectral bands\ncontain additional information?  A study conducted by\n\\cite{Boucheron07} set out to answer this question in the scope of\nroutine clinical histopathology imagery. They compared MSI stacks with\nRGB imagery with the use of several classifier ranging from linear\ndiscriminant analysis (LDA) to support vector machines (SVM).  For\nH\\&E slide the results indicate performance differences of less than\n1\\% using multispectral imagery as opposed to preprocessed RGB\nimagery.  Using only single image bands for classification showed that\nthe single best multispectral band (in the red portion of the\nspectrum) resulted in a performance increase of $0.57\\%$, compared to\nthe performance of the single best RGB band (red).  Principal\ncomponents analysis (PCA) of the multispectral imagery indicated only\ntwo significant image bands, which is not surprising given the\npresence of two stains.  The results of \\cite{Boucheron07} indicate\nthat MSI provides minimal additional spectral information than would\nstandard RGB imagery for routine H\\&E stained histopathology.\n\t\t\t\nAlthough the results of this study are convincing it has to be noted\nthat only slides with two channels were analyzed. For triple and\nquadruple staining as described in \\cite{Loos08} MSI could still\nencode additional information which should lead to a higher\nclassification performance.  Similar conclusions are drawn by\n\\cite{Cukierski09}, stating that MSI has significant potential to\nimprove segmentation and classification accuracy either by\nincorporation of features computed across multiple wavelengths or by\nthe addition of spectral unmixing algorithms.  \n\t\t\t\nComplementary to supervised learning as described before,\n\\cite{Rabinovich03} proposed unsupervised blind source separation for\nextracting the contributions of various histological stains to the\noverall spectral composition throughout a tissue sample. As a\npreprocessing step all images of the multispectral stack were\nregistered to each other considering affine transformations.\nSubsequently it was shown that Non-negative Matrix Factorization (NMF)\n\\cite{Lee99} and Independent Component Analysis (ICA)\n\\cite{Hyvarinen01} compare favorable to Color Deconvolution\n\\cite{Ruifrok01}.  Along the same lines \\cite{Begelman09} advocate\nprincipal component analysis (PCA) and blind source separation (BSS)\nto decompose hyperspectral images into spectrally homogeneous\ncompounds.\n\nIn the domain of fluorescence imaging \\cite{Zimmermann05} give an\noverview of several source separation methods. The main difficulty\nstems from the significant overlap of the emission spectra even with\nthe use of fluorescent dyes.  To this end \\cite{Newberg09} conduct a\nstudy on more than 3500 images from the Human Protein Atlas\n\\cite{Berglund08, Ponten08}.  They concluded that subcellular\nlocations can be determined with an accuracy of $87.5\\%$ by the use of\nsupport vector machines and random forests \\cite{Amit97, Breiman01}.\nDue to the spread of Type-2 diabetes there is growing interest in\npancreatic islet segmentation and cell counting of $\\alpha$ and\n$\\beta$-cells \\cite{Herold09}.  An approach which is based on the\nstrategies described in Section \\ref{ssec:invariance} and Section\n\\ref{ssec:interactive} is described in \\cite{FlorosMICCAI09}.\n\n\nIt is an appealing idea to apply source separation techniques not only\nto multispectral imaging but also to standard RGB images. This\napproach could be useful for a global staining estimation of the\nseparate channels or as a preprocessing step for training a\nclassifier. Unfortunately, antigen-antibody reactions are not\nstoichiometric. Hence the intensity/darkness of a stain does not\nnecessarily\ncorrelate with the amount of reaction products. With the\nexception of Feulgen staining also most histological stains \nare not stoichiometric.  \\cite{Loos08} also state that the brown DAB\nreaction product is not a true absorber of light, but a scatterer of\nlight, and has a very broad, featureless spectrum. This optical\nbehavior implies that DAB does not follow the Beer-Lambert law, which\ndescribes the linear relationship between the concentration of a\ncompound and its absorbance, or optical density. As a consequence,\ndarkly stained DAB has a different spectral shape than lightly stained\nDAB. Therefore attempting to quantify DAB intensity using source\nseparation techniques is not advisable.  Contrary to this observation,\nemploying a non-linear convolution algorithm as preprocessing for a linear\nclassifier, e.g. for segmentation could be of benefit.\n\nFinally, multispectral imaging is not available for automated whole\nslide scanning which constrains its applicability. Imaging a TMA\nmanually with a microscope and a MSI adapter is too tedious and time\nconsuming.\n\t\t\t\n\t\t\n\n\\subsection{Software Engineering Aspects}\t\t\t\n\t\t\nOne of the earliest approaches for high performance computing in\npathology used image matching algorithms based on decision trees to\nretrieve images from a database \\cite{Wetzel97}. The approach was\napplied to Gleason grading in prostate cancer. Web-based data\nmanagement frameworks for TMAs like \\cite{Thallinger07} facilitate not\nonly storage of image data but also storage of experimental and\nproduction parameters throughout the TMA workflow.\n\n\nA crucial demand on software engineering is the ability to scale\nautomated analysis to multiple spots on a TMA slide and even\nmultiple whole microscopy slides.\nBesides cloud computing one possibility to achieve that goal \nis grid computing.\n\\cite{Foran09} demonstrated the feasibility of such a system\nby using the caGrid infrastructure \\cite{Oster08} for Grid-enabled \ndeployment of an automated cancer tissue segmentation algorithm for \nTMAs.\n\n\nA comprehensive list of open source and public domain software for\nimage analysis in pathology is available at\n\\href{www.computational-pathology.org}{www.computational-pathology.org}.\n\n\n\n\n\n\\section{Statistics: Survival Analysis and Machine Learning in Medical Statistics}\\label{sec:statistics}  \n\t\t\nThe main thrust of research in computational pathology is to build\ncompletely probabilistic models of the complete processing pipelines\nfor histological and medical data. In\nmedical research this nearly always also includes time to event data,\nwhere the event is either overall survival, specific survival, event\nfree survival or recurrence free survival of patients.  Statistics and\nmachine learning within this scope is defined as Survival Analysis.\n\n\\subsection{Censoring and Descriptive Statistics}\t\t\nMost difficulties in survival statistics arise from the fact, that\nnearly all clinical datasets contain patients with censored survival\ntimes. The most common form of censoring is right censored data which\nmeans that the death of the patient is not observer during the runtime\nof the study or that the patient withdrew from the study, e.g. because\nhe moved to another location.\n\t\t\nThe nonparametric Kaplan-Meier estimator \\cite{Kaplan58} is frequently\nused to estimate the survival function from right censored data. This\nprocedure requires first toorder the survival times from the smallest\nto the largest such that $t_{1}\\leq t_{2}\\leq t_{3}\\leq\\ldots\\leq\nt_{n}$, where $t_{j}$ is the $j$th largest unique survival time. The\nKaplan-Meier estimate of the survival function is then obtained as\n\n", "itemtype": "equation", "pos": 38109, "prevtext": "\nFor each rectangle the intensities of the underlying gray scale image\nare summed up and normalized by the area of the rectangle.  The\nfeature $f(s,R_1,R_2)$ evaluates to a boolean value by comparing these\nquantities:\n\n", "index": 3, "text": "\\begin{equation}\nf(s,R_1,R_2) = \\begin{cases} 1 & \\text{if }\n  \\displaystyle\\sum_{i|x_i \\in  R_1}  \\frac{x_i}{n_{1}} < \n  \\sum_{i|x_i \\in R_2}\\frac{x_i}{n_{2}} \\\\\n  0 & \\text{otherwise}\n\\end{cases}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"f(s,R_{1},R_{2})=\\begin{cases}1&amp;\\text{if }\\displaystyle\\sum_{i|x_{i}\\in R_{1}}%&#10;\\frac{x_{i}}{n_{1}}&lt;\\sum_{i|x_{i}\\in R_{2}}\\frac{x_{i}}{n_{2}}\\\\&#10;0&amp;\\text{otherwise}\\end{cases}\" display=\"block\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><msub><mi>R</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mn>1</mn></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo stretchy=\"false\">|</mo><msub><mi>x</mi><mi>i</mi></msub><mo>\u2208</mo><msub><mi>R</mi><mn>1</mn></msub></mrow></munder><mfrac><msub><mi>x</mi><mi>i</mi></msub><msub><mi>n</mi><mn>1</mn></msub></mfrac></mrow></mrow><mo>&lt;</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo stretchy=\"false\">|</mo><msub><mi>x</mi><mi>i</mi></msub><mo>\u2208</mo><msub><mi>R</mi><mn>2</mn></msub></mrow></munder><mfrac><msub><mi>x</mi><mi>i</mi></msub><msub><mi>n</mi><mn>2</mn></msub></mfrac></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $r_j$ is the number of individuals at risk just before $t_{j}$,\nand $d_j$ is the number of individuals who die at time $t_{j}$.\n\nTo measure the goodness of separation between two or more groups, the\nlog-rank test (Mantel-Haenszel test) \\cite{Mantel59} is employed to\nassesses the null hypothesis that there is no difference in the\nsurvival experience of the individuals in the different groups. The\ntest statistic of the log-rank test (LRT) is $\\chi^2$ distributed:\n\n", "itemtype": "equation", "pos": 56538, "prevtext": "\nwhere $x_i$ is the gray value intensity of pixel $i$ of sample\n$s=\\{x_1,x_2,\\ldots,x_n\\}$ and \n$n_1,n_2$ denote the number of samples in $R_1, R_2$, respectively.\nFrom a general point of view this definition is similar to generalized\nHaar features but there are two main differences: (i) the quantity of\ninterest is not the continuous difference between the rectangles but\nthe boolean relation between them and hence (ii) it is not necessary\nto learn a threshold on the difference to binarize the feature.\n\t\t\t\t\t\t\nFor example, in the validation experiments a window size of\n$65\\times65$ pixels was chosen.  Taking into account that rectangles\nare flipping invariant, this results in\n$\\left((64^4)/4\\right)^2 \\approx 2\\cdot10^{13}$ possible\nfeatures.\\\\ Putting this into perspective, the restriction of the\ndetector to windows of size $24\\times 24$ leads to $\\sim6.9\\cdot10^9$\nfeatures which are significantly more than the $45,396$ Haar features\nfrom classical object detection approaches \\cite{Viola01}.\n\t\t\nFor such huge feature spaces it is currently not possible to\nexhaustively evaluate all features while training a\nclassifier. Approaches like AdaBoost \\cite{freund96} which yield very\ngood results for up to hundreds of thousands of features are not\napplicable any more.  These problems can be overcome by employing\nrandomized algorithms \\cite{FuchsISVC2009, Geurts06} where features\nare sampled randomly for learning classifiers on these random\nprojections.\n\n\\subsection{Inter-Active and Online Learning for Clinical\n  Application}\\label{ssec:interactive} \n\nDay-to-day clinical application of computational pathology algorithms\nrequire adaptivity to a large variety of scenarios. \nNot only that staining protocols and slide\nscanners are constantly updated and changed but common algorithms like\nthe quantification of proliferation factors have to work robustly on\nvarious tissue types.  The detection of multiple objects like nuclei\nin noisy images without an explicit model is still one of the most\nchallenging tasks in computer vision.  Methods which can be applied in\nan plug-and-play \nmanner are not available to date.\n\n\\cite{FuchsOLCV2009} present an inter-active ensemble learning\nalgorithm based on randomized trees, which can be employed to learn an\nobject detector in an inter-active fashion. In addition this learning\nmethod can cope with high dimensional feature spaces in an efficient\nmanner and in contrast to classical approaches, subspaces are not\nsplit based on thresholds but by learning relations between features.\n\nIncorporating the knowledge of domain experts into the process of\nlearning statistical models poses one of the main challenges in machine\nlearning \\cite{Vapnik98} and computer vision.  Data analysis applications in\npathology share properties \nof online and active learning which can be termed inter-active\nlearning. The domain expert interferes with the learning process by\ncorrecting falsely classified samples.  Algorithm\n\\ref{alg_interactive} sketches an overview of the inter-active\nlearning process.\n\t\t \nIn recent years online learning has been of major interest to a large\nvariety of scientific fields.  From the viewpoint of machine learning\n\\cite{Blum96} summarizes a comprehensive overview of existing methods and\nopen challenges. In computer vision online boosting has been\nsuccessfully applied to car detection \\cite{Nguyen07}, video\nsurveillance \\cite{celik08} and visual tracking \\cite{Grabner08}.  One\nof the first inter-active frameworks was developed by \\cite{roth08}\nand applied to pedestrian detection.\n\t\t\nEnsemble methods like boosting \\cite{freund96} and random forests\n\\cite{Amit97, Breiman01} celebrated success\nin a large variety of tasks in statistical learning but in most cases\nthey are only applied offline. Lately, online ensemble learning for\nboosting and bagging was investigated by \\cite{oza01} and\n\\cite{Fern03}.  The online random forest as proposed by\n\\cite{Elgawi08} incrementally adopts new features. Updating decision\ntrees with new samples was described by \\cite{utgoff89,utgoff94} and\nextended by \\cite{kalles96,PfahringerHK07}. Update schemes for pools\nof experts like the WINNOW and Weighted Majority Algorithm were\nintroduced by \\cite{Littlestone88,Littlestone89} and successfully\nemployed since then.\n\t\t\nIn many, not only medical domains, accurate and robust object\ndetection specifies a crucial step in data analysis pipelines. In\npathology for example, the detection of cell nuclei on histological\nslides serves as the basis for a larger number of tasks such as\nimmunohistochemical staining estimation and morphological grading.\nResults of medical interest such as survival prediction are\nsensitively influenced by the accuracy of the object detection\nalgorithm. The diagnosis of the pathologist in turn leads to different\ntreatment strategies and hence directly affects the patient.  For most\nof these medical procedures the ground truth is not known (see Section\n\\ref{sec:ground.truth}) and for most problems biomedical science lacks\northogonal methods which could verify a considered\nhypotheses. Therefore, the subjective opinion of the medical doctor is\nthe only gold standard available for training such decision support\nsystems.\n\n\n\\begin{algorithm}[htbp]\n  \\SetAlgoInsideSkip{medskip}\n  \\vspace{0.3cm}\n  \\KwData{Unlabeled Instances $U = \\{u_1,\\ldots,u_n\\}$ }\t \\%(e.g. image)\n  \\KwIn{Domain Expert $E$}\n  \\KwOut{Ensemble Classifier $C$}\t\t\n  \\caption{Schematic workflow of an inter-active ensemble learning framework. \n    The domain expert interacts with the algorithm\n    to produce a classifier (object detector) which satisfies the conditions \n    based on the experts domain knowledge. }\n  \n  \\vspace{0.3cm}\n  \\While{(expert is unsatisfied with current result)}\n\t{\n\t  classify all samples $u_i$\\;\n\t  \\While{(expert corrects falsely predicted sample $u_i$ with label $l_i$)}\n\t\t{\t\t\t\t\t\n\t\t  update weights of the base classifiers\\\\\n\t\t  learn new base classifiers\n\t\t}\t\t\t\t\t\t\n\t}\n\treturn $C$\n\t\n\t\\label{alg_interactive}\n\\end{algorithm}\t\n\t\t\t\n\t\t\nIn such scenarios the subjective influence of a single human can be\nmitigated by combining the opinions of a larger number of experts. In\npractice consolidating expert judgments is a cumbersome and expensive\nprocess and often additional experts are not available at a given\ntime. To overcome these problems online learning algorithms are\ncapable of incorporating additional knowledge, so-called\nside-information, when it is available.\n\t\t\nIn an ideal clinical setting, a specialized algorithm for cell nuclei\ndetection should be available for each subtype of cancer. By using and\ncorrecting the algorithm several domain experts as its users\ncontinuously train and update the method. Thereby, the combined knowledge of a\nlarge number of experts and repeated training over a longer period of\ntime yields more accurate and more robust classifiers than batch\nlearning techniques.\n\t\t\nThe described setting differs from the conventional views of online\nlearning and active learning insofar that new samples are neither\nchosen at random nor proposed for labeling by the algorithm itself. In\naddition, the adversary is not considered malicious but also not\ncompletely trustworthy. The domain expert reacts to the classification\nof unlabeled data and corrects wrongly classified instances.  These\npreconditions lead to the success or failure of different combination rules.\n\t\t\nIt has to be noted, that these kind of machine learning approaches are\nin sharp contrast to classical rule bases expert systems\n\\cite{Hayes83} which are still used by a number of commercial medical\nimaging companies.  For these applications the user has to be an image\nprocessing experts who chooses dozens of features and thresholds by\nhand to create a rule set adapted to the data.  Contrary to that\nstrategy, in an inter-active learning framework the user has to be a\ndomain expert, in our case a trained pathologists. Feature extraction\nand learning of statistical models is performed by the algorithms so\nthat the expert can concentrate on the biomedical problem at hand.\nInter-active learning frameworks like \\cite{Nguyen07, FuchsOLCV2009}\nshow promising results, but further research especially on long term\nlearning and robustness is mandatory to estimate the reliability of\nthese methods prior to an application in clinical practice.\n\n\n\\subsection{Multispectral Imaging and Source Separation}\n\t\t\nMultispectral imaging \\cite{Levenson2006, Loos08} for\nimmunohistochemically stained tissue and brightfield microscopy seems\nto be a promising technology although a number of limitations have to\nbe kept in mind.\n\t\t\t\nTo date, double- or triple-staining of tissue samples on a single\nslide in brightfield (non-fluorescence) microscopy poses still a major\nchallenge. \nTraditionally, double staining relied on chromogens, which have been\nselected to provide maximum color contrast for observation with the\nunaided eye.  For visually good color combinations, however,\ntechnically feasible choices always include at least one diffuse\nchromogen, due to the lack of appropriate chromogen colors.\nAdditional problems arise from spatial overlapping and from unclear\nmixing of colors.  Currently, these problem are addressed by cutting\nserial sections and by staining each one with a different antibody and\na single colored label. Unfortunately, localized information on a\ncell-by-cell basis is lost with this approach. In the absence of\nlarger structures like glands, registration of sequential slices\nproved to be highly unreliable and often not feasible at all.\nMultispectral imaging yield single-cell-level multiplexed imaging of\nstandard Immunohistochemistry in the same cellular compartment. This\ntechnique even works in the presence of a counterstain and each label\ncan be unmixed into separate channels without bleed-through.\n\t\t\t\t\t\t\nComputational pathology algorithms would profit from multispectral\nimaging also is experiments with single stains, due to the possibility\nto accurately separate the specific label signals from the background\ncounterstain.\n\t\t\t\nPractical suggestions for immunoenzyme double staining procedures for\nfrequently encountered antibody combinations like rabbit\u00e2\u0080\u0093mouse,\ngoat\u00e2\u0080\u0093mouse, mouse\u00e2\u0080\u0093mouse, and rabbit\u00e2\u0080\u0093rabbit are discussed in\n\\cite{Loos08}. The suggested protocols are all suitable for a\nclassical red-brown color combination plus blue nuclear\ncounterstain. Although the red and brown chromogens do not contrast\nvery well visually, they both show a crisp localization and can be\nunmixed by spectral imaging.\n\nDetection an segmentation of nuclei, glands or other structures\nconstitute a crucial steps in various computational pathology\nframeworks. With the use of supervised machine learning techniques\nthese tasks are often performed by trained classifiers which assign\nlabels to single pixels. Naturally one can ask if MSI could improve\nthis classification process and if the additional spectral bands\ncontain additional information?  A study conducted by\n\\cite{Boucheron07} set out to answer this question in the scope of\nroutine clinical histopathology imagery. They compared MSI stacks with\nRGB imagery with the use of several classifier ranging from linear\ndiscriminant analysis (LDA) to support vector machines (SVM).  For\nH\\&E slide the results indicate performance differences of less than\n1\\% using multispectral imagery as opposed to preprocessed RGB\nimagery.  Using only single image bands for classification showed that\nthe single best multispectral band (in the red portion of the\nspectrum) resulted in a performance increase of $0.57\\%$, compared to\nthe performance of the single best RGB band (red).  Principal\ncomponents analysis (PCA) of the multispectral imagery indicated only\ntwo significant image bands, which is not surprising given the\npresence of two stains.  The results of \\cite{Boucheron07} indicate\nthat MSI provides minimal additional spectral information than would\nstandard RGB imagery for routine H\\&E stained histopathology.\n\t\t\t\nAlthough the results of this study are convincing it has to be noted\nthat only slides with two channels were analyzed. For triple and\nquadruple staining as described in \\cite{Loos08} MSI could still\nencode additional information which should lead to a higher\nclassification performance.  Similar conclusions are drawn by\n\\cite{Cukierski09}, stating that MSI has significant potential to\nimprove segmentation and classification accuracy either by\nincorporation of features computed across multiple wavelengths or by\nthe addition of spectral unmixing algorithms.  \n\t\t\t\nComplementary to supervised learning as described before,\n\\cite{Rabinovich03} proposed unsupervised blind source separation for\nextracting the contributions of various histological stains to the\noverall spectral composition throughout a tissue sample. As a\npreprocessing step all images of the multispectral stack were\nregistered to each other considering affine transformations.\nSubsequently it was shown that Non-negative Matrix Factorization (NMF)\n\\cite{Lee99} and Independent Component Analysis (ICA)\n\\cite{Hyvarinen01} compare favorable to Color Deconvolution\n\\cite{Ruifrok01}.  Along the same lines \\cite{Begelman09} advocate\nprincipal component analysis (PCA) and blind source separation (BSS)\nto decompose hyperspectral images into spectrally homogeneous\ncompounds.\n\nIn the domain of fluorescence imaging \\cite{Zimmermann05} give an\noverview of several source separation methods. The main difficulty\nstems from the significant overlap of the emission spectra even with\nthe use of fluorescent dyes.  To this end \\cite{Newberg09} conduct a\nstudy on more than 3500 images from the Human Protein Atlas\n\\cite{Berglund08, Ponten08}.  They concluded that subcellular\nlocations can be determined with an accuracy of $87.5\\%$ by the use of\nsupport vector machines and random forests \\cite{Amit97, Breiman01}.\nDue to the spread of Type-2 diabetes there is growing interest in\npancreatic islet segmentation and cell counting of $\\alpha$ and\n$\\beta$-cells \\cite{Herold09}.  An approach which is based on the\nstrategies described in Section \\ref{ssec:invariance} and Section\n\\ref{ssec:interactive} is described in \\cite{FlorosMICCAI09}.\n\n\nIt is an appealing idea to apply source separation techniques not only\nto multispectral imaging but also to standard RGB images. This\napproach could be useful for a global staining estimation of the\nseparate channels or as a preprocessing step for training a\nclassifier. Unfortunately, antigen-antibody reactions are not\nstoichiometric. Hence the intensity/darkness of a stain does not\nnecessarily\ncorrelate with the amount of reaction products. With the\nexception of Feulgen staining also most histological stains \nare not stoichiometric.  \\cite{Loos08} also state that the brown DAB\nreaction product is not a true absorber of light, but a scatterer of\nlight, and has a very broad, featureless spectrum. This optical\nbehavior implies that DAB does not follow the Beer-Lambert law, which\ndescribes the linear relationship between the concentration of a\ncompound and its absorbance, or optical density. As a consequence,\ndarkly stained DAB has a different spectral shape than lightly stained\nDAB. Therefore attempting to quantify DAB intensity using source\nseparation techniques is not advisable.  Contrary to this observation,\nemploying a non-linear convolution algorithm as preprocessing for a linear\nclassifier, e.g. for segmentation could be of benefit.\n\nFinally, multispectral imaging is not available for automated whole\nslide scanning which constrains its applicability. Imaging a TMA\nmanually with a microscope and a MSI adapter is too tedious and time\nconsuming.\n\t\t\t\n\t\t\n\n\\subsection{Software Engineering Aspects}\t\t\t\n\t\t\nOne of the earliest approaches for high performance computing in\npathology used image matching algorithms based on decision trees to\nretrieve images from a database \\cite{Wetzel97}. The approach was\napplied to Gleason grading in prostate cancer. Web-based data\nmanagement frameworks for TMAs like \\cite{Thallinger07} facilitate not\nonly storage of image data but also storage of experimental and\nproduction parameters throughout the TMA workflow.\n\n\nA crucial demand on software engineering is the ability to scale\nautomated analysis to multiple spots on a TMA slide and even\nmultiple whole microscopy slides.\nBesides cloud computing one possibility to achieve that goal \nis grid computing.\n\\cite{Foran09} demonstrated the feasibility of such a system\nby using the caGrid infrastructure \\cite{Oster08} for Grid-enabled \ndeployment of an automated cancer tissue segmentation algorithm for \nTMAs.\n\n\nA comprehensive list of open source and public domain software for\nimage analysis in pathology is available at\n\\href{www.computational-pathology.org}{www.computational-pathology.org}.\n\n\n\n\n\n\\section{Statistics: Survival Analysis and Machine Learning in Medical Statistics}\\label{sec:statistics}  \n\t\t\nThe main thrust of research in computational pathology is to build\ncompletely probabilistic models of the complete processing pipelines\nfor histological and medical data. In\nmedical research this nearly always also includes time to event data,\nwhere the event is either overall survival, specific survival, event\nfree survival or recurrence free survival of patients.  Statistics and\nmachine learning within this scope is defined as Survival Analysis.\n\n\\subsection{Censoring and Descriptive Statistics}\t\t\nMost difficulties in survival statistics arise from the fact, that\nnearly all clinical datasets contain patients with censored survival\ntimes. The most common form of censoring is right censored data which\nmeans that the death of the patient is not observer during the runtime\nof the study or that the patient withdrew from the study, e.g. because\nhe moved to another location.\n\t\t\nThe nonparametric Kaplan-Meier estimator \\cite{Kaplan58} is frequently\nused to estimate the survival function from right censored data. This\nprocedure requires first toorder the survival times from the smallest\nto the largest such that $t_{1}\\leq t_{2}\\leq t_{3}\\leq\\ldots\\leq\nt_{n}$, where $t_{j}$ is the $j$th largest unique survival time. The\nKaplan-Meier estimate of the survival function is then obtained as\n\n", "index": 5, "text": "\\begin{equation}\n  \\hat{S}(t) = \\prod_{j:t_{(j)}\\leq t}{\\left(  1-\\frac{d_j}{r_j}\\right)}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\hat{S}(t)=\\prod_{j:t_{(j)}\\leq t}{\\left(1-\\frac{d_{j}}{r_{j}}\\right)}\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>S</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>j</mi><mo>:</mo><mrow><msub><mi>t</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msub><mo>\u2264</mo><mi>t</mi></mrow></mrow></munder><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><msub><mi>d</mi><mi>j</mi></msub><msub><mi>r</mi><mi>j</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $d_{1i}$ is the number of deaths in the first group at $t_{i}$\nand $e_{1i}=r_{1j}\\frac{d_{i}}{r_i}$ where $d_i$ is the total number\nof deaths at time $t_{(i)}$, $r_j$ is the total number of individuals\nat risk at this time, and $r_{1i}$ the number of individuals at risk\nin the first group. Figure \\ref{fig:surv} depicts Kaplan-Meier plots\nfor two subgroups each and the LRT p-values. The associated data is\ndescribed in detail in Section \\ref{sec:view}.\n\t\t\t\t\t\n\n\\subsection{Survival Analysis}\nSurvival Analysis as a branch of statistics is not restricted to\nmedicine but analyses time to failure or event data and is also\napplicable to biology, engineering, economics etc.  Particularly in\nthe context of medical statistics, it is a powerful tool for\nunderstanding the effect of patient features on survival patterns\nwithin specific groups \\cite{Klein97}. A parametric approach to such\nan analysis involves the estimation of parameters of a probability\ndensity function which models time.\n\nIn general the distribution of a random variable $T$ (representing\ntime) is defined over the interval $[0,\\infty)$. Furthermore, a\nstandard survival function is specified based on the cumulative\ndistribution over $T$ as follows:\n\n\n", "itemtype": "equation", "pos": 57115, "prevtext": "\nwhere $r_j$ is the number of individuals at risk just before $t_{j}$,\nand $d_j$ is the number of individuals who die at time $t_{j}$.\n\nTo measure the goodness of separation between two or more groups, the\nlog-rank test (Mantel-Haenszel test) \\cite{Mantel59} is employed to\nassesses the null hypothesis that there is no difference in the\nsurvival experience of the individuals in the different groups. The\ntest statistic of the log-rank test (LRT) is $\\chi^2$ distributed:\n\n", "index": 7, "text": "\\begin{equation}\n  \\hat{\\chi^2} =\n  \\frac{\n    \\left(\\sum^m_{i=1}{(d_{1i}-\\hat{e}_{1i})}\\right)^2\n  }{\n    \\sum^m_{i=1}{\\hat{v}_{1i}}\n  } \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\hat{\\chi^{2}}=\\frac{\\left(\\sum^{m}_{i=1}{(d_{1i}-\\hat{e}_{1i})}\\right)^{2}}{%&#10;\\sum^{m}_{i=1}{\\hat{v}_{1i}}}\" display=\"block\"><mrow><mover accent=\"true\"><msup><mi>\u03c7</mi><mn>2</mn></msup><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mfrac><msup><mrow><mo>(</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>d</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>-</mo><msub><mover accent=\"true\"><mi>e</mi><mo stretchy=\"false\">^</mo></mover><mrow><mn>1</mn><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><msub><mover accent=\"true\"><mi>v</mi><mo stretchy=\"false\">^</mo></mover><mrow><mn>1</mn><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhich models the probability of an individual surviving up to time\n$t_0$.  The hazard function $h(t)$, the instantaneous rate of failure\nat time $t$, is defined as follows:\n\n", "itemtype": "equation", "pos": 58495, "prevtext": "\nwhere $d_{1i}$ is the number of deaths in the first group at $t_{i}$\nand $e_{1i}=r_{1j}\\frac{d_{i}}{r_i}$ where $d_i$ is the total number\nof deaths at time $t_{(i)}$, $r_j$ is the total number of individuals\nat risk at this time, and $r_{1i}$ the number of individuals at risk\nin the first group. Figure \\ref{fig:surv} depicts Kaplan-Meier plots\nfor two subgroups each and the LRT p-values. The associated data is\ndescribed in detail in Section \\ref{sec:view}.\n\t\t\t\t\t\n\n\\subsection{Survival Analysis}\nSurvival Analysis as a branch of statistics is not restricted to\nmedicine but analyses time to failure or event data and is also\napplicable to biology, engineering, economics etc.  Particularly in\nthe context of medical statistics, it is a powerful tool for\nunderstanding the effect of patient features on survival patterns\nwithin specific groups \\cite{Klein97}. A parametric approach to such\nan analysis involves the estimation of parameters of a probability\ndensity function which models time.\n\nIn general the distribution of a random variable $T$ (representing\ntime) is defined over the interval $[0,\\infty)$. Furthermore, a\nstandard survival function is specified based on the cumulative\ndistribution over $T$ as follows:\n\n\n", "index": 9, "text": "\\begin{equation}\n  S(t) = 1 - p(T \\leq t_0) = 1 - \\int_0^{t_0}{p(t)dt},\n  \\label{eq:survivalfunction}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"S(t)=1-p(T\\leq t_{0})=1-\\int_{0}^{t_{0}}{p(t)dt},\" display=\"block\"><mrow><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mn>1</mn><mo>-</mo><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo>\u2264</mo><msub><mi>t</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mn>1</mn><mo>-</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><msub><mi>t</mi><mn>0</mn></msub></msubsup><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><mi>t</mi><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\n\t\t\nThe model is further extended by considering the effect of covariates\n$X$ on time via a regression component.  In medical statistics the\nmost popular method for modeling such effects is Cox's proportionality\nhazards model \\cite{Cox72}:\n\n", "itemtype": "equation", "pos": 58785, "prevtext": "\nwhich models the probability of an individual surviving up to time\n$t_0$.  The hazard function $h(t)$, the instantaneous rate of failure\nat time $t$, is defined as follows:\n\n", "index": 11, "text": "\\begin{equation}\n  h(t) = \\lim\\limits_{\\Delta t \\rightarrow 0} \\frac{P(t< T \\leq t +\n    \\Delta t | T > t )}{\\Delta t } = \\frac{p(T=t)}{S(t)}. \n  \\label{eq:hazardrate}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"h(t)=\\lim\\limits_{\\Delta t\\rightarrow 0}\\frac{P(t&lt;T\\leq t+\\Delta t|T&gt;t)}{%&#10;\\Delta t}=\\frac{p(T=t)}{S(t)}.\" display=\"block\"><mrow><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>t</mi></mrow><mo>\u2192</mo><mn>0</mn></mrow></munder><mo>\u2061</mo><mfrac><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>\u2062</mo><mrow><mo>&lt;</mo><mrow><mi>T</mi><mo>\u2264</mo><mrow><mi>t</mi><mo>+</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>t</mi></mrow></mrow></mrow><mo stretchy=\"false\">|</mo><mi>T</mi><mo>&gt;</mo></mrow><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></mrow><mo>=</mo><mfrac><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo>=</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $h_0 (t)$ is the baseline hazard function, which is the chance\nof instant death given survival till time $t$, ${\\boldsymbol{x}}$ is the vector\nof covariates and ${\\boldsymbol{\\beta}}$ are the regression coefficients.\n\t\t\n\t\n\\subsection{A Bayesian View of Survival Regression}\t\t\t\n\t\t\nBayesian methods are gaining more and more popularity in machine\nlearning in general and in medical statistics in special. A big\nadvantage in survival analysis is the possibility to investigate the\nposterior distribution of a model.  Especially in regularized survival\nregression models \\cite{RothFuchs08} it is possible to get a posterior\ndistribution also on zero coefficients, i.e. for biomarkers which\nhence were not included in the model.\n\t\t\nA common choice of distribution for modeling time is the Weibull\ndistribution which is flexible in terms of being able to model a\nvariety of survival functions and hazard rates. Apart from\nflexibility, it is also the only distribution which captures both the\naccelerated time model and the proportionality hazards model\n\\cite{josephming}.  The Weibull distribution is defined as follows:\n\n", "itemtype": "equation", "pos": 59207, "prevtext": "\n\t\t\nThe model is further extended by considering the effect of covariates\n$X$ on time via a regression component.  In medical statistics the\nmost popular method for modeling such effects is Cox's proportionality\nhazards model \\cite{Cox72}:\n\n", "index": 13, "text": "\\begin{equation}\n  h(t | {\\boldsymbol{x}}) = h_0 (t) \\exp({\\boldsymbol{x}}^{T} {\\boldsymbol{\\beta}} ),\n  \\label{eq:hazards}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"h(t|{\\boldsymbol{x}})=h_{0}(t)\\exp({\\boldsymbol{x}}^{T}{\\boldsymbol{\\beta}}),\" display=\"block\"><mrow><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>h</mi><mn>0</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mi>exp</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc99</mi><mi>T</mi></msup><mi>\ud835\udf37</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $\\alpha_w$ and $\\lambda_w$ are the shape and scale parameters,\nrespectively. Based on the above definition and assuming\nright-censored data \\cite{Klein97}, the likelihood assumes the form\n\n", "itemtype": "equation", "pos": 60467, "prevtext": "\nwhere $h_0 (t)$ is the baseline hazard function, which is the chance\nof instant death given survival till time $t$, ${\\boldsymbol{x}}$ is the vector\nof covariates and ${\\boldsymbol{\\beta}}$ are the regression coefficients.\n\t\t\n\t\n\\subsection{A Bayesian View of Survival Regression}\t\t\t\n\t\t\nBayesian methods are gaining more and more popularity in machine\nlearning in general and in medical statistics in special. A big\nadvantage in survival analysis is the possibility to investigate the\nposterior distribution of a model.  Especially in regularized survival\nregression models \\cite{RothFuchs08} it is possible to get a posterior\ndistribution also on zero coefficients, i.e. for biomarkers which\nhence were not included in the model.\n\t\t\nA common choice of distribution for modeling time is the Weibull\ndistribution which is flexible in terms of being able to model a\nvariety of survival functions and hazard rates. Apart from\nflexibility, it is also the only distribution which captures both the\naccelerated time model and the proportionality hazards model\n\\cite{josephming}.  The Weibull distribution is defined as follows:\n\n", "index": 15, "text": "\\begin{equation}\n  p(t | \\alpha_w, \\lambda_w)\t = \\alpha_w \\frac{1}{\\lambda_w}\n  t^{\\alpha_w -1} \\exp\\left(-\\frac{1}{\\lambda_w} t^{\\alpha_w}\\right), \n  \\label{eq:weib}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"p(t|\\alpha_{w},\\lambda_{w})=\\alpha_{w}\\frac{1}{\\lambda_{w}}t^{\\alpha_{w}-1}%&#10;\\exp\\left(-\\frac{1}{\\lambda_{w}}t^{\\alpha_{w}}\\right),\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">|</mo><msub><mi>\u03b1</mi><mi>w</mi></msub><mo>,</mo><msub><mi>\u03bb</mi><mi>w</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>\u03b1</mi><mi>w</mi></msub><mfrac><mn>1</mn><msub><mi>\u03bb</mi><mi>w</mi></msub></mfrac><msup><mi>t</mi><mrow><msub><mi>\u03b1</mi><mi>w</mi></msub><mo>-</mo><mn>1</mn></mrow></msup><mi>exp</mi><mrow><mo>(</mo><mo>-</mo><mfrac><mn>1</mn><msub><mi>\u03bb</mi><mi>w</mi></msub></mfrac><msup><mi>t</mi><msub><mi>\u03b1</mi><mi>w</mi></msub></msup><mo>)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\nwhere $\\delta_i = 0$ when the $i^{th}$ observation is censored and $1$\notherwise.  Further, to model the effect of covariates ${\\boldsymbol{x}}$ on the\ndistribution over time, Cox's proportional hazards model can be\napplied. Under this model, the covariates are assumed to have a\nmultiplicative effect on the hazard function.\n\n\t\t\n\t\t\n\\subsection{Higher Order Interactions}\n\nA reoccurring question in biomedical research projects and especially\nin TMA analysis studies interactions of markers and their influence on\nthe target. Two modern approaches within the scope of computational\npathology try to solve this question from a frequentist\n\\cite{Dahinden10} and a Bayesian \\cite{RothFuchs08} point of view.\n\t\t\nThe most frequent approach for modeling higher-order interactions\n(like pairs or triplets of features etc.) instead of modeling just the\nmain effects (individual features) are polynomial expansions of\nfeatures. For example the vector ${\\boldsymbol{x}} = \\left\\{x_1,x_2,x_3\\right\\}$\ncan be expanded up to order 2 as ${\\boldsymbol{x}}^{'} =\n\\left\\{x_1,x_2,x_3,x_1:x_2,x_1:x_3,x_2:x_3,x_1:x_2:x_3\\right\\}$.\nAdditional flexibility is built into this model by including a random effect\nin $\\eta$ in the following manner:\n\n", "itemtype": "equation", "pos": 60843, "prevtext": "\nwhere $\\alpha_w$ and $\\lambda_w$ are the shape and scale parameters,\nrespectively. Based on the above definition and assuming\nright-censored data \\cite{Klein97}, the likelihood assumes the form\n\n", "index": 17, "text": "\\begin{equation}\n  p(\\left\\{t_i\\right\\}_{i=0}^{N} | \\alpha_w,\\lambda_w) = \n  \\prod_{i=1}^N{\\left(\\frac{\\alpha_w}{\\lambda_w} t_i^{\\alpha_w\n      -1}\\right) ^{\\delta_i} \\exp\\left(-\\frac{1}{\\lambda_w}\n    t_i^{\\alpha_w}\\right)}, \n  \\label{eq:like1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"p(\\left\\{t_{i}\\right\\}_{i=0}^{N}|\\alpha_{w},\\lambda_{w})=\\prod_{i=1}^{N}{\\left%&#10;(\\frac{\\alpha_{w}}{\\lambda_{w}}t_{i}^{\\alpha_{w}-1}\\right)^{\\delta_{i}}\\exp%&#10;\\left(-\\frac{1}{\\lambda_{w}}t_{i}^{\\alpha_{w}}\\right)},\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mrow><mo>{</mo><msub><mi>t</mi><mi>i</mi></msub><mo>}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>N</mi></msubsup><mo stretchy=\"false\">|</mo><msub><mi>\u03b1</mi><mi>w</mi></msub><mo>,</mo><msub><mi>\u03bb</mi><mi>w</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mrow><mo>(</mo><mfrac><msub><mi>\u03b1</mi><mi>w</mi></msub><msub><mi>\u03bb</mi><mi>w</mi></msub></mfrac><msubsup><mi>t</mi><mi>i</mi><mrow><msub><mi>\u03b1</mi><mi>w</mi></msub><mo>-</mo><mn>1</mn></mrow></msubsup><mo>)</mo></mrow><msub><mi>\u03b4</mi><mi>i</mi></msub></msup><mi>exp</mi><mrow><mo>(</mo><mo>-</mo><mfrac><mn>1</mn><msub><mi>\u03bb</mi><mi>w</mi></msub></mfrac><msubsup><mi>t</mi><mi>i</mi><msub><mi>\u03b1</mi><mi>w</mi></msub></msubsup><mo>)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.00027.tex", "nexttext": "\n\t\t\nTo include the covariate effect the likelihood of Equation\n\\ref{eq:like1} is modified as follows:\n\t\t\n\\begin{eqnarray*}\n  p(\\left\\{t_i \\right\\}_{i=0}^{N} |{\\boldsymbol{x}}_i, \\alpha_w,\\lambda_w) & = &\n  \\prod_{i=1}^N{\\left[\\frac{\\alpha_w}{\\lambda_w} t_i^{\\alpha_w -1}\n      \\exp(\\eta_i)\\right] ^{\\delta_i} } \\cdot \\\\ \n  & & \\dot\n  \\exp\\left(-\\frac{1}{\\lambda_w} t_i^{\\alpha_w} \\exp(\\eta_i)\\right)\n  \\label{eq:like2}\t\n\\end{eqnarray*}\n\t\t\n\t\t\n\t\t\nThese kind of models can be seen as enhancement of generalized linear\nmodels \\cite{Mccullaghand} and are called random-intercept models. For\na full Bayesian treatment of the model, suitable priors have to be\ndefined for the parameters of the model, namely $\\alpha_w$,\n$\\lambda_w$, $\\sigma$ and ${\\boldsymbol{\\beta}}$.  Useful priors for this model\nare described in \\cite{RothFuchs08}.\n\n\n\\subsection{Mixtures of Survival Experts}\n\t\t\nFrequently,  sub-groups of patients specified by characteristic\nsurvival times have to be identified together with the effects of\ncovariates within each sub-group. Such information might hint at the\ndisease mechanisms. Statistically this grouping is represented by\na mixture model or specifically by a mixture of survival experts.\n\n\nTo this end, \\cite{rosentanner99} define a \\textit{finite}\nmixture-of-experts model by maximizing the partial likelihood for the\nregression coefficients and by using some heuristics to resolve the\nnumber of experts in the model. More recently\n\\cite{Ando04kernelmixture} use a maximum likelihood approach to infer\nthe parameters of the model and the Akaike information criterion (AIC)\nto determine the number of mixture components.\n\t\t\nA Bayesian version of the mixture model \\cite{Kottas2006578} analyzes\nthe model with respect to time but does not capture the effect of\ncovariates. On the other hand the work by\n\\cite{Ibrahim96bayesianvariable} performs variable selection based on\nthe covariates but ignores the clustering aspect of the modeling.\nSimilarly, \\cite{paserman04} defines an infinite mixture model but\ndoes not include a mixture of experts, hence implicitly assuming that all\nthe covariates are generated by the same distribution with a common\nshape parameter for the Weibull distribution.\n\n\t\t\t\t\n\\cite{RothFuchs08} unify the various important elements of this\nanalysis into a Bayesian mixture-of-experts (MOE) framework to model\nsurvival time, while capturing the effect of covariates and also\ndealing with an unknown number of mixing components. To infer the\nnumber of experts a Dirichlet process prior on the mixing proportions\nis applied, which solves the issue of determining the number of\nmixture components beforehand \\cite{Rasmussen02infinitemixtures}. Due\nto the lack of fixed-length sufficient statistics, the Weibull\ndistribution is not part of the exponential family of distributions\nand hence the regression component, introduced via the proportionality\nhazards model, is non-standard. Furthermore, the framework of\n\\cite{RothFuchs08} includes sparsity constraints to the regression\ncoefficients in order to determine the key explanatory factors\n(biomarkers) for each mixture component. Sparseness \nis achieved by utilizing a Bayesian version of the Group-Lasso\n\\cite{Raman09a, Raman09b} which is a sparse constraint for grouped\ncoefficients \\cite{yuan06model}.\n\t\t\n\n\n\n\n\\section{The Computational Pathology Pipeline: A holistic View}\\label{sec:view}\n\t\t\t\nThis chapter describes an genuine computational pathology project,\nwhich has been designed following the principles described in the previous\nsections. It is an ongoing project in kidney cancer research\nconducted at the University Hospital Zurich and ETH Zurich. Parts of\nit were published in \\cite{FuchsMICCAI2008} and \\cite{FuchsISVC2009},\nwhere also algorithmic details of the computational approach can be\nfound.\n\t\t\t\n\\begin{figure*}[htbp]\n  \\begin{center}\t\t\t\t\t\n    \\includegraphics[width=1\\linewidth]{images/CompPathRCC_wide.png}\t\t\t\t\n  \\end{center}\t\t\t\n  \\caption{A computational pathology framework for investigating the\n  proliferation marker MIB-1 in clear cell renal cell carcinoma.\n  Following the definition in Section \\ref{ssec:definition} the\n  framework consists of three parts: (i) The covariate data $X$\n  existing of images of TMA spots was generated in a trial at \n  the University Hospital Zurich. Extensive labeling experiments\n  were conducted to generate a gold standard comprising cancerous\n  cell nuclei and background samples.\n  (ii) Image analysis consisted of learning a relational detection\n  forest (RDF) and conducting mean shift clustering for nuclei \n  detection. Subsequently, the staining of detected nuclei was\n  determined based on their color histograms.\n  (iii) Using this system, TMA spots of $133$ RCC patients were \n  analysed. Finnaly, the subgroup of patients with high \n  expression of the proliferation marker was compared to\n  the group with low expression using the Kaplen-Meier estimator.\n    \\label{fig:comppathrcc}}\n\\end{figure*}\n\t\t\t\nFigure \\ref{fig:comppathrcc} depicts a schematic overview of the\nproject subdivided into the three main parts which are discussed\nin the following:\n\n\\subsection{Data Generation}\nThe data generation process consists of acquiring images of the TMA \nspots representing the covariates $X$ in the statistical model and\nthe target variable $Y$ which comprises detection and classification\nlabels for nuclei.\n\nThe tissue microarray block was generated in a trial at the \nUniversity Hospital Zurich. TMA slides were immunohistochemically \nstained with the MIB-1 (Ki-67) antigen and scanned on a Nanozoomer \nC9600 virtual slide light microscope scanner from HAMAMATSU. \nThe magnification of $40\\times$ resulted in a per pixel \nresolution of $0.23\\mu m$. The tissue microarry was tiled into single \nspots of size $3000\\times3000$ pixel, representing one patient each.\n\nVarious strategies can be devised to estimate the progression status\nof cancerous tissue: (i) we could first detect cell nuclei and then\nclassify the detected nuclei as cancerous or benign\n\\cite{FuchsDAGM2008}; (ii) the nucleus detection phase could be merged\nwith the malignant/benign classification to simultaneously train a\nsliding window detector for cancerous nuclei only.\nTo this end samples of cancerous nuclei were collected using the\nlabeling experiments described in Section \\ref{ssec:labelingex}.\nVoronoi Sampling \\cite{FuchsISVC2009} was used to generate a set of\nnegative background patches which are spatially well distributed in\nthe training images. Hence a Voronoi tessellation is created based on\nthe locations of the positive samples and background patches are\nsampled at the vertices of the Voronoi diagram.  In contrast to\nuniform rejection sampling, using a tessellation has the advantage\nthat the negative samples are concentrated on the area of tissue close\nto the nulei and few samples are spent on the homogeneous\nbackground. (The algorithm should not be confused with Lloyd's\nalgorithm \\cite{Lloyd82} which is also known as Voronoi iteration.)\nThe result of the data generation process is a labeled set of\nimage patches of size $65 \\times 65$ pixel.\n\n\n\n\\subsection{Image Analysis}\nThe image analysis part of the pipeline consists of learning\na relational detection forest \\cite{FuchsISVC2009} based on\nthe samples extracted in the previous step. To guarantee\nillumination invariance, the feature basis described in \nSection \\ref{ssec:invariance} is used.\n\nThe strong class imbalance in the training set is accounted for by\nrandomly subsampling the background class for each tree\nof the ensemble. The model parameters are adjusted by\noptimizing the out of bag (OOB) error \\cite{Breiman01}\nand they consist of the number of trees, the maximum tree depth\nand the number of features sampled at each node in a tree.\n\nFor prediction each pixel of a TMA spot is classified\nby the relation detection forest. This results in a \nprobability map in the size of the image where the gray \nvalue at each position indicates the probability of being \nthe location of a cancerous nucleus.\nFinally, weighted mean shift clustering is conducted with\na circular box kernel based on the average radius $r$ of \nthe nuclei in the training set. This process yields the final\ncoordinates of the detected cancerous nuclei.\n\nTo differentiate a stained nucleus from a non-stained \nnucleus a simple color model is learned. Based on the \nlabeled nuclei, color histograms are generated for both \nclasses based on the pixels within a radius $r$.\nA test nucleus is then classified based on the \ndistance to the centroid histograms of both classes.\n\nThe final staining estimation per patient is achieved\nby calculating the percentage of stained cancerous\nnuclei.\n\n\n\n\\subsection{Survival Statistics}\n\nThe only objective endpoint in the majority of TMA studies is the\nprediction of the number of months a patient survived. The experiments\ndescribed in Section \\ref{ssec:labelingex} document the large disagreement\nbetween pathologists for the estimation of staining. Hence, fitting an\nalgorithm to the estimates of a single pathologist or to a consensus\nvoting of a commitee of pathologist is not desirable.\n\t\t\t\t\nTo this end the proposed computational pathology framework is\nvalidated against the right censored clinical survival data of the\n$133$ ccRCC patients. In addition these results were compared to the\nestimations of an expert pathologist specialized on renal cell\ncarcinoma. He analyzed all spots in an exceptional thorough manner\nwhich required him more than two hours. This time consuming annotation\nexceeds the standard clinical practice significantly by a factor of\n$10-20$ and, therefore, the results can be viewed as an excellent\nhuman estimate for this dataset.\n\t\t\t\n\t\t\t\n\n\\begin{figure}[htbp]\n  \\begin{center}\t\t\t\t\t\n    \\includegraphics[width=1\\linewidth]{images/survivalFinal.pdf}\t\t\t\t\n  \\end{center}\t\t\t\n  \\caption{Kaplan-Meier estimators show significantly different\n    survival times for renal cell carcinoma patients with high and low\n    proliferating tumors. Compared to the manual estimation from the\n    pathologist (a) ($p=0.04$), the fully automatic estimation from\n    the algorithm (b) compares favorable ($p=0.01$) in terms of\n    survival differences (log rank test) for the partitioning of\n    patients into two groups of equal size \\cite{FuchsISVC2009}.\n    \\label{fig:surv}}\n\\end{figure}\n\nFigure \\ref{fig:surv} shows Kaplan-Meier plots of the estimated\ncumulative survival for the pathologist and the computational\npathology framework. The farther the survival estimates of the two\ngroups are separated the better the estimation. Quantifying this\ndifference with a log-rank test shows that the proposed framework\nperforms favorable ($p=0.0113$) to the trained pathologist\n($p=0.0423$) and it can differentiate between the survival\nexpectancy of the two groups of patients.\n\n\n\\subsection{Project Conclusion}\nThe presented computational pathology framework can be characterized\nby the following properties: (i) \\textbf{Simplicity:} It can be used\nin a plug-and-play fashion\nto train object detectors in near real time for large variety of\ntasks. (ii) \\textbf{Novel Feature Basis:} The introduced relational\nfeatures are able to capture shape information, they are illumination\ninvariant and extremely fast to evaluate. (iii)\n\\textbf{Randomization:} The randomized tree induction algorithm is\nable to \nexploit the richness of the intractable large feature space and to\ntake advantage of it by increasing diversity of the ensemble.  (iv)\n\\textbf{Real World Applicability:} The proposed algorithms perform\nwell not only on renal cancer tissue but also in fluorescent imaging\nof pancreatic islets \\cite{FlorosMICCAI09} and in quantifying staining\nin murine samples \\cite{Bettermann10}.\n\n\n\n\n\n\n\\section{Future Directions}\n\n\t\t\t\t\t\n\\subsection{Histopathological Imaging}\nOne promising research direction in medical image analysis points to\nonline learning and interactive learning of computer vision\nmodels. Not only covers histopathology a broad and heterogeneous field but\nnew biomarkers, antibodies and stainings are developed on a daily\nbasis. To this end, real world applications have to \nquickly adapt to changing tissue types and staining modalities. Domain\nexperts should be able to train these models in an interactive fashion\nto accustom novel data. For example, a classifier for object detection\ncan be trained by clicking on novel objects or correcting for false\ndetections.\n\nA necessary prerequisite for research in computational pathology\nproved to be the scanning of whole slides and TMAs. \\cite{Huisman10}\ndescribe a fully digital pathology slide archive which has been\nassembled \nby high-volume tissue slide scanning.  The Peta bytes of histological\ndata which\nwill be available in the near future pose also a number of software\nengineering challenges, including\ndistributed processing of whole slides and TMAs in clusters or the\ncloud, multiprocessor and multicore implementations of analysis\nalgorithms and facilitating real time image processing on GPUs.\n\n\t\t\t\t\t\t\t\n\\subsection{Clinical Application and Decision Support}\n\nIn today's patient care we observe the interesting trend \nto integrate pathological diagnoses in web based patient files.\nAvatar based visualization proved to be useful not only for medical\nexperts but also for a new generation of patients who are better\ninformed and demand online updated and appropriately visualized\ninformations about their own disease state and treatment procedures.\n\nFurthermore this approach can be extended for decision support by\nstatistical models which are able to utilize this unified view of\npatients incorporating data from a large variety of clinical sources,\ne.g. pathology, cytology, radiology, etc.\n\n\n\\subsection{Pathology@home}\nReal-time, in vivo cancer detection on cellular level appears as a futuristic\ndream in patient care but could be a reality in a few years.\n\\cite{Shin10} constructed a fiber-optic fluorescence microscope using\na consumer-grade camera for in vivo cellular imaging. The fiber-optic\nfluorescence microscope includes an LED light, an objective lens, a\nfiber-optic bundle, and a consumer-grade DSLR. The system was used to\nimage an oral cancer cell line, a human tissue specimen and the oral\nmucosa of a healthy human subject in vivo, following topical\napplication of $0.01\\%$ proflavine.  The fiber-optic microscope\nresolved individual nuclei in all specimens and tissues imaged. This\ncapability allowed qualitative and quantitative differences between\nnormal and precancerous or cancerous tissues to be identified. In\ncombination with a computational pathology framework, this technique\nwould allow the real time classification of cancerous cells in\nepithelial tissues.  Such a portable and inexpensive system is\nespecially interesting for patient care in low-resource settings \nlike the developing world.\n\n\nConstructing a microscope for mobile phones defines the future of\npatient care in remote sites with centralized analysis support. \n\\cite{Breslauer09} built a mobile phone-mounted light microscope and\ndemonstrated its potential for clinical use by imaging sickle and\nP. falciparum-infected red blood cells in brightfield and\nM. tuberculosis-infected sputum samples in fluorescence with LED\nexcitation. In all cases the resolution exceeded the critical level\nthat is necessary to detect blood cell and microorganism morphology.\nThis concept could provide an interesting tool for disease diagnosis\nand screening, especially in the developing world and rural areas\nwhere laboratory facilities are scarce but mobile phone infrastructure\nis available.\n\n\n\\subsection{Standards and Exchange Formats}\nOne of the major obstacles for wide spread use of computational\npathology is the absence of generally agreed upon standards and\nexchange formats.  This deficit not only handicaps slide processing\nmanagement and whole slide digital imaging \\cite{Daniel09}, but it\nalso extends to statistical models and analysis software.\nStandardized exchange formats would support project specific\ncombinations of object detectors, staining estimation algorithms and\nmedical statistics.  It would be very much desirable if at least the\nresearch community would agree on a few simple interfaces for data and\nmodel exchange.\n\n\n\\subsection{Further Reading}\nAll links and references presented in this review together with\nsoftware, statistical models and a blog about the topic are\navailable from \\href{www.computational-pathology.org}{www.computational-pathology.org}.\n\n\n\n\\section*{Acknowledgments}\nThe authors wish to thank Holger Moch and Peter Schraml for their help \nin conducting the RCC TMA project, Peter Wild and Peter Bode for annotating the\nmedical data and Monika Bieri and Norbert Wey for scanning and tiling\nthe TMA slides. Special thanks also to Volker Roth and Sudhir Raman for\nvaluable discussions. We also acknowledge financial support from the FET\nprogram within the EU FP7, under the SIMBAD project (Contract\n213250).\n\n\n\n\\bibliographystyle{elsarticle-num}\n\\bibliography{main}\n\n\n\n", "itemtype": "equation", "pos": 62328, "prevtext": "\nwhere $\\delta_i = 0$ when the $i^{th}$ observation is censored and $1$\notherwise.  Further, to model the effect of covariates ${\\boldsymbol{x}}$ on the\ndistribution over time, Cox's proportional hazards model can be\napplied. Under this model, the covariates are assumed to have a\nmultiplicative effect on the hazard function.\n\n\t\t\n\t\t\n\\subsection{Higher Order Interactions}\n\nA reoccurring question in biomedical research projects and especially\nin TMA analysis studies interactions of markers and their influence on\nthe target. Two modern approaches within the scope of computational\npathology try to solve this question from a frequentist\n\\cite{Dahinden10} and a Bayesian \\cite{RothFuchs08} point of view.\n\t\t\nThe most frequent approach for modeling higher-order interactions\n(like pairs or triplets of features etc.) instead of modeling just the\nmain effects (individual features) are polynomial expansions of\nfeatures. For example the vector ${\\boldsymbol{x}} = \\left\\{x_1,x_2,x_3\\right\\}$\ncan be expanded up to order 2 as ${\\boldsymbol{x}}^{'} =\n\\left\\{x_1,x_2,x_3,x_1:x_2,x_1:x_3,x_2:x_3,x_1:x_2:x_3\\right\\}$.\nAdditional flexibility is built into this model by including a random effect\nin $\\eta$ in the following manner:\n\n", "index": 19, "text": "\\begin{equation}\n  \\eta = {\\boldsymbol{x}}^{t} {\\boldsymbol{\\beta}} + \\epsilon, \\hspace{20pt} \\text{where\n    \\  } \\epsilon \\sim N(0,\\sigma^2). \n  \\label{eq:etanormal}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\eta={\\boldsymbol{x}}^{t}{\\boldsymbol{\\beta}}+\\epsilon,\\hskip 20.0pt\\text{%&#10;where&#10;\\ }\\epsilon\\sim N(0,\\sigma^{2}).\" display=\"block\"><mrow><mrow><mrow><mi>\u03b7</mi><mo>=</mo><mrow><mrow><msup><mi>\ud835\udc99</mi><mi>t</mi></msup><mo>\u2062</mo><mi>\ud835\udf37</mi></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><mtext>where\u00a0</mtext><mo>\u2062</mo><mi>\u03f5</mi></mrow><mo>\u223c</mo><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><msup><mi>\u03c3</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]