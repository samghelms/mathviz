[{"file": "1601.04071.tex", "nexttext": "\nwhere the product goes over all node pairs $i, j$ in the network, $x_{ij}$ is the hyperbolic distance between pair $i, j$,\n\\begin{eqnarray}\n\\label{eq:x_ji}\n\\nonumber x_{ij}&=&\\mathrm{arccosh}\\left(\\cosh{r_i}\\cosh{r_j}-\\sinh{r_i} \\sinh {r_j} \\cos{\\Delta\\theta_{ij}}\\right)\\\\\n\\nonumber &\\approx& r_i+r_j+2\\ln{\\sin{(\\Delta\\theta_{ij}/2)}},\\\\\n\\nonumber &\\approx& r_i+r_j+2\\ln{(\\Delta\\theta_{ij}/2)},\\\\\n&\\quad\\textnormal{where}~~& \\Delta \\theta_{ij}=\\pi-|\\pi-|\\theta_i-\\theta_j||,\n\\end{eqnarray}\nand $p(x_{ij})$ is the Fermi-Dirac connection probability,\n\n", "itemtype": "equation", "pos": 47985, "prevtext": "\n\n\\author{Kaj-Kolja Kleineberg}\n\\email{kkl@ffn.ub.edu}\n\\author{Mari\\'an Bogu\\~{n}\\'a}\n\\email{marian.boguna@ub.edu}\n\\affiliation{Departament de F\\'isica Fonamental, Universitat de Barcelona, \nMart\\'i i Franqu\\`es 1, 08028 Barcelona, Spain}\n\\author{M. \u00c3\u0081ngeles Serrano}\n\\email{marian.serrano@ub.edu}\n\\affiliation{Instituci\\'o Catalana de Recerca i Estudis Avan\\c{c}ats (ICREA), Passeig Llu\\'is Companys 23, E-08010 Barcelona, Spain}\n\\affiliation{Departament de F\\'isica Fonamental, Universitat de Barcelona, Mart\\'i i Franqu\\`es 1, 08028 Barcelona, Spain}\n\\author{Fragkiskos Papadopoulos}\n\\email{f.papadopoulos@cut.ac.cy}\n\\affiliation{Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology, 33 Saripolou Street, 3036 Limassol, Cyprus}\n\\date{\\today}\n\n\\title{Geometric correlations in real multiplex networks: \\\\multidimensional communities, trans-layer link prediction, and efficient navigation}\n\n\\begin{abstract}\nReal networks often form interacting parts of larger and more complex systems. Examples can be found in different domains, ranging from the Internet to structural and functional brain networks. Here, we show that these multiplex systems are not random combinations of single network layers. Instead, they are organized in specific ways dictated by hidden geometric correlations between the individual layers. We find that these correlations are strong in different real multiplexes, and form a key framework for answering many important questions. Specifically, we show that these geometric correlations facilitate: (i) the definition and detection of multidimensional communities, which are sets of nodes that are simultaneously similar in multiple layers; (ii) accurate trans-layer link prediction, where connections in one layer can be predicted by observing the hidden geometric space of another layer;  and (iii) efficient targeted navigation in the multilayer system using only local knowledge, which outperforms navigation in the single layers only if the geometric correlations are sufficiently strong. Our findings uncover fundamental organizing principles behind real multiplexes and can have important applications in diverse domains.\n\\end{abstract}\n\n\\keywords{complex networks, multiplex networks, network geometry, hyperbolic geometry, geometric correlations, multidimensional communities, trans-layer link prediction, mutual greedy routing}\n\n\\maketitle\n\n\n\\section{Introduction}\n\\label{introduction}\n\nReal networks are often not isolated entities but instead can be considered constituents of larger systems, called multiplexes or multilayer networks~\\cite{multilayer:kivel, arenas:radicchi:2013, ginestra:natphys, radicci:percolation, arenas:multiplex,Thurner:multi, Menichetti, Halu}. Examples can be found everywhere. The most classical one is the multiplex consisting of the different social networks that a person may belong to. Other examples include \nthe Internet's IPv4 and IPv6 topologies, or the structural and functional networks in the brain. Understanding the relations among the networks comprising a larger multiplex is crucial for understanding the behavior of a wide range of real world systems~\\cite{our:model, ecology20, worldmodel, DeDomenico2014, Simas2015}. However, despite the burst of recent research in studying the properties of multiplex networks, e.g.,~\\cite{arenas:multiplex,multilayer:kivel,Boccaletti20141}, a universal framework describing the relations among the single networks comprising a multiplex, and what implications these relations may have when it comes to applications, remains elusive.\n\nHere, we show that real multiplexes are not random combinations of single network layers. Instead, we find that their constituent networks exhibit strong \\emph{hidden geometric correlations}. These correlations are called ``hidden\" as they are not directly observable by looking at each individual network's topology. Specifically, each single network can be mapped (embedded) into a separate hyperbolic space~\\cite{Krioukov2010,Boguna2010,frag:hypermap,frag:hypermap_cn}, where node coordinates abstract the \\emph{popularity} and \\emph{similarity} of nodes~\\cite{Serrano2008,boguna:popularity}. We find that node coordinates are strongly correlated across layers of real multiplexes, meaning that distances between nodes in the underlying hyperbolic spaces of the constituent networks are also strongly correlated.\n\nThe discovered geometric correlations yield a very powerful framework for answering important questions related to real multiplexes. Specifically, we first show that these correlations imply the existence of multidimensional communities, which are sets of nodes that are similar (close in the underlying space) in multiple layers, and which we can detect. Further, we show that strong geometric correlations imply accurate trans-layer link prediction, where connections in one layer can be predicted by knowing the hyperbolic distances among nodes in another layer. This is important for applications where we only know the connections among nodes in one context, e.g., structural connections between brain regions, and we want to predict connections between the same nodes in some other context, e.g., likelihood of functional connections between the same brain regions. \n\nFinally, we also consider targeted navigation that uses only local knowledge. Targeted navigation is a key function of many real networks, where either goods, people, or information is transferred from a source to a destination using the connections of the network. It has been shown that single complex networks, like the IPv4 Internet or the network of airport connections, can be navigated efficiently by performing \\emph{greedy routing} in their underlying geometric spaces~\\cite{Boguna2008, Boguna2010, Papadopoulos2010, Krioukov2010}. In greedy routing, nodes forward a message to their neighbor that is closest to the destination in the geometric space. The message either reaches its target, or it enters a loop, i.e. the message is given back to a node it already visited, and the delivery fails. To study navigation in multilayer systems, we extend the notion of greedy routing so that a node forwards a message to its neighbor that is closest to the destination in any of the layers comprising the system. We call this process \\emph{mutual greedy routing}.\n\nMutual greedy routing follows the same line of reasoning as greedy routing in Milgram's experiment~\\cite{milgram1969}. For example, in the case of a single network, to reach a lawyer in Boston one might want to forward a message to a judge in Los Angeles (greedy routing). However, in the case of two network layers, it might be known that the lawyer in Boston is also a passionate vintage model train collector. An individual who knows a judge in Los Angeles and the owner of a vintage model train shop in New York, who might be attending all the vintage train meetings, would probably choose to forward the message to the latter (mutual greedy routing). Similarly, air travel networks can be supported by train networks to enhance the possibilities to navigate the physical world, individuals can use different online social networks to increase their outreach, and so on. In this work, we consider the real Internet, which is used to navigate the digital world, and show that mutual greedy routing in the multiplex consisting of the IPv4 and IPv6 Internet topologies~\\cite{as_topo} outperforms greedy routing in the single IPv4 and IPv6 networks. We also use synthetic model networks to show that geometric correlations improve the navigation of multilayer systems, which outperforms navigation in the single layers if these correlations are sufficiently strong. In this context, we also investigate under which conditions adding more layers improves the navigability of a multilayer system.\n\n\n\\section{Geometric organization of real multiplexes}\nIt has been shown that many real (single layer) complex networks have an effective or hidden geometry underneath their observed topologies, which is hyperbolic rather than Euclidean~\\cite{Krioukov2009, Krioukov2010, Boguna2010, boguna:popularity}. In this work, we extend the hidden geometry paradigm to real multiplexes and prove that the coordinates of nodes in the different underlying spaces of layers are correlated.\n\n\\subsection{Geometry of single layer networks}\nNodes of real single-layered networks can be mapped to points in the hyperbolic plane, such that each node $i$ has the polar coordinates, or hidden variables, $r_i, \\theta_i$. The radial coordinate $r_i$ abstracts the node popularity. The smaller the radial coordinate of a node, the more popular the node is, and the more likely it attracts connections. The angular distance between two nodes, $\\Delta \\theta_{ij}=\\pi-|\\pi-|\\theta_i-\\theta_j||$, abstracts their similarity. The smaller this distance, the more similar two nodes are, and the more likely they are connected. The hyperbolic distance between two nodes, very well approximated by $x_{ij} \\approx r_i+r_j+2\\ln{\\sin{(\\Delta\\theta_{ij}/2)}}$~\\cite{Krioukov2010}, is then a single-metric representation of a combination of the two attractiveness attributes, radial popularity and angular similarity. The smaller the hyperbolic distance between two nodes, the higher is the probability that the nodes are connected, meaning that connections take place by optimizing trade-offs between popularity and similarity~\\cite{boguna:popularity}. \n\nTechniques based on Maximum Likelihood Estimation for inferring the popularity and similarity node coordinates in a real network have been derived in~\\cite{Boguna2010} and recently optimized in~\\cite{frag:hypermap, frag:hypermap_cn}. It has been shown that through the constructed hyperbolic maps one can identify soft communities of nodes, which are groups of nodes located close to each other in the angular similarity space~\\cite{Boguna2010, Serrano2011, boguna:popularity}; predict missing links with high precision~\\cite{Serrano2011,frag:hypermap, frag:hypermap_cn}; and facilitate efficient greedy routing in the Internet, which can reach destinations with more than $90$\\% success rate, following almost shortest network paths~\\cite{Boguna2010, frag:hypermap, frag:hypermap_cn}.\n\n\n\\subsection{Geometry of real multiplexes}\n\\begin{figure}[b]\n\\centering\n\\includegraphics[width=1\\linewidth]{figure1.pdf}\n\\caption{\\textbf{Hyperbolic mapping of the IPv4/IPv6 Internet.} \\textbf{A:} IPv4 topology---for clarity only nodes with degrees greater than $3$ are shown. \\textbf{B:} IPv6 topology. \n\\label{fig_internet_embedding}}\n\\end{figure}\n\\begin{table*}[t]\n\\begin{ruledtabular}\n\\begin{tabular}{lllll}\n\\textbf{Name} &  \\textbf{Type} & \\textbf{Nodes} & \\textbf{Layer~1/Layer~2} &~\\textbf{Source} \\\\ \\hline\nInternet & Technological & Autonomous Systems & IPv4 AS topology/IPv6 AS topology &~\\cite{as_topo} \\\\ \nAir/Train & Technological & Airports, Train stations & Indian airport network/Indian train network &~\\cite{Halu} \\\\\nDrosophila & Biological & Proteins & Suppressive genetic interaction/Additive genetic interaction &~\\cite{biogrid,arenas:reduce} \\\\\nC. Elegans & Biological & Neurons & Electric synaptic junctions/Chemical monadic synaptic junctions &~\\cite{pnas:celegans,muxviz} \\\\\nBrain & Biological & Brain regions & Structural network/Functional network &~\\cite{Simas2015} \\\\\narXiv & Collaboration & Authors & physics.bio-ph category/cond-mat.dis-nn category& ~\\cite{prx:modular} \\\\\n\\end{tabular}\n\\end{ruledtabular}\n\\caption{Overview of the considered real-world multiplex network data. Details for each dataset can be found in Appdenix~\\ref{appendix_datasets}.\n\\label{tab_datasets}}\n\\end{table*}\n\nWe now consider different real-world multiplex networks from diverse domains. Specifically, we consider the IPv4 and IPv6 topologies of the Internet's Autonomous Systems~\\cite{as_topo}, the Indian airport and train networks~\\cite{Halu}, genetic interaction networks from the Drosophila Melanogaster (common fruit fly)~\\cite{biogrid, arenas:reduce}, synaptic junction networks from the  C. Elegans Connectomme~\\cite{pnas:celegans, muxviz}, structural and functional networks from the human brain~\\cite{Simas2015}, and collaboration networks from two different categories of arXiv papers that have the word ``networks\" in the title or abstract~\\cite{prx:modular}. An overview of the considered datasets is given in Table~\\ref{tab_datasets}---see Appendix~\\ref{appendix_datasets} for a more detailed description.\n\nFor each multiplex, we map each network layer independently to an underlying hyperbolic space using the \\emph{HyperMap} method~\\cite{frag:hypermap, frag:hypermap_cn} (see Appendix~\\ref{appendix_hypermap}), thus inferring the popularity and similarity coordinates $r,\\theta$ of all of its nodes. A vizualization of the mapped IPv4 and IPv6 Internet layers is shown in Fig.~\\ref{fig_internet_embedding}.\nFor each of our real multiplexes, we find that node coordinates across layers are not independent. Specifically, we find that both the radial and the angular coordinates of nodes that exist in different layers are correlated. \n\nThe radial popularity coordinate of a node $i$ depends on its observed degree in the network $k_i$ via $r_i \\sim \\ln{N}-\\ln{k_i}$, where $N$ is the total number of nodes~\\cite{Boguna2010, frag:hypermap, frag:hypermap_cn}. Therefore, radial correlations are equivalent to correlations among node degrees, which have been recently found and studied~\\cite{pre:multiplex:correlations, pre:degree:correlations:2, prl:degree:correlations, scirep:degree:corr, self:similar:multiplex}. Consistent with these findings, radial correlations are present in our real multiplexes and are encoded in the conditional probability $P(r_2|r_1)$, which is the probability that a node has radial coordinate $r_2$ in layer 2 given its radial coordinate $r_1$ in layer 1. $P(r_2|r_1)$ for the Internet is shown in Fig.~\\ref{fig_conditional_radial} of Appendix~\\ref{appendix_hypermap}, where we observe strong correlations among the radial coordinates of nodes in the IPv4 and IPv6 topologies.\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=1\\linewidth]{figure2.png}\n\\caption{\\textbf{Distribution of nodes in the two-dimensional similarity space of the Internet, Drosophila, and arXiv multiplexes (top panel)}. The plots correspond to nodes that exist in both layers of each system. The angular similarity coordinate of a node in layer 1 is denoted by $\\theta_1$ and in layer 2 by $\\theta_2$. The histogram heights are equal to the number of nodes falling within each two-dimensional similarity bin, and the colors in each case denote the relative magnitude of the heights. \\textbf{Bottom panel:} The same distributions as in the top panel but for the reshuffled counterparts of the real systems. \n\\label{fig_histogram}}\n\\end{figure*}\n\nThe correlation among the angular similarity coordinates, on the other hand, is a fundamentally new result that has important practical implications. Fig.~\\ref{fig_histogram} shows the distribution of nodes that have angular coordinates $\\theta_1,\\theta_2$ in layers $1, 2$ of the real Internet, Drosophila, and arXiv multiplexes. The figure also shows the corresponding distributions in the reshuffled counterparts of the real systems, where we have destroyed the trans-layer coordinate correlations by randomly reshuffling node ids (see Appendix~\\ref{appendix_reshuffling}). From Fig.~\\ref{fig_histogram}, we observe an overabundance of two-dimensional similarity clusters in the real multiplexes. These clusters consist of nodes that are similar, i.e., are located at small angular distances, in both layers of the multiplex. These similarity clusters do not exist in the reshuffled counterparts of the real systems, and are evidence of strong angular correlations. \nSimilar results hold for the rest of the real multiplexes that we considered (see  Fig.~\\ref{fig_appendix_histo} in Appendix~\\ref{appendix_all_histograms}).\n\nThe generalization of community definition and detection techniques from single layer networks to multiplex systems has recently gained attention~\\cite{multiplex:communities, prx:modular, multiplex:community:cs}. Our approach here allows one to naturally define and detect multidimensional communities of nodes, which are sets of nodes that are similar, that is, close in the angular similarity space, in multiple layers simultaneously. Furthermore, it also provides a measure of distance between different communities, cf.~Fig.~\\ref{fig_histogram}. In Appendix~\\ref{appendix_regions_communities}, we show how certain geographic regions are associated to two-dimensional communities in the IPv4/IPv6 Internet.\n\n\nThe radial and angular correlations across different layers suggest that the hyperbolic distances among nodes are also correlated. Since nodes that are closer hyperbolically have higher chances of being connected, we expect that by knowing the hyperbolic distances between nodes in one layer we can predict the likelihood that the nodes are connected in the other layer. Fig.~\\ref{fig_link_prediction} (top) validates that this is indeed the case. The figure shows the empirical trans-layer connection probability, $P(1|2)$ ($P(2|1)$), that two nodes are connected in one of the layers of the multiplex, given their hyperbolic distance in the other layer. The results are for the Internet, Drosophila, and arXiv multiplexes, and for their reshuffled counterparts. Fig.~\\ref{fig_con_prob_si} in Appendix~\\ref{appendix_all_histograms} shows the results for the rest of the multiplexes. \n\nTo compute the trans-layer connection probability, we consider all nodes that exist in both layers. In each of the layers, we bin the range of hyperbolic distances between these nodes from zero to the maximum distance into small bins. For each bin we then find all the node pairs located at the hyperbolic distances falling within the bin. The percentage of pairs in this set of pairs that are connected by a link in the other layer, is the value of the empirical trans-layer connection probability at the bin. We observe (Fig.~\\ref{fig_link_prediction} (top)) that this probability decreases with the hyperbolic distance between nodes in all the real multiplexes. By contrast, in their reshuffled counterparts, which do not exhibit geometric correlations, this probability is almost a straight line. Fig.~\\ref{fig_link_prediction} (bottom) shows that the trans-layer connection probability decreases with the angular distance between nodes, which provides an alternative empirical validation of the existence of strong similarity correlations across the layers.\n\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=01\\linewidth]{figure3.pdf}\n\\caption{\\textbf{Trans-layer connection probability in the Internet, Drosophila, and arXiv multiplexes.} \\textbf{Top panel:} Trans-layer connection probability as a function of hyperbolic distance. $P(j|i)$ denotes the probability that a pair of nodes is connected in layer $j$ given its hyperbolic distance $x$ in layer $i$. $P_{\\text{ran}}(j|i)$ denotes the same probability for the reshuffled counterpart of each real system. \\textbf{Bottom panel:} Corresponding trans-layer connection probabilities when considering only the angular (similarity) distance between nodes, $\\Delta\\theta$.\n\\label{fig_link_prediction}}\n\\end{figure*}\n\nThe problem of link prediction has been extensively studied in the context of predicting missing and future links in single layer networks~\\cite{link:prediction:1,Clauset:2008:Hierarchicalstructure}. Its generalization to real-world multilayer systems is recently gaining attention~\\cite{multiplex:link:prediction:1}. The trans-layer link prediction approach we described here is quite general, i.e., applicable to any real multiplex with geometric structure, and allows one to estimate the most probable connections among nodes in one layer of the multiplex, by knowing the hyperbolic distances among the same nodes in another layer. \n\n\n\\section{Modeling geometric correlations and implications to mutual greedy routing}\n\\label{sec_model}\n\nThe IPv4 Internet has been found to be navigable~\\cite{Boguna2010, frag:hypermap, frag:hypermap_cn}. Specifically, it has been shown that greedy routing (GR) could reach destinations with more than 90\\% success rate in the constructed hyperbolic maps of the IPv4 topology in 2009. We find a similar efficiency of GR in both the IPv4 and IPv6 topologies considered here, which correspond to January 2015. Specifically,  we perform GR in the hyperbolic map of each topology among $10^5$ randomly selected source-destination pairs that exist in both topologies. We find that GR reaches destinations with $90\\%$ success rate in IPv4, and with $92\\%$ success rate in IPv6. Furthermore, we also perform angular GR, which is the same as GR but uses only the angular distances. We find that the success rate in this case is almost $60\\%$ in both the IPv4 and IPv6 topologies. However, hyperbolic mutual greedy routing (that hereafter we refer to as mutual GR) between the same source-destination pairs, which travels to any neighbor in any layer closer to destination, increases the success rate to $95\\%$, while the angular mutual GR that uses only the angular distances, increases the success rate along the angular direction to $66\\%$. We are interested in angular mutual GR because its performance depends only on the angular similarity coordinates of nodes in the different layers. More details about the mutual GR process are found in Appendix~\\ref{appendix_navigation}. \n\nThe observations above raise the following fundamental questions. (i) How do the radial and angular correlations affect the performance of mutual GR? (ii) Under which conditions does mutual GR perform better than single-layer GR? (iii) How does the performance of mutual GR depend on the number of layers in a multilayer system? And (iv), how close to the optimal---in terms of mutual GR's performance---are the geometric correlations in the IPv4/IPv6 Internet? Answering these questions requires a framework to construct realistic synthetic topologies (layers) where correlations---both radial and angular---can be tuned without altering the topological characteristics of each individual layer. We develop such a framework here, whose technical details are given in Appendix~\\ref{appendix_model_general}.\n\nOur framework builds on the (single-layer) network construction procedure prescribed by the newtonian $\\mathbb{S}^{1}$\\cite{Serrano2008} and hyperbolic $\\mathbb{H}^{2}$ models~\\cite{Krioukov2010}. The two models are isomorphic and here we present the results for the $\\mathbb{H}^{2}$ version even if for calculations it is more convenient to make use of the $\\mathbb{S}^{1}$. We recall that to construct a network of size $N$, the $\\mathbb{H}^{2}$ model firsts assigns to each node $i=1,\\ldots, N$ its popularity and similarity coordinates $r_i, \\theta_i$. Subsequently, it connects each pair of nodes $i, j$ with probability $p(x_{ij})=1/(1+e^{\\frac{1}{2T}(x_{ij}-R)})$, where $x_{ij}$ is the hyperbolic distance between the nodes and $R \\sim \\ln{N}$ (see Appendix~\\ref{single_layer}). The connection probability $p(x_{ij})$ is nothing but the Fermi-Dirac distribution. Parameter $T$ is the \\emph{temperature} and controls clustering in the network~\\cite{Dorogovtsev10-book}, which is the probability that two neighbors of a node are connected. The average clustering $\\bar{c}$ is maximized at $T=0$, nearly linearly decreases to zero with $T \\in [0,1)$, and is asymptotically zero if $T>1$. It has been shown that the $\\mathbb{S}^{1}$ and $\\mathbb{H}^{2}$ models can construct synthetic networks that resemble real networks across a wide range of structural characteristics, including power law degree distributions and strong clustering~\\cite{Serrano2008,Krioukov2010}.  Our framework constructs single-layer topologies using these models, and allows for radial and angular coordinate correlations across the different layers. The strength of these correlations can be tuned via model parameters $\\nu \\in [0,1]$ and $g \\in [0,1]$, without affecting the topological characteristics of the individual layers, which can have different properties and different sizes (see Appendix~\\ref{appendix_model_general}). The radial correlations increase with parameter $\\nu$---at $\\nu=0$ there are no radial correlations, while at $\\nu=1$ radial correlations are maximized. Similarly, the angular correlations increase with parameter $g$---at $g=0$ there are no angular correlations, while at $g=1$ angular correlations are maximized. \n\n\\begin{figure*}[t]\n\\includegraphics[width=1\\linewidth]{figure4.pdf}  \n\\caption{\\textbf{Performance of mutual navigation in synthetic multiplexes with geometric correlations.} \\textbf{A,~B:}~Success rate of angular mutual GR (Angular routing) and of mutual GR (Hyperbolic routing) for a two-layer multiplex system as a function of the radial ($\\nu$) and angular ($g$) correlation strengths. Each layer has $N=30000$ nodes, power law degree distribution $P(k) \\sim k^{-2.5}$, $\\bar{k}=10$, and temperature $T=0.4$.\n\\textbf{C-E:}~Failure rate ($1-$success rate) of mutual GR (red triangles or circles) and angular mutual GR (blue triangles or circles). Each layer has the same parameters as in plots \\textbf{A,~B} and the same temperature $T$ that takes different values, $T =(0.1, 0.2, 0.4, 0.8, 0.9)$, corresponding for each navigation type respectively to the triangle/circle points, from the leftmost triangle/circle to the rightmost triangle/circle. Circles correspond to the case where there are no coordinate correlations among the layers, while triangles correspond to the case where there are optimal correlations, i.e., radial and angular correlation strengths that maximize the corresponding performance of mutual GR  or angular mutual GR. \\textbf{F:}~Mitigation factor as a function of the number of layers for optimal coordinate correlations and for uncorrelated coordinates.\n\\label{fig_layers_panel}}\n\\end{figure*}\n\nTo investigate how radial and angular correlations affect the performance of mutual navigation, we consider two-, three- and four-layer multiplexes constructed using our framework with different values of the correlation strength parameters $\\nu$ and $g$. Each layer consists of $N=30000$ nodes, has a power law degree distribution $P(k)\\sim k^{-\\gamma}$ with $\\gamma=2.5$, average node degree $\\bar{k}=10$, and the same temperature $T$ that we vary in $(0, 1)$. From Figs.~\\ref{fig_layers_panel}A,B and Figs.~\\ref{fig_appendix_routing_2}--\\ref{fig_4l_routing} in Appendix~\\ref{appendix_navigation}, we observe that in general both mutual GR and angular mutual GR perform better as we increase the correlation strengths $\\nu$ and $g$.\n\nWhen both radial and angular correlations are weak we do not observe any significant benefits from mutual navigation. Indeed, in Figs.~\\ref{fig_layers_panel}C-E we observe that in the uncorrelated case ($\\nu \\to 0$, $g\\to 0$) mutual GR performs almost identical to the single-layer GR, irrespectively of the number of layers. This is because when a message reaches a node in one layer after the first iteration of the mutual GR process, the probability that this node will have a neighbor in another layer that can get the message closer to the destination is small. That is, even though a node may have more options (neighbors in other layers) for forwarding a message, these options are basically useless. \n\nIncreasing the strength of correlations makes the different forwarding options that a node has more useful, as the probability to have a neighbor that can get the message closer to the destination in another layer increases. However, increasing the strength of correlations also increases the edge overlap between the layers (see Appendix~\\ref{appendix_model_overlap}), which reduces the options that a node has for forwarding a message. We observe that very strong radial and angular correlations may not be optimal at low temperatures (cf. Figs.~\\ref{fig_appendix_routing_2}--\\ref{fig_4l_routing} for $T=0.1$ in Appendix~\\ref{appendix_navigation}). This is because when the layers have the same nodes and the same parameters $\\bar{k}, \\gamma$, then as $\\nu \\to 1$, $g \\to 1$, the coordinates of the nodes in the layers become identical (see Appendix~\\ref{appendix_model_general}). If at the same time the temperature of the layers is $T \\to 0$, the connection probability $p(x_{ij})$ in each layer becomes the step function, where two nodes $i,j$ are deterministically connected if their hyperbolic distance is $x_{ij} \\leq R$. That is, as $T \\to 0$, $\\nu \\to 1$, $g \\to 1$, all layers become identical, and mutual GR degenerates to single-layer GR. We observe (Figs.~\\ref{fig_layers_panel}A,B and Figs.~\\ref{fig_appendix_routing_2}--\\ref{fig_4l_routing} in Appendix~\\ref{appendix_navigation}) that the best mutual GR performance is always achieved at high angular correlations, and either high radial correlations if the temperature of the individual layers is high, or low radial correlations if the temperature of the layers is low. The best angular mutual GR performance is always achieved at high angular and low radial correlations. \n\nFrom Figs.~\\ref{fig_layers_panel}C-E we observe that for a fixed number of layers the failure rate ($1-$success rate) is reduced for optimal correlations by a constant factor, which is independent of the navigation type (mutual GR or angular mutual GR) and the layer temperature. This factor, which we call \\emph{failure mitigation factor}, is the inverse of the slope of the best-fit lines in Figs.~\\ref{fig_layers_panel}C-E. \nFig.~\\ref{fig_layers_panel}F shows the failure mitigation factor for our two-, three- and four-layer multiplexes for both uncorrelated and optimally correlated coordinates.  Remarkably, if optimal correlations are present, the failure mitigation factor grows superlinerarly with the number of layers, suggesting that more layers with the right correlations can quickly make multiplex systems almost perfectly navigable. On the contrary, more layers without correlations do not have a significant effect on mutual navigation, which performs virtually identical to single-layer navigation.\n\n\nFinally, we investigate how close to the optimal---in terms of mutual navigation performance---are the radial and angular correlations in the IPv4/IPv6 Internet. To this end, we use our framework to construct a two-layer synthetic multiplex, where layer 1 has approximately the same number of nodes as in the IPv4 topology, $N_1=37563$ nodes, as well as the same power law degree distribution exponent $\\gamma_1=2.1$, average node degree $\\bar{k}_1\\approx 5$, and average clustering $\\bar{c}_1 \\approx 0.63$. Layer 2 has approximately the same number of nodes as in the IPv6 topology, $N_2=5163$ nodes, and the same power law exponent $\\gamma_2=2.1$, average node degree $\\bar{k}_2\\approx 5.2$, and average clustering $\\bar{c}_2 \\approx 0.55$.\n\nThe IPv4 topology is significantly larger than the IPv6 topology, and there are $4819$ common nodes (Autonomous Systems) in the two topologies. We find that nodes with a higher degree in IPv4 are more likely to also exist in IPv6. Specifically, we find that the empirical probability $\\psi(k)$ that a node of degree $k$ in IPv4 also exists in IPv6 can be approximated by $\\psi(k)=1/(1+15.4k^{-1.05})$ (see Fig.~\\ref{fig_estimate_psi} in Appendix~\\ref{appendix_different_size_model}). We capture this effect in our synthetic multiplex by first constructing layer 1, and then sampling with the empirical probability $\\psi(k)$ nodes from layer 1 that will also be present in layer 2 (see Appendix~\\ref{appendix_different_size_model}). A visualization illustrating the common nodes in the real Internet and in our synthetic multiplex is given in Figs.~\\ref{fig_psi_fitted_graphs}A,B. We note that the fact that nodes with higher degrees in the larger layer have higher probability to also exist in the smaller layer has also been observed in several other real multiplexes~\\cite{pre:multiplex:correlations}. However, our model for constructing synthetic multiplexes with different layer sizes  is quite general, and allows for any sampling function $\\psi(k)$ to be applied (see Appendix~\\ref{appendix_different_size_model}).\n\\begin{figure}[t]\n\\includegraphics[width=1\\linewidth]{figure5.pdf}\n\\caption{\\textbf{Performance of mutual navigation as a function of radial and angular correlation strengths ($\\nu, g$) in a two-layer synthetic multiplex that best mimics the real IPv4/IPv6 Internet.} \\textbf{A:}~Hyperbolic mapping of the real IPv4 topology where nodes marked by red also exist in the IPv6 topology. \\textbf{B:}~Hyperbolic mapping of layer 1 of our Internet-like synthetic multiplex, where nodes marked by red also exist in layer 2. \\textbf{C}:~Performance of angular mutual GR. \\textbf{D}:~Performance of mutual GR. In \\textbf{C, D} the black star indicates the achieved performance with the estimated correlation strengths in the real IPv4/IPv6 Internet, $\\nu_E \\approx 0.4, g_E \\approx 0.4$.\n \\label{fig_psi_fitted_graphs}} \n\\end{figure}\n\nFor the nodes that exist in both layers of our multiplex, we tune the correlations among their coordinates as before, by varying the parameters $\\nu$ and $g$ (see Appendix~\\ref{appendix_different_size_model}). For each $\\nu,g$ pair, we perform mutual navigation among $10^5$ randomly selected source-destination pairs that exist in both layers. Figs.~\\ref{fig_psi_fitted_graphs}C,D show respectively the performance of angular mutual GR and of mutual GR. We observe again that increasing the correlation strengths improves performance. In angular mutual GR, the success rate is $63\\%$ with uncorrelated coordinates, while with optimal correlations it becomes $75\\%$. In mutual GR, the success rate with uncorrelated coordinates is $85\\%$ and with optimal correlations is $91\\%$. The star in Figs.~\\ref{fig_psi_fitted_graphs}C,D indicates the achieved performance with the empirical correlation strengths in the IPv4/IPv6 Internet, $\\nu_E \\approx 0.4, g_E \\approx 0.4$, which are estimated using the inferred radial and angular coordinates of nodes (see Appendix~\\ref{appendix_estimate_nu_g}). At $\\nu=\\nu_E, g=g_E$, the success rate of angular mutual GR is $71\\%$, which is closer to the rate obtained with optimal correlations than to the uncorrelated case. For mutual GR, the success rate is $88\\%$, which lies in the middle of the uncorrelated and optimally correlated cases.\n\n\n\\section{Conclusion}\n\nNumerous real-world systems are multiplex networks where nodes in one network layer can simultaneously exist in other network layers. Each single network layer can be mapped into its own hyperbolic space, where node coordinates abstract the popularity and similarity of nodes. We have found that in different real multiplexes the coordinates of nodes in different layers are correlated, meaning that the underlying hyperbolic distances of the single layers are also correlated. \n\nOur findings yield a very powerful and general framework for understanding and analyzing real multiplexes. Specifically, we have shown that one can define and detect multidimensional communities, which are sets of nodes that are simultaneously similar in multiple layers. We have found that such communities are overabundant in different real multiplexes compared to their reshuffled counterparts that do not exhibit geometric correlations. Furthermore, we have also shown that one can facilitate trans-layer link prediction, where the most probable connections in one layer can be predicted by knowing the hyperbolic distances among the nodes in some other layer. Finally, we have focused on mutual navigation, which uses the coordinates and connectivity of nodes in different layers to reach intended communication targets. We have shown that trans-layer geometric correlations improve the performance of mutual navigation, which outperforms navigation in the single layers, only if these correlations are sufficiently strong. Our results also reveal that having more layers with the right correlations can quickly make multiplex systems almost perfectly navigable. On the contrary, more layers without correlations do not improve mutual navigation.\n  \nOur findings can have important applications in diverse domains, ranging from improving information transport and navigation or search in multilayer communication systems and decentralized data architectures~\\cite{Contreras11122015,helbing:digital_democracy}, to understanding functional and structural brain networks and deciphering their precise relationship(s)~\\cite{Simas2015}, to predicting links among nodes (e.g., terrorists) in a specific network by knowing their connectivity in some other network.\n\n\\begin{acknowledgments}\nThis work was supported by: the European Commission through the Marie Curie ITN ``iSocial'' grant no.\\ PITN-GA-2012-316808; a James S. McDonnell Foundation Scholar Award in Complex Systems; the ICREA Academia prize, funded by the {\\it Generalitat de Catalunya}; the MINECO project no.\\ FIS2013-47282-C2-1-P;  and the {\\it Generalitat de Catalunya} grant no.\\ 2014SGR608. Furthermore, M.~B. and M. A. S. acknowledge support from the European Commission FET-Proactive Project  MULTIPLEX no.\\ 317532.\n\\end{acknowledgments}\n\n\n\\appendix\n\n\\section{Real-world multiplex network data}\n\\label{appendix_datasets}\n\nHere we provide details on the real-world multiplex network data we have considered. An overview of the data is given in Table~\\ref{tab_datasets} of the main text.  \n\n\\textbf{IPv4/IPv6 Internet.} The IPv4 and IPv6 Autonomous Systems (AS) Internet topologies were extracted from the data collected by the Archipelago active measurement infrastructure (ARK) developed by CAIDA~\\cite{ark2009}. The connections in each topology are not physical but logical, representing AS relationships. An AS is a part of the Internet infrastructure administrated by a single company or organization. Pairs of ASs peer to exchange traffic. These peering relationships in the AS topology are represented as links between AS nodes. CAIDA's IPv4 and IPv6~\\cite{as_topo} datasets provide regular snapshots of AS links derived from ongoing traceroute-based IP-level topology measurements. The IPv4 dataset consists of ASs that can route Internet packets with IPv4 destination addresses, while the IPv6 dataset consists of ASs that can route packets with IPv6 destination addresses. The considered IPv4 and IPv6 topologies were constructed by merging the AS link snapshots during the first 15 days of January 2015, which are provided at~\\cite{link1and2}. The IPv4 topology (Layer~1) consists of $N_1=37563$ nodes (ASs), and has a power law degree distribution with exponent $\\gamma_1=2.1$, average node degree $\\bar{k}_1=5.06$, and average clustering $\\bar{c}_1=0.63$. The IPv6 topology (Layer~2) consists of $N_2=5163$ nodes, has a power law degree distribution with exponent $\\gamma_2=2.1$, average node degree $\\bar{k}_2=5.21$, and average clustering $\\bar{c}_2=0.55$. There are $4819$ common nodes in the two topologies, i.e., ASs that can route both IPv4 and IPv6 packets.\n\n\\textbf{Air/Train.} The Air/Train data is taken from~\\cite{Halu}. The data contains the network of airports and the network of train stations in India, as well as the geographic distances between the airports and the train stations. For each airport, we aggregate all train stations that are within 50km from the airport into a supernode. Subsequently, we declare two supernodes connected if they have at least one train station in common, or if at least one train station from the one supernode is directly connected to a train station from the other supernode. If there are no train stations within 50km from an airport, we consider the nearest train station to the airport, which is considered a supernode on its own. Each supernode has the same id as its corresponding airport, i.e., it is considered to be the same node in the multiplex system. The idea behind this aggregation procedure is to relate train stations to the airports to which they are geographically close. The considered multiplex consists of the network of airports (Air) and the network of aggregated supernodes of train stations (Train).  The two networks consist of $N_1=N_2=69$ common nodes. The Air network (Layer~1) has average degree $\\bar{k}_1=5.22$, maximum degree $k_{1}^{\\textnormal{max}}=42$, and average clustering $\\bar{c}_1=0.79$. The Train network (Layer~2) has average degree $\\bar{k}_2=9.33$, maximum degree $k_{2}^{\\textnormal{max}}=41$, and average clustering $\\bar{c}_2=0.48$.\n\n\\textbf{Drosophila Melanogaster.} The Drosophila Melanogaster dataset is taken from~\\cite{biogrid,arenas:reduce}. In this dataset, the networks represent protein--protein interactions and the layers correspond to interactions of different nature. Layer 1 in our multiplex corresponds to suppressive genetic interaction, while layer 2 corresponds to additive genetic interaction. More details on the data can be found in~\\cite{biogrid,arenas:reduce}. Layer~1 has $N_1=838$ nodes, average degree $\\bar{k}_1=4.43$, and average clustering $\\bar{c}_1=0.28$. Its degree distribution can be approximated by a power law with exponent $\\gamma_1=2.6$. Layer~2 has $N_2=755$ nodes, average degree $\\bar{k}_2=3.77$, and average clustering $\\bar{c}_2=0.29$. Its degree distribution can be approximated by a power law with exponent $\\gamma_2=2.8$. There are $557$ common nodes in the two layers.\n\n\\textbf{C. Elegans Connectomme.} The C. Elegans dataset is taken from~\\cite{pnas:celegans, muxviz}. It corresponds to the neuronal network of the nematode Caenorhabditis Elegans. The nodes are neurons and each layer corresponds to a different type of synaptic connection: Electric (Layer~1) and Chemical Monadic (Layer~2). Layer 1 has $N_1=253$ nodes, average degree $\\bar{k}_1=4.06$, and average clustering $\\bar{c}_1=0.24$. Layer 2 has $N_2=260$ nodes, average degree $\\bar{k}_2=6.83$, and average clustering $\\bar{c}_2=0.21$.  The degree distribution in both layers can be approximated by a power law with exponent $\\gamma_1=\\gamma_2=2.9$, and the two layers have $238$ common nodes.\n \n\\textbf{Human Brain.} The human brain data is taken from~\\cite{Simas2015}. The data consists of a structural (anatomical) network, as well as a functional network obtained by an algebraic aggregation procedure. In both networks, nodes are brain regions---there are $90$ different brain regions in the data. The structural network is obtained by Diffusion Magnetic Resonance Imaging (dMRI).  For each pair of brain regions, the data gives the probability that these regions are connected. The connection probability is proportional to the density of the axonal fibers between the regions. In our multiplex, we declare two regions of the structural network connected if their connection probability is larger than a threshold $th_s=0.92$. The functional network is obtained by BOLD fMRI resting state recordings for the same brain regions. The probability that two regions are connected here is proportional to a correlation coefficient between the fMRI time series of the region voxels~\\cite{Simas2015}. In our multiplex, we declare two regions of the functional network connected if their correlation coefficient is larger than the threshold $th_f=0.67$. The resulting structural network (Layer~1) consists of a giant connected component of $85$ nodes, with average degree $\\bar{k}_1=5.41$, maximum degree $k_1^{\\textnormal{max}}=12$, and average clustering $\\bar{c}_1=0.49$. The resulting functional network (Layer~2) has a giant connected component of $78$ nodes, average degree $\\bar{k}_2=5.48$, maximum degree $\\bar{k}_2^{\\textnormal{max}}=14$, and average clustering $\\bar{c}_2=0.40$. The two layers have $77$ nodes in common.\n\n\\textbf{arXiv.} The arXiv data is taken from~\\cite{prx:modular} and contains co-authorship networks from the free scientific repository arXiv. The nodes are authors that are connected if they have co-authored a paper. In arXiv, each paper is assigned to one or more relevant categories. The data considers only papers with the word ``networks\" in the title or abstract from 13 different categories up to May 2014. Layer 1 (physics.bio-ph) in our multiplex corresponds to the co-authorship network formed by the authors of papers in the ``Biological Physics\" category. Layer 2 (cond-mat.dis-nn) corresponds to the co-authorship network formed by the authors of papers in the ``Disordered Systems and Neural Networks\" category. Layer~1 has $N_1=2956$ nodes, average degree $\\bar{k}_1=4.13$, and average clustering $\\bar{c}_1=0.83$.\n Layer~2 has $N_2=3506$ nodes, average degree $\\bar{k}_2=4.19$, and average clustering $\\bar{c}_2=0.81$. The degree distribution in both layers can be approximated by a power law with exponent $\\gamma_1=\\gamma_2=2.6$, and the two layers have $1514$ common nodes.\n \n\n\\section{Hyperbolic Mapping}\n\\label{appendix_hypermap}\n\nWe map each layer of each real multiplex to its hyperbolic space using the~\\emph{HyperMap} method~\\cite{frag:hypermap,frag:hypermap_cn}, whose implementation is available at~\\cite{hypermap_code}. On its input the method takes the network adjacency matrix  $\\alpha_{ij}$ ($\\alpha_{ij}=\\alpha_{ji}=1$ if there is a link between nodes $i$ and $j$, and $\\alpha_{ij}=\\alpha_{ji}=0$ otherwise), and the network parameters $m, \\gamma, T$. It then computes radial and angular coordinates $r_i, \\theta_i$, for all nodes $i \\leq N$ in the network. Parameter $m$ is the expected minimum node degree, $\\gamma$ is the power law degree distribution exponent, and $T$ is the temperature. The values of $m, \\gamma, T$ used to embed each layer are shown in Table~\\ref{hypermap_parameters}. \n\\begin{table*}[t]\n\\begin{ruledtabular}\n\\begin{tabular}{llllllll}\n\\textbf{Layer } & $N$ & $\\bar{k}$ & $\\bar{c}$ & $\\gamma$ & $m$ & $T$\\\\ \\hline\nInternet Layer 1 & 37563 & 5.06 & 0.63 & 2.1 & 1.0  & 0.5\\\\\\hline\nInternet Layer 2 & 5163 & 5.21 & 0.55 & 2.1 & 1.0  & 0.5\\\\\\hline\nAir/Train Layer 1 & 69 & 5.22 & 0.79 &  2.6 & 1.0  & 0.005\\\\\\hline\nAir/Train Layer 2 & 69 & 9.33 & 0.48 & 2.9 & 1.0  & 0.4\\\\\\hline\nDrosophila Layer 1 & 838 & 4.43 & 0.28  & 2.6 & 0.5 & 0.68\\\\\\hline\nDrosophila Layer 2 & 755 & 3.77 & 0.29 & 2.8 & 0.5  & 0.65\\\\\\hline\nC. Elegans Layer 1 & 253 & 4.06 & 0.24 & 2.9 & 2.0  & 0.65\\\\\\hline\nC. Elegans Layer 2 & 260 & 6.83 & 0.21 & 2.9 & 3.4  & 0.7\\\\\\hline\nBrain Layer 1 & 85 & 5.41 & 0.49 & 6.0 & 2.7  & 0.4\\\\\\hline\nBrain Layer 2 & 78 & 5.48 & 0.40 & 6.0 & 1.0  & 0.5\\\\\\hline\narXiv Layer 1 & 2956 & 4.13 & 0.83 & 2.6 & 2.0  & 0.05\\\\\\hline \narXiv Layer 2 & 3506 & 4.19 & 0.81 & 2.6 & 2.0  & 0.05\\\\\n\\end{tabular}\n\\end{ruledtabular}\n\\caption{Topological properties and HyperMap parameter values for the considered empirical multiplex networks.\n\\label{hypermap_parameters}}\n\\end{table*}\n\nTo estimate the values of $m, \\gamma, T$ for each layer, we use the Extended Popularity$\\times$Similarity Optimization (E-PSO) model described in~\\cite{frag:hypermap}. The E-PSO model grows synthetic complex networks and it is equivalent to the hyperbolic $\\mathbb{H}^{2}$ model~\\cite{Krioukov2010}. It takes as input the final network size $N$, the average node degree $\\bar{k}$, and the network parameters $m, \\gamma, T$. We use the E-PSO model to construct synthetic networks with the same size $N$ and average degree $\\bar{k}$ as in each real layer, using different parameter values for $m, \\gamma, T$. The estimated $m, \\gamma, T$ values for each layer are then the values that best match the degree distribution and average clustering between the layer and the corresponding synthetic network. We observe from Table~\\ref{hypermap_parameters} that in several cases the layers of the same multiplex have the same or similar estimated parameter values.\n\nHyperMap is based on Maximum Likelihood Estimation. It finds the radial and angular coordinates $r_i, \\theta_i$ for all nodes $i \\leq N$, which maximize the likelihood\n\n", "index": 1, "text": "\\begin{equation}\n\\label{eq:likelihood}\n\\mathcal L=\\prod_{1 \\leq j < i \\leq N} p(x_{ij})^{\\alpha_{ij}}\\left[1-p(x_{ij})\\right]^{1-\\alpha_{ij}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{L}=\\prod_{1\\leq j&lt;i\\leq N}p(x_{ij})^{\\alpha_{ij}}\\left[1-p(x_{ij})%&#10;\\right]^{1-\\alpha_{ij}},\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mn>1</mn><mo>\u2264</mo><mi>j</mi><mo>&lt;</mo><mi>i</mi><mo>\u2264</mo><mi>N</mi></mrow></munder><mrow><mi>p</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><msub><mi>\u03b1</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></msup><mo>\u2062</mo><msup><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b1</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></msup></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere $R \\sim \\ln N$. To efficiently and accurately maximize the likelihood in Eq.~(\\ref{eq:likelihood}) the method follows the techniques described in~\\cite{frag:hypermap,frag:hypermap_cn}. Here, we have used the most recent version of the method described in~\\cite{frag:hypermap_cn}.\n\nThe inferred radial coordinate of a node $i$ depends on its observed degree in the network $k_i$ via $r_i \\sim \\ln{N}-\\ln{k_i}$~\\cite{frag:hypermap}. Therefore, if node degrees are correlated in different layers so will be the radial coordinates.  Fig.~\\ref{fig_conditional_radial} shows the conditional probability $P(r_2|r_1)$ for the IPv4/IPv6 Internet, which is the probability that a node (AS) has radial coordinate $r_2$ in layer 2 (IPv6) given its radial coordinate $r_1$ in layer 1 (IPv4). We observe strong correlations among the radial coordinates of nodes in the IPv4 and IPv6 topologies.\n\\begin{figure}[t]\n\\centering \n\\includegraphics[width=0.8\\linewidth]{sfig1.png}\n\\caption{\\textbf{Conditional probability $P(r_2|r_1)$ that an AS has radial coordinate $r_2$ in the IPv6 topology given its radial coordinate $r_1$ in the IPv4 topology.} \n\\label{fig_conditional_radial}}\n\\end{figure}\n\n\n\\section{Destroying trans-layer correlations}\n\\label{appendix_reshuffling}\n\nTo destroy the geometric trans-layer correlations in our real multiplexes, we randomly reshuffle the trans-layer node-to-node mappings. Specifically, for each real multiplex we select one of its layers and  we interchange the id of each node of the layer with the id of a randomly selected node from the same layer. The idea behind this process is that if a node with id $i$ is node $n_1$ in layer 1 and node $n_2$ in layer 2 with correlated coordinates $(r_{n_1}, \\theta_{n_1})$, $(r_{n_2}, \\theta_{n_2})$, then, after reshuffling layer 2, the node will become  some other node $n_2'$ in this layer, with coordinates $(r_{n_2'}, \\theta_{n_2'})$ that will not be correlated with $(r_{n_1}, \\theta_{n_1})$. We note that this reshuffling process is just a random id interchange among the nodes of a layer and does not alter the layer's topology. We used this process to create the reshuffled counterparts of the real multiplexes in the main text and in the next section.  The reshuffled counterparts serve as a null model for what one would expect if there were no geometric correlations among the layers.\n\n\n\\section{Similarity communities and trans-layer connection probabilities in the C. Elegans, Air/Train, and human brain multiplexes}\n\\label{appendix_all_histograms}\n\nFig.~\\ref{fig_appendix_histo} shows the distribution of nodes that have angular coordinates $\\theta_1,\\theta_2$ in layers $1, 2$ of the C. Elegans, Air/Train, and human brain multiplexes, as well as the corresponding distributions in their reshuffled counterparts. Fig.~\\ref{fig_con_prob_si} shows the empirical trans-layer connection probability, $P(1|2)$ ($P(2|1)$), that two nodes are connected in one of the layers of each multiplex, given their hyperbolic or angular distance in the other layer. We can make similar observations as with the Internet, Drosophila, and arXiv multiplexes in the main text (cf. Figs.~\\ref{fig_histogram},~\\ref{fig_link_prediction}). We also observe that some multiplexes such as the Air/Train have weaker trans-layer correlations compared to others.\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig2.png}\n\\caption{\\textbf{Distribution of nodes in the two-dimensional similarity space of the C. Elegans, Air/Train, and human brain multiplexes (top panel).} The plots correspond to nodes that exist in both layers of each system. The angular similarity coordinate of a node in layer 1 is denoted by $\\theta_1$ and in layer 2 by $\\theta_2$. The histogram heights are equal to the number of nodes falling within each two-dimensional similarity bin, and the colors in each case denote the relative magnitude of the heights. \\textbf{Bottom panel:} The same distributions as in the top panel but for the reshuffled counterparts of the real systems. \n\\label{fig_appendix_histo}}\n\\end{figure*}\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig3.pdf}\n\\caption{\\textbf{Trans-layer connection probability in the C. Elegans, Air/Train, and human brain multiplexes.} \\textbf{Top panel:} Trans-layer connection probability as a function of hyperbolic distance. $P(j|i)$ denotes the probability that a pair of nodes is connected in layer $j$ given its hyperbolic distance $x$ in layer $i$. $P_{\\text{ran}}(j|i)$ denotes the same probability for the reshuffled counterpart of each real system. \\textbf{Bottom panel:} Corresponding trans-layer connection probabilities when considering only the angular (similarity) distance between nodes, $\\Delta\\theta$.\n\\label{fig_con_prob_si}}\n\\end{figure*}\n\n\n\\section{Similarity communities and geographic regions in the IPv4/IPv6 Internet}\n\\label{appendix_regions_communities}\n\nIn~\\cite{Boguna2010, frag:hypermap, frag:hypermap_cn}, we have considered the IPv4 Internet topology. We have shown that the mapping of the topology to its underlying hyperbolic space yields meaningful results, since ASs belonging to the same country are mapped close to each other. Specifically, for the majority of the countries, we have shown that their ASs are localized in narrow angular (similarity) regions. The reason for this effect is that ASs belonging to the same country are usually connected more densely to each other than to the rest of the world, and the mapping method (HyperMap) correctly places all such ASs in narrow regions close to each other. We note that other reasons besides geographic proximity may affect the connectivity between ASs, such as economical, political, and performance-related reasons. The mapping method does not favor any specific reason, but relies only on the connectivity between nodes (ASs in this case) in order to place the nodes at the right angular (and hyperbolic) distances.\n\\begin{figure}[!ht]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig4.png}\n\\caption{\\textbf{Distribution of ASs of the same region/country in the two-dimensional similarity space of the IPv4/IPv6 Internet.} The plots correspond to ASs belonging to different regions/countries, which exist both in IPv4 and IPv6. The angular similarity coordinate of an AS in IPv4 is denoted by $\\theta_1$ and in IPv6 by $\\theta_2$. For each region/country, the histogram heights are normalized by the total number of ASs that belong to the region/country. In~\\textbf{A}, ``Post Soviet\" corresponds to the ASs belonging to Russia, Ukraine, Estonia, and Latvia; ``Europe\" corresponds to the ASs belonging to Germany, France, Spain, Finland, Austria, Netherlands, Sweden, Italy, and Greece; ``North America\" corresponds to the ASs belonging to the USA and Canada;  and ``South America\" corresponds to the ASs belonging to Brazil, Uruguay, Argentina, and Colombia. The histograms in~\\textbf{B-D} correspond to the ASs belonging to 10 distinct countries. In~\\textbf{B}, the countries are Germany (DE), Austria (AT), and Switzerland (CH); in~\\textbf{C}, the countries are Japan (JP), China (CN), Taiwan (TW), and USA (US); and in~\\textbf{D}, the countries are Ukraine (UA), Russia (RU), and Poland (PL).\n \\label{fig_internet_regions}}\n\\end{figure}\n\nIn Fig.~\\ref{fig_internet_regions}, we observe a similar effect in the two-dimensional similarity space of the IPv4/IPv6 Internet. The figure shows the distribution of ASs belonging to different regions and countries. The AS-to-country mapping is taken from the CAIDA AS Organizations Dataset~\\cite{as_to_country_mapping}. In Fig.~\\ref{fig_internet_regions}, we can see ASs from regions/countries that are narrowly distributed in the two-dimensional similarity space, as well as ASs from regions/countries that are more widely spread. The former group of ASs are the ASs that form strong communities, i.e., that are densely connected to each other, in both the IPv4 and IPv6 topologies. In the figure, these are the ASs belonging to the Post-Soviet and South America regions (Fig.~\\ref{fig_internet_regions}A), as well as the ASs belonging to some distinct counties such as Austria, Japan, China, Taiwan (Figs.~\\ref{fig_internet_regions}B,C). By contrast, ASs belonging to the US and Europe are more widely spread in both the IPv4 and IPv6 similarity spaces (Figs.~\\ref{fig_internet_regions}A,C). We note that Europe in Fig.~\\ref{fig_internet_regions}A represents not one country but a collection of 9 different countries. Finally, we also observe that there can be ASs from countries that are narrowly distributed in the one similarity space, but not in the other. This is the case for example with the ASs belonging to Poland, which are narrowly distributed in the IPv4 space but not in the IPv6 (Fig.~\\ref{fig_internet_regions}D). This suggests that these ASs do not form a strong community in IPv6, while they do in IPv4.\n\n\n\\section{Modeling multiplex networks with geometric correlations}\n\\label{appendix_model_general}\n\nIn this section we discuss the technical details of our framework, which constructs synthetic multiplex networks with geometric correlations. As mentioned, our framework constructs single-layer topologies using the $\\mathbb{H}^{2}$ model~\\cite{Krioukov2010}, and allows for radial and angular coordinate correlations across the different layers. Instead of working directly with the $\\mathbb{H}^{2}$ model, we make use of the $\\mathbb{S}^{1}$ model~\\cite{Serrano2008} that is more convenient to work with, and which is isomorphic to the $\\mathbb{H}^{2}$ model through a simple change of variables~\\cite{Krioukov2010}. We first review the $\\mathbb{S}^{1}$ model and its relation to the $\\mathbb{H}^{2}$ model.\n\n\n\\subsection{$\\mathbb{S}^{1}/\\mathbb{H}^{2}$ model of single-layer networks}\n\\label{single_layer}\n\nInstead of radial and angular coordinates $r_i, \\theta_i$, each node $i$ in the $\\mathbb{S}^{1}$ model has hidden variables $\\kappa_i, \\theta_i$. The hidden variable $\\kappa_i$ is the node's expected degree in the resulting network, while $\\theta_i$ is the angular (similarity) coordinate of the node on a circle of radius $N/2\\pi$, where $N$ is the total number of nodes. To construct a network with the $\\mathbb{S}^{1}$ model that has size $N$, average node degree $\\bar{k}$, power law degree distribution with exponent $\\gamma > 2$, and temperature $T \\in [0,1)$, we perform the following steps:\n\\begin{enumerate}\n\\item[i.] Sample the angular coordinates of nodes $\\theta_i$, $i=1,2,\\ldots,N$, uniformly at random from $[0, 2\\pi]$, and their hidden variables $\\kappa_{i}$, $i=1,2,\\ldots,N$, from the probability density function (PDF)\n\\begin{eqnarray}\n\\rho(\\kappa) &=& (\\gamma-1) \\kappa^{\\text{min}^{\\gamma-1}} \\kappa^{-\\gamma},\\\\\n\\nonumber \\kappa^{\\text{min}}&=&\\bar{k}\\frac{\\gamma-2}{\\gamma-1},\n\\end{eqnarray}\nwhere $\\kappa^{\\text{min}}$ is the expected minimum node degree, which is a function of the average degree $\\bar{k}$;~\\footnote{By sampling from a PDF $f(x)$ we mean that we first compute the CDF $F(x)=\\int_{x_{\\textnormal{min}}}^{x} \\mathrm{d}x' \\rho(x')$, where $x_{\\textnormal{min}}$ is the minimum value of $x$, then generate a random number $u_i$ uniformly at random from $[0,1]$, and finally compute the value $x_i$ such that $F(x_i) = u_i$. The value $x_i$ is a sample from the PDF $\\rho(x)$ (or the CDF $F(x)$).}\n\\item[ii.] Connect every pair of nodes $i,j$ with probability\n\\begin{eqnarray}\n\\label{r_s1}\nr(\\kappa_{i}, \\theta_{i}; \\kappa_{j}, \\theta_{j})  &=& {1\n\\over 1 + \\left[\\frac{d\\left(\\theta_i ,\\theta_j\\right)}{\\mu\\kappa_i\\kappa_j}\\right]^{\\frac{1}{T}}},\\\\\n\\nonumber d(\\theta_i, \\theta_j) &=& \\frac{N}{2\\pi} \\Delta \\theta_{ij},~\\Delta \\theta_{ij}=|\\pi - | \\pi -|\\theta_i - \\theta_j|||,\\\\\n\\nonumber \\mu&=&\\frac{\\sin{T \\pi}}{2\\bar{k}T\\pi},\n\\end{eqnarray}\nwhere $d(\\theta_i, \\theta_j)$ is the angular distance between nodes $i, j$ on the circle.\n\\end{enumerate}\n\nThe $\\mathbb{S}^{1}$ model is equivalent to the $\\mathbb{H}^{2}$ model after transforming the expected node degrees $\\kappa_i$ to radial coordinates $r_i$ via\n\n", "itemtype": "equation", "pos": 48693, "prevtext": "\nwhere the product goes over all node pairs $i, j$ in the network, $x_{ij}$ is the hyperbolic distance between pair $i, j$,\n\\begin{eqnarray}\n\\label{eq:x_ji}\n\\nonumber x_{ij}&=&\\mathrm{arccosh}\\left(\\cosh{r_i}\\cosh{r_j}-\\sinh{r_i} \\sinh {r_j} \\cos{\\Delta\\theta_{ij}}\\right)\\\\\n\\nonumber &\\approx& r_i+r_j+2\\ln{\\sin{(\\Delta\\theta_{ij}/2)}},\\\\\n\\nonumber &\\approx& r_i+r_j+2\\ln{(\\Delta\\theta_{ij}/2)},\\\\\n&\\quad\\textnormal{where}~~& \\Delta \\theta_{ij}=\\pi-|\\pi-|\\theta_i-\\theta_j||,\n\\end{eqnarray}\nand $p(x_{ij})$ is the Fermi-Dirac connection probability,\n\n", "index": 3, "text": "\\begin{equation}\n\\label{eq:p_x_ji}\np(x_{ij})=\\frac{1}{1+e^{\\frac{1}{2T}(x_{ij}-R)}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"p(x_{ij})=\\frac{1}{1+e^{\\frac{1}{2T}(x_{ij}-R)}},\" display=\"block\"><mrow><mrow><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>T</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mi>R</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": " \nwhere $R$ is the radius of the hyperbolic disc in the $\\mathbb{H}^{2}$ model where all nodes reside,\n\\begin{eqnarray}\n\\label{R}\nR&=&2\\ln{\\frac{N}{c}},\\\\\n\\nonumber c&=&\\bar{k}\\frac{\\sin{T\\pi}}{2T}\\left(\\frac{\\gamma-2}{\\gamma-1}\\right)^2.\n\\end{eqnarray}\nIt is easy to see that after the above change of variables the connection probability in Eq.~(\\ref{r_s1}) becomes the Fermi-Dirac connection probability in the $\\mathbb{H}^{2}$ model,\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $R \\sim \\ln N$. To efficiently and accurately maximize the likelihood in Eq.~(\\ref{eq:likelihood}) the method follows the techniques described in~\\cite{frag:hypermap,frag:hypermap_cn}. Here, we have used the most recent version of the method described in~\\cite{frag:hypermap_cn}.\n\nThe inferred radial coordinate of a node $i$ depends on its observed degree in the network $k_i$ via $r_i \\sim \\ln{N}-\\ln{k_i}$~\\cite{frag:hypermap}. Therefore, if node degrees are correlated in different layers so will be the radial coordinates.  Fig.~\\ref{fig_conditional_radial} shows the conditional probability $P(r_2|r_1)$ for the IPv4/IPv6 Internet, which is the probability that a node (AS) has radial coordinate $r_2$ in layer 2 (IPv6) given its radial coordinate $r_1$ in layer 1 (IPv4). We observe strong correlations among the radial coordinates of nodes in the IPv4 and IPv6 topologies.\n\\begin{figure}[t]\n\\centering \n\\includegraphics[width=0.8\\linewidth]{sfig1.png}\n\\caption{\\textbf{Conditional probability $P(r_2|r_1)$ that an AS has radial coordinate $r_2$ in the IPv6 topology given its radial coordinate $r_1$ in the IPv4 topology.} \n\\label{fig_conditional_radial}}\n\\end{figure}\n\n\n\\section{Destroying trans-layer correlations}\n\\label{appendix_reshuffling}\n\nTo destroy the geometric trans-layer correlations in our real multiplexes, we randomly reshuffle the trans-layer node-to-node mappings. Specifically, for each real multiplex we select one of its layers and  we interchange the id of each node of the layer with the id of a randomly selected node from the same layer. The idea behind this process is that if a node with id $i$ is node $n_1$ in layer 1 and node $n_2$ in layer 2 with correlated coordinates $(r_{n_1}, \\theta_{n_1})$, $(r_{n_2}, \\theta_{n_2})$, then, after reshuffling layer 2, the node will become  some other node $n_2'$ in this layer, with coordinates $(r_{n_2'}, \\theta_{n_2'})$ that will not be correlated with $(r_{n_1}, \\theta_{n_1})$. We note that this reshuffling process is just a random id interchange among the nodes of a layer and does not alter the layer's topology. We used this process to create the reshuffled counterparts of the real multiplexes in the main text and in the next section.  The reshuffled counterparts serve as a null model for what one would expect if there were no geometric correlations among the layers.\n\n\n\\section{Similarity communities and trans-layer connection probabilities in the C. Elegans, Air/Train, and human brain multiplexes}\n\\label{appendix_all_histograms}\n\nFig.~\\ref{fig_appendix_histo} shows the distribution of nodes that have angular coordinates $\\theta_1,\\theta_2$ in layers $1, 2$ of the C. Elegans, Air/Train, and human brain multiplexes, as well as the corresponding distributions in their reshuffled counterparts. Fig.~\\ref{fig_con_prob_si} shows the empirical trans-layer connection probability, $P(1|2)$ ($P(2|1)$), that two nodes are connected in one of the layers of each multiplex, given their hyperbolic or angular distance in the other layer. We can make similar observations as with the Internet, Drosophila, and arXiv multiplexes in the main text (cf. Figs.~\\ref{fig_histogram},~\\ref{fig_link_prediction}). We also observe that some multiplexes such as the Air/Train have weaker trans-layer correlations compared to others.\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig2.png}\n\\caption{\\textbf{Distribution of nodes in the two-dimensional similarity space of the C. Elegans, Air/Train, and human brain multiplexes (top panel).} The plots correspond to nodes that exist in both layers of each system. The angular similarity coordinate of a node in layer 1 is denoted by $\\theta_1$ and in layer 2 by $\\theta_2$. The histogram heights are equal to the number of nodes falling within each two-dimensional similarity bin, and the colors in each case denote the relative magnitude of the heights. \\textbf{Bottom panel:} The same distributions as in the top panel but for the reshuffled counterparts of the real systems. \n\\label{fig_appendix_histo}}\n\\end{figure*}\n\\begin{figure*}[p]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig3.pdf}\n\\caption{\\textbf{Trans-layer connection probability in the C. Elegans, Air/Train, and human brain multiplexes.} \\textbf{Top panel:} Trans-layer connection probability as a function of hyperbolic distance. $P(j|i)$ denotes the probability that a pair of nodes is connected in layer $j$ given its hyperbolic distance $x$ in layer $i$. $P_{\\text{ran}}(j|i)$ denotes the same probability for the reshuffled counterpart of each real system. \\textbf{Bottom panel:} Corresponding trans-layer connection probabilities when considering only the angular (similarity) distance between nodes, $\\Delta\\theta$.\n\\label{fig_con_prob_si}}\n\\end{figure*}\n\n\n\\section{Similarity communities and geographic regions in the IPv4/IPv6 Internet}\n\\label{appendix_regions_communities}\n\nIn~\\cite{Boguna2010, frag:hypermap, frag:hypermap_cn}, we have considered the IPv4 Internet topology. We have shown that the mapping of the topology to its underlying hyperbolic space yields meaningful results, since ASs belonging to the same country are mapped close to each other. Specifically, for the majority of the countries, we have shown that their ASs are localized in narrow angular (similarity) regions. The reason for this effect is that ASs belonging to the same country are usually connected more densely to each other than to the rest of the world, and the mapping method (HyperMap) correctly places all such ASs in narrow regions close to each other. We note that other reasons besides geographic proximity may affect the connectivity between ASs, such as economical, political, and performance-related reasons. The mapping method does not favor any specific reason, but relies only on the connectivity between nodes (ASs in this case) in order to place the nodes at the right angular (and hyperbolic) distances.\n\\begin{figure}[!ht]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig4.png}\n\\caption{\\textbf{Distribution of ASs of the same region/country in the two-dimensional similarity space of the IPv4/IPv6 Internet.} The plots correspond to ASs belonging to different regions/countries, which exist both in IPv4 and IPv6. The angular similarity coordinate of an AS in IPv4 is denoted by $\\theta_1$ and in IPv6 by $\\theta_2$. For each region/country, the histogram heights are normalized by the total number of ASs that belong to the region/country. In~\\textbf{A}, ``Post Soviet\" corresponds to the ASs belonging to Russia, Ukraine, Estonia, and Latvia; ``Europe\" corresponds to the ASs belonging to Germany, France, Spain, Finland, Austria, Netherlands, Sweden, Italy, and Greece; ``North America\" corresponds to the ASs belonging to the USA and Canada;  and ``South America\" corresponds to the ASs belonging to Brazil, Uruguay, Argentina, and Colombia. The histograms in~\\textbf{B-D} correspond to the ASs belonging to 10 distinct countries. In~\\textbf{B}, the countries are Germany (DE), Austria (AT), and Switzerland (CH); in~\\textbf{C}, the countries are Japan (JP), China (CN), Taiwan (TW), and USA (US); and in~\\textbf{D}, the countries are Ukraine (UA), Russia (RU), and Poland (PL).\n \\label{fig_internet_regions}}\n\\end{figure}\n\nIn Fig.~\\ref{fig_internet_regions}, we observe a similar effect in the two-dimensional similarity space of the IPv4/IPv6 Internet. The figure shows the distribution of ASs belonging to different regions and countries. The AS-to-country mapping is taken from the CAIDA AS Organizations Dataset~\\cite{as_to_country_mapping}. In Fig.~\\ref{fig_internet_regions}, we can see ASs from regions/countries that are narrowly distributed in the two-dimensional similarity space, as well as ASs from regions/countries that are more widely spread. The former group of ASs are the ASs that form strong communities, i.e., that are densely connected to each other, in both the IPv4 and IPv6 topologies. In the figure, these are the ASs belonging to the Post-Soviet and South America regions (Fig.~\\ref{fig_internet_regions}A), as well as the ASs belonging to some distinct counties such as Austria, Japan, China, Taiwan (Figs.~\\ref{fig_internet_regions}B,C). By contrast, ASs belonging to the US and Europe are more widely spread in both the IPv4 and IPv6 similarity spaces (Figs.~\\ref{fig_internet_regions}A,C). We note that Europe in Fig.~\\ref{fig_internet_regions}A represents not one country but a collection of 9 different countries. Finally, we also observe that there can be ASs from countries that are narrowly distributed in the one similarity space, but not in the other. This is the case for example with the ASs belonging to Poland, which are narrowly distributed in the IPv4 space but not in the IPv6 (Fig.~\\ref{fig_internet_regions}D). This suggests that these ASs do not form a strong community in IPv6, while they do in IPv4.\n\n\n\\section{Modeling multiplex networks with geometric correlations}\n\\label{appendix_model_general}\n\nIn this section we discuss the technical details of our framework, which constructs synthetic multiplex networks with geometric correlations. As mentioned, our framework constructs single-layer topologies using the $\\mathbb{H}^{2}$ model~\\cite{Krioukov2010}, and allows for radial and angular coordinate correlations across the different layers. Instead of working directly with the $\\mathbb{H}^{2}$ model, we make use of the $\\mathbb{S}^{1}$ model~\\cite{Serrano2008} that is more convenient to work with, and which is isomorphic to the $\\mathbb{H}^{2}$ model through a simple change of variables~\\cite{Krioukov2010}. We first review the $\\mathbb{S}^{1}$ model and its relation to the $\\mathbb{H}^{2}$ model.\n\n\n\\subsection{$\\mathbb{S}^{1}/\\mathbb{H}^{2}$ model of single-layer networks}\n\\label{single_layer}\n\nInstead of radial and angular coordinates $r_i, \\theta_i$, each node $i$ in the $\\mathbb{S}^{1}$ model has hidden variables $\\kappa_i, \\theta_i$. The hidden variable $\\kappa_i$ is the node's expected degree in the resulting network, while $\\theta_i$ is the angular (similarity) coordinate of the node on a circle of radius $N/2\\pi$, where $N$ is the total number of nodes. To construct a network with the $\\mathbb{S}^{1}$ model that has size $N$, average node degree $\\bar{k}$, power law degree distribution with exponent $\\gamma > 2$, and temperature $T \\in [0,1)$, we perform the following steps:\n\\begin{enumerate}\n\\item[i.] Sample the angular coordinates of nodes $\\theta_i$, $i=1,2,\\ldots,N$, uniformly at random from $[0, 2\\pi]$, and their hidden variables $\\kappa_{i}$, $i=1,2,\\ldots,N$, from the probability density function (PDF)\n\\begin{eqnarray}\n\\rho(\\kappa) &=& (\\gamma-1) \\kappa^{\\text{min}^{\\gamma-1}} \\kappa^{-\\gamma},\\\\\n\\nonumber \\kappa^{\\text{min}}&=&\\bar{k}\\frac{\\gamma-2}{\\gamma-1},\n\\end{eqnarray}\nwhere $\\kappa^{\\text{min}}$ is the expected minimum node degree, which is a function of the average degree $\\bar{k}$;~\\footnote{By sampling from a PDF $f(x)$ we mean that we first compute the CDF $F(x)=\\int_{x_{\\textnormal{min}}}^{x} \\mathrm{d}x' \\rho(x')$, where $x_{\\textnormal{min}}$ is the minimum value of $x$, then generate a random number $u_i$ uniformly at random from $[0,1]$, and finally compute the value $x_i$ such that $F(x_i) = u_i$. The value $x_i$ is a sample from the PDF $\\rho(x)$ (or the CDF $F(x)$).}\n\\item[ii.] Connect every pair of nodes $i,j$ with probability\n\\begin{eqnarray}\n\\label{r_s1}\nr(\\kappa_{i}, \\theta_{i}; \\kappa_{j}, \\theta_{j})  &=& {1\n\\over 1 + \\left[\\frac{d\\left(\\theta_i ,\\theta_j\\right)}{\\mu\\kappa_i\\kappa_j}\\right]^{\\frac{1}{T}}},\\\\\n\\nonumber d(\\theta_i, \\theta_j) &=& \\frac{N}{2\\pi} \\Delta \\theta_{ij},~\\Delta \\theta_{ij}=|\\pi - | \\pi -|\\theta_i - \\theta_j|||,\\\\\n\\nonumber \\mu&=&\\frac{\\sin{T \\pi}}{2\\bar{k}T\\pi},\n\\end{eqnarray}\nwhere $d(\\theta_i, \\theta_j)$ is the angular distance between nodes $i, j$ on the circle.\n\\end{enumerate}\n\nThe $\\mathbb{S}^{1}$ model is equivalent to the $\\mathbb{H}^{2}$ model after transforming the expected node degrees $\\kappa_i$ to radial coordinates $r_i$ via\n\n", "index": 5, "text": "\\begin{equation}\n\\label{kappa_i}\nr_i = R - 2 \\ln \\frac{\\kappa_i}{\\kappa^{\\text{min}}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"r_{i}=R-2\\ln\\frac{\\kappa_{i}}{\\kappa^{\\text{min}}},\" display=\"block\"><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>R</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mfrac><msub><mi>\u03ba</mi><mi>i</mi></msub><msup><mi>\u03ba</mi><mtext>min</mtext></msup></mfrac></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere $x_{ij} \\approx r_i+r_j+2\\ln{\\frac{\\Delta \\theta_{ij}}{2}}$ is the hyperbolic distance between nodes $i,j$~\\cite{Krioukov2010}. We note that without loss of generality, we use here a hyperbolic plane of curvature $K=-1$. See~\\cite{Krioukov2010} for further details.\n\n\n\\subsection{Two-layer multiplex model}\n\\label{two_layer_model}\n\nWe now describe our framework for constructing a two-layer multiplex system with geometric correlations. Each single-layer (layer 1, layer 2) is constructed according to the $\\mathbb{S}^{1}$ model, and we account for correlations among the hidden variables of nodes in the two layers, whose strength can be tuned. The extension of the framework to more than two layers is straightforward and described in Appendix~\\ref{multilayer_extension}. In a nutshell, our framework consists of the following steps:\n\\begin{enumerate}\n\\item[i.] Assignment of hidden variables $\\kappa_{1,i}, \\theta_{1,i}$ to each node $i$ in layer 1 \nlike in the $\\mathbb{S}^{1}$ model (Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_uniform_theta}));\n\\item[ii.] Assignment of hidden variables $\\kappa_{2,i}, \\theta_{2,i}$ to each node $i$ in layer 2, depending on the node's hidden variables in layer 1 (Eqs.~(\\ref{draw_kappa_paper_1}), (\\ref{eqn_assign_theta}))---the assignment here is done such that the marginal (unconditional) distribution of $\\kappa_{2,i}, \\theta_{2,i}$ is still the one prescribed by the $\\mathbb{S}^{1}$ model (Eqs.~(\\ref{eqn_rho_kappa_2}), (\\ref{eqn_uniform_theta}));\n\\item[iii.] Creation of edges, by connecting node pairs in each layer with the corresponding $\\mathbb{S}^{1}$ connection probability, which depends exclusively on the assigned hidden variables of nodes in each layer (Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}));\n\\item[iv.] $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation, by mapping the hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ to radial coordinates $r_{1,i}, r_{2,i}$ (Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2})).\n\\end{enumerate}\nBelow, we describe these steps in detail. We assume that the two layers have the same number of nodes $N_1=N_2=N$. The extension of the framework to multiplexes with different layer sizes is given in Appendix~\\ref{appendix_different_size_model}.\n\n\n\\emph{i. Assignment of hidden variables in layer 1.} For each node  $i=1,2,\\ldots,N$ in layer 1 we sample  its hidden variable $\\kappa_{1,i}$ from the PDF\n\\begin{eqnarray}\n\\label{eqn_rho_kappa_1}\n\\rho_1(\\kappa_1) &=& (\\gamma_1-1) \\kappa_{1}^{\\text{min}^{\\gamma_1-1}} \\kappa_1^{-\\gamma_1},\\\\\n\\label{kappa_0_1}\n\\kappa_{1}^{\\text{min}}&=&\\bar{k}_1\\frac{\\gamma_1-2}{\\gamma_1-1}, \n\\end{eqnarray}\nwhere $\\bar{k}_1$ and $\\gamma_1 > 2$ are respectively the target average degree and power law degree distribution exponent in layer 1. The angular coordinate $\\theta_{1,i}$ of each node $i=1,2,\\ldots,N$, is sampled from the uniform PDF\n\n", "itemtype": "equation", "pos": 61383, "prevtext": " \nwhere $R$ is the radius of the hyperbolic disc in the $\\mathbb{H}^{2}$ model where all nodes reside,\n\\begin{eqnarray}\n\\label{R}\nR&=&2\\ln{\\frac{N}{c}},\\\\\n\\nonumber c&=&\\bar{k}\\frac{\\sin{T\\pi}}{2T}\\left(\\frac{\\gamma-2}{\\gamma-1}\\right)^2.\n\\end{eqnarray}\nIt is easy to see that after the above change of variables the connection probability in Eq.~(\\ref{r_s1}) becomes the Fermi-Dirac connection probability in the $\\mathbb{H}^{2}$ model,\n\n", "index": 7, "text": "\\begin{equation}\n\\label{fermi_dirac}\np(x_{ij})=\\frac{1}{1+e^{\\frac{1}{2T}(x_{ij}-R)}}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"p(x_{ij})=\\frac{1}{1+e^{\\frac{1}{2T}(x_{ij}-R)}},\" display=\"block\"><mrow><mrow><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>T</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mi>R</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\n\n\\emph{ii. Assignment of hidden variables in layer 2.} We now want to assign to each node $i=1,2,\\ldots,N$ its hidden variable $\\kappa_{2,i}$ in layer 2, conditioned on the value of its hidden variable $\\kappa_{1,i}$ in layer 1. At the same time, we want the $\\kappa_{2,i}$'s to satisfy the marginal (unconditional) PDF\n\\begin{eqnarray}\n\\label{eqn_rho_kappa_2}\n\\rho_2(\\kappa_2) &=& (\\gamma_2-1) \\kappa_{2}^{\\text{min}^{\\gamma_2-1}} \\kappa_2^{-\\gamma_2},\\\\\n\\label{kappa_0_2}\n\\kappa_{2}^{\\text{min}}&=&\\bar{k}_2\\frac{\\gamma_2-2}{\\gamma_2-1}, \n\\end{eqnarray}\nwhere $\\bar{k}_2$ and $\\gamma_2 > 2$ are respectively the target average degree and power law degree distribution exponent in layer 2. Eq.~(\\ref{eqn_rho_kappa_2}) should be satisfied irrespectively of the correlation strength between the $\\kappa_{2,i}$ and $\\kappa_{1,i}$. To accomplish this, we sample the hidden variable $\\kappa_{2,i}$ of each node $i=1,2,\\ldots,N$, from the conditional cumulative distribution function (CDF) \n\n", "itemtype": "equation", "pos": 64343, "prevtext": "\nwhere $x_{ij} \\approx r_i+r_j+2\\ln{\\frac{\\Delta \\theta_{ij}}{2}}$ is the hyperbolic distance between nodes $i,j$~\\cite{Krioukov2010}. We note that without loss of generality, we use here a hyperbolic plane of curvature $K=-1$. See~\\cite{Krioukov2010} for further details.\n\n\n\\subsection{Two-layer multiplex model}\n\\label{two_layer_model}\n\nWe now describe our framework for constructing a two-layer multiplex system with geometric correlations. Each single-layer (layer 1, layer 2) is constructed according to the $\\mathbb{S}^{1}$ model, and we account for correlations among the hidden variables of nodes in the two layers, whose strength can be tuned. The extension of the framework to more than two layers is straightforward and described in Appendix~\\ref{multilayer_extension}. In a nutshell, our framework consists of the following steps:\n\\begin{enumerate}\n\\item[i.] Assignment of hidden variables $\\kappa_{1,i}, \\theta_{1,i}$ to each node $i$ in layer 1 \nlike in the $\\mathbb{S}^{1}$ model (Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_uniform_theta}));\n\\item[ii.] Assignment of hidden variables $\\kappa_{2,i}, \\theta_{2,i}$ to each node $i$ in layer 2, depending on the node's hidden variables in layer 1 (Eqs.~(\\ref{draw_kappa_paper_1}), (\\ref{eqn_assign_theta}))---the assignment here is done such that the marginal (unconditional) distribution of $\\kappa_{2,i}, \\theta_{2,i}$ is still the one prescribed by the $\\mathbb{S}^{1}$ model (Eqs.~(\\ref{eqn_rho_kappa_2}), (\\ref{eqn_uniform_theta}));\n\\item[iii.] Creation of edges, by connecting node pairs in each layer with the corresponding $\\mathbb{S}^{1}$ connection probability, which depends exclusively on the assigned hidden variables of nodes in each layer (Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}));\n\\item[iv.] $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation, by mapping the hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ to radial coordinates $r_{1,i}, r_{2,i}$ (Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2})).\n\\end{enumerate}\nBelow, we describe these steps in detail. We assume that the two layers have the same number of nodes $N_1=N_2=N$. The extension of the framework to multiplexes with different layer sizes is given in Appendix~\\ref{appendix_different_size_model}.\n\n\n\\emph{i. Assignment of hidden variables in layer 1.} For each node  $i=1,2,\\ldots,N$ in layer 1 we sample  its hidden variable $\\kappa_{1,i}$ from the PDF\n\\begin{eqnarray}\n\\label{eqn_rho_kappa_1}\n\\rho_1(\\kappa_1) &=& (\\gamma_1-1) \\kappa_{1}^{\\text{min}^{\\gamma_1-1}} \\kappa_1^{-\\gamma_1},\\\\\n\\label{kappa_0_1}\n\\kappa_{1}^{\\text{min}}&=&\\bar{k}_1\\frac{\\gamma_1-2}{\\gamma_1-1}, \n\\end{eqnarray}\nwhere $\\bar{k}_1$ and $\\gamma_1 > 2$ are respectively the target average degree and power law degree distribution exponent in layer 1. The angular coordinate $\\theta_{1,i}$ of each node $i=1,2,\\ldots,N$, is sampled from the uniform PDF\n\n", "index": 9, "text": "\\begin{equation}\n\\label{eqn_uniform_theta}\nf(\\theta)=\\frac{1}{2\\pi},~\\theta\\in [0, 2\\pi].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"f(\\theta)=\\frac{1}{2\\pi},\\leavevmode\\nobreak\\ \\theta\\in[0,2\\pi].\" display=\"block\"><mrow><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></mfrac></mrow><mo rspace=\"7.5pt\">,</mo><mrow><mi>\u03b8</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>,</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": " \nwhere $\\kappa_1$ is the value of the hidden variable of the node in layer 1, $\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}$ are the network parameters defined earlier, and $\\nu \\in [0,1]$ is the correlation strength parameter. The higher the value of $\\nu$ the stronger is the correlation between $\\kappa_{2,i}$ and $\\kappa_{1,i}$. It is easy to see that when $\\nu=0$ (no correlation between $\\kappa_{2,i}$ and $\\kappa_{1,i}$), Eq.~(\\ref{draw_kappa_paper_1}) becomes the marginal CDF of $\\kappa_{2,i}$ given in Eq.~(\\ref{cdf_2}) below. On the other hand, when $\\nu \\to 1$ (maximally correlated $\\kappa_{2,i}$ and $\\kappa_{1,i}$), Eq.~(\\ref{draw_kappa_paper_1}) \nbecomes\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\\emph{ii. Assignment of hidden variables in layer 2.} We now want to assign to each node $i=1,2,\\ldots,N$ its hidden variable $\\kappa_{2,i}$ in layer 2, conditioned on the value of its hidden variable $\\kappa_{1,i}$ in layer 1. At the same time, we want the $\\kappa_{2,i}$'s to satisfy the marginal (unconditional) PDF\n\\begin{eqnarray}\n\\label{eqn_rho_kappa_2}\n\\rho_2(\\kappa_2) &=& (\\gamma_2-1) \\kappa_{2}^{\\text{min}^{\\gamma_2-1}} \\kappa_2^{-\\gamma_2},\\\\\n\\label{kappa_0_2}\n\\kappa_{2}^{\\text{min}}&=&\\bar{k}_2\\frac{\\gamma_2-2}{\\gamma_2-1}, \n\\end{eqnarray}\nwhere $\\bar{k}_2$ and $\\gamma_2 > 2$ are respectively the target average degree and power law degree distribution exponent in layer 2. Eq.~(\\ref{eqn_rho_kappa_2}) should be satisfied irrespectively of the correlation strength between the $\\kappa_{2,i}$ and $\\kappa_{1,i}$. To accomplish this, we sample the hidden variable $\\kappa_{2,i}$ of each node $i=1,2,\\ldots,N$, from the conditional cumulative distribution function (CDF) \n\n", "index": 11, "text": "\\begin{multline}\n\\label{draw_kappa_paper_1}\nF_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = e^{-(\\varphi_1^{1 / (1-\\nu)}+\\varphi_2^{1 / (1-\\nu)})^{1-\\nu}} \\\\ \\times \\left[ \\varphi_1^{1 / (1-\\nu)} + \\varphi_2^{1 / (1-\\nu)} \\right]^{-\\nu} \\frac{\\varphi_1^{\\nu/(1-\\nu)} {\\kappa_{1}^{\\text{min}}} {\\kappa_{1}}^{{\\gamma_1}}}{{\\kappa_{1}^{\\text{min}}} {\\kappa_{1}}^{{\\gamma_1}}-\\kappa_1^{\\text{min}^{{\\gamma_1}}} {\\kappa_{1}}},\\\\\n\\varphi_i = -\\ln \\left[1-(\\kappa_{i}^{\\text{min}}/\\kappa_i)^{\\gamma_i-1}\\right],~\\textnormal{for}~i=1,2,\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle F_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}},{%&#10;\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=e^{-(\\varphi_{1}^{1/(1-%&#10;\\nu)}+\\varphi_{2}^{1/(1-\\nu)})^{1-\\nu}}\\\\&#10;\\displaystyle\\times\\left[\\varphi_{1}^{1/(1-\\nu)}+\\varphi_{2}^{1/(1-\\nu)}\\right%&#10;]^{-\\nu}\\frac{\\varphi_{1}^{\\nu/(1-\\nu)}{\\kappa_{1}^{\\text{min}}}{\\kappa_{1}}^{%&#10;{\\gamma_{1}}}}{{\\kappa_{1}^{\\text{min}}}{\\kappa_{1}}^{{\\gamma_{1}}}-\\kappa_{1}%&#10;^{\\text{min}^{{\\gamma_{1}}}}{\\kappa_{1}}},\\\\&#10;\\displaystyle\\varphi_{i}=-\\ln\\left[1-(\\kappa_{i}^{\\text{min}}/\\kappa_{i})^{%&#10;\\gamma_{i}-1}\\right],\\leavevmode\\nobreak\\ \\textnormal{for}\\leavevmode\\nobreak%&#10;\\ i=1,2,\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>F</mi><mi>\u03bd</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msup><mi>e</mi><mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\u03c6</mi><mn>1</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo>+</mo><msubsup><mi>\u03c6</mi><mn>2</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow></msup></mrow></msup></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo>\u00d7</mo><mrow><msup><mrow><mo>[</mo><mrow><msubsup><mi>\u03c6</mi><mn>1</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo>+</mo><msubsup><mi>\u03c6</mi><mn>2</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup></mrow><mo>]</mo></mrow><mrow><mo>-</mo><mi>\u03bd</mi></mrow></msup><mo>\u2062</mo><mfrac><mrow><msubsup><mi>\u03c6</mi><mn>1</mn><mrow><mi>\u03bd</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup><mo>\u2062</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><mmultiscripts><mi>\u03ba</mi><mn>1</mn><none/><none/><msub><mi>\u03b3</mi><mn>1</mn></msub></mmultiscripts></mrow><mrow><mrow><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><mmultiscripts><mi>\u03ba</mi><mn>1</mn><none/><none/><msub><mi>\u03b3</mi><mn>1</mn></msub></mmultiscripts></mrow><mo>-</mo><mrow><msubsup><mi>\u03ba</mi><mn>1</mn><msup><mtext>min</mtext><msub><mi>\u03b3</mi><mn>1</mn></msub></msup></msubsup><mo>\u2062</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow></mrow></mfrac></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mrow><msub><mi>\u03c6</mi><mi>i</mi></msub><mo>=</mo><mrow><mo>-</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\u03ba</mi><mi>i</mi><mtext>min</mtext></msubsup><mo>/</mo><msub><mi>\u03ba</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><msub><mi>\u03b3</mi><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mo rspace=\"7.5pt\">,</mo><mrow><mrow><mpadded width=\"+5pt\"><mtext>for</mtext></mpadded><mo>\u2062</mo><mi>i</mi></mrow><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></mrow></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere $\\Theta[x]$ denotes the Heaviside step function. That is, when $\\nu \\to 1$ \n\n", "itemtype": "equation", "pos": 66749, "prevtext": " \nwhere $\\kappa_1$ is the value of the hidden variable of the node in layer 1, $\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}$ are the network parameters defined earlier, and $\\nu \\in [0,1]$ is the correlation strength parameter. The higher the value of $\\nu$ the stronger is the correlation between $\\kappa_{2,i}$ and $\\kappa_{1,i}$. It is easy to see that when $\\nu=0$ (no correlation between $\\kappa_{2,i}$ and $\\kappa_{1,i}$), Eq.~(\\ref{draw_kappa_paper_1}) becomes the marginal CDF of $\\kappa_{2,i}$ given in Eq.~(\\ref{cdf_2}) below. On the other hand, when $\\nu \\to 1$ (maximally correlated $\\kappa_{2,i}$ and $\\kappa_{1,i}$), Eq.~(\\ref{draw_kappa_paper_1}) \nbecomes\n\n", "index": 13, "text": "\\begin{multline}\n\\label{kappa_i_2_limit}\nF_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) \\\\ = \\Theta\\left[\\kappa_2 - {\\kappa_{2}^{\\text{min}}}  \\left(\\frac{{\\kappa_{1}}}{{\\kappa_{1}^{\\text{min}}}}\\right)^{(1-{\\gamma_1})/(1-{\\gamma_2})} \\right],\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle F_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}},{%&#10;\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})\\\\&#10;\\displaystyle=\\Theta\\left[\\kappa_{2}-{\\kappa_{2}^{\\text{min}}}\\left(\\frac{{%&#10;\\kappa_{1}}}{{\\kappa_{1}^{\\text{min}}}}\\right)^{(1-{\\gamma_{1}})/(1-{\\gamma_{2%&#10;}})}\\right],\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>F</mi><mi>\u03bd</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo>=</mo><mrow><mi mathvariant=\"normal\">\u0398</mi><mo>\u2062</mo><mrow><mo>[</mo><mrow><msub><mi>\u03ba</mi><mn>2</mn></msub><mo>-</mo><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><msup><mrow><mo>(</mo><mfrac><msub><mi>\u03ba</mi><mn>1</mn></msub><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup></mfrac><mo>)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b3</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b3</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhich yields $\\kappa_{2,i}=\\kappa_{1,i}$ if ${\\kappa_{2}^{\\text{min}}}={\\kappa_{1}^{\\text{min}}}$ and ${\\gamma_1}={\\gamma_2}$.\n\nTo derive Eq.~(\\ref{draw_kappa_paper_1}) we use copulas~\\cite{copulas}. Copulas are multivariate probability distributions used to describe the dependence between random variables. In particular, any multivariate CDF $F(\\kappa_1, . . . , \\kappa_n)$ of $n$ random variables $\\kappa_1, . . . , \\kappa_n$, can be written in the form $F(\\kappa_1, . . . , \\kappa_n) = C(F_1(\\kappa_1), . . . , F_n(\\kappa_n))$ where $F_1(\\kappa_1), . . . , F_n(\\kappa_n)$ are the marginal CDFs of  $F(\\kappa_1, . . . , \\kappa_n)$, and $C$ is called a copula. Each of the marginals of $C$ is uniform in $[0, 1]$, and there are many parametric copula families available, which have parameters that control the strength of the dependence between the random variables~\\cite{copulas}.\n\nIn our case, the random variables are the node hidden variables $\\kappa_1, \\kappa_2$ in layers 1 and 2, whose marginal CDFs can be computed from Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_rho_kappa_2}),\n\\begin{eqnarray}\n\\label{cdf_1}\nF_1(\\kappa_1) =  1 - {\\kappa_{1}}^{(1 - {\\gamma_1})} \\kappa_1^{\\text{min}^{({\\gamma_1}-1)}},\\\\ \n\\label{cdf_2}\nF_2(\\kappa_2) =  1 - {\\kappa_{2}}^{(1 - {\\gamma_2})} \\kappa_2^{\\text{min}^{({\\gamma_2}-1)}}.\n\\end{eqnarray}\nFor the copula function $C$, we use the bivariate Gumbel-Hougaard copula~\\cite{copulas}, defined as\n\\begin{eqnarray}\n\\label{c_h_copula}\nC_\\eta(u,v)&=&e^{-[(-\\ln{u})^\\eta+(-\\ln{v})^\\eta]^{1/\\eta}},\\\\ \n\\nonumber \\eta &\\equiv& \\frac{1}{1-\\nu} \\in [1, \\infty). \n\\end{eqnarray}\nHence, our copula reads\n\n", "itemtype": "equation", "pos": 67156, "prevtext": "\nwhere $\\Theta[x]$ denotes the Heaviside step function. That is, when $\\nu \\to 1$ \n\n", "index": 15, "text": "\\begin{equation}\n\\kappa_{2,i} =  {\\kappa_{2}^{\\text{min}}}  \\left(\\frac{\\kappa_{1,i}}{{\\kappa_{1}^{\\text{min}}}}\\right)^{(1-{\\gamma_1})/(1-{\\gamma_2})} {\\,,}\n\\label{kappa_i_2_limit_relation}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\kappa_{2,i}={\\kappa_{2}^{\\text{min}}}\\left(\\frac{\\kappa_{1,i}}{{\\kappa_{1}^{%&#10;\\text{min}}}}\\right)^{(1-{\\gamma_{1}})/(1-{\\gamma_{2}})}{\\,,}\" display=\"block\"><mrow><mrow><msub><mi>\u03ba</mi><mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub><mo>=</mo><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msup><mrow><mo>(</mo><mfrac><msub><mi>\u03ba</mi><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup></mfrac><mo>)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b3</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b3</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mpadded></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nThe joint PDF of ${\\kappa_{1}}$ and ${\\kappa_{2}}$, $\\rho_\\eta({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$, can be obtained by differentiating the copula with respect to $\\kappa_1, \\kappa_2$,\n\n", "itemtype": "equation", "pos": 68994, "prevtext": "\nwhich yields $\\kappa_{2,i}=\\kappa_{1,i}$ if ${\\kappa_{2}^{\\text{min}}}={\\kappa_{1}^{\\text{min}}}$ and ${\\gamma_1}={\\gamma_2}$.\n\nTo derive Eq.~(\\ref{draw_kappa_paper_1}) we use copulas~\\cite{copulas}. Copulas are multivariate probability distributions used to describe the dependence between random variables. In particular, any multivariate CDF $F(\\kappa_1, . . . , \\kappa_n)$ of $n$ random variables $\\kappa_1, . . . , \\kappa_n$, can be written in the form $F(\\kappa_1, . . . , \\kappa_n) = C(F_1(\\kappa_1), . . . , F_n(\\kappa_n))$ where $F_1(\\kappa_1), . . . , F_n(\\kappa_n)$ are the marginal CDFs of  $F(\\kappa_1, . . . , \\kappa_n)$, and $C$ is called a copula. Each of the marginals of $C$ is uniform in $[0, 1]$, and there are many parametric copula families available, which have parameters that control the strength of the dependence between the random variables~\\cite{copulas}.\n\nIn our case, the random variables are the node hidden variables $\\kappa_1, \\kappa_2$ in layers 1 and 2, whose marginal CDFs can be computed from Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_rho_kappa_2}),\n\\begin{eqnarray}\n\\label{cdf_1}\nF_1(\\kappa_1) =  1 - {\\kappa_{1}}^{(1 - {\\gamma_1})} \\kappa_1^{\\text{min}^{({\\gamma_1}-1)}},\\\\ \n\\label{cdf_2}\nF_2(\\kappa_2) =  1 - {\\kappa_{2}}^{(1 - {\\gamma_2})} \\kappa_2^{\\text{min}^{({\\gamma_2}-1)}}.\n\\end{eqnarray}\nFor the copula function $C$, we use the bivariate Gumbel-Hougaard copula~\\cite{copulas}, defined as\n\\begin{eqnarray}\n\\label{c_h_copula}\nC_\\eta(u,v)&=&e^{-[(-\\ln{u})^\\eta+(-\\ln{v})^\\eta]^{1/\\eta}},\\\\ \n\\nonumber \\eta &\\equiv& \\frac{1}{1-\\nu} \\in [1, \\infty). \n\\end{eqnarray}\nHence, our copula reads\n\n", "index": 17, "text": "\\begin{equation}\nC_\\eta(F_1(\\kappa_1),F_2(\\kappa_2))=e^{-[(-\\ln{F_1(\\kappa_1)})^\\eta+(-\\ln{F_2(\\kappa_2)})^\\eta]^{1/\\eta}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"C_{\\eta}(F_{1}(\\kappa_{1}),F_{2}(\\kappa_{2}))=e^{-[(-\\ln{F_{1}(\\kappa_{1})})^{%&#10;\\eta}+(-\\ln{F_{2}(\\kappa_{2})})^{\\eta}]^{1/\\eta}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>C</mi><mi>\u03b7</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>F</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msup><mi>e</mi><mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">[</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>F</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>\u03b7</mi></msup><mo>+</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>F</mi><mn>2</mn></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>\u03b7</mi></msup></mrow><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>\u03b7</mi></mrow></msup></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhile the conditional PDF $\\rho_\\eta({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ can be written as\n\n", "itemtype": "equation", "pos": 69387, "prevtext": "\nThe joint PDF of ${\\kappa_{1}}$ and ${\\kappa_{2}}$, $\\rho_\\eta({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$, can be obtained by differentiating the copula with respect to $\\kappa_1, \\kappa_2$,\n\n", "index": 19, "text": "\\begin{equation}\n\\rho_\\eta({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\frac{\\partial^2 C_\\eta(F_1(\\kappa_1),F_2(\\kappa_2))}{\\partial {\\kappa_{1}} \\partial {\\kappa_{2}}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\rho_{\\eta}({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_{1}},{\\gamma_{2}},{\\kappa_{1}^%&#10;{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=\\frac{\\partial^{2}C_{\\eta}(F_{1}(%&#10;\\kappa_{1}),F_{2}(\\kappa_{2}))}{\\partial{\\kappa_{1}}\\partial{\\kappa_{2}}},\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03c1</mi><mi>\u03b7</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><msup><mo>\u2202</mo><mn>2</mn></msup><mo>\u2061</mo><msub><mi>C</mi><mi>\u03b7</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>F</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>\u03ba</mi><mn>2</mn></msub></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nThe conditional CDF $F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ can be therefore computed as \n\n", "itemtype": "equation", "pos": 69797, "prevtext": "\nwhile the conditional PDF $\\rho_\\eta({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ can be written as\n\n", "index": 21, "text": "\\begin{multline}\n \\rho_\\eta({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\\\ \\rho_\\eta({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) \\frac{1}{\\rho_1({\\kappa_{1}})}.\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\rho_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}}%&#10;,{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=\\\\&#10;\\displaystyle\\rho_{\\eta}({\\kappa_{1}},{\\kappa_{2}},\\{{\\gamma_{1}},{\\gamma_{2}}%&#10;,{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})\\frac{1}{\\rho_{1}({%&#10;\\kappa_{1}})}.\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>\u03c1</mi><mi>\u03b7</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><msub><mi>\u03c1</mi><mi>\u03b7</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mfrac><mn>1</mn><mrow><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhich yields Eq.~(\\ref{draw_kappa_paper_1}).\n\n\nThe angular coordinate $\\theta_{2,i}$ of each node $i=1,2,\\ldots,N$ in layer 2 is obtained by\n\n", "itemtype": "equation", "pos": 70263, "prevtext": "\nThe conditional CDF $F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ can be therefore computed as \n\n", "index": 23, "text": "\\begin{multline}\nF_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\\\ \\int_{{\\kappa_{2}^{\\text{min}}}}^{{\\kappa_{2}}} \\! \\mathrm{d}\\kappa' \\, \\rho_\\eta(\\kappa'|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\\\ \\frac{\\partial C_\\eta(F_1(\\kappa_1),F_2(\\kappa_2))}{\\partial {\\kappa_{1}}} \\frac{1}{\\rho_1({\\kappa_{1}})},\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}},{%&#10;\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=\\\\&#10;\\displaystyle\\int_{{\\kappa_{2}^{\\text{min}}}}^{{\\kappa_{2}}}\\!\\mathrm{d}\\kappa%&#10;^{\\prime}\\,\\rho_{\\eta}(\\kappa^{\\prime}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}%&#10;},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=\\\\&#10;\\displaystyle\\frac{\\partial C_{\\eta}(F_{1}(\\kappa_{1}),F_{2}(\\kappa_{2}))}{%&#10;\\partial{\\kappa_{1}}}\\frac{1}{\\rho_{1}({\\kappa_{1}})},\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>F</mi><mi>\u03b7</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mpadded width=\"-1.7pt\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><msub><mi>\u03ba</mi><mn>2</mn></msub></msubsup></mpadded><mi mathvariant=\"normal\">d</mi><mpadded width=\"+1.7pt\"><msup><mi>\u03ba</mi><mo>\u2032</mo></msup></mpadded><msub><mi>\u03c1</mi><mi>\u03b7</mi></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03ba</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>C</mi><mi>\u03b7</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>F</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow></mfrac><mo>\u2062</mo><mfrac><mn>1</mn><mrow><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere $\\theta_{1,i}$ is the angular coordinate of the node in layer 1, and $l_i$ is a directed arc length on the $\\mathbb{S}^1$ circle of radius $R=N/2\\pi$, which is sampled from the zero-mean truncated Gaussian PDF\n\\begin{eqnarray}\n\\label{eqn_trunc_gauss}\nf_{\\sigma}(l) &=&\\frac{ \\frac{1}{\\sigma} \\phi\\left(\\frac{l}{\\sigma}\\right) }{\\Phi\\left(\\frac{N}{2\\sigma}\\right) - \\Phi\\left(-\\frac{N}{2\\sigma}\\right)},~~-\\frac{N}{2} \\leq l \\leq \\frac{N}{2},\\\\\n\\nonumber \\sigma& \\equiv &100 \\left(\\frac{1}{g}-1\\right),\n\\end{eqnarray}\nwhere $\\phi(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^2}$, $\\Phi(x) = \\int \\! \\mathrm{d}x \\, \\phi(x)$, $\\sigma \\in (0,\\infty)$ is the variance of the PDF, and $g \\in [0,1]$ is the angular correlation strength parameter. The higher the value of $g$ the stronger is the correlation between $\\theta_{2,i}$ and $\\theta_{1,i}$. When $g \\to 0$, $\\sigma \\to \\infty$, $f_{\\sigma}(l)$ becomes the uniform PDF, and $\\theta_{2,i}$, $\\theta_{1,i}$ are not correlated. When $g=1$, $\\sigma=0$, and $l_i=0$, meaning that the angles of each node $i$ are identical in the two layers, $\\theta_{2,i}=\\theta_{1,i}$. \n \n\n\\emph{iii. Creation of edges.} Once all node hidden variables are assigned, we connect each node pair $i, j$ in layers 1 and 2 with the corresponding $\\mathbb{S}^{1}$ connection probabilities given in Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}) below,\n\\begin{eqnarray}\n\\label{c_prob_1}\nr_1(\\kappa_{1,i}, \\theta_{1,i}; \\kappa_{1,j}, \\theta_{1,j})  &=& {1 \\over 1 + \\left[\\frac{d_1\\left(\\theta_{1,i} ,\\theta_{1,j}\\right)}{\\mu_1\\kappa_{1,i}\\kappa_{1,j}}\\right]^{\\frac{1}{T_1}}},\\\\\n\\nonumber d_1(\\theta_{1,i}, \\theta_{1,j}) &=& \\frac{N}{2\\pi} \\Delta \\theta_{1,ij},\n\\\\\n\\nonumber \\Delta \\theta_{1,ij}&=&|\\pi - | \\pi -|\\theta_{1,i} - \\theta_{1,j}|||,\\\\\n\\nonumber \\mu_1&=&\\frac{\\sin{T_1 \\pi}}{2\\bar{k}_1T\\pi},\\\\\n\\label{c_prob_2}\nr_2(\\kappa_{2,i}, \\theta_{2,i}; \\kappa_{2,j}, \\theta_{2,j})  &=& {1 \\over 1 + \\left[\\frac{d_2\\left(\\theta_{2,i} ,\\theta_{2,j}\\right)}{\\mu_2\\kappa_{2,i}\\kappa_{2,j}}\\right]^{\\frac{1}{T_2}}},\\\\\n\\nonumber d_2(\\theta_{2,i}, \\theta_{2,j}) &=& \\frac{N}{2\\pi} \\Delta \\theta_{2,ij}, \n\\\\\n\\nonumber \\Delta \\theta_{2,ij}&=&|\\pi - | \\pi -|\\theta_{2,i} - \\theta_{2,j}|||,\\\\\n\\nonumber \\mu_2&=&\\frac{\\sin{T_2\\pi}}{2\\bar{k}_2T_2\\pi},\n\\end{eqnarray}\nwhere $T_1 \\in [0,1), T_2 \\in [0,1)$ are the temperatures, which control clustering in each layer. We recall that the average node clustering is maximized at temperature $T = 0$, and nearly linearly decreases to zero with $T \\in [0, 1)$.\n\n\n\\emph{iv. $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation.} Finally, we map the node hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ in layers 1, 2, to radial coordinates $r_{1,i}, r_{2,i}$ using the relations below,\n\\begin{eqnarray}\n\\label{kappa_i_1}\nr_{1,i} &=& R_1 - 2 \\ln \\frac{\\kappa_{1,i}}{\\kappa_{1}^{\\text{min}}},~R_1= 2\\ln{\\frac{N}{c_1}},\\\\\n\\nonumber c_1&=&\\bar{k}_1\\frac{\\sin{T_1\\pi}}{2T_1}\\left(\\frac{\\gamma_1-2}{\\gamma_1-1}\\right)^2,\\\\\n\\label{kappa_i_2}\nr_{2,i} &=& R_2 - 2 \\ln \\frac{\\kappa_{2,i}}{\\kappa_{2}^{\\text{min}}},~R_2= 2\\ln{\\frac{N}{c_2}},\\\\\n\\nonumber c_2&=&\\bar{k}_2\\frac{\\sin{T_2\\pi}}{2T_2}\\left(\\frac{\\gamma_2-2}{\\gamma_2-1}\\right)^2,\n\\end{eqnarray}\nwhere $\\kappa_{1}^{\\text{min}}, \\kappa_{2}^{\\text{min}}$ are given in Eqs.~(\\ref{kappa_0_1}), (\\ref{kappa_0_2}).\n\n\n\\subsection{Modeling more than two layers}\n\\label{multilayer_extension}\n\nTo construct a multilayer system consisting of $n$ layers (layer 1, layer 2, $\\ldots$, layer $n$), we work in the same way as with the two-layer system described above. Specifically, for each two consecutive layers $j-1, j$, for $2 \\leq j \\leq n$, we first fix their radial and angular correlation strength  parameters $\\nu_{j, j-1} \\in [0,1]$, $g_{j, j-1} \\in [0,1]$\nto some desired values. Subsequently, we assign hidden variables $\\kappa_{1,i}, \\theta_{1,i}$ to nodes in layer 1 as described earlier (Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_uniform_theta})), as well as hidden variables $\\kappa_{2,i}, \\theta_{2,i}$ to nodes in layer 2, conditioned on $\\kappa_{1,i}, \\theta_{1,i}$ (Eqs.~(\\ref{draw_kappa_paper_1}), (\\ref{eqn_assign_theta})). Then, we continue by assigning hidden variables $\\kappa_{j,i}, \\theta_{j,i}$ to nodes in layer $3 \\leq j \\leq n$, conditioned on the values of the hidden variables $\\kappa_{j-1,i}, \\theta_{j-1,i}$ of the nodes in layer $j-1$. This conditional assignment is done in exactly the same manner as the assignment of $\\kappa_{2,i}, \\theta_{2,i}$, which is conditioned on the values of $\\kappa_{1,i}, \\theta_{1,i}$. Once all node hidden variables in all layers are assigned, we create edges in each layer by connecting each node pair with the corresponding $\\mathbb{S}^{1}$ connection probability (cf. Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2})). Finally, for each layer $1 \\leq j \\leq n$, we map the node hidden variables $\\kappa_{j,i}$ to radial coordinates $r_{j,i}$ as described earlier (cf. Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2})). We have used this procedure to construct our three- and four-layer multiplexes in the main text and in Appendix~\\ref{appendix_navigation}, where the correlation strengths between subsequent layers are set to the same value, $\\nu_{j, j-1} =\\nu \\in [0,1]$, $g_{j, j-1}=g \\in [0,1]$,~$\\forall j \\geq 2$.\n\n\n\\subsection{Extension to multiplexes with different layer sizes}\n\\label{appendix_different_size_model}\n\nHere, we extend our framework to multiplexes with different layer sizes. Specifically, we consider a two-layer multiplex with layers 1, 2, which have number of nodes $N_1, N_2$. We assume that $N_1 > N_2$ and that there is a subset of $N_{\\textnormal{common}}$ nodes in layer 1 that also exist in layer 2, $N_{\\textnormal{common}} \\leq N_2$. To construct the two-layer multiplex we follow the steps below.\n\n\\emph{(i) Assignment of hidden variables in layer 1.} For each node  $i=1,2,\\ldots,N_1$ in layer 1, we sample  its hidden variable $\\kappa_{1,i}$ as before, i.e., from the PDF $\\rho_1(\\kappa_1)$ in Eq.~(\\ref{eqn_rho_kappa_1}), and its angular coordinate $\\theta_{1,i}$ from the uniform PDF$f(\\theta)$ in Eq.~(\\ref{eqn_uniform_theta}).\n\n\\emph{(ii) Determining the common nodes.} We now need to decide the $N_{\\textnormal{common}}$  nodes from layer 1 that will also be present in layer 2. The simplest approach is to randomly select (approximately) $N_{\\textnormal{common}}$ nodes from layer~1, by sampling each node from layer~1 with the same probability $\\psi$,\n\n", "itemtype": "equation", "pos": 70849, "prevtext": "\nwhich yields Eq.~(\\ref{draw_kappa_paper_1}).\n\n\nThe angular coordinate $\\theta_{2,i}$ of each node $i=1,2,\\ldots,N$ in layer 2 is obtained by\n\n", "index": 25, "text": "\\begin{equation}\n\\theta_{2,i} = \\mod\\left[\\theta_{1,i} + \\frac{2 \\pi l_i}{N},2\\pi\\right],\n\\label{eqn_assign_theta}  \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\theta_{2,i}=\\mod\\left[\\theta_{1,i}+\\frac{2\\pi l_{i}}{N},2\\pi\\right],\" display=\"block\"><mrow><msub><mi>\u03b8</mi><mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub><mo>=</mo><mo lspace=\"2.5pt\" rspace=\"2.5pt\">mod</mo><mrow><mo>[</mo><msub><mi>\u03b8</mi><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub><mo>+</mo><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msub><mi>l</mi><mi>i</mi></msub></mrow><mi>N</mi></mfrac><mo>,</mo><mn>2</mn><mi>\u03c0</mi><mo>]</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": " \nand declaring each sampled node as a common node that will also exist in layer~2. However, this random sampling approach may not be realistic. Indeed, as we have mentioned in the main text, nodes with a higher degree in the IPv4 Internet (larger layer) have a higher probability to also exist in the IPv6 Internet (smaller layer). Fig.~\\ref{fig_estimate_psi} shows the empirical probability for a node (AS) to exist in the IPv6 Internet given its degree in the IPv4 Internet. \n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{sfig5.pdf}\n\\caption{\\textbf{Probability that a node (AS) exists in the IPv6 Internet given its degree in the IPv4 Internet.} \n\\label{fig_estimate_psi}}\n\\end{figure}\nThis probability can be approximated by\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $\\theta_{1,i}$ is the angular coordinate of the node in layer 1, and $l_i$ is a directed arc length on the $\\mathbb{S}^1$ circle of radius $R=N/2\\pi$, which is sampled from the zero-mean truncated Gaussian PDF\n\\begin{eqnarray}\n\\label{eqn_trunc_gauss}\nf_{\\sigma}(l) &=&\\frac{ \\frac{1}{\\sigma} \\phi\\left(\\frac{l}{\\sigma}\\right) }{\\Phi\\left(\\frac{N}{2\\sigma}\\right) - \\Phi\\left(-\\frac{N}{2\\sigma}\\right)},~~-\\frac{N}{2} \\leq l \\leq \\frac{N}{2},\\\\\n\\nonumber \\sigma& \\equiv &100 \\left(\\frac{1}{g}-1\\right),\n\\end{eqnarray}\nwhere $\\phi(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^2}$, $\\Phi(x) = \\int \\! \\mathrm{d}x \\, \\phi(x)$, $\\sigma \\in (0,\\infty)$ is the variance of the PDF, and $g \\in [0,1]$ is the angular correlation strength parameter. The higher the value of $g$ the stronger is the correlation between $\\theta_{2,i}$ and $\\theta_{1,i}$. When $g \\to 0$, $\\sigma \\to \\infty$, $f_{\\sigma}(l)$ becomes the uniform PDF, and $\\theta_{2,i}$, $\\theta_{1,i}$ are not correlated. When $g=1$, $\\sigma=0$, and $l_i=0$, meaning that the angles of each node $i$ are identical in the two layers, $\\theta_{2,i}=\\theta_{1,i}$. \n \n\n\\emph{iii. Creation of edges.} Once all node hidden variables are assigned, we connect each node pair $i, j$ in layers 1 and 2 with the corresponding $\\mathbb{S}^{1}$ connection probabilities given in Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}) below,\n\\begin{eqnarray}\n\\label{c_prob_1}\nr_1(\\kappa_{1,i}, \\theta_{1,i}; \\kappa_{1,j}, \\theta_{1,j})  &=& {1 \\over 1 + \\left[\\frac{d_1\\left(\\theta_{1,i} ,\\theta_{1,j}\\right)}{\\mu_1\\kappa_{1,i}\\kappa_{1,j}}\\right]^{\\frac{1}{T_1}}},\\\\\n\\nonumber d_1(\\theta_{1,i}, \\theta_{1,j}) &=& \\frac{N}{2\\pi} \\Delta \\theta_{1,ij},\n\\\\\n\\nonumber \\Delta \\theta_{1,ij}&=&|\\pi - | \\pi -|\\theta_{1,i} - \\theta_{1,j}|||,\\\\\n\\nonumber \\mu_1&=&\\frac{\\sin{T_1 \\pi}}{2\\bar{k}_1T\\pi},\\\\\n\\label{c_prob_2}\nr_2(\\kappa_{2,i}, \\theta_{2,i}; \\kappa_{2,j}, \\theta_{2,j})  &=& {1 \\over 1 + \\left[\\frac{d_2\\left(\\theta_{2,i} ,\\theta_{2,j}\\right)}{\\mu_2\\kappa_{2,i}\\kappa_{2,j}}\\right]^{\\frac{1}{T_2}}},\\\\\n\\nonumber d_2(\\theta_{2,i}, \\theta_{2,j}) &=& \\frac{N}{2\\pi} \\Delta \\theta_{2,ij}, \n\\\\\n\\nonumber \\Delta \\theta_{2,ij}&=&|\\pi - | \\pi -|\\theta_{2,i} - \\theta_{2,j}|||,\\\\\n\\nonumber \\mu_2&=&\\frac{\\sin{T_2\\pi}}{2\\bar{k}_2T_2\\pi},\n\\end{eqnarray}\nwhere $T_1 \\in [0,1), T_2 \\in [0,1)$ are the temperatures, which control clustering in each layer. We recall that the average node clustering is maximized at temperature $T = 0$, and nearly linearly decreases to zero with $T \\in [0, 1)$.\n\n\n\\emph{iv. $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation.} Finally, we map the node hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ in layers 1, 2, to radial coordinates $r_{1,i}, r_{2,i}$ using the relations below,\n\\begin{eqnarray}\n\\label{kappa_i_1}\nr_{1,i} &=& R_1 - 2 \\ln \\frac{\\kappa_{1,i}}{\\kappa_{1}^{\\text{min}}},~R_1= 2\\ln{\\frac{N}{c_1}},\\\\\n\\nonumber c_1&=&\\bar{k}_1\\frac{\\sin{T_1\\pi}}{2T_1}\\left(\\frac{\\gamma_1-2}{\\gamma_1-1}\\right)^2,\\\\\n\\label{kappa_i_2}\nr_{2,i} &=& R_2 - 2 \\ln \\frac{\\kappa_{2,i}}{\\kappa_{2}^{\\text{min}}},~R_2= 2\\ln{\\frac{N}{c_2}},\\\\\n\\nonumber c_2&=&\\bar{k}_2\\frac{\\sin{T_2\\pi}}{2T_2}\\left(\\frac{\\gamma_2-2}{\\gamma_2-1}\\right)^2,\n\\end{eqnarray}\nwhere $\\kappa_{1}^{\\text{min}}, \\kappa_{2}^{\\text{min}}$ are given in Eqs.~(\\ref{kappa_0_1}), (\\ref{kappa_0_2}).\n\n\n\\subsection{Modeling more than two layers}\n\\label{multilayer_extension}\n\nTo construct a multilayer system consisting of $n$ layers (layer 1, layer 2, $\\ldots$, layer $n$), we work in the same way as with the two-layer system described above. Specifically, for each two consecutive layers $j-1, j$, for $2 \\leq j \\leq n$, we first fix their radial and angular correlation strength  parameters $\\nu_{j, j-1} \\in [0,1]$, $g_{j, j-1} \\in [0,1]$\nto some desired values. Subsequently, we assign hidden variables $\\kappa_{1,i}, \\theta_{1,i}$ to nodes in layer 1 as described earlier (Eqs.~(\\ref{eqn_rho_kappa_1}), (\\ref{eqn_uniform_theta})), as well as hidden variables $\\kappa_{2,i}, \\theta_{2,i}$ to nodes in layer 2, conditioned on $\\kappa_{1,i}, \\theta_{1,i}$ (Eqs.~(\\ref{draw_kappa_paper_1}), (\\ref{eqn_assign_theta})). Then, we continue by assigning hidden variables $\\kappa_{j,i}, \\theta_{j,i}$ to nodes in layer $3 \\leq j \\leq n$, conditioned on the values of the hidden variables $\\kappa_{j-1,i}, \\theta_{j-1,i}$ of the nodes in layer $j-1$. This conditional assignment is done in exactly the same manner as the assignment of $\\kappa_{2,i}, \\theta_{2,i}$, which is conditioned on the values of $\\kappa_{1,i}, \\theta_{1,i}$. Once all node hidden variables in all layers are assigned, we create edges in each layer by connecting each node pair with the corresponding $\\mathbb{S}^{1}$ connection probability (cf. Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2})). Finally, for each layer $1 \\leq j \\leq n$, we map the node hidden variables $\\kappa_{j,i}$ to radial coordinates $r_{j,i}$ as described earlier (cf. Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2})). We have used this procedure to construct our three- and four-layer multiplexes in the main text and in Appendix~\\ref{appendix_navigation}, where the correlation strengths between subsequent layers are set to the same value, $\\nu_{j, j-1} =\\nu \\in [0,1]$, $g_{j, j-1}=g \\in [0,1]$,~$\\forall j \\geq 2$.\n\n\n\\subsection{Extension to multiplexes with different layer sizes}\n\\label{appendix_different_size_model}\n\nHere, we extend our framework to multiplexes with different layer sizes. Specifically, we consider a two-layer multiplex with layers 1, 2, which have number of nodes $N_1, N_2$. We assume that $N_1 > N_2$ and that there is a subset of $N_{\\textnormal{common}}$ nodes in layer 1 that also exist in layer 2, $N_{\\textnormal{common}} \\leq N_2$. To construct the two-layer multiplex we follow the steps below.\n\n\\emph{(i) Assignment of hidden variables in layer 1.} For each node  $i=1,2,\\ldots,N_1$ in layer 1, we sample  its hidden variable $\\kappa_{1,i}$ as before, i.e., from the PDF $\\rho_1(\\kappa_1)$ in Eq.~(\\ref{eqn_rho_kappa_1}), and its angular coordinate $\\theta_{1,i}$ from the uniform PDF$f(\\theta)$ in Eq.~(\\ref{eqn_uniform_theta}).\n\n\\emph{(ii) Determining the common nodes.} We now need to decide the $N_{\\textnormal{common}}$  nodes from layer 1 that will also be present in layer 2. The simplest approach is to randomly select (approximately) $N_{\\textnormal{common}}$ nodes from layer~1, by sampling each node from layer~1 with the same probability $\\psi$,\n\n", "index": 27, "text": "\\begin{equation}\n\\psi=\\frac{N_{\\textnormal{common}}}{N_1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\psi=\\frac{N_{\\textnormal{common}}}{N_{1}},\" display=\"block\"><mrow><mrow><mi>\u03c8</mi><mo>=</mo><mfrac><msub><mi>N</mi><mtext>common</mtext></msub><msub><mi>N</mi><mn>1</mn></msub></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nA dependence of the probability that a node exists in different layers on the degree of the node has also been observed in several other real multiplexes~\\cite{pre:multiplex:correlations}. Therefore, a more realistic and general approach is to sample each node from layer~1 with a probability $\\psi(\\kappa_1)$ that is a function of its expected degree $\\kappa_{1,i}$, such that \n\n", "itemtype": "equation", "pos": 78238, "prevtext": " \nand declaring each sampled node as a common node that will also exist in layer~2. However, this random sampling approach may not be realistic. Indeed, as we have mentioned in the main text, nodes with a higher degree in the IPv4 Internet (larger layer) have a higher probability to also exist in the IPv6 Internet (smaller layer). Fig.~\\ref{fig_estimate_psi} shows the empirical probability for a node (AS) to exist in the IPv6 Internet given its degree in the IPv4 Internet. \n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{sfig5.pdf}\n\\caption{\\textbf{Probability that a node (AS) exists in the IPv6 Internet given its degree in the IPv4 Internet.} \n\\label{fig_estimate_psi}}\n\\end{figure}\nThis probability can be approximated by\n\n", "index": 29, "text": "\\begin{equation}\n\\psi(\\kappa_1) = \\frac{1}{1+15.4 \\kappa_1^{-1.05}}.\n\\label{eqn_psi_fit}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\psi(\\kappa_{1})=\\frac{1}{1+15.4\\kappa_{1}^{-1.05}}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mrow><mn>15.4</mn><mo>\u2062</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mrow><mo>-</mo><mn>1.05</mn></mrow></msubsup></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": " \nwhere $\\kappa_{1}^{\\text{min}}$ is given in Eq.~(\\ref{kappa_0_1}). In the main text, we used the $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}) to sample nodes from layer~1 that also exist in layer~2 of the synthetic multiplex that best mimics the real IPv4/IPv6 Internet (Fig.~\\ref{fig_psi_fitted_graphs}). The sampling yielded $N_{\\textnormal{common}}\\approx 4800$, which is approximately equal to the number of common ASs (4819) in the real IPv4/IPv6 Internet.\n\n\\emph{iii. Assignment of hidden variables in layer 2.} For the nodes $i$ in layer~2 that do not exist in layer~1 (non-common nodes), we sample their $\\kappa_{2,i}$'s from the unconditional PDF $\\rho_2(\\kappa_2)$ in Eq.~(\\ref{eqn_rho_kappa_2}), and their $\\theta_{2,i}$'s from the uniform PDF $f(\\theta)$ in Eq.~(\\ref{eqn_uniform_theta}). For the common nodes, we assign hidden variables $\\kappa_{2,i}, \\theta_{2,i}$, as described below. \n \nWe first compute the PDF $\\tilde{\\rho}_1(\\kappa_1)$ of the hidden variables $\\kappa_1$ of the common nodes,\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nA dependence of the probability that a node exists in different layers on the degree of the node has also been observed in several other real multiplexes~\\cite{pre:multiplex:correlations}. Therefore, a more realistic and general approach is to sample each node from layer~1 with a probability $\\psi(\\kappa_1)$ that is a function of its expected degree $\\kappa_{1,i}$, such that \n\n", "index": 31, "text": "\\begin{equation}\n\\int_{\\kappa_{1}^{\\text{min}}}^{\\infty}\\mathrm{d}\\kappa_1\\psi(\\kappa_1)\\rho_1(\\kappa_1)=\\frac{N_{\\textnormal{common}}}{N_1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\int_{\\kappa_{1}^{\\text{min}}}^{\\infty}\\mathrm{d}\\kappa_{1}\\psi(\\kappa_{1})%&#10;\\rho_{1}(\\kappa_{1})=\\frac{N_{\\textnormal{common}}}{N_{1}},\" display=\"block\"><mrow><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mi mathvariant=\"normal\">\u221e</mi></msubsup><mrow><mrow><mo>d</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mfrac><msub><mi>N</mi><mtext>common</mtext></msub><msub><mi>N</mi><mn>1</mn></msub></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nand the CDF $\\tilde{F}_1(\\kappa_1)$,\n\n", "itemtype": "equation", "pos": 79889, "prevtext": " \nwhere $\\kappa_{1}^{\\text{min}}$ is given in Eq.~(\\ref{kappa_0_1}). In the main text, we used the $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}) to sample nodes from layer~1 that also exist in layer~2 of the synthetic multiplex that best mimics the real IPv4/IPv6 Internet (Fig.~\\ref{fig_psi_fitted_graphs}). The sampling yielded $N_{\\textnormal{common}}\\approx 4800$, which is approximately equal to the number of common ASs (4819) in the real IPv4/IPv6 Internet.\n\n\\emph{iii. Assignment of hidden variables in layer 2.} For the nodes $i$ in layer~2 that do not exist in layer~1 (non-common nodes), we sample their $\\kappa_{2,i}$'s from the unconditional PDF $\\rho_2(\\kappa_2)$ in Eq.~(\\ref{eqn_rho_kappa_2}), and their $\\theta_{2,i}$'s from the uniform PDF $f(\\theta)$ in Eq.~(\\ref{eqn_uniform_theta}). For the common nodes, we assign hidden variables $\\kappa_{2,i}, \\theta_{2,i}$, as described below. \n \nWe first compute the PDF $\\tilde{\\rho}_1(\\kappa_1)$ of the hidden variables $\\kappa_1$ of the common nodes,\n\n", "index": 33, "text": "\\begin{equation}\n\\tilde{\\rho}_1(\\kappa_1) =\\frac{ \\psi(\\kappa_1) \\rho_1(\\kappa_1)}{\\int_{\\kappa_{1}^{\\text{min}}}^{\\infty}\\mathrm{d}\\kappa_1\\psi(\\kappa_1)\\rho_1(\\kappa_1)},\n\\label{eqn_rho_tilde}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\tilde{\\rho}_{1}(\\kappa_{1})=\\frac{\\psi(\\kappa_{1})\\rho_{1}(\\kappa_{1})}{\\int_%&#10;{\\kappa_{1}^{\\text{min}}}^{\\infty}\\mathrm{d}\\kappa_{1}\\psi(\\kappa_{1})\\rho_{1}%&#10;(\\kappa_{1})},\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>\u03c1</mi><mo stretchy=\"false\">~</mo></mover><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mi mathvariant=\"normal\">\u221e</mi></msubsup><mrow><mrow><mo>d</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nThen, we compute the conditional CDF $F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ in exactly the same manner as in Appendix~\\ref{two_layer_model}, with the only difference that in place of $F_1(\\kappa_1)$ in Eq.~(\\ref{cdf_1}), we use the $\\tilde{F}_1(\\kappa_1)$ that we compute in Eq.~(\\ref{cdf_1_tilde}), and instead of $\\rho_1(\\kappa_1)$ we use $\\tilde{\\rho}_1(\\kappa_1)$. That is,\n\n", "itemtype": "equation", "pos": 80136, "prevtext": "\nand the CDF $\\tilde{F}_1(\\kappa_1)$,\n\n", "index": 35, "text": "\\begin{equation}\n\\label{cdf_1_tilde}\n\\tilde{F}_1(\\kappa_1)=\\int_{\\kappa_{1}^{\\text{min}}}^{\\kappa_1} \\mathrm{d} \\kappa' \\tilde{\\rho}_1(\\kappa').\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\tilde{F}_{1}(\\kappa_{1})=\\int_{\\kappa_{1}^{\\text{min}}}^{\\kappa_{1}}\\mathrm{d%&#10;}\\kappa^{\\prime}\\tilde{\\rho}_{1}(\\kappa^{\\prime}).\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>F</mi><mo stretchy=\"false\">~</mo></mover><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><msub><mi>\u03ba</mi><mn>1</mn></msub></msubsup><mrow><mrow><mo>d</mo><msup><mi>\u03ba</mi><mo>\u2032</mo></msup></mrow><mo>\u2062</mo><msub><mover accent=\"true\"><mi>\u03c1</mi><mo stretchy=\"false\">~</mo></mover><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03ba</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere $C_\\eta(u,v)$ is the Gumbel-Hougaard copula (Eq.~(\\ref{c_h_copula})) and $F_2(\\kappa_2)$ is given in Eq.~(\\ref{cdf_2}). The hidden variable $\\kappa_{2,i}$ of each common node $i$ is then sampled from the conditional CDF in Eq.~(\\ref{eqn_pc_full}). The angular coordinate of each common node $\\theta_{2,i}$ is assigned using Eqs.~(\\ref{eqn_assign_theta}), (\\ref{eqn_trunc_gauss}) with $N=N_2$.\n \n\\emph{iv. Creation of edges.} The creation of edges in each layer is performed as before using the connection probabilities of the two layers in Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}), with the only difference that now $d_1(\\theta_{1,i}, \\theta_{1,j})=\\frac{N_1}{2\\pi} \\Delta \\theta_{ij}^1$ and $d_2(\\theta_{2,i}, \\theta_{2,j})=\\frac{N_2}{2\\pi} \\Delta \\theta_{ij}^2$.\n\n\\emph{v. $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation.} Finally, we again map the node hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ in layers 1, 2, to radial coordinates $r_i^1, r_i^2$ using Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2}), with the difference that now in these equations we have $R_1= 2\\ln{\\frac{N_1}{c_1}}$ and $R_2= 2\\ln{\\frac{N_2}{c_2}}$.\n\nThe above framework can be extended to more than two layers in the same manner as described in Appendix~\\ref{multilayer_extension}. \nWe note that when $\\psi(\\kappa_1)$ is the Internet's $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}), the conditional CDF in Eq.~(\\ref{eqn_pc_full}) can be approximated by\n\n", "itemtype": "equation", "pos": 80751, "prevtext": "\nThen, we compute the conditional CDF $F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})$ in exactly the same manner as in Appendix~\\ref{two_layer_model}, with the only difference that in place of $F_1(\\kappa_1)$ in Eq.~(\\ref{cdf_1}), we use the $\\tilde{F}_1(\\kappa_1)$ that we compute in Eq.~(\\ref{cdf_1_tilde}), and instead of $\\rho_1(\\kappa_1)$ we use $\\tilde{\\rho}_1(\\kappa_1)$. That is,\n\n", "index": 37, "text": "\\begin{multline}\nF_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})  = \\\\ \\frac{\\partial C_{\\eta}( \\tilde{F}_1(\\kappa_1), F_2(\\kappa_2))}{\\partial {\\kappa_{1}}} \\frac{1}{ \\tilde{\\rho}_1(\\kappa_1)},\n\\label{eqn_pc_full}\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle F_{\\eta}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_{1}},{\\gamma_{2}},{%&#10;\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\})=\\\\&#10;\\displaystyle\\frac{\\partial C_{\\eta}(\\tilde{F}_{1}(\\kappa_{1}),F_{2}(\\kappa_{2%&#10;}))}{\\partial{\\kappa_{1}}}\\frac{1}{\\tilde{\\rho}_{1}(\\kappa_{1})},\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>F</mi><mi>\u03b7</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>1</mn><mtext>min</mtext></msubsup><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>C</mi><mi>\u03b7</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mover accent=\"true\"><mi>F</mi><mo stretchy=\"false\">~</mo></mover><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>F</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow></mfrac><mo>\u2062</mo><mfrac><mn>1</mn><mrow><msub><mover accent=\"true\"><mi>\u03c1</mi><mo stretchy=\"false\">~</mo></mover><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\nwhere\n\n", "itemtype": "equation", "pos": 82481, "prevtext": "\nwhere $C_\\eta(u,v)$ is the Gumbel-Hougaard copula (Eq.~(\\ref{c_h_copula})) and $F_2(\\kappa_2)$ is given in Eq.~(\\ref{cdf_2}). The hidden variable $\\kappa_{2,i}$ of each common node $i$ is then sampled from the conditional CDF in Eq.~(\\ref{eqn_pc_full}). The angular coordinate of each common node $\\theta_{2,i}$ is assigned using Eqs.~(\\ref{eqn_assign_theta}), (\\ref{eqn_trunc_gauss}) with $N=N_2$.\n \n\\emph{iv. Creation of edges.} The creation of edges in each layer is performed as before using the connection probabilities of the two layers in Eqs.~(\\ref{c_prob_1}), (\\ref{c_prob_2}), with the only difference that now $d_1(\\theta_{1,i}, \\theta_{1,j})=\\frac{N_1}{2\\pi} \\Delta \\theta_{ij}^1$ and $d_2(\\theta_{2,i}, \\theta_{2,j})=\\frac{N_2}{2\\pi} \\Delta \\theta_{ij}^2$.\n\n\\emph{v. $\\mathbb{S}^{1}$-to-$\\mathbb{H}^{2}$ transformation.} Finally, we again map the node hidden variables $\\kappa_{1,i}, \\kappa_{2,i}$ in layers 1, 2, to radial coordinates $r_i^1, r_i^2$ using Eqs.~(\\ref{kappa_i_1}), (\\ref{kappa_i_2}), with the difference that now in these equations we have $R_1= 2\\ln{\\frac{N_1}{c_1}}$ and $R_2= 2\\ln{\\frac{N_2}{c_2}}$.\n\nThe above framework can be extended to more than two layers in the same manner as described in Appendix~\\ref{multilayer_extension}. \nWe note that when $\\psi(\\kappa_1)$ is the Internet's $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}), the conditional CDF in Eq.~(\\ref{eqn_pc_full}) can be approximated by\n\n", "index": 39, "text": "\\begin{multline}\n\\label{draw_kappa_paper_2}\nF_{\\nu}({\\kappa_{2}}|\\tilde{\\kappa},\\{{\\gamma_2},{\\kappa_{2}^{\\text{min}}}\\}) = \ne^{-(\\tilde{\\varphi}^{1 / (1-\\nu)}+\\varphi_2^{1 / (1-\\nu)})^{1-\\nu}} \\\\ \n\\times \\left[ \\tilde{\\varphi}^{1 / (1-\\nu)} + \\varphi_2^{1 / (1-\\nu)} \\right]^{-\\nu} \n\\frac{\\tilde{\\varphi}^{\\nu/(1-\\nu)} {\\kappa_{2}^{\\text{min}}} \\tilde{\\kappa}^{{\\gamma_2}}}{{\\kappa_{2}^{\\text{min}}} \\tilde{\\kappa}^{{\\gamma_2}}-\\kappa_2^{\\text{min}^{{\\gamma_2}}} \\tilde{\\kappa}},\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle F_{\\nu}({\\kappa_{2}}|\\tilde{\\kappa},\\{{\\gamma_{2}},{\\kappa_{2}^{%&#10;\\text{min}}}\\})=e^{-(\\tilde{\\varphi}^{1/(1-\\nu)}+\\varphi_{2}^{1/(1-\\nu)})^{1-%&#10;\\nu}}\\\\&#10;\\displaystyle\\times\\left[\\tilde{\\varphi}^{1/(1-\\nu)}+\\varphi_{2}^{1/(1-\\nu)}%&#10;\\right]^{-\\nu}\\frac{\\tilde{\\varphi}^{\\nu/(1-\\nu)}{\\kappa_{2}^{\\text{min}}}%&#10;\\tilde{\\kappa}^{{\\gamma_{2}}}}{{\\kappa_{2}^{\\text{min}}}\\tilde{\\kappa}^{{%&#10;\\gamma_{2}}}-\\kappa_{2}^{\\text{min}^{{\\gamma_{2}}}}\\tilde{\\kappa}},\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>F</mi><mi>\u03bd</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03ba</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msup><mi>e</mi><mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mover accent=\"true\"><mi>\u03c6</mi><mo stretchy=\"false\">~</mo></mover><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>+</mo><msubsup><mi>\u03c6</mi><mn>2</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow></msup></mrow></msup></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo>\u00d7</mo><mrow><msup><mrow><mo>[</mo><mrow><msup><mover accent=\"true\"><mi>\u03c6</mi><mo stretchy=\"false\">~</mo></mover><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>+</mo><msubsup><mi>\u03c6</mi><mn>2</mn><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup></mrow><mo>]</mo></mrow><mrow><mo>-</mo><mi>\u03bd</mi></mrow></msup><mo>\u2062</mo><mfrac><mrow><msup><mover accent=\"true\"><mi>\u03c6</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>\u03bd</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bd</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover><msub><mi>\u03b3</mi><mn>2</mn></msub></msup></mrow><mrow><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover><msub><mi>\u03b3</mi><mn>2</mn></msub></msup></mrow><mo>-</mo><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><msup><mtext>min</mtext><msub><mi>\u03b3</mi><mn>2</mn></msub></msup></msubsup><mo>\u2062</mo><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover></mrow></mrow></mfrac></mrow></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": " \nand ${\\kappa_{2}^{\\text{min}}}$ is given in Eq.~(\\ref{kappa_0_2}).\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{sfig6.pdf}\n\\caption{\\textbf{$\\kappa_2$ as a function of $\\kappa_1$ at the limit $\\nu \\rightarrow 1$.} The triangles denote the values of $\\kappa_2$ by numerically evaluating Eq.~\\eqref{eqn_pc_full} using the $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}) and the IPv4/IPv6 Internet parameters $\\gamma_1=\\gamma_2=2.1, {\\kappa_{1}^{\\text{min}}}=0.84, {\\kappa_{2}^{\\text{min}}}=1.30$. The best-fit line corresponds to $\\kappa_2=1.11 + 0.22 \\kappa_1$.\n\\label{fig_full_fit}}\n\\end{figure}\n\nEq.~\\eqref{map_full_approx} is obtained by considering the maximally correlated case $\\nu \\to 1$, where Eq.~(\\ref{eqn_pc_full}) converges to a Heaviside step function $F_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\Theta\\left[\\kappa_2 - \\tilde{\\kappa}\\right]$. That is, for $\\nu \\to 1$, $\\kappa_2 \\approx 1.11 + 0.22\\kappa_1 \\equiv \\tilde{\\kappa}$. This relation is the analogue of Eq.~\\eqref{kappa_i_2_limit_relation}, and is obtained by numerically evaluating Eq.~(\\ref{eqn_pc_full}) at $\\nu \\to 1$, see Fig.~\\ref{fig_full_fit}. Once this result is known, then for $\\nu \\neq 1$, we can approximate Eq.~\\eqref{eqn_pc_full} with Eq.~\\eqref{draw_kappa_paper_2}, which results from Eq.~(\\ref{draw_kappa_paper_1}) if in place of $\\kappa_1, \\gamma_1, {\\kappa_{1}^{\\text{min}}}$, we use $\\tilde{\\kappa}, \\gamma_2, \\kappa_{2}^{\\text{min}}$. The idea behind this approximation is that instead of directly correlating the $\\kappa_{2,i}$ with the $\\kappa_{1,i}$ via Eq.~(\\ref{eqn_pc_full}), we correlate them via Eq.~\\eqref{draw_kappa_paper_2} with the corresponding values of $\\kappa_{2,i}$ at the maximal correlations ($\\nu \\to 1$), which in our case are given by $\\kappa_{2,i}=1.11 + 0.22\\kappa_{1,i}$.  \n\nIn our synthetic Internet-like multiplex in the main text (Fig.~\\ref{fig_psi_fitted_graphs}), we sample the hidden variables $\\kappa_{2,i}$ of the common nodes in layer~2 from the conditional CDF in Eq.~(\\ref{draw_kappa_paper_2}). In Fig.~\\ref{fig_degree_dists_l1_l2}, we show the marginal PDFs of the $\\kappa_{2,i}$ of the common nodes at correlation strengths $\\nu=0$ (no correlations, where the $\\kappa_{2,i}$ are sampled from their marginal CDF), $\\nu=0.5$ (partial correlations, where the $\\kappa_{2,i}$ are sampled from the conditional CDF in Eq.~(\\ref{draw_kappa_paper_2})), and $\\nu=1$ (full correlations, where the $\\kappa_{2,i}$ are directly obtained by Eq.~\\eqref{map_full_approx}). \nIn all cases, the marginal PDFs are nearly identical, validating the approximation described above. \n\\begin{figure}[t]\n\\includegraphics[width=0.9\\linewidth]{sfig7.pdf}\n\\caption{\\textbf{Degree distribution (PDF) in layer~2 of our synthetic Internet-like multiplex  (Fig.~\\ref{fig_psi_fitted_graphs} in the main text) at correlation strengths $\\nu=0, 0.5, 1$.}\n\\label{fig_degree_dists_l1_l2}}\n\\end{figure}\n\n\n\\section{Geometric correlations lead to significant edge overlap}\n\\label{appendix_model_overlap}\n\nThe radial and angular correlations across different layers naturally give rise to a significant amount of edge overlap between the layers, as observed in many real multiplexes~\\cite{Thurner:multi,Halu}. The edge overlap $O$ between two layers (layer 1, layer 2) is formally defined as the ratio of the number of overlapping (i.e., common) edges between the layers, to the maximum possible number of common edges~\\cite{battiston:multiplex:measures,elisa:overlap},\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere\n\n", "index": 41, "text": "\\begin{align}\n\\nonumber \\tilde{\\varphi} &= -\\ln \\left[1-\\left({\\kappa_{2}^{\\text{min}}}/\\tilde{\\kappa}\\right)^{{\\gamma_2}-1}\\right],\\\\ \n\\nonumber \\varphi_2 &= -\\ln \\left[1-\\left(\\kappa_{2}^{\\text{min}}/\\kappa_2\\right)^{{\\gamma_2}-1}\\right],\\\\\n\\tilde{\\kappa} & = 1.11 + 0.22 \\kappa_1,  \\label{map_full_approx}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tilde{\\varphi}\" display=\"inline\"><mover accent=\"true\"><mi>\u03c6</mi><mo stretchy=\"false\">~</mo></mover></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\ln\\left[1-\\left({\\kappa_{2}^{\\text{min}}}/\\tilde{\\kappa}\\right%&#10;)^{{\\gamma_{2}}-1}\\right],\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mo>-</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><msup><mrow><mo>(</mo><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>/</mo><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover></mrow><mo>)</mo></mrow><mrow><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\varphi_{2}\" display=\"inline\"><msub><mi>\u03c6</mi><mn>2</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\ln\\left[1-\\left(\\kappa_{2}^{\\text{min}}/\\kappa_{2}\\right)^{{%&#10;\\gamma_{2}}-1}\\right],\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mo>-</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><msup><mrow><mo>(</mo><mrow><msubsup><mi>\u03ba</mi><mn>2</mn><mtext>min</mtext></msubsup><mo>/</mo><msub><mi>\u03ba</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow><mrow><msub><mi>\u03b3</mi><mn>2</mn></msub><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\tilde{\\kappa}\" display=\"inline\"><mover accent=\"true\"><mi>\u03ba</mi><mo stretchy=\"false\">~</mo></mover></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1.11+0.22\\kappa_{1},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mn>1.11</mn><mo>+</mo><mrow><mn>0.22</mn><mo>\u2062</mo><msub><mi>\u03ba</mi><mn>1</mn></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04071.tex", "nexttext": "\n\\begin{figure}[t]\n\\includegraphics[width=1\\linewidth]{sfig8.pdf}\n\\caption{\\textbf{Edge overlap $O$ in a two-layer synthetic multiplex as a function of the radial ($\\nu$) and angular ($g$) correlation strengths.} Each layer has $N = 30000$ nodes, power law degree distribution $P(k) \\sim k^{-2.5}, \\bar{k} = 10$, and temperature $T = 0.4$.\n\\label{fig_overlap}} \n\\end{figure}\n\nFig.~\\ref{fig_overlap} shows the edge overlap in a synthetic two-layer multiplex as a function of the radial and angular correlation strength parameters $\\nu, g$. We observe that the overlap increases as we increase the correlation strengths $\\nu, g$, and it is maximized at fully correlated coordinates, $\\nu=1, g=1$. For uncorrelated coordinates, $\\nu=0, g=0$, the overlap is minimized---it can be shown that when  $\\nu=0, g=0$, the overlap vanishes in the thermodynamic limit ($N \\to \\infty$), i.e., as the layer sizes increase. \n\nThe edge overlap also depends on the temperature of the layers. For fixed values of $\\nu, g$, a higher overlap is achieved when the temperature of the layers is lower. Specifically, if two layers have the same parameters $N, \\gamma, \\bar{k}, T$, and $\\nu=g=1$, i.e., the node coordinates in the two layers are identical, then at $T=0$ the edge overlap is $100$\\%, i.e., the topologies of the two layers are identical. \n\n\n\\section{Performance of mutual navigation in two-, three- and four-layer synthetic multiplexes.}\n\\label{appendix_navigation}\n \nFigs.~\\ref{fig_appendix_routing_2}...\\ref{fig_4l_routing} show the success rate of angular mutual GR (Angular routing) and of mutual GR (Hyperbolic routing) in two-, three- and four-layer synthetic multiplexes as a function of the radial ($\\nu$) and angular ($g$) correlation strengths, and for different layer temperatures $T$. \n\nIn mutual GR with $n$ layers (layer 1, \\ldots, layer $n$), a node with a message first computes the distance between its neighbors and the destination of the message in layer 1, then it does the same for its neighbors and the destination in layer 2, and so on. The node then forwards the message to the neighbor that has the smallest distance to the destination across all computed distances. If a message is given back to a node it already visited, the delivery fails. The success rate is  the percentage of messages that reach their destinations. In Figs.~\\ref{fig_appendix_routing_2}...\\ref{fig_4l_routing} the success rate is evaluated across $10^5$ randomly selected source-destination pairs. In mutual GR, hyperbolic distances ($x_{ij}$) between nodes are used, while in angular mutual GR only angular distances ($\\Delta \\theta_{ij}$) are used (Eq.~(\\ref{eq:x_ji})).\n\n\\begin{figure*}[t]\n\\includegraphics[width=1\\linewidth]{sfig9.pdf}\n\\caption{\\textbf{Success rate of angular mutual GR (Angular routing, top row) and of mutual GR (Hyperbolic routing, bottom row) for a two-layer multiplex system as a function of the radial ($\\nu$) and angular ($g$) correlation strengths.} Each layer has $N=30000$ nodes, power law degree distribution $P(k) \\sim k^{-2.5}$, $\\bar{k}=10$, and temperature parameter $T$. From left to right, $T=0.1,0.4,0.8$.\n\\label{fig_appendix_routing_2}}\n\\end{figure*}\n\\begin{figure*}[t]\n\\includegraphics[width=1\\linewidth]{sfig10.pdf}\n\\caption{\\textbf{Success rate of angular mutual GR (Angular routing, top row) and of mutual GR (Hyperbolic routing, bottom row) for a three-layer multiplex system as a function of the radial ($\\nu$) and angular ($g$) correlation strengths.} Each layer has $N=30000$ nodes, power law degree distribution $P(k) \\sim k^{-2.5}$, $\\bar{k}=10$, and temperature parameter $T$. From left to right, $T=0.1,0.4,0.8$.\n\\label{fig_3l_routing}}\n\\end{figure*}\n\\begin{figure*}[t]\n\\includegraphics[width=1\\linewidth]{sfig11.pdf}\n\\caption{\\textbf{Success rate of angular mutual GR (Angular routing, top row) and of mutual GR (Hyperbolic routing, bottom row) for a four-layer multiplex system as a function of the radial ($\\nu$) and angular ($g$) correlation strengths.} Each layer has $N=30000$ nodes, power law degree distribution $P(k) \\sim k^{-2.5}$, $\\bar{k}=10$, and temperature parameter $T$. From left to right, $T=0.1,0.4,0.8$.\n\\label{fig_4l_routing}}\n\\end{figure*}\n\n\n\\section{Estimation of the radial and angular correlation strengths $\\nu_E, g_E$ in the IPv4/IPv6 Internet}\n\\label{appendix_estimate_nu_g}\n\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=1\\linewidth]{sfig12.pdf}\n\\caption{\\textbf{Estimation of $\\nu_E, g_E$ in the IPv4/IPv6 Internet.} \\textbf{A.} Pearson correlation coefficient between the inferred radial coordinates of common ASs in the IPv4/IPv6 Internet (straight dashed line), and in our synthetic Internet-like multiplex at various radial correlation strengths $\\nu$. The two coefficients are equal at $\\nu \\approx 0.4 \\equiv \\nu_E$. \\textbf{B.} Edge overlap $O$ between reconstructed IPv4 and IPv6 topologies with inferred radial and angular coordinates (straight dashed line), and with synthetic angular coordinates for the common nodes in IPv6, at various correlation strengths $g$ with their inferred IPv4 angles. The two overlaps are equal at $g \\approx 0.4 \\equiv g_E$.\n\\label{fig_estimate_nu_g}}\n\\end{figure}\n\nTo estimate the empirical $\\nu_E$, we first compute the Pearson correlation coefficient  between the inferred radial coordinates of common nodes (ASs) in the IPv4/IPv6 Internet. Then, we compute the same coefficient between the radial coordinates of common nodes in our synthetic Internet-like multiplex (Fig.~\\ref{fig_psi_fitted_graphs}B in the main text), at various radial correlation strengths $\\nu \\in [0,1]$. The value of $\\nu$ where the two coefficients are equal is the estimated value of $\\nu_E$. Fig.~\\ref{fig_estimate_nu_g}A shows the results, where we obtain $\\nu_E \\approx 0.4$.\n\nTo estimate $g_E$, we reconstruct IPv4-like and IPv6-like topologies as follows. We first consider all nodes in the real IPv4 topology with their inferred radial and angular coordinates, and connect each pair of nodes with the Fermi-Dirac connection probability $p(x_{ij})$ in Eq.~(\\ref{fermi_dirac}), using the estimated temperature of the IPv4 topology, $T_1=0.5$, and such that the resulting network has the same average degree and power law degree distribution exponent as the real IPv4 topology, $\\bar{k}_1 \\approx 5$, $\\gamma_1=2.1$. Subsequently, we consider all nodes in the real IPv6 topology. We assign to these nodes their inferred radial coordinates. For the nodes that also exist in IPv4, their angular coordinates are assigned using Eqs.~(\\ref{eqn_assign_theta}), (\\ref{eqn_trunc_gauss}), and are correlated to their real angular coordinates in IPv4, using different correlation strengths $g \\in [0,1]$. The angular coordinates of the non-common nodes are set equal to their inferred angular coordinates. Then, we connect each pair of nodes in IPv6 with the Fermi-Dirac connection probability $p(x_{ij})$ in Eq.~(\\ref{fermi_dirac}), using the estimated temperature of the IPv6 topology, $T_2=0.5$, and such that the resulting network has the same average degree and power law degree distribution exponent as the real IPv6 topology, $\\bar{k}_2 \\approx 5.2$, $\\gamma_2=2.1$. For the different values of $g$, we evaluate the edge overlap $O$ (Eq.~(\\ref{eqn_overlap})) between the reconstructed IPv4 and IPv6 topologies. The value of $g$ that matches the edge overlap obtained when we reconstruct the IPv6 topology with all nodes having their inferred angular coordinates, is the estimated value of $g_E$. Fig.~\\ref{fig_estimate_nu_g}B shows the results, where we obtain $g_E \\approx 0.4$. \n\n\n\n\n\n\n\n\n\n\n\\begin{thebibliography}{51}\n\\makeatletter\n\\providecommand \\@ifxundefined [1]{\n \\@ifx{#1\\undefined}\n}\n\\providecommand \\@ifnum [1]{\n \\ifnum #1\\expandafter \\@firstoftwo\n \\else \\expandafter \\@secondoftwo\n \\fi\n}\n\\providecommand \\@ifx [1]{\n \\ifx #1\\expandafter \\@firstoftwo\n \\else \\expandafter \\@secondoftwo\n \\fi\n}\n\\providecommand \\natexlab [1]{#1}\n\\providecommand \\enquote  [1]{``#1''}\n\\providecommand \\bibnamefont  [1]{#1}\n\\providecommand \\bibfnamefont [1]{#1}\n\\providecommand \\citenamefont [1]{#1}\n\\providecommand \\href@noop [0]{\\@secondoftwo}\n\\providecommand \\href [0]{\\begingroup \\@sanitize@url \\@href}\n\\providecommand \\@href[1]{\\@@startlink{#1}\\@@href}\n\\providecommand \\@@href[1]{\\endgroup#1\\@@endlink}\n\\providecommand \\@sanitize@url [0]{\\catcode `\\\\12\\catcode `\\$12\\catcode\n  `\\&12\\catcode `\\#12\\catcode `\\^12\\catcode `\\_12\\catcode `\\%12\\relax}\n\\providecommand \\@@startlink[1]{}\n\\providecommand \\@@endlink[0]{}\n\\providecommand \\url  [0]{\\begingroup\\@sanitize@url \\@url }\n\\providecommand \\@url [1]{\\endgroup\\@href {#1}{\\urlprefix }}\n\\providecommand \\urlprefix  [0]{URL }\n\\providecommand \\Eprint [0]{\\href }\n\\providecommand \\doibase [0]{http://dx.doi.org/}\n\\providecommand \\selectlanguage [0]{\\@gobble}\n\\providecommand \\bibinfo  [0]{\\@secondoftwo}\n\\providecommand \\bibfield  [0]{\\@secondoftwo}\n\\providecommand \\translation [1]{[#1]}\n\\providecommand \\BibitemOpen [0]{}\n\\providecommand \\bibitemStop [0]{}\n\\providecommand \\bibitemNoStop [0]{.\\EOS\\space}\n\\providecommand \\EOS [0]{\\spacefactor3000\\relax}\n\\providecommand \\BibitemShut  [1]{\\csname bibitem#1\\endcsname}\n\\let\\auto@bib@innerbib\\@empty\n\n\\bibitem [{\\citenamefont {Kivel\\\"{a}}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Kivel\\\"{a}}, \\citenamefont {Arenas}, \\citenamefont {Barthelemy},\n  \\citenamefont {Gleeson}, \\citenamefont {Moreno},\\ and\\ \\citenamefont\n  {Porter}}]{multilayer:kivel}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Mikko}\\ \\bibnamefont\n  {Kivel\\\"{a}}}, \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}}, \\bibinfo {author} {\\bibfnamefont {Marc}\\ \\bibnamefont\n  {Barthelemy}}, \\bibinfo {author} {\\bibfnamefont {James~P.}\\ \\bibnamefont\n  {Gleeson}}, \\bibinfo {author} {\\bibfnamefont {Yamir}\\ \\bibnamefont {Moreno}},\n  \\ and\\ \\bibinfo {author} {\\bibfnamefont {Mason~A.}\\ \\bibnamefont {Porter}},\\\n  }\\bibfield  {title} {\\enquote {\\bibinfo {title} {{Multilayer networks}},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Journal of Complex\n  Networks}\\ } (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Radicchi}\\ and\\ \\citenamefont\n  {Arenas}(2013)}]{arenas:radicchi:2013}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Filippo}\\ \\bibnamefont\n  {Radicchi}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {{Abrupt\n  transition in the structural formation of interconnected networks}},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Nature Physics}\\\n  }\\textbf {\\bibinfo {volume} {9}},\\ \\bibinfo {pages} {717--720} (\\bibinfo\n  {year} {2013})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Bianconi}(2014)}]{ginestra:natphys}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Ginestra}\\\n  \\bibnamefont {Bianconi}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Multilayer networks: Dangerous liaisons?}}\\ }\\href@noop {} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Nature Physics}\\ }\\textbf {\\bibinfo {volume}\n  {10}},\\ \\bibinfo {pages} {712--714} (\\bibinfo {year} {2014})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Radicchi}(2015)}]{radicci:percolation}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Filippo}\\ \\bibnamefont\n  {Radicchi}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Percolation in\n  real interdependent networks},}\\ }\\href@noop {} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Nature Physics}\\ }\\textbf {\\bibinfo {volume} {11}},\\\n  \\bibinfo {pages} {597\u00e2\u0080\u0093602} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {De~Domenico}\\ \\emph {et~al.}(2013)\\citenamefont\n  {De~Domenico}, \\citenamefont {Sol\\'e-Ribalta}, \\citenamefont {Cozzo},\n  \\citenamefont {Kivel\\\"a}, \\citenamefont {Moreno}, \\citenamefont {Porter},\n  \\citenamefont {G\\'omez},\\ and\\ \\citenamefont {Arenas}}]{arenas:multiplex}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Manlio}\\ \\bibnamefont\n  {De~Domenico}}, \\bibinfo {author} {\\bibfnamefont {Albert}\\ \\bibnamefont\n  {Sol\\'e-Ribalta}}, \\bibinfo {author} {\\bibfnamefont {Emanuele}\\ \\bibnamefont\n  {Cozzo}}, \\bibinfo {author} {\\bibfnamefont {Mikko}\\ \\bibnamefont {Kivel\\\"a}},\n  \\bibinfo {author} {\\bibfnamefont {Yamir}\\ \\bibnamefont {Moreno}}, \\bibinfo\n  {author} {\\bibfnamefont {Mason~A.}\\ \\bibnamefont {Porter}}, \\bibinfo {author}\n  {\\bibfnamefont {Sergio}\\ \\bibnamefont {G\\'omez}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {Alex}\\ \\bibnamefont {Arenas}},\\ }\\bibfield  {title} {\\enquote\n  {\\bibinfo {title} {Mathematical formulation of multilayer networks},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys Rev X}\\\n  }\\textbf {\\bibinfo {volume} {3}},\\ \\bibinfo {pages} {041022} (\\bibinfo {year}\n  {2013})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Szell}\\ \\emph {et~al.}(2010)\\citenamefont {Szell},\n  \\citenamefont {Lambiotte},\\ and\\ \\citenamefont {Thurner}}]{Thurner:multi}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Michael}\\ \\bibnamefont\n  {Szell}}, \\bibinfo {author} {\\bibfnamefont {Renaud}\\ \\bibnamefont\n  {Lambiotte}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Stefan}\\ \\bibnamefont\n  {Thurner}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Multirelational\n  organization of large-scale social networks in an online world},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Proceedings of the\n  National Academy of Sciences}\\ }\\textbf {\\bibinfo {volume} {107}},\\ \\bibinfo\n  {pages} {13636--13641} (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Menichetti}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Menichetti}, \\citenamefont {Remondini},\\ and\\ \\citenamefont\n  {Bianconi}}]{Menichetti}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Giulia}\\ \\bibnamefont\n  {Menichetti}}, \\bibinfo {author} {\\bibfnamefont {Daniel}\\ \\bibnamefont\n  {Remondini}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Ginestra}\\\n  \\bibnamefont {Bianconi}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Correlations between weights and overlap in ensembles of weighted multiplex\n  networks},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys.\n  Rev. E}\\ }\\textbf {\\bibinfo {volume} {90}},\\ \\bibinfo {pages} {062817}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Halu}\\ \\emph {et~al.}(2014)\\citenamefont {Halu},\n  \\citenamefont {Mukherjee},\\ and\\ \\citenamefont {Bianconi}}]{Halu}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Arda}\\ \\bibnamefont\n  {Halu}}, \\bibinfo {author} {\\bibfnamefont {Satyam}\\ \\bibnamefont\n  {Mukherjee}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Ginestra}\\\n  \\bibnamefont {Bianconi}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Emergence of overlap in ensembles of spatial multiplexes and statistical\n  mechanics of spatial interacting network ensembles}},}\\ }\\href@noop {}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Physical Review E}\\ }\\textbf\n  {\\bibinfo {volume} {89}} (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Kleineberg}\\ and\\ \\citenamefont\n  {Bogu\\~n\\'a}(2014)}]{our:model}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Kaj-Kolja}\\\n  \\bibnamefont {Kleineberg}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Mari\\'an}\\\n  \\bibnamefont {Bogu\\~n\\'a}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Evolution of the digital society reveals balance between viral and mass\n  media influence},}\\ }\\href {\\doibase 10.1103/PhysRevX.4.031046} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Phys Rev X}\\ }\\textbf {\\bibinfo {volume}\n  {4}},\\ \\bibinfo {pages} {031046} (\\bibinfo {year} {2014})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Kleineberg}\\ and\\ \\citenamefont\n  {Bogu\\~n\\'a}(2015)}]{ecology20}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Kaj-Kolja}\\\n  \\bibnamefont {Kleineberg}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Mari\\'an}\\\n  \\bibnamefont {Bogu\\~n\\'a}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Digital ecology: Coexistence and domination among interacting networks},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Sci. Rep.}\\\n  }\\textbf {\\bibinfo {volume} {5}},\\ \\bibinfo {pages} {10268} (\\bibinfo {year}\n  {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Kleineberg}\\ and\\ \\citenamefont\n  {{Boguna}}(2015)}]{worldmodel}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Kaj-Kolja}\\\n  \\bibnamefont {Kleineberg}}\\ and\\ \\bibinfo {author} {\\bibfnamefont\n  {M.}~\\bibnamefont {{Boguna}}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo\n  {title} {Is bigger always better? how local online social networks can\n  outperform global ones},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo\n  {journal} {ArXiv:1504.01368}\\ } (\\bibinfo {year} {2015})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {De~Domenico}\\ \\emph {et~al.}(2014)\\citenamefont\n  {De~Domenico}, \\citenamefont {Sol\u00c3\u00a9-Ribalta}, \\citenamefont {G\u00c3\u00b3mez},\\ and\\\n  \\citenamefont {Arenas}}]{DeDomenico2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Manlio}\\ \\bibnamefont\n  {De~Domenico}}, \\bibinfo {author} {\\bibfnamefont {Albert}\\ \\bibnamefont\n  {Sol\u00c3\u00a9-Ribalta}}, \\bibinfo {author} {\\bibfnamefont {Sergio}\\ \\bibnamefont\n  {G\u00c3\u00b3mez}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Navigability of\n  interconnected networks under random failures},}\\ }\\href@noop {} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Proceedings of the National Academy of\n  Sciences}\\ }\\textbf {\\bibinfo {volume} {111}},\\ \\bibinfo {pages} {8351--8356}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Simas}\\ \\emph {et~al.}(2015)\\citenamefont {Simas},\n  \\citenamefont {Chavez}, \\citenamefont {Rodriguez},\\ and\\ \\citenamefont\n  {Diaz-Guilera}}]{Simas2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Tiago}\\ \\bibnamefont\n  {Simas}}, \\bibinfo {author} {\\bibfnamefont {Mario}\\ \\bibnamefont {Chavez}},\n  \\bibinfo {author} {\\bibfnamefont {Pablo~R.}\\ \\bibnamefont {Rodriguez}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {Albert}\\ \\bibnamefont\n  {Diaz-Guilera}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {An\n  algebraic topological method for multimodal brain networks comparison},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Frontiers in\n  Psychology}\\ }\\textbf {\\bibinfo {volume} {6}},\\ \\bibinfo {pages} {904}\n  (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Boccaletti}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Boccaletti}, \\citenamefont {Bianconi}, \\citenamefont {Criado}, \\citenamefont\n  {del Genio}, \\citenamefont {G\u00c3\u00b3mez-Garde\u00c3\u00b1es}, \\citenamefont {Romance},\n  \\citenamefont {Sendi\u00c3\u00b1a-Nadal}, \\citenamefont {Wang},\\ and\\ \\citenamefont\n  {Zanin}}]{Boccaletti20141}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {S.}~\\bibnamefont\n  {Boccaletti}}, \\bibinfo {author} {\\bibfnamefont {G.}~\\bibnamefont\n  {Bianconi}}, \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont {Criado}},\n  \\bibinfo {author} {\\bibfnamefont {C.I.}\\ \\bibnamefont {del Genio}}, \\bibinfo\n  {author} {\\bibfnamefont {J.}~\\bibnamefont {G\u00c3\u00b3mez-Garde\u00c3\u00b1es}}, \\bibinfo\n  {author} {\\bibfnamefont {M.}~\\bibnamefont {Romance}}, \\bibinfo {author}\n  {\\bibfnamefont {I.}~\\bibnamefont {Sendi\u00c3\u00b1a-Nadal}}, \\bibinfo {author}\n  {\\bibfnamefont {Z.}~\\bibnamefont {Wang}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {M.}~\\bibnamefont {Zanin}},\\ }\\bibfield  {title} {\\enquote\n  {\\bibinfo {title} {The structure and dynamics of multilayer networks},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Physics Reports}\\\n  }\\textbf {\\bibinfo {volume} {544}},\\ \\bibinfo {pages} {1 -- 122} (\\bibinfo\n  {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Krioukov}\\ \\emph {et~al.}(2010)\\citenamefont\n  {Krioukov}, \\citenamefont {Papadopoulos}, \\citenamefont {Kitsak},\n  \\citenamefont {Vahdat},\\ and\\ \\citenamefont {Bogu\\~{n}\\'{a}}}]{Krioukov2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Dmitri}\\ \\bibnamefont\n  {Krioukov}}, \\bibinfo {author} {\\bibfnamefont {Fragkiskos}\\ \\bibnamefont\n  {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {Maksim}\\ \\bibnamefont\n  {Kitsak}}, \\bibinfo {author} {\\bibfnamefont {Amin}\\ \\bibnamefont {Vahdat}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {Mari\\'{a}n}\\ \\bibnamefont\n  {Bogu\\~{n}\\'{a}}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Hyperbolic geometry of complex networks}},}\\ }\\href {\\doibase\n  10.1103/PhysRevE.82.036106} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physical Review E}\\ }\\textbf {\\bibinfo {volume} {82}},\\ \\bibinfo {pages}\n  {036106} (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Bogu\\~{n}\\'{a}}\\ \\emph {et~al.}(2010)\\citenamefont\n  {Bogu\\~{n}\\'{a}}, \\citenamefont {Papadopoulos},\\ and\\ \\citenamefont\n  {Krioukov}}]{Boguna2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Mari\\'{a}n}\\\n  \\bibnamefont {Bogu\\~{n}\\'{a}}}, \\bibinfo {author} {\\bibfnamefont\n  {Fragkiskos}\\ \\bibnamefont {Papadopoulos}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {Dmitri}\\ \\bibnamefont {Krioukov}},\\ }\\bibfield  {title}\n  {\\enquote {\\bibinfo {title} {{Sustaining the Internet with hyperbolic\n  mapping.}}}\\ }\\href {\\doibase 10.1038/ncomms1063} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Nature communications}\\ }\\textbf {\\bibinfo {volume}\n  {1}},\\ \\bibinfo {pages} {62} (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Papadopoulos}\\ \\emph\n  {et~al.}(2015{\\natexlab{a}})\\citenamefont {Papadopoulos}, \\citenamefont\n  {Psomas},\\ and\\ \\citenamefont {Krioukov}}]{frag:hypermap}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {C.}~\\bibnamefont\n  {Psomas}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {D.}~\\bibnamefont\n  {Krioukov}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Network\n  mapping by replaying hyperbolic growth},}\\ }\\href {\\doibase\n  10.1109/TNET.2013.2294052} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Networking, IEEE/ACM Transactions on}\\ }\\textbf {\\bibinfo {volume} {23}},\\\n  \\bibinfo {pages} {198--211} (\\bibinfo {year}\n  {2015}{\\natexlab{a}})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Papadopoulos}\\ \\emph\n  {et~al.}(2015{\\natexlab{b}})\\citenamefont {Papadopoulos}, \\citenamefont\n  {Aldecoa},\\ and\\ \\citenamefont {Krioukov}}]{frag:hypermap_cn}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Fragkiskos}\\\n  \\bibnamefont {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {Rodrigo}\\\n  \\bibnamefont {Aldecoa}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Dmitri}\\\n  \\bibnamefont {Krioukov}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Network geometry inference using common neighbors},}\\ }\\href {\\doibase\n  10.1103/PhysRevE.92.022807} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys.\n  Rev. E}\\ }\\textbf {\\bibinfo {volume} {92}},\\ \\bibinfo {pages} {022807}\n  (\\bibinfo {year} {2015}{\\natexlab{b}})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Serrano}\\ \\emph {et~al.}(2008)\\citenamefont\n  {Serrano}, \\citenamefont {Krioukov},\\ and\\ \\citenamefont\n  {Bogu{\\~{n}}{\\'{a}}}}]{Serrano2008}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Serrano}}, \\bibinfo {author} {\\bibfnamefont {Dmitri}\\ \\bibnamefont\n  {Krioukov}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Mari{\\'{a}}n}\\\n  \\bibnamefont {Bogu{\\~{n}}{\\'{a}}}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo\n  {title} {{Self-Similarity of Complex Networks and Hidden Metric Spaces}},}\\\n  }\\href {\\doibase 10.1103/PhysRevLett.100.078701} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Physical Review Letters}\\ }\\textbf {\\bibinfo {volume}\n  {100}},\\ \\bibinfo {pages} {078701} (\\bibinfo {year} {2008})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Papadopoulos}\\ \\emph {et~al.}(2012)\\citenamefont\n  {Papadopoulos}, \\citenamefont {Kitsak}, \\citenamefont {Serrano},\n  \\citenamefont {Bogu{\\~n}{\\'a}},\\ and\\ \\citenamefont\n  {Krioukov}}]{boguna:popularity}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Kitsak}}, \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Serrano}},\n  \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Bogu{\\~n}{\\'a}}}, \\ and\\\n  \\bibinfo {author} {\\bibfnamefont {D.}~\\bibnamefont {Krioukov}},\\ }\\bibfield\n  {title} {\\enquote {\\bibinfo {title} {Popularity versus similarity in growing\n  networks},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Nature}\\ }\\textbf {\\bibinfo {volume} {489}},\\ \\bibinfo {pages} {537--540}\n  (\\bibinfo {year} {2012})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Bogu\\~{n}\\'{a}}\\ \\emph {et~al.}(2008)\\citenamefont\n  {Bogu\\~{n}\\'{a}}, \\citenamefont {Krioukov},\\ and\\ \\citenamefont\n  {Claffy}}]{Boguna2008}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Mari\\'{a}n}\\\n  \\bibnamefont {Bogu\\~{n}\\'{a}}}, \\bibinfo {author} {\\bibfnamefont {Dmitri}\\\n  \\bibnamefont {Krioukov}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {K.~C.}\\\n  \\bibnamefont {Claffy}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Navigability of complex networks}},}\\ }\\href {\\doibase 10.1038/nphys1130}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Nature Physics}\\ }\\textbf\n  {\\bibinfo {volume} {5}},\\ \\bibinfo {pages} {74--80} (\\bibinfo {year}\n  {2008})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Papadopoulos}\\ \\emph {et~al.}(2010)\\citenamefont\n  {Papadopoulos}, \\citenamefont {Krioukov}, \\citenamefont {Boguna},\\ and\\\n  \\citenamefont {Vahdat}}]{Papadopoulos2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Fragkiskos}\\\n  \\bibnamefont {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {Dmitri}\\\n  \\bibnamefont {Krioukov}}, \\bibinfo {author} {\\bibfnamefont {Marian}\\\n  \\bibnamefont {Boguna}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Amin}\\\n  \\bibnamefont {Vahdat}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Greedy Forwarding in Dynamic Scale-Free Networks Embedded in Hyperbolic\n  Metric Spaces}},}\\ }\\href {\\doibase 10.1109/INFCOM.2010.5462131} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Proceedings of IEEE INFOCOM}\\ ,\\ \\bibinfo\n  {pages} {1--9}} (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Travers}\\ and\\ \\citenamefont\n  {Milgram}(1969)}]{milgram1969}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Jeffrey}\\ \\bibnamefont\n  {Travers}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Stanley}\\ \\bibnamefont\n  {Milgram}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {An experimental\n  study of the small world problem},}\\ }\\href\n  {http://www.jstor.org/stable/2786545} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Sociometry}\\ }\\textbf {\\bibinfo {volume} {32}},\\ \\bibinfo {pages}\n  {425--443} (\\bibinfo {year} {1969})}\\BibitemShut {NoStop}\n\\bibitem [{as_(2015{\\natexlab{a}})}]{as_topo}\n  \\BibitemOpen\n  \\href@noop {} {\\enquote {\\bibinfo {title} {{The IPv4 and IPv6 Topology\n  Datasets}},}\\ } (\\bibinfo {year} {2015}{\\natexlab{a}}),\\ \\bibinfo {note}\n  {\\url{http://www.caida.org/data/active/ipv4_routed_topology_aslinks_dataset.xml}\n  and\n  \\url{https://www.caida.org/data/active/ipv6_allpref_topology_dataset.xml}}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Krioukov}\\ \\emph {et~al.}(2009)\\citenamefont\n  {Krioukov}, \\citenamefont {Papadopoulos}, \\citenamefont {Vahdat},\\ and\\\n  \\citenamefont {Bogu\\~{n}\\'{a}}}]{Krioukov2009}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Dmitri}\\ \\bibnamefont\n  {Krioukov}}, \\bibinfo {author} {\\bibfnamefont {Fragkiskos}\\ \\bibnamefont\n  {Papadopoulos}}, \\bibinfo {author} {\\bibfnamefont {Amin}\\ \\bibnamefont\n  {Vahdat}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Mari\\'{a}n}\\ \\bibnamefont\n  {Bogu\\~{n}\\'{a}}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Curvature and temperature of complex networks}},}\\ }\\href {\\doibase\n  10.1103/PhysRevE.80.035101} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physical Review E}\\ }\\textbf {\\bibinfo {volume} {80}},\\ \\bibinfo {pages}\n  {035101} (\\bibinfo {year} {2009})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Serrano}\\ \\emph {et~al.}(2012)\\citenamefont\n  {Serrano}, \\citenamefont {Boguna},\\ and\\ \\citenamefont\n  {Sagues}}]{Serrano2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M~Angeles}\\\n  \\bibnamefont {Serrano}}, \\bibinfo {author} {\\bibfnamefont {Marian}\\\n  \\bibnamefont {Boguna}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Francesc}\\\n  \\bibnamefont {Sagues}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {{Uncovering the hidden geometry behind metabolic networks}},}\\ }\\href\n  {\\doibase 10.1039/C2MB05306C} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Mol. BioSyst.}\\ }\\textbf {\\bibinfo {volume} {8}},\\ \\bibinfo {pages}\n  {843--850} (\\bibinfo {year} {2012})}\\BibitemShut {NoStop}\n\\bibitem [{bio(2006)}]{biogrid}\n  \\BibitemOpen\n  \\bibfield  {title} {\\enquote {\\bibinfo {title} {Biogrid: a general repository\n  for interaction datasets},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Nucleic Acids Research}\\ }\\textbf {\\bibinfo {volume} {34}},\\\n  \\bibinfo {pages} {D535\u00e2\u0080\u0093D539} (\\bibinfo {year} {2006})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {{De Domenico}}\\ \\emph {et~al.}(2015)\\citenamefont\n  {{De Domenico}}, \\citenamefont {{Nicosia}}, \\citenamefont {{Arenas}},\\ and\\\n  \\citenamefont {{Latora}}}]{arenas:reduce}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {{De\n  Domenico}}}, \\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont {{Nicosia}}},\n  \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont {{Arenas}}}, \\ and\\\n  \\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont {{Latora}}},\\ }\\bibfield\n  {title} {\\enquote {\\bibinfo {title} {{Structural reducibility of multilayer\n  networks}},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Nature Communications}\\ }\\textbf {\\bibinfo {volume} {6}},\\ \\bibinfo {pages}\n  {6864} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Chen}\\ \\emph {et~al.}(2006)\\citenamefont {Chen},\n  \\citenamefont {Hall},\\ and\\ \\citenamefont {Chklovskii}}]{pnas:celegans}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Beth~L.}\\ \\bibnamefont\n  {Chen}}, \\bibinfo {author} {\\bibfnamefont {David~H.}\\ \\bibnamefont {Hall}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {Dmitri~B.}\\ \\bibnamefont\n  {Chklovskii}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {{Wiring\n  optimization can relate neuronal structure and function}},}\\ }\\href {\\doibase\n  10.1073/pnas.0506806103} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Proceedings of the National Academy of Sciences of the United States of\n  America}\\ }\\textbf {\\bibinfo {volume} {103}},\\ \\bibinfo {pages} {4723--4728}\n  (\\bibinfo {year} {2006})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {De~Domenico}\\ \\emph\n  {et~al.}(2015{\\natexlab{a}})\\citenamefont {De~Domenico}, \\citenamefont\n  {Porter},\\ and\\ \\citenamefont {Arenas}}]{muxviz}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Manlio}\\ \\bibnamefont\n  {De~Domenico}}, \\bibinfo {author} {\\bibfnamefont {Mason~A.}\\ \\bibnamefont\n  {Porter}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Muxviz: a tool\n  for multilayer analysis and visualization of networks},}\\ }\\href@noop {}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Journal of Complex Networks}\\\n  }\\textbf {\\bibinfo {volume} {3}},\\ \\bibinfo {pages} {159--176} (\\bibinfo\n  {year} {2015}{\\natexlab{a}})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {De~Domenico}\\ \\emph\n  {et~al.}(2015{\\natexlab{b}})\\citenamefont {De~Domenico}, \\citenamefont\n  {Lancichinetti}, \\citenamefont {Arenas},\\ and\\ \\citenamefont\n  {Rosvall}}]{prx:modular}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Manlio}\\ \\bibnamefont\n  {De~Domenico}}, \\bibinfo {author} {\\bibfnamefont {Andrea}\\ \\bibnamefont\n  {Lancichinetti}}, \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Martin}\\ \\bibnamefont\n  {Rosvall}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Identifying\n  modular flows on multilayer networks reveals highly overlapping organization\n  in interconnected systems},}\\ }\\href {\\doibase 10.1103/PhysRevX.5.011027}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Phys. Rev. X}\\ }\\textbf {\\bibinfo\n  {volume} {5}},\\ \\bibinfo {pages} {011027} (\\bibinfo {year}\n  {2015}{\\natexlab{b}})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Nicosia}\\ and\\ \\citenamefont\n  {Latora}(2015)}]{pre:multiplex:correlations}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Vincenzo}\\\n  \\bibnamefont {Nicosia}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Vito}\\\n  \\bibnamefont {Latora}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Measuring and modeling correlations in multiplex networks},}\\ }\\href\n  {\\doibase 10.1103/PhysRevE.92.032805} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Phys. Rev. E}\\ }\\textbf {\\bibinfo {volume} {92}},\\ \\bibinfo\n  {pages} {032805} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Min}\\ \\emph {et~al.}(2014)\\citenamefont {Min},\n  \\citenamefont {Yi}, \\citenamefont {Lee},\\ and\\ \\citenamefont\n  {Goh}}]{pre:degree:correlations:2}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Byungjoon}\\\n  \\bibnamefont {Min}}, \\bibinfo {author} {\\bibfnamefont {Su~Do}\\ \\bibnamefont\n  {Yi}}, \\bibinfo {author} {\\bibfnamefont {Kyu-Min}\\ \\bibnamefont {Lee}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {K.-I.}\\ \\bibnamefont {Goh}},\\\n  }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Network robustness of\n  multiplex networks with interlayer degree correlations},}\\ }\\href {\\doibase\n  10.1103/PhysRevE.89.042811} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys.\n  Rev. E}\\ }\\textbf {\\bibinfo {volume} {89}},\\ \\bibinfo {pages} {042811}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Kim}\\ and\\ \\citenamefont\n  {Goh}(2013)}]{prl:degree:correlations}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Jung~Yeol}\\\n  \\bibnamefont {Kim}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {K.-I.}\\\n  \\bibnamefont {Goh}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Coevolution and correlated multiplexity in multiplex networks},}\\ }\\href\n  {\\doibase 10.1103/PhysRevLett.111.058702} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Phys. Rev. Lett.}\\ }\\textbf {\\bibinfo {volume} {111}},\\ \\bibinfo\n  {pages} {058702} (\\bibinfo {year} {2013})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Gemmetto}\\ and\\ \\citenamefont\n  {Garlaschelli}(2015)}]{scirep:degree:corr}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont\n  {Gemmetto}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {D.}~\\bibnamefont\n  {Garlaschelli}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Multiplexity versus correlation: the role of local constraints in real\n  multiplexes},}\\ }\\href {\\doibase 10.1038/srep09120} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Scientific Reports}\\ }\\textbf {\\bibinfo {volume} {5}},\\\n  \\bibinfo {pages} {9120} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {\u00c3\u0081ngeles Serrano}\\ \\emph {et~al.}(2015)\\citenamefont\n  {\u00c3\u0081ngeles Serrano}, \\citenamefont {\u00c4\u00bdubo\u00c5\u00a1 Buzna},\\ and\\ \\citenamefont\n  {Bogu\u00c3\u00b1\u00c3\u00a1}}]{self:similar:multiplex}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M}~\\bibnamefont\n  {\u00c3\u0081ngeles Serrano}}, \\bibinfo {author} {\\bibnamefont {\u00c4\u00bdubo\u00c5\u00a1 Buzna}}, \\ and\\\n  \\bibinfo {author} {\\bibfnamefont {Mari\u00c3\u00a1n}\\ \\bibnamefont {Bogu\u00c3\u00b1\u00c3\u00a1}},\\\n  }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Escaping the avalanche\n  collapse in self-similar multiplexes},}\\ }\\href\n  {http://stacks.iop.org/1367-2630/17/i=5/a=053033} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {New Journal of Physics}\\ }\\textbf {\\bibinfo {volume}\n  {17}},\\ \\bibinfo {pages} {053033} (\\bibinfo {year} {2015})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Loe}\\ and\\ \\citenamefont\n  {Jensen}(2015)}]{multiplex:communities}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Chuan~Wen}\\\n  \\bibnamefont {Loe}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Henrik~Jeldtoft}\\\n  \\bibnamefont {Jensen}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Comparison of communities detection algorithms for multiplex},}\\ }\\href@noop\n  {} {\\bibfield  {journal} {\\bibinfo  {journal} {Physica A: Statistical\n  Mechanics and its Applications}\\ }\\textbf {\\bibinfo {volume} {431}},\\\n  \\bibinfo {pages} {29 -- 45} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Zhu}\\ and\\ \\citenamefont\n  {Li}(2014)}]{multiplex:community:cs}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Guangyao}\\\n  \\bibnamefont {Zhu}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Kan}\\\n  \\bibnamefont {Li}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {A\n  unified model for community detection of multiplex networks},}\\ }in\\\n  \\href@noop {} {\\emph {\\bibinfo {booktitle} {Web Information Systems\n  Engineering \u00e2\u0080\u0093 WISE 2014}}},\\ \\bibinfo {series} {Lecture Notes in Computer\n  Science}, Vol.\\ \\bibinfo {volume} {8786}\\ (\\bibinfo  {publisher} {Springer\n  International Publishing},\\ \\bibinfo {year} {2014})\\ pp.\\ \\bibinfo {pages}\n  {31--46}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {L\u00c3\u00bc}\\ and\\ \\citenamefont\n  {Zhou}(2011)}]{link:prediction:1}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Linyuan}\\ \\bibnamefont\n  {L\u00c3\u00bc}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Tao}\\ \\bibnamefont {Zhou}},\\\n  }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Link prediction in complex\n  networks: A survey},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Physica A: Statistical Mechanics and its Applications}\\ }\\textbf\n  {\\bibinfo {volume} {390}},\\ \\bibinfo {pages} {1150 -- 1170} (\\bibinfo {year}\n  {2011})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Clauset}\\ \\emph {et~al.}(2008)\\citenamefont\n  {Clauset}, \\citenamefont {Moore},\\ and\\ \\citenamefont\n  {Newman}}]{Clauset:2008:Hierarchicalstructure}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Aaron}\\ \\bibnamefont\n  {Clauset}}, \\bibinfo {author} {\\bibfnamefont {Cristopher}\\ \\bibnamefont\n  {Moore}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.~E.~J.}\\ \\bibnamefont\n  {Newman}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Hierarchical\n  structure and the prediction of missing links in networks},}\\ }\\href@noop {}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Nature}\\ }\\textbf {\\bibinfo\n  {volume} {453}},\\ \\bibinfo {pages} {98--101} (\\bibinfo {year}\n  {2008})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Hristova}\\ \\emph {et~al.}(2015)\\citenamefont\n  {Hristova}, \\citenamefont {Noulas}, \\citenamefont {Brown}, \\citenamefont\n  {Musolesi},\\ and\\ \\citenamefont {Mascolo}}]{multiplex:link:prediction:1}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Desislava}\\\n  \\bibnamefont {Hristova}}, \\bibinfo {author} {\\bibfnamefont {Anastasios}\\\n  \\bibnamefont {Noulas}}, \\bibinfo {author} {\\bibfnamefont {Chlo{\\\"{e}}}\\\n  \\bibnamefont {Brown}}, \\bibinfo {author} {\\bibfnamefont {Mirco}\\ \\bibnamefont\n  {Musolesi}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Cecilia}\\ \\bibnamefont\n  {Mascolo}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {A multilayer\n  approach to multiplexity and link prediction in online geo-social\n  networks},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {arXiv:1508.07876}\\ } (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Dorogovtsev}(2010)}]{Dorogovtsev10-book}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {S~N}\\ \\bibnamefont\n  {Dorogovtsev}},\\ }\\href@noop {} {\\emph {\\bibinfo {title} {{Lectures on\n  Complex Networks}}}}\\ (\\bibinfo  {publisher} {Oxford University Press},\\\n  \\bibinfo {address} {Oxford},\\ \\bibinfo {year} {2010})\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Contreras}\\ and\\ \\citenamefont\n  {Reichman}(2015)}]{Contreras11122015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Jorge~L.}\\\n  \\bibnamefont {Contreras}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Jerome~H.}\\\n  \\bibnamefont {Reichman}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Sharing by design: Data and decentralized commons},}\\ }\\href@noop {}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Science}\\ }\\textbf {\\bibinfo\n  {volume} {350}},\\ \\bibinfo {pages} {1312--1314} (\\bibinfo {year}\n  {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Helbing}\\ and\\ \\citenamefont\n  {Pournaras}(2015)}]{helbing:digital_democracy}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Dirk}\\ \\bibnamefont\n  {Helbing}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {Evangelos}\\ \\bibnamefont\n  {Pournaras}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Society:\n  Build digital democracy},}\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Nature}\\ }\\textbf {\\bibinfo {volume} {527}},\\ \\bibinfo {pages}\n  {33--34} (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Claffy}\\ \\emph {et~al.}(2009)\\citenamefont {Claffy},\n  \\citenamefont {Hyun}, \\citenamefont {Keys}, \\citenamefont {Fomenkov},\\ and\\\n  \\citenamefont {Krioukov}}]{ark2009}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {K.}~\\bibnamefont\n  {Claffy}}, \\bibinfo {author} {\\bibfnamefont {Young}\\ \\bibnamefont {Hyun}},\n  \\bibinfo {author} {\\bibfnamefont {K.}~\\bibnamefont {Keys}}, \\bibinfo {author}\n  {\\bibfnamefont {M.}~\\bibnamefont {Fomenkov}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {D.}~\\bibnamefont {Krioukov}},\\ }\\bibfield  {title} {\\enquote\n  {\\bibinfo {title} {Internet mapping: From art to science},}\\ }in\\ \\href\n  {\\doibase 10.1109/CATCH.2009.38} {\\emph {\\bibinfo {booktitle} {Conference For\n  Homeland Security, 2009. CATCH '09. Cybersecurity Applications Technology}}}\\\n  (\\bibinfo {year} {2009})\\ pp.\\ \\bibinfo {pages} {205--211}\\BibitemShut\n  {NoStop}\n\\bibitem [{lin(January 2015)}]{link1and2}\n  \\BibitemOpen\n  \\href@noop {} {\\enquote {\\bibinfo {title} {{IPv4 and IPv6 Topology Data}},}\\\n  } (\\bibinfo {year} {January 2015}),\\ \\bibinfo {note}\n  {\\url{http://data.caida.org/datasets/topology/ark/ipv6/as-links/2015/01/} and\n  \\url{http://data.caida.org/datasets/topology/ark/ipv4/as-links/}}\\BibitemShut\n  {NoStop}\n\\bibitem [{hyp()}]{hypermap_code}\n  \\BibitemOpen\n  \\href@noop {} {\\enquote {\\bibinfo {title} {{HyperMap-CN Software Package}},}\\\n  }\\bibinfo {note}\n  {\\url{https://bitbucket.org/dk-lab/2015_code_hypermap}}\\BibitemShut {NoStop}\n\\bibitem [{as_(2015{\\natexlab{b}})}]{as_to_country_mapping}\n  \\BibitemOpen\n  \\href@noop {} {\\enquote {\\bibinfo {title} {{The CAIDA AS Organizations\n  Dataset, 09-Jan-2015}},}\\ } (\\bibinfo {year} {2015}{\\natexlab{b}}),\\ \\bibinfo\n  {note} {\\url{http://www.caida.org/data/as-organizations}}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Nelsen}(2006)}]{copulas}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Roger~B.}\\\n  \\bibnamefont {Nelsen}},\\ }\\href@noop {} {\\emph {\\bibinfo {title} {{An\n  Introduction to Copulas}}}},\\ {Springer Series in Statistics}\\ (\\bibinfo\n  {publisher} {Springer-Verlag New York},\\ \\bibinfo {year} {2006})\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Battiston}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Battiston}, \\citenamefont {Nicosia},\\ and\\ \\citenamefont\n  {Latora}}]{battiston:multiplex:measures}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Federico}\\\n  \\bibnamefont {Battiston}}, \\bibinfo {author} {\\bibfnamefont {Vincenzo}\\\n  \\bibnamefont {Nicosia}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Vito}\\\n  \\bibnamefont {Latora}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title}\n  {Structural measures for multiplex networks},}\\ }\\href {\\doibase\n  10.1103/PhysRevE.89.032804} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys.\n  Rev. E}\\ }\\textbf {\\bibinfo {volume} {89}},\\ \\bibinfo {pages} {032804}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Omodei}\\ \\emph {et~al.}(2015)\\citenamefont {Omodei},\n  \\citenamefont {De~Domenico},\\ and\\ \\citenamefont {Arenas}}]{elisa:overlap}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Elisa}\\ \\bibnamefont\n  {Omodei}}, \\bibinfo {author} {\\bibfnamefont {Manlio~De}\\ \\bibnamefont\n  {De~Domenico}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {Alex}\\ \\bibnamefont\n  {Arenas}},\\ }\\bibfield  {title} {\\enquote {\\bibinfo {title} {Characterizing\n  interactions in online social networks during exceptional events},}\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Frontiers in\n  Physics}\\ }\\textbf {\\bibinfo {volume} {3}} (\\bibinfo {year}\n  {2015})}\\BibitemShut {NoStop}\n\\end{thebibliography}\n\n\n\n        \n\n", "itemtype": "equation", "pos": 86852, "prevtext": " \nand ${\\kappa_{2}^{\\text{min}}}$ is given in Eq.~(\\ref{kappa_0_2}).\n\\begin{figure}[t]\n\\centering\n\\includegraphics[width=0.9\\linewidth]{sfig6.pdf}\n\\caption{\\textbf{$\\kappa_2$ as a function of $\\kappa_1$ at the limit $\\nu \\rightarrow 1$.} The triangles denote the values of $\\kappa_2$ by numerically evaluating Eq.~\\eqref{eqn_pc_full} using the $\\psi(\\kappa_1)$ in Eq.~(\\ref{eqn_psi_fit}) and the IPv4/IPv6 Internet parameters $\\gamma_1=\\gamma_2=2.1, {\\kappa_{1}^{\\text{min}}}=0.84, {\\kappa_{2}^{\\text{min}}}=1.30$. The best-fit line corresponds to $\\kappa_2=1.11 + 0.22 \\kappa_1$.\n\\label{fig_full_fit}}\n\\end{figure}\n\nEq.~\\eqref{map_full_approx} is obtained by considering the maximally correlated case $\\nu \\to 1$, where Eq.~(\\ref{eqn_pc_full}) converges to a Heaviside step function $F_{\\nu}({\\kappa_{2}}|{\\kappa_{1}},\\{{\\gamma_1},{\\gamma_2},{\\kappa_{1}^{\\text{min}}},{\\kappa_{2}^{\\text{min}}}\\}) = \\Theta\\left[\\kappa_2 - \\tilde{\\kappa}\\right]$. That is, for $\\nu \\to 1$, $\\kappa_2 \\approx 1.11 + 0.22\\kappa_1 \\equiv \\tilde{\\kappa}$. This relation is the analogue of Eq.~\\eqref{kappa_i_2_limit_relation}, and is obtained by numerically evaluating Eq.~(\\ref{eqn_pc_full}) at $\\nu \\to 1$, see Fig.~\\ref{fig_full_fit}. Once this result is known, then for $\\nu \\neq 1$, we can approximate Eq.~\\eqref{eqn_pc_full} with Eq.~\\eqref{draw_kappa_paper_2}, which results from Eq.~(\\ref{draw_kappa_paper_1}) if in place of $\\kappa_1, \\gamma_1, {\\kappa_{1}^{\\text{min}}}$, we use $\\tilde{\\kappa}, \\gamma_2, \\kappa_{2}^{\\text{min}}$. The idea behind this approximation is that instead of directly correlating the $\\kappa_{2,i}$ with the $\\kappa_{1,i}$ via Eq.~(\\ref{eqn_pc_full}), we correlate them via Eq.~\\eqref{draw_kappa_paper_2} with the corresponding values of $\\kappa_{2,i}$ at the maximal correlations ($\\nu \\to 1$), which in our case are given by $\\kappa_{2,i}=1.11 + 0.22\\kappa_{1,i}$.  \n\nIn our synthetic Internet-like multiplex in the main text (Fig.~\\ref{fig_psi_fitted_graphs}), we sample the hidden variables $\\kappa_{2,i}$ of the common nodes in layer~2 from the conditional CDF in Eq.~(\\ref{draw_kappa_paper_2}). In Fig.~\\ref{fig_degree_dists_l1_l2}, we show the marginal PDFs of the $\\kappa_{2,i}$ of the common nodes at correlation strengths $\\nu=0$ (no correlations, where the $\\kappa_{2,i}$ are sampled from their marginal CDF), $\\nu=0.5$ (partial correlations, where the $\\kappa_{2,i}$ are sampled from the conditional CDF in Eq.~(\\ref{draw_kappa_paper_2})), and $\\nu=1$ (full correlations, where the $\\kappa_{2,i}$ are directly obtained by Eq.~\\eqref{map_full_approx}). \nIn all cases, the marginal PDFs are nearly identical, validating the approximation described above. \n\\begin{figure}[t]\n\\includegraphics[width=0.9\\linewidth]{sfig7.pdf}\n\\caption{\\textbf{Degree distribution (PDF) in layer~2 of our synthetic Internet-like multiplex  (Fig.~\\ref{fig_psi_fitted_graphs} in the main text) at correlation strengths $\\nu=0, 0.5, 1$.}\n\\label{fig_degree_dists_l1_l2}}\n\\end{figure}\n\n\n\\section{Geometric correlations lead to significant edge overlap}\n\\label{appendix_model_overlap}\n\nThe radial and angular correlations across different layers naturally give rise to a significant amount of edge overlap between the layers, as observed in many real multiplexes~\\cite{Thurner:multi,Halu}. The edge overlap $O$ between two layers (layer 1, layer 2) is formally defined as the ratio of the number of overlapping (i.e., common) edges between the layers, to the maximum possible number of common edges~\\cite{battiston:multiplex:measures,elisa:overlap},\n\n", "index": 43, "text": "\\begin{equation}\nO = \\frac{\\#(\\text{overlapping edges)}}{\\min[\\#(\\text{edges in layer 1}),\\#(\\text{edges in layer 2})]} {\\,.}\n\\label{eqn_overlap}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"O=\\frac{\\#(\\text{overlapping edges)}}{\\min[\\#(\\text{edges in layer 1}),\\#(%&#10;\\text{edges in layer 2})]}{\\,.}\" display=\"block\"><mrow><mrow><mi>O</mi><mo>=</mo><mpadded width=\"+1.7pt\"><mfrac><mrow><mi mathvariant=\"normal\">#</mi><mrow><mo stretchy=\"false\">(</mo><mtext>overlapping edges)</mtext></mrow></mrow><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi mathvariant=\"normal\">#</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mtext>edges in layer 1</mtext><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi mathvariant=\"normal\">#</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mtext>edges in layer 2</mtext><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mfrac></mpadded></mrow><mo>.</mo></mrow></math>", "type": "latex"}]