[{"file": "1601.06908.tex", "nexttext": "\n\n\nBy using the above decomposition in a recursive manner, it follow that any RM code can be built from repetition and identity codes. This also implies that any $RM(m-1,m)$ code is a Single Parity Check (SPC) code.\n\nOver the erasure channel, a codeword $a$ is received with some erased positions. One can try to decode $u$ and $v$ with $a=(u | u + v)$ recursively. \n\nFor example, if $a\\in RM(1,3)$, we have $u\\in RM(1,2)$, which is an SPC code, and $v\\in RM(0,2)$, which is a repetition code. Therefore, $u$ can be decoded if it has at most one lost position, and $v$ can be decoded if at least one of its position is known. Moreover, decoding new positions on either $u$ or $v$ can reveal some new positions on the other vector, as we have $a_{\\frac{n}{2}+i} = u_i + v_i$, for any $0\\leq i\\leq \\frac{n}{2}$. This decoding decomposition will be referred to as the \\textit{classical recursive algorithm}. By nature, this algorithm has a  $O(n \\log n)$ complexity.\n\n\\subsection{Permutation Decoding}\n\nOne interesting property of $RM(r,m)$ codes is that they admit the general affine group $GA(m)$ as a permutation group \\cite{MWSl77}. In other words, if $a=(a_0,a_1,...,a_{n-1}) \\in RM(r,m)$, then $a'=(a_{\\Pi(0)},a_{\\Pi(1)},...,a_{\\Pi(n-1)}) \\in RM(r,m)$, where $\\Pi(x) = Ax+b$, $A$ is a $m\\times m$ binary invertible matrix and $b$ a vector of $(\\mathbb{F}_2)^m$. This group is known to be doubly-transitive, \\textit{i.e.} there exists a permutation that sends any pair of positions onto any other pair of positions.\n\nIt can be observed that the success of the recursive decoding depends on the erasure pattern. Applying some specific permutation on a received word can make successful a decoding that has initially failed. The effects of permutations on the iterative erasure decoding was studied in \\cite{hehn} for cyclic and extended cyclic codes, but not for general {Reed-M\\\"{u}ller } codes. \n\n\n\n\\textit{Example :}\t\nLet us consider that a received pattern of $a\\in RM(1,3)$ is $(a_0,\\times,\\times,\\times,\\times,a_5,a_6,a_7)$. Only one in $u=(a_0,\\times,\\times,\\times)$ is known thus it can not be decoded. Moreover, no positions of $v$, obtained by summing $u$ and $(u+v)$, are known. Decoding is then impossible.  Using the permutation matrix \n\n", "itemtype": "equation", "pos": 5228, "prevtext": "\n\n\n\\title{Enhanced Recursive Reed-Muller Erasure Decoding}\n\n\n\n\n\n\\author{\n\\authorblockN{Alexandre Soro$^1$, J\\'er\\^ome Lacan$^1$ , Vincent Roca$^2$, Valentin Savin$^3$ and Mathieu Cunche$^{2,4}$}\n\\authorblockA{$^1$Univ. of Toulouse, ISAE/DISC, \n10 avenue Edouard Belin, BP 54032 - 31055 Toulouse cedex 4 - FRANCE\\\\\n$^2$INRIA Rhone-Alpes, Privatics team, Inovall\\'ee, 655 av. de l'Europe, Montbonnot, 38334 St Ismier cedex - FRANCE\\\\\n$^3$CEA-LETI, MINATEC Campus, 17 rue des Martyrs, 38054 Grenoble - FRANCE\\\\\n$^4$INSA-Lyon, Laboratoire CITI 6 Avenue des Arts, 69621 Villeurbanne - FRANCE\\\\\nEmail: jerome.lacan@isae.fr, \\{vincent.roca,mathieu.cunche\\}@inria.fr,valentin.savin@cea.fr}\n}\n\n\n\n\\maketitle\n\n\\begin{abstract}\nRecent work have shown that {Reed-M\\\"{u}ller } (RM) codes achieve the erasure channel capacity. However, this performance is obtained with maximum-likelihood decoding which can be costly for practical applications. In this paper, we propose an encoding/decoding scheme for {Reed-M\\\"{u}ller }  codes on the packet erasure channel based on Plotkin construction. We present several improvements over the generic decoding. They allow, for a light cost, to compete with maximum-likelihood  decoding performance, especially on high-rate codes, while significantly outperforming it in terms of speed. \n\\end{abstract}\n\n\n\\section{Introduction}\n\n\nIntroduced in 1951 by Mitani \\cite{mitani:51} and popularized by Reed \\cite{reed:54} and M\\\"uller \\cite{muller:54}, {Reed-M\\\"{u}ller } codes are still used in many applications (\\textit{e.g.} \\cite{dvb_s2}). Their structural properties allow the use of very simple but efficient coding and decoding algorithms. Traditionally, {Reed-M\\\"{u}ller } codes were mainly considered for the Gaussian channel because they are able to reach their Maximum-Likelihood (ML) decoding performance with fast soft decision decoding algorithms \\cite{dumer,dumer02,JLacanAIAA2007}. But recently, very interesting results have shown that {Reed-M\\\"{u}ller } codes achieve the capacity of the erasure channel \\cite{CapacityGrouped16,Abbe15}. These results were followed by new contributions on decoding algorithms of these codes \\cite{Abbe15,LinearError15}.  \n\nCapacity-achieving erasure codes have interesting practical applications. For example, they are used on higher layers of communication protocols stacks for multicast or real-time transmissions \\cite{hanle}. In this context, the data are transmitted into packets and the erasure code is used to generate repair packets from information packets. On the channel, called packet erasure channel, each packet is correctly received or erased.  Classically, packet erasure codes are Fountain codes \\cite{rfc5053}, LDPC codes \\cite{rfc5170} or MDS (Reed-Solomon-based) codes \\cite{rfc5510}. \n\nThe main issue concerning the use of {Reed-M\\\"{u}ller } codes on the packet erasure channel is that the traditional decoding algorithm achieving the capacity is based on an inversion (through a Gaussian elimination) of the submatrix of generator matrix corresponding to the received symbols and a matrix-vector multiplication. The gaussian elimination, which has a cubic complexity, is done only once for a codeword of packets but the matrix-vector multiplication is done $z$ times, where $z$ is the size of the packets. This operation can be very costly when the code length increases. \n \nThe main contribution of this paper is to propose a sub-quadratic decoding algorithms of {Reed-M\\\"{u}ller } codes for the packet erasure channel which obtain performances very close to the capacity. For that, we extend some results presented in \\cite{TheseASoro}. The decoding algorithm make use of various structural properties of {Reed-M\\\"{u}ller } codes like the Plotkin recursive decomposition \\cite{plotkin} and the doubly transitive permutation group. A similar technique was shown to obtain excellent decoding performance on the Gaussian channel \\cite{dumer}. Our main contribution is to show that, when used in a different way and combined with additional tools (partial information passing and blank decoding), this techniques yields decoding performance close to maximum likelihood on the packet erasure channel with a very low complexity cost. \n\n\n\nIn the next Section, we present the Plotkin construction of Reed-Muller codes and then our algorithm. In Section \\ref{results}, we compare the recovering performance and the speed of our decoding algorithm to  the ML decoding with Gaussian Elimination (GE). Finally, we draw some conclusions and perspectives for this algorithm.\n\n\\section{Proposed decoding algorithm}\n\\label{presentation}\n\n\n\\subsection{Introduction to Reed-Muller codes}\n\nReed-Muller codes defined by parameters $r$ and $m$, where $r\\leq m$, are denoted by $RM(r,m)$. The dimension $k$, and the length $n$ of $RM(r,m)$ are given by $k=\\sum_{i=0}^{r}{\\binom{m}{i}}$ and $n=2^m$.\n\nOne way to construct Reed-Muller codes is to use the recursive decomposition introduced by Plotkin. For any $m$, $RM(0,m)$ is defined as the repetition code and $RM(m,m)$ is the identity code. In the general case, for $0<r<m$, any codeword $a\\in RM(r,m)$ can be uniquily built from two codewords $u\\in RM(r,m-1)$ and $v\\in RM(r-1,m-1)$. Precisely, we have:\n\n\n", "index": 1, "text": "\\begin{multline*}\nRM(r,m) = \\{(u | u + v), u\\in RM(r,m-1),\\\\\nv\\in RM(r-1,m-1)\\}\n\\end{multline*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"p1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle RM(r,m)=\\{(u|u+v),u\\in RM(r,m-1),\\\\&#10;\\displaystyle v\\in RM(r-1,m-1)\\}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mi>R</mi><mi>M</mi><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">|</mo><mi>u</mi><mo>+</mo><mi>v</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi>u</mi><mo>\u2208</mo><mi>R</mi><mi>M</mi><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>,</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mi>v</mi><mo>\u2208</mo><mi>R</mi><mi>M</mi><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.06908.tex", "nexttext": " \nthe vector to be decoded is then $a'=(a_0,\\times, \\times, \\times, a_6, a_7, \\times, a_5)$ and thus $u'=(a_0,\\times,\\times,\\times)$ and $u'+v'=(a_6, a_7, \\times, a_5)$. By summing $u'$ and $u'+v'$, we obtain $v'=(a_0+a_6, \\times, \\times, \\times)$.  Since $v'$ is a codeword of the $RM(0,2)$ which is the repetition code of length $4$, $v'_{decoded}=(a_0+a_6, a_0+a_6,a_0+a_6,a_0+a_6)$. By summing $v'_{decoded}$ and the received $u'+v'$, we obtain an updated version of $u'$, $u'_{updated}=(a_0, a_7+a_0+a_6,\\times ,a_5+a_0+a_6)$. Since $u'$ belongs to the  $RM(1,2)$ which is a SPC code, we can decode it as $u'_{decoded}=(a_0, a_7+a_0+a_6, a_0+a_5+a_7, a_5+a_0+a_6)$. We can then rebuild the decoded version of $u'+v'$ and finally apply the inverse permutation on $a'$ to obtain the decoded word $a$.\t\n\n\nThe key challenge in the previous example is to find a specific permutation, suited for the given erasure pattern. Simulation results have shown that decoding is more efficient by starting the decoding process with the decoding of $v$. As a consequence, the main point is to determine a permutation which maximizes the number of received positions in $v$ for a small complexity cost. \n\nFirst we can notice that the vector $b$ is useless. Indeed, for a received word $a=(u | u + v)$, the known positions of $v$ are the positions where $a_i$ and $a_{i + \\frac{n}{2}}$ are known. We can observe that the number of known positions of $v$ will not change when the vector $b$  is added to all positions. Without loss of generality, in the following, we restrict ourselves to the set of invertible matrices $A$, \\textit{i.e.} the general linear group $GL(m,2)$. For all binary invertible matrices of size $m$, we have to process the images of the $n$ positions. Following \\cite{MWSl77} which gives the number of invertible matrices of size $n$, the complexity of testing all possible matrices corresponding to a permutation of size $n$ is roughly $O(n\\times 0.29\\times 2^{\\log^2n})$.\n\n\nIn order to avoid such a prohibitive cost, we propose a lower complexity algorithm. Instead of testing the whole set of invertible matrices, we only select the matrices that leave the $\\frac{n}{2}$ leftmost positions, \\textit{i.e.} the vector $u$, invariant. It means that their first $m-1$ columns correspond to the first $m-1$ columns of the identity matrix.  \n\nHence, the number of permutations to be tested is equal to $\\frac{n}{2}$, since corresponding matrices are completely determined by their last column, which must be chosen outside the vector subspace spanned by the first $m-1$ columns. For each of these permutations, as the leftmost positions are invariant, only the images of the $\\frac{n}{2}$ rightmost positions are processed. The complexity of testing this set of matrices for one permutation of size $n$ is thus $O(\\frac{n^2}{4})$. The impact of this permutation selection on the global complexity of the decoding process is discussed in Section \\ref{sec:blankDecoding}.\n\n\n\n\n\n\\subsection{Partial Decoding}\n\nOrthogonally to the previous point, we propose a second improvement to the algorithm. One of the weaknesses of the raw recursive decoding algorithm is that, if one recursion fails, the whole decoding fails. This is harmful for the performance as for instance a recursion in $v$ can fail but some new symbols from other recursions may have been recovered. We propose to pass this partial recovered information to the higher levels of the recursion. \n\nFor example, let $a$ be decomposed by $u$ and $v$, which itself is decomposed by $v_1$ and $v_2$. Let the decoding of $v_2$ succeed and $v_1$ fail. $v_2$ may bring some new symbols to $v$, which can themselves bring new symbols to $a$ and then improve the decoding of $u$. Finally, if $u$ reveals new symbols, they can be useful for $v$ and $v_1$ and so forth. Simulation results have shown that most of the time (over 95\\%), the number of recursive calls is two, especially for higher levels of recursion, which also means that the use of this mechanism is limited.\n\n\\subsection{Blank Decoding}\n\\label{sec:blankDecoding}\n\nUnlike the previous improvements enhancing the decoding capability, \"blank decoding\" is focused on speed. \n\nTo explain this mechanism, let us consider a packet erasure code generating $n-k$ repair packets from $k$ information packets. By assuming that all packets have size $z$ bits, the encoding of the packet code can be seen as the parallel encoding of $z$ binary codewords of size $n$. Each one of the $n$ transmitted packets contains exactly one bit of each of the $z$ encoded vectors. The interest of this scheme is that the erased packets produce the same erasure pattern on all the binary codewords. In the decoding process of the packet code, this property is used to pool together operations that are common to the $z$ decodings of the binary codewords.   \n\n\n\nActually, before each packet block decoding, a blank block (\\textit{i. e.} a block with packets of null size) decoding is processed with the received loss pattern. During this process, the decoder searches the best permutation to apply and the best partial information passing strategy, according to the algorithms described above and records it. If this decoding succeeds, the actual decoding of the $z$ binary codewords are simply done by following the path traced by the blank pattern. If the blank decoding fails, a partial decoding may however be possible. A Gaussian Elimination may also be attempted, also in a blank mode, either after or instead of this partial decoding.\n\nAs seen previously, the main point is to find the permutations recursively. Consequently the complexity of this blank decoding is roughly $O(n^2\\log n)$, processed only once per packet block. This cost must be compared to the decodings of the $z$ binary codewords (each one having a complexity $O(n\\log n)$). The impact of blank decoding on the global decoding complexity of a packet block is evaluated in next section. \n\n\n\n\\section{Results}\n\\label{results}\n\nWe have compared our proposal with maximum likelihood decoding using Gaussian Elimination (GE) on an Intel Core 2 Extreme @3.06Ghz on Mac OS X 10.6 in 64-bit mode. Fig. \\ref{fig:ineff} shows the decoding failure probabilities for $RM(3,7)$ code ($k=64$, $n=128$), in terms of extra-packets. By extra-packets, we mean the number of received symbols above the source block size $k$, which corresponds to  the erasure channel capacity. We compare ML, which is optimal, with our algorithm and the classical recursive algorithm. In addition, we provide results for the recursive algorithm with only permutation selection and only partial information passing.\n\n\\begin{figure}[htb]\n  \\begin{center}\n   \\includegraphics[width=.49\\textwidth]{ineff2.png}\n    \\end{center}\n    \\caption{Decoding failure rate of GE and recursive algorithms in terms of extra-symbols for $RM(3,7)$}\n   \\label{fig:ineff}\n\\end{figure}\n\nWe can see that our algorithm performs well compared to the optimal GE and requires only 3 extra-symbols in average to match the performances of GE. On the opposite, the raw recursive algorithm is not able to recover anything with up to 20\\% of extra-symbols. For $RM(3,7)$, the decoding speed of both algorithms is provided in Table \\ref{tab:rm}. For the sake of completeness,  the encoding speed for the RM(3,7) code is in the order of 4Gbps, and the decoding speed of a Reed-Solomon code with the same parameters is around 350Mbps \\cite{rfc5510}.\n\nIn Table \\ref{tab:rm}, we provide a comparison of the decoding speed and the average overhead between GE and our algorithm for various {Reed-M\\\"{u}ller } codes. All results are provided for packets of 1500 bytes.\n\n\\begin{table}[ht]\n\\begin{center}\n\n\\begin{tabular}{|r|c|c|c|c|c|}\n\\hline\n\t\t &  Recursive & Gaussian Elim. & Recursive & ML \\\\\n\t\t& speed\t& speed & overhead & overhead \\\\\n\\hline\nRM(3,6)\t& 2021 Mbps &  842 Mbps & 5.41\\% & 5.06\\% \\\\\n\\hline\nRM(3,7)\t& 1073 Mbps &  544 Mbps & 8.59\\% & 4.75\\% \\\\\n\\hline\nRM(4,7)\t& 2393 Mbps &  381 Mbps & 3.45\\% & 2.79\\% \\\\\n\\hline\nRM(4,8)\t& 1363 Mbps &  215 Mbps & 9.08\\% & 1.44\\% \\\\\n\\hline\nRM(5,8)\t& 2774 Mbps &  181 Mbps & 2.44\\% & 1.17\\% \\\\\n\\hline\nRM(5,9)\t& 1783 Mbps &  85 Mbps & 9.23\\% & 0.45\\% \\\\\n\\hline\nRM(6,9)\t& 3291 Mbps &  80 Mbps & 1.90\\% & 0.47\\% \\\\\n\\hline\nRM(6,10)\t& 3486 Mbps &  44 Mbps & 8.05\\% & 0.18\\% \\\\\n\\hline\n\\end{tabular}\n\n\\end{center}\n\\caption{Decoding speed and overhead for various RM codes}\n\\label{tab:rm}\n\\end{table}\n\nFor the $RM(6,9)$ ($k=466$, $n=512$) code, we compare the decoding speed of GE with our implementation. We provide results for packets of $50$, $500$ and $1500$ bytes which represent classical VoIP, median Internet and LAN data units, in Table \\ref{tab:ineff}.\n\n\\begin{table}[ht]\n\\begin{center}\n\n\\begin{tabular}{|r|c|c|c|c|}\n\\hline\nPacket Size\t\t &  Recursive Alg. & Gaussian Elim. & Speed Ratio\\\\\n\\hline\n50 bytes\t& 546 Mbps &  8 Mbps & 66x \\\\\n\\hline\n500 bytes\t& 2463 Mbps &  51 Mbps & 49x \\\\\n\\hline\n1500 bytes\t& 3291 Mbps &  80 Mbps & 41x \\\\\n\\hline\n\\end{tabular}\n\n\\end{center}\n\\caption{Decoding speed for $RM(6,9)$ code with $5\\%$ of extra-symbols}\n\\label{tab:ineff}\n\\end{table}\n\nFor this code, the speed up ratio between our code and the GE is between 40x and 60x, depending on the packet size. This variation can be explained by the fact that the smaller is the packet size, the longer is the pre-decoding phase compared to the actual decoding. This pre-decoding is more complex for GE (a cubic complexity matrix inversion) than the blank decoding for the recursive algorithm. Note, however, that the blank decoding represents $86\\%$, $38\\%$ and $17\\%$ of decoding time for recursive decoding for packet sizes of $50$, $500$ and $1500$ bytes. It is worth pointing out that for the recursive decoding, only the encoded vector is recovered. We do not take into account the final step which consists in recovering the source symbols from the whole encoded vector, which is in the magnitude of $8$ Gbps for this code, and thus far faster than the decoding.\\\\\n\n\nIn high code rates scenarios, our algorithm is able to decode with only $1\\%-2\\%$ more symbols than the optimal GE decoding. Depending on the target application, one may be interested to use this decoding algorithm, as it allows a ratio of 5x - 20x decoding speed compared to GE.\n\n\\section{Conclusions}\n\\label{conclusions}\n\nIn this contribution, we have presented a recursive decoding algorithm for Reed-Muller codes based on Plotkin construction. We have shown that the permutation selection and the blank decoding dramatically improve the performances of the decoder. In many scenarios, our algorithm can achieve decoding performance close to the capacity, while achieving speeds of several Gbps. Because of their high decoding speed, {Reed-M\\\"{u}ller } codes are an interesting alternative for the packet erasure channel, when the decoding cost is a bottleneck (\\textit{e.g.} in low power devices and real-time applications). \n\n\\bibliographystyle{IEEEtran}\n\\bibliography{rm, RM_aiaa}\n\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\nBy using the above decomposition in a recursive manner, it follow that any RM code can be built from repetition and identity codes. This also implies that any $RM(m-1,m)$ code is a Single Parity Check (SPC) code.\n\nOver the erasure channel, a codeword $a$ is received with some erased positions. One can try to decode $u$ and $v$ with $a=(u | u + v)$ recursively. \n\nFor example, if $a\\in RM(1,3)$, we have $u\\in RM(1,2)$, which is an SPC code, and $v\\in RM(0,2)$, which is a repetition code. Therefore, $u$ can be decoded if it has at most one lost position, and $v$ can be decoded if at least one of its position is known. Moreover, decoding new positions on either $u$ or $v$ can reveal some new positions on the other vector, as we have $a_{\\frac{n}{2}+i} = u_i + v_i$, for any $0\\leq i\\leq \\frac{n}{2}$. This decoding decomposition will be referred to as the \\textit{classical recursive algorithm}. By nature, this algorithm has a  $O(n \\log n)$ complexity.\n\n\\subsection{Permutation Decoding}\n\nOne interesting property of $RM(r,m)$ codes is that they admit the general affine group $GA(m)$ as a permutation group \\cite{MWSl77}. In other words, if $a=(a_0,a_1,...,a_{n-1}) \\in RM(r,m)$, then $a'=(a_{\\Pi(0)},a_{\\Pi(1)},...,a_{\\Pi(n-1)}) \\in RM(r,m)$, where $\\Pi(x) = Ax+b$, $A$ is a $m\\times m$ binary invertible matrix and $b$ a vector of $(\\mathbb{F}_2)^m$. This group is known to be doubly-transitive, \\textit{i.e.} there exists a permutation that sends any pair of positions onto any other pair of positions.\n\nIt can be observed that the success of the recursive decoding depends on the erasure pattern. Applying some specific permutation on a received word can make successful a decoding that has initially failed. The effects of permutations on the iterative erasure decoding was studied in \\cite{hehn} for cyclic and extended cyclic codes, but not for general {Reed-M\\\"{u}ller } codes. \n\n\n\n\\textit{Example :}\t\nLet us consider that a received pattern of $a\\in RM(1,3)$ is $(a_0,\\times,\\times,\\times,\\times,a_5,a_6,a_7)$. Only one in $u=(a_0,\\times,\\times,\\times)$ is known thus it can not be decoded. Moreover, no positions of $v$, obtained by summing $u$ and $(u+v)$, are known. Decoding is then impossible.  Using the permutation matrix \n\n", "index": 3, "text": "$$A = \\left( \\begin{matrix} 1&0&0\\\\ 1&1&0 \\\\ 0&0&1 \\end{matrix} \\right) \\textrm{ and }b= \\left( \\begin{matrix} 0\\\\ 0 \\\\ 0 \\end{matrix} \\right),$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"A=\\left(\\begin{matrix}1&amp;0&amp;0\\\\&#10;1&amp;1&amp;0\\\\&#10;0&amp;0&amp;1\\end{matrix}\\right)\\textrm{ and }b=\\left(\\begin{matrix}0\\\\&#10;0\\\\&#10;0\\end{matrix}\\right),\" display=\"block\"><mrow><mrow><mi>A</mi><mo>=</mo><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>1</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>1</mn></mtd><mtd columnalign=\"center\"><mn>1</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>1</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><mtext>\u00a0and\u00a0</mtext><mo>\u2062</mo><mi>b</mi></mrow><mo>=</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}]