[{"file": "1601.01070.tex", "nexttext": "\nwhere $\\mathbf{x} = \\left[x_1, x_2, \\cdots, x_L\\right]^{T}$ is the vector of transmit signals across all the $L$ BSs and \n$\\mathbf{h}_k \\in \\mathbb{C}^{L \\times 1}$ is the vector of channel gains from all the $L$ BSs to user $k$. \nThe received noise $n_k$ is modeled as a complex Gaussian random variable with zero mean and variance $\\sigma^2$. \nEach user decodes its own message $s_k \\in \\mathbb{C}$ from the received signal $y_k$. \n\n\n\n\nIn this paper, we investigate two fundamental but different transmission strategies, \nthe data-sharing strategy and the compression strategy, for the downlink C-RAN for delivering the message $s_k$ to user $k$ \nvia the transmit signal $\\mathbf{x}$ from the BSs. \nIn particular, we compare the potential of these two strategies in improving the energy efficiency. \nBefore discussing the details of the two strategies, we first describe the power consumption model adopted in this paper. \n\n\n\n\n\\subsection{Power Consumption Model}\n\nTraditional cellular network transmission strategy design typically only considers transmit power at each BS, which is written as \n\n", "itemtype": "equation", "pos": 20005, "prevtext": "\n\n\n\n\\title{Energy Efficiency of Downlink Transmission Strategies for Cloud Radio Access Networks}\n\n\n\n\n\n\\author{\\IEEEauthorblockN{Binbin Dai, \\IEEEmembership{Student Member, IEEE} and Wei Yu, \\IEEEmembership{Fellow, IEEE}}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\thanks{Manuscript submitted on April 15, 2015; revised on September 15, 2015; accepted on December 11, 2015. This work was supported by Huawei Technologies, Canada, \nand Natural Sciences and Engineering Research Council (NSERC) of Canada. \nThe authors are with The Edward S. Rogers Sr. Department of Electrical\nand Computer Engineering, University of Toronto, Toronto, ON M5S 3G4, \nCanada (e-mails: \\{bdai, weiyu\\}@comm.utoronto.ca).}\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\\begin{abstract}\n\nThis paper studies the energy efficiency of the cloud radio access network (C-RAN), specifically focusing on two fundamental and different downlink transmission strategies, \nnamely the data-sharing strategy and the compression strategy. \nIn the data-sharing strategy, the backhaul links connecting the central processor (CP) and the base-stations (BSs) are used to carry user messages -- each user's messages \nare sent to multiple BSs; the BSs locally form the beamforming vectors then cooperatively transmit the messages to the user. \nIn the compression strategy, the user messages are precoded centrally at the CP, which forwards a compressed version of the analog beamformed signals to the BSs for cooperative transmission. \nThis paper compares the energy efficiencies of \nthe two strategies by formulating an optimization problem of minimizing the total network power consumption subject to user target rate constraints, \nwhere the total network power includes the BS transmission power, BS activation power, and load-dependent backhaul power. \nTo tackle the discrete and nonconvex nature of the optimization problems, \nwe utilize the techniques of reweighted $\\ell_1$ minimization and successive convex approximation \nto devise provably convergent algorithms. \nOur main finding is that both the optimized data-sharing and compression strategies in C-RAN achieve much higher energy efficiency as compared to the non-optimized coordinated multi-point transmission, \nbut their comparative effectiveness in energy saving depends on the user target rate. \nAt low user target rate, data-sharing consumes less total power than compression, however, as the user target rate increases, \nthe backhaul power consumption for data-sharing increases significantly leading to better energy efficiency of compression at the high user rate regime. \n\n\n\\end{abstract}\n\n\n\n\n\n\n\n\\begin{IEEEkeywords}\nCloud radio access network (C-RAN), data-sharing strategy, compression strategy,\nenergy efficiency, power minimization, base-station activation, base-station clustering,\nbeamforming, backhaul power. \n\\end{IEEEkeywords}\n\n\n\n\n\n\n\n\n\n\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\\section{Introduction} \n\n\n\\IEEEPARstart{U}{ltra-dense} deployment of small cells and cooperative communications are recognized as \ntwo promising technologies to meet the ever increasing demand of data traffic for future wireless networks \\cite{Rost14}. \nHowever, both technologies come at the cost of increase in energy consumption \nbecause of the additional energy needed to support the increasing number of base-station (BS) sites and the substantially increased backhaul between the BSs for cooperation. \nThe excessive energy consumption of wireless networks not only has an ecological impact in terms of carbon footprint but also has \nan economical impact on the operational cost to the mobile operators.  \nThus, the compelling call for improvement of \\emph{spectrum efficiency} in the fifth-generation (5G) wireless network \nneeds to be accompanied by a call for improvement of \\emph{energy efficiency} to the same extent. \n\n\nCloud radio access network (C-RAN) is an emerging network architecture that shows significant promises in improving both the \nspectrum efficiency and the energy efficiency of current wireless networks \\cite{CRAN}. \nIn C-RAN, the BSs are connected to a central processor (CP) through backhaul links. \nThe benefits of the C-RAN architecture in energy saving are several-fold. \nFirst, under the C-RAN architecture, most of the baseband signal processing in traditional BSs \ncan be migrated to the cloud computing center \nso that the conventional high-cost high-power BSs can be replaced by low-cost low-power radio remote heads (RRHs). \nSecond, the existence of CP also allows for the joint precoding of user messages for interference mitigation. \nWith less interference generated, the transmit power at the BSs can therefore be reduced. \nThird, as on average (and especially during non-peak time) a significant portion of network resources can be idle \\cite{Correia10}, \nthe CP can perform joint resource allocation among the BSs to allocate resources on demand and put idle BSs into \nsleep mode for energy saving \\cite{Frenger11}. \n\n\nThe above-mentioned benefits of C-RAN in energy saving are concerned with the BS side. However, the additional energy consumption due to \nthe increased backhaul between the CP and the BSs also needs to be taken into account \\cite{Tombaz11}. \nIn this paper, we investigate the potential of C-RAN in improving energy efficiency of the \ncommunication aspect of the network by considering \nthe energy consumption due to BS activation, transmission, and backhaul provisioning. \nThe backhaul energy consumption depends on the backhaul rate, which further \ndepends on the interface between the CP and the BSs. \nIn this paper, we investigate two fundamental and different transmission strategies for the downlink C-RAN. \nIn the \\emph{data-sharing strategy}, the CP uses the backhaul links to share user messages to a cluster of cooperating BSs. \nThe backhaul cost of the data-sharing strategy depends on the number of BSs that the user messages need to be delivered to:\nlarger cluster size leads to larger cooperative gain, but also higher backhaul rate. \nIn an alternative strategy called the \\emph{compression strategy}, the CP performs joint precoding of the user messages centrally then forwards a compressed version of the \nprecoded signals to the BSs.\nThe backhaul cost of the compression strategy depends on the resolution of \nthe compressed signals: higher-resolution leads to better beamformers, but also larger backhaul rate. \n\nThis paper aims to quantify the energy saving of C-RAN while accounting for both the BS and the backhaul energy consumptions, and \nspecifically to answer the question of between the data-sharing strategy and the compression strategy, which one is more energy efficient? \nThe answer to this question is nontrivial as there are three factors that can lead to energy reduction: \ndecrease in BS transmit power, turning-off of the BSs, and reduction in backhaul rate. \nThese three factors are interrelated. For example, it may be beneficial to keep more BSs active and to allocate higher backhaul \nrate in order to allow for better cooperation among the BSs so that more interference can be mitigated. \nThis leads to less transmit power consumption, but it can also lead to higher BS and backhaul power consumption. \nThis paper intends to capture such interplay using an optimization framework. \nSpecifically, we propose a joint design of the BS transmit power, BS activation and backhaul by minimizing \nnetwork-wide power under given user rate constraints for both the data-sharing strategy and the compression strategy. \nThe resulting optimization problems are nonconvex in nature and are highly nontrivial to solve globally. \nThis paper approximates the problems using reweighted $\\ell_1$ minimization technique \\cite{Candes08} \nand successive convex approximation technique, and devises efficient algorithms with convergence guarantee. \nWe identify operating regimes where one strategy is superior to the other, and show that overall optimized C-RAN transmission can lead to \nmore energy efficient network operation than the non-optimized coordinated multi-point (CoMP) transmission. \n\n\n\n\\subsection{Related Work}\n\nThe potential of C-RAN in improving the performance for future wireless networks has \nattracted considerable attentions recently. \nIn the uplink, \\cite{Lei13} and \\cite{Yuhan14} show that with the capability of jointly decoding user messages in the CP, \nthe throughput of traditional cellular networks can be significantly improved. \nA similar conclusion also has been drawn in the downlink. \nIn particular, \\cite{Park13} proposes a joint design of beamforming and multivariate compression to \nmaximize the weighted sum rate for the compression strategy, while \n\\cite{hong12} and \\cite{BinbinSparseBFJnal} consider joint beamforming and BS clustering design to maximize the \nweighted sum rate for data-sharing. \n\n\nThis paper focuses on the energy efficiency of C-RAN in the downlink.  \nSeveral metrics have been proposed in the literature to measure the energy efficiency of a network. \nFor example, the area power consumption metric (watts$/$unit area) is proposed in \\cite{Richter09} to evaluate \nthe energy efficiency of networks of different cell site densities. \nAnother widely adopted measurement in energy efficiency is bits per joule metric, \nwhich has been studied in \\cite{Sarkiss12} under a simplified \nsingle-user-two-BSs model from an information-theoretical point of view and \nalso studied in \\cite{Schober12, Peng14, Huq14} for \northogonal frequency division multiple access (OFDMA) based cooperative networks from the practical system design point of view. \n\n\nIn this paper, we formulate the problem of minimizing the total required power for downlink C-RAN in order to \nprovide a given set of quality-of-service (QoS) targets for the scheduled users. \nSuch an optimization problem can also be thought of as minimizing watts per bit (or maximizing the bits per watt) at given user service rates. \nIn this domain, most of the previous works are restricted to the data-sharing strategy \\cite{Shi13, Rui14, Han14}. \nSpecifically, \\cite{Shi13} proposes a joint BS selection and beamforming design algorithm to minimize the total power consumption in the \ndownlink, while \\cite{Rui14} generalizes to a joint downlink and uplink total power minimization problem. \nBoth \\cite{Shi13} and \\cite{Rui14} take advantage of the fact that if a BS is not selected to serve any user at the current time slot, \nit can be put into low-power sleep mode for energy saving purpose.  \nIn contrast, \\cite{Han14} assumes fixed BS association but exploits the delay tolerance of the users to improve the energy efficiency \nin CoMP transmission. \nIn delay-tolerant applications, BSs can aggregate the user messages and transmit them with high rate during a short time frame while \nremain idle for the rest of the time slots under power-saving sleep mode. \nFast deactivation/activation of hardware power-consuming components achieve significant energy reductions \\cite{Frenger11, Kimmo13}. \n\n\n\nIn this paper, we adopt a similar energy saving perspective as in \\cite{Shi13} but consider in addition the compression strategy. \nCompression strategy differs from data-sharing strategy in the way that the backhaul is utilized. \nWe adopt the model proposed in \\cite{Fehske10} to model the power consumption of backhaul links as a linear function of backhaul rates. \nThis is in contrast to \\cite{Shi13}, where the backhaul power is modeled as a step function \nwith only two levels of power consumption depending on whether the backhaul link is active or not. \n\n\nIn addition to the backhaul power, we also consider the BS power consumption \nby adopting the model proposed in \\cite{Auer11}, which \napproximates the power consumption of a BS as a piecewise linear function of transmit power. \nIn such model, BS sleep mode corresponds to a constant but lower power consumption with zero transmit power. \nBS active mode corresponds to a higher constant power plus a nonzero transmit power. \nThe overall framework of this paper is a joint optimization of BS transmit power, BS activation and backhaul rate for both the compression and the data-sharing strategies. \n\n\nFrom the optimization perspective, the total power consumption for the data-sharing strategy \ninvolves a sum of weighted nonconvex $\\ell_0$-norms, \nwhich is highly nontrivial to optimize globally. \nInstead, we adopt the reweighted $\\ell_1$ technique \\cite{Candes08} to approximate \nthe nonconvex total power into a convex weighted sum of transmit power, \nwhere the weights are iteratively updated in a way to reduce not only the number of active BSs \nbut also the backhaul rate. \nSuch technique has also been applied to minimize the total backhaul rate in \\cite{Zhao12}, \nand to optimize the tradeoff between the total transmit power and total backhaul rate in \\cite{binbin13}. \nOn a related note, the discrete $\\ell_0$-norm can also be approximated using other tractable continuous functions such as \nGaussian-like function in \\cite{Zhuang14} and exponential function in \\cite{Vu14}. \nIt has been reported recently in \\cite{ZhouTaoChen} that \nthose approximation methods show similar effectiveness in inducing sparsity. \n\n\nFurther, the mathematical expression of the total power consumption for the compression strategy involves a difference of two logarithmic functions, \nwhich is also nonconvex. \nWe propose to approximate the first logarithmic function using the successive convex approximation technique, which transforms the objective function into a convex form. \nThe adopted reweighted $\\ell_1$ minimization technique and successive convex approximation technique in this paper are related to \nthe majorization-minimization (MM) algorithm \\cite{Bharath11}, \nwhich deals with an optimization problem with nonconvex objective function by successively solving a sequence of optimization \nproblems with approximate objective functions. \nThis paper utilizes the known sufficient conditions of convergence for the MM algorithm in the literature \\cite{Meisam13} \nto show the convergence of the proposed algorithms for both the data-sharing and the compression strategies. \n\n\n\nFinally, we mention that the data-sharing and compression strategies considered in this paper are not the only possibilities for the downlink of C-RAN. \nThere is a potential to combine these two strategies by sending directly the messages of only the strong users to the BSs and compressing the rest \\cite{Patil14}. \nAlso, reverse compute-and-forward strategy that accounts for the lattice nature of the transmitted message is also possible\n\\cite{HongCaire13}. However, such strategy is difficult to optimize because of the need in choosing the \nright integer zero-forcing precoding coefficients at the CP so that the effective noise, caused by the non-integer penalty due to practical channels, at each user is minimized. \n\n\n\n\n\n\\subsection{Main Contributions}\n\n\nThis paper considers energy-efficient design of the data-sharing strategy and the compression strategy for \ndownlink C-RAN by formulating a problem of minimizing the total network power consumption subject to user rate constraints. \nThe first contribution of this paper is the modeling of both the BS power and the \nbackhaul power consumption in the network. \nThe BS power consumption model includes a low-power sleep mode, while the backhaul power consumption \nis modeled as a linear function of backhaul traffic rate. \n\nFor the data-sharing strategy, we propose a novel application of reweighted $\\ell_1$ minimization technique to approximate the \nnonconvex BS activation power and backhaul power. \nSuch approximation technique reduces the nonconvex optimization problem to a conventional convex \ntransmit power minimization problem, \nwhich can be solved efficiently using the uplink-downlink duality approach or through transformation as \nsecond-order cone programming (SOCP). Moreover, we adopt a reweighting function that enables us to \nconnect the reweighted $\\ell_1$ minimization technique with the MM algorithm. \nThis connection allows us to prove the convergence behavior of the proposed algorithm for the data-sharing strategy.  \n\nFor the compression strategy, in addition to the reweighted $\\ell_1$ approximation to the BS activation power as in the data-sharing strategy, \nwe propose a successive convex approximation to the backhaul power, which is in a nonconvex form as \na difference of two logarithmic functions. \nThe proposed successive convex approximation technique and the reweighted $\\ell_1$ approximation technique can be \ncombined together. \nThe combined algorithm falls into the class of the MM algorithms and has convergence guarantee.  \n\n\nThrough simulations, we show that optimized data-sharing and compression strategies in C-RAN can bring much improved energy efficiency as compared to the non-optimized CoMP transmission.\nHowever, the comparative energy saving of data-sharing \nversus compression depends on the user target rates. \nThe energy efficiency of the data-sharing strategy is superior to that of the compression strategy in the low-rate regime. However, the  backhaul power consumption of the data-sharing strategy \nincreases significantly with the user rate. Thus, in high user rate regime, the compression strategy may be preferred from an energy saving perspective. \n\n\n\n\n\n\\subsection{Paper Organization and Notations}\n\nThe remainder of this paper is organized as follows. \nSection~\\ref{sec:SystemModel} introduces the system model and power consumption model considered throughout this paper. \nSection~\\ref{sec:data_sharing} considers the total power minimization under the data-sharing transmission strategy, while \nSection~\\ref{sec:compression} considers the compression strategy. \nSimulation results are presented in Section~\\ref{sec:simulations} and conclusions are drawn in Section~\\ref{sec:conclusion}. \n\n\nThroughout this paper, lower-case letters (e.g. $x$) and lower-case bold letters (e.g. $\\mathbf{x}$) denote scalars and column vectors \nrespectively. \nWe use $\\mathbb{C}$ to represent complex domain. \nThe transpose, conjugate transpose and $\\ell_p$-norm of a vector are denoted as $(\\cdot)^{T}$, $(\\cdot)^H$ and $\\Vert\\cdot\\Vert_p$ respectively. \nThe expectation of a random variable is denoted as $\\mathsf{E} \\left [ \\cdot \\right]$. \nCalligraphy letters are used to denote sets, while $|\\cdot|$ stands for either the size of a set or the absolute value of a  scalar, depending on the context. \n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{System and Power Consumption Model}\\label{sec:SystemModel}\n\nIn this section, we describe the overall system model and power consumption model for the downlink C-RAN \nconsidered throughout this paper. \n\n\n\n  \n  \n\n\n\n\n\n\n\\subsection{System Model}\n\n\nConsider a downlink C-RAN with $L$ BSs serving $K$ users. \nAll the BSs are connected to a CP via backhaul\\footnote{This paper refers the link between CP and BSs as \\emph{backhaul}, which \nis appropriate if the data-sharing strategy is used. \nHowever, in a C-RAN architecture implementing the compression strategy where the BSs are simply RRHs, \nthe connection between RRH and CP can be referred to more appropriately as \\emph{fronthaul}.} links and each user  receives a single independent data stream from the BSs. \nAll the user messages are assumed to be available at the CP and are jointly processed before being forwarded to the BSs through the backhaul links. \nWe assume that the CP has access to global channel state information (CSI) but point out that such assumption can be relaxed so that \nonly the CSI from the neighboring BSs of each user is needed in the CP. \n\n\nTo simplify notations and ease analysis, we assume that the BSs and the users are equipped with a single antenna each, although the \nproposed algorithms in this paper can be easily generalized to the case of multi-antenna BSs as discussed later in the paper.  \nLet $x_l \\in \\mathbb{C}$ denote the transmit signal at BS $l$, we can write the received signal $y_k \\in \\mathbb{C}$ at user $k$ as \n\n", "index": 1, "text": "\\begin{equation}\\label{eq:yk_general}\ny_k = \\mathbf{h}_k^{H} \\mathbf{x} + n_k, \\quad k \\in  \\mathcal{K} = \\left\\{1, 2, \\cdots, K\\right\\}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"y_{k}=\\mathbf{h}_{k}^{H}\\mathbf{x}+n_{k},\\quad k\\in\\mathcal{K}=\\left\\{1,2,%&#10;\\cdots,K\\right\\}\" display=\"block\"><mrow><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><mrow><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><mi>\ud835\udc31</mi></mrow><mo>+</mo><msub><mi>n</mi><mi>k</mi></msub></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mo>=</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>,</mo><mi>K</mi><mo>}</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $P_l$ is the transmit power budget available at BS $l$. \nHowever, a full characterization of power consumption at a BS should also consider the efficiency of the power amplifier and \nother power-consuming components such as baseband unit, cooling system, etc. \nIn addition, the power consumption of backhaul links connecting the BSs to the CP also needs to be taken into account for the specific \nC-RAN architecture considered in this paper. \nIn the following, we describe the power consumption model adopted in this paper for the BSs and the backhaul links respectively. \n\n\n\n\\subsubsection{Base-Station Power Consumption}\n\nThe characteristic of power-consuming components in a BS depends on the BS design. \nWe adopt the following unified power consumption model proposed in \\cite{Auer11}, which is applicable for different types of BSs. \nThis model approximates the BS power consumption as a piecewise linear function of the transmit power $P_{l, tx}$: \n\n", "itemtype": "equation", "pos": 21255, "prevtext": "\nwhere $\\mathbf{x} = \\left[x_1, x_2, \\cdots, x_L\\right]^{T}$ is the vector of transmit signals across all the $L$ BSs and \n$\\mathbf{h}_k \\in \\mathbb{C}^{L \\times 1}$ is the vector of channel gains from all the $L$ BSs to user $k$. \nThe received noise $n_k$ is modeled as a complex Gaussian random variable with zero mean and variance $\\sigma^2$. \nEach user decodes its own message $s_k \\in \\mathbb{C}$ from the received signal $y_k$. \n\n\n\n\nIn this paper, we investigate two fundamental but different transmission strategies, \nthe data-sharing strategy and the compression strategy, for the downlink C-RAN for delivering the message $s_k$ to user $k$ \nvia the transmit signal $\\mathbf{x}$ from the BSs. \nIn particular, we compare the potential of these two strategies in improving the energy efficiency. \nBefore discussing the details of the two strategies, we first describe the power consumption model adopted in this paper. \n\n\n\n\n\\subsection{Power Consumption Model}\n\nTraditional cellular network transmission strategy design typically only considers transmit power at each BS, which is written as \n\n", "index": 3, "text": "\\begin{equation}\\label{eq:TxPower}\nP_{l, tx} = \\mathsf{E} \\left[ \\vert x_l \\vert^{2} \\right] \\leq P_l, \\quad l \\in \\mathcal{L} = \\left\\{1, 2, \\cdots, L\\right\\}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"P_{l,tx}=\\mathsf{E}\\left[|x_{l}|^{2}\\right]\\leq P_{l},\\quad l\\in\\mathcal{L}=%&#10;\\left\\{1,2,\\cdots,L\\right\\},\" display=\"block\"><mrow><mrow><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>=</mo><mrow><mi>\ud835\udda4</mi><mo>\u2062</mo><mrow><mo>[</mo><msup><mrow><mo stretchy=\"false\">|</mo><msub><mi>x</mi><mi>l</mi></msub><mo stretchy=\"false\">|</mo></mrow><mn>2</mn></msup><mo>]</mo></mrow></mrow><mo>\u2264</mo><msub><mi>P</mi><mi>l</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi><mo>=</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>,</mo><mi>L</mi><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\eta_l > 0$ is a constant reflecting the power amplifier efficiency, feeder loss and other loss factors due to power supply and cooling for BS $l$, \n$P_{l, tx}$ is the transmit power defined in \\eqref{eq:TxPower} and $P_{l, active}$ is the minimum power required to support BS $l$ with \nnon-zero transmit power. If BS $l$ has nothing to transmit, it can be put into sleep mode with low power consumption $P_{l, sleep}$. \nTypically, $P_{l, sleep} < P_{l, active}$ so that it is beneficial to turn BSs into sleep mode, whenever possible, \nfor energy-saving purpose. \n\n\n\n\\subsubsection{Backhaul Power Consumption}\n\n\nIn C-RAN, the BSs are connected to the CP with the backhaul links. \nThe power consumption due to backhaul links varies with different backhaul technologies. \nIn this paper, we model the backhaul as a set of communication channels, each with \ncapacity $C_l$ and power dissipation $P_{l,max}^{BH}$, and write the backhaul power consumption as \n\n", "itemtype": "equation", "pos": 22393, "prevtext": "\nwhere $P_l$ is the transmit power budget available at BS $l$. \nHowever, a full characterization of power consumption at a BS should also consider the efficiency of the power amplifier and \nother power-consuming components such as baseband unit, cooling system, etc. \nIn addition, the power consumption of backhaul links connecting the BSs to the CP also needs to be taken into account for the specific \nC-RAN architecture considered in this paper. \nIn the following, we describe the power consumption model adopted in this paper for the BSs and the backhaul links respectively. \n\n\n\n\\subsubsection{Base-Station Power Consumption}\n\nThe characteristic of power-consuming components in a BS depends on the BS design. \nWe adopt the following unified power consumption model proposed in \\cite{Auer11}, which is applicable for different types of BSs. \nThis model approximates the BS power consumption as a piecewise linear function of the transmit power $P_{l, tx}$: \n\n", "index": 5, "text": "\\begin{equation} \\label{eq:bs_power}\nP_{l}^{BS} = \\left \\{\n   \\begin{array}{ll}\n\t \\eta_l P_{l, tx} + P_{l, active}, & \\text{if} ~ 0 < P_{l, tx} \\leq P_l \\\\\n\t P_{l, sleep}, & \\text{if} ~ P_{l, tx} = 0\n\t \\end{array}\n  \\right. \\hspace{-3mm}, ~ l \\in \\mathcal{L}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"P_{l}^{BS}=\\left\\{\\begin{array}[]{ll}\\eta_{l}P_{l,tx}+P_{l,active},&amp;\\text{if}~%&#10;{}0&lt;P_{l,tx}\\leq P_{l}\\\\&#10;P_{l,sleep},&amp;\\text{if}~{}P_{l,tx}=0\\end{array}\\right.\\hskip-8.535827pt,~{}l\\in%&#10;\\mathcal{L}\" display=\"block\"><mrow><mrow><msubsup><mi>P</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>S</mi></mrow></msubsup><mo>=</mo><mrow><mo>{</mo><mpadded width=\"-8.5pt\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msub><mi>\u03b7</mi><mi>l</mi></msub><mo>\u2062</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub></mrow><mo>+</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>a</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><mi>e</mi></mrow></mrow></msub></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+3.3pt\"><mtext>if</mtext></mpadded><mo>\u2062</mo><mn>0</mn></mrow><mo>&lt;</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>\u2264</mo><msub><mi>P</mi><mi>l</mi></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>s</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>p</mi></mrow></mrow></msub><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+3.3pt\"><mtext>if</mtext></mpadded><mo>\u2062</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub></mrow><mo>=</mo><mn>0</mn></mrow></mtd></mtr></mtable></mpadded><mi/></mrow></mrow><mo rspace=\"5.8pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\rho_l = P_{l,max}^{BH} / C_l$ is a constant scaling factor and $R_l^{BH}$ is the backhaul traffic between BS $l$ and the CP.\nThis model has been used in \\cite{Fehske10} for microwave backhaul links and can also be generalized to other \nbackhaul technologies, such as passive optical network, fiber-based Ethernet, etc., as mentioned in \\cite{wu2012green}. \nNote that \\cite{Shi13} also considers the sleep mode capability for backhaul links. We point out that \nsuch consideration can be unified with \n$P_{l, active}$ and $P_{l, sleep}$ in the BS power consumption model \\eqref{eq:bs_power}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Total Power Consumption}\n\nBased on the above BS power consumption model \\eqref{eq:bs_power} and backhaul power consumption model \\eqref{eq:bkhaul_power}, \nwe can write the total power consumption $P_{total}$ for C-RAN as\n\n", "itemtype": "equation", "pos": 23629, "prevtext": "\nwhere $\\eta_l > 0$ is a constant reflecting the power amplifier efficiency, feeder loss and other loss factors due to power supply and cooling for BS $l$, \n$P_{l, tx}$ is the transmit power defined in \\eqref{eq:TxPower} and $P_{l, active}$ is the minimum power required to support BS $l$ with \nnon-zero transmit power. If BS $l$ has nothing to transmit, it can be put into sleep mode with low power consumption $P_{l, sleep}$. \nTypically, $P_{l, sleep} < P_{l, active}$ so that it is beneficial to turn BSs into sleep mode, whenever possible, \nfor energy-saving purpose. \n\n\n\n\\subsubsection{Backhaul Power Consumption}\n\n\nIn C-RAN, the BSs are connected to the CP with the backhaul links. \nThe power consumption due to backhaul links varies with different backhaul technologies. \nIn this paper, we model the backhaul as a set of communication channels, each with \ncapacity $C_l$ and power dissipation $P_{l,max}^{BH}$, and write the backhaul power consumption as \n\n", "index": 7, "text": "\\begin{equation}\\label{eq:bkhaul_power}\nP_l^{BH} = \\frac{R_l^{BH}}{C_l} P_{l,max}^{BH} = \\rho_l R_l^{BH}, \\quad l \\in \\mathcal{L}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"P_{l}^{BH}=\\frac{R_{l}^{BH}}{C_{l}}P_{l,max}^{BH}=\\rho_{l}R_{l}^{BH},\\quad l%&#10;\\in\\mathcal{L}\" display=\"block\"><mrow><mrow><msubsup><mi>P</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup><mo>=</mo><mrow><mfrac><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup><msub><mi>C</mi><mi>l</mi></msub></mfrac><mo>\u2062</mo><msubsup><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup></mrow><mo>=</mo><mrow><msub><mi>\u03c1</mi><mi>l</mi></msub><mo>\u2062</mo><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\mathbbm{1}_{\\left\\{ \\cdot \\right\\}}$ is the indicator function defined as \n\n", "itemtype": "equation", "pos": 24622, "prevtext": "\nwhere $\\rho_l = P_{l,max}^{BH} / C_l$ is a constant scaling factor and $R_l^{BH}$ is the backhaul traffic between BS $l$ and the CP.\nThis model has been used in \\cite{Fehske10} for microwave backhaul links and can also be generalized to other \nbackhaul technologies, such as passive optical network, fiber-based Ethernet, etc., as mentioned in \\cite{wu2012green}. \nNote that \\cite{Shi13} also considers the sleep mode capability for backhaul links. We point out that \nsuch consideration can be unified with \n$P_{l, active}$ and $P_{l, sleep}$ in the BS power consumption model \\eqref{eq:bs_power}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Total Power Consumption}\n\nBased on the above BS power consumption model \\eqref{eq:bs_power} and backhaul power consumption model \\eqref{eq:bkhaul_power}, \nwe can write the total power consumption $P_{total}$ for C-RAN as\n\n", "index": 9, "text": "\\begin{align}\\label{eq:total_power}\nP_{total} \n& = \\sum_{l \\in \\mathcal{L}} \\left( P_{l}^{BS} + P_l^{BH} \\right)\\nonumber \\\\ \n& = \\sum_{l \\in \\mathcal{L}} \\bigg( \\eta_l P_{l, tx} + \\mathbbm{1}_{\\left\\{ P_{l, tx} \\right\\}} \\left( P_{l, active} -  P_{l, sleep}  \\right) \\nonumber \\\\ \n& \\hspace{4.5cm} + P_{l, sleep} + \\rho_l R_l^{BH} \\bigg) \\nonumber \\\\\n& = \\sum_{l \\in \\mathcal{L}} \\bigg( \\eta_l P_{l, tx} + \\mathbbm{1}_{\\left\\{ P_{l, tx} \\right\\}} P_{l, \\Delta} + \\rho_l R_l^{BH} \\bigg) \\nonumber \\\\ \n& \\hspace{4.5cm} + \\underbrace{\\sum_{l \\in \\mathcal{L}} P_{l, sleep}}_{\\text{constant}}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P_{total}\" display=\"inline\"><msub><mi>P</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{l\\in\\mathcal{L}}\\left(P_{l}^{BS}+P_{l}^{BH}\\right)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo>(</mo><mrow><msubsup><mi>P</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>S</mi></mrow></msubsup><mo>+</mo><msubsup><mi>P</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{l\\in\\mathcal{L}}\\bigg{(}\\eta_{l}P_{l,tx}+\\mathbbm{1}_{%&#10;\\left\\{P_{l,tx}\\right\\}}\\left(P_{l,active}-P_{l,sleep}\\right)\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>+</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>}</mo></mrow></msub><mrow><mo>(</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>a</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><mi>e</mi></mrow></mrow></msub><mo>-</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>s</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>p</mi></mrow></mrow></msub><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+P_{l,sleep}+\\rho_{l}R_{l}%&#10;^{BH}\\bigg{)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>s</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>p</mi></mrow></mrow></msub><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{l\\in\\mathcal{L}}\\bigg{(}\\eta_{l}P_{l,tx}+\\mathbbm{1}_{%&#10;\\left\\{P_{l,tx}\\right\\}}P_{l,\\Delta}+\\rho_{l}R_{l}^{BH}\\bigg{)}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><mrow><msub><mi>\u03b7</mi><mi>l</mi></msub><mo>\u2062</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub></mrow><mo>+</mo><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>}</mo></mrow></msub><mo>\u2062</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub></mrow><mo>+</mo><mrow><msub><mi>\u03c1</mi><mi>l</mi></msub><mo>\u2062</mo><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\underbrace{\\sum_{l\\in%&#10;\\mathcal{L}}P_{l,sleep}}_{\\text{constant}}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><munder><munder accentunder=\"true\"><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo movablelimits=\"false\">\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><msub><mi>P</mi><mrow><mi>l</mi><mo movablelimits=\"false\">,</mo><mrow><mi>s</mi><mo movablelimits=\"false\">\u2062</mo><mi>l</mi><mo movablelimits=\"false\">\u2062</mo><mi>e</mi><mo movablelimits=\"false\">\u2062</mo><mi>e</mi><mo movablelimits=\"false\">\u2062</mo><mi>p</mi></mrow></mrow></msub></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mtext>constant</mtext></munder></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nand $P_{l, \\Delta} = P_{l, active} -  P_{l, sleep}$ is the difference between the minimum active BS power consumption and the \nsleep mode BS power consumption. \n\nAs we can see from \\eqref{eq:total_power}, there are three possibilities in improving the energy efficiency of C-RAN: \nreducing the transmit power, putting BSs into sleep mode, and decreasing the backhaul traffic. \nHowever, these three aspects cannot be realized simultaneously: deactivating more BSs means reduced capability for interference \nmitigation among the active BSs, which leads to higher transmit power in order to maintain the QoS for the users; \nhigher backhaul rate can allow for more user information being shared among the BSs so that the BSs can better \ncooperate to mitigate interference, thus less transmit power may be needed. \nA joint design is necessary in order to balance the roles of transmit power, BS activation and backhaul traffic rate in achieving \nenergy efficiency. \nIn the following, we describe the general problem formulation considered in this paper for such joint design used in both the \ndata-sharing and the compression strategies. \n\n\n\n\n\n\n\\subsection{Energy Efficiency Maximization}\n\nThis paper aims to understand the energy efficiency for downlink C-RAN, which can be defined as \nthe ratio of the achievable sum rate and the sum power consumption, i.e. $\\frac{\\sum_{k} R_k}{P_{total}}$ \nwhere $R_k$ is the data rate for user $k$ determined by the specific transmission strategy \nand $P_{total}$ is the total consumed power defined in \\eqref{eq:total_power}. \nTowards this end, this paper takes the similar approach as in \\cite{Han14} to fix the service rates of scheduled users \nand consider the minimization of total power consumption: \n\n", "itemtype": "equation", "pos": 25306, "prevtext": "\nwhere $\\mathbbm{1}_{\\left\\{ \\cdot \\right\\}}$ is the indicator function defined as \n\n", "index": 11, "text": "\\begin{equation}\\label{eq:indicator}\n \\mathbbm{1}_{\\left\\{x\\right\\}}  = \\left \\{\n   \\begin{array}{l}\n\t 1, \\quad \\text{if} ~ x > 0 \\\\\n\t 0, \\quad \\text{otherwise} \n\t \\end{array}\n  \\right. , \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\mathbbm{1}_{\\left\\{x\\right\\}}=\\left\\{\\begin{array}[]{l}1,\\quad\\text{if}~{}x&gt;0%&#10;\\\\&#10;0,\\quad\\text{otherwise}\\end{array}\\right.,\" display=\"block\"><mrow><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mi>x</mi><mo>}</mo></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mn>1</mn><mo rspace=\"12.5pt\">,</mo><mrow><mpadded width=\"+3.3pt\"><mtext>if</mtext></mpadded><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo>&gt;</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mn>0</mn><mo rspace=\"12.5pt\">,</mo><mtext>otherwise</mtext></mrow></mtd></mtr></mtable><mi/></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $r_k$ is the fixed target rate for user $k$. \nThe solution to the above problem gives us the energy efficiency $\\frac{\\sum_{k} R_k}{P_{total}}$ of the system \nat the operating point $\\left(r_1, r_2, \\cdots, r_K \\right)$. \nTo maximize energy efficiency, we need to further search over all operating points. \nFor the rest of the paper, we study and compare the minimum required total power for different transmission strategies under the same operating point $\\left(r_1, r_2, \\cdots, r_K \\right)$ in the downlink of C-RAN. \nNote that problem \\eqref{prob:power_min} implicitly assumes fixed user scheduling. \nThere also exists a possibility of doing joint user scheduling and power minimization \nby considering a problem of minimizing the total power consumption across \\emph{multiple time slots} subject to a minimum target \nfor each user's \\emph{average} rate. Such problem is considerably more complicated. \n\n\n\n\\subsection{Data-Sharing versus Compression}\n\n\nData-sharing and compression are two \nfundamentally different transmission strategies for the downlink of C-RAN for delivering data to the users. \nThese two strategies correspond to alternative functional splits in C-RAN.\nIn the data-sharing transmission strategy, the CP routes each scheduled user's intended message to a cluster of BSs \nthrough the backhaul links; the cluster of BSs then cooperatively serve that user through joint beamforming. \nIn contrast, in the compression strategy, the precoding operation is implemented centrally at the CP, which then \nforwards a compressed version of the analog beamformed signal to the BSs through the backhaul/fronthaul links. \nThe BSs then simply transmit the compressed beamforming signals to the users \\cite{Park13, Patil14, PratikEUSIPCO}. \n\n\n\n\n\n\n\nThe data-sharing strategy differs from the compression strategy in backhaul utilization.  \nIn data-sharing, the backhaul rate is a function of the user message rate and the BS cluster size, \nwhile in the compression strategy the backhaul cost is determined by the compression resolution. \nIntuitively, as the user target rate and BS cluster size increase, the backhaul rate for the data-sharing strategy \nwould increase significantly, leading to high energy consumption. \nHowever, in the low user rate regime where the BS cluster size is small, data-sharing can be more efficient than compression as the latter suffers from quantization noise. \nTherefore, there exists a tradeoff between data-sharing and compression in terms of backhaul rate \nand energy efficiency at different user target rate operating points. \nIn the following two sections, we describe in details the data-sharing strategy and the compression strategy, and propose \ncorresponding algorithms to find the minimum required total power for each strategy. \n \n\nThroughout this paper, we primarily account for the energy consumption due to \n\\emph{communications} in either the backhaul or the transmission front-end at the BSs, \nrather than the energy consumption due to \\emph{computing}. \nThere is significant additional energy saving due to migrating signal processing from \nthe BSs to the cloud computer center in the C-RAN architecture. We refer the readers to \\cite{Chen14}.\n\n\n\n\\section{Data-Sharing Strategy}\\label{sec:data_sharing}\n\n\\begin{figure}[!t]\n  \\centering\n\t\\psfrag{p}[tc][Bc][1]{Central Processor}\n\t\\psfrag{q}[tc][Bc][1]{$s_1, s_2$}\n\t\\psfrag{a}[tc][cc][1]{$s_1$}\n\t\\psfrag{b}[tc][cc][1]{$s_2$}\n\t\\psfrag{i}[tl][tl][0.7]{$R_1^{BH} = R_1$}\n\t\\psfrag{j}[tl][tl][0.7]{$R_2^{BH} = $}\n\t\\psfrag{w}[tl][tl][0.7]{$R_1 + R_2$}\n\t\\psfrag{k}[tl][tl][0.7]{$R_3^{BH} = R_2$}\n\t\\psfrag{x}[tc][cl][0.8]{$x_1 = w_{11}s_1$}\n\t\\psfrag{y}[tc][cl][0.8]{$x_2 = w_{21}s_1$}\n\t\\psfrag{h}[tc][tl][0.8]{$+ w_{22}s_2$}\n\t\\psfrag{z}[tc][cl][0.8]{$x_3 = w_{32}s_2$}\n\t\\psfrag{m}[tc][tc][0.9]{BS $1$}\n\t\\psfrag{e}[tc][tc][0.9]{BS $2$}\n\t\\psfrag{g}[tc][tc][0.9]{BS $3$}\n\t\\psfrag{n}[tc][tc][0.9]{User $1$}\n\t\\psfrag{f}[tc][tc][0.9]{User $2$}\n\t\n  \\includegraphics[width= 0.45\\textwidth]{DataSharingModelFinal.eps}\n\\caption{Downlink C-RAN with data-sharing transmission strategy. In this illustrative example, the CP transmits \nuser $1$'s message $s_1$ to BSs $1$ and $2$, and user $2$'s message $s_2$ to BSs $2$ and $3$. \nThe BS cluster $(1, 2)$ then cooperatively serves user $1$ and the BS cluster $(2, 3)$ cooperatively serves user $2$ through joint beamforming.}\n\\label{fig:DataSharingModel} \n\\end{figure}\n\n \nIn this section, we study the minimum total power required for the data-sharing strategy \nin order to support the given scheduled users at guaranteed service rates. \n\n\n\\subsection{Problem Formulation}\n\nConsider the data-sharing transmission strategy for the downlink of C-RAN as illustrated \nin Fig.~\\ref{fig:DataSharingModel}, where the each user's message is shared among a cluster of serving BSs. \nLet $w_{lk} \\in \\mathbb{C}$ be the beamforming coefficient for BS $l$ to serve user $k$. \nIf BS $l$ is not part of user $k$'s serving cluster, $w_{lk}$ is set to be zero. \nThe transmit signal $x_l$ at BS $l$ can be written as $x_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$. \nWe model the user messages $s_k$'s as independent and identically distributed complex Gaussian \nrandom variables with zero mean and unit variance. The transmit power $P_{l, tx}$ formulated in \\eqref{eq:TxPower} can be written as \n\n", "itemtype": "equation", "pos": 27250, "prevtext": "\nand $P_{l, \\Delta} = P_{l, active} -  P_{l, sleep}$ is the difference between the minimum active BS power consumption and the \nsleep mode BS power consumption. \n\nAs we can see from \\eqref{eq:total_power}, there are three possibilities in improving the energy efficiency of C-RAN: \nreducing the transmit power, putting BSs into sleep mode, and decreasing the backhaul traffic. \nHowever, these three aspects cannot be realized simultaneously: deactivating more BSs means reduced capability for interference \nmitigation among the active BSs, which leads to higher transmit power in order to maintain the QoS for the users; \nhigher backhaul rate can allow for more user information being shared among the BSs so that the BSs can better \ncooperate to mitigate interference, thus less transmit power may be needed. \nA joint design is necessary in order to balance the roles of transmit power, BS activation and backhaul traffic rate in achieving \nenergy efficiency. \nIn the following, we describe the general problem formulation considered in this paper for such joint design used in both the \ndata-sharing and the compression strategies. \n\n\n\n\n\n\n\\subsection{Energy Efficiency Maximization}\n\nThis paper aims to understand the energy efficiency for downlink C-RAN, which can be defined as \nthe ratio of the achievable sum rate and the sum power consumption, i.e. $\\frac{\\sum_{k} R_k}{P_{total}}$ \nwhere $R_k$ is the data rate for user $k$ determined by the specific transmission strategy \nand $P_{total}$ is the total consumed power defined in \\eqref{eq:total_power}. \nTowards this end, this paper takes the similar approach as in \\cite{Han14} to fix the service rates of scheduled users \nand consider the minimization of total power consumption: \n\n", "index": 13, "text": "\\begin{align} \\label{prob:power_min}\n{\\operatorname{minimize}} & \\quad  P_{total} \\\\\n {\\operatorname{subject \\text{ } to}} & \\quad R_k \\geq r_k, \\quad \\forall k \\in \\mathcal{K} \\nonumber \\\\\n& \\quad \\mathsf{E} \\left[ \\vert x_l \\vert^{2} \\right] \\leq P_l, \\quad \\forall l \\in \\mathcal{L} \\nonumber \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{minimize}}\" display=\"inline\"><mo>minimize</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad P_{total}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><msub><mi>P</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi></mrow></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad R_{k}\\geq r_{k},\\quad\\forall k\\in\\mathcal{K}\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><msub><mi>R</mi><mi>k</mi></msub></mrow><mo>\u2265</mo><msub><mi>r</mi><mi>k</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mi>k</mi></mrow><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\mathsf{E}\\left[|x_{l}|^{2}\\right]\\leq P_{l},\\quad\\forall l%&#10;\\in\\mathcal{L}\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mi>\ud835\udda4</mi><mo>\u2062</mo><mrow><mo>[</mo><msup><mrow><mo stretchy=\"false\">|</mo><msub><mi>x</mi><mi>l</mi></msub><mo stretchy=\"false\">|</mo></mrow><mn>2</mn></msup><mo>]</mo></mrow></mrow><mo>\u2264</mo><msub><mi>P</mi><mi>l</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mi>l</mi></mrow><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\nSubstituting $x_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$ into \\eqref{eq:yk_general}, the received signal $y_k$ at user $k$ is \n\n", "itemtype": "equation", "pos": 32874, "prevtext": "\nwhere $r_k$ is the fixed target rate for user $k$. \nThe solution to the above problem gives us the energy efficiency $\\frac{\\sum_{k} R_k}{P_{total}}$ of the system \nat the operating point $\\left(r_1, r_2, \\cdots, r_K \\right)$. \nTo maximize energy efficiency, we need to further search over all operating points. \nFor the rest of the paper, we study and compare the minimum required total power for different transmission strategies under the same operating point $\\left(r_1, r_2, \\cdots, r_K \\right)$ in the downlink of C-RAN. \nNote that problem \\eqref{prob:power_min} implicitly assumes fixed user scheduling. \nThere also exists a possibility of doing joint user scheduling and power minimization \nby considering a problem of minimizing the total power consumption across \\emph{multiple time slots} subject to a minimum target \nfor each user's \\emph{average} rate. Such problem is considerably more complicated. \n\n\n\n\\subsection{Data-Sharing versus Compression}\n\n\nData-sharing and compression are two \nfundamentally different transmission strategies for the downlink of C-RAN for delivering data to the users. \nThese two strategies correspond to alternative functional splits in C-RAN.\nIn the data-sharing transmission strategy, the CP routes each scheduled user's intended message to a cluster of BSs \nthrough the backhaul links; the cluster of BSs then cooperatively serve that user through joint beamforming. \nIn contrast, in the compression strategy, the precoding operation is implemented centrally at the CP, which then \nforwards a compressed version of the analog beamformed signal to the BSs through the backhaul/fronthaul links. \nThe BSs then simply transmit the compressed beamforming signals to the users \\cite{Park13, Patil14, PratikEUSIPCO}. \n\n\n\n\n\n\n\nThe data-sharing strategy differs from the compression strategy in backhaul utilization.  \nIn data-sharing, the backhaul rate is a function of the user message rate and the BS cluster size, \nwhile in the compression strategy the backhaul cost is determined by the compression resolution. \nIntuitively, as the user target rate and BS cluster size increase, the backhaul rate for the data-sharing strategy \nwould increase significantly, leading to high energy consumption. \nHowever, in the low user rate regime where the BS cluster size is small, data-sharing can be more efficient than compression as the latter suffers from quantization noise. \nTherefore, there exists a tradeoff between data-sharing and compression in terms of backhaul rate \nand energy efficiency at different user target rate operating points. \nIn the following two sections, we describe in details the data-sharing strategy and the compression strategy, and propose \ncorresponding algorithms to find the minimum required total power for each strategy. \n \n\nThroughout this paper, we primarily account for the energy consumption due to \n\\emph{communications} in either the backhaul or the transmission front-end at the BSs, \nrather than the energy consumption due to \\emph{computing}. \nThere is significant additional energy saving due to migrating signal processing from \nthe BSs to the cloud computer center in the C-RAN architecture. We refer the readers to \\cite{Chen14}.\n\n\n\n\\section{Data-Sharing Strategy}\\label{sec:data_sharing}\n\n\\begin{figure}[!t]\n  \\centering\n\t\\psfrag{p}[tc][Bc][1]{Central Processor}\n\t\\psfrag{q}[tc][Bc][1]{$s_1, s_2$}\n\t\\psfrag{a}[tc][cc][1]{$s_1$}\n\t\\psfrag{b}[tc][cc][1]{$s_2$}\n\t\\psfrag{i}[tl][tl][0.7]{$R_1^{BH} = R_1$}\n\t\\psfrag{j}[tl][tl][0.7]{$R_2^{BH} = $}\n\t\\psfrag{w}[tl][tl][0.7]{$R_1 + R_2$}\n\t\\psfrag{k}[tl][tl][0.7]{$R_3^{BH} = R_2$}\n\t\\psfrag{x}[tc][cl][0.8]{$x_1 = w_{11}s_1$}\n\t\\psfrag{y}[tc][cl][0.8]{$x_2 = w_{21}s_1$}\n\t\\psfrag{h}[tc][tl][0.8]{$+ w_{22}s_2$}\n\t\\psfrag{z}[tc][cl][0.8]{$x_3 = w_{32}s_2$}\n\t\\psfrag{m}[tc][tc][0.9]{BS $1$}\n\t\\psfrag{e}[tc][tc][0.9]{BS $2$}\n\t\\psfrag{g}[tc][tc][0.9]{BS $3$}\n\t\\psfrag{n}[tc][tc][0.9]{User $1$}\n\t\\psfrag{f}[tc][tc][0.9]{User $2$}\n\t\n  \\includegraphics[width= 0.45\\textwidth]{DataSharingModelFinal.eps}\n\\caption{Downlink C-RAN with data-sharing transmission strategy. In this illustrative example, the CP transmits \nuser $1$'s message $s_1$ to BSs $1$ and $2$, and user $2$'s message $s_2$ to BSs $2$ and $3$. \nThe BS cluster $(1, 2)$ then cooperatively serves user $1$ and the BS cluster $(2, 3)$ cooperatively serves user $2$ through joint beamforming.}\n\\label{fig:DataSharingModel} \n\\end{figure}\n\n \nIn this section, we study the minimum total power required for the data-sharing strategy \nin order to support the given scheduled users at guaranteed service rates. \n\n\n\\subsection{Problem Formulation}\n\nConsider the data-sharing transmission strategy for the downlink of C-RAN as illustrated \nin Fig.~\\ref{fig:DataSharingModel}, where the each user's message is shared among a cluster of serving BSs. \nLet $w_{lk} \\in \\mathbb{C}$ be the beamforming coefficient for BS $l$ to serve user $k$. \nIf BS $l$ is not part of user $k$'s serving cluster, $w_{lk}$ is set to be zero. \nThe transmit signal $x_l$ at BS $l$ can be written as $x_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$. \nWe model the user messages $s_k$'s as independent and identically distributed complex Gaussian \nrandom variables with zero mean and unit variance. The transmit power $P_{l, tx}$ formulated in \\eqref{eq:TxPower} can be written as \n\n", "index": 15, "text": "\\begin{equation}\\label{eq:Tx_power_data_sharing}\nP_{l, tx} = \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}, \\quad l \\in \\mathcal{L}. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"P_{l,tx}=\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2},\\quad l\\in\\mathcal{L}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\mathbf{w}_k = \\left[w_{1k}, w_{2k}, \\cdots, w_{Lk}  \\right]^{T}$ is the network beamformer for user $k$. \nBased on \\eqref{eq:y_k_data_sharing}, the received signal-to-interference-plus-noise ratio (SINR) at user $k$ can be expressed as \n\n", "itemtype": "equation", "pos": 33164, "prevtext": "\n\nSubstituting $x_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$ into \\eqref{eq:yk_general}, the received signal $y_k$ at user $k$ is \n\n", "index": 17, "text": "\\begin{equation}\\label{eq:y_k_data_sharing}\ny_k = \\mathbf{h}_k^{H} \\mathbf{w}_k s_k + \\sum_{j \\neq k}\\mathbf{h}_k^{H} \\mathbf{w}_j s_j + n_k, \\quad k \\in \\mathcal{K}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"y_{k}=\\mathbf{h}_{k}^{H}\\mathbf{w}_{k}s_{k}+\\sum_{j\\neq k}\\mathbf{h}_{k}^{H}%&#10;\\mathbf{w}_{j}s_{j}+n_{k},\\quad k\\in\\mathcal{K},\" display=\"block\"><mrow><mrow><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><mrow><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>k</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>k</mi></msub></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>k</mi></mrow></munder><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow><mo>+</mo><msub><mi>n</mi><mi>k</mi></msub></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nand the achievable rate for user $k$ is then\n\n", "itemtype": "equation", "pos": 33592, "prevtext": "\nwhere $\\mathbf{w}_k = \\left[w_{1k}, w_{2k}, \\cdots, w_{Lk}  \\right]^{T}$ is the network beamformer for user $k$. \nBased on \\eqref{eq:y_k_data_sharing}, the received signal-to-interference-plus-noise ratio (SINR) at user $k$ can be expressed as \n\n", "index": 19, "text": "\\begin{equation}\n\t\t\\text{SINR}_k =\n\\frac{\\left\\vert\\mathbf{h}_k^{H}\\mathbf{w}_k \\right\\vert^2}{\\sum_{j \\neq\nk}\\left\\vert\\mathbf{h}_k^{H}\\mathbf{w}_j\\right\\vert^2 + \\sigma^2}, \\quad k \\in \\mathcal{K}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\text{SINR}_{k}=\\frac{\\left|\\mathbf{h}_{k}^{H}\\mathbf{w}_{k}\\right|^{2}}{\\sum_%&#10;{j\\neq k}\\left|\\mathbf{h}_{k}^{H}\\mathbf{w}_{j}\\right|^{2}+\\sigma^{2}},\\quad k%&#10;\\in\\mathcal{K}\" display=\"block\"><mrow><mrow><msub><mtext>SINR</mtext><mi>k</mi></msub><mo>=</mo><mfrac><msup><mrow><mo>|</mo><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>k</mi></msub></mrow><mo>|</mo></mrow><mn>2</mn></msup><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>k</mi></mrow></msub><msup><mrow><mo>|</mo><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>j</mi></msub></mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mfrac></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\Gamma_m$ stands for the signal-to-noise ratio (SNR) gap due to practical modulation scheme. \n\n\nFor the data-sharing strategy, if user $k$ is served by BS $l$, then the CP needs to send \nuser $k$'s message $s_k$, along with the beamforming coefficient $w_{lk}$, to BS $l$ through the backhaul link. \nIn this paper, we assume that the channels are slow varying and ignore the backhaul required for sharing CSI and beamformers, and only \nconsider the backhaul capacity consumption due to data-sharing. \nHence, the backhaul rate for BS $l$, $R_{l}^{BH}$, is the accumulated data rates of those users served by BS $l$, which \ncan be formulated as \n\n", "itemtype": "equation", "pos": 33851, "prevtext": "\nand the achievable rate for user $k$ is then\n\n", "index": 21, "text": "\\begin{equation}\\label{eq:R_k_data_sharing}\nR_k = \\log_2\\left(1+\\frac{\\text{SINR}_k}{\\Gamma_m}\\right), \\quad k \\in \\mathcal{K},  \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"R_{k}=\\log_{2}\\left(1+\\frac{\\text{SINR}_{k}}{\\Gamma_{m}}\\right),\\quad k\\in%&#10;\\mathcal{K},\" display=\"block\"><mrow><mrow><mrow><msub><mi>R</mi><mi>k</mi></msub><mo>=</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><msub><mtext>SINR</mtext><mi>k</mi></msub><msub><mi mathvariant=\"normal\">\u0393</mi><mi>m</mi></msub></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}}$ is the indicator function defined in \\eqref{eq:indicator} and \nindicates whether or not BS $l$ serves user $k$. \n\n\nSubstituting \\eqref{eq:Tx_power_data_sharing} and \\eqref{eq:bkhaul_data_sharing} into \\eqref{eq:total_power}, \nthe total power minimization problem \\eqref{prob:power_min} can be formulated for the data-sharing strategy as\n\\begin{subequations} \\label{prob1:data_sharing}\n\n", "itemtype": "equation", "pos": 34647, "prevtext": "\nwhere $\\Gamma_m$ stands for the signal-to-noise ratio (SNR) gap due to practical modulation scheme. \n\n\nFor the data-sharing strategy, if user $k$ is served by BS $l$, then the CP needs to send \nuser $k$'s message $s_k$, along with the beamforming coefficient $w_{lk}$, to BS $l$ through the backhaul link. \nIn this paper, we assume that the channels are slow varying and ignore the backhaul required for sharing CSI and beamformers, and only \nconsider the backhaul capacity consumption due to data-sharing. \nHence, the backhaul rate for BS $l$, $R_{l}^{BH}$, is the accumulated data rates of those users served by BS $l$, which \ncan be formulated as \n\n", "index": 23, "text": "\\begin{equation} \\label{eq:bkhaul_data_sharing}\nR_{l}^{BH} = \\sum_{k \\in \\mathcal{K}} \\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} R_k, \\quad l \\in \\mathcal{L}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"R_{l}^{BH}=\\sum_{k\\in\\mathcal{K}}\\mathbbm{1}_{\\left\\{\\left|w_{lk}\\right|^{2}%&#10;\\right\\}}R_{k},\\quad l\\in\\mathcal{L},\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow></msub><mo>\u2062</mo><msub><mi>R</mi><mi>k</mi></msub></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\\end{subequations}\nNote that the $\\sum_{l \\in \\mathcal{L}} P_{l, sleep}$ term in \\eqref{eq:total_power} is a constant and has been \ndropped in the objective function \\eqref{obj_data_sharing1}.\nIt is easy to see that the minimum rate constraint \\eqref{rate_const} is met with equality at the optimal point. \nHence, problem \\eqref{prob1:data_sharing} can be equivalently formulated as\n\\begin{subequations} \\label{prob:data_sharing}\n\n", "itemtype": "equation", "pos": 35302, "prevtext": "\nwhere $\\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}}$ is the indicator function defined in \\eqref{eq:indicator} and \nindicates whether or not BS $l$ serves user $k$. \n\n\nSubstituting \\eqref{eq:Tx_power_data_sharing} and \\eqref{eq:bkhaul_data_sharing} into \\eqref{eq:total_power}, \nthe total power minimization problem \\eqref{prob:power_min} can be formulated for the data-sharing strategy as\n\\begin{subequations} \\label{prob1:data_sharing}\n\n", "index": 25, "text": "\\begin{align} \n\\displaystyle {\\operatorname{minimize}}_{\\left\\{w_{lk} \\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  + \n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} P_{l, \\Delta}   \\nonumber \\\\ \n& \\hspace{2.5cm} + \\rho_l \\sum_{k\\in \\mathcal{K}} \\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} R_k \\Bigg) \n\\label{obj_data_sharing1} \\\\\n {\\operatorname{subject \\text{ } to}} & \\quad R_k = \\log_2\\left(1+\\frac{\\text{SINR}_k}{\\Gamma_m}\\right) \\geq r_k, ~ k \\in \\mathcal{K} \\label{rate_const} \\\\\n  &\\quad \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\leq P_l, \\quad l \\in \\mathcal{L}.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle{\\operatorname{minimize}}_{\\left\\{w_{lk}\\right\\}}\" display=\"inline\"><msub><mo>minimize</mo><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\sum_{k\\in\\mathcal{K}}%&#10;\\left|w_{lk}\\right|^{2}+\\mathbbm{1}_{\\left\\{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}%&#10;\\right|^{2}\\right\\}}P_{l,\\Delta}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup><mo>+</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mrow><mstyle displaystyle=\"false\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>}</mo></mrow></msub><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\rho_{l}\\sum_{k\\in\\mathcal{K}}\\mathbbm{1}_%&#10;{\\left\\{\\left|w_{lk}\\right|^{2}\\right\\}}R_{k}\\Bigg{)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow></msub><msub><mi>R</mi><mi>k</mi></msub><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad R_{k}=\\log_{2}\\left(1+\\frac{\\text{SINR}_{k}}{\\Gamma_{m}}%&#10;\\right)\\geq r_{k},~{}k\\in\\mathcal{K}\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><msub><mi>R</mi><mi>k</mi></msub></mrow><mo>=</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><msub><mtext>SINR</mtext><mi>k</mi></msub><msub><mi mathvariant=\"normal\">\u0393</mi><mi>m</mi></msub></mfrac></mstyle></mrow><mo>)</mo></mrow></mrow><mo>\u2265</mo><msub><mi>r</mi><mi>k</mi></msub></mrow><mo rspace=\"5.8pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\leq P_{l},%&#10;\\quad l\\in\\mathcal{L}.\" display=\"inline\"><mrow><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>\u2264</mo><msub><mi>P</mi><mi>l</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\\end{subequations}\nwhere the variable $R_k$ in \\eqref{obj_data_sharing1} is replaced by the target rate $r_k$ in \\eqref{obj_data_sharing} and \n$\\gamma_k = \\Gamma_m \\left(2^{r_k} - 1\\right)$ in \\eqref{sinr_const}. \nThe new SINR constraint \\eqref{sinr_const} is also met with equality at the optimality. However, we keep \\eqref{sinr_const} as an \ninequality constraint, so that it can be reformulated as a convex second-order cone (SOC) constraint \\cite{wiesel2006}.\nNote that problem \\eqref{prob:data_sharing} is equivalent to problem \\eqref{prob1:data_sharing} in the sense that they have the same \noptimal solutions and the same feasibility region. \n\n\n\nNote that the above optimization is over the beamforming coefficients and also implicitly over the BS cluster for each user. \nThe overall optimization problem \\eqref{prob:data_sharing} aims to choose the optimal cluster of serving BSs for each scheduled user for \nminimizing the total power consumption while satisfying the user QoS constraints. \nDue to the indicator functions in the objective function \\eqref{obj_data_sharing}, problem \\eqref{prob:data_sharing} is nonconvex  \n(discrete), \nso finding its global optimum solution is challenging. \nIn the following, we propose to approximate the nonconvex indicator function using reweighted convex $\\ell_1$-norm and show that \nwith a particular reweighting function the proposed algorithm always converges\\footnote{In fact, it converges to the stationary point solution of an approximation to problem \\eqref{prob:data_sharing}.}.  \n\n\n\\subsection{Proposed Algorithm}\n\nWe make an observation that the indicator function defined in \\eqref{eq:indicator} is equivalent to the $\\ell_0$-norm of a scalar. \nThe $\\ell_0$-norm of a vector is defined as the number of nonzero entries in the vector, so it reduces to the indicator function in \nthe scalar case. In compressive sensing literature \\cite{Candes08}, nonconvex $\\ell_0$-norm minimization problem can be approximated \nas convex reweighted $\\ell_1$ minimization problem. We take advantage of this technique and propose to approximate the \nindicator functions in the objective function \\eqref{obj_data_sharing} as\n\n", "itemtype": "equation", "pos": 36468, "prevtext": "\n\\end{subequations}\nNote that the $\\sum_{l \\in \\mathcal{L}} P_{l, sleep}$ term in \\eqref{eq:total_power} is a constant and has been \ndropped in the objective function \\eqref{obj_data_sharing1}.\nIt is easy to see that the minimum rate constraint \\eqref{rate_const} is met with equality at the optimal point. \nHence, problem \\eqref{prob1:data_sharing} can be equivalently formulated as\n\\begin{subequations} \\label{prob:data_sharing}\n\n", "index": 27, "text": "\\begin{align} \n\\displaystyle {\\operatorname{minimize}}_{\\left\\{w_{lk} \\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  + \n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} P_{l, \\Delta}  \\nonumber \\\\ \n& \\hspace{2.5cm} + \\rho_l \\sum_{k\\in \\mathcal{K}} \\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} r_k \\Bigg) \n\\label{obj_data_sharing} \\\\\n {\\operatorname{subject \\text{ } to}}  & \\quad \\text{SINR}_k \\geq \\gamma_k, \\quad k \\in \\mathcal{K} \\label{sinr_const} \\\\\n&  \\quad \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\leq P_l, \\quad l \\in \\mathcal{L} \\label{Per_BS_Power}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle{\\operatorname{minimize}}_{\\left\\{w_{lk}\\right\\}}\" display=\"inline\"><msub><mo>minimize</mo><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\sum_{k\\in\\mathcal{K}}%&#10;\\left|w_{lk}\\right|^{2}+\\mathbbm{1}_{\\left\\{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}%&#10;\\right|^{2}\\right\\}}P_{l,\\Delta}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup><mo>+</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mrow><mstyle displaystyle=\"false\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>}</mo></mrow></msub><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\rho_{l}\\sum_{k\\in\\mathcal{K}}\\mathbbm{1}_%&#10;{\\left\\{\\left|w_{lk}\\right|^{2}\\right\\}}r_{k}\\Bigg{)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow></msub><msub><mi>r</mi><mi>k</mi></msub><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\text{SINR}_{k}\\geq\\gamma_{k},\\quad k\\in\\mathcal{K}\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><msub><mtext>SINR</mtext><mi>k</mi></msub></mrow><mo>\u2265</mo><msub><mi>\u03b3</mi><mi>k</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\leq P_{l},%&#10;\\quad l\\in\\mathcal{L}\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>\u2264</mo><msub><mi>P</mi><mi>l</mi></msub></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 39353, "prevtext": "\n\\end{subequations}\nwhere the variable $R_k$ in \\eqref{obj_data_sharing1} is replaced by the target rate $r_k$ in \\eqref{obj_data_sharing} and \n$\\gamma_k = \\Gamma_m \\left(2^{r_k} - 1\\right)$ in \\eqref{sinr_const}. \nThe new SINR constraint \\eqref{sinr_const} is also met with equality at the optimality. However, we keep \\eqref{sinr_const} as an \ninequality constraint, so that it can be reformulated as a convex second-order cone (SOC) constraint \\cite{wiesel2006}.\nNote that problem \\eqref{prob:data_sharing} is equivalent to problem \\eqref{prob1:data_sharing} in the sense that they have the same \noptimal solutions and the same feasibility region. \n\n\n\nNote that the above optimization is over the beamforming coefficients and also implicitly over the BS cluster for each user. \nThe overall optimization problem \\eqref{prob:data_sharing} aims to choose the optimal cluster of serving BSs for each scheduled user for \nminimizing the total power consumption while satisfying the user QoS constraints. \nDue to the indicator functions in the objective function \\eqref{obj_data_sharing}, problem \\eqref{prob:data_sharing} is nonconvex  \n(discrete), \nso finding its global optimum solution is challenging. \nIn the following, we propose to approximate the nonconvex indicator function using reweighted convex $\\ell_1$-norm and show that \nwith a particular reweighting function the proposed algorithm always converges\\footnote{In fact, it converges to the stationary point solution of an approximation to problem \\eqref{prob:data_sharing}.}.  \n\n\n\\subsection{Proposed Algorithm}\n\nWe make an observation that the indicator function defined in \\eqref{eq:indicator} is equivalent to the $\\ell_0$-norm of a scalar. \nThe $\\ell_0$-norm of a vector is defined as the number of nonzero entries in the vector, so it reduces to the indicator function in \nthe scalar case. In compressive sensing literature \\cite{Candes08}, nonconvex $\\ell_0$-norm minimization problem can be approximated \nas convex reweighted $\\ell_1$ minimization problem. We take advantage of this technique and propose to approximate the \nindicator functions in the objective function \\eqref{obj_data_sharing} as\n\n", "index": 29, "text": "\\begin{equation}\\label{wgt_l}\n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}}\n= \\left\\Vert  \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\right\\Vert_0 \n\\approx \\mu_l \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\mathbbm{1}_{\\left\\{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\right\\}}=%&#10;\\left\\|\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\right\\|_{0}\\approx\\mu_{l}%&#10;\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\" display=\"block\"><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mrow><mstyle displaystyle=\"false\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>}</mo></mrow></msub><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>\u2248</mo><mrow><msub><mi>\u03bc</mi><mi>l</mi></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwith weights $\\mu_l$ and $\\nu_{lk}$ iteratively updated according to \n\n", "itemtype": "equation", "pos": 39650, "prevtext": "\n\n", "index": 31, "text": "\\begin{equation}\\label{wgt_lk}\n\\mathbbm{1}_{\\left\\{ \\left\\vert w_{lk} \\right\\vert^{2} \\right\\}} \n= \\left\\Vert  \\left\\vert w_{lk} \\right\\vert^{2} \\right\\Vert_0\n\\approx \\nu_{lk} \\left\\vert w_{lk} \\right\\vert^{2} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\mathbbm{1}_{\\left\\{\\left|w_{lk}\\right|^{2}\\right\\}}=\\left\\|\\left|w_{lk}\\right%&#10;|^{2}\\right\\|_{0}\\approx\\nu_{lk}\\left|w_{lk}\\right|^{2}\" display=\"block\"><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow></msub><mo>=</mo><msub><mrow><mo>\u2225</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>\u2248</mo><mrow><msub><mi>\u03bd</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\left\\{ w_{lk} \\right\\}$ is the beamformer from the previous iteration, $\\tau_1 > 0$ and $\\tau_2 > 0$ are some \nconstant regularization factors, and $c_1, c_2$ are constants.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that in the above iterative updates of $\\mu_l$ and $\\nu_{lk}$, the BSs with small transmit power,  \n$\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$, or small transmit power to user $k$, \n$\\left\\vert w_{lk} \\right\\vert^{2}$, at current iteration are given larger weights $\\mu_l$ or $\\nu_{lk}$ in the next iteration. \nThis further decreases $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$ or $\\left\\vert w_{lk} \\right\\vert^{2}$ \nin the next iteration, \nand eventually forces BS $l$ toward sleep mode (i.e., $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} = 0$) or \nto be removed from user $k$'s serving cluster (i.e., $\\left\\vert w_{lk} \\right\\vert^{2} = 0$). \nThe weight $\\mu_l$ has the effect of putting appropriate BSs to sleep mode, while $\\nu_{lk}$ has the effect of \ndetermining the BS cluster size for user $k$, which in turn affects the backhaul capacity consumption of user $k$. \n\n\n\nThe resulting optimization problem after the $\\ell_1$-norm approximation is formulated as follows:  \n\n\n", "itemtype": "equation", "pos": 39946, "prevtext": "\nwith weights $\\mu_l$ and $\\nu_{lk}$ iteratively updated according to \n\n", "index": 33, "text": "\\begin{align}\\label{wgt_update_data}\n \\mu_l = f\\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}, \\tau_1 \\right) \n& = \\frac{c_1}{\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + \\tau_1} ~ , \\nonumber \\\\ \n \\nu_{lk} = f\\left(\\left\\vert w_{lk} \\right\\vert^{2}, \\tau_2\\right) \n& = \\frac{c_2}{\\left\\vert w_{lk} \\right\\vert^{2} + \\tau_2} \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu_{l}=f\\left(\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2},\\tau%&#10;_{1}\\right)\" display=\"inline\"><mrow><msub><mi>\u03bc</mi><mi>l</mi></msub><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>,</mo><msub><mi>\u03c4</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{c_{1}}{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+\\tau_%&#10;{1}}~{},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mpadded width=\"+3.3pt\"><mstyle displaystyle=\"true\"><mfrac><msub><mi>c</mi><mn>1</mn></msub><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msub><mi>\u03c4</mi><mn>1</mn></msub></mrow></mfrac></mstyle></mpadded></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\nu_{lk}=f\\left(\\left|w_{lk}\\right|^{2},\\tau_{2}\\right)\" display=\"inline\"><mrow><msub><mi>\u03bd</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>,</mo><msub><mi>\u03c4</mi><mn>2</mn></msub><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{c_{2}}{\\left|w_{lk}\\right|^{2}+\\tau_{2}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>c</mi><mn>2</mn></msub><mrow><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup><mo>+</mo><msub><mi>\u03c4</mi><mn>2</mn></msub></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\nwhere $\\alpha_{lk} = \\eta_l + \\mu_l P_{l, \\Delta} + \\rho_l \\nu_{lk} r_k$. \nProblem \\eqref{prob:data_sharing_approx} is a weighted sum transmit power minimization problem, which can be solved \nefficiently through the uplink-downlink duality approach \\cite{dahrouj10} or by transforming it into an SOCP problem \\cite{wiesel2006}. \nWe now summarize the proposed algorithm to solve the total power minimization problem \\eqref{prob:data_sharing} for the \ndata-sharing strategy in Algorithm~\\ref{alg:data_sharing}. \n\n\\begin{algorithm}[t]\n{\\bf Initialization}: Set the initial values for $\\left\\{\\mu_{l}, \\nu_{lk} \\right\\}$ according to \\eqref{wgt_update_data} \nwith the $\\left\\{ w_{lk} \\right\\}$ chosen as a feasible point of problem \\eqref{prob:data_sharing}; \\\\\n{\\bf Repeat}:\n\\begin{enumerate}\n\\item Fix $\\left\\{\\mu_{l}, \\nu_{lk}\\right\\}$, find the optimal \n$\\left\\{ w_{lk} \\right\\}$ by solving problem \\eqref{prob:data_sharing_approx} \nusing the uplink-downlink duality approach \\cite{dahrouj10} or by transforming it into an SOCP problem \\cite{wiesel2006};  \n\\item Update $\\left\\{\\mu_{l}, \\nu_{lk} \\right\\}$ \naccording to \\eqref{wgt_update_data}. \n\\end{enumerate}\n{\\bf Until} convergence\n\\caption{Total Power Minimization for Data-Sharing Strategy}\n\\label{alg:data_sharing}\n\\end{algorithm}\n\n\nNote that a similar problem as to \\eqref{prob:data_sharing} is considered in our previous work \\cite{binbin13}, \nwhere we formulate the problem as a tradeoff between the BS transmit power and the backhaul capacity. \nThis paper considers a more realistic BS power consumption model with sleep mode capability, and also accounts for backhaul power consumption. \nThe considered problem \\eqref{prob:data_sharing} in this paper \ncan also be thought of as providing a tradeoff between the per-BS power consumption and the per-BS \nbackhaul capacity consumption, where the tradeoff constant $\\rho_l$ is specifically chosen according to the backhaul power consumption model \n\\eqref{eq:bkhaul_power}. \n\n\n\n\n\n\\subsection{Convergence Analysis}\\label{sec:Data_Converge}\n\n\n\nAlgorithm~\\ref{alg:data_sharing} relies on the reweighting heuristic \\eqref{wgt_update_data} to deactivate BSs and \nreduce the BS cluster size for energy saving purpose. \nTo establish the convergence proof for Algorithm~\\ref{alg:data_sharing} under arbitrary reweighting function is challenging, however, \nwe show in the following that if the reweighting function is chosen as \n\n", "itemtype": "equation", "pos": 41552, "prevtext": "\nwhere $\\left\\{ w_{lk} \\right\\}$ is the beamformer from the previous iteration, $\\tau_1 > 0$ and $\\tau_2 > 0$ are some \nconstant regularization factors, and $c_1, c_2$ are constants.  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that in the above iterative updates of $\\mu_l$ and $\\nu_{lk}$, the BSs with small transmit power,  \n$\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$, or small transmit power to user $k$, \n$\\left\\vert w_{lk} \\right\\vert^{2}$, at current iteration are given larger weights $\\mu_l$ or $\\nu_{lk}$ in the next iteration. \nThis further decreases $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$ or $\\left\\vert w_{lk} \\right\\vert^{2}$ \nin the next iteration, \nand eventually forces BS $l$ toward sleep mode (i.e., $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} = 0$) or \nto be removed from user $k$'s serving cluster (i.e., $\\left\\vert w_{lk} \\right\\vert^{2} = 0$). \nThe weight $\\mu_l$ has the effect of putting appropriate BSs to sleep mode, while $\\nu_{lk}$ has the effect of \ndetermining the BS cluster size for user $k$, which in turn affects the backhaul capacity consumption of user $k$. \n\n\n\nThe resulting optimization problem after the $\\ell_1$-norm approximation is formulated as follows:  \n\n\n", "index": 35, "text": "\\begin{align} \\label{prob:data_sharing_approx}\n\\displaystyle {\\operatorname{minimize}}_{\\left\\{w_{lk} \\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \\sum_{k\\in \\mathcal{K}} \n\\alpha_{lk} \\left\\vert w_{lk} \\right\\vert^{2} \\\\\n {\\operatorname{subject \\text{ } to}}  & \\quad \\eqref{sinr_const}, ~~ \\eqref{Per_BS_Power} \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle{\\operatorname{minimize}}_{\\left\\{w_{lk}\\right\\}}\" display=\"inline\"><msub><mo>minimize</mo><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\sum_{k\\in\\mathcal{K}}\\alpha_{lk}\\left%&#10;|w_{lk}\\right|^{2}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mrow><msub><mi>\u03b1</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\eqref{sinr_const},~{}~{}\\eqref{Per_BS_Power}\" display=\"inline\"><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mi>(</mi><mo>\u2062</mo><mtext mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_font_italic ltx_ref_self\"><span class=\"ltx_text ltx_ref_tag\">17</span></span></mtext><mo>\u2062</mo><mi>)</mi></mrow><mo rspace=\"9.1pt\">,</mo><mrow><mi>(</mi><mo>\u2062</mo><mtext mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_font_italic ltx_ref_self\"><span class=\"ltx_text ltx_ref_tag\">18</span></span></mtext><mo>\u2062</mo><mi>)</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\ni.e. the constants in \\eqref{wgt_update_data} are chosen as \n$c_1 = \\frac{1}{\\ln \\left( 1 + \\tau_1^{-1} \\right)}, c_2 = \\frac{1}{\\ln \\left( 1 + \\tau_2^{-1} \\right)}$, \nAlgorithm~\\ref{alg:data_sharing} can be seen as a special case of the MM algorithms \\cite{Bharath11} and is guaranteed to converge. \n\\begin{theorem}\\label{thm:1}\nStarting with any initial point, the sequence $\\left\\{ w_{lk}^{(n)} \\right\\}_{n=1}^{\\infty}$ generated by Algorithm~\\ref{alg:data_sharing} with the reweighting function chosen as \\eqref{eq:reweight} \nis guaranteed to converge. \n\\end{theorem}\n\\begin{IEEEproof}\nSee Appendix~\\ref{apdx:a}.\n\\end{IEEEproof}\n\n\n\nFinally, we point out that the choice of the reweighting function \\eqref{eq:reweight} is not unique. \nThere exist other reweighting functions that may work well in different problem setups \\cite{Candes08}. \nRecently, \\cite{ZhouTaoChen} has experimented with other approximation functions to the $\\ell_0$-norm, \ne.g. exponential function and arc-tangent function, in addition to the logarithmic \nfunction \\eqref{lim_approx} used in this paper, and observed similar effectiveness of these functions in inducing sparsity. \n\n\n\n\\subsection{Complexity Analysis}\n\n\nAlgorithm~\\ref{alg:data_sharing} is an iterative procedure between updating the weights $\\left\\{\\mu_{l}, \\nu_{lk}\\right\\}$ and \nsolving the weighted transmit power minimization problem \\eqref{prob:data_sharing_approx}. \nThe problem \\eqref{prob:data_sharing_approx} can be formulated as an SOCP and solved using the \ninterior-point method, e.g. using the convex optimization solver \\cite{CVX}. \nThe total number of variables in problem \\eqref{prob:data_sharing_approx} is $LK$ and the total number of SOC \nconstraints is $\\left(L + K \\right)$. The complexity order for solving such a problem through\ninterior-point method is given as $O\\left( \\left(L + K \\right) \\left(LK\\right)^3 \\right)$ \\cite{boyd}. \nAssuming that Algorithm~\\ref{alg:data_sharing} requires a total number of $T_1$ weight updates, \nthe overall complexity order for Algorithm~\\ref{alg:data_sharing} is then $O\\left( T_1\\left(L + K \\right) \\left(LK\\right)^3\\right)$. \n\nNote that in the above complexity order, $K$ is the number of scheduled users, which is comparable to the number of active BSs in\nthe network. In addition, instead of considering all the $L$ BSs in the entire network, we can set the nearest $L_c < L$ BSs around each scheduled user as its candidate serving BS cluster. \nThis further reduces the computational complexity for Algorithm~\\ref{alg:data_sharing} with negligible performance loss. \n\n\n\n\\subsection{Generalization to the Multi-Antenna System}\n\n\nAlgorithm~\\ref{alg:data_sharing} can be readily generalized to the case with multiple transmit antennas at each BS. \nIn such case, one only needs to replace the beamforming coefficient $w_{lk}$ with the \nbeamforming vector $\\mathbf{w}_{lk} \\in \\mathbb{C}^{N_l \\times 1}$ from BS $l$ to user $k$, where $N_l$ is the number of \nantennas at BS $l$. \nThe rest of the optimization parameters are straightforward extensions based on $\\mathbf{w}_{lk}$ \\cite{binbin13}. \n\nAlgorithm~\\ref{alg:data_sharing} can also be applied to the case with multiple receive antennas at each user but with fixed \nreceive beamformer. In this case, the only change is to replace the channel gain vector $\\mathbf{h}_{k}$ \nwith the effective channel gain $\\tilde{\\mathbf{h}}_{k} = \\mathbf{H}_{k} \\mathbf{u}_{k}$, where \n$\\mathbf{H}_{k} \\in \\mathbb{C}^{L \\times M_k}$ and $\\mathbf{u}_{k} \\in \\mathbb{C}^{M_k \\times 1}$ are the channel matrix \nseen by user $k$ and the receive beamformer at user $k$, $M_k$ is the number receive antennas at user $k$. \nHowever, the joint design of transmit beamformer and receive beamformer for the multiple receive antennas case is more complicated.\nOne possible way is to iteratively design the transmit beamformer assuming fixed receive beamformer and update the receiver as the \noptimal minimum mean square error (MMSE) beamformer.  \n\n\n\n\n\n\n\n\\begin{figure}[!t]\n  \\centering\n\t\\psfrag{p}[tc][Bc][1]{Central Processor}\n\t\\psfrag{q}[tc][Bc][0.9]{$\\hat{x}_l = w_{l1}s_1 + w_{l2}s_2$}\n\t\\psfrag{l}[tc][Bc][0.9]{$l = 1, 2, 3$}\n\t\\psfrag{a}[tc][tc][0.9]{$x_1$}\n\t\\psfrag{b}[tc][tc][0.9]{$x_2$}\n\t\\psfrag{c}[tc][tc][0.9]{$x_3$}\n\t\\psfrag{i}[tl][tc][0.8]{$R_1^{BH}$}\n\t\\psfrag{j}[tl][tc][0.8]{$R_2^{BH}$}\n\t\\psfrag{k}[tl][tc][0.8]{$R_3^{BH}$}\n\t\\psfrag{x}[tc][cl][0.8]{$x_1 = \\hat{x}_1 + e_1$}\n\t\\psfrag{y}[tc][cl][0.8]{$x_2 = \\hat{x}_2 + e_2$}\n\t\\psfrag{z}[tc][cl][0.8]{$x_3 = \\hat{x}_3 + e_3$}\n\t\\psfrag{m}[tc][tc][0.8]{BS $1$}\n\t\\psfrag{e}[tc][tc][0.8]{BS $2$}\n\t\\psfrag{g}[tc][tc][0.8]{BS $3$}\n\t\\psfrag{n}[tc][tc][0.8]{User $1$}\n\t\\psfrag{f}[tc][tc][0.8]{User $2$}\n  \\includegraphics[width= 0.45\\textwidth]{CompressionModelFinal.eps}\n\\caption{Downlink C-RAN with compression transmission strategy. In this illustrative example, the CP centrally precodes \nboth users' messages $s_1$ and $s_2$ to $\\hat{x}_l, l=1,2,3,$ and forwards the compressed precoded signals \n$x_l,l=1,2,3,$ to each of the BSs. Each BS transmits the compressed beamformed signal received from the CP to both users.}\n\\label{fig:CompressionModel}\n\\end{figure}\n\n\n\n\n\\section{Compression Strategy}\\label{sec:compression}\n\n\nIn this section, we aim to minimize the total power consumption for downlink C-RAN under the \ncompression strategy. \n\n\n\n\\subsection{Problem Formulation}\n\nConsider the compression transmission strategy for downlink C-RAN as illustrated in Fig.~\\ref{fig:CompressionModel}.\nLet $\\hat{x}_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$ denote the beamformed signal formed in the CP for BS $l$. \nThe CP compresses $\\hat{x}_l$ into $x_l$ and sends $x_l$ to BS $l$. \nIn this paper, we assume that each $\\hat{x}_l$ is compressed independently\\footnote{Correlated compression is also possible and has been considered in \\cite{Park13}.} and model the compression procedure as the following forward test channel: \n\n", "itemtype": "equation", "pos": 44310, "prevtext": "\n\nwhere $\\alpha_{lk} = \\eta_l + \\mu_l P_{l, \\Delta} + \\rho_l \\nu_{lk} r_k$. \nProblem \\eqref{prob:data_sharing_approx} is a weighted sum transmit power minimization problem, which can be solved \nefficiently through the uplink-downlink duality approach \\cite{dahrouj10} or by transforming it into an SOCP problem \\cite{wiesel2006}. \nWe now summarize the proposed algorithm to solve the total power minimization problem \\eqref{prob:data_sharing} for the \ndata-sharing strategy in Algorithm~\\ref{alg:data_sharing}. \n\n\\begin{algorithm}[t]\n{\\bf Initialization}: Set the initial values for $\\left\\{\\mu_{l}, \\nu_{lk} \\right\\}$ according to \\eqref{wgt_update_data} \nwith the $\\left\\{ w_{lk} \\right\\}$ chosen as a feasible point of problem \\eqref{prob:data_sharing}; \\\\\n{\\bf Repeat}:\n\\begin{enumerate}\n\\item Fix $\\left\\{\\mu_{l}, \\nu_{lk}\\right\\}$, find the optimal \n$\\left\\{ w_{lk} \\right\\}$ by solving problem \\eqref{prob:data_sharing_approx} \nusing the uplink-downlink duality approach \\cite{dahrouj10} or by transforming it into an SOCP problem \\cite{wiesel2006};  \n\\item Update $\\left\\{\\mu_{l}, \\nu_{lk} \\right\\}$ \naccording to \\eqref{wgt_update_data}. \n\\end{enumerate}\n{\\bf Until} convergence\n\\caption{Total Power Minimization for Data-Sharing Strategy}\n\\label{alg:data_sharing}\n\\end{algorithm}\n\n\nNote that a similar problem as to \\eqref{prob:data_sharing} is considered in our previous work \\cite{binbin13}, \nwhere we formulate the problem as a tradeoff between the BS transmit power and the backhaul capacity. \nThis paper considers a more realistic BS power consumption model with sleep mode capability, and also accounts for backhaul power consumption. \nThe considered problem \\eqref{prob:data_sharing} in this paper \ncan also be thought of as providing a tradeoff between the per-BS power consumption and the per-BS \nbackhaul capacity consumption, where the tradeoff constant $\\rho_l$ is specifically chosen according to the backhaul power consumption model \n\\eqref{eq:bkhaul_power}. \n\n\n\n\n\n\\subsection{Convergence Analysis}\\label{sec:Data_Converge}\n\n\n\nAlgorithm~\\ref{alg:data_sharing} relies on the reweighting heuristic \\eqref{wgt_update_data} to deactivate BSs and \nreduce the BS cluster size for energy saving purpose. \nTo establish the convergence proof for Algorithm~\\ref{alg:data_sharing} under arbitrary reweighting function is challenging, however, \nwe show in the following that if the reweighting function is chosen as \n\n", "index": 37, "text": "\\begin{equation}\\label{eq:reweight}\nf\\left(x, \\tau\\right) = \\frac{1}{\\left(x + \\tau\\right) \\ln \\left( 1 + \\tau^{-1} \\right) } ~, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"f\\left(x,\\tau\\right)=\\frac{1}{\\left(x+\\tau\\right)\\ln\\left(1+\\tau^{-1}\\right)}~%&#10;{},\" display=\"block\"><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>\u03c4</mi><mo>)</mo></mrow></mrow><mo>=</mo><mpadded width=\"+3.3pt\"><mfrac><mn>1</mn><mrow><mrow><mo>(</mo><mrow><mi>x</mi><mo>+</mo><mi>\u03c4</mi></mrow><mo>)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msup><mi>\u03c4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>)</mo></mrow></mrow></mrow></mfrac></mpadded></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $e_l \\in \\mathbb{C}$ is the quantization noise independent of $\\hat{x}_l$ \nand is assumed to be Gaussian distributed with zero mean and variance $q_l^{2}$. \nSubstituting \\eqref{eq:compressX} to \\eqref{eq:TxPower}, the transmit power at BS $l$ under the compression strategy can be written as \n\n", "itemtype": "equation", "pos": 50356, "prevtext": "\ni.e. the constants in \\eqref{wgt_update_data} are chosen as \n$c_1 = \\frac{1}{\\ln \\left( 1 + \\tau_1^{-1} \\right)}, c_2 = \\frac{1}{\\ln \\left( 1 + \\tau_2^{-1} \\right)}$, \nAlgorithm~\\ref{alg:data_sharing} can be seen as a special case of the MM algorithms \\cite{Bharath11} and is guaranteed to converge. \n\\begin{theorem}\\label{thm:1}\nStarting with any initial point, the sequence $\\left\\{ w_{lk}^{(n)} \\right\\}_{n=1}^{\\infty}$ generated by Algorithm~\\ref{alg:data_sharing} with the reweighting function chosen as \\eqref{eq:reweight} \nis guaranteed to converge. \n\\end{theorem}\n\\begin{IEEEproof}\nSee Appendix~\\ref{apdx:a}.\n\\end{IEEEproof}\n\n\n\nFinally, we point out that the choice of the reweighting function \\eqref{eq:reweight} is not unique. \nThere exist other reweighting functions that may work well in different problem setups \\cite{Candes08}. \nRecently, \\cite{ZhouTaoChen} has experimented with other approximation functions to the $\\ell_0$-norm, \ne.g. exponential function and arc-tangent function, in addition to the logarithmic \nfunction \\eqref{lim_approx} used in this paper, and observed similar effectiveness of these functions in inducing sparsity. \n\n\n\n\\subsection{Complexity Analysis}\n\n\nAlgorithm~\\ref{alg:data_sharing} is an iterative procedure between updating the weights $\\left\\{\\mu_{l}, \\nu_{lk}\\right\\}$ and \nsolving the weighted transmit power minimization problem \\eqref{prob:data_sharing_approx}. \nThe problem \\eqref{prob:data_sharing_approx} can be formulated as an SOCP and solved using the \ninterior-point method, e.g. using the convex optimization solver \\cite{CVX}. \nThe total number of variables in problem \\eqref{prob:data_sharing_approx} is $LK$ and the total number of SOC \nconstraints is $\\left(L + K \\right)$. The complexity order for solving such a problem through\ninterior-point method is given as $O\\left( \\left(L + K \\right) \\left(LK\\right)^3 \\right)$ \\cite{boyd}. \nAssuming that Algorithm~\\ref{alg:data_sharing} requires a total number of $T_1$ weight updates, \nthe overall complexity order for Algorithm~\\ref{alg:data_sharing} is then $O\\left( T_1\\left(L + K \\right) \\left(LK\\right)^3\\right)$. \n\nNote that in the above complexity order, $K$ is the number of scheduled users, which is comparable to the number of active BSs in\nthe network. In addition, instead of considering all the $L$ BSs in the entire network, we can set the nearest $L_c < L$ BSs around each scheduled user as its candidate serving BS cluster. \nThis further reduces the computational complexity for Algorithm~\\ref{alg:data_sharing} with negligible performance loss. \n\n\n\n\\subsection{Generalization to the Multi-Antenna System}\n\n\nAlgorithm~\\ref{alg:data_sharing} can be readily generalized to the case with multiple transmit antennas at each BS. \nIn such case, one only needs to replace the beamforming coefficient $w_{lk}$ with the \nbeamforming vector $\\mathbf{w}_{lk} \\in \\mathbb{C}^{N_l \\times 1}$ from BS $l$ to user $k$, where $N_l$ is the number of \nantennas at BS $l$. \nThe rest of the optimization parameters are straightforward extensions based on $\\mathbf{w}_{lk}$ \\cite{binbin13}. \n\nAlgorithm~\\ref{alg:data_sharing} can also be applied to the case with multiple receive antennas at each user but with fixed \nreceive beamformer. In this case, the only change is to replace the channel gain vector $\\mathbf{h}_{k}$ \nwith the effective channel gain $\\tilde{\\mathbf{h}}_{k} = \\mathbf{H}_{k} \\mathbf{u}_{k}$, where \n$\\mathbf{H}_{k} \\in \\mathbb{C}^{L \\times M_k}$ and $\\mathbf{u}_{k} \\in \\mathbb{C}^{M_k \\times 1}$ are the channel matrix \nseen by user $k$ and the receive beamformer at user $k$, $M_k$ is the number receive antennas at user $k$. \nHowever, the joint design of transmit beamformer and receive beamformer for the multiple receive antennas case is more complicated.\nOne possible way is to iteratively design the transmit beamformer assuming fixed receive beamformer and update the receiver as the \noptimal minimum mean square error (MMSE) beamformer.  \n\n\n\n\n\n\n\n\\begin{figure}[!t]\n  \\centering\n\t\\psfrag{p}[tc][Bc][1]{Central Processor}\n\t\\psfrag{q}[tc][Bc][0.9]{$\\hat{x}_l = w_{l1}s_1 + w_{l2}s_2$}\n\t\\psfrag{l}[tc][Bc][0.9]{$l = 1, 2, 3$}\n\t\\psfrag{a}[tc][tc][0.9]{$x_1$}\n\t\\psfrag{b}[tc][tc][0.9]{$x_2$}\n\t\\psfrag{c}[tc][tc][0.9]{$x_3$}\n\t\\psfrag{i}[tl][tc][0.8]{$R_1^{BH}$}\n\t\\psfrag{j}[tl][tc][0.8]{$R_2^{BH}$}\n\t\\psfrag{k}[tl][tc][0.8]{$R_3^{BH}$}\n\t\\psfrag{x}[tc][cl][0.8]{$x_1 = \\hat{x}_1 + e_1$}\n\t\\psfrag{y}[tc][cl][0.8]{$x_2 = \\hat{x}_2 + e_2$}\n\t\\psfrag{z}[tc][cl][0.8]{$x_3 = \\hat{x}_3 + e_3$}\n\t\\psfrag{m}[tc][tc][0.8]{BS $1$}\n\t\\psfrag{e}[tc][tc][0.8]{BS $2$}\n\t\\psfrag{g}[tc][tc][0.8]{BS $3$}\n\t\\psfrag{n}[tc][tc][0.8]{User $1$}\n\t\\psfrag{f}[tc][tc][0.8]{User $2$}\n  \\includegraphics[width= 0.45\\textwidth]{CompressionModelFinal.eps}\n\\caption{Downlink C-RAN with compression transmission strategy. In this illustrative example, the CP centrally precodes \nboth users' messages $s_1$ and $s_2$ to $\\hat{x}_l, l=1,2,3,$ and forwards the compressed precoded signals \n$x_l,l=1,2,3,$ to each of the BSs. Each BS transmits the compressed beamformed signal received from the CP to both users.}\n\\label{fig:CompressionModel}\n\\end{figure}\n\n\n\n\n\\section{Compression Strategy}\\label{sec:compression}\n\n\nIn this section, we aim to minimize the total power consumption for downlink C-RAN under the \ncompression strategy. \n\n\n\n\\subsection{Problem Formulation}\n\nConsider the compression transmission strategy for downlink C-RAN as illustrated in Fig.~\\ref{fig:CompressionModel}.\nLet $\\hat{x}_l = \\sum_{k \\in \\mathcal{K}} w_{lk} s_k$ denote the beamformed signal formed in the CP for BS $l$. \nThe CP compresses $\\hat{x}_l$ into $x_l$ and sends $x_l$ to BS $l$. \nIn this paper, we assume that each $\\hat{x}_l$ is compressed independently\\footnote{Correlated compression is also possible and has been considered in \\cite{Park13}.} and model the compression procedure as the following forward test channel: \n\n", "index": 39, "text": "\\begin{equation}\\label{eq:compressX}\nx_l = \\hat{x}_l + e_l, \\quad l \\in \\mathcal{L}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"x_{l}=\\hat{x}_{l}+e_{l},\\quad l\\in\\mathcal{L},\" display=\"block\"><mrow><mrow><mrow><msub><mi>x</mi><mi>l</mi></msub><mo>=</mo><mrow><msub><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">^</mo></mover><mi>l</mi></msub><mo>+</mo><msub><mi>e</mi><mi>l</mi></msub></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nComparing \\eqref{eq:Tx_power_compression} with \\eqref{eq:Tx_power_data_sharing}, we can see that different from the data-sharing \nstrategy, the BS transmit power in the compression strategy involves a quantization noise power in addition to the beamforming power. \n\n\nSubstituting \\eqref{eq:compressX} into \\eqref{eq:yk_general}, the received signal $y_k$ at user $k$ \nunder the compression strategy can be written as \n\n", "itemtype": "equation", "pos": 50756, "prevtext": "\nwhere $e_l \\in \\mathbb{C}$ is the quantization noise independent of $\\hat{x}_l$ \nand is assumed to be Gaussian distributed with zero mean and variance $q_l^{2}$. \nSubstituting \\eqref{eq:compressX} to \\eqref{eq:TxPower}, the transmit power at BS $l$ under the compression strategy can be written as \n\n", "index": 41, "text": "\\begin{equation}\\label{eq:Tx_power_compression}\nP_{l, tx} = \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^{2}, \\quad l \\in \\mathcal{L}. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"P_{l,tx}=\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2},\\quad l\\in%&#10;\\mathcal{L}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mrow><mi>t</mi><mo>\u2062</mo><mi>x</mi></mrow></mrow></msub><mo>=</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\mathbf{e} = \\left[e_1, e_2, \\cdots, e_L \\right]^{T}$ is the quantization noise vector transmitted from all the $L$ BSs. \nAs we can see, besides the inter-user interference and background noise, each user now also receives an additional quantization noise term \n$\\mathbf{h}_k^{H} \\mathbf{e}$ from the BSs. The user received SINR is expressed as \n\n", "itemtype": "equation", "pos": 51345, "prevtext": "\nComparing \\eqref{eq:Tx_power_compression} with \\eqref{eq:Tx_power_data_sharing}, we can see that different from the data-sharing \nstrategy, the BS transmit power in the compression strategy involves a quantization noise power in addition to the beamforming power. \n\n\nSubstituting \\eqref{eq:compressX} into \\eqref{eq:yk_general}, the received signal $y_k$ at user $k$ \nunder the compression strategy can be written as \n\n", "index": 43, "text": "\\begin{equation}\\label{eq:y_k_compression}\ny_k = \\mathbf{h}_k^{H} \\mathbf{w}_k s_k + \\sum_{j \\neq k}\\mathbf{h}_k^{H} \\mathbf{w}_j s_j +  \\mathbf{h}_k^{H} \\mathbf{e} + n_k, \\quad k \\in \\mathcal{K}, \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"y_{k}=\\mathbf{h}_{k}^{H}\\mathbf{w}_{k}s_{k}+\\sum_{j\\neq k}\\mathbf{h}_{k}^{H}%&#10;\\mathbf{w}_{j}s_{j}+\\mathbf{h}_{k}^{H}\\mathbf{e}+n_{k},\\quad k\\in\\mathcal{K},\" display=\"block\"><mrow><mrow><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><mrow><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>k</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>k</mi></msub></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>k</mi></mrow></munder><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow></mrow><mo>+</mo><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><mi>\ud835\udc1e</mi></mrow><mo>+</mo><msub><mi>n</mi><mi>k</mi></msub></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\n\nThe backhaul capacity consumption for the compression strategy is related to the level of quantization noise $q_l^2$: \nlower quantization noise requires higher backhaul rate. \nUnder the forward test channel \\eqref{eq:compressX}, the achievable compression rate is the mutual information between \n$x$ and $\\hat{x}$, according to rate-distortion theory \\cite{EIT}, given as \n$\\log_2 \\left( 1 + \\frac{\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right)$,  \nwhere $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$ is the power of the signal to be compressed, i.e. $\\hat{x}_l$. \nHowever, practical quantizer may be far from the theoretically ideal quantizer. \nSimilar to \\cite{PratikEUSIPCO}, we introduce a notion of gap to rate-distortion limit, denote as $\\Gamma_q > 1$, \nto account for the loss due to practical quantizer and formulate the backhaul capacity consumption for BS $l$ as \n\n", "itemtype": "equation", "pos": 51911, "prevtext": "\nwhere $\\mathbf{e} = \\left[e_1, e_2, \\cdots, e_L \\right]^{T}$ is the quantization noise vector transmitted from all the $L$ BSs. \nAs we can see, besides the inter-user interference and background noise, each user now also receives an additional quantization noise term \n$\\mathbf{h}_k^{H} \\mathbf{e}$ from the BSs. The user received SINR is expressed as \n\n", "index": 45, "text": "\\begin{equation}\\label{eq:sinr_compression}\n\t\t\\text{SINR}_k =\n\\frac{\\left\\vert\\mathbf{h}_k^{H}\\mathbf{w}_k \\right\\vert^2}{\\sum_{j \\neq\nk}\\left\\vert\\mathbf{h}_k^{H}\\mathbf{w}_j\\right\\vert^2 + \n\\sum_{l \\in \\mathcal{L}} \\left\\vert h_{lk} q_l \\right\\vert^2 + \\sigma^2}, \\quad k \\in \\mathcal{K}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\text{SINR}_{k}=\\frac{\\left|\\mathbf{h}_{k}^{H}\\mathbf{w}_{k}\\right|^{2}}{\\sum_%&#10;{j\\neq k}\\left|\\mathbf{h}_{k}^{H}\\mathbf{w}_{j}\\right|^{2}+\\sum_{l\\in\\mathcal{%&#10;L}}\\left|h_{lk}q_{l}\\right|^{2}+\\sigma^{2}},\\quad k\\in\\mathcal{K}.\" display=\"block\"><mrow><mrow><mrow><msub><mtext>SINR</mtext><mi>k</mi></msub><mo>=</mo><mfrac><msup><mrow><mo>|</mo><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>k</mi></msub></mrow><mo>|</mo></mrow><mn>2</mn></msup><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>k</mi></mrow></msub><msup><mrow><mo>|</mo><mrow><msubsup><mi>\ud835\udc21</mi><mi>k</mi><mi>H</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc30</mi><mi>j</mi></msub></mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></msub><msup><mrow><mo>|</mo><mrow><msub><mi>h</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><msub><mi>q</mi><mi>l</mi></msub></mrow><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mfrac></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\n\nSubstituting \\eqref{eq:Tx_power_compression} and \\eqref{eq:bkhaul_compression} into \\eqref{eq:total_power}, the total power \nminimization problem for the compression strategy is formulated as follows\n\\begin{subequations} \\label{prob:compression}\n\\begin{eqnarray} \n& \\hspace{-5mm} \\displaystyle \\min_{\\left\\{w_{lk}, q_l\\right\\}} & \\hspace{-1mm} \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right)+ \n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right\\}} P_{l, \\Delta} \\nonumber \\\\\n & \\quad &\\hspace{1.2cm} + \\rho_l \\log_2 \\left( 1 + \\frac{\\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right) \\Bigg) \n\\label{obj_compression} \\\\\n& \\hspace{-5mm} {\\operatorname{s.t.}} &  \\hspace{-1mm} \\text{SINR}_k \\geq \\gamma_k, \\quad k \\in \\mathcal{K} \\label{sinr_const_compression} \\\\\n&  \\quad & \\hspace{-1mm} \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\leq P_l, \\quad l \\in \\mathcal{L} \\label{compression_power_const}\n\\end{eqnarray}\n\\end{subequations} \nwhere the SINR in \\eqref{sinr_const_compression} is defined in \\eqref{eq:sinr_compression}. \nDue to the indicator function as well as the backhaul rate expression in \\eqref{obj_compression}, \nthe optimization problem \\eqref{prob:compression} is nonconvex. \nIn the following, we describe the techniques to approximate \\eqref{obj_compression} in a convex form. \n\n\n\n\n\\subsection{Proposed Algorithm}\n\nThe difficulties in solving problem \\eqref{prob:compression} lie in both the indicator function and the nonconvex backhaul rate \nexpression in the objective function \\eqref{obj_compression}. \nFor the indicator function, we can utilize the similar technique used in the previous section to approximate \nit using reweighted $\\ell_1$-norm: \n\n\n", "itemtype": "equation", "pos": 53138, "prevtext": "\n\n\nThe backhaul capacity consumption for the compression strategy is related to the level of quantization noise $q_l^2$: \nlower quantization noise requires higher backhaul rate. \nUnder the forward test channel \\eqref{eq:compressX}, the achievable compression rate is the mutual information between \n$x$ and $\\hat{x}$, according to rate-distortion theory \\cite{EIT}, given as \n$\\log_2 \\left( 1 + \\frac{\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right)$,  \nwhere $\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}$ is the power of the signal to be compressed, i.e. $\\hat{x}_l$. \nHowever, practical quantizer may be far from the theoretically ideal quantizer. \nSimilar to \\cite{PratikEUSIPCO}, we introduce a notion of gap to rate-distortion limit, denote as $\\Gamma_q > 1$, \nto account for the loss due to practical quantizer and formulate the backhaul capacity consumption for BS $l$ as \n\n", "index": 47, "text": "\\begin{equation}\\label{eq:bkhaul_compression}\nR_{l}^{BH} = \\log_2 \\left( 1 + \\frac{\\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right), \\quad l \\in \\mathcal{L}. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"R_{l}^{BH}=\\log_{2}\\left(1+\\frac{\\Gamma_{q}\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}%&#10;\\right|^{2}}{q_{l}^{2}}\\right),\\quad l\\in\\mathcal{L}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>R</mi><mi>l</mi><mrow><mi>B</mi><mo>\u2062</mo><mi>H</mi></mrow></msubsup><mo>=</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\beta_l$ is iteratively updated according to the following reweighting function\n\n", "itemtype": "equation", "pos": 55190, "prevtext": "\n\n\nSubstituting \\eqref{eq:Tx_power_compression} and \\eqref{eq:bkhaul_compression} into \\eqref{eq:total_power}, the total power \nminimization problem for the compression strategy is formulated as follows\n\\begin{subequations} \\label{prob:compression}\n\\begin{eqnarray} \n& \\hspace{-5mm} \\displaystyle \\min_{\\left\\{w_{lk}, q_l\\right\\}} & \\hspace{-1mm} \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right)+ \n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right\\}} P_{l, \\Delta} \\nonumber \\\\\n & \\quad &\\hspace{1.2cm} + \\rho_l \\log_2 \\left( 1 + \\frac{\\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right) \\Bigg) \n\\label{obj_compression} \\\\\n& \\hspace{-5mm} {\\operatorname{s.t.}} &  \\hspace{-1mm} \\text{SINR}_k \\geq \\gamma_k, \\quad k \\in \\mathcal{K} \\label{sinr_const_compression} \\\\\n&  \\quad & \\hspace{-1mm} \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\leq P_l, \\quad l \\in \\mathcal{L} \\label{compression_power_const}\n\\end{eqnarray}\n\\end{subequations} \nwhere the SINR in \\eqref{sinr_const_compression} is defined in \\eqref{eq:sinr_compression}. \nDue to the indicator function as well as the backhaul rate expression in \\eqref{obj_compression}, \nthe optimization problem \\eqref{prob:compression} is nonconvex. \nIn the following, we describe the techniques to approximate \\eqref{obj_compression} in a convex form. \n\n\n\n\n\\subsection{Proposed Algorithm}\n\nThe difficulties in solving problem \\eqref{prob:compression} lie in both the indicator function and the nonconvex backhaul rate \nexpression in the objective function \\eqref{obj_compression}. \nFor the indicator function, we can utilize the similar technique used in the previous section to approximate \nit using reweighted $\\ell_1$-norm: \n\n\n", "index": 49, "text": "\\begin{align} \\label{eq:rewgt_compression}\n\\mathbbm{1}_{\\left\\{ \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right\\}}\n & = \\left\\Vert \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2   \\right\\Vert_0  \\nonumber \\\\ \n &\\approx \\beta_l \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2  \\right) \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbbm{1}_{\\left\\{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}%&#10;+q_{l}^{2}\\right\\}}\" display=\"inline\"><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mrow><mrow><mstyle displaystyle=\"false\"><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left\\|\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2}%&#10;\\right\\|_{0}\" display=\"inline\"><mrow><mi/><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>\u2225</mo></mrow><mn>0</mn></msub></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\approx\\beta_{l}\\left(\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{%&#10;2}+q_{l}^{2}\\right)\" display=\"inline\"><mrow><mi/><mo>\u2248</mo><mrow><msub><mi>\u03b2</mi><mi>l</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhere $\\left\\{w_{lk}, q_l \\right\\}$ come from the previous iteration, $\\tau_3 > 0$ is some constant regularization factor, \nand $c_3$ is a constant. \n\n\n\n\n\nFor the backhaul rate \\eqref{eq:bkhaul_compression}, we can express it as a difference of two logarithmic functions: \n$\\log_2 \\left( q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  \\right) - 2 \\rho_l \\log_2 q_l$. \nAlthough the second term $- 2 \\rho_l \\log_2 q_l$ is convex in $q_l$, the first term is still nonconvex. \nTo deal with the nonconvexity of the backhaul rate, we propose to \nsuccessively approximate the first logarithmic function using the following inequality\n\n", "itemtype": "equation", "pos": 55646, "prevtext": "\nwhere $\\beta_l$ is iteratively updated according to the following reweighting function\n\n", "index": 51, "text": "\\begin{equation}\\label{wgt_mu}\n\\beta_l = f\\left(\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 , \\tau_3\\right) \n= \\frac{c_3}{\\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 + \\tau_3}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"\\beta_{l}=f\\left(\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2},\\tau_%&#10;{3}\\right)=\\frac{c_{3}}{\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2%&#10;}+\\tau_{3}}\" display=\"block\"><mrow><msub><mi>\u03b2</mi><mi>l</mi></msub><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>,</mo><msub><mi>\u03c4</mi><mn>3</mn></msub><mo>)</mo></mrow></mrow><mo>=</mo><mfrac><msub><mi>c</mi><mn>3</mn></msub><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>+</mo><msub><mi>\u03c4</mi><mn>3</mn></msub></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\ndue to the concavity of $\\log_2(x)$. The above inequality achieves equality if and only if \n\n", "itemtype": "equation", "pos": 56540, "prevtext": "\nwhere $\\left\\{w_{lk}, q_l \\right\\}$ come from the previous iteration, $\\tau_3 > 0$ is some constant regularization factor, \nand $c_3$ is a constant. \n\n\n\n\n\nFor the backhaul rate \\eqref{eq:bkhaul_compression}, we can express it as a difference of two logarithmic functions: \n$\\log_2 \\left( q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  \\right) - 2 \\rho_l \\log_2 q_l$. \nAlthough the second term $- 2 \\rho_l \\log_2 q_l$ is convex in $q_l$, the first term is still nonconvex. \nTo deal with the nonconvexity of the backhaul rate, we propose to \nsuccessively approximate the first logarithmic function using the following inequality\n\n", "index": 53, "text": "\\begin{align} \\label{ineq:compression}\n &\\log_2 \\left( q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  \\right) \\nonumber \\\\\n & \\leq  ~ \\log_2 \\lambda_l  +  \\frac{ q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{\\lambda_l \\ln 2} - \n\\frac{1}{\\ln 2} \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\log_{2}\\left(q_{l}^{2}+\\Gamma_{q}\\sum_{k\\in\\mathcal{K}}\\left|w_{%&#10;lk}\\right|^{2}\\right)\" display=\"inline\"><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><mrow><mo>(</mo><mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq~{}\\log_{2}\\lambda_{l}+\\frac{q_{l}^{2}+\\Gamma_{q}\\sum_{k\\in%&#10;\\mathcal{K}}\\left|w_{lk}\\right|^{2}}{\\lambda_{l}\\ln 2}-\\frac{1}{\\ln 2}\" display=\"inline\"><mrow><mi/><mo rspace=\"5.8pt\">\u2264</mo><mrow><mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><msub><mi>\u03bb</mi><mi>l</mi></msub></mrow><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mrow><msub><mi>\u03bb</mi><mi>l</mi></msub><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mn>2</mn></mrow></mrow></mfrac></mstyle></mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>ln</mi><mo>\u2061</mo><mn>2</mn></mrow></mfrac></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": " \nThe right-hand side of \\eqref{ineq:compression} is a convex quadratic function in $\\left\\{ w_{lk}, q_l \\right\\}$ for fixed \n$\\lambda_l$. \nThis fact motivates us to successively solve the \nproblem \\eqref{prob:compression} with $\\log_2 \\left( q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  \\right)$ replaced by the right-hand side of \\eqref{ineq:compression} for fixed $\\lambda_l$, then to \niteratively update $\\lambda_l$ according to \\eqref{lambda_update}. \n\nCombining the above described $\\ell_1$-norm reweighting and successive convex approximation techniques, \nwe get the resulting optimization problem under fixed $\\beta_l$ and $\\lambda_l$ as \n\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\ndue to the concavity of $\\log_2(x)$. The above inequality achieves equality if and only if \n\n", "index": 55, "text": "\\begin{equation}\\label{lambda_update}\n\\lambda_l = q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"\\lambda_{l}=q_{l}^{2}+\\Gamma_{q}\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}.\" display=\"block\"><mrow><mrow><msub><mi>\u03bb</mi><mi>l</mi></msub><mo>=</mo><mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\nwhere $\\phi_{l} = \\eta_l + \\beta_l P_{l, \\Delta} + \\frac{\\rho_l \\Gamma_q}{\\lambda_l \\ln 2}$ and \n$\\psi_{l} = \\eta_l + \\beta_l P_{l, \\Delta} + \\frac{\\rho_l}{\\lambda_l \\ln 2}$. \nSimilar to the SINR constraint in \\eqref{sinr_const}, the constraint \\eqref{sinr_const_compression} can also be \nequivalently reformulated as an SOC constraint. \nThus, problem \\eqref{prob:approx_compression1} is a convex optimization problem and can be solved \nefficiently using standard convex optimization solver, e.g. \\cite{CVX}, with polynomial complexity. \n\n\n\n\n\n\\begin{algorithm}[t]\n{\\bf Initialization}: Set the initial values for $\\left\\{ \\beta_l \\right\\}$ and $\\left\\{ \\lambda_l \\right\\}$\naccording to \\eqref{wgt_mu} and \\eqref{lambda_update} respectively with $\\left\\{ w_{lk}, q_l \\right\\}$ chosen as a feasible \npoint of problem \\eqref{prob:compression}; \\\\\n{\\bf Repeat}:\n\\begin{enumerate}\n\\item Fix $\\left\\{ \\beta_l, \\lambda_l \\right\\}$, find the optimal \n$\\left\\{ w_{lk}, q_l \\right\\}$ by solving the convex optimization problem \\eqref{prob:approx_compression1}; \n\\item Update $\\left\\{ \\beta_l \\right\\}$ and $\\left\\{ \\lambda_l \\right\\}$\naccording to \\eqref{wgt_mu} and \\eqref{lambda_update} respectively. \n\\end{enumerate}\n{\\bf Until} convergence\n\\caption{Total Power Minimization for Compression Strategy}\n\\label{alg:compression}\n\\end{algorithm}\n\n\n\n\nWe summarize the proposed algorithm for solving problem \\eqref{prob:compression} in \nAlgorithm~\\ref{alg:compression}, which admits guaranteed convergence property as stated in the following theorem. \n\\begin{theorem}\\label{thm:2}\nStarting with any initial point, the sequence $\\left\\{ w_{lk}^{(n)}, q_l^{(n)} \\right\\}_{n=1}^{\\infty}$ generated by Algorithm~\\ref{alg:compression} with the reweighting function in \\eqref{wgt_mu} chosen as \n\\eqref{eq:reweight} is guaranteed to converge. \n\\end{theorem}\n\\begin{IEEEproof}\nSee Appdendix~\\ref{apdx:b}\n\\end{IEEEproof}\n\n\n\nAlgorithm~\\ref{alg:compression} shows a similar computational complexity as Algorithm~\\ref{alg:data_sharing} but with \nadditional $L$ quantization noise variables to be optimized in each iteration.  \nAssuming that Algorithm~\\ref{alg:compression} converges in $T_2$ iterations, its complexity order \nis then given as $O\\left( T_2\\left(L + K \\right) \\left(LK + L\\right)^3 \\right)$. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Generalization to the Multi-Antenna System}\n\nAlgorithm~\\ref{alg:compression} can be readily applied to the scenario where multiple transmit antennas are available at the BSs assuming \nthat the CP performs independent compression for each antenna. \nJoint compression among the antennas may improve the performance but results in a different optimization problem. \nSimilar to Algorithm~\\ref{alg:data_sharing}, \ngeneralization of Algorithm~\\ref{alg:compression} to multiple receive antennas at the user side is also straightforward if the receive beamformer is assumed to be fixed, however, joint design of transmit and receive beamformer is \nby no means trivial and requires additional efforts. \n\n\n\n\n\n\\section{Numerical Evaluation of Energy Efficiency}\\label{sec:simulations}\n\n\n\n\\begin{table}[t]\n\\centering\n\\caption{Simulation Parameters.}\n\\label{table:system-parameter}\n\\begin{tabular}{|c|c|}\n\\hline \nCellular  & Hexagonal  \\\\\n     Layout        &  $7$-cell wrapped-around \\\\\\hline\nChannel bandwidth & $10$ MHz    \\\\ \\hline\nDistance between cells  &  $0.8$ km \\\\ \\hline\nNumber of RRHs$/$cell  &  $4$   \\\\ \\hline\nNumber of antennas$/$(RRH, user)  &   $(1, 1)$ \\\\ \\hline\nMaximum transmit power for RRH $P_l$   &  $20$ Watts \\\\ \\hline\nActive mode power for RRH $P_{l, active}$ & $84$ Watts \\\\ \\hline\nSleep mode power for RRH $P_{l, sleep}$ & $56$ Watts \\\\ \\hline\nSlope of transmit power $\\eta_l$ & $2.8$ \\\\ \\hline\nBackhaul link capacity $C_l$ & $100$ Mbps \\\\ \\hline\nMaximum backhaul power $P_{l,max}^{BH}$ & $50$ Watts \\\\ \\hline\n Antenna gain & $15$ dBi \\\\ \\hline\n Background noise  & $-169$ dBm/Hz \\\\ \\hline\n Path loss from RRH to user & $128.1+ 37.6 \\log_{10}(d)$ \\\\ \\hline\nLog-normal shadowing & $8$ dB \\\\ \\hline\nRayleigh small scale fading & $0$ dB  \\\\ \\hline\nSNR gap $\\Gamma_m$ & $0$ dB \\\\ \\hline\nGap to rate-distortion limit $\\Gamma_q$ & $4.3$ dB \\\\ \\hline\nReweighting parameters ($\\tau_1, \\tau_2, \\tau_3$) & $(10^{-5}, 10^{-8}, 10^{-5})$ \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[cc][cc][0.8]{km}\n\\psfrag{ylabel}[cc][cc][0.8]{km}\n\\psfrag{0}[cr][cr][0.7]{$0$}\n\\psfrag{0.5}[cr][cr][0.7]{$0.5$}\n\\psfrag{1}[cr][cr][0.7]{$1$}\n\\psfrag{1.5}[cr][cr][0.7]{$1.5$}\n\\psfrag{-0.5}[cr][cr][0.7]{$-0.5$}\n\\psfrag{-1}[cr][cr][0.7]{$-1$}\n\\psfrag{-1.5}[cc][cc][0.7]{$-1.5$}\n\\psfrag{x4}[cr][cr][0.7]{$0$}\n\\psfrag{x5}[cr][cr][0.7]{$0.5$}\n\\psfrag{x6}[cr][cr][0.7]{$1$}\n\\psfrag{x7}[cr][cr][0.7]{$1.5$}\n\\psfrag{x3}[cr][cr][0.7]{$-0.5$}\n\\psfrag{x2}[cr][cr][0.7]{$-1$}\n\\psfrag{x1}[cc][cc][0.7]{$-1.5$}\n\n  \\centering\n  \\includegraphics[width=0.45\\textwidth]{topology.eps}\n\\caption{A cellular topology with $7$ cells and $4$ RRHs each cell, where each dot represents a RRH.}\n\\label{fig:topology}\n\\end{figure}\n\n\n\n\n\nIn this section, we evaluate the energy efficiency of the data-sharing and compression strategies \nfor downlink C-RAN using the proposed algorithms for a $7$-cell network with wrapped-around topology.\nEach cell here refers to a geographic area with $4$ RRHs as shown in Fig.~\\ref{fig:topology}. \nEquivalently, the network consists of $28$ BSs. \nThe out-of-cell interference combined with background noise is set as $-150$ dBm$/$Hz. \nThe gap to rate-distortion limit is set as $\\Gamma_q = 4.3$ dB corresponding to the uncoded fixed rate \nuniform scalar quantizer \\cite{Gray98}. \nFor simplicity, the SNR gap is set to be $\\Gamma_m = 0$ dB. \nThe parameters in the BS power consumption model \\eqref{eq:bs_power} are taken from \n\\cite{Auer11} while the parameters for the backhaul power model \\eqref{eq:bkhaul_power} are from \\cite{Fehske10}. \nAll the parameters related to the simulations are listed in Table~\\ref{table:system-parameter}. \n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[tc][Bc][0.8]{Iteration }\n\\psfrag{ylabel}[Bc][tc][0.8]{Number of Active BSs}\n\\psfrag{Algorithm 1 w/ 1 user/cell extraaaaaa}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 1 w/ 2 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 1 w/ 3 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $3$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 1 user/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 2 w/ 2 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 3 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $3$ users$/$cell}\n\\psfrag{x1}[cc][cr][0.7]{$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{y0}[rc][rc][0.7]{$5$}\n\\psfrag{y1}[rc][rc][0.7]{$10$}\n\\psfrag{y2}[rc][rc][0.7]{$15$}\n\\psfrag{y3}[rc][rc][0.7]{$20$}\n\\psfrag{y4}[rc][rc][0.7]{$25$}\n\\psfrag{y5}[rc][rc][0.7]{$30$}\n\\psfrag{y6}[rc][rc][0.7]{$35$}\n  \\centering\n  \\includegraphics[width=0.45\\textwidth]{Per_Iteration_Active_BS.eps}\n\\caption{Trajectories of number of active BSs under $r_k = 20$ Mbps target rate for each user.}\n\\label{fig:DataSharingActiveBSs}\n\\end{figure}\n\n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[tc][Bc][0.8]{Iteration}\n\\psfrag{ylabel}[Bc][tc][0.7]{Objective Value of Problem \\eqref{prob:data_sharing_approx_lim}$/$\\eqref{prob:compression_approx}}\n\\psfrag{Algorithm 1 w/ 1 user/cell extraaaaaaaa}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 1 w/ 2 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 1 w/ 3 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $3$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 1 user/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 2 w/ 2 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 3 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $3$ users$/$cell}\n\\psfrag{x1}[cc][cr][0.7]{$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{x8}[cc][cc][0.7]{$80$}\n\\psfrag{0}[rc][rc][0.7]{$0$}\n\\psfrag{400}[rc][rc][0.7]{$400$}\n\\psfrag{800}[rc][rc][0.7]{$800$}\n\\psfrag{1200}[rc][rc][0.7]{$1200$}\n\\psfrag{1600}[rc][rc][0.7]{$1600$}\n\\psfrag{2000}[rc][rc][0.7]{$2000$}\n  \\includegraphics[width=0.45\\textwidth]{Per_Iteration_Obj.eps}\n\\caption{Convergence behavior of proposed algorithms under $r_k = 20$ Mbps target rate for each user.}\n\\label{fig:compressionObj}\n\\end{figure}\n\n\n\n\n\n\nWe first evaluate the effectiveness of the proposed $\\ell_1$-norm reweighting technique in turning off BSs.\nWe plot the number of active BSs remained in each iteration for both data-sharing (Algorithm~\\ref{alg:data_sharing}) \nand compression (Algorithm~\\ref{alg:compression}) strategies in Fig.~\\ref{fig:DataSharingActiveBSs}. \nThe user target rate is set to be $20$ Mbps for every user and different number of scheduled users are simulated. \nInstead of considering all the $28$ BSs in the entire network as potential serving BSs for each user, we set the \ninitial BS cluster for each user as the strongest $L_c = 14$ BSs to \nreduce the amount of CSI acquisition for the CP. \nFrom Fig.~\\ref{fig:DataSharingActiveBSs} we can see that all the BSs are active at the first iteration, however,  \nthe number of active BSs decreases as the iteration goes on.  \nIntuitively, more users are served, more BSs need to remain active. \nThis can be verified from Fig.~\\ref{fig:DataSharingActiveBSs}. \nWe also observe from Fig.~\\ref{fig:DataSharingActiveBSs} that Algorithm~\\ref{alg:data_sharing} for data-sharing \nexhibits faster convergence speed than Algorithm~\\ref{alg:compression} for compression, \nwhere the former converges within $30$ iterations while the later requires $50$ iterations to converge \nin the worst case. \n\n\n\nWe then evaluate the convergence behavior of the proposed algorithms in Fig.~\\ref{fig:compressionObj}.  \nAs in Fig.~\\ref{fig:DataSharingActiveBSs}, different number of scheduled users are tested and each user's \ntarget rate is set to be $20$ Mbps. \nAs we can see, the objective values monotonically decrease and converge for both the data-sharing (Algorithm~\\ref{alg:data_sharing}) \nand the compression (Algorithm~\\ref{alg:compression}) strategies. \nSimilar to Fig.~\\ref{fig:DataSharingActiveBSs}, we also observe faster convergence speed for data-sharing than \nfor compression in Fig.~\\ref{fig:compressionObj}. \nThis is possibly due to the fact that compression strategy involves more variables to be optimized. \n\n\n\nWe now compare the performance of the data-sharing strategy and the compression strategy in terms of power \nsaving in Fig.~\\ref{sim:total_power}. \nIn addition, we consider two reference schemes. \nIn the first scheme, each user is only served by its strongest BS that is not already associated with another user.\nThis scheme is termed as ``Single BS Association'', for which the transmit power for each user can be minimized using  \nthe strategy in \\cite{yates1995}. \nIn the second scheme, each user's message is shared among the $4$ RRHs in its own cell and \nis cooperatively served by the $4$ RRHs using the \ncoordinated beamforming strategy of \\cite{dahrouj10}. Such scheme is termed as ``Per-Cell CoMP''.  \nThe ``Single BS Association'' and ``Per-Cell CoMP'' are two extreme cases in terms of number of active BSs: \nthe former only has $K$ (number of scheduled users) active BSs while in the latter all the $28$ BSs in the entire network remain active.\nEach point in Fig.~\\ref{sim:total_power} is averaged over $100$ channel realizations. \n\n\n\nAs we can see from Fig.~\\ref{sim:total_power}, ``Per-Cell CoMP'' consumes the most power since all the BSs are active in this scheme. \n``Single BS Association'' consumes the least power, similar to the data-sharing strategy, but only at low user rate regime \nbecause the minimum number of BSs are selected to serve the users in this scheme. \nHowever, as the user rate or the number of scheduled users increases, ``Single BS Association'' becomes infeasible very quickly. \nFor instance, in Fig.~\\ref{sim:total_power}(b) where there are $2$ users per cell, ``Single BS Association'' can only support each user \nwith $10$ Mbps service rate, while in Fig.~\\ref{sim:total_power}(c) the case of 3 users per cell, ``Single BS Association'' \nis not feasible even at $10$ Mbps per user. \n\n\n\n\n\\begin{figure*}[t]\n\\centering\n\\psfrag{xlabel}[tc][cc][0.7]{User Target Rate (Mbps)}\n\\psfrag{ylabel}[tc][cc][0.7]{Total Power Consumption (kWatts)}\n\\psfrag{Compression}[Bl][Bl][0.65]{Compression}\n\\psfrag{Data Sharing}[Bl][Bl][0.65]{Data-Sharing}\n\\psfrag{Per Cell CoMP}[Bl][Bl][0.65]{Per-Cell CoMP}\n\\psfrag{Single BS Association}[Bl][Bl][0.65]{Single BS Association}\n\\psfrag{x1}[cc][cc][0.7]{\\hspace{2mm}$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{1500}[cc][cc][0.7]{\\hspace{2mm}$1.5$}\n\\psfrag{2000}[cc][cc][0.7]{\\hspace{2mm}$2.0$}\n\\psfrag{2500}[cc][cc][0.7]{\\hspace{2mm}$2.5$}\n\\psfrag{3000}[cc][cc][0.7]{\\hspace{2mm}$3.0$}\n\\psfrag{3500}[cc][cc][0.7]{\\hspace{2mm}$3.5$}\n\\psfrag{4000}[cc][cc][0.7]{\\hspace{2mm}$4.0$}\n\\psfrag{4500}[cc][cc][0.7]{\\hspace{2mm}$4.5$}\n\\psfrag{5000}[cc][cc][0.7]{\\hspace{2mm}$5.0$}\n\\subfloat[1 user per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user1.eps}\n\\label{sim:power_u1}}\n\\hfil\n\\subfloat[2 users per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user2.eps}\n\\label{sim:power_u2}}\n\\hfil\n\\subfloat[3 users per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user3.eps}\n\\label{sim:power_u3}}\n\\caption{Total power consumption comparison between different schemes. \nMissing points indicate that the corresponding scheme is infeasible. \nFor instance, ``Single BS Association'' is feasible only for the first \nthree points in (a), and is only feasible for the very first point in (b), and is infeasible in (c). \nFor ``Per-Cell CoMP'' scheme in (c), it is only feasible at $10$ Mbps target rate.}\n\\label{sim:total_power}\n\\end{figure*}\n\n\n\nIt is worth noting that ``Single BS Association'' consumes the same amount of power as data-sharing \nin the low user target rate regime in Fig.~\\ref{sim:total_power}, as the latter essentially reduces to single BS association at low user rates. However, there is still significant advantage in migrating signal processing to the cloud in a C-RAN as compared to the conventional cellular architecture in term of computation power saving, which is not included in the model in this paper. It is also worth noting that the optimized data-sharing and compression strategies outperform the non-optimized per-Cell CoMP significantly in Fig.~\\ref{sim:total_power}, highlighting the importance of optimization approaches proposed in this paper. \nOther optimized CoMP schemes with larger cooperation cluster may consume less BS transmission power, \nhowever, the overall power consumptions can be still very high if all the BSs remain active. \n\n\nWe also observe from Fig.~\\ref{sim:total_power} that neither the data-sharing nor the compression strategy \ndominates the other over the entire user target rate regime. \nFor example in Fig.~\\ref{sim:total_power}(b), although data-sharing consumes less power \nthan compression when the user target rate is below $30$ Mbps, \nits power consumption increases dramatically with the user rate and \neventually crosses over the total power consumed by compression after $40$ Mbps target rate. \nSimilar trend can be observed from Fig.~\\ref{sim:total_power}(a) and \\ref{sim:total_power}(c). \nThis trend is parallel to the observation made in \\cite{PratikEUSIPCO}, in which these two downlink strategies are \ncompared from the utility maximization perspective with limited backhaul constraint. \nIt is observed in \\cite{PratikEUSIPCO} that with low backhaul rate, data-sharing produces higher utility than compression while \nwith high backhaul rate, compression outperforms data-sharing. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure}[t]\n  \\centering\n\t\\psfrag{xlabel}[tc][Bc][0.7]{User Target Rate (Mbps) }\n\\psfrag{ylabel}[Bc][tc][0.7]{Power (kWatts)}\n\\psfrag{Data Sharing BS Power}[Bl][Bl][0.7]{Data-Sharing BS Power}\n\\psfrag{Data Sharing Backhaul Power}[Bl][Bl][0.7]{Data-Sharing Backhaul Power}\n\\psfrag{Compression BS Power}[Bl][Bl][0.7]{Compression BS Power}\n\\psfrag{Compression Backhaul Power}[Bl][Bl][0.7]{Compression Backhaul Power}\n\\psfrag{x1}[cc][cc][0.85]{$10$}\n\\psfrag{x2}[cc][cc][0.85]{$20$}\n\\psfrag{x3}[cc][cc][0.85]{$30$}\n\\psfrag{x4}[cc][cc][0.85]{$40$}\n\\psfrag{x5}[cc][cc][0.85]{$50$}\n\\psfrag{x6}[cc][cc][0.85]{$60$}\n\\psfrag{x7}[cc][cc][0.85]{$70$}\n\\psfrag{1}[cc][cc][0.85]{$1$}\n\\psfrag{2}[cc][cc][0.85]{$2$}\n\\psfrag{3}[cc][cc][0.85]{$3$}\n\\psfrag{4}[cc][cc][0.85]{$4$}\n\\psfrag{5}[cc][cc][0.85]{$5$}\n\\psfrag{6}[cc][cc][0.85]{$6$}\n\\psfrag{7}[cc][cc][0.85]{$7$}\t\n\\psfrag{0}[cc][cc][0.85]{$0$}\t\n  \\includegraphics[width= 0.45\\textwidth]{PowerDecomp.eps}\n\\caption{Power consumptions of BSs and backhaul links with $2$ users each cell.}\n\\label{fig:power_decomp}\n\\end{figure}\n\n\n\n\n\nTo investigate further, \nwe plot the individual power consumption of BSs and backhaul links for both the \ndata-sharing and the compression strategies in Fig.~\\ref{fig:power_decomp} for the case of $2$ users per cell. \nAs seen from Fig.~\\ref{fig:power_decomp}, although the BS power consumptions for data-sharing and compression \nare similar in each case of the user target rate, the backhaul power consumptions are significantly different \nand are the determining factor in the choice of strategies.  \nAs the user target rate increases, the backhaul power consumption for data-sharing increases significantly \nand crosses over the compression strategy at around $30$ Mbps. \nThis is because in data-sharing, each user's message needs to be delivered to each one of its serving BSs through backhaul links.\nSo, the backhaul rate directly depends on both the user target rate and the BS cluster size. \nNote that as user target rate increases, the size of serving BS cluster also increases. \nThe two factors together contribute to a much higher backhaul rate. \nIn contrast, the backhaul rate of compression strategy depends on \nthe logarithm of the signal-to-quantization-noise ratio, which only increases gradually as user target rate increases. \nAlso, note that in the low user rate regime, \ndata-sharing consumes less backhaul power than compression in Fig.~\\ref{fig:power_decomp}. \nThis is because it is more efficient to share data directly than to compress when only a few BSs are involved. \n\n\n\n\n\nIn Fig.~\\ref{sim:active_bs}, we compare the percentage of active BSs in the data-sharing strategy versus in the compression strategy. \nSimilar to Fig.~\\ref{sim:total_power}, each point in Fig.~\\ref{sim:active_bs} is averaged over $100$ channel realizations. \nAs we can see, with higher user target rate and more users to be served, more BSs need to remain active for \ntransmission. Also, from Fig.~\\ref{sim:active_bs}, it is observed that the compression strategy tends to turn off more BSs than the \ndata-sharing strategy. \n\n\n\n\\begin{figure*}[!t]\n\\centering\n\\psfrag{xlabel}[tc][cc][0.6]{User Target Rate (Mbps)}\n\\psfrag{ylabel}[cc][cc][0.6]{{Fraction of Active BSs}}\n\\psfrag{Compression}[Bl][Bl][0.65]{Compression}\n\\psfrag{Data Sharing}[Bl][Bl][0.65]{Data Sharing}\n\\psfrag{10}[cc][cr][0.7]{$10$}\n\\psfrag{20}[cc][cc][0.7]{$20$}\n\\psfrag{30}[cc][cc][0.7]{$30$}\n\\psfrag{40}[cc][cc][0.7]{$40$}\n\\psfrag{50}[cc][cc][0.7]{$50$}\n\\psfrag{60}[cc][cc][0.7]{$60$}\n\\psfrag{70}[cc][cc][0.7]{$70$}\n\\psfrag{0.2}[cc][cc][0.7]{$0.2$}\n\\psfrag{0.3}[cc][cc][0.7]{$0.3$}\n\\psfrag{0.4}[cc][cc][0.7]{$0.4$}\n\\psfrag{0.5}[cc][cc][0.7]{$0.5$}\n\\psfrag{0.6}[cc][cc][0.7]{$0.6$}\n\\psfrag{0.7}[cc][cc][0.7]{$0.7$}\n\\psfrag{0.8}[cc][cc][0.7]{$0.8$}\n\\psfrag{0.9}[cc][cc][0.7]{$0.9$}\n\\psfrag{0.65}[cc][cc][0.7]{$0.65$}\n\\psfrag{0.75}[cc][cc][0.7]{$0.75$}\n\\psfrag{0.85}[cc][cc][0.7]{$0.85$}\n\\psfrag{0.95}[cc][cc][0.7]{$0.95$}\n\\psfrag{1}[cc][cl][0.8]{\\hspace{-2mm}$1.0$}\n\\subfloat[1 user per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_1.eps}\n\\label{sim:bs_u1}}\n\\hfil\n\\subfloat[2 users per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_2.eps}\n\\label{sim:bs_u2}}\n\\hfil\n\\subfloat[3 users per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_3.eps}\n\\label{sim:bs_u3}}\n\\caption{Comparison of average fraction of active BSs. Note that the ``Per-Cell CoMP'' scheme considered in Fig.~\\ref{sim:total_power} \ncorresponds to $100\\%$ of active BSs, while the percentage of active BSs for ``Single BS Association'' \nscheme depends on the number of users in each cell, which are $25\\%$, $50\\%$ and $75\\%$ respectively for $1$, $2$ and $3$ users per cell, \nalthough only those few points corresponding to Fig.~\\ref{sim:total_power} are feasible.}\n\\label{sim:active_bs}\n\\end{figure*}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Conclusion}\\label{sec:conclusion}\n\n\nThis paper compares the energy efficiency between the data-sharing strategy and the compression strategy in downlink C-RAN. \nWe formulate the problem as that of minimizing the total network power consumption subject to user target rate constraints, \nwith both the BS power consumption and the backhaul power consumption taken into account. \nBy taking advantage of the $\\ell_1$-norm reweighting technique and successive convex approximation technique, we \ntransform the nonconvex optimization problems into convex form and devise efficient algorithms with provable \nconvergence guarantees. \n\nThe main conclusions of this paper are that C-RAN significantly \nimproves the range of feasible user data rates in a wireless cellular network, and that \nboth data-sharing and compression strategies bring \nmuch improved energy efficiency to downlink C-RAN as compared to non-optimized CoMP. \nMoreover, between the data-sharing strategy and the compression strategy, either may be preferred \ndepending on the different target rate regimes: at low user target rate, data-sharing consumes less power, while at high user target \nrate compression is preferred since the backhaul rate for data-sharing increases significantly as user \nrate increases. \n\n\n\n\n\n\n\n\n\\appendices\n\n\\section{Proof for Theorem~\\ref{thm:1}}\\label{apdx:a}\n\nThe idea is to show that Algorithm~\\ref{alg:data_sharing} \nconverges to the stationary point solution of the following problem: \n\n", "itemtype": "equation", "pos": 57772, "prevtext": " \nThe right-hand side of \\eqref{ineq:compression} is a convex quadratic function in $\\left\\{ w_{lk}, q_l \\right\\}$ for fixed \n$\\lambda_l$. \nThis fact motivates us to successively solve the \nproblem \\eqref{prob:compression} with $\\log_2 \\left( q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  \\right)$ replaced by the right-hand side of \\eqref{ineq:compression} for fixed $\\lambda_l$, then to \niteratively update $\\lambda_l$ according to \\eqref{lambda_update}. \n\nCombining the above described $\\ell_1$-norm reweighting and successive convex approximation techniques, \nwe get the resulting optimization problem under fixed $\\beta_l$ and $\\lambda_l$ as \n\n\n", "index": 57, "text": "\\begin{align} \\label{prob:approx_compression1}\n\\displaystyle {\\operatorname{minimize}}_{\\left\\{w_{lk}, q_l\\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \\sum_{k\\in\\mathcal{K}} \\phi_{l} \\left\\vert w_{lk} \\right\\vert^{2} + \\sum_{l\\in\\mathcal{L}} \\left( \\psi_{l} q_l^2 - 2 \\rho_l \\log_2 q_l\\right) \\nonumber \\\\ \n& \\hspace{1.5cm} + \\underbrace{\\sum_{l\\in\\mathcal{L}} \\rho_l \\left( \\log_2 \\lambda_l -  \\frac{1}{\\ln 2} \\right)}_{\\text{constant}} \\\\\n {\\operatorname{subject \\text{ } to}}  & \\quad \\eqref{sinr_const_compression}, ~~ \\eqref{compression_power_const} \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle{\\operatorname{minimize}}_{\\left\\{w_{lk},q_{l}\\right\\}}\" display=\"inline\"><msub><mo>minimize</mo><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>,</mo><msub><mi>q</mi><mi>l</mi></msub><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\sum_{k\\in\\mathcal{K}}\\phi_{l}\\left|w_%&#10;{lk}\\right|^{2}+\\sum_{l\\in\\mathcal{L}}\\left(\\psi_{l}q_{l}^{2}-2\\rho_{l}\\log_{2%&#10;}q_{l}\\right)\" display=\"inline\"><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mrow><msub><mi>\u03d5</mi><mi>l</mi></msub><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo>(</mo><mrow><mrow><msub><mi>\u03c8</mi><mi>l</mi></msub><mo>\u2062</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mo>\u2062</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>\u2061</mo><msub><mi>q</mi><mi>l</mi></msub></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\underbrace{\\sum_{l\\in\\mathcal{L}}\\rho_{l}\\left(%&#10;\\log_{2}\\lambda_{l}-\\frac{1}{\\ln 2}\\right)}_{\\text{constant}}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><munder><munder accentunder=\"true\"><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo movablelimits=\"false\">\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><msub><mi>\u03c1</mi><mi>l</mi></msub><mo movablelimits=\"false\">\u2062</mo><mrow><mo movablelimits=\"false\">(</mo><mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo movablelimits=\"false\">\u2061</mo><msub><mi>\u03bb</mi><mi>l</mi></msub></mrow><mo movablelimits=\"false\">-</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>ln</mi><mo movablelimits=\"false\">\u2061</mo><mn>2</mn></mrow></mfrac></mstyle></mrow><mo movablelimits=\"false\">)</mo></mrow></mrow></mrow><mo movablelimits=\"false\">\u23df</mo></munder><mtext>constant</mtext></munder></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\eqref{sinr_const_compression},~{}~{}\\eqref{compression_%&#10;power_const}\" display=\"inline\"><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mi>(</mi><mo>\u2062</mo><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\">LABEL:sinr_const_compression</span></mtext><mo>\u2062</mo><mi>)</mi></mrow><mo rspace=\"9.1pt\">,</mo><mrow><mi>(</mi><mo>\u2062</mo><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\">LABEL:compression_power_const</span></mtext><mo>\u2062</mo><mi>)</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\n\n\n\n\nFirst, we note that problem \\eqref{prob:data_sharing_approx_lim} differs from the original problem \\eqref{prob:data_sharing} in that \nthe $\\ell_0$-norms in the objective function \\eqref{obj_data_sharing} are approximated by the logarithmic functions in \n\\eqref{prob:data_sharing_approx_lim}. This approximation stems from the relation that with $x \\geq 0$, \n\n", "itemtype": "equation", "pos": 80990, "prevtext": "\n\nwhere $\\phi_{l} = \\eta_l + \\beta_l P_{l, \\Delta} + \\frac{\\rho_l \\Gamma_q}{\\lambda_l \\ln 2}$ and \n$\\psi_{l} = \\eta_l + \\beta_l P_{l, \\Delta} + \\frac{\\rho_l}{\\lambda_l \\ln 2}$. \nSimilar to the SINR constraint in \\eqref{sinr_const}, the constraint \\eqref{sinr_const_compression} can also be \nequivalently reformulated as an SOC constraint. \nThus, problem \\eqref{prob:approx_compression1} is a convex optimization problem and can be solved \nefficiently using standard convex optimization solver, e.g. \\cite{CVX}, with polynomial complexity. \n\n\n\n\n\n\\begin{algorithm}[t]\n{\\bf Initialization}: Set the initial values for $\\left\\{ \\beta_l \\right\\}$ and $\\left\\{ \\lambda_l \\right\\}$\naccording to \\eqref{wgt_mu} and \\eqref{lambda_update} respectively with $\\left\\{ w_{lk}, q_l \\right\\}$ chosen as a feasible \npoint of problem \\eqref{prob:compression}; \\\\\n{\\bf Repeat}:\n\\begin{enumerate}\n\\item Fix $\\left\\{ \\beta_l, \\lambda_l \\right\\}$, find the optimal \n$\\left\\{ w_{lk}, q_l \\right\\}$ by solving the convex optimization problem \\eqref{prob:approx_compression1}; \n\\item Update $\\left\\{ \\beta_l \\right\\}$ and $\\left\\{ \\lambda_l \\right\\}$\naccording to \\eqref{wgt_mu} and \\eqref{lambda_update} respectively. \n\\end{enumerate}\n{\\bf Until} convergence\n\\caption{Total Power Minimization for Compression Strategy}\n\\label{alg:compression}\n\\end{algorithm}\n\n\n\n\nWe summarize the proposed algorithm for solving problem \\eqref{prob:compression} in \nAlgorithm~\\ref{alg:compression}, which admits guaranteed convergence property as stated in the following theorem. \n\\begin{theorem}\\label{thm:2}\nStarting with any initial point, the sequence $\\left\\{ w_{lk}^{(n)}, q_l^{(n)} \\right\\}_{n=1}^{\\infty}$ generated by Algorithm~\\ref{alg:compression} with the reweighting function in \\eqref{wgt_mu} chosen as \n\\eqref{eq:reweight} is guaranteed to converge. \n\\end{theorem}\n\\begin{IEEEproof}\nSee Appdendix~\\ref{apdx:b}\n\\end{IEEEproof}\n\n\n\nAlgorithm~\\ref{alg:compression} shows a similar computational complexity as Algorithm~\\ref{alg:data_sharing} but with \nadditional $L$ quantization noise variables to be optimized in each iteration.  \nAssuming that Algorithm~\\ref{alg:compression} converges in $T_2$ iterations, its complexity order \nis then given as $O\\left( T_2\\left(L + K \\right) \\left(LK + L\\right)^3 \\right)$. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Generalization to the Multi-Antenna System}\n\nAlgorithm~\\ref{alg:compression} can be readily applied to the scenario where multiple transmit antennas are available at the BSs assuming \nthat the CP performs independent compression for each antenna. \nJoint compression among the antennas may improve the performance but results in a different optimization problem. \nSimilar to Algorithm~\\ref{alg:data_sharing}, \ngeneralization of Algorithm~\\ref{alg:compression} to multiple receive antennas at the user side is also straightforward if the receive beamformer is assumed to be fixed, however, joint design of transmit and receive beamformer is \nby no means trivial and requires additional efforts. \n\n\n\n\n\n\\section{Numerical Evaluation of Energy Efficiency}\\label{sec:simulations}\n\n\n\n\\begin{table}[t]\n\\centering\n\\caption{Simulation Parameters.}\n\\label{table:system-parameter}\n\\begin{tabular}{|c|c|}\n\\hline \nCellular  & Hexagonal  \\\\\n     Layout        &  $7$-cell wrapped-around \\\\\\hline\nChannel bandwidth & $10$ MHz    \\\\ \\hline\nDistance between cells  &  $0.8$ km \\\\ \\hline\nNumber of RRHs$/$cell  &  $4$   \\\\ \\hline\nNumber of antennas$/$(RRH, user)  &   $(1, 1)$ \\\\ \\hline\nMaximum transmit power for RRH $P_l$   &  $20$ Watts \\\\ \\hline\nActive mode power for RRH $P_{l, active}$ & $84$ Watts \\\\ \\hline\nSleep mode power for RRH $P_{l, sleep}$ & $56$ Watts \\\\ \\hline\nSlope of transmit power $\\eta_l$ & $2.8$ \\\\ \\hline\nBackhaul link capacity $C_l$ & $100$ Mbps \\\\ \\hline\nMaximum backhaul power $P_{l,max}^{BH}$ & $50$ Watts \\\\ \\hline\n Antenna gain & $15$ dBi \\\\ \\hline\n Background noise  & $-169$ dBm/Hz \\\\ \\hline\n Path loss from RRH to user & $128.1+ 37.6 \\log_{10}(d)$ \\\\ \\hline\nLog-normal shadowing & $8$ dB \\\\ \\hline\nRayleigh small scale fading & $0$ dB  \\\\ \\hline\nSNR gap $\\Gamma_m$ & $0$ dB \\\\ \\hline\nGap to rate-distortion limit $\\Gamma_q$ & $4.3$ dB \\\\ \\hline\nReweighting parameters ($\\tau_1, \\tau_2, \\tau_3$) & $(10^{-5}, 10^{-8}, 10^{-5})$ \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[cc][cc][0.8]{km}\n\\psfrag{ylabel}[cc][cc][0.8]{km}\n\\psfrag{0}[cr][cr][0.7]{$0$}\n\\psfrag{0.5}[cr][cr][0.7]{$0.5$}\n\\psfrag{1}[cr][cr][0.7]{$1$}\n\\psfrag{1.5}[cr][cr][0.7]{$1.5$}\n\\psfrag{-0.5}[cr][cr][0.7]{$-0.5$}\n\\psfrag{-1}[cr][cr][0.7]{$-1$}\n\\psfrag{-1.5}[cc][cc][0.7]{$-1.5$}\n\\psfrag{x4}[cr][cr][0.7]{$0$}\n\\psfrag{x5}[cr][cr][0.7]{$0.5$}\n\\psfrag{x6}[cr][cr][0.7]{$1$}\n\\psfrag{x7}[cr][cr][0.7]{$1.5$}\n\\psfrag{x3}[cr][cr][0.7]{$-0.5$}\n\\psfrag{x2}[cr][cr][0.7]{$-1$}\n\\psfrag{x1}[cc][cc][0.7]{$-1.5$}\n\n  \\centering\n  \\includegraphics[width=0.45\\textwidth]{topology.eps}\n\\caption{A cellular topology with $7$ cells and $4$ RRHs each cell, where each dot represents a RRH.}\n\\label{fig:topology}\n\\end{figure}\n\n\n\n\n\nIn this section, we evaluate the energy efficiency of the data-sharing and compression strategies \nfor downlink C-RAN using the proposed algorithms for a $7$-cell network with wrapped-around topology.\nEach cell here refers to a geographic area with $4$ RRHs as shown in Fig.~\\ref{fig:topology}. \nEquivalently, the network consists of $28$ BSs. \nThe out-of-cell interference combined with background noise is set as $-150$ dBm$/$Hz. \nThe gap to rate-distortion limit is set as $\\Gamma_q = 4.3$ dB corresponding to the uncoded fixed rate \nuniform scalar quantizer \\cite{Gray98}. \nFor simplicity, the SNR gap is set to be $\\Gamma_m = 0$ dB. \nThe parameters in the BS power consumption model \\eqref{eq:bs_power} are taken from \n\\cite{Auer11} while the parameters for the backhaul power model \\eqref{eq:bkhaul_power} are from \\cite{Fehske10}. \nAll the parameters related to the simulations are listed in Table~\\ref{table:system-parameter}. \n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[tc][Bc][0.8]{Iteration }\n\\psfrag{ylabel}[Bc][tc][0.8]{Number of Active BSs}\n\\psfrag{Algorithm 1 w/ 1 user/cell extraaaaaa}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 1 w/ 2 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 1 w/ 3 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $3$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 1 user/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 2 w/ 2 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 3 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $3$ users$/$cell}\n\\psfrag{x1}[cc][cr][0.7]{$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{y0}[rc][rc][0.7]{$5$}\n\\psfrag{y1}[rc][rc][0.7]{$10$}\n\\psfrag{y2}[rc][rc][0.7]{$15$}\n\\psfrag{y3}[rc][rc][0.7]{$20$}\n\\psfrag{y4}[rc][rc][0.7]{$25$}\n\\psfrag{y5}[rc][rc][0.7]{$30$}\n\\psfrag{y6}[rc][rc][0.7]{$35$}\n  \\centering\n  \\includegraphics[width=0.45\\textwidth]{Per_Iteration_Active_BS.eps}\n\\caption{Trajectories of number of active BSs under $r_k = 20$ Mbps target rate for each user.}\n\\label{fig:DataSharingActiveBSs}\n\\end{figure}\n\n\n\n\n\n\\begin{figure}[t]\n\\centering\n\\psfrag{xlabel}[tc][Bc][0.8]{Iteration}\n\\psfrag{ylabel}[Bc][tc][0.7]{Objective Value of Problem \\eqref{prob:data_sharing_approx_lim}$/$\\eqref{prob:compression_approx}}\n\\psfrag{Algorithm 1 w/ 1 user/cell extraaaaaaaa}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 1 w/ 2 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 1 w/ 3 users/cell}[Bl][Bl][0.65]{Data-Sharing (Alg.1) w/ $3$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 1 user/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $1$ user$/$cell}\n\\psfrag{Algorithm 2 w/ 2 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $2$ users$/$cell}\n\\psfrag{Algorithm 2 w/ 3 users/cell}[Bl][Bl][0.65]{Compression (Alg.2) w/ $3$ users$/$cell}\n\\psfrag{x1}[cc][cr][0.7]{$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{x8}[cc][cc][0.7]{$80$}\n\\psfrag{0}[rc][rc][0.7]{$0$}\n\\psfrag{400}[rc][rc][0.7]{$400$}\n\\psfrag{800}[rc][rc][0.7]{$800$}\n\\psfrag{1200}[rc][rc][0.7]{$1200$}\n\\psfrag{1600}[rc][rc][0.7]{$1600$}\n\\psfrag{2000}[rc][rc][0.7]{$2000$}\n  \\includegraphics[width=0.45\\textwidth]{Per_Iteration_Obj.eps}\n\\caption{Convergence behavior of proposed algorithms under $r_k = 20$ Mbps target rate for each user.}\n\\label{fig:compressionObj}\n\\end{figure}\n\n\n\n\n\n\nWe first evaluate the effectiveness of the proposed $\\ell_1$-norm reweighting technique in turning off BSs.\nWe plot the number of active BSs remained in each iteration for both data-sharing (Algorithm~\\ref{alg:data_sharing}) \nand compression (Algorithm~\\ref{alg:compression}) strategies in Fig.~\\ref{fig:DataSharingActiveBSs}. \nThe user target rate is set to be $20$ Mbps for every user and different number of scheduled users are simulated. \nInstead of considering all the $28$ BSs in the entire network as potential serving BSs for each user, we set the \ninitial BS cluster for each user as the strongest $L_c = 14$ BSs to \nreduce the amount of CSI acquisition for the CP. \nFrom Fig.~\\ref{fig:DataSharingActiveBSs} we can see that all the BSs are active at the first iteration, however,  \nthe number of active BSs decreases as the iteration goes on.  \nIntuitively, more users are served, more BSs need to remain active. \nThis can be verified from Fig.~\\ref{fig:DataSharingActiveBSs}. \nWe also observe from Fig.~\\ref{fig:DataSharingActiveBSs} that Algorithm~\\ref{alg:data_sharing} for data-sharing \nexhibits faster convergence speed than Algorithm~\\ref{alg:compression} for compression, \nwhere the former converges within $30$ iterations while the later requires $50$ iterations to converge \nin the worst case. \n\n\n\nWe then evaluate the convergence behavior of the proposed algorithms in Fig.~\\ref{fig:compressionObj}.  \nAs in Fig.~\\ref{fig:DataSharingActiveBSs}, different number of scheduled users are tested and each user's \ntarget rate is set to be $20$ Mbps. \nAs we can see, the objective values monotonically decrease and converge for both the data-sharing (Algorithm~\\ref{alg:data_sharing}) \nand the compression (Algorithm~\\ref{alg:compression}) strategies. \nSimilar to Fig.~\\ref{fig:DataSharingActiveBSs}, we also observe faster convergence speed for data-sharing than \nfor compression in Fig.~\\ref{fig:compressionObj}. \nThis is possibly due to the fact that compression strategy involves more variables to be optimized. \n\n\n\nWe now compare the performance of the data-sharing strategy and the compression strategy in terms of power \nsaving in Fig.~\\ref{sim:total_power}. \nIn addition, we consider two reference schemes. \nIn the first scheme, each user is only served by its strongest BS that is not already associated with another user.\nThis scheme is termed as ``Single BS Association'', for which the transmit power for each user can be minimized using  \nthe strategy in \\cite{yates1995}. \nIn the second scheme, each user's message is shared among the $4$ RRHs in its own cell and \nis cooperatively served by the $4$ RRHs using the \ncoordinated beamforming strategy of \\cite{dahrouj10}. Such scheme is termed as ``Per-Cell CoMP''.  \nThe ``Single BS Association'' and ``Per-Cell CoMP'' are two extreme cases in terms of number of active BSs: \nthe former only has $K$ (number of scheduled users) active BSs while in the latter all the $28$ BSs in the entire network remain active.\nEach point in Fig.~\\ref{sim:total_power} is averaged over $100$ channel realizations. \n\n\n\nAs we can see from Fig.~\\ref{sim:total_power}, ``Per-Cell CoMP'' consumes the most power since all the BSs are active in this scheme. \n``Single BS Association'' consumes the least power, similar to the data-sharing strategy, but only at low user rate regime \nbecause the minimum number of BSs are selected to serve the users in this scheme. \nHowever, as the user rate or the number of scheduled users increases, ``Single BS Association'' becomes infeasible very quickly. \nFor instance, in Fig.~\\ref{sim:total_power}(b) where there are $2$ users per cell, ``Single BS Association'' can only support each user \nwith $10$ Mbps service rate, while in Fig.~\\ref{sim:total_power}(c) the case of 3 users per cell, ``Single BS Association'' \nis not feasible even at $10$ Mbps per user. \n\n\n\n\n\\begin{figure*}[t]\n\\centering\n\\psfrag{xlabel}[tc][cc][0.7]{User Target Rate (Mbps)}\n\\psfrag{ylabel}[tc][cc][0.7]{Total Power Consumption (kWatts)}\n\\psfrag{Compression}[Bl][Bl][0.65]{Compression}\n\\psfrag{Data Sharing}[Bl][Bl][0.65]{Data-Sharing}\n\\psfrag{Per Cell CoMP}[Bl][Bl][0.65]{Per-Cell CoMP}\n\\psfrag{Single BS Association}[Bl][Bl][0.65]{Single BS Association}\n\\psfrag{x1}[cc][cc][0.7]{\\hspace{2mm}$10$}\n\\psfrag{x2}[cc][cc][0.7]{$20$}\n\\psfrag{x3}[cc][cc][0.7]{$30$}\n\\psfrag{x4}[cc][cc][0.7]{$40$}\n\\psfrag{x5}[cc][cc][0.7]{$50$}\n\\psfrag{x6}[cc][cc][0.7]{$60$}\n\\psfrag{x7}[cc][cc][0.7]{$70$}\n\\psfrag{1500}[cc][cc][0.7]{\\hspace{2mm}$1.5$}\n\\psfrag{2000}[cc][cc][0.7]{\\hspace{2mm}$2.0$}\n\\psfrag{2500}[cc][cc][0.7]{\\hspace{2mm}$2.5$}\n\\psfrag{3000}[cc][cc][0.7]{\\hspace{2mm}$3.0$}\n\\psfrag{3500}[cc][cc][0.7]{\\hspace{2mm}$3.5$}\n\\psfrag{4000}[cc][cc][0.7]{\\hspace{2mm}$4.0$}\n\\psfrag{4500}[cc][cc][0.7]{\\hspace{2mm}$4.5$}\n\\psfrag{5000}[cc][cc][0.7]{\\hspace{2mm}$5.0$}\n\\subfloat[1 user per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user1.eps}\n\\label{sim:power_u1}}\n\\hfil\n\\subfloat[2 users per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user2.eps}\n\\label{sim:power_u2}}\n\\hfil\n\\subfloat[3 users per cell]{\\includegraphics*[width=0.33\\textwidth]{total_power_user3.eps}\n\\label{sim:power_u3}}\n\\caption{Total power consumption comparison between different schemes. \nMissing points indicate that the corresponding scheme is infeasible. \nFor instance, ``Single BS Association'' is feasible only for the first \nthree points in (a), and is only feasible for the very first point in (b), and is infeasible in (c). \nFor ``Per-Cell CoMP'' scheme in (c), it is only feasible at $10$ Mbps target rate.}\n\\label{sim:total_power}\n\\end{figure*}\n\n\n\nIt is worth noting that ``Single BS Association'' consumes the same amount of power as data-sharing \nin the low user target rate regime in Fig.~\\ref{sim:total_power}, as the latter essentially reduces to single BS association at low user rates. However, there is still significant advantage in migrating signal processing to the cloud in a C-RAN as compared to the conventional cellular architecture in term of computation power saving, which is not included in the model in this paper. It is also worth noting that the optimized data-sharing and compression strategies outperform the non-optimized per-Cell CoMP significantly in Fig.~\\ref{sim:total_power}, highlighting the importance of optimization approaches proposed in this paper. \nOther optimized CoMP schemes with larger cooperation cluster may consume less BS transmission power, \nhowever, the overall power consumptions can be still very high if all the BSs remain active. \n\n\nWe also observe from Fig.~\\ref{sim:total_power} that neither the data-sharing nor the compression strategy \ndominates the other over the entire user target rate regime. \nFor example in Fig.~\\ref{sim:total_power}(b), although data-sharing consumes less power \nthan compression when the user target rate is below $30$ Mbps, \nits power consumption increases dramatically with the user rate and \neventually crosses over the total power consumed by compression after $40$ Mbps target rate. \nSimilar trend can be observed from Fig.~\\ref{sim:total_power}(a) and \\ref{sim:total_power}(c). \nThis trend is parallel to the observation made in \\cite{PratikEUSIPCO}, in which these two downlink strategies are \ncompared from the utility maximization perspective with limited backhaul constraint. \nIt is observed in \\cite{PratikEUSIPCO} that with low backhaul rate, data-sharing produces higher utility than compression while \nwith high backhaul rate, compression outperforms data-sharing. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{figure}[t]\n  \\centering\n\t\\psfrag{xlabel}[tc][Bc][0.7]{User Target Rate (Mbps) }\n\\psfrag{ylabel}[Bc][tc][0.7]{Power (kWatts)}\n\\psfrag{Data Sharing BS Power}[Bl][Bl][0.7]{Data-Sharing BS Power}\n\\psfrag{Data Sharing Backhaul Power}[Bl][Bl][0.7]{Data-Sharing Backhaul Power}\n\\psfrag{Compression BS Power}[Bl][Bl][0.7]{Compression BS Power}\n\\psfrag{Compression Backhaul Power}[Bl][Bl][0.7]{Compression Backhaul Power}\n\\psfrag{x1}[cc][cc][0.85]{$10$}\n\\psfrag{x2}[cc][cc][0.85]{$20$}\n\\psfrag{x3}[cc][cc][0.85]{$30$}\n\\psfrag{x4}[cc][cc][0.85]{$40$}\n\\psfrag{x5}[cc][cc][0.85]{$50$}\n\\psfrag{x6}[cc][cc][0.85]{$60$}\n\\psfrag{x7}[cc][cc][0.85]{$70$}\n\\psfrag{1}[cc][cc][0.85]{$1$}\n\\psfrag{2}[cc][cc][0.85]{$2$}\n\\psfrag{3}[cc][cc][0.85]{$3$}\n\\psfrag{4}[cc][cc][0.85]{$4$}\n\\psfrag{5}[cc][cc][0.85]{$5$}\n\\psfrag{6}[cc][cc][0.85]{$6$}\n\\psfrag{7}[cc][cc][0.85]{$7$}\t\n\\psfrag{0}[cc][cc][0.85]{$0$}\t\n  \\includegraphics[width= 0.45\\textwidth]{PowerDecomp.eps}\n\\caption{Power consumptions of BSs and backhaul links with $2$ users each cell.}\n\\label{fig:power_decomp}\n\\end{figure}\n\n\n\n\n\nTo investigate further, \nwe plot the individual power consumption of BSs and backhaul links for both the \ndata-sharing and the compression strategies in Fig.~\\ref{fig:power_decomp} for the case of $2$ users per cell. \nAs seen from Fig.~\\ref{fig:power_decomp}, although the BS power consumptions for data-sharing and compression \nare similar in each case of the user target rate, the backhaul power consumptions are significantly different \nand are the determining factor in the choice of strategies.  \nAs the user target rate increases, the backhaul power consumption for data-sharing increases significantly \nand crosses over the compression strategy at around $30$ Mbps. \nThis is because in data-sharing, each user's message needs to be delivered to each one of its serving BSs through backhaul links.\nSo, the backhaul rate directly depends on both the user target rate and the BS cluster size. \nNote that as user target rate increases, the size of serving BS cluster also increases. \nThe two factors together contribute to a much higher backhaul rate. \nIn contrast, the backhaul rate of compression strategy depends on \nthe logarithm of the signal-to-quantization-noise ratio, which only increases gradually as user target rate increases. \nAlso, note that in the low user rate regime, \ndata-sharing consumes less backhaul power than compression in Fig.~\\ref{fig:power_decomp}. \nThis is because it is more efficient to share data directly than to compress when only a few BSs are involved. \n\n\n\n\n\nIn Fig.~\\ref{sim:active_bs}, we compare the percentage of active BSs in the data-sharing strategy versus in the compression strategy. \nSimilar to Fig.~\\ref{sim:total_power}, each point in Fig.~\\ref{sim:active_bs} is averaged over $100$ channel realizations. \nAs we can see, with higher user target rate and more users to be served, more BSs need to remain active for \ntransmission. Also, from Fig.~\\ref{sim:active_bs}, it is observed that the compression strategy tends to turn off more BSs than the \ndata-sharing strategy. \n\n\n\n\\begin{figure*}[!t]\n\\centering\n\\psfrag{xlabel}[tc][cc][0.6]{User Target Rate (Mbps)}\n\\psfrag{ylabel}[cc][cc][0.6]{{Fraction of Active BSs}}\n\\psfrag{Compression}[Bl][Bl][0.65]{Compression}\n\\psfrag{Data Sharing}[Bl][Bl][0.65]{Data Sharing}\n\\psfrag{10}[cc][cr][0.7]{$10$}\n\\psfrag{20}[cc][cc][0.7]{$20$}\n\\psfrag{30}[cc][cc][0.7]{$30$}\n\\psfrag{40}[cc][cc][0.7]{$40$}\n\\psfrag{50}[cc][cc][0.7]{$50$}\n\\psfrag{60}[cc][cc][0.7]{$60$}\n\\psfrag{70}[cc][cc][0.7]{$70$}\n\\psfrag{0.2}[cc][cc][0.7]{$0.2$}\n\\psfrag{0.3}[cc][cc][0.7]{$0.3$}\n\\psfrag{0.4}[cc][cc][0.7]{$0.4$}\n\\psfrag{0.5}[cc][cc][0.7]{$0.5$}\n\\psfrag{0.6}[cc][cc][0.7]{$0.6$}\n\\psfrag{0.7}[cc][cc][0.7]{$0.7$}\n\\psfrag{0.8}[cc][cc][0.7]{$0.8$}\n\\psfrag{0.9}[cc][cc][0.7]{$0.9$}\n\\psfrag{0.65}[cc][cc][0.7]{$0.65$}\n\\psfrag{0.75}[cc][cc][0.7]{$0.75$}\n\\psfrag{0.85}[cc][cc][0.7]{$0.85$}\n\\psfrag{0.95}[cc][cc][0.7]{$0.95$}\n\\psfrag{1}[cc][cl][0.8]{\\hspace{-2mm}$1.0$}\n\\subfloat[1 user per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_1.eps}\n\\label{sim:bs_u1}}\n\\hfil\n\\subfloat[2 users per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_2.eps}\n\\label{sim:bs_u2}}\n\\hfil\n\\subfloat[3 users per cell]{\\includegraphics[width=0.33\\textwidth]{active_BS_3.eps}\n\\label{sim:bs_u3}}\n\\caption{Comparison of average fraction of active BSs. Note that the ``Per-Cell CoMP'' scheme considered in Fig.~\\ref{sim:total_power} \ncorresponds to $100\\%$ of active BSs, while the percentage of active BSs for ``Single BS Association'' \nscheme depends on the number of users in each cell, which are $25\\%$, $50\\%$ and $75\\%$ respectively for $1$, $2$ and $3$ users per cell, \nalthough only those few points corresponding to Fig.~\\ref{sim:total_power} are feasible.}\n\\label{sim:active_bs}\n\\end{figure*}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Conclusion}\\label{sec:conclusion}\n\n\nThis paper compares the energy efficiency between the data-sharing strategy and the compression strategy in downlink C-RAN. \nWe formulate the problem as that of minimizing the total network power consumption subject to user target rate constraints, \nwith both the BS power consumption and the backhaul power consumption taken into account. \nBy taking advantage of the $\\ell_1$-norm reweighting technique and successive convex approximation technique, we \ntransform the nonconvex optimization problems into convex form and devise efficient algorithms with provable \nconvergence guarantees. \n\nThe main conclusions of this paper are that C-RAN significantly \nimproves the range of feasible user data rates in a wireless cellular network, and that \nboth data-sharing and compression strategies bring \nmuch improved energy efficiency to downlink C-RAN as compared to non-optimized CoMP. \nMoreover, between the data-sharing strategy and the compression strategy, either may be preferred \ndepending on the different target rate regimes: at low user target rate, data-sharing consumes less power, while at high user target \nrate compression is preferred since the backhaul rate for data-sharing increases significantly as user \nrate increases. \n\n\n\n\n\n\n\n\n\\appendices\n\n\\section{Proof for Theorem~\\ref{thm:1}}\\label{apdx:a}\n\nThe idea is to show that Algorithm~\\ref{alg:data_sharing} \nconverges to the stationary point solution of the following problem: \n\n", "index": 59, "text": "\\begin{align} \\label{prob:data_sharing_approx_lim}\n\\displaystyle \\min_{\\left\\{w_{lk} \\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}  + \nP_{l, \\Delta}  \\frac{\\ln \\left( 1 +  \\tau_1^{-1} \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}\\right)}{\\ln \\left( 1 + \\tau_1^{-1} \\right)}  \\nonumber \\\\ \n&  \\hspace{1.4cm} + \n\\rho_l \\sum_{k\\in \\mathcal{K}}    \\frac{\\ln \\left( 1 + \\tau_2^{-1} \\left\\vert w_{lk} \\right\\vert^{2} \\right)}{\\ln \\left( 1 + \\tau_2^{-1} \\right)}     r_k \\Bigg) \\\\\n {\\operatorname{s.t.}}  & \\quad \\eqref{sinr_const},  ~~ \\eqref{Per_BS_Power} \\nonumber \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle\\min_{\\left\\{w_{lk}\\right\\}}\" display=\"inline\"><munder><mi>min</mi><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>}</mo></mrow></munder></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\sum_{k\\in\\mathcal{K}}%&#10;\\left|w_{lk}\\right|^{2}+P_{l,\\Delta}\\frac{\\ln\\left(1+\\tau_{1}^{-1}\\sum_{k\\in%&#10;\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\right)}{\\ln\\left(1+\\tau_{1}^{-1}\\right)}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup><mo>+</mo><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub><mstyle displaystyle=\"true\"><mfrac><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\rho_{l}\\sum_{k\\in\\mathcal{K}}\\frac{\\ln\\left(1+\\tau_%&#10;{2}^{-1}\\left|w_{lk}\\right|^{2}\\right)}{\\ln\\left(1+\\tau_{2}^{-1}\\right)}r_{k}%&#10;\\Bigg{)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle><msub><mi>r</mi><mi>k</mi></msub><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{s.t.}}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">s</mi><mo>.</mo><mi mathvariant=\"normal\">t</mi><mo>.</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\eqref{sinr_const},~{}~{}\\eqref{Per_BS_Power}\" display=\"inline\"><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mi>(</mi><mo>\u2062</mo><mtext mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_font_italic ltx_ref_self\"><span class=\"ltx_text ltx_ref_tag\">17</span></span></mtext><mo>\u2062</mo><mi>)</mi></mrow><mo rspace=\"9.1pt\">,</mo><mrow><mi>(</mi><mo>\u2062</mo><mtext mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_font_italic ltx_ref_self\"><span class=\"ltx_text ltx_ref_tag\">18</span></span></mtext><mo>\u2062</mo><mi>)</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n \n\nNow, due to the concavity of $\\ln x$, the inequality $\\ln x \\leq \\ln x_0 + x_0^{-1} x - 1$ \nholds for any $x>0, x_0>0$ and achieves equality if and only if $x = x_0$. Hence, we have \n\n", "itemtype": "equation", "pos": 82009, "prevtext": "\n\n\n\n\n\nFirst, we note that problem \\eqref{prob:data_sharing_approx_lim} differs from the original problem \\eqref{prob:data_sharing} in that \nthe $\\ell_0$-norms in the objective function \\eqref{obj_data_sharing} are approximated by the logarithmic functions in \n\\eqref{prob:data_sharing_approx_lim}. This approximation stems from the relation that with $x \\geq 0$, \n\n", "index": 61, "text": "\\begin{equation}\\label{lim_approx}\n\\mathbbm{1}_{\\left\\{x\\right\\}} = \\left\\Vert x \\right\\Vert_0 = \\lim_{\\tau \\to 0} \\frac{\\ln \\left( 1 + x \\tau^{-1}\\right)}{\\ln \\left( 1 + \\tau^{-1} \\right)} ~.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35.m1\" class=\"ltx_Math\" alttext=\"\\mathbbm{1}_{\\left\\{x\\right\\}}=\\left\\|x\\right\\|_{0}=\\lim_{\\tau\\to 0}\\frac{\\ln%&#10;\\left(1+x\\tau^{-1}\\right)}{\\ln\\left(1+\\tau^{-1}\\right)}~{}.\" display=\"block\"><mrow><mrow><msub><mn>\ud835\udfd9</mn><mrow><mo>{</mo><mi>x</mi><mo>}</mo></mrow></msub><mo>=</mo><msub><mrow><mo>\u2225</mo><mi>x</mi><mo>\u2225</mo></mrow><mn>0</mn></msub><mo>=</mo><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>\u03c4</mi><mo>\u2192</mo><mn>0</mn></mrow></munder><mo>\u2061</mo><mpadded width=\"+3.3pt\"><mfrac><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>x</mi><mo>\u2062</mo><msup><mi>\u03c4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msup><mi>\u03c4</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>)</mo></mrow></mrow></mfrac></mpadded></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwith equality if and only if \n\n", "itemtype": "equation", "pos": 82403, "prevtext": "\n \n\nNow, due to the concavity of $\\ln x$, the inequality $\\ln x \\leq \\ln x_0 + x_0^{-1} x - 1$ \nholds for any $x>0, x_0>0$ and achieves equality if and only if $x = x_0$. Hence, we have \n\n", "index": 63, "text": "\\begin{align} \\label{data_ineq}\n\\hspace{-4mm} \\eqref{prob:data_sharing_approx_lim}  \\leq &  \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}   \\nonumber \\\\ \n& \\hspace{2mm} + P_{l, \\Delta}  \\frac{ \\ln x_{l} + x_{l}^{-1} \\left( 1 +  \\tau_1^{-1} \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} \\right) - 1   }{\\ln \\left( 1 + \\tau_1^{-1} \\right)}   \\nonumber \\\\\n& \\hspace{2mm} + \\rho_l \\sum_{k\\in \\mathcal{K}}    \\frac{ \\ln y_{lk} + y_{lk}^{-1} \\left(   1 + \\tau_2^{-1} \\left\\vert w_{lk} \\right\\vert^{2}  \\right) - 1 }{\\ln \\left( 1 + \\tau_2^{-1} \\right)}     r_k \\Bigg) ~ , \\nonumber \\\\\n& \\hspace{4.2cm} \\forall x_{l} >0, \\quad y_{lk} > 0 \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\eqref{prob:data_sharing_approx_lim}\\leq\" display=\"inline\"><mrow><mrow><mi>(</mi><mo>\u2062</mo><mtext mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_font_italic ltx_ref_self\">S0.Ex15</span></mtext><mo>\u2062</mo><mi>)</mi></mrow><mo>\u2264</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\sum_{k\\in\\mathcal{K}}\\left%&#10;|w_{lk}\\right|^{2}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0+P_{l,\\Delta}\\frac{\\ln x_{l}+x_{l}^{-1}\\left(1+\\tau_{1}^{-1}%&#10;\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}\\right)-1}{\\ln\\left(1+\\tau_{1}^{-%&#10;1}\\right)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0</mi><mo>+</mo><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>x</mi><mi>l</mi></msub></mrow><mo>+</mo><mrow><msubsup><mi>x</mi><mi>l</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0+\\rho_{l}\\sum_{k\\in\\mathcal{K}}\\frac{\\ln y_{lk}+y_{lk}^{-1}%&#10;\\left(1+\\tau_{2}^{-1}\\left|w_{lk}\\right|^{2}\\right)-1}{\\ln\\left(1+\\tau_{2}^{-1%&#10;}\\right)}r_{k}\\Bigg{)}~{},\" display=\"inline\"><mrow><mi>\u00a0\u00a0</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>y</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow><mo>+</mo><mrow><msubsup><mi>y</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle><msub><mi>r</mi><mi>k</mi></msub><mo maxsize=\"260%\" minsize=\"260%\" rspace=\"5.8pt\">)</mo><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\\forall x_{l}&gt;0,\\quad y_{lk}&gt;0\" display=\"inline\"><mrow><mrow><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>\u2062</mo><mrow><mo>\u2200</mo><msub><mi>x</mi><mi>l</mi></msub></mrow></mrow><mo>&gt;</mo><mn>0</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msub><mi>y</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>&gt;</mo><mn>0</mn></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\n\nAlthough problem \\eqref{prob:data_sharing_approx_lim} is nonconvex due to the logarithmic objective function, \nthe function on the right-hand side of \\eqref{data_ineq} is a convex quadratic function in $\\left\\{ w_{lk} \\right\\}$. \nBased on this fact, we can develop an MM algorithm to solve problem \n\\eqref{prob:data_sharing_approx_lim} by solving a sequence of convex optimization problems with the objective function in \n\\eqref{prob:data_sharing_approx_lim} replaced by \nthe convex function in \\eqref{data_ineq} and iteratively updating the parameters $x_{l}, y_{lk}$ \naccording to \\eqref{x_update}.  \nComparing such MM algorithm with Algorithm~\\ref{alg:data_sharing}, it is easy to see that \nAlgorithm~\\ref{alg:data_sharing} reduces to the MM algorithm \nif the reweighting function in \\eqref{wgt_update_data} is chosen as \\eqref{eq:reweight}. \n\nIt is known in the literature \\cite{Meisam13} that an MM algorithm is guaranteed to converge to the stationary point solutions of the original problem if \nthe approximate function satisfies the following conditions: 1) it is continuous, \n2) it is a tight upper bound of the original objective function and \n3) it has the same first-order derivative as the original objective function at the point where the upper bound is tight. \nIt is easy to check that the function in \\eqref{data_ineq} satisfies all these sufficient conditions. \nThus, Algorithm~\\ref{alg:data_sharing}, which is equivalent to an MM algorithm, must converge. \n\n\n\n\n\n\n\\section{Proof for Theorem~\\ref{thm:2}}\\label{apdx:b}\n\nSimilar to the proof for Theorem~\\ref{thm:1}, the idea is show that Algorithm~\\ref{alg:compression} converges to the stationary point \nsolution of the following optimization problem: \n\n", "itemtype": "equation", "pos": 83140, "prevtext": "\nwith equality if and only if \n\n", "index": 65, "text": "\\begin{align}\\label{x_update}\nx_{l} = 1 +  \\tau_1^{-1} \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}, \\quad\ny_{lk} = 1 + \\tau_2^{-1} \\left\\vert w_{lk} \\right\\vert^{2}. \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle x_{l}=1+\\tau_{1}^{-1}\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{%&#10;2},\\quad y_{lk}=1+\\tau_{2}^{-1}\\left|w_{lk}\\right|^{2}.\" display=\"inline\"><mrow><mrow><mrow><msub><mi>x</mi><mi>l</mi></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msub><mi>y</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>=</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nwhich is a logarithmic approximation to the original problem \\eqref{prob:compression}. \n\nProblem \\eqref{prob:compression_approx} is nonconvex due to the logarithmic functions in its objective function. \nHowever, we can develop an MM algorithm to solve \\eqref{prob:compression_approx} by solving a sequence of \nconvex optimization problems with the objective function in \\eqref{prob:compression_approx} replaced by its upper bound shown below \n\n", "itemtype": "equation", "pos": 85056, "prevtext": "\n\nAlthough problem \\eqref{prob:data_sharing_approx_lim} is nonconvex due to the logarithmic objective function, \nthe function on the right-hand side of \\eqref{data_ineq} is a convex quadratic function in $\\left\\{ w_{lk} \\right\\}$. \nBased on this fact, we can develop an MM algorithm to solve problem \n\\eqref{prob:data_sharing_approx_lim} by solving a sequence of convex optimization problems with the objective function in \n\\eqref{prob:data_sharing_approx_lim} replaced by \nthe convex function in \\eqref{data_ineq} and iteratively updating the parameters $x_{l}, y_{lk}$ \naccording to \\eqref{x_update}.  \nComparing such MM algorithm with Algorithm~\\ref{alg:data_sharing}, it is easy to see that \nAlgorithm~\\ref{alg:data_sharing} reduces to the MM algorithm \nif the reweighting function in \\eqref{wgt_update_data} is chosen as \\eqref{eq:reweight}. \n\nIt is known in the literature \\cite{Meisam13} that an MM algorithm is guaranteed to converge to the stationary point solutions of the original problem if \nthe approximate function satisfies the following conditions: 1) it is continuous, \n2) it is a tight upper bound of the original objective function and \n3) it has the same first-order derivative as the original objective function at the point where the upper bound is tight. \nIt is easy to check that the function in \\eqref{data_ineq} satisfies all these sufficient conditions. \nThus, Algorithm~\\ref{alg:data_sharing}, which is equivalent to an MM algorithm, must converge. \n\n\n\n\n\n\n\\section{Proof for Theorem~\\ref{thm:2}}\\label{apdx:b}\n\nSimilar to the proof for Theorem~\\ref{thm:1}, the idea is show that Algorithm~\\ref{alg:compression} converges to the stationary point \nsolution of the following optimization problem: \n\n", "index": 67, "text": "\\begin{align} \\label{prob:compression_approx}\n\\displaystyle  {\\operatorname{minimize}}_{\\left\\{w_{lk}, q_l\\right\\}} & \\quad \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right) \\nonumber \\\\ \n& \\hspace{6mm}+ \n P_{l, \\Delta} \\frac{\\ln\\left( 1 + \\tau_3^{-1} \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2  \\right) \\right)}{\\ln\\left( 1 + \\tau_3^{-1}  \\right)} \\nonumber \\\\\n & \\hspace{6mm} + \\rho_l \\log_2 \\left( 1 + \\frac{\\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{q_l^2}  \\right) \\Bigg) \\\\\n {\\operatorname{subject \\text{ } to}}  &  \\quad \\eqref{sinr_const_compression}, ~~ \\eqref{compression_power_const} ~,\\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\displaystyle{\\operatorname{minimize}}_{\\left\\{w_{lk},q_{l}\\right\\}}\" display=\"inline\"><msub><mo>minimize</mo><mrow><mo>{</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>,</mo><msub><mi>q</mi><mi>l</mi></msub><mo>}</mo></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\left(\\sum_{k\\in%&#10;\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2}\\right)\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mrow><mo>(</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+P_{l,\\Delta}\\frac{\\ln\\left(1+\\tau_{3}^{-1}\\left(\\sum_{k\\in%&#10;\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2}\\right)\\right)}{\\ln\\left(1+\\tau_{%&#10;3}^{-1}\\right)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>3</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>3</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0+\\rho_{l}\\log_{2}\\left(1+\\frac{\\Gamma_{q}\\sum_{k\\in\\mathcal%&#10;{K}}\\left|w_{lk}\\right|^{2}}{q_{l}^{2}}\\right)\\Bigg{)}\" display=\"inline\"><mrow><mi>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><msub><mi>log</mi><mn>2</mn></msub><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mfrac></mstyle><mo>)</mo></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\operatorname{subject\\text{ }to}}\" display=\"inline\"><mrow><mi>subject</mi><mo>\u2062</mo><mtext>\u00a0</mtext><mo>\u2062</mo><mi>to</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\eqref{sinr_const_compression},~{}~{}\\eqref{compression_%&#10;power_const}~{},\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>\u2062</mo><mi>(</mi><mo>\u2062</mo><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\">LABEL:sinr_const_compression</span></mtext><mo>\u2062</mo><mi>)</mi></mrow><mo rspace=\"9.1pt\">,</mo><mrow><mi>(</mi><mo>\u2062</mo><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\">LABEL:compression_power_const</span></mtext><mo>\u2062</mo><mpadded width=\"+3.3pt\"><mi>)</mi></mpadded></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01070.tex", "nexttext": "\nand iteratively updating the parameters $z_{l}$ as $z_{l} = 1 +  \\tau_3^{-1}\\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right)$ \nand $\\lambda_l$ as \\eqref{lambda_update}.  \nIt is easy to see that such MM algorithm is equivalent to Algorithm~\\ref{alg:compression} with the reweighting \nfunction in \\eqref{wgt_mu} chosen as \\eqref{eq:reweight}. \nWe can also easily verify that the majorizing function in the right-hand side of \\eqref{func:major_comp} \nsatisfies all the sufficient conditions in \\cite{Meisam13} for the convergence guarantee of MM algorithm. \nHence, Algorithm~\\ref{alg:compression} must converge. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\\bibliographystyle{IEEEtran}\n\n\n\\bibliography{IEEEabrv,myref}\n\n\n\n\n\n\n\n\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Binbin_Dai}}]\n{Binbin Dai} (S'12) received the B.E. degree in Information Science and Engineering from Chien-Shiung Wu Honors College, Southeast University, Nanjing, China, in 2011 and M.A.Sc degree in Electrical and Computer Engineering from University of Toronto, Toronto, Ontario, Canada, in 2014. He is currently working towards the Ph.D degree with the Department of Electrical and Computer Engineering, University of Toronto, Toronto, Ontario, Canada. His research interests include optimization, wireless communications and signal processing. \n\\end{IEEEbiography}\n\n\n\n\\begin{IEEEbiography}[{\\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Wei_Yu}}]\n{Wei Yu} (S'97-M'02-SM'08-F'14) received the B.A.Sc. degree in Computer Engineering and Mathematics from the University of Waterloo, Waterloo, Ontario, Canada in 1997 and M.S. and Ph.D. degrees in Electrical Engineering from Stanford University, Stanford, CA, in 1998 and 2002, respectively. Since 2002, he has been with the Electrical and Computer Engineering Department at the University of Toronto, Toronto, Ontario, Canada, where he is now Professor and holds a Canada Research Chair (Tier 1) in Information Theory and Wireless Communications. His main research interests include information theory, optimization, wireless communications and broadband access networks.\n\nProf. Wei Yu currently serves on the IEEE Information Theory Society Board of Governors (2015-17). He is an IEEE Communications Society Distinguished Lecturer (2015-16). He served as an Associate Editor for \\textsc{IEEE Transactions on Information Theory} (2010-2013), as an Editor for \\textsc{IEEE Transactions on Communications} (2009-2011), as an Editor for \\textsc{IEEE Transactions on Wireless Communications} (2004-2007), and as a Guest Editor for a number of special issues for the \\textsc{IEEE Journal on Selected Areas in Communications} and the \\textsc{EURASIP Journal on Applied Signal Processing}. He was a Technical Program co-chair of the IEEE Communication Theory Workshop in 2014, and a Technical Program Committee co-chair of the Communication Theory Symposium at the IEEE International Conference on Communications (ICC) in 2012. He was a member of the Signal Processing for Communications and Networking Technical Committee of the IEEE Signal Processing Society (2008-2013). Prof. Wei Yu received a Steacie Memorial Fellowship in 2015, an IEEE Communications Society Best Tutorial Paper Award in 2015, an IEEE ICC Best Paper Award in 2013, an IEEE Signal Processing Society Best Paper Award in 2008, the McCharles Prize for Early Career Research Distinction in 2008, the Early Career Teaching Award from the Faculty of Applied Science and Engineering, University of Toronto in 2007, and an Early Researcher Award from Ontario in 2006. He was named a Highly Cited Researcher by Thomson Reuters in 2014.\n\n\n\\end{IEEEbiography}\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 86245, "prevtext": "\nwhich is a logarithmic approximation to the original problem \\eqref{prob:compression}. \n\nProblem \\eqref{prob:compression_approx} is nonconvex due to the logarithmic functions in its objective function. \nHowever, we can develop an MM algorithm to solve \\eqref{prob:compression_approx} by solving a sequence of \nconvex optimization problems with the objective function in \\eqref{prob:compression_approx} replaced by its upper bound shown below \n\n", "index": 69, "text": "\\begin{align}\\label{func:major_comp}\n\n&  \\sum_{l\\in\\mathcal{L}} \n\\Bigg( \\eta_l \\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2 \\right)  - 2 \\rho_l \\log_2 q_l \\nonumber \\\\ \n& \\quad + \n P_{l, \\Delta} \\frac{\\ln z_{l} + z_{l}^{-1} \\left( 1 +  \\tau_3^{-1}\\left( \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2} + q_l^2\\right)\\right) - 1}{\\ln\\left( 1 + \\tau_3^{-1}  \\right)} \\nonumber \\\\\n & \\quad + \n\\rho_l \\left(\\log_2 \\lambda_l  +  \\frac{ q_l^2 + \\Gamma_q \\sum_{k \\in \\mathcal{K}} \\left\\vert w_{lk} \\right\\vert^{2}}{\\lambda_l \\ln 2} - \n\\frac{1}{\\ln 2} \\right) \n  \\Bigg)\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{l\\in\\mathcal{L}}\\Bigg{(}\\eta_{l}\\left(\\sum_{k\\in\\mathcal{K}%&#10;}\\left|w_{lk}\\right|^{2}+q_{l}^{2}\\right)-2\\rho_{l}\\log_{2}q_{l}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi></mrow></munder></mstyle><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><msub><mi>\u03b7</mi><mi>l</mi></msub><mrow><mo>(</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder></mstyle><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><msup><mo>|</mo><mn>2</mn></msup><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>)</mo></mrow><mo>-</mo><mn>2</mn><msub><mi>\u03c1</mi><mi>l</mi></msub><msub><mi>log</mi><mn>2</mn></msub><msub><mi>q</mi><mi>l</mi></msub></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad+P_{l,\\Delta}\\frac{\\ln z_{l}+z_{l}^{-1}\\left(1+\\tau_{3}^{-1}%&#10;\\left(\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}+q_{l}^{2}\\right)\\right)-1}%&#10;{\\ln\\left(1+\\tau_{3}^{-1}\\right)}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>+</mo><mrow><msub><mi>P</mi><mrow><mi>l</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi></mrow></msub><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>z</mi><mi>l</mi></msub></mrow><mo>+</mo><mrow><msubsup><mi>z</mi><mi>l</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mrow><msubsup><mi>\u03c4</mi><mn>3</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup></mrow><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><msubsup><mi>\u03c4</mi><mn>3</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad+\\rho_{l}\\left(\\log_{2}\\lambda_{l}+\\frac{q_{l}^{2}+\\Gamma_{q%&#10;}\\sum_{k\\in\\mathcal{K}}\\left|w_{lk}\\right|^{2}}{\\lambda_{l}\\ln 2}-\\frac{1}{\\ln&#10;2%&#10;}\\right)\\Bigg{)}\" display=\"inline\"><mrow><mi mathvariant=\"normal\">\u2003</mi><mo>+</mo><msub><mi>\u03c1</mi><mi>l</mi></msub><mrow><mo>(</mo><msub><mi>log</mi><mn>2</mn></msub><msub><mi>\u03bb</mi><mi>l</mi></msub><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mi>q</mi><mi>l</mi><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi mathvariant=\"normal\">\u0393</mi><mi>q</mi></msub><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></msub><msup><mrow><mo>|</mo><msub><mi>w</mi><mrow><mi>l</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mrow><msub><mi>\u03bb</mi><mi>l</mi></msub><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mn>2</mn></mrow></mrow></mfrac></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>ln</mi><mo>\u2061</mo><mn>2</mn></mrow></mfrac></mstyle><mo>)</mo></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></math>", "type": "latex"}]