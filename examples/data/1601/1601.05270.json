[{"file": "1601.05270.tex", "nexttext": "\n\n\\item Consistency states that the values should not be conflicting. We measure it using \n\n", "itemtype": "equation", "pos": 41983, "prevtext": "\n\n\\maketitle\n\n\\begin{abstract}\n\nFor many use cases it is not feasible to access RDF data in a truly federated fashion.\nFor consistency, latency and performance reasons data needs to be replicated in order to be used locally.\nHowever, both a replica and its origin dataset undergo changes over time.\nThe concept of co-evolution refers to mutual propagation of the changes between a replica and its origin dataset.\nThe co-evolution process addresses synchronization and conflict resolution issues.\nIn this article, we initially provide formal definitions of all the concepts required for realizing co-evolution of RDF datasets.\nThen, we propose a methodology to address the co-evolution of RDF datasets. \nWe rely on a property-oriented approach for employing the most suitable strategy or functionality.\nThis methodology was implemented and tested for a number of different scenarios.\nThe result of our experimental study shows the performance and robustness aspect of this methodology.\n\\end{abstract}\n\n{\\par\\addvspace\\baselineskip \\noindent\\keywordname\\enspace\\ignorespaces{Dataset Synchronization, Dataset Co-evolution, Conflict Identification, Conflict Resolution, RDF Dataset}}\n\n\\section{Introduction}\n\nRecently, the amount of structured data which has been published on the Web as Linked Open Data (LOD) has been enormously grown.\nCurrently, it comprises more than 85 billion triples from approximately 3400 datasets\\footnote{observed on 17th December 2015 on \\url{http://stats.lod2.eu/}.}. \nStill, mainly because of performance issues, small applications prefer to have a small replica for their local data consumption.\nBoth a replica and its origin dataset undergo changes over time.\nHuge RDF datasets basically publish the updates as different RDF files that contain only the changes (i.e. removed and added triples);\nthese can also be downloaded and easily integrated to the older versions of the dataset.  \nFor instance, \\emph{DBpedia Live mirror tool}\\footnote{\\url{https://github.com/dbpedia/dbpedia-live-mirror}} publishes changes in a public changesets folder\\footnote{\\url{http://live.dbpedia.org/change sets/}}. \n\nThe concept of co-evolution refers to mutual propagation of the changes between a replica and its origin dataset.\nThe concept of propagation specially in a mutual way raises serious challenges which need to be addressed otherwise it causes data inconsistency.\nThese challenges are about how should the updates be propagated and in case of inconsistency (herein is so-called conflict) how should it be handled.\nThus, co-evolution process is comprised of two main issues as (i) synchronization approach and (ii) conflict identification and resolution approach.\nIn this article, the origin dataset is called source dataset and the replica is called target dataset.\nWe assume that either the source dataset integrates a tool to compute a changeset at real-time or the third party tools can be used for this purpose. \n\nAs shown in ~\\autoref{fig:co-evolution}, initially at time $t_0$, the target dataset $T_{t_0}$ is sliced from the source dataset $S_{t_0}$ of dataset $S$.\nBoth the datasets evolve to $S_{t_j}$ and $T_{t_j}$ during timeframe $ t_i-t_j $, while $ t_i \\, < \\, t_j $. \nThe changes from $ S_{t_j} $, that is, $ \\delta(S_{t_i-t_j}) $  are propagated to the target and vice versa. \nAt time point $t_j$, the co-evolution manager identifies the conflicts and resolves them. \nThe resolved conflicts are applied on the source and target datasets to vanish inconsistencies.\n\nThe paper is structured as follows: \n~\\autoref{sec:preliminaries} provides formal definitions of the basic notations and concepts we used in this article. \n~\\autoref{sec:problemstatement} presents detailed problem description and different synchronization strategies.\nWe then present the proposed approach in~\\autoref{sec:approach} followed by evaluation in~\\autoref{sec:evaluation}.\n~\\autoref{sec:relatedwork} presents the related work.\nWe close with the conclusion and the directions for the future work.\n\n\\begin{figure}[tb]\n\\centering\n\\includegraphics[width=0.7\\textwidth]{concept.pdf}\n\\caption{Co-evolution of linked datasets}\n\\label{fig:co-evolution}\n\\end{figure}\n\n\\section{Preliminaries}\\label{sec:preliminaries}\\label{sec:problemstatement}\n\nIn this section, we formalize the main concepts required for realizing co-evolution of RDF datasets. \nThe \\emph{Resource Description Framework (RDF)}\\footnote{\\url{http://www.w3.org/TR/rdf11-concepts/}} is widely used to represent information on the Web. \nA resource can be any thing (either physical or conceptual). \nThe RDF data model expresses statements about Web resources in the form of subject-predicate-object (triple).\nThe subject denotes a resource; the predicate expresses a property of subject or a relationship between the subject and the object; the object is either a resource or literal. \nFor identifying resources, RDF uses Uniform Resource Identifiers (URIs)\\footnote{A URI is a string of characters used as unique identifier for a Web resource.}\nand Internationalized Resource Identifier (IRIs)\\footnote{A generalization of URIs enabling the use of international character sets.}.\nThe rationale behind is that the names of resources must be universally unique.\nWe assume that both source and target datasets are RDF datasets. An RDF dataset is formally defined as follows:\n\n\\begin{definition}[RDF Dataset]\nFormally, an RDF dataset is a finite set of triples $(s, p, o) \\in (R  \\cup B) \\times P \\times (R \\cup L \\cup B)$, where $R$ is the set of all RDF resources, $B$ is the set of all blank nodes ($B \\cap R = \\emptyset$), $P$ is the set of all predicates ($P \\subseteq R$) and $L$ is the set of all literals ($L \\cap R = \\emptyset$).\n\\end{definition}\n\n\\paragraph{Use case scenario:} Herein, we present an use case scenario and track this scenario during the entire paper. \nLet us assume a mobile application which requires information of restaurants (i.e., name, rating, chef, abstract, and depiction) nearby users' location.\n\nThis information can be sliced from the huge datasets like LinkedGeoData\\footnote{http://linkedgeodata.org} or DBpedia \\footnote{http://dbpedia.org} and use locally by the mobile application. \nWe use the following SPARQL query to slice DBpedia for our use case scenario:\n\\begin{lstlisting}\n CONSTRUCT \n WHERE {\n     ?s    a               dbo:Restaurant.\n     ?s    rdfs:label      ?label.\n     ?s    georss:point    ?point.\n     ?s    dbo:abstract    ?abstract.\n     ?s    dbp:rating      ?rating.\n     ?s    foaf:depiction  ?depiction.\n     ?s    dbp:headOfChief ?headOfChief\n  }\n \\end{lstlisting}\n\nLet us assume that the slice contains the following triples~\\footnote{@prefix wmcf: http://commons.wikimedia.org/wiki/Special:FilePath/}\n \n\n\\begin{lstlisting}[caption={Content of initial target dataset}, captionpos=b, label={lst:targetinit}]\ndbr:FLIP_Burger_Boutique   a     dbo:Restaurant;\n         foaf:name         \"FLIP\"@en ;\n         georss:point      \"33.7984 -84.4159\";\n         dbo:abstract      \"FLIP is an upscale full-service American restaurant ... \"@en;\n         dbp:rating        4;\n         foaf:depiction    wmcf:Richard_Blais.JPG ;\n         dbp:headChef      \"Richard Blais\"@en.\ndbr:Jean_Georges  a        dbo:Restaurant;\n         foaf:name         \"Jean-Georges Vongerichten\"@en;\n         georss:point      \"40.76905277777778 -73.98143055555556\";\n         dbo:abstract      \"Jean Georges is a three-Michelin-stars restaurant at 1 Central Park ...\"@en;\n         dbp:rating        5;\n         foaf:depiction    wmcf:JGV.jpg;\n         dbp:headChef      \"Mark LaPico\"@en.\n\\end{lstlisting}\n\nThis local copy of sliced dataset is referred as 'Target dataset' might undergo changes by user feedback (e.g. user can update the restaurant rating or fulfil abstract information).\n\nAfter some time, DBpedia dataset also evolves by adding new restaurants information or updating the existing ones. \nAs a result, Target dataset might be out of date and need to be synchronized with DBpedia. \nDuring synchronization, a conflict (defined in \\autoref{def:conflict}) might occur, if the same information was updated by the source (DBpedia) dataset and the target dataset (by the app users). \n\n\n\\begin{definition}[Evolving RDF Dataset]\\label{def:evolvingDataset}\nLet us assume that $D_{t_i}$ represents the version of the RDF dataset $D$ at the particular time $t_i$.\nAn evolving dataset $D$ is a dataset whose triples change over time. \nIn other words, for timeframe $t_i-t_j$,  there is a triple $x$ such as either $( x \\in D_{t_i}  \\wedge x \\notin D_{t_j}) $ or $ (x \\notin D_{t_i}  \\wedge x \\in D_{t_j} )$.\n\\end{definition}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{definition}[Changeset]\\label{def:changeset}\nLet us assume that $D$ is an evolving RDF dataset. \nand $D_{t_i}$ is the version of $D$ at time $t_i$. \nA changeset which is denoted by $\\delta ( D_{t_i-t_j} ) $ shows the difference of two versions of an evolving RDF dataset in a particular timeframe $ t_i-t_j $, while $ t_i \\, < \\, t_j $.\nThe changeset is formally defined as $ \\delta ( D_{t_i-t_j} ) = < \\delta ( D_{t_i-t_j} ) ^ + , \\delta ( D_{t_i-t_j} ) ^ - > $ where,\n\\begin{compactitem}\n\\item $ \\delta ( D_{t_i-t_j} ) ^ + $ is a set of triples which have been added to the version $D_{t_j}$ in comparison to the version $D_{t_i}$. \n\\item $ \\delta ( D_{t_i-t_j} ) ^ - $ is a set of triples which have been deleted from the version $D_{t_j}$ in comparison to the version $D_{t_i}$. \n\\end{compactitem}\n\\end{definition}\n\n\n\\begin{example}[Changesets]\\label{ex:changeset}\nLet the following files are found as changesets at time $t_i$ from the source and target datasets.\n\n\\begin{lstlisting}[caption={Source changeset, (A)=$ \\delta ( S_{t_i-t_j} ) ^ -$ , and (B) = $ \\delta ( S_{t_i-t_j} ) ^ +$ }, captionpos=b,label={lst:sourcechangesets} ]\n#(A). Deleted triples\ndbr:FLIP_Burger_Boutique  foaf:name       \"FLIP\"@en ;\n                          dbo:abstract    \"FLIP is an upscale full-service ..\"@en.\ndbr:Jean_Georges          foaf:name       \"Jean-Georges Vongerichten\"@en;\n                          foaf:depiction  wmcf:JGV.jpg.\n#______________________________________________________________________________________\n#(B). Added triples\ndbr:FLIP_Burger_Boutique  foaf:name       \"FLIP burger boutique\"@en ;\n                          dbo:abstract \t  \"FLIP burger boutique (stylized as FLIP)..\"@en.\ndbr:Jean_Georges          foaf:depiction  wmcf:FLIP.jpg;\n                          foaf:name       \"Jean-Georges\"@en.\ndbr:Het_Groot_Paradijs    a               dbo:Restaurant;\n                          foaf:name       \"Het Groot Paradijs\";\n                          dbo:abstract    \"Het Groot Paradijs was a restaurant located in Middelburg,..\";\n                          georss:point    \"51.50027222222222 3.6166805555555555\";\n                          dbp:rating      4.\n\\end{lstlisting}\n\n\n\\begin{lstlisting}[caption={Target changeset, (A)= $ \\delta ( T_{t_i-t_j} ) ^ -$ , and (B) = $ \\delta ( T_{t_i-t_j} ) ^ +$}, captionpos=b,label={lst:targetchangesets}]\n#(A) Deleted triples\ndbr:Jean_Georges          foaf:name      \"Jean-Georges Vongerichten\"@en;\n                          foaf:depiction  wmcf:JGV.jpg.\n#______________________________________________________________________________________\n#(B) Added triples\ndbr:Jean_Georges          foaf:name      \"JGV restaurant\"@en;\n                          foaf:depiction  myp:jgvn.jpg.\n\\end{lstlisting}\n\\end{example}\n\n\\section{Problem Statement}\\label{sec:problemstatement}\nThe core of the co-evolution concept relies on the mutual propagation of changes between the source and target datasets in order to keep the datasets in sync.\nThus, from time to time, the target dataset and the source dataset have to exchange the changesets and then update the local repositories.\nPlease note that updating a dataset with changesets from the source dataset might cause inconsistencies. \nOur co-evolution strategy aims to deal with changesets from either the source or target datasets and provide a suitable reconciliation strategy. \nVarious strategies can be employed for synchronising datasets.\nIn this section we provide requirements and formal definitions for guiding the co-evolution process.\n\n\\subsection{Synchronization}\nIn the beginning the target dataset is derived (as a slice or excerpt) from the source dataset, thus the following requirement always holds.\n\n\\begin{requirement}[Initial Inclusion]\\label{req:Initial_Inclusion}\nAt the initial time $t_0$, the target dataset $T$ is a subset of the source dataset $S$: $ T_{t_0} \\subseteq S_{t_0} $ and thus source and target datasets are in sync.\n\\end{requirement}\n\n\n\\begin{definition}[Synchronized Dataset]\\label{def:syncds}\nTwo evolving datasets, $D^{(1)}$ and $D^{(2)}$, are said to be synchronized (or in sync) iff one of the following is true at a give time $t_k$: i) $D^{(1)}_{t_k} \\subseteq D^{(2)}_{t_k}$, ii) $D^{(2)}_{t_k} \\subseteq D^{(1)}_{t_k}$, or iii) $D^{(1)}_{t_k} \\equiv D^{(2)}_{t_k}$.\n\\end{definition}\n\nAfter some time, both source and target datasets evolve. \nAt time $t_i$, the target dataset is $T_{t_i} = T_{t_0} + \\delta (T_{t_0-t_i})$ and the source dataset is $S_{t_i} = S_{t_0} + \\delta (S_{t_0-t_i})$.\n\n\n\\begin{requirement}[Required Synchronization]\\label{req:Required_Synchronization}\nAt time $t_j$, a synchronization of both datasets is required iff source and target datasets were synchronised at time $t_i$ and the changesets applied to source and target datasets differ, i.e. $ \\delta ( S_{t_i-t_j}) \\neq \\delta (T_{t_i-t_j})$.\n\\end{requirement}\n\n\\subsection{Conflict }\nWhen we synchronize the target $T_{t_i}$ with source $S_{t_i}$, there may exist triples which have been changed in both datasets. \nThese changed triples may be conflicting.\n\n\\begin{definition}[Potential Conflict]\\label{def:conflict}\nLet us assume that a synchronization is required for a given time slot $t_i-t_j$. $ \\delta (S_{t_i-t_j}) $ is the changeset of the source dataset and  $\\delta (T_{t_i-t_j})$ is the changeset of the target dataset. \nA potential conflict is observed when there are triples $x_1 =  ( s, \\, p, \\, o_1) \\in S_{t_j} \\wedge x_2 = ( s, \\, p, \\, o_2)  \\in \\delta (T_{t_i-t_j}) \\wedge x_2 \\notin S_{t_j} =S_{t_i}+\\delta (S_{t_i-t_j}) $ with $o_1 \\notequiv o_2$.\n\\end{definition}\n\nTaking $o_1 \\notequiv o_2 $ as an indication for a conflict is subjective; in the sense that the characteristics of the involved property $p$ influences the decision.\nConsider two triples $ (s, \\, p, \\, o_1) $ and $ (s, \\, p, \\, o_2) $. \nIf $p$ is a functional data type property, two triples are conflicting iff the object values $o_1$ and $o_2$ are not equal.\nHowever, if the property $p$ is a functional object property, the two triples conflicting if the objects are or can be inferred to be different (e.g. via \\verb|owl:differentFrom|).\n\n\n\nAnother property which needs special consideration is \\verb|rdf:type|.\nFor this property it is necessary to check whether $o_1$ and $o_2$ belong to disjoint classes. \nOnly then these triples would be conflicting. \nFor example, \\verb|s1 rdf:type Person|  and \\verb|s1 rdf:type Athlete| are not conflicting if \\verb|Athlete| is a subclass of \\verb|Person| (i.e. not disjoint).  \nThus, the process of detecting conflicts is considering the inherent characteristics of the involved property.\n\n\\subsection{Synchronization Strategies}\\label{def:strategies}\nIn the following, we list possible strategies for synchronization.\nWe consider the time frame $t_i-t_j$, where in the time $t_i$, the source and target datasets are synchronised and until time $t_j$, both source and target datasets have been evolving independently.\nBefore applying synchronization, the state of the source dataset is $S_{t_j}=S_{t_i} + \\delta (S_{t_i-t_j})$ and the target dataset is $T_{t_j}=T_{t_i} + \\delta (T_{t_i-t_j})$.\n\n\\subsubsection{Strategy I:}\nThis synchronization strategy prefers the source dataset and ignores all local changes on the target dataset; thus, the following requirement is necessary. \n\n\\begin{requirement}[Inclusion for synchronization]\\label{req:Inclusion1}\nAt any given time $t_j$, after synchronising using selected strategy, the target dataset should be a subset of the source dataset, i.e. $T_{t_j} \\subseteq S_{t_j} $.\n\\end{requirement}\n\nTherefore, the target dataset ignores all triples $ \\{ x \\, | \\, x \\notin \\delta (S_{t_i-t_j}) \\, \\wedge \\, x \\in \\delta (T_{t_i-t_j}) \\} $ and adds only the triples $ \\{ y \\, | \\, y \\in \\delta (S_{t_i-t_j}) \\} $.\nAfter synchronization, the state of source dataset is $S_{t_j}=S_{t_i} +  \\delta (S_{t_i-t_j})$ and the state of the target dataset is $T_{t_j}=T_{t_i} +  \\delta (S_{t_i-t_j})$.\nThus, the requirement \\autoref{req:Inclusion1} is met and $ T_{t_j} \\subseteq S_{t_j} $. \nA special case of this strategy is when the target is not evolving. \n\n\\begin{example} \\label{exmp:strategyI}\nApplying strategy I for synchronization on \\autoref{ex:changeset} gives the following triples:\n\n\\begin{lstlisting}[breaklines=true]\ndbr:FLIP_Burger_Boutique   a     dbo:Restaurant;\n\t foaf:name          \"FLIP burger boutique\"@en ;\n\t dbo:abstract \t    \"FLIP burger boutique (stylized as FLIP)..\"@en.\n         georss:point       \"33.7984 -84.4159\";\n         dbp:rating         4;\n         foaf:depiction     wmcf:Richard_Blais.JPG ;\n         dbp:headChef       \"Richard Blais\"@en.\ndbr:Jean_Georges  a         dbo:Restaurant;\n\t foaf:depiction     wmcf:FLIP.jpg;\n         foaf:name          \"Jean-Georges\"@en.\n         georss:point       \"40.76905277777778 -73.98143055555556\";\n         dbo:abstract       \"Jean Georges is a three-Michelin-stars restaurant at 1 Central Park ...\"@en;\n         dbp:rating         5;\n         dbp:headChef       \"Mark LaPico\"@en.\ndbr:Het_Groot_Paradijs      a       dbo:Restaurant;\n         foaf:name          \"Het Groot Paradijs\";\n         dbo:abstract       \"Het Groot Paradijs was a restaurant located in Middelburg,..\";\n         georss:point       \"51.50027222222222 3.6166805555555555\";\n         dbp:rating         4.\n\\end{lstlisting}\n\\end{example}\n\n\\subsubsection{Strategy II:}\nWith this strategy, the target dataset is not synchronized with the source dataset and keeps all its local changes.\nThus, the target dataset is not influenced by any change from the source dataset and evolves locally.\nAfter synchronization, at time $t_j$, the state of the target dataset is $T_{t_j}=T_{t_i} \\cup  \\delta (T_{t_i-t_j}) $, and the state of the source dataset is $S_{t_j}=S_{t_i} \\cup  \\delta (S_{t_i-t_j}) $.\t\n\n\\begin{example} \\label{exmp:strategyII}\nApplying strategy II for synchronization on \\autoref{ex:changeset} gives the following triples:\n\n\\begin{lstlisting}[breaklines=true]\ndbr:FLIP_Burger_Boutique   a     dbo:Restaurant;\n         foaf:name         \"FLIP\"@en ;\n         georss:point      \"33.7984 -84.4159\";\n         dbo:abstract      \"FLIP is an upscale full-service American restaurant ... \"@en;\n         dbp:rating        4;\n         foaf:depiction    wmcf:Richard_Blais.JPG ;\n         dbp:headChef      \"Richard Blais\"@en.\ndbr:Jean_Georges  a        dbo:Restaurant;\n         foaf:name         \"JGV restaurant\"@en;\n         georss:point      \"40.76905277777778 -73.98143055555556\";\n         dbo:abstract      \"Jean Georges is a three-Michelin-stars restaurant at 1 Central Park ...\"@en;\n         dbp:rating        5;\n         foaf:depiction    myp:jgvn.jpg;\n         dbp:headChef      \"Mark LaPico\"@en.\n\\end{lstlisting}\n\\end{example}\n\n\\subsubsection{Strategy III:} \\label{strategy III} \nThis synchronization strategy respects the changesets of both source and target datasets except that it ignores conflicting triples.\n\n\n\n\nHere, the set of triples in which conflicts occur is $X = \\{ x_1 =  ( s, \\, p, \\, o_1) \\in S_{t_j} \\wedge x_2 = ( s, \\, p, \\, o_2)  \\in \\delta (T_{t_i-t_j}) \\wedge x_2 \\notin S_{t_j} $ with $o_1 \\notequiv o_2\\} $\\footnote{Set of conflicting triples selected after considering the inherent characteristics of the involved property. In rest of the paper, we say potential conflict a conflict, unless otherwise specified.}. \nWith Strategy III, the set of conflicting triples $X$ is removed from the target dataset while the source changeset $\\delta ( S_{t_i-t_j} )$ and the target changeset $\\delta ( T_{t_i-t_j} )$ are added. \nAfter synchronization, the state of the source dataset is $S_{t_j}=(S_{t_i}  \\cup  \\delta (S_{t_i-t_j}) \\cup  \\delta (T_{t_i-t_j}) )\\setminus X$ and the state of the target dataset is $T_{t_j}=(T_{t_i} \\cup  \\delta (T_{t_i-t_j}) \\cup \\delta (S_{t_i-t_j})) \\setminus X$.\nThus, requirement \\autoref{req:Inclusion1} is met. \n\n\\begin{example} \\label{exmp:maian}\nApplying strategy III for synchronization on \\autoref{ex:changeset} gives the following triples:\n\n\\begin{lstlisting}[breaklines=true]\ndbr:FLIP_Burger_Boutique   a     dbo:Restaurant;\n         foaf:name         \"FLIP burger boutique\"@en;\n         georss:point      \"33.7984 -84.4159\";\n         dbo:abstract      \"FLIP burger boutique (stylized as FLIP)..\"@en;\n         dbp:rating        4;\n         foaf:depiction    wmcf:Richard_Blais.JPG ;\n         dbp:headChef      \"Richard Blais\"@en.\ndbr:Jean_Georges  a        dbo:Restaurant;\n         georss:point      \"40.76905277777778 -73.98143055555556\";\n         dbo:abstract      \"Jean Georges is a three-Michelin-stars restaurant at 1 Central Park ...\"@en;\n         dbp:rating        5;\n         dbp:headChef      \"Mark LaPico\"@en.\ndbr:Het_Groot_Paradijs     a       dbo:Restaurant;\n         foaf:name         \"Het Groot Paradijs\";\n         dbo:abstract      \"Het Groot Paradijs was a restaurant located in Middelburg,..\";\n         georss:point      \"51.50027222222222 3.6166805555555555\";\n         dbp:rating         4.                       \n\\end{lstlisting}\n\\end{example}\n\n\\subsubsection{Strategy IV:} \\label{strategy IV}\nThis synchronization strategy also respects the changesets of both source and target datasets. \nIn addition, it includes conflicting triples after resolving the conflicts.\n\n\n\n\nHere, we consider the set of triples in which conflict occurs as $X = \\{ x_1 =  ( s, \\, p, \\, o_1) \\in S_{t_j} \\wedge x_2 = ( s, \\, p, \\, o_2)  \\in \\delta (T_{t_i-t_j}) \\wedge x_2 \\notin S_{t_j} $ with $o_1 \\notequiv o_2\\}$. \n\nThe conflicts over these triples should be resolved. \n\\autoref{tab:resolutionfunctions} shows a list of various policies for resolving the conflicts.    \nConflict resolution results in a new set of triples called $Y$ whose triples are originated from $X$ but their conflicts have been resolved.\nThen, this new set (i.e. $Y$) is added to the both source and target datasets.\nAfter synchronization, the state of the source dataset is $S_{t_j}=((S_{t_i} \\cup \\delta (S_{t_i-t_j}) \\cup  \\delta (T_{t_i-t_j})) \\setminus X) \\cup Y$ and the state of target dataset is $T_{t_j}=((T_{t_i} \\cup  \\delta (T_{t_i-t_j}) \\cup \\delta (S_{t_i-t_j})) \\setminus X) \\cup Y$. \nThus, requirement \\autoref{req:Inclusion1} is met.           \n\n\\begin{table}[ht]\n\\caption{Conflict resolution policies and functions}\n\n\\scriptsize\n \\begin{tabular}{|l|llll|}\n    \\hline \\textbf{Category} & \\textbf{Policy} & \\textbf{Function} & \\textbf{Type} & \\textbf{Description} \\\\\n      \\hline\n       \\multirow{8}{*}{\\parbox{0.1\\linewidth}{Deciding}} \n       \t\t& \\parbox{0.13\\linewidth}{Roll the dice} & Any & A & Pick random value.\\\\\n            \\cline{2-5}        \t\t\t\n            \n       \t\t& \\parbox{0.12\\linewidth}{Reputation} & \\parbox{0.15\\linewidth}{Best source} & A & \\parbox{0.5\\linewidth}{Select the value from the preffered dataset.} \\\\                    \n             \\cline{2-5}  \n       \n         & \\parbox{0.12\\linewidth}{Cry with the wolves} & \\parbox{0.15\\linewidth}{Global vote} & A & \\parbox{0.5\\linewidth}{Select the frequently occurring value for the respective attribute among all entities.}  \\\\                         \t\t\n       \t\t \\cline{2-5}   \n       \t\t  \n       \t\t& \\multirow{2}{*}{\\parbox{0.12\\linewidth}{Keep up-to-date}}\n        \t\t\t\t& First* & A & \\parbox{0.5\\linewidth}{Select the first value in order.} \\\\  \n        \t\t\t\t \\cline{3-5}\n\t\t    \t\t\t&  & Latest* & A & \\parbox{0.5\\linewidth}{Select the most recent value.} \\\\\n              \\cline{2-5}        \n                             \n  \t \t\t& \\multirow{3}{*}{\\parbox{0.12\\linewidth}{Filter}} \n  \t\t \t\t& Threshold* & A &  \\parbox{0.5\\linewidth}{Select the value with a quality score higher than a given threshold.} \\\\ \n        \t\t\t\t \\cline{3-5}\n\t\t\t\t& & Best* & A & \\parbox{0.5\\linewidth}{Select the value with highest quality score.} \\\\  \n        \t\t\t\t \\cline{3-5}\n       \t\t\t& & TopN* & A & \\parbox{0.5\\linewidth}{Select the N best values.} \\\\     \n                           \n\t \\hline\n      \\multirow{3}{*}{\\parbox{0.1\\linewidth}{Mediating}}\n      \t\t& \\multirow{3}{*}{\\parbox{0.12\\linewidth}{Meet in the middle}}   \t\t\n \t\t\t& \\parbox{0.2\\linewidth}{Standard deviation, variance} & N & \\parbox{0.5\\linewidth}{Apply the corresponding function to get value.} \\\\ \n             \\cline{3-5}  \t                         \n \t\t\t\n \t\t\t& & \\parbox{0.2\\linewidth}{Average, median} & N & \\parbox{0.5\\linewidth}{Apply the corresponding function to get value.}  \\\\ \n             \\cline{3-5} \n\n             & & Sum & N & \\parbox{0.5\\linewidth}{Select the sum of all values  as the resultant.}  \\\\                              \n                          \n    \\hline \n  {\\parbox{0.1\\linewidth}{Conflict ignorance}}\n       \t\t& \\parbox{0.12\\linewidth}{Pass it on} & Concatenation & A & \\parbox{0.5\\linewidth}{Concatenate all the values to get the resultant.} \\\\  \n   \n         \\hline\n       \\multirow{7}{*}{\\parbox{0.1\\linewidth}{Conflict avoidance}} \n           \n       \t\t& \\multirow{4}{*}{\\parbox{0.12\\linewidth}{Take the information}}\n    \t\t\t\t& Longest & {\\parbox{0.08\\linewidth}{S, C, T}} & \\parbox{0.5\\linewidth}{Select the longest (non-NULL) value.}  \\\\           \t\t\t            \t\t \\cline{3-5} \n             \t     & & Shortest & {\\parbox{0.08\\linewidth}{S, C, T}} & \\parbox{0.5\\linewidth}{Select the shortest (non-NULL) value.}  \\\\ \t \t\t\t\t\t\t\\cline{3-5}\n\t\t    \t\t& & Max & N & \\parbox{0.5\\linewidth}{Select the maximum value from all.}  \\\\ \n             \t\t\\cline{3-5}\n\t\t    \t\t& & Min & N & \\parbox{0.5\\linewidth}{Select the minimum value from all.}\\\\                              \n             \\cline{2-5}  \t             \n      \t\t& \\multirow{3}{*}{\\parbox{0.12\\linewidth}{Trust your friends}} \n\t\t& {\\parbox{0.15\\linewidth}{Choose depending*}} & A & \\parbox{0.5\\linewidth}{Select the value that belongs to a triple having a specific given value for another given attribute.} \\\\\n             \\cline{3-5} \n                     \t \n\t\t& & \\parbox{0.15\\linewidth}{Choose corresponding} & A & \\parbox{0.5\\linewidth}{Select the value that belongs to a triple whose value is already chosen for another given attribute.} \\\\    \n\t\t   \\cline{3-5}\n             \n         & & \\parbox{0.15\\linewidth}{Most complete*} & A & \\parbox{0.5\\linewidth}{Select the value from the dataset (source or target) that has fewest NULLs across all entities for the respective attribute.}   \\\\         \t \n                      \n\t \\hline     \n\\end{tabular}\n\n\\vspace{.5em}\n\n\t* - requires metadata, A - All, S - String, C - Category (i.e., domain values have no order), T - Taxonomy (i.e., domain values have semi-order), N - Numeric. \n\n\n\n\\label{tab:resolutionfunctions}\n\\end{table}\n\n\\begin{example} \\label{exmp:strategyIV}\nApplying strategy IV for synchronization on \\autoref{ex:changeset} while resolving the conflicts using function 'Any' gives the following triples:\n\n\\begin{lstlisting}[breaklines=true]\ndbr:FLIP_Burger_Boutique   a     dbo:Restaurant;\n         foaf:name         \"FLIP burger boutique\"@en;\n         georss:point      \"33.7984 -84.4159\";\n         dbo:abstract      \"FLIP burger boutique (stylized as FLIP)..\"@en;\n         dbp:rating        4;\n         foaf:depiction    wmcf:Richard_Blais.JPG ;\n         dbp:headChef      \"Richard Blais\"@en.\ndbr:Jean_Georges  a        dbo:Restaurant;\n\t foaf:name         \"JGV restaurant\"@en;\n\t foaf:depiction    wmcf:FLIP.jpg;\n         georss:point      \"40.76905277777778 -73.98143055555556\";\n         dbo:abstract      \"Jean Georges is a three-Michelin-stars restaurant at 1 Central Park ...\"@en;\n         dbp:rating        5;\n         dbp:headChef      \"Mark LaPico\"@en.\ndbr:Het_Groot_Paradijs     a      dbo:Restaurant;\n         foaf:name         \"Het Groot Paradijs\";\n         dbo:abstract      \"Het Groot Paradijs was a restaurant located in Middelburg,..\";\n         georss:point      \"51.50027222222222 3.6166805555555555\";\n         dbp:rating        4.\n\\end{lstlisting}\n\\end{example}\n\n\n\\section{Approach}\\label{sec:approach}\n \nOur approach allows a user to choose a synchronization strategy (as presented in \\autoref{def:strategies}). \nBelow, we describe the status of the source and target datasets after applying each synchronization strategy (see \\autoref{alg:datasetStatus}).\n\n\\begin{algorithm}[h] \n\\KwData{$S_{t_i},T_{t_i}, \\delta (T_{t_i-t_j}), \\delta (S_{t_i-t_j} ), strategy$}\n\\KwResult{$S_{t_j},T_{t_j}$ }\n\\scriptsize\n\\Switch{strategy}{\n \t\\tcc{Synchronise with the source and ignore local changes}\n \t\\Case{Stategy I}{\n \t\t$ T_{t_j} := T_{t_i} \\cup \\delta (S_{t_i-t_j} )$ \\;\n \t\t$ S_{t_j} := S_{t_j} $\n \t}\n \t\\tcc{Do not synchronise with the source and keep local changes}\n \t\\Case{Stategy II}{\n \t\t$ T_{t_j} := T_{t_i}  \\cup \\delta (T_{t_i-t_j} )$ \\; \n \t\t$ S_{t_j} := S_{t_i}  \\cup \\delta (S_{t_i-t_j} )$ \n \t}\n \t\\tcc{Synchronise with the source and target datasets and ignore conflicts}\n \t\\Case{Stategy III}{ \n \t\t$ S_{t_j}, T_{t_j} := CDR (\\delta (S_{t_i-t_j} ), \\delta (T_{t_i-t_j} ), T_{t_i}, false) $\n \t}\n \t\\tcc{Synchronise with the source and target datasets and resolve the conflicts}\n \t\\Case{Strategy IV}{\n \t\t$S_{t_j}, T_{t_j} := CDR (\\delta (S_{t_i-t_j} ), \\delta (T_{t_i-t_j} ), T_{t_i}, true) $\n \t}\n }\n \n\\caption{Updating the source and target datasets by the chosen synchronization strategy.}\n\\label{alg:datasetStatus}\n\\end{algorithm}\n\nPlease note that the function $CDR$ is presented in \\autoref{alg:CDR} which\n(i) identifies conflicts for the case of strategy III and strategy IV, and then \n(ii) resolves conflicts only in case of strategy IV.\nOur approach considers triple-based operations, explained below using eight cases, to identify conflicts. \n\nConsider three triples $x_1= ( s, \\, p, \\, o_1 )$, $x_2 = ( s, \\, p, \\, o_2 )$, and $x_3 = ( s, \\, p, \\, o_3 )$ which are in conflict with each other \n$x_1 \\in \\delta ( S_{t_i-t_j} )  \\wedge x_2 \\in \\delta ( T_{t_i-t_j} ) \\wedge x_3 \\in \\{\\delta ( S_{t_i-t_j} )  \\wedge \\delta ( T_{t_i-t_j} )\\}  \\wedge o_1 \\notequiv o_2  \\notequiv o_3$. \nIn the following we present eight cases of evolution causing conflicts. \nFor the first four cases (I-IV), the conflict resolution is straightforward. \nBut for the cases V-VIII, we have to employ a conflict resolution policy to decide about the triples $x_1$ and $x_2$:\n\n\\begin{itemize}\n\n\\item \\textbf{\\emph{Case I:}} $x_1$ is added to $T_{t_j}$ if $x_1$ is added by the source dataset and $x_2$ is deleted from the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^+ \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^- $.  \n\\item \\textbf{\\emph{Case II:}} $x_2$ is added to $S_{t_j}$ if $x_1$ is deleted by the source dataset and $x_2$ is added to the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^- \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^+ $.  \n\\item \\textbf{\\emph{Case III:}} $ x_1 $ is added to $ T_{t_j} $ if $x_1$ is modified by the source dataset and $x_2$ is deleted from the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^+  \\wedge  x_2 \\in \\delta (S_{t_i-t_j} )^- \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^- $.  \n\\item \\textbf{\\emph{Case IV:}} $ x_2 $ is added to $ S_{t_j} $ if $x_1$ is deleted from the source dataset and $x_2$ is modified in the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^- \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^+  \\wedge x_1 \\in \\delta (T_{t_i-t_j}  )^- $.  \n\\item \\textbf{\\emph{Case V:}}  if the triple $x_1$ is added to the source dataset and $x_2$ is added to the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^+ \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^+ $.\n\n\\item \\textbf{\\emph{Case VI:}} if $x_3$ is modified by both source and target datasets: $ x_2 \\in \\delta (S_{t_i-t_j} )^+ \\wedge x_3 \\in \\delta (S_{t_i-t_j} )^- \\wedge x_1 \\in \\delta (T_{t_i-t_j}  )^+ \\wedge x_3 \\in \\delta (T_{t_i-t_j}  )^- $.\n\n\\item \\textbf{\\emph{Case VII:}} if $x_1$ is modified by the target dataset: $ x_1 \\in \\delta (S_{t_i-t_j} )^+  \\wedge x_2 \\in \\delta (T_{t_i-t_j}  )^+ \\wedge x_1 \\in \\delta (T_{t_i-t_j}  )^- $. \n\\item \\textbf{\\emph{Case VIII:}} if $x_1$ is modified by the source dataset: $ x_2 \\in \\delta (S_{t_i-t_j} )^+  \\wedge x_1 \\in \\delta (S_{t_i-t_j} )^- \\wedge x_1 \\in \\delta (T_{t_i-t_j}  )^+ $. \n\n\\end{itemize}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{algorithm}[tb]\n\\label{alg:CDRALG} \n\\KwData{$S_{t_i},T_{t_i}, \\delta (T_{t_i-t_j}), \\delta (S_{t_i-t_j} ), conflictresolution$}\n\\KwResult{$S_{t_j},T_{t_j}$ }\n\\scriptsize\n\n$ T_{t_j} = \\phi $ \\;\n$ S_{t_j} = \\phi $ \\;\n$ temp   = \\phi $ \\;\n \\tcc{$step_1$}\n\\For{all triples $ x_1 = (s_1,\\, p_1,\\, o_1) \\in \\delta (S_{t_i-t_j} )^+ $}{\n\n \\tcc{finding triples which are in conflict with $x_1$}\n$ X = \\{ x_2 = (s_1,\\, p_1,\\, Node.ANY) \\in \\delta (S_{t_i-t_j} )^- \\cup \\delta (T_{t_i-t_j} )^+ \\cup \\delta (T_{t_i-t_j} )^- \\cup T_{t_i} \\}$ \\;\n\n  \\If { $ X  == \\phi $} {\n\t    $ temp =  temp \\cup x_1 $ \\;\t }\t\n   \t    \\Else \n   \t   {  x = resolveConflict($ x_1, X $) \\;\n   \t     $ temp =  temp \\cup x $ \\;}\n}\n\n\n\n\n\n\n\n\n\n \\tcc{$step_2$}\n$ T_{t_i} := T_{t_i} \\setminus \\delta (T_{t_i-t_j} )^- \\cup  \\delta (S_{t_i-t_j} )^- $\\;\n$ S_{t_i} := S_{t_i} \\setminus \\delta (S_{t_i-t_j} )^- $ \\;\n \\tcc{$step_3$}\n$ temp :=  temp \\cup \\delta (S_{t_i-t_j} )^+ \\cup \\delta (T_{t_i-t_j} )^+$ \\;\n\\tcc{Updating the target dataset}\n$ T_{t_j} := T_{t_i} \\cup temp $ \\;\n\\tcc{Updating the source dataset}\n$ S_{t_j} := S_{t_i} \\cup temp $ \\;\n  \t\n\\caption{CDR algorithm: Conflict Detection and Resolution}\n\\label{alg:CDR}\n\\end{algorithm}\n\n  \n\\autoref{alg:CDR} shows the pseudocode of the procedure for updating the source and target datasets at the end of each timeframe.   \t\nThe function \\texttt{resolveConflict} identifies operations described in Case I-VIII. \nIn addition, for the cases V-VIII, it resolves conflicts based on the type of involved predicate.\nAs we discussed earlier, whether a conflict between two triple exists depends heavily on the type of property.\nConsider two triples $(s,\\, p,\\, o_1)$ and $(s,\\, p,\\, o_2) $, if $p$ is \\verb|rdfs:label|, we measure the similarity between $o_1$ and $o_2$ using the Levenshtein distance.\nWe pick both values of \\texttt{rdfs:label} if their similarity is below a certain threshold otherwise we treat them as conflicting. \nThe function \\texttt{resolveConflict} identifies operations containing deleted in the source, deleted/added/modified in the target dataset. \nIn case of deleted in the source dataset and added/modified by the target dataset, it returns a triple to be added in $T_{t_j}$ otherwise null. \n\n\n\\autoref{fig:DT2} illustrates \\autoref{alg:CDR} for updating the target dataset $T_{t_i} $. \nWe choose the synchronization strategy IV for the synchronization task.\nIn the first step, we use a tree structure to identify conflicts for the triples in $ \\delta (S_{t_i-t_j} )^+ $. \nConsider the tree structure (a) in $step_1$ for the triple $ (s_1,\\, p_1,\\, o_{11}) \\in  \\delta (S_{t_i-t_j} )^+ $. \nWe find different object values for $ (s_1,\\, p_1) $ in $ \\delta (S_{t_i-t_j} )^-, \\delta (T_{t_i-t_j} )^+ $, $\\delta (T_{t_i-t_j} )^-$,  and $ T_{t_i} $. \nThen, we identify the triple based operation.\nFor example, if we find the object value $ o_{11} $ in $ \\delta (S_{t_i-t_j} )^+ , o_{12} $ in $ \\delta (T_{t_i-t_j} )^+ $, and $ o_1 $ in $ \\delta (S_{t_i-t_j} )^-, \\delta (T_{t_i-t_j} )^- $, and $ T_{t_i} $ it means $  (s_1,\\, p_1,\\, o_1) $ is modified by both source and target. \nThus, this case represents a conflicting triple. \nWe resolve it using the conflict resolution policy 'source preference' selected for predicate $ p_1 $ and add it in $ T_{t_j} $.   \nThe triple-based operation for $step_1 (b)$ is source addition.  \nThe $step_1 (c)$ for the triple $ (s_6,\\, p_6,\\, o_6) $ shows triple-based operations source addition and target modification.\n\n\nFurthermore, the user has the opportunity to adopt the manual or automatic selection of resolution functions. \nThe resolution function is oriented to the type of predicates. \nThe list of supported resolution functions is shown in \\autoref{tab:resolutionfunctions}.\nFor automatic selection of conflict resolution functions for predicates, we check attributes of predicates (e.g. type, cardinality). \nBased on the usage analysis of different functions in \\cite{Bleiholder2006}, we prefer functions such as first, longest, and maximum for resolving conflicts.\nFor instance, we prefer function longest for strings to avoid loss of information. \nFor numeric data types, we prefer function max to keep the up-to-date value.\nFor URIs, we pick the first value.\n \n\\begin{figure}[tb]\n\n\\centering\n\\includegraphics[width=0.95\\textwidth]{DT_Example.pdf}\n\\caption{Execution of \\autoref{alg:CDR} to synchronize $ T_{t_i} $ with $S_{t_i}$}\n\\label{fig:DT2}\n\t\\vspace{-1.7em}\n\\end{figure}  \n\n\\section{Evaluation}\\label{sec:evaluation}\n\\vspace{-0.75em}\n\nIn order to assess the discussed approaches for synchronization and conflict identification/resolution, we prepared a testbed based on a slice of DBpedia using the following SPARQL query.\n\\begin{lstlisting}\nCONSTRUCT WHERE  {\n    ?s    a                Politician ;\n          foaf:name        ?name ;\n          dbo:nationality  ?nationality ;\n          dbo:abstract     ?abstract ;\n          dbp:party        ?party ;\n          dbp:office       ?office\n    OPTIONAL { ?s  foaf:depiction  ?depiction }\n}\n\\end{lstlisting}\n\nThe extracted dataset is used as the initial source and target dataset.\nThen, we collected a series of changesets from DBpedia-live published from September 01, 2015 to October 31, 2015 using iRap~\\cite{irap2015}.\nWe collected a total of 304 changesets.\nThese changesets are leveraged to simulate updates of the source and target datasets.\nWe randomly select a total of 91 addition parts of changesets and altered values of their triples.\n\\autoref{tab:size} provides the number of triples of initial target, source and their associated changesets before synchronization.\nInitially, we have \\emph{200082} triples with 163114 unique objects in $ T_{t_i}$ where $t_i  = September 01, 2015$. \n\n\\begin{table}[ht]\n\n\\scriptsize\n\n\\centering\n \\begin{tabular}{|c|c|c|c|c|c|}\n    \\hline \\textbf{$S_{t_i}$} & \\textbf{$T_{t_i}$} & \\textbf{$\\delta (S_{t_i-t_j} )^+$} & \\textbf{$\\delta (S_{t_i-t_j} )^-$} & \\textbf{$\\delta (T_{t_i-t_j} )^+$} \n    &  \\textbf{$\\delta (T_{t_i-t_j} )^-$}  \\\\\n        \\hline 200082 & 200082 & 948 & 160 & 11725 & 81  \\\\     \n    \\hline \n             \n\\end{tabular}\n\\caption{ \\scriptsize \\# of triples in the source, target, changesets for a given timeframe.}\n\n\\label{tab:size}\n\\end{table}\n\n\nFor the given timeframe $t_i-t_j$ \\footnote{09/01/2015-10/31/2015.}, we want to synchronize the source and target datasets.\nTo do that, we define five different scenarios.\nIn four scenarios, we apply subsequently the strategy (I-IV) over all predicates of the changesets and measure the performance.\nFor the last scenario, we apply two strategies in a combined form on the changesets where we select strategy IV for predicate dbp:office, and strategy I for predicates dbp:party, dbo:nationality, \nrdf:type, foaf:name, dbo:abstract, and foaf:depiction.\n\nFor all predicates using strategy IV, we select the resolution function 'any'.\n\\autoref{tab:strategy} provides the number of triples produced as a result of synchronising $S_{t_i}$ and $T_{t_i}$ in each scenario. \n\nThe updated changesets are sent back to the source as well as target for synchronization purpose. \nThe number of conflicting triples found in scenarios 3, 4, and 5 are shown in \\autoref{tab:strategy}. \n\n\\begin{table}[ht]\n\\scriptsize\n\\centering\n \\begin{tabular}{|c|c|c|c|c|c|c|}\n \n    \\hline \\textbf{Scenario} & \\textbf{$\\delta (S_{t_i-t_j})^+$} & \\textbf{$\\delta (S_{t_i-t_j})^-$} & \\textbf{$\\delta (T_{t_i-t_j})^+$} \n    & \\textbf{$\\delta (T_{t_i-t_j})^-$} & \\textbf{Conflicting triples} \\\\\n        \\hline  1 & 0 & 0 & 948 & 160 & - \\\\    \n        \\hline  2 & 0 & 0 & 11725 & 81 & - \\\\    \n        \\hline  3 & 11682\t& 81 &\t12060 & 81 & 343 \\\\     \n        \\hline  4 &  11800 & 195\t& 12186 & 81 & 343 \\\\       \n        \\hline  5 & 5227\t& 131\t& 6081 & 121 & 186 \\\\     \n        \n    \\hline \n             \n\\end{tabular}\n\\caption{Results of synchronization}\n\\label{tab:strategy}\n\\end{table}\n\\vspace{-2.15em}\n\nThe running time of the five different scenarios is shown in \\autoref{tab:time} (Please note that these times are recorded only for the execution of synchronization part). \nScenario 4 where conflicts for all predicates were found and resolved using strategy IV took more time as compared to all other scenarios.\nEvaluation showed that strategy IV needs more time even from strategy 3 (performed in scenario 3) where all conflicts were detected but not resolved. \n\n\\begin{table}[ht]\n\\scriptsize\n\\centering\n \\begin{tabular}{|c|c|c|c|c|c|c|}\n \n    \\hline \\textbf{Scenario} & \\textbf{RunTime (minute)} \\\\\n        \\hline  1 & 0:0 \\\\    \n        \\hline  2 & 0:0 \\\\    \n        \\hline  3 & 24:4 \\\\     \n        \\hline  4 & 49:5\\\\       \n        \\hline  5 & 9:1\\\\     \n       \n    \\hline \n             \n\\end{tabular}\n\\caption{Runtime per scenario}\n\\label{tab:time}\n\\end{table}\n\\vspace{-2.15em}\nSynchronization influences data quality specially in terms of data consistency.\nTo evaluate the usefulness of the synchronization approach, we use three data quality metrics i.e. (1) \\emph{completeness}, (2) \\emph{conciseness}, and (3) \\emph{consistency} described as follows:\n\\begin{enumerate}\n\\item Completeness refers to the degree to which all required information is present in a dataset \\cite{Zaveri2015}.\n\nWe measure it for source and target changesets to identify which helps more in completeness using\n\n", "index": 1, "text": "\n\\[ \\frac{Number\\,of\\,unique\\,triples\\,in\\,synchronised\\,dataset}{Number\\,of\\,unique\\,triples\\,in\\,(initial\\,dataset\\,+\\,changeset)} \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\frac{Number\\,of\\,unique\\,triples\\,in\\,synchronised\\,dataset}{Number\\,of\\,%&#10;unique\\,triples\\,in\\,(initial\\,dataset\\,+\\,changeset)}\" display=\"block\"><mfrac><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>q</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>y</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>d</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>q</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>l</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>t</mi></mpadded></mrow><mo rspace=\"4.2pt\">+</mo><mrow><mi>c</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></math>", "type": "latex"}, {"file": "1601.05270.tex", "nexttext": "\n\n\n\\item Conciseness measures the degree to which the dataset does not contain redundant information using\n", "itemtype": "equation", "pos": 42209, "prevtext": "\n\n\\item Consistency states that the values should not be conflicting. We measure it using \n\n", "index": 3, "text": "\n\\[ \\frac{Number\\,of\\,non-conflicting\\,triples\\,in\\,synchronized\\,dataset} {Number\\,of\\,triples\\,in\\,(initial\\,dataset\\,+\\,source\\,and\\,target\\,changesets)} \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\frac{Number\\,of\\,non-conflicting\\,triples\\,in\\,synchronized\\,dataset}{Number%&#10;\\,of\\,triples\\,in\\,(initial\\,dataset\\,+\\,source\\,and\\,target\\,changesets)}\" display=\"block\"><mfrac><mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>n</mi></mrow><mo>-</mo><mrow><mi>c</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>g</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>y</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>z</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>d</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>l</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>t</mi></mpadded></mrow><mo rspace=\"4.2pt\">+</mo><mrow><mi>s</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>d</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>t</mi></mpadded><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>s</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></math>", "type": "latex"}, {"file": "1601.05270.tex", "nexttext": "\nConciseness (before synchronization) is computed using initial target dataset and source and target changesets.\n\\end{enumerate}\n \nWe compute these metrics for all the assumed scenarios, the results are shown in \\autoref{tab:complete}. \nFor our sample case study, we found almost equal contribution of both source and target changesets in reducing the missing information.\nHowever, we found minimum 163191 number of unique objects using strategy II and maximum 163591 number of unique objects using strategy IV.\nThrough evaluation, we found significant increase in conciseness for all strategies.\n\n\\begin{table}[h]\n\\scriptsize\n\\centering\n \\begin{tabular}{|c|c|c|c|c|c|c|}\n \n    \\hline \\textbf{Scenario} & \\parbox{0.17\\linewidth}{\\textbf{Completeness (source)}} & \\parbox{0.17\\linewidth}{\\textbf{Completeness (target)}} & \\textbf{Consistency}  & \\parbox{0.17\\linewidth}{\\textbf{Conciseness (before synchronization)}} & \\parbox{0.17\\linewidth}{\\textbf{Conciseness (after synchronization)}} \\\\\n        \\hline  1 & 99\\% & 100\\% & - & 77\\% & 81\\% \\\\     \n        \\hline  2 & 99\\% & 99\\% & - & 77\\% & 81\\% \\\\   \n        \\hline  3 & 99\\% & 100\\% & 94\\% & 77\\% & 81\\% \\\\     \n        \\hline  4 & 99\\% & 100\\% & 94\\%& 77\\% & 81\\% \\\\       \n        \\hline  5 & 99\\% & 100\\% & - & 77\\% & 81\\% \\\\                               \n    \\hline \n             \n\\end{tabular}\n\\caption{Synchronization effect on completeness, consistency, and conciseness}\n\n\\label{tab:complete}\n\\end{table}\n\\vspace{-2.15em}\n\n\\section{Related Work}\\label{sec:relatedwork}\n\nRelated work includes synchronization of semantic stores for concurrent updates by autonomous clients \\cite{Aslan2011}, synchronization of source and target \\cite{Tummarello2007}, replication of partial RDF graphs \\cite{Schandl2010}, ontology change management \\cite{Konstantinidis2007}, and conflict resolution for data integration \\cite{Bleiholder2006, Motro2006, Michelfeit2014, Knap2012, Paton2012, Mendes2012, Schultz2011, Bilke2005, Yan1999, Yager2004, Bryl2014}. \nWe discuss related work here along the dimensions change management and conflict resolution.\n\n\\subsubsection{Change management.}\n\nEfficient synchronization of semantic stores is challenging due to the factors, scalability and number of autonomous participants using replica. \n\\emph{C-Set}~\\cite{Aslan2011} is a Commutative Replicated Data Type (CRDT) that ensures consistency irrespective of the order of operations insert/delete at reception. \nCRDT allows concurrent operations to be commutative and thus, avoids other integration algorithms for consistency. \n\n\\emph{RDFSync}~\\cite{Tummarello2007} is a synchronization algorithm. \n\n\n\nIt offers three types of synchronization: \n1) the target graph is equivalent to merge of source and target graphs, \n2) the target removes unknown information to/from the source, and \n3) the target graph is equivalent to source.\\\\\nThe approach, proposed in \\cite{Schandl2010}, allows to replicate part of an RDF graph on clients. \nClients can apply offline changes to this partial replica and write-back to original data source upon reconnection. \nThe partial replica also contains triples that describe which parts of the source RDF graph are not included in it. \n\n\nThe coordination-free protocol~\\cite{Ibanez2014} namely, Col-Graph, solves the writability, availability, and scalability issues of linked data (LD). \nIt allows LD consumers to replicate subset of data locally, perform querying, and modify replica to improve data quality. \n\n\n\\autoref{tab:changemanagement} provides a comparative analysis of change management approaches used for synchronization.\n\nA few surveyed approaches~\\cite{Konstantinidis2007, Auer2006, Papavassiliou2009} are related to ontological change management.\nIn \\cite{Konstantinidis2007}, a framework is developed for ontology change management and tested for RDF ontologies. \nThis framework allows to design ontology evolution algorithms. \n\n\n\n\n\n\nIn \\cite{Auer2006}, an approach for the versioning and evolution of ontologies, based on RDF data model, is presented. \n\nIt considers atomic changes such as addition or deletion of statement and then aggregates them to compound changes to form a change hierarchy. \nThis change hierarchy allows human reviewers to analyze at various levels of details. \nIn \\cite{Papavassiliou2009}, a formal language of changes and a framework to define changes for RDF/S ontologies is developed. \nThe change language aggregates several low-level changes into high-level changes to form concise and intuitive changesets. \n\n\n\\begin{table}[b]\n\\caption{Synchronization approaches}\n\\centering\n\\scriptsize\n \\begin{tabular}{|c|c|c|c|c|}\n    \\hline \\textbf{Approach} & \\textbf{Synchronization} & \\textbf{Bi-directional} & \\textbf{Participants} & \\textbf{Conflict handling*}  \\\\\n        \\hline  \\emph{C-Set} & \\checkmark & \\checkmark & n & x \\\\    \n         \\hline  \\emph{RDFSync} & \\checkmark & x & source, target & x \\\\\n          \\hline  \\emph{Col-graph} & \\checkmark & \\checkmark & n & x \\\\\n           \\hline  [14] & \\checkmark & back to source & n & x \\\\\n            \\hline  \\emph{Co-evolution} & \\checkmark & \\checkmark & source, target & \\checkmark \\\\\n    \\hline \n\\end{tabular}\\\\\n\n\t* - Triple level conflicts according to \\autoref{def:conflict}\n\\label{tab:changemanagement}\n\\end{table}\n\n\\subsubsection{Conflict resolution.}\n\n\nData integration is performed in multiple steps, one of which is data fusion where records representing same real world entity are combined to form a single and consistent representation~\\cite{Bleiholder2006, Motro2006}.\n\\\\\nIn \\cite{Michelfeit2014}, a data fusion algorithm is proposed for the Linked Data integration framework \\emph{ODCleanStore}~\\cite{Knap2012}. \nIt resolves conflicts at schema, data, and identity level. \nIn contrast to our approach, it allows to resolve conflicts at query time like pay-as-you-go approach~\\cite{Paton2012}. \nAdditionally, it computes quality scores of integrated data to help users to decide about the trustworthiness of results. \n\\\\\n\\emph{Sieve}~\\cite{Mendes2012} is a data fusion module of \\emph{LDIF}~\\cite{Schultz2011}. \nIt uses quality scores to perform conflict resolution at the time of data loading into a data store. \n\nFor example, fusion function KeepFirst can select the value which belongs to a data source with highest reputation.\n\\emph{Sieve Fusion Policy Learner}~\\cite{Bryl2014} uses a gold standard dataset to learn optimal fusion function for each property. \nThe user specifies possible conflict resolution strategies from which the learning algorithm selects the one that gives maximum results within error threshold with respect to the gold standard. \n\\\\\nFor relational databases, there is much work on inconsistency resolution \\cite{Bleiholder2006, Motro2006, Bilke2005, Yager2004, Yan1999}. \n\\cite{Bleiholder2006} classifies conflict resolution strategies and presents a catalog of their underlying resolution functions. \nIt divides the conflict resolution strategies into three classes: ignorance, avoidance, and resolution. \nConflict ignorance strategies are not aware of conflicts in the data. \n\nConflict avoidance strategies are aware of whether and how to handle inconsistent data. \nThese can be further divided into instance-based and metadata-based. \nSource preferences can be based on reliability, cost, size, or some other quality criteria. \nConflict resolution strategies may use metadata to resolve conflicts. \nThese can be divided into deciding and mediating. \nA deciding strategy chooses value from already existing values whereas a mediating strategy may compute a new value. \n\\\\\nThe \\emph{Humboldt Merger}~\\cite{Bilke2005}, extension to SQL with a FUSE BY statement, resolves conflicts at runtime. \n\\emph{Fusionplex}~\\cite{Motro2006} integrates data from heterogeneous data sources and resolves inconsistencies during data fusion. \nFor fusion, it uses parameters such as user-defined data utility, threshold of acceptance, fusion functions, and metadata. \n\\emph{AURORA}~\\cite{Yan1999} framework extends SQL to support conflict-tolerant queries. \nYager\u00e2\u0080\u0099s fusion framework~\\cite{Yager2004} uses a voting-like mechanism to find the best value. \n\n\n\n\\section{Conclusion and Future Work}\n\\label{sec:conclusion}\nIn this paper we presented an approach to deal with co-evolution which refers to mutual propagation of the changes between a replica and its origin dataset.\nUsing the co-evolution process, we address synchronization and conflict resolution issues.\nWe demonstrated the approach using formal definitions of all the concepts required for realizing co-evolution of RDF datasets and implemented it using different strategies.\nWe evaluated the approach using data quality metrics completeness, conciseness, and consistency.\nA thorough evaluation of the approach, using DBpedia changesets, indicates that our method can significantly improve the quality of dataset.\nIn the future, we will extend the concept of conflict resolution at schema level. \nFor example, renaming a class invalidates all triples that belong to it in a dataset.\nFurther, we will evaluate the scalability and performance of our proposed approach using a benchmark dataset.\n\n\\bibliography{co-evolution}\n\n\\bibliographystyle{splncs03}\n\n\n", "itemtype": "equation", "pos": 42474, "prevtext": "\n\n\n\\item Conciseness measures the degree to which the dataset does not contain redundant information using\n", "index": 5, "text": "\n\\[ \\frac{Number\\,of\\,unique\\,triples\\,in\\,dataset}{Number\\,of\\,all\\,triples\\,in\\,dataset} \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\frac{Number\\,of\\,unique\\,triples\\,in\\,dataset}{Number\\,of\\,all\\,triples\\,in\\,dataset}\" display=\"block\"><mfrac><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>q</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>e</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow><mrow><mi>N</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>r</mi></mpadded><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>l</mi></mpadded><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>s</mi></mpadded><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi>n</mi></mpadded><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi></mrow></mfrac></math>", "type": "latex"}]