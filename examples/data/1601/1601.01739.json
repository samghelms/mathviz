[{"file": "1601.01739.tex", "nexttext": "\nwhere $f_{m,j}$($f_{n,j}$) denotes the $j$th attribute among $4C+r$\ninput pattern for the $m$th ($n$th)\npoints, $k$ represents the total number of attributes. The points in\nGroup 1 and Group 2 show that those outlier quasars cannot be\ncorrectly identified in an Euclidean space. In other words, we cannot\nhave a simple plane as a useful separating criterion between points\nin Group 1 and Group 2. Based on the present data, the provided\ninformation is not enough to give good estimation of the outlier\npoints. Now there is a question whether those outlier points can be\nlinearly separable in a high-dimensional non-Euclidean feature\nspace? Thereby, we explore the kernel function in SVM and map\nfeatures into a high dimension space and test if we can correctly\nclassify outlier points in Group 1 and Group 2. From the analysis\nabove, we propose a two-stage integration approach by fusion of\nestimation with KNN and classification with SVM.\n\n\n\\subsection{Estimation with K-Nearest-Neighbor}\n\nK-Nearest-Neighbor (KNN) algorithm is a lazy predictor which\nrequires a training set for learning. It first finds the nearest\nneighbors by comparing distances between a test sample and training\nsamples that are similar to it in a feature space. Next, it assigns\nthe average value of the nearest neighbors to the test sample as its\nprediction value. In general, the distance is computed as\nEuclidean distance described in Equation~1. In the era of big data,\nwe have been collecting more data than ever before and KNN achieves\nmuch accurate predictions (Zhang et~al. 2013). Thereby, we also use\nKNN in our research. One disadvantage of KNN is the high computation\ncost. We apply KD-tree to efficiently implement KNN algorithm.\n\n\n\\subsection{Classification with Support Vector Machine}\n\nSupport Vector Machine (SVM) is an effective classification\nalgorithm based on structural risk minimization principle proposed\nby Vapnik (1995). Given a training dataset with $n$ records,\neach record has the pattern of ($x_i,y_i$) for $i=1,2,...,n$, we\naim to build a linear classifier with the following Equation~2,\n\n", "itemtype": "equation", "pos": 12074, "prevtext": "\n\n   \\title{Photometric Redshift Estimation for Quasars by Integration of KNN and SVM\n$^*$ \\footnotetext{\\small $*$ Supported by the National Natural\nScience Foundation of China.} }\n\n\n \\volnopage{ {\\bf 2012} Vol.\\ {\\bf X} No. {\\bf XX}, 000--000}\n   \\setcounter{page}{1}\n\n\n   \\author{Bo Han\\inst{1}, Hongpeng Ding\\inst{1}, Yanxia Zhang\\inst{2}, Yongheng Zhao\\inst{2}}\n   \\institute{ International School of Software, Wuhan University, Wuhan, 430072,\n   P.R.China; \\\\\n        \\and Key Laboratory of Optical Astronomy, National Astronomical Observatories,\nChinese Academy of Sciences, 20A Datun Road, Chaoyang District,\n100012, Beijing, P.R.China {\\it zyx@bao.ac.cn}\\\\\n\\vs \\no\n   {\\small Received 2015 June 12; accepted }\n}\n\n\\abstract{The massive photometric data collected from multiple\nlarge-scale sky surveys offer significant opportunities for\nmeasuring distances of celestial objects by photometric redshifts.\nHowever, catastrophic failure is still an unsolved problem for a\nlong time and exists in the current photometric redshift estimation\napproaches (such as $k$-nearest-neighbor). In this paper, we propose\na novel two-stage approach by integration of $k$-nearest-neighbor\n(KNN) and support vector machine (SVM) methods together. In the\nfirst stage, we apply KNN algorithm on photometric data and estimate\ntheir corresponding z$_{\\rm phot}$. By analysis, we find two dense\nregions with catastrophic failure, one in the range of z$_{\\rm\nphot}\\in[0.3,1.2]$, the other in the range of z$_{\\rm phot}\\in\n[1.2,2.1]$. In the second stage, we map the photometric input\npattern of points falling into the two ranges from original\nattribute space into a high dimensional feature space by Gaussian\nkernel function in SVM. In the high dimensional feature space, many\noutlier points resulting from catastrophic failure by simple\nEuclidean distance computation in KNN can be identified by a\nclassification hyperplane of SVM and further be corrected.\nExperimental results based on the SDSS (the Sloan Digital Sky\nSurvey) quasar data show that the two-stage fusion approach can\nsignificantly mitigate catastrophic failure and improve the\nestimation accuracy of photometric redshifts of quasars. The\npercents in different |$\\Delta$z| ranges and rms (root mean square)\nerror by the integrated method are $83.47\\%$, $89.83\\%$, $90.90\\%$ and 0.192, respectively,\ncompared to the results by KNN ($71.96\\%$, $83.78\\%$, $89.73\\%$ and 0.204).\n\\keywords{catalogs - galaxies: distances and redshifts - methods:\nstatistical - quasars: general - surveys - techniques: photometric }\n}\n\n   \\authorrunning{B. Han et al. }            \n   \\titlerunning{Photometric Redshift Estimation}  \n   \\maketitle\n\n\n\\section{Introduction}\nPhotometric redshifts are obtained by images or photometry. Compared\nto spectroscopic redshifts, they show the advantages of high\nefficiency and low cost. Especially, with the running of multiple\nongoing multiband photometric surveys, such as SDSS (the Sloan\nDigital Sky Survey), UKIDSS (the UKIRT Infrared Deep Sky Survey) and\nWISE (the Wide-Field Infrared Survey Explorer), a huge volume of\nphotometric data are collected, which are larger than spectroscopic\ndata by two or three orders of magnitude. The massive photometric\ndata offer significant opportunities for measuring distances of\ncelestial objects by photometric redshifts. However, photometric\nredshifts show the disadvantages of low accuracy compared to\nspectroscopic redshifts, and require more sophisticated estimation\nalgorithms to overcome the problem. Researchers worldwide have\ninvestigated the photometric redshift estimation techniques in\nrecent years. Basically, these techniques are categorized into two\ntypes: template-fitting models and data mining approaches.\nTemplate-fitting model is the traditional approach for estimating\nphotometric redshifts in astronomy. It extracts features from\ncelestial observational information, such as multiband values, and\nthen matches them with the designed templates constructed by\ntheoretical models or real observations. With feature matching,\nresearchers can estimate photometric redshifts. For example,\nBolzonella et~al. (2000) estimated photometric redshifts through a\nstandard SED fitting procedure, where SEDs (spectral energy\ndistributions) were obtained from broad-band photometry. Wu et~al.\n(2004) estimated the photometric redshifts of a large sample of\nquasars with the $\\chi^2$ minimization technique by using derived\ntheoretical color-redshift relation templates. Rowan-Robinson et~al.\n(2008) proposed an approach using fixed galaxy and quasar templates\napplied to data at 0.36-4.5 $\\mu m$, and on a set of four infrared\nemission templates fitted to infrared excess data at 3.6-170$\\mu m$.\nIlbert et~al. (2009) applied a template-fitting method (Le Phare) to\ncalculate photometric redshifts in the 2-deg$^2$ COSMOS field.\nExperimental results from the above template-fitting methods showed\nthat their estimation accuracy relied on the templates constructed\nby either simulation or real observational data.\n\nData mining approaches apply statistics and machine learning\nalgorithms on a set of training samples and automatically learn\ncomplicated functional correlations between multiband photometric\nobservations and their corresponding high confidence redshift\nparameters. These algorithms are data-driven approaches, rather than\ntemplate-driven approaches. The experimental results showed that\nthey achieved much accurate photometric estimations in many\napplications. For example, Ball et~al. (2008) applied a nearest\nneighbor algorithm to estimate photometric redshifts for galaxies\nand quasars using SDSS and GALEX (the Galaxy Evolution Explorer)\ndata sets. Abdalla et~al. (2008) estimated photometric redshifts by\nusing a neural network method. Freeman et~al. (2009) proposed a\nnon-linear spectral connectivity analysis for transforming\nphotometric colors to a simpler, more natural coordinate system\nwherein they applied regression to make redshift estimations. Gerdes\net~al. (2010) developed a boosted decision tree method, called\nArborZ, to estimate photometric redshifts for galaxies. Way et~al.\n(2012) proposed an approach based on Self-Organizing-Mapping (SOM)\nto estimate photometric redshifts. Bovy et~al. (2012) presented the\nextreme deconvolution technique for simultaneous classification and\nredshift estimation of quasars and demonstrated that the addition of\ninformation from UV and NIR bands was of great importance to\nphotometric quasar-star separation and essentially the redshift\ndegeneracies for quasars were resolved. Carrasco et~al. (2013)\npresented an algorithm using prediction trees and random forest\ntechniques for estimating photometric redshifts, incorporating\nmeasurement errors into the calculation while also efficiently\ndealing with missing values in the photometric data. Brescia et~al.\n(2013) applied the Multi Layer Perceptron with Quasi Newton\nAlgorithm (MLPQNA) to evaluate photometric redshifts of quasars with\nthe data set from four different surveys (SDSS, GALEX, UKIDSS, and\nWISE).\n\nThough template-fitting approaches and data mining approaches can\nroughly estimate photometric redshifts, they both suffer the\ncatastrophic failure problem in estimating photometric redshifts of\nquasars when the spectroscopic redshift is less than 3 (Richards et~al. 2001; Weinstein\net~al. 2004; Wu et~al. 2004). Zhang et~al.\n(2013) practically demonstrated that with cross-matched multiband\ndata from multiple surveys, such as SDSS, UKIDSS and WISE, $k$-nearest\nneighbor (KNN) algorithm can largely solve the catastrophic failure problem\nand improve photometric redshift estimation accuracy. The method\nbecomes more important as the development of multiple large\nphotometric sky surveys and the coming of the age of astronomical\nbig data. However, during the data preparation process, we need to cross-match\nmultiband information of quasars from multiple photometric surveys.\nThe number of matched quasar records is far less than the original\nquasar number in a single survey. For example, there are 105,783\nquasar samples available in SDSS DR7. However, the number of\ncross-matched samples from SDSS, WISE and UKIDSS is only 24,089. The\ncross-matched sample is around one fourth of SDSS quasar data. This\nshortcoming greatly limits the application scope of this\nestimation approach to only a small portion of\ncross-matched quasars observed by all surveys.\n\nIn this paper, we propose a novel two-stage photometric redshift\nestimation approach, i.e., the integration of KNN ($k$-nearest\nneighbor) and SVM (support vector machine) approaches, to mitigate\ncatastrophic failure for quasars by using relative few band\nattributes only from a single survey. The paper is organized as\nfollows. Section 2 describes the data used. Section 3 presents a\nbrief overview of KNN, SVM and KNN+SVM. Section 4 gives the\nexperimental results by KNN+SVM. The conclusions and discussions are\nsummarized in Section 5.\n\n\\section{Data}\n\nOur experiments are based on a dataset generated from the Sloan\nDigital Sky Survey (SDSS; York et~al. 2000), which labels highly\nreliable spectroscopic redshifts and has been widely used in\nphotometric redshift estimation. The dataset was constructed by\nZhang et~al. (2013) for estimating photometric redshifts of quasars.\nThey used the samples of the Quasar Catalogue V (Schneider et~al.\n2010) in SDSS DR7, which included 105,783 spectrally confirmed\nquasars. In each quasar record, five band features\n$u,g,r,i,z$ are provided. Similar to Zhang et~al. (2013), in our experiments, we use\nthese five attributes $u-g,g-r,r-i,i-z,r$ (short for $4C+r$) as the input and the corresponding\nspectroscopic redshift as a regression output.\n\n\n\\section{Methodology}\n\nFirstly, we study the characteristics of catastrophic failure for\nquasars and observe that the outlier points by KNN are clustered\ninto two groups: one group's spectroscopic redshift z$_{\\rm spec}$ is between 0.2\nand 1.1, while its photometric redshift z$_{\\rm phot}$ is between 1.2 and 2.1, and\nthe other group's z$_{\\rm spec}$ is between 1.4 and 2.3,\nwhile its z$_{\\rm phot}$ is between 0.3 and 1.2 (shown in Figure~1). Some points\nwith z$_{\\rm phot}$ falling into Group 1 actually have z$_{\\rm spec}$ close to the\nrange of Group 2, but they are wrongly estimated by KNN and are\nmixed into Group 1, and vice versa. The two\ngroups look almost 180-degree rotationally symmetric along the 45-degree diagonal line in\nthe z$_{\\rm phot}$ vs. z$_{\\rm spec}$ diagram.\nThe two outlier clusters show that KNN method cannot\neffectively distinguish outlier points from good estimation\npoints using Euclidean distance in the two regions. Next, we propose\na two-stage integration approach by fusion of $k$-nearest neighbors\n(KNN) and support vector machine (SVM) methods. In the first stage,\nwe apply KNN algorithm on photometric data and estimate their\ncorresponding z$_{\\rm phot}$. In the second stage, we map\nphotometric multiband input pattern of points falling into the two\nranges with z$_{\\rm phot}\\in [0.3,1.2]$ and z$_{\\rm phot}\\in\n[1.2,2.1]$ from an original attribute space into a high dimensional\nfeature space by Gaussian kernel function in SVM. In the high\ndimensional feature space, many outlier points can be\nidentified by a classification hyperplane in SVM and further be\ncorrected. Since most points of catastrophic failure have been\nidentified and corrected, our integration approach can improve the\nphotometric redshift estimation accuracy.\n\n\n\\begin{figure}\n   \\centering\n   \\includegraphics[width=12cm,clip]{figure1.eps}\n   \\caption\n   { \\label{fig:example}\nPhotometric redshift estimation by KNN estimation. The points in Group 1 and Group 2 are outlier points. $\\mu$ is the parameter representing the error tolerant scope. The slant dotted lines give the corrected estimated range of photometric redshifts. The horizontal dotted lines describes the zones of Group 1 and Group 2.}\n   \\end{figure}\n\n\n\n\nThe KNN algorithm generally applies Euclidean distance of attributes\n(shown in Equation~1) to compute distance between point $m$ and\npoint $n$,\n\n", "index": 1, "text": "\\begin{equation}\nd_{m,n}=\\sqrt{(f_{m,1}-f_{n,1})^2+(f_{m,2}-f_{n,2})^2+...+(f_{m,k}-f_{n,k})^2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"d_{m,n}=\\sqrt{(f_{m,1}-f_{n,1})^{2}+(f_{m,2}-f_{n,2})^{2}+...+(f_{m,k}-f_{n,k}%&#10;)^{2}}\" display=\"block\"><mrow><msub><mi>d</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow></msub><mo>=</mo><msqrt><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>f</mi><mrow><mi>m</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>n</mi><mo>,</mo><mn>1</mn></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>f</mi><mrow><mi>m</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>n</mi><mo>,</mo><mn>2</mn></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mi mathvariant=\"normal\">\u2026</mi><mo>+</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>f</mi><mrow><mi>m</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>-</mo><msub><mi>f</mi><mrow><mi>n</mi><mo>,</mo><mi>k</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\nHere, $w$ and $b$ are weight vector and bias respectively. Figure~2\nillustrates that several lines can separate two categories of\npoints. In SVM, for minimizing the classification error risk for\nother test datasets, we aim to find a line (shown as the dash line\nin Figure~2) with the maximized margin to separate the two classes\nof points. This principle makes SVM have a better classification\naccuracy than other competing machine learning models in many\nclassification tasks.\n\n\\begin{figure}\n   \\centering\n      \\includegraphics[bb=5 0 329 233,width=12cm,clip]{figure2.eps}\n      \\caption\n   { \\label{fig:example}\nMaximizing classification margin is aimed in SVM. The points on the\ndotted lines are called as support vectors. The distance between the\ntwo dotted lines is named as Margin. When the Margin is maximized, the classification accuracy achieves best.}\n   \\end{figure}\n\n\\begin{figure}\n    \\centering\n   \\includegraphics[bb=1 2 485 197,width=12cm,clip]{figure3.eps}\n   \\caption\n   { \\label{fig:example}\nLinear indistinguishable points in a low dimensional space ($\\Re^d$) can be\nseparated in a high dimensional space ($\\Re^D$) by the application of kernel\nfunction ($\\emptyset$) in SVM. $f(x)=0$ represents the hyperplane that separates the two classes.}\n   \\end{figure}\n\nSometimes, a classification task is hard and not linearly solvable.\nThe left graph in Figure~3 shows one such case. In such case, by\nVapnik-Chervonenk in dimension theory, SVM applies a kernel function\nto promote the original flat space in the ordinary inner product\nconcepts. By the theory of reproducing kernels, we can map the\noriginal Euclidean feature space to the high-dimensional\nnon-Euclidean feature space in SVM classification algorithm.\nThereby, some of non-linearity problems in the original\nlow-dimensional feature space $\\Re^d$ become linearly solvable in\nthe high-dimensional space $\\Re^D$. The right graph in Figure~3\nshows a dimension mapping by kernel function to solve the problem.\nTherefore, Equation~2 can be transformed to the following form by\nfeature mapping function $\\emptyset$,\n\n\n", "itemtype": "equation", "pos": 14277, "prevtext": "\nwhere $f_{m,j}$($f_{n,j}$) denotes the $j$th attribute among $4C+r$\ninput pattern for the $m$th ($n$th)\npoints, $k$ represents the total number of attributes. The points in\nGroup 1 and Group 2 show that those outlier quasars cannot be\ncorrectly identified in an Euclidean space. In other words, we cannot\nhave a simple plane as a useful separating criterion between points\nin Group 1 and Group 2. Based on the present data, the provided\ninformation is not enough to give good estimation of the outlier\npoints. Now there is a question whether those outlier points can be\nlinearly separable in a high-dimensional non-Euclidean feature\nspace? Thereby, we explore the kernel function in SVM and map\nfeatures into a high dimension space and test if we can correctly\nclassify outlier points in Group 1 and Group 2. From the analysis\nabove, we propose a two-stage integration approach by fusion of\nestimation with KNN and classification with SVM.\n\n\n\\subsection{Estimation with K-Nearest-Neighbor}\n\nK-Nearest-Neighbor (KNN) algorithm is a lazy predictor which\nrequires a training set for learning. It first finds the nearest\nneighbors by comparing distances between a test sample and training\nsamples that are similar to it in a feature space. Next, it assigns\nthe average value of the nearest neighbors to the test sample as its\nprediction value. In general, the distance is computed as\nEuclidean distance described in Equation~1. In the era of big data,\nwe have been collecting more data than ever before and KNN achieves\nmuch accurate predictions (Zhang et~al. 2013). Thereby, we also use\nKNN in our research. One disadvantage of KNN is the high computation\ncost. We apply KD-tree to efficiently implement KNN algorithm.\n\n\n\\subsection{Classification with Support Vector Machine}\n\nSupport Vector Machine (SVM) is an effective classification\nalgorithm based on structural risk minimization principle proposed\nby Vapnik (1995). Given a training dataset with $n$ records,\neach record has the pattern of ($x_i,y_i$) for $i=1,2,...,n$, we\naim to build a linear classifier with the following Equation~2,\n\n", "index": 3, "text": "\\begin{equation}\nf(x)=w\\cdot x+b\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"f(x)=w\\cdot x+b\" display=\"block\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>w</mi><mo>\u22c5</mo><mi>x</mi></mrow><mo>+</mo><mi>b</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\n\nIn this way, we can have the following objective function and\nconstraints for a SVM classifier as below, and minimize \n", "itemtype": "equation", "pos": 16413, "prevtext": "\nHere, $w$ and $b$ are weight vector and bias respectively. Figure~2\nillustrates that several lines can separate two categories of\npoints. In SVM, for minimizing the classification error risk for\nother test datasets, we aim to find a line (shown as the dash line\nin Figure~2) with the maximized margin to separate the two classes\nof points. This principle makes SVM have a better classification\naccuracy than other competing machine learning models in many\nclassification tasks.\n\n\\begin{figure}\n   \\centering\n      \\includegraphics[bb=5 0 329 233,width=12cm,clip]{figure2.eps}\n      \\caption\n   { \\label{fig:example}\nMaximizing classification margin is aimed in SVM. The points on the\ndotted lines are called as support vectors. The distance between the\ntwo dotted lines is named as Margin. When the Margin is maximized, the classification accuracy achieves best.}\n   \\end{figure}\n\n\\begin{figure}\n    \\centering\n   \\includegraphics[bb=1 2 485 197,width=12cm,clip]{figure3.eps}\n   \\caption\n   { \\label{fig:example}\nLinear indistinguishable points in a low dimensional space ($\\Re^d$) can be\nseparated in a high dimensional space ($\\Re^D$) by the application of kernel\nfunction ($\\emptyset$) in SVM. $f(x)=0$ represents the hyperplane that separates the two classes.}\n   \\end{figure}\n\nSometimes, a classification task is hard and not linearly solvable.\nThe left graph in Figure~3 shows one such case. In such case, by\nVapnik-Chervonenk in dimension theory, SVM applies a kernel function\nto promote the original flat space in the ordinary inner product\nconcepts. By the theory of reproducing kernels, we can map the\noriginal Euclidean feature space to the high-dimensional\nnon-Euclidean feature space in SVM classification algorithm.\nThereby, some of non-linearity problems in the original\nlow-dimensional feature space $\\Re^d$ become linearly solvable in\nthe high-dimensional space $\\Re^D$. The right graph in Figure~3\nshows a dimension mapping by kernel function to solve the problem.\nTherefore, Equation~2 can be transformed to the following form by\nfeature mapping function $\\emptyset$,\n\n\n", "index": 5, "text": "\\begin{equation}\nf(x)=w\\cdot \\emptyset(x)+b\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"f(x)=w\\cdot\\emptyset(x)+b\" display=\"block\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mi>w</mi><mo>\u22c5</mo><mi mathvariant=\"normal\">\u2205</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>b</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\nsubject to\n\n", "itemtype": "equation", "pos": 16591, "prevtext": "\n\nIn this way, we can have the following objective function and\nconstraints for a SVM classifier as below, and minimize \n", "index": 7, "text": "$$\\mid\\mid\nw\\mid\\mid^2+C\\sum_{i=1}^{n}\\epsilon_i\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mid\\mid w\\mid\\mid^{2}+C\\sum_{i=1}^{n}\\epsilon_{i}\" display=\"block\"><mrow><msup><mrow><mo>\u2223</mo><mrow><mo>\u2223</mo><mi>w</mi><mo>\u2223</mo></mrow><mo>\u2223</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mi>C</mi><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>\u03f5</mi><mi>i</mi></msub></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\nhere, $C$ is a regularization parameter and $\\epsilon_i$ is a slack\nvariable.\n\nBy represented theorem, we have,\n\n", "itemtype": "equation", "pos": 16654, "prevtext": "\nsubject to\n\n", "index": 9, "text": "\\begin{equation}\ny_i\\cdot(<w,\\emptyset(x_i)>+b)\\ge 1-\\epsilon_i\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"y_{i}\\cdot(&lt;w,\\emptyset(x_{i})&gt;+b)\\geq 1-\\epsilon_{i}\" display=\"block\"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>\u22c5</mo><mrow><mo stretchy=\"false\">(</mo><mo>&lt;</mo><mi>w</mi><mo>,</mo><mi mathvariant=\"normal\">\u2205</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>&gt;</mo><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2265</mo><mn>1</mn><mo>-</mo><msub><mi>\u03f5</mi><mi>i</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\n\n$\\alpha_i$ is a parameter with the constraint that $\\alpha_i \\ge 0$.\nFor solving Equation~5, SVM introduces a kernel function defined\nas,\n\n", "itemtype": "equation", "pos": 16845, "prevtext": "\nhere, $C$ is a regularization parameter and $\\epsilon_i$ is a slack\nvariable.\n\nBy represented theorem, we have,\n\n", "index": 11, "text": "\\begin{equation}\nf(x)=\\sum_{i=1}^{n}\\alpha_iy_i\\emptyset(x_i)^T\\emptyset(x)+b\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"f(x)=\\sum_{i=1}^{n}\\alpha_{i}y_{i}\\emptyset(x_{i})^{T}\\emptyset(x)+b\" display=\"block\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>y</mi><mi>i</mi></msub><mo>\u2062</mo><mi mathvariant=\"normal\">\u2205</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mi mathvariant=\"normal\">\u2205</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mi>b</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\n\nIn this paper, we practically apply Gaussian kernel (shown in\nEquation~7) to achieve the non-linear classification.\n\n", "itemtype": "equation", "pos": 17077, "prevtext": "\n\n$\\alpha_i$ is a parameter with the constraint that $\\alpha_i \\ge 0$.\nFor solving Equation~5, SVM introduces a kernel function defined\nas,\n\n", "index": 13, "text": "\\begin{equation}\nK(x_i,x)=\\emptyset(x_i)^T\\emptyset(x)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"K(x_{i},x)=\\emptyset(x_{i})^{T}\\emptyset(x)\" display=\"block\"><mrow><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi mathvariant=\"normal\">\u2205</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mi mathvariant=\"normal\">\u2205</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\nwhere $x_1, x_2$ represents vectors of multiband attributes or\ninput patterns observed from a single survey, $\\sigma$ is a free\nparameter.\n\nIn this way, we aim to apply a SVM classifier to distinguish the\nmixture points in Group 1 and other points around the minor diagonal\nwith z$_{\\rm phot}\\in[1.2,2.1]$ in the z$_{\\rm phot}$ vs. z$_{\\rm\nspec}$ diagram. Similarly, we can distinguish points in Group 2 and\nother points with z$_{\\rm phot}\\in[0.3,1.2]$.\n\n\\subsection{Integration of KNN and SVM for Photometric Redshift Estimation}\n\nThe photometric redshift estimation algorithm by integration of KNN\nand SVM is presented in the following. To obtain the robust accuracy\nmeasure for our integration approach, we repeat the experiments for\n$num$ rounds. In each round, the data sets will experience the\ninitialization step, KNN step, SVM training step, SVM test step,\ncorrection step and evaluation step. In initialization step, we\nrandomly divide the SDSS data set into separate training set, validation set\nand test set. In KNN step, we apply KNN\nalgorithm ($k=17$) to estimate z$_{\\rm phot-validation}$ and z$_{\\rm\nphot-test}$ based on training set and the union of training set and\nvalidation set respectively. In SVM training step, we aim to build\ntwo SVM classifiers: SVM1 and SVM2 to distinguish good estimation and\noutlier points with z$_{\\rm phot-validation}\\in[1.2,2.1]$ and\nz$_{\\rm phot-validation}\\in[0.3,1.2]$, respectively. The good\nestimation or outlier points is defined in the following Equation~8,\n\n", "itemtype": "equation", "pos": 17264, "prevtext": "\n\nIn this paper, we practically apply Gaussian kernel (shown in\nEquation~7) to achieve the non-linear classification.\n\n", "index": 15, "text": "\\begin{equation}\nK(x_i,x)=e^{-\\frac{\\mid\\mid x_1-x_2\\mid\\mid^2}{2\\sigma^2}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"K(x_{i},x)=e^{-\\frac{\\mid\\mid x_{1}-x_{2}\\mid\\mid^{2}}{2\\sigma^{2}}}\" display=\"block\"><mrow><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msup><mi>e</mi><mrow><mo>-</mo><mfrac><msup><mrow><mo>\u2223</mo><mrow><mo>\u2223</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>-</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>\u2223</mo></mrow><mo>\u2223</mo></mrow><mn>2</mn></msup><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\nhere, $\\mu$ is the parameter which means the error tolerant scope derived from the validation set.\n\nVisually, the good estimation points will fall into area close to\n45-degree diagonal line in the diagram, while the outlier\npoints will fall into Group 1 and Group 2 in Figure~1.\n\nSpecifically, we use those outlier points with z$_{\\rm\nphot-validation}\\in[1.2,2.1]$ and z$_{\\rm phot-validation}\\in\n[0.3,1.2]$ to construct datasets: Group1\\_trainingdata and\nGroup2\\_trainingdata, respectively. In the two datasets, inputs are\npatterns $4C+r$ and z$_{\\rm phot}$ directly from KNN, and the output is z$_{\\rm spec}$.\n\nIn SVM test step, we apply classifiers SVM1 and SVM2 to identify\noutlier points.\n\nIn correction step, we use KNN algorithm based on Group1\\_data to\ncompute z$_{\\rm phot}$ for those outlier points distinguished by\nSVM1 in test data. Since Group1\\_data and those outlier points have\nthe similar pattern while the output of Group1\\_trainingdata is\nz$_{\\rm spec}$, the KNN algorithm can improve the z$_{\\rm phot}$\nestimation. Similarly, we can use Group 2 to train data and then correct\noutlier points distinguished by SVM2 in test data.\n\nIn evaluation step, we apply the percents in different |$\\Delta$z| ranges and root mean square (rms)\nerror of $\\Delta$z to test our photometric redshift estimation\napproach. The definition of $\\Delta$z is listed in\nEquation~9.\n\n", "itemtype": "equation", "pos": 18868, "prevtext": "\nwhere $x_1, x_2$ represents vectors of multiband attributes or\ninput patterns observed from a single survey, $\\sigma$ is a free\nparameter.\n\nIn this way, we aim to apply a SVM classifier to distinguish the\nmixture points in Group 1 and other points around the minor diagonal\nwith z$_{\\rm phot}\\in[1.2,2.1]$ in the z$_{\\rm phot}$ vs. z$_{\\rm\nspec}$ diagram. Similarly, we can distinguish points in Group 2 and\nother points with z$_{\\rm phot}\\in[0.3,1.2]$.\n\n\\subsection{Integration of KNN and SVM for Photometric Redshift Estimation}\n\nThe photometric redshift estimation algorithm by integration of KNN\nand SVM is presented in the following. To obtain the robust accuracy\nmeasure for our integration approach, we repeat the experiments for\n$num$ rounds. In each round, the data sets will experience the\ninitialization step, KNN step, SVM training step, SVM test step,\ncorrection step and evaluation step. In initialization step, we\nrandomly divide the SDSS data set into separate training set, validation set\nand test set. In KNN step, we apply KNN\nalgorithm ($k=17$) to estimate z$_{\\rm phot-validation}$ and z$_{\\rm\nphot-test}$ based on training set and the union of training set and\nvalidation set respectively. In SVM training step, we aim to build\ntwo SVM classifiers: SVM1 and SVM2 to distinguish good estimation and\noutlier points with z$_{\\rm phot-validation}\\in[1.2,2.1]$ and\nz$_{\\rm phot-validation}\\in[0.3,1.2]$, respectively. The good\nestimation or outlier points is defined in the following Equation~8,\n\n", "index": 17, "text": "\\begin{equation}\n\\left\\{\n\\begin{array}{rcl}\n\\mid z_{\\rm spec}-z_{\\rm phot}\\mid &\\le&\\mu\\,\\,\\,\\,\\, {\\rm good}\\\\\n\\mid z_{\\rm spec}-z_{\\rm phot}\\mid &>&\\mu\\,\\,\\,\\,\\, {\\rm bad}\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\left\\{\\begin{array}[]{rcl}\\mid z_{\\rm spec}-z_{\\rm phot}\\mid&amp;\\leq&amp;\\mu\\,\\,\\,\\,%&#10;\\,{\\rm good}\\\\&#10;\\mid z_{\\rm spec}-z_{\\rm phot}\\mid&amp;&gt;&amp;\\mu\\,\\,\\,\\,\\,{\\rm bad}\\end{array}\\right.\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mo>\u2223</mo><mrow><msub><mi>z</mi><mi>spec</mi></msub><mo>-</mo><msub><mi>z</mi><mi>phot</mi></msub></mrow><mo>\u2223</mo></mrow></mtd><mtd columnalign=\"center\"><mo>\u2264</mo></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+8.5pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mi>good</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mo>\u2223</mo><mrow><msub><mi>z</mi><mi>spec</mi></msub><mo>-</mo><msub><mi>z</mi><mi>phot</mi></msub></mrow><mo>\u2223</mo></mrow></mtd><mtd columnalign=\"center\"><mo>&gt;</mo></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+8.5pt\"><mi>\u03bc</mi></mpadded><mo>\u2062</mo><mi>bad</mi></mrow></mtd></mtr></mtable><mi/></mrow></math>", "type": "latex"}, {"file": "1601.01739.tex", "nexttext": "\n\nThe detailed steps of the two-stage method are as following. To be\nmuch clearer, the flow chart of the whole process is shown in\nFigure~4.\n\nLoopId$=1$;\n\nDo while LoopId$\\le num$;\n\nInitialization Step:\n\n\\quad Randomly select 1/3 sample from the SDSS quasar sample as the training set,\nanother 1/3 sample as the validation set, and the remaining 1/3\nsample as the test set.\n\nKNN Step:\n\n\\quad 1. Based on training set, we apply KNN ($k=17$) algorithm to\nestimate z$_{\\rm phot-validation}$ for each sample in validation\nset;\n\n\\quad 2. Based on the union of training set and validation set, we\napply KNN ($k=17$) algorithm to estimate z$_{\\rm phot-test}$ for each sample\nin test set.\n\nSVM Training Step:\n\n\\quad 1. For those samples with z$_{\\rm phot-validation}\\in\n[1.2,2.1]$ in validation set, we train a classifier SVM1 with\nGaussian kernel, which distinguishes good estimation and outlier\npoints by Equation~8. With those outlier points, we build a data set\nGroup1\\_trainingdata, which is composed of $4C+r$ and z$_{\\rm phot}$ as the input and\nz$_{\\rm spec}$ as the output;\n\n\\quad 2. Similarly, for those samples with z$_{\\rm\nphot-validation}\\in [0.3,1.2]$ in validation set, we train a classifier SVM2 with Gaussian kernel, which distinguishes good estimation and outlier points. With those outlier points, we build a\ndata set Group2\\_trainingdata, which is composed of $4C+r$ and z$_{\\rm phot}$ as the\ninput and z$_{\\rm spec}$ as the output.\n\nSVM Test Step:\n\n\\quad 1. For those samples with z$_{\\rm phot-test}\\in [1.2,2.1]$ in\ntest set, we apply the classifier SVM1 to distinguish good\nestimation and outlier points;\n\n\\quad 2. Similarly, for those samples with z$_{\\rm phot-test}\\in\n[0.3,1.2]$ in test set, we apply the classifier SVM2 to\ndistinguish good estimation and outlier points.\n\nCorrection Step:\n\n\\quad 1. For those outlier points with z$_{\\rm phot-test}\\in\n[1.2,2.1]$ in test set, we apply the KNN algorithm based on the data\nset Group1\\_trainingdata;\n\n\\quad 2. For those outlier points with z$_{\\rm phot-test}\\in\n[0.3,1.2]$ in test set, we apply the KNN algorithm based on the data\nset Group2\\_trainingdata.\n\nEvaluation Step:\n\n\\quad By comparing z$_{\\rm phot-test}$ and z$_{\\rm spec}$ for all\nsamples in test set, we compute the popular accuracy measures for\nredshift estimation and rms error of $\\Delta$z.\n\nLoopId=LoopId+1;\n\nEnd do.\n\nOutput the mean and standard error for the percents in different |$\\Delta$z| ranges and rms error of $\\Delta$z to evaluate the accuracy of our proposed integrated approach KNN+SVM.\n\n\n\\begin{figure}[!!!h]\n   \\centering\n   \\includegraphics[width=16cm,clip]{figure4.eps}\n   \\caption\n   { \\label{fig:example}\nThe flow chart of photometric redshift estimation by the integration\nof KNN and SVM.}\n   \\end{figure}\n\n\\section{Experimental results}\n\nIn the experiments, we adopt the input pattern $4C+r$ as attributes,\nwhich are widely accepted by recent researches on photometric\nredshift estimation. In our designed algorithm, we practically set\n$num=10$ and repeat the experiments for 10 times.\n\nFor classification, we apply the widely used tool LIBSVM (Chang,\n2011). By using Gaussian kernel function, we train classifiers\nSVM1 and SVM2 for the sample with z$_{\\rm phot-validation}\\in\n[1.2,2.1]$ and for the sample with z$_{\\rm phot-validation}\\in\n[0.3,1.2]$ in the validation set, separately. To optimize the estimation\naccuracy, we adjust two parameters controlling the\nGaussian kernel in SVM, a cost coefficient $C$ that measures the\ndata unbalance and a factor $\\gamma$ depicting the shape of the high\ndimensional feature space. Other parameters are set to the default\nvalues in LIBSVM. In order to obtain the best model parameters, the\ngrid search is adopted. The grid search in SVM1 and SVM2 is\nindicated in Figure~5. For SVM1, the optimal model parameter $C$ is\n2, $\\gamma$ is 8, meanwhile, the classification accuracy is 94.12\\%.\nFor SVM2, the best model parameter $C$ is 128, $\\gamma$ is 0.5, the\nclassification accuracy amounts to 90.04\\%.\n\n\n\\begin{figure}\n   \\centering\n   \\includegraphics[width=16cm,clip]{figure5a.eps}\n   \\includegraphics[width=16cm,clip]{figure5b.eps}\n   \\caption\n   { \\label{fig:example}\nTop: the best model parameter in SVM1 is obtained by grid search,\ni.e. $C$=2, $\\gamma$=8, the accuracy of classification achieves\n94.12\\%. Bottom: the best model parameter in SVM2 is obtained by grid\nsearch, i.e. $C$=128, $\\gamma$=0.5, the accuracy of classification\nis 90.04\\%.}\n   \\end{figure}\n\nWith the optimized parameters and the union of the training set and\nthe validation set as a new training set, we compare the estimation\naccuracy between original KNN ($k=17$) algorithm and our integration\napproach KNN+SVM. The parameter $\\mu$ is a factor to\ndetermine whether a point has good estimation or not. We change the\nvalue of $\\mu$ to check its influence on the estimation accuracy.\nThe results are listed in Table 1. For KNN, the proportions of\n|$\\Delta$z|$<0.1,0.2,0.3$ and rms error of predicted photometric\nredshifts are 71.96\\%, 83.78\\%, 89.73\\% and 0.204, separately; for\nKNN+SVM, these optimal measures are 83.47\\%, 89.83\\%, 90.90\\% and\n0.192, respectively, when $\\mu$=0.3, which are bold in Table~1.\nObviously, these criteria for photometric redshift estimation are\nall significantly improved with the new method. It suggests that the\nintegration approach can effectively correct those outlier points\nwith z$_{\\rm phot}\\in[1.2,2.1]$ and z$_{\\rm phot}\\in[0.3,1.2]$.\nThereby, it can significantly mitigate catastrophic failure and\nimprove the estimation accuracy of photometric redshifts.\n\n\\begin{table*}\n\\begin{center}\n\\caption{Comparison of KNN and our integration approach}\n\\bigskip\n\\begin{tabular}{lcccl}\n\\hline\\hline\nMethod&|$\\Delta$z|$<0.1(\\%)$&|$\\Delta$z|$<0.2(\\%)$&|$\\Delta$z|$<0.3(\\%)$& rms error\\\\\n\\hline\nKNN($k=17$)         & 71.96$\\pm$0.20 & 83.78$\\pm$0.18 &89.73$\\pm$0.16 &0.204$\\pm$0.004\\\\\nSVM+KNN($\\mu=$0.1)& 75.06$\\pm$3.03 & 81.43$\\pm$2.31 &85.51$\\pm$1.69 &0.232$\\pm$0.022\\\\\nSVM+KNN($\\mu=$0.2)& 80.86$\\pm$1.19 & 85.56$\\pm$1.95 &86.57$\\pm$1.81 &0.224$\\pm$0.013\\\\\n\\bf SVM+KNN($\\mu=$0.3)&\\bf 83.47$\\pm$0.86 &\\bf 89.83$\\pm$0.51 &\\bf 90.90$\\pm$0.42 &\\bf 0.192$\\pm$0.007\\\\\nSVM+KNN($\\mu=$0.4)& 81.63$\\pm$0.64 & 89.53$\\pm$0.32 &91.54$\\pm$0.33 &0.193$\\pm$0.005\\\\\nSVM+KNN($\\mu=$0.5)& 78.89$\\pm$0.22 & 88.30$\\pm$0.24 &91.63$\\pm$0.21 &0.194$\\pm$0.005\\\\\nSVM+KNN($\\mu=$0.6)& 75.84$\\pm$0.14 & 86.60$\\pm$0.13 &90.58$\\pm$0.11 &0.199$\\pm$0.003\\\\\n\\hline \\hline\n\\end{tabular}\n\\bigskip\n\\end{center}\n\\end{table*}\n\nThe experimental results also show that without cross-matching\nmultiband observations from multiple surveys, we can effectively\napply Gaussian kernel function in SVM to identify outlier points in\nGroup 1 and Group 2 from catastrophic failure by mapping attributes\nfrom a single data source into a high dimensional feature space. The\nidentification helps us correct those outlier points and thereby\nimprove estimation accuracy.\n\nIn order to compare the performance of photometric redshift\nestimation by KNN algorithm with that by KNN and SVM approach, the\nphotometric redshift estimation with these two methods is shown in\nFigure~6 and Figure~7, respectively. As indicated by Figures 6-7, we\ncan see clearly that the outlier points in both Group 1 and Group 2\nhave been significantly decreased by adopting the new method\nKNN+SVM. It intuitively proves that our proposed approach is\neffective.\n\n\\begin{figure}\n   \\centering\n\\includegraphics[width=10cm,height=10cm,clip]{figure6.eps}\n\\caption[fig4] {Photometric redshift estimation by KNN.}\n\\end{figure}\n\n\\begin{figure}\n   \\centering\n\\includegraphics[width=10cm,height=10cm,clip]{figure7.eps}\n\\caption[fig4] {Photometric redshift estimation by KNN+SVM.}\n\\end{figure}\n\n\\section{Conclusions and Discussions}\n\nCatastrophic failure is an unsolved problem with a long history\nexisting in most photometric redshift estimation approaches. In this\npaper, we firstly analyze the reasons of catastrophic failure for\nquasars and point out that the outlier points result from being\nnon-linearly separable in Euclidean feature space of input pattern.\nNext, we propose a new estimation approach by integration of KNN and\nSVM methods together. By Gaussian kernel function in SVM, we map\nmultiband input pattern from an original Euclidean space into a high\ndimensional feature space. In this way, many outlier points can be\nidentified by a hyperplane and then corrected. The experimental\nresults based on SDSS data for quasars show that the integration\napproach can significantly mitigate catastrophic failure and improve\nthe photometric redshift estimation accuracy, e.g. the\npercentages in different |$\\Delta$z| ranges and rms error are $83.47\\%$, $89.83\\%$, $90.90\\%$ and 0.192, respectively. While different previous researches of mitigating catastrophic failure by\ncross-match of data from several surveys, our approach can achieve\nthe similar objective only from a single survey and needn't cross-match among multiple surveys avoiding cross-match efforts especially for the growing of large survey data. Moreover, not all sources have observation from different surveys. Therefore this method can be widely applied for a single large sky survey photometric data. In addition, the integration method with data from more bands may\nfurther improve the accuracy of estimating photometric redshifts of\nquasars.\n\n\\begin{acknowledgements}\nWe are very grateful to the referee's important comments and\nsuggestions which help us improve our paper. This work is supported\nby the National Natural Science Foundation of China under Grants\nNO.61272272 and NO.U1531122, National Key Basic Research Program of China\n2014CB845700 and NSFC-Texas A\\&M University Joint Research Program\nNo.11411120219. We acknowledgment SDSS database. The SDSS is managed\nby the Astrophysical Research Consortium for the Participating\nInstitutions. The Participating Institutions are the American Museum\nof Natural History, Astrophysical Institute Potsdam, University of\nBasel, University of Cambridge, Case Western Reserve University,\nUniversity of Chicago, Drexel University, Fermilab, the Institute\nfor Advanced Study, the Japan Participation Group, Johns Hopkins\nUniversity, the Joint Institute for Nuclear Astrophysics, the Kavli\nInstitute for Particle Astrophysics and Cosmology, the Korean\nScientist Group, the Chinese Academy of Sciences (LAMOST), Los\nAlamos National Laboratory, the Max-Planck-Institute for Astronomy\n(MPIA), the Max-Planck-Institute for Astrophysics (MPA), New Mexico\nState University, Ohio State University, University of Pittsburgh,\nUniversity of Portsmouth, Princeton University, the United States\nNaval Observatory, and the University of Washington.\n\\end{acknowledgements}\n\n\\begin{thebibliography}{}\n\n\\bibitem[Abdalla et al.(2008)]{2008MNRAS.387..969A} Abdalla, F.~B., Amara,\nA., Capak, P., et al.\\ 2008, \\mnras, 387, 969\n\n\\bibitem[Ball et al.(2008)]{2008ApJ...683...12B} Ball, N.~M., Brunner,\nR.~J., Myers, A.~D., et al.\\ 2008, \\apj, 683, 12\n\n\\bibitem[Brescia et al.(2013)]{2013ApJ...772..140B} Brescia, M., Cavuoti,\nS., D'Abrusco, R., Longo, G., \\& Mercurio, A.\\ 2013, \\apj, 772, 140\n\n\\bibitem[Bolzonella et\nal.(2000)]{2000A&A...363..476B} Bolzonella, M., Miralles, J.-M., \\&\nPell{\\'o}, R.\\ 2000, \\aap, 363, 476\n\n\\bibitem[Bovy et al.(2012)]{2012ApJ...749...41B} Bovy, J., Myers, A.~D.,\nHennawi, J.~F., et al.\\ 2012, \\apj, 749, 41\n\n\\bibitem[Carrasco Kind\n\\& Brunner(2013)]{2013MNRAS.432.1483C} Carrasco Kind, M., \\&\nBrunner, R.~J.\\ 2013, \\mnras, 432, 1483\n\n\\bibitem[Chang et al.(2011)]{}\nChang, C.-C., Lin, C.-J.\\ 2011, ACM Transactions on Intelligent Systems and Technology, 2, 1\n\n\\bibitem[Freeman et al.(2009)]{2009MNRAS.398.2012F} Freeman, P.~E., Newman,\nJ.~A., Lee, A.~B., Richards, J.~W., \\& Schafer, C.~M.\\ 2009, \\mnras,\n398, 2012\n\n\\bibitem[Gerdes et al.(2010)]{2010ApJ...715..823G} Gerdes, D.~W.,\nSypniewski, A.~J., McKay, T.~A., et al.\\ 2010, \\apj, 715, 823\n\n\\bibitem[Ilbert et al.(2009)]{2009ApJ...690.1236I} Ilbert, O., Capak, P.,\nSalvato, M., et al.\\ 2009, \\apj, 690, 1236\n\n\\bibitem[Rowan-Robinson et al.(2008)]{2008MNRAS.386..697R} Rowan-Robinson,\nM., Babbedge, T., Oliver, S., et al.\\ 2008, \\mnras, 386, 697\n\n\\bibitem[Richards et al.(2001)]{2001AJ....122.1151R} Richards, G.~T.,\nWeinstein, M.~A., Schneider, D.~P., et al.\\ 2001, \\aj, 122, 1151\n\n\\bibitem[Schneider et al.(2010)]{2010AJ....139.2360S} Schneider, D.~P., Richards, G.~T., Hall, P.~B., et~al.\\ 2010, \\aj, 139, 2360\n\n\\bibitem[Vapnik (1995)]{}\nVapnik, V. The Nature of Statistical Learning Theory. Springer Verlag, New York, 1995\n\n\\bibitem[Way\n\\& Klose(2012)]{2012PASP..124..274W} Way, M.~J., \\& Klose, C.~D.\\\n2012, \\pasp, 124, 274\n\n\\bibitem[Weinstein et al.(2004)]{2004ApJS..155..243W} Weinstein, M.~A.,\nRichards, G.~T., Schneider, D.~P., et al.\\ 2004, \\apjs, 155, 243\n\n\\bibitem[Wu et al.(2004)]{2004ChJAA...4...17W} Wu, X.-B., Zhang, W.,\n\\& Zhou, X.\\ 2004, \\cjaa, 4, 17\n\n\\bibitem[York et al.(2000)]{2000AJ....120.1579Y} York, D.~G., Adelman, J.,\nAnderson, J.~E., Jr., et al.\\ 2000, \\aj, 120, 1579\n\n\\bibitem[Zhang et al.(2013)]{2013AJ....146...22Z} Zhang, Y., Ma, H., Peng,\nN., Zhao, Y., \\& Wu, X.-b.\\ 2013, \\aj, 146, 22\n\n\n\\end{thebibliography}\n\n\n\n", "itemtype": "equation", "pos": 20451, "prevtext": "\nhere, $\\mu$ is the parameter which means the error tolerant scope derived from the validation set.\n\nVisually, the good estimation points will fall into area close to\n45-degree diagonal line in the diagram, while the outlier\npoints will fall into Group 1 and Group 2 in Figure~1.\n\nSpecifically, we use those outlier points with z$_{\\rm\nphot-validation}\\in[1.2,2.1]$ and z$_{\\rm phot-validation}\\in\n[0.3,1.2]$ to construct datasets: Group1\\_trainingdata and\nGroup2\\_trainingdata, respectively. In the two datasets, inputs are\npatterns $4C+r$ and z$_{\\rm phot}$ directly from KNN, and the output is z$_{\\rm spec}$.\n\nIn SVM test step, we apply classifiers SVM1 and SVM2 to identify\noutlier points.\n\nIn correction step, we use KNN algorithm based on Group1\\_data to\ncompute z$_{\\rm phot}$ for those outlier points distinguished by\nSVM1 in test data. Since Group1\\_data and those outlier points have\nthe similar pattern while the output of Group1\\_trainingdata is\nz$_{\\rm spec}$, the KNN algorithm can improve the z$_{\\rm phot}$\nestimation. Similarly, we can use Group 2 to train data and then correct\noutlier points distinguished by SVM2 in test data.\n\nIn evaluation step, we apply the percents in different |$\\Delta$z| ranges and root mean square (rms)\nerror of $\\Delta$z to test our photometric redshift estimation\napproach. The definition of $\\Delta$z is listed in\nEquation~9.\n\n", "index": 19, "text": "\\begin{equation}\n\\Delta z=\\frac{z_{\\rm spec}-z_{\\rm phot}}{1+z_{\\rm spec}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\Delta z=\\frac{z_{\\rm spec}-z_{\\rm phot}}{1+z_{\\rm spec}}\" display=\"block\"><mrow><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>z</mi></mrow><mo>=</mo><mfrac><mrow><msub><mi>z</mi><mi>spec</mi></msub><mo>-</mo><msub><mi>z</mi><mi>phot</mi></msub></mrow><mrow><mn>1</mn><mo>+</mo><msub><mi>z</mi><mi>spec</mi></msub></mrow></mfrac></mrow></math>", "type": "latex"}]