[{"file": "1601.06755.tex", "nexttext": "\n\nFigure \\ref{fig:mu2d} shows how this appropriateness measure works in a setup similar to that in figure \\ref{fig:pnth}. \n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{mu2d.pdf}\n\\caption{Membership in a concept. The prototype of the label is at $[0.5, 0.5]$ and the threshold ${\\varepsilon}$ has distribution $U[0,0.3]$. When $x = [0.5,0.5]$, $\\mu_L(x) = 1$. As we move further away from the prototype, membership in the concept decreases, and is $0$ when $d(x, P_i) > 0.3$}\n\\label{fig:mu2d}\n\\end{figure}\n\nThis appropriateness measure is similar to Zadeh's description of fuzzy membership in a concept \\cite{zadeh1965}.\n\n\\subsection{Linguistic hedges}\nHedges are words or phrases such as `very', `quite', `strictly speaking' which modify the domain of application of a concept. In particular, `very', and `quite' respectively contract or expand the domain of application of a concept,  so that, for example, `very tall' applies to fewer people than does `tall', whereas `quite tall' applies to more. Within fuzzy set theory, we expect that $\\mu_{\\text{very } L} (x) \\leq \\mu_L (x)$ and $\\mu_{\\text{quite } L} (x) \\geq \\mu_L (x)$. Applying this to the concept `tall', again,  this means that membership in the concept `very tall' should always be less than membership in `tall'. So anyone who can be described as `very tall' can also be described as `tall'.  Zadeh \\cite{zadehhedges} uses operations of \\emph{concentration} and \\emph{dilation} to render these ideas. Concentration is described as $CON(\\mu_{L_i}(x)) = (\\mu_{L_i}(x))^2$ and dilation is often rendered as $DIL(\\mu_{L_i}(x)) = (\\mu_{L_i}(x))^{1/2}$. However, we argue, as do \\cite{bosc}, that Zadeh's formulae are, to an extent, arbitrary, since the notion of taking a power of a membership value does not correspond to anything that language users might do. Rather, it simply has some of the right effects. As with \\cite{bosc}, we take a semantic approach.\n\nIn \\cite{lewis2014}, we propose that a concept `very $L$' or `quite $L$' be rendered by considering that the prototype of `very/quite $L$' is equal to that of the base concept $L$, but that the threshold of the hedged concept `very/quite $L$' is respectively smaller or larger than that of the base concept. This approach is grounded in the idea that `very/quite $L$' should apply to respectively fewer or more objects than $L$. Narrowing or widening the threshold achieves this in a natural way. This is illustrated in figure \\ref{fig:vq}. \n\n\\begin{figure}\n\t \\centering\n\t\t  \\caption{Representation of `very $L_i$' and `quite $L_i$'. `Very $L_i$' has prototype $P_i$ and threshold $v{\\varepsilon}_i \\leq {\\varepsilon}_i$. `Quite $L_i$' has prototype $P_i$ and threshold $q{\\varepsilon}_i \\geq {\\varepsilon}_i$. Notice that although $L_i$ is appropriate to describe $a$, $vL_i$ is not. Also, although $L_i$ is not appropriate to describe $b$, $qL_i$ is.}\n\t\\label{fig:vq}\n\\end{figure}\n\nOur model of the hedges `very' and `quite' therefore requires simply that $v{\\varepsilon}_i \\leq {\\varepsilon}_i$ and that $q{\\varepsilon}_i \\geq {\\varepsilon}_i$. We implement this model in a version of the multi-agent simulation created in \\cite{ettie} in order to investigate how the use of these hedges in a model of language helps the emergence of shared categories across a community of language users.\n\n\\section{METHODS}\n\\label{sec:method}\n\\subsection{Overview}\nTo investigate the utility of hedged assertions we implement a multi-agent simulation of a version of the category game \\cite{belp}, following \\cite{ettie}, in which shared categories develop over time as a result of the interactions of the category users. An overview of the game is as follows. Agents use labels to describe a conceptual space $\\Omega$. At each timestep, agents are randomly paired into speakers and listeners, and each pair is shown a distinct element $x \\in \\Omega$. The speaker makes an assertion $\\theta$ about the element based on its label set. The listener then updates its own label set to be more similar to that of the speaker, based on this assertion and a parameter $w$ which can be thought of as the age of the speaker. The update made by the speaker is a combination of shifting the prototype of the relevant label and changing the size of the threshold. The aim is that after a number of timesteps, label sets across the population have converged to a common set of shared categories.\n\n\\subsection{Conceptual models}\nEach agent is equipped with the same number $n$ of labels $L_i$, with point prototypes $P_i \\in \\Omega$, where $\\Omega  = [0,1]^3$. At the start of the simulations the $P_i$ are uniformly distributed around the space. Thresholds ${\\varepsilon}_i$ are also randomly initiated, and considered to be some multiple of a base threshold ${\\varepsilon}$. Each threshold ${\\varepsilon}_i \\sim U(0, b_i)$, where again, the $b_i$ can be considered to be a multiple of some common $b$, and the $b_i$ are taken from $U[0.5, 2]$. The distance metric is Euclidean. \n\nEach agent therefore has a label set $LA= \\{L_1, L_2, ... L_n\\}$. These labels can be hedged to form a set $LA^+ = LA \\cup \\{ \\text{very }L_i, \\text{quite }L_i : i = 1,..., n\\}$. Hedged concepts have the same prototype $P_i$ as basic labels, but a scaled threshold $v{\\varepsilon}_i$ or $q{\\varepsilon}_i$ where  $v < 1$ and $q >1$. Agents can assert positive or negated, hedged or basic labels, giving an assertion set $AS = \\{kL_i, \\neg kL_i : i = 1, ..., n; k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$, where $k = \\text{basic}$ means that the label is not hedged.\n\n\\subsection{Assertion model}\nAt each timestep, half the agents are designated speaker agents and make assertions, determined by the assertion model used.The assertion model is based on the probability of making a particular assertion $\\theta$, given that the object being described is $x$. Following methods in \\cite{ettie, lawry2009}, we calculate the posterior probability of each $\\theta \\in AS$, given an element $x \\in \\Omega$. The assertion made by a speaker agent is the assertion with the highest probability. The posterior probability of each $\\theta$, given $x$, is determined by the appropriateness of the assertion $\\theta$ to describe $x$, i.e. $\\mu_\\theta(x)$, and the prior probability $P(\\theta)$ of asserting $\\theta$.\n\nWe first consider which sets of labels that are appropriate to describe $x \\in \\Omega$. The probability that any particular set of labels $F\\subseteq LA$ are appropriate to describe $x$ is given by a probability mass function $m_x: 2^{LA} \\rightarrow [0, 1]$. One way of determining $m_x$ is via the \\emph{consonant selection function} introduced in \\cite{lawry2009}. This states:\n\n\\begin{dfn}[Consonant selection function]\nGiven non-zero appropriateness measures on basic labels $\\mu_{L_i}(x): i = 1,..., n$ ordered such that $\\mu_{L_i}(x) \\geq \\mu_{L_{i+1}}$ for $i = 1, ..., n$, the consonant selection function identifies the mass function \n\n", "itemtype": "equation", "pos": 8135, "prevtext": "\n\\newtheorem{dfn}{Definition}\n\\newtheorem{lem}[dfn]{Lemma}\n\\newtheorem{prop}[dfn]{Proposition}\n\\newtheorem{thm}[dfn]{Theorem}\n\\newtheorem{cor}[dfn]{Corollary}\n\\newtheorem{fact}[dfn]{Fact}\n\\newtheorem {exa}[dfn]{Example}\n\n\n\\title{The Utility of Hedged Assertions in the Emergence of Shared Categorical Labels}\n\n\\author{Martha Lewis \\and Jonathan Lawry \\institute{University of Bristol, England, email: martha.lewis@bristol.ac.uk, j.lawry@bristol.ac.uk} }\n\n\\maketitle\n\\bibliographystyle{AISB}\n\n\\begin{abstract}\nWe investigate the emergence of shared concepts in a community of language users using a multi-agent simulation. We extend results showing that negated assertions are of use in developing shared categories, to include assertions modified by linguistic hedges. Results show that using hedged assertions positively affects the emergence of shared categories in two distinct ways. Firstly, using contraction hedges like `very' gives better convergence over time. Secondly, using expansion hedges such as `quite' reduces concept overlap. However, both these improvements come at a cost of slower speed of development.\n\\end{abstract}\n\n\\section{INTRODUCTION}\nAn evolutionary approach to semantics enables the development in robots and autonomous agents of flexible, mutable concepts that could be learnt through interaction and can change over time \\cite{steels}. This approach is investigated by Eyre and Lawry in \\cite{ettie}, in which they develop a model of language evolution based in the label semantics framework. They show that using a mixture of positive and negated assertions enables the development of languages that are both shared, and discriminate effectively between elements within the environment. We extend this work to include assertions modified by the words `very' and `quite', and show that doing so improves performance in two ways. Use of the hedge `very' improves levels of convergence attained. Using the hedge `quite' reduces the amount of overlap within an agent's label set. We describe in detail the theoretical approach to concepts taken and linguistic hedges in the remainder of this section. Section \\ref{sec:method} gives details of the mathematical and computational model used in the simulations. Section \\ref{sec:results} gives results of the simulations which are discussed in section \\ref{sec:discussion}. Lastly, section \\ref{sec:conc} gives conclusions and further avenues of research.\n\n\\subsection{A representation model for concepts}\nWe model concepts within the label semantics framework \\cite{lawry2004, lawry2009}, combined with prototype theory \\cite{rosch} and the conceptual spaces model of concepts \\cite{gard2004}. Prototype theory offers an alternative to the classical theory of concepts, basing categorization on proximity to a prototype. This approach is based on experimental results where human subjects were found to view membership in a concept as a matter of degree, with some objects having higher membership than others \\cite{rosch}. Fuzzy set theory \\cite{zadeh1965}, in which an object $x$ has a graded membership $\\mu_L(x)$ in a concept $L$, was proposed as a formalism for prototype theory. However, numerous objections to its suitability have been made \\cite{osh1981, smith, kp, hamp, hamp1987}. \n\nConceptual spaces theory renders concepts as convex regions of a \\emph{conceptual space} - a geometrical structure with quality dimensions and a distance metric. Examples are: the RGB colour cube, pictured in figure \\ref{fig:rgbcube}; physical dimensions of height, breadth and depth; or the taste tetrahedron. Since concepts are convex regions of such spaces, the centroid of such a region can naturally be viewed as the prototype of the concept.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.3\\textwidth]{rgbcube.png}\n\\caption{The RGB cube represents colours in three dimensions of Red, Green and Blue. A colour concept such as `purple' can be represented as a region of this conceptual space.}\n\\label{fig:rgbcube}\n\\end{figure}\n\nLabel semantics \\cite{lawry2004} is a random set approach to concepts which quantifies an agent's uncertainty about the extent of application of a concept. We refer to this as \\emph{subjective uncertainty} \\cite{lawry2009} to emphasise that it concerns the definition of concepts and categories, in contrast to stochastic uncertainty which concerns the state of the world. Lawry and Tang \\cite{lawry2009} combine the label semantics approach with conceptual spaces and prototype theory, to give a formalisation of concepts as based on a prototype and a threshold, located in a conceptual space. \n\nWithin this framework, agents use sets of labels $LA = \\{L_1, L_2, ..., L_n\\}$ to describe an underlying conceptual space $\\Omega$ with distance metric $d(x, y)$ between points. The conceptual space could be, as mentioned, the RGB colour space. Labels $L_i$ would then be concepts such as `red', `blue', `purple', `orange' and so on. These labels are viewed as regions of the conceptual space. So the concept `blue' is represented by the blue region in the colour cube. Within label semantics, these regions are specified by prototypes $P_i$ and thresholds ${\\varepsilon}_i$. This is in contrast to G\\\"{a}rdenfors' original approach which is to view the space as partitioned by a Voronoi tessellation. If this latter approach is taken, each individual point in the conceptual space is allocated to exactly one label. With a prototype-threshold approach, it is easy to accommodate the idea of an object being accurately described by more than one concept, or conversely, some points within the space not being assigned to any concept. This difference is illustrated in figures \\ref{fig:vplot} and \\ref{fig:cplot}.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.3\\textwidth]{vplot.pdf}\n\\caption{Conceptual space divided into concepts according to a Voronoi tessellation around prototypes. Each part of the space corresponds to exactly one concept.}\n\\label{fig:vplot}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.3\\textwidth]{cplot.pdf}\n\\caption{Conceptual space divided into concepts according to a prototype-threshold approach. Some points in the space correspond to more than one concept, and some correspond to none.}\n\\label{fig:cplot}\n\\end{figure}\n\n In this model, however, agents are uncertain as to exactly where the thresholds lie. To illustrate this, consider the concept `tall'. It is easy to point out a tall person, and to point out a person who is not tall, but it is difficult to specify the exact threshold between `tall' and `not tall'. This uncertainty concerning where the threshold lies is represented in the label semantics framework by saying that a threshold ${\\varepsilon}_i$ is drawn from a probability distribution $\\delta_i$. Labels $L_i$ are associated with neighbourhoods $\\mathcal{N}^{{\\varepsilon}_i}_{L_i} = \\{\\vec{x} \\in \\Omega : d(\\vec{x}, P_i) \\leq {\\varepsilon}_i\\}$, i.e. the region within the threshold. These ideas are represented in figure \\ref{fig:pnth}.\n\n\\begin{figure}\n\t \\centering\n\t\n\t  \\caption{Prototype-threshold representation of a concept $L_i$. The conceptual space has dimensions $x_1$ and $x_2$. The concept has prototype $P_i$ and threshold ${\\varepsilon}_i$. The uncertainty about the threshold is represented by the dotted line. The neighbourhood $\\mathcal{N}^{{\\varepsilon}_i}_{L_i}$ is the area within the dotted line. Element $a$ in the conceptual space is within the threshold, so it is appropriate to assert `$a$ is $L_i$'. Element $b$ is outside the threshold, so it is not appropriate to assert `$b$ is $L_i$'}\n\t\\label{fig:pnth}\n\\end{figure}\n\nThe threshold ${\\varepsilon}_i$ is uncertain, however, so there is some probability that ${\\varepsilon}_i$ in figure \\ref{fig:pnth} is actually wide enough to include the object $b$, i.e. that $L_i$ is appropriate to describe $b$. The appropriateness $\\mu_{L_i}(x)$ of a label $L_i$ to describe an element $x$ is then given by the probability that $x$ lies within the neighbourhood $\\mathcal{N}^{{\\varepsilon}_i}_{L_i}$, i.e. that the distance $d(x, P_i)$ is less than ${\\varepsilon}_i$. So:\n\n", "index": 1, "text": "\n\\[\n\\mu_{L_i}(x) = P(d(x, P_i) \\leq {\\varepsilon}_i) = \\int_{d(x, P_i)}^\\infty \\delta_i({\\varepsilon}_i)\\mathrm{d}{\\varepsilon}_i\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mu_{L_{i}}(x)=P(d(x,P_{i})\\leq{\\varepsilon}_{i})=\\int_{d(x,P_{i})}^{\\infty}%&#10;\\delta_{i}({\\varepsilon}_{i})\\mathrm{d}{\\varepsilon}_{i}\" display=\"block\"><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><msub><mi>P</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><msub><mi>\u03b5</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><msub><mi>P</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mi mathvariant=\"normal\">\u221e</mi></msubsup><msub><mi>\u03b4</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03b5</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">d</mi><msub><mi>\u03b5</mi><mi>i</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\\end{dfn}\n\nBecause we have ordered the labels by $\\mu_{L_i}(x) \\geq \\mu_{L_{i+1}}$, if the label $L_i$ is appropriate to describe $x$, all labels $L_j : j < i$ must also be appropriate to describe $x$. The quantity $\\mu_{L_i}(x) - \\mu_{L_{i+1}}(x)$ corresponds to the idea that $x$ in some sense lies between the thresholds ${\\varepsilon}_{i+1}$ and ${\\varepsilon}_i$, so that $L_i$ is appropriate to describe $x$, but $L_{i+1}$ is not.  We extend this definition to the case of hedged labels simply by considering all hedged labels as basic labels, explained in the example below.\n\n\\begin{exa}[Determining the mass function]\n\\label{exa:mf}\nSuppose we are determining the mass function for subsets $F \\subseteq \\{kL_1, kL_2: k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$, given the point $a \\in x_1 \\times x_2$, as illustrated in figure \\ref{fig:mf}.\n\\begin{figure}\n\t \\centering\n\t \t  \\caption{Determining the mass function on subsets of $\\{kL_1, kL_2: k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$. $P_1$ and $P_2$ represent prototypes for each lable $L_1$ and $L_2$, and the dotted lines give the different thresholds according to the hedges, as in figure \\ref{fig:vq}. Notice that `quite $L_2$', $L_2$, `very $L_2$' and `quite $L_1$' are all appropriate to describe $a$, although with different appropriateness measures (not shown), but $L_1$ and `very $L_1$' are not.}\n\t\\label{fig:mf}\n\\end{figure}\n\nSuppose that $\\mu_{\\text{quite }L_2}(a) = 0.9$, $\\mu_{L_2}(a) = 0.7$, $\\mu_{\\text{quite }L_1}(a) = 0.3$, $\\mu_{\\text{very }L_2}(a) = 0.1$, $\\mu_{L_1}(a) = 0$, $\\mu_{\\text{very }L_1}(a) = 0$, giving us the order $\\mu_{\\text{quite }L_2}(a) \\geq \\mu_{L_2}(a) \\geq \\mu_{\\text{quite }L_1}(a) \\geq \\mu_{\\text{very }L_2}(a) \\geq \\mu_{L_1}(a) \\geq \\mu_{\\text{very }L_1}(a)$. We may then assign probabilities to subsets of labels according to the consonant selection function:\n\n", "itemtype": "equation", "pos": 15226, "prevtext": "\n\nFigure \\ref{fig:mu2d} shows how this appropriateness measure works in a setup similar to that in figure \\ref{fig:pnth}. \n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{mu2d.pdf}\n\\caption{Membership in a concept. The prototype of the label is at $[0.5, 0.5]$ and the threshold ${\\varepsilon}$ has distribution $U[0,0.3]$. When $x = [0.5,0.5]$, $\\mu_L(x) = 1$. As we move further away from the prototype, membership in the concept decreases, and is $0$ when $d(x, P_i) > 0.3$}\n\\label{fig:mu2d}\n\\end{figure}\n\nThis appropriateness measure is similar to Zadeh's description of fuzzy membership in a concept \\cite{zadeh1965}.\n\n\\subsection{Linguistic hedges}\nHedges are words or phrases such as `very', `quite', `strictly speaking' which modify the domain of application of a concept. In particular, `very', and `quite' respectively contract or expand the domain of application of a concept,  so that, for example, `very tall' applies to fewer people than does `tall', whereas `quite tall' applies to more. Within fuzzy set theory, we expect that $\\mu_{\\text{very } L} (x) \\leq \\mu_L (x)$ and $\\mu_{\\text{quite } L} (x) \\geq \\mu_L (x)$. Applying this to the concept `tall', again,  this means that membership in the concept `very tall' should always be less than membership in `tall'. So anyone who can be described as `very tall' can also be described as `tall'.  Zadeh \\cite{zadehhedges} uses operations of \\emph{concentration} and \\emph{dilation} to render these ideas. Concentration is described as $CON(\\mu_{L_i}(x)) = (\\mu_{L_i}(x))^2$ and dilation is often rendered as $DIL(\\mu_{L_i}(x)) = (\\mu_{L_i}(x))^{1/2}$. However, we argue, as do \\cite{bosc}, that Zadeh's formulae are, to an extent, arbitrary, since the notion of taking a power of a membership value does not correspond to anything that language users might do. Rather, it simply has some of the right effects. As with \\cite{bosc}, we take a semantic approach.\n\nIn \\cite{lewis2014}, we propose that a concept `very $L$' or `quite $L$' be rendered by considering that the prototype of `very/quite $L$' is equal to that of the base concept $L$, but that the threshold of the hedged concept `very/quite $L$' is respectively smaller or larger than that of the base concept. This approach is grounded in the idea that `very/quite $L$' should apply to respectively fewer or more objects than $L$. Narrowing or widening the threshold achieves this in a natural way. This is illustrated in figure \\ref{fig:vq}. \n\n\\begin{figure}\n\t \\centering\n\t\t  \\caption{Representation of `very $L_i$' and `quite $L_i$'. `Very $L_i$' has prototype $P_i$ and threshold $v{\\varepsilon}_i \\leq {\\varepsilon}_i$. `Quite $L_i$' has prototype $P_i$ and threshold $q{\\varepsilon}_i \\geq {\\varepsilon}_i$. Notice that although $L_i$ is appropriate to describe $a$, $vL_i$ is not. Also, although $L_i$ is not appropriate to describe $b$, $qL_i$ is.}\n\t\\label{fig:vq}\n\\end{figure}\n\nOur model of the hedges `very' and `quite' therefore requires simply that $v{\\varepsilon}_i \\leq {\\varepsilon}_i$ and that $q{\\varepsilon}_i \\geq {\\varepsilon}_i$. We implement this model in a version of the multi-agent simulation created in \\cite{ettie} in order to investigate how the use of these hedges in a model of language helps the emergence of shared categories across a community of language users.\n\n\\section{METHODS}\n\\label{sec:method}\n\\subsection{Overview}\nTo investigate the utility of hedged assertions we implement a multi-agent simulation of a version of the category game \\cite{belp}, following \\cite{ettie}, in which shared categories develop over time as a result of the interactions of the category users. An overview of the game is as follows. Agents use labels to describe a conceptual space $\\Omega$. At each timestep, agents are randomly paired into speakers and listeners, and each pair is shown a distinct element $x \\in \\Omega$. The speaker makes an assertion $\\theta$ about the element based on its label set. The listener then updates its own label set to be more similar to that of the speaker, based on this assertion and a parameter $w$ which can be thought of as the age of the speaker. The update made by the speaker is a combination of shifting the prototype of the relevant label and changing the size of the threshold. The aim is that after a number of timesteps, label sets across the population have converged to a common set of shared categories.\n\n\\subsection{Conceptual models}\nEach agent is equipped with the same number $n$ of labels $L_i$, with point prototypes $P_i \\in \\Omega$, where $\\Omega  = [0,1]^3$. At the start of the simulations the $P_i$ are uniformly distributed around the space. Thresholds ${\\varepsilon}_i$ are also randomly initiated, and considered to be some multiple of a base threshold ${\\varepsilon}$. Each threshold ${\\varepsilon}_i \\sim U(0, b_i)$, where again, the $b_i$ can be considered to be a multiple of some common $b$, and the $b_i$ are taken from $U[0.5, 2]$. The distance metric is Euclidean. \n\nEach agent therefore has a label set $LA= \\{L_1, L_2, ... L_n\\}$. These labels can be hedged to form a set $LA^+ = LA \\cup \\{ \\text{very }L_i, \\text{quite }L_i : i = 1,..., n\\}$. Hedged concepts have the same prototype $P_i$ as basic labels, but a scaled threshold $v{\\varepsilon}_i$ or $q{\\varepsilon}_i$ where  $v < 1$ and $q >1$. Agents can assert positive or negated, hedged or basic labels, giving an assertion set $AS = \\{kL_i, \\neg kL_i : i = 1, ..., n; k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$, where $k = \\text{basic}$ means that the label is not hedged.\n\n\\subsection{Assertion model}\nAt each timestep, half the agents are designated speaker agents and make assertions, determined by the assertion model used.The assertion model is based on the probability of making a particular assertion $\\theta$, given that the object being described is $x$. Following methods in \\cite{ettie, lawry2009}, we calculate the posterior probability of each $\\theta \\in AS$, given an element $x \\in \\Omega$. The assertion made by a speaker agent is the assertion with the highest probability. The posterior probability of each $\\theta$, given $x$, is determined by the appropriateness of the assertion $\\theta$ to describe $x$, i.e. $\\mu_\\theta(x)$, and the prior probability $P(\\theta)$ of asserting $\\theta$.\n\nWe first consider which sets of labels that are appropriate to describe $x \\in \\Omega$. The probability that any particular set of labels $F\\subseteq LA$ are appropriate to describe $x$ is given by a probability mass function $m_x: 2^{LA} \\rightarrow [0, 1]$. One way of determining $m_x$ is via the \\emph{consonant selection function} introduced in \\cite{lawry2009}. This states:\n\n\\begin{dfn}[Consonant selection function]\nGiven non-zero appropriateness measures on basic labels $\\mu_{L_i}(x): i = 1,..., n$ ordered such that $\\mu_{L_i}(x) \\geq \\mu_{L_{i+1}}$ for $i = 1, ..., n$, the consonant selection function identifies the mass function \n\n", "index": 3, "text": "\\begin{align*}\n&m_x(\\{L_1, ... , L_n\\}) = \\mu_{L_n}(x) \\\\\n&m_x(\\{L_1, ... , L_i\\}) = \\mu_{L_i}(x) - \\mu_{L_{i+1}}(x) \\text{ for } i = 1, .. n-1 \\\\ \n&m_x(\\emptyset) = 1 - \\mu_{L_1}(x)\\\\\n&m_x(F) = 0 \\text{ if }F \\neq \\{L_1, L_2, ..., L_k\\} \\text{ for some } k \\leq n \n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(\\{L_{1},...,L_{n}\\})=\\mu_{L_{n}}(x)\" display=\"inline\"><mrow><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>L</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>L</mi><mi>n</mi></msub><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>n</mi></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(\\{L_{1},...,L_{i}\\})=\\mu_{L_{i}}(x)-\\mu_{L_{i+1}}(x)\\text{%&#10; for }i=1,..n-1\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>L</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><msub><mi>\u03bc</mi><msub><mi>L</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mtext>\u00a0for\u00a0</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mi>n</mi><mo>-</mo><mn>1</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(\\emptyset)=1-\\mu_{L_{1}}(x)\" display=\"inline\"><mrow><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2205</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F)=0\\text{ if }F\\neq\\{L_{1},L_{2},...,L_{k}\\}\\text{ for %&#10;some }k\\leq n\" display=\"inline\"><mrow><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>F</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>0</mn><mo>\u2062</mo><mtext>\u00a0if\u00a0</mtext><mo>\u2062</mo><mi>F</mi></mrow><mo>\u2260</mo><mrow><mrow><mo stretchy=\"false\">{</mo><msub><mi>L</mi><mn>1</mn></msub><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>L</mi><mi>k</mi></msub><mo stretchy=\"false\">}</mo></mrow><mo>\u2062</mo><mtext>\u00a0for some\u00a0</mtext><mo>\u2062</mo><mi>k</mi></mrow><mo>\u2264</mo><mi>n</mi></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\\end{exa}\n\nHaving determined the probability mass function on sets of labels, a mass assignment on sets of assertions is then defined.\n\n\\begin{dfn}[Mass assignment on assertions]\n\n$ma_x: 2^{AS} \\rightarrow [0, 1]$ is defined such that:\n", "itemtype": "equation", "pos": 17381, "prevtext": "\n\\end{dfn}\n\nBecause we have ordered the labels by $\\mu_{L_i}(x) \\geq \\mu_{L_{i+1}}$, if the label $L_i$ is appropriate to describe $x$, all labels $L_j : j < i$ must also be appropriate to describe $x$. The quantity $\\mu_{L_i}(x) - \\mu_{L_{i+1}}(x)$ corresponds to the idea that $x$ in some sense lies between the thresholds ${\\varepsilon}_{i+1}$ and ${\\varepsilon}_i$, so that $L_i$ is appropriate to describe $x$, but $L_{i+1}$ is not.  We extend this definition to the case of hedged labels simply by considering all hedged labels as basic labels, explained in the example below.\n\n\\begin{exa}[Determining the mass function]\n\\label{exa:mf}\nSuppose we are determining the mass function for subsets $F \\subseteq \\{kL_1, kL_2: k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$, given the point $a \\in x_1 \\times x_2$, as illustrated in figure \\ref{fig:mf}.\n\\begin{figure}\n\t \\centering\n\t \t  \\caption{Determining the mass function on subsets of $\\{kL_1, kL_2: k = \\text{very}, \\text{ quite}, \\text{ basic}\\}$. $P_1$ and $P_2$ represent prototypes for each lable $L_1$ and $L_2$, and the dotted lines give the different thresholds according to the hedges, as in figure \\ref{fig:vq}. Notice that `quite $L_2$', $L_2$, `very $L_2$' and `quite $L_1$' are all appropriate to describe $a$, although with different appropriateness measures (not shown), but $L_1$ and `very $L_1$' are not.}\n\t\\label{fig:mf}\n\\end{figure}\n\nSuppose that $\\mu_{\\text{quite }L_2}(a) = 0.9$, $\\mu_{L_2}(a) = 0.7$, $\\mu_{\\text{quite }L_1}(a) = 0.3$, $\\mu_{\\text{very }L_2}(a) = 0.1$, $\\mu_{L_1}(a) = 0$, $\\mu_{\\text{very }L_1}(a) = 0$, giving us the order $\\mu_{\\text{quite }L_2}(a) \\geq \\mu_{L_2}(a) \\geq \\mu_{\\text{quite }L_1}(a) \\geq \\mu_{\\text{very }L_2}(a) \\geq \\mu_{L_1}(a) \\geq \\mu_{\\text{very }L_1}(a)$. We may then assign probabilities to subsets of labels according to the consonant selection function:\n\n", "index": 5, "text": "\\begin{align*}\nm_x(F_6) &= m_x(\\{\\text{quite }L_2, L_2, \\text{quite }L_1, \\text{very }L_2, L_1, \\text{very }L_1\\}) \\\\\n&= \\mu_{\\text{very }L_1}(a) = 0\\\\\nm_x(F_5) &= m_x(\\{\\text{quite }L_2, L_2, \\text{quite }L_1, \\text{very }L_2, L_1\\}) \\\\\n&= \\mu{L_1}(a) -\\mu_{\\text{very }L_1}(a) = 0\\\\\nm_x(F_4) &= m_x(\\{\\text{quite }L_2, L_2, \\text{quite }L_1, \\text{very }L_2\\}) \\\\\n&= \\mu_{\\text{very }L_2}(a) - \\mu_{L_1}(a) = 0.1\\\\\nm_x(F_3)&= m_x(\\{\\text{quite }L_2, L_2, \\text{quite }L_1\\}) \\\\\n&= \\mu_{\\text{quite }L_1}(a) - \\mu_{\\text{very }L_2}(a) = 0.2\\\\\nm_x(F_2) &= m_x(\\{\\text{quite }L_2, L_2\\}) = \\mu_{L_2}(a) - \\mu_{\\text{quite }L_1}(a) = 0.4\\\\\nm_x(F_1) &= m_x(\\{\\text{quite }L_2\\}) = \\mu_{\\text{quite }L_2}(a) - \\mu_{L_2}(a) = 0.2\\\\\nm_x(\\emptyset) &= 1 - \\mu_{\\text{quite }L_2}(a) = 0.1\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{6})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2},L_{2},\\text{quite }L_{1},\\text{very }%&#10;L_{2},L_{1},\\text{very }L_{1}\\})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo>,</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>1</mn></msub><mo>,</mo><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mu_{\\text{very }L_{1}}(a)=0\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>\u03bc</mi><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{5})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>5</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2},L_{2},\\text{quite }L_{1},\\text{very }%&#10;L_{2},L_{1}\\})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo>,</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>1</mn></msub><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mu{L_{1}}(a)-\\mu_{\\text{very }L_{1}}(a)=0\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bc</mi><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{4})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>4</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2},L_{2},\\text{quite }L_{1},\\text{very }%&#10;L_{2}\\})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo>,</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mu_{\\text{very }L_{2}}(a)-\\mu_{L_{1}}(a)=0.1\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><msub><mi>\u03bc</mi><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>1</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0.1</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{3})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2},L_{2},\\text{quite }L_{1}\\})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo>,</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mu_{\\text{quite }L_{1}}(a)-\\mu_{\\text{very }L_{2}}(a)=0.2\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><msub><mi>\u03bc</mi><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mtext>very\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0.2</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{2})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2},L_{2}\\})=\\mu_{L_{2}}(a)-\\mu_{\\text{%&#10;quite }L_{1}}(a)=0.4\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo>,</mo><msub><mi>L</mi><mn>2</mn></msub><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0.4</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(F_{1})\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=m_{x}(\\{\\text{quite }L_{2}\\})=\\mu_{\\text{quite }L_{2}}(a)-\\mu_{L%&#10;_{2}}(a)=0.2\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03bc</mi><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mn>2</mn></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0.2</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle m_{x}(\\emptyset)\" display=\"inline\"><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u2205</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=1-\\mu_{\\text{quite }L_{2}}(a)=0.1\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mrow><msub><mi>\u03bc</mi><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0.1</mn></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\nwhere  $\\mathscr{C}(F) = \\{\\theta \\in AS : F\\in \\lambda(\\theta)\\}$, and $\\lambda(\\theta)$ is defined recursively by \n\n \n", "itemtype": "equation", "pos": 18410, "prevtext": "\n\\end{exa}\n\nHaving determined the probability mass function on sets of labels, a mass assignment on sets of assertions is then defined.\n\n\\begin{dfn}[Mass assignment on assertions]\n\n$ma_x: 2^{AS} \\rightarrow [0, 1]$ is defined such that:\n", "index": 7, "text": "\n\\[\nma_x(G) = \\sum_{F \\subseteq LA^+ : \\mathscr{C}(F) = G} m_x(F)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"ma_{x}(G)=\\sum_{F\\subseteq LA^{+}:\\mathscr{C}(F)=G}m_{x}(F)\" display=\"block\"><mrow><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>F</mi><mo>\u2286</mo><mrow><mi>L</mi><mo>\u2062</mo><msup><mi>A</mi><mo>+</mo></msup></mrow></mrow><mo>:</mo><mrow><mrow><mi class=\"ltx_font_mathscript\">\ud835\udc9e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>F</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi>G</mi></mrow></mrow></munder><mrow><msub><mi>m</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>F</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\\end{dfn}\n\nThis definition has the implication that for $G_i = F_i \\cup \\{\\neg kL_j: kL_j \\in LA^+\\backslash F_i\\}$, $ma_x(G_i) = m_x(F_i)$.\n\nThen the probability of an assertion $\\theta$ being made, given that an object $x$ is being described, can be calculated by summing over $G \\subseteq AS$ that contain $\\theta$.\n\n\\begin{dfn}\nGiven a prior distribution on $AS$, a posterior distribution given an object $x$ can be calculated by:\n \n", "itemtype": "equation", "pos": 18598, "prevtext": "\nwhere  $\\mathscr{C}(F) = \\{\\theta \\in AS : F\\in \\lambda(\\theta)\\}$, and $\\lambda(\\theta)$ is defined recursively by \n\n \n", "index": 9, "text": "\\begin{align*}\n\\lambda(kL_i) &= \\{F \\subseteq LA^+: kLi \\in F\\}\\\\\n\\lambda(\\neg \\theta) &= (\\lambda(\\theta))^c\\\\\n\\lambda(\\theta \\wedge \\phi) &= \\lambda(\\theta) \\cap \\lambda(\\phi)\\\\\n\\lambda(\\theta \\vee \\phi) &= \\lambda(\\theta) \\cup \\lambda(\\phi)\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda(kL_{i})\" display=\"inline\"><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>\u2062</mo><msub><mi>L</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\{F\\subseteq LA^{+}:kLi\\in F\\}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>F</mi><mo>\u2286</mo><mrow><mi>L</mi><mo>\u2062</mo><msup><mi>A</mi><mo>+</mo></msup></mrow></mrow><mo>:</mo><mrow><mrow><mi>k</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><mi>i</mi></mrow><mo>\u2208</mo><mi>F</mi></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda(\\neg\\theta)\" display=\"inline\"><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=(\\lambda(\\theta))^{c}\" display=\"inline\"><mrow><mi/><mo>=</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>c</mi></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda(\\theta\\wedge\\phi)\" display=\"inline\"><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b8</mi><mo>\u2227</mo><mi>\u03d5</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda(\\theta)\\cap\\lambda(\\phi)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2229</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d5</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\lambda(\\theta\\vee\\phi)\" display=\"inline\"><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b8</mi><mo>\u2228</mo><mi>\u03d5</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\lambda(\\theta)\\cup\\lambda(\\phi)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u222a</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d5</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\\end{dfn}\nHere, $P(G) = \\sum_{\\varphi \\in G} P(\\varphi)$\n\nThe value of $P(\\theta)$ for one particular label $L$ is a product of two elements: the prior probability $pp$ of making a positive assertion (or $1 - pp$ for a negated assertion); and the prior probability of making a hedged assertion, given by $pv$ for making an assertion hedged with the word `very', $pq$ for making an assertion hedged with `quite' or $1 - pv - pq$ for making a basic assertion, summarised in table \\ref{tab:ptab}.\n\n\\begin{table}\n\t\\centering\n\t\\caption{Prior probabilities of each type of assertion $\\pm kLi$}\n\t\\begin{tabular}{cccc}\n\t\\hline\n\t$*$ & $pv$ & $pb$ & $pq$\\\\ \\hline\n\t$pp$ & $P(vL)$ & $P(L)$ & $P(qL)$\\\\ \\hline\n\t$pn$ & $P(\\neg vL)$ & $P(\\neg L)$ & $ P(\\neg qL)$ \\\\ \\hline\n\t\\end{tabular}\n\t\\label{tab:ptab}\n\\end{table}\n\nThe prior probability of asserting any particular label $L_i \\in LA$ is uniform across $LA$. Hence the value of $P(\\theta)$ calculated above should be divided by $n$, giving, for example, \n", "itemtype": "equation", "pos": 19293, "prevtext": "\n\\end{dfn}\n\nThis definition has the implication that for $G_i = F_i \\cup \\{\\neg kL_j: kL_j \\in LA^+\\backslash F_i\\}$, $ma_x(G_i) = m_x(F_i)$.\n\nThen the probability of an assertion $\\theta$ being made, given that an object $x$ is being described, can be calculated by summing over $G \\subseteq AS$ that contain $\\theta$.\n\n\\begin{dfn}\nGiven a prior distribution on $AS$, a posterior distribution given an object $x$ can be calculated by:\n \n", "index": 11, "text": "\\begin{align*}\nP(\\mathscr{A} = \\theta | x) &= \\sum_{G \\subseteq AS: \\theta \\in G} ma_x(G)P(\\mathscr{A} = \\theta |\\mathscr{A} \\in G) \\\\\n&= P(\\theta) \\sum_{G \\subseteq AS: \\theta \\in G} \\frac{ma_x(G)}{P(G)}\n \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\mathscr{A}=\\theta|x)\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi><mo>=</mo><mi>\u03b8</mi><mo stretchy=\"false\">|</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{G\\subseteq AS:\\theta\\in G}ma_{x}(G)P(\\mathscr{A}=\\theta|%&#10;\\mathscr{A}\\in G)\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>G</mi><mo>\u2286</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>S</mi></mrow></mrow><mo>:</mo><mrow><mi>\u03b8</mi><mo>\u2208</mo><mi>G</mi></mrow></mrow></munder></mstyle><mi>m</mi><msub><mi>a</mi><mi>x</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi><mo>=</mo><mi>\u03b8</mi><mo stretchy=\"false\">|</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi><mo>\u2208</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=P(\\theta)\\sum_{G\\subseteq AS:\\theta\\in G}\\frac{ma_{x}(G)}{P(G)}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>G</mi><mo>\u2286</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>S</mi></mrow></mrow><mo>:</mo><mrow><mi>\u03b8</mi><mo>\u2208</mo><mi>G</mi></mrow></mrow></munder></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\n\n\\begin{exa}[Determining the posterior probability of assertion]\nSuppose, for an easy example, we want to calculate the probability of asserting `very $L_1$', given object $a$, as in example \\ref{exa:mf}. We need to calculate \n\n", "itemtype": "equation", "pos": 20505, "prevtext": "\n\\end{dfn}\nHere, $P(G) = \\sum_{\\varphi \\in G} P(\\varphi)$\n\nThe value of $P(\\theta)$ for one particular label $L$ is a product of two elements: the prior probability $pp$ of making a positive assertion (or $1 - pp$ for a negated assertion); and the prior probability of making a hedged assertion, given by $pv$ for making an assertion hedged with the word `very', $pq$ for making an assertion hedged with `quite' or $1 - pv - pq$ for making a basic assertion, summarised in table \\ref{tab:ptab}.\n\n\\begin{table}\n\t\\centering\n\t\\caption{Prior probabilities of each type of assertion $\\pm kLi$}\n\t\\begin{tabular}{cccc}\n\t\\hline\n\t$*$ & $pv$ & $pb$ & $pq$\\\\ \\hline\n\t$pp$ & $P(vL)$ & $P(L)$ & $P(qL)$\\\\ \\hline\n\t$pn$ & $P(\\neg vL)$ & $P(\\neg L)$ & $ P(\\neg qL)$ \\\\ \\hline\n\t\\end{tabular}\n\t\\label{tab:ptab}\n\\end{table}\n\nThe prior probability of asserting any particular label $L_i \\in LA$ is uniform across $LA$. Hence the value of $P(\\theta)$ calculated above should be divided by $n$, giving, for example, \n", "index": 13, "text": "\n\\[\nP(\\neg vL_2) = \\frac{pn*pv}{n}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m1\" class=\"ltx_Math\" alttext=\"P(\\neg vL_{2})=\\frac{pn*pv}{n}\" display=\"block\"><mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">\u00ac</mi><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><msub><mi>L</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><mrow><mi>p</mi><mo>\u2062</mo><mi>n</mi></mrow><mo>*</mo><mi>p</mi></mrow><mo>\u2062</mo><mi>v</mi></mrow><mi>n</mi></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nwhere $G_i = F_i \\cup \\{\\neg kL_j: kL_j \\in LA^+\\backslash F_i\\}$. However, the only subset $G_i \\ni$ `very $L_1$' is $G_6$, so \n\n\n", "itemtype": "equation", "pos": 20771, "prevtext": "\n\n\n\\begin{exa}[Determining the posterior probability of assertion]\nSuppose, for an easy example, we want to calculate the probability of asserting `very $L_1$', given object $a$, as in example \\ref{exa:mf}. We need to calculate \n\n", "index": 15, "text": "\n\\[\nP(\\mathscr{A} = \\text{`very $L_1$'} | a) = P(\\theta) \\sum_{G \\subseteq AS: \\text{`very $L_1$'} \\in G} \\frac{ma_x(G)}{P(G)}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex26.m1\" class=\"ltx_Math\" alttext=\"P(\\mathscr{A}=\\text{`very $L_{1}$'}|a)=P(\\theta)\\sum_{G\\subseteq AS:\\text{`%&#10;very $L_{1}$'}\\in G}\\frac{ma_{x}(G)}{P(G)}\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi><mo>=</mo><mrow><mtext>\u2018very\u00a0</mtext><msub><mi>L</mi><mn>1</mn></msub><mtext>\u2019</mtext></mrow><mo stretchy=\"false\">|</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>G</mi><mo>\u2286</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>S</mi></mrow></mrow><mo>:</mo><mrow><mrow><mtext>\u2018very\u00a0</mtext><msub><mi>L</mi><mn mathsize=\"98%\">1</mn></msub><mtext>\u2019</mtext></mrow><mo>\u2208</mo><mi>G</mi></mrow></mrow></munder><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>G</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\n\nSuppose, for a more involved example, the label set $LA^+$ is as in example \\ref{exa:mf}, with $pp = 0.7$, $pv = 0.7$, $pq = 0.2$, and we want to determine $P(\\mathscr{A} = \\text{quite }L_1 | a)$. The prior probability $P(\\text{quite }L_1) = \\frac{0.7*0.2}{2} = 0.07$. So we have:\n\n\n", "itemtype": "equation", "pos": 21032, "prevtext": "\n\nwhere $G_i = F_i \\cup \\{\\neg kL_j: kL_j \\in LA^+\\backslash F_i\\}$. However, the only subset $G_i \\ni$ `very $L_1$' is $G_6$, so \n\n\n", "index": 17, "text": "\\begin{align*}\nP(\\mathscr{A} = \\text{`very $L_1$'} | x) &= P(\\text{`very $L_1$'}) \\frac{ma_x(G_6)}{P(G_6)}\\\\\n&=0\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\mathscr{A}=\\text{`very $L_{1}$'}|x)\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi><mo>=</mo><mrow><mtext>\u2018very\u00a0</mtext><msub><mi>L</mi><mn>1</mn></msub><mtext>\u2019</mtext></mrow><mo stretchy=\"false\">|</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex27.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=P(\\text{`very $L_{1}$'})\\frac{ma_{x}(G_{6})}{P(G_{6})}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mtext>\u2018very\u00a0</mtext><msub><mi>L</mi><mn>1</mn></msub><mtext>\u2019</mtext></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex28.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0\" display=\"inline\"><mrow><mi/><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\\end{exa}\n\nHaving calculated the probability of each assertion, the speaker agent makes the most probable assertion $\\theta \\in AS$.\n\n\\subsection{Updating algorithms}\nOnce the speaker agent has made assertion $\\theta$, the listener agent computes $\\mu_\\theta(x)$ based on its current label set. If $\\mu_\\theta(x) < w$, where $w$ is a parameter that can be thought of as the age of the speaker agent, the listener agent updates its label set $LA$ by moving the prototype and/or changing the threshold of the concept, until $\\mu_{\\theta}(x) = w$. Formulae  for these updates are again based on \\cite{ettie}. A label defined by $P_i$ and ${\\varepsilon}_i$ is updated to $P_i' = P_i - \\lambda(x - P_i)$ and ${\\varepsilon}_i' = \\alpha {\\varepsilon}_i$. Values for $\\lambda$ and $\\alpha$ are sought, such that $\\mu_{\\theta}'(x) = w$.\n\n\\subsubsection{Case 1: $\\theta = kL_i$}\nRecall that ${\\varepsilon}_i \\sim U(0, b_i)$, so that for $x \\in\\Omega$,\n", "itemtype": "equation", "pos": 21442, "prevtext": "\n\n\nSuppose, for a more involved example, the label set $LA^+$ is as in example \\ref{exa:mf}, with $pp = 0.7$, $pv = 0.7$, $pq = 0.2$, and we want to determine $P(\\mathscr{A} = \\text{quite }L_1 | a)$. The prior probability $P(\\text{quite }L_1) = \\frac{0.7*0.2}{2} = 0.07$. So we have:\n\n\n", "index": 19, "text": "\\begin{align*}\nP(\\mathscr{A} &= \\text{quite }L_1 | a)\\\\\n&= 0.07\\sum_{G_i: \\text{quite }L_1 \\in G_i} \\frac{ma_x(G_i)} {P(G_i)}\\\\\n&= 0.07(\\frac{ma_x(G_6)} {P(G_6)} + \\frac{ma_x(G_5)} {P(G_5)}+\\frac{ma_x(G_4)} {P(G_4)}+ \\frac{ma_x(G_3)} {P(G_3)})\\\\\n &= 0.07(0 + 0 + \\frac{0.1}{\\sum_{\\varphi \\in G_4}P(\\varphi)} + \\frac{0.2}{\\sum_{\\varphi \\in G_3}P(\\varphi)})\\\\\n &= 0.07(\\frac{0.1}{0.54} + \\frac{0.2}{0.4})\\\\\n &= 0.048\\\\\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\mathscr{A}\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathscript\">\ud835\udc9c</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex29.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\text{quite }L_{1}|a)\" display=\"inline\"><mrow><mo>=</mo><mtext>quite\u00a0</mtext><msub><mi>L</mi><mn>1</mn></msub><mo stretchy=\"false\">|</mo><mi>a</mi><mo stretchy=\"false\">)</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex30.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.07\\sum_{G_{i}:\\text{quite }L_{1}\\in G_{i}}\\frac{ma_{x}(G_{i})}%&#10;{P(G_{i})}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>0.07</mn><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>G</mi><mi>i</mi></msub><mo>:</mo><mrow><mrow><mtext>quite\u00a0</mtext><mo>\u2062</mo><msub><mi>L</mi><mn>1</mn></msub></mrow><mo>\u2208</mo><msub><mi>G</mi><mi>i</mi></msub></mrow></mrow></munder></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex31.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.07(\\frac{ma_{x}(G_{6})}{P(G_{6})}+\\frac{ma_{x}(G_{5})}{P(G_{5}%&#10;)}+\\frac{ma_{x}(G_{4})}{P(G_{4})}+\\frac{ma_{x}(G_{3})}{P(G_{3})})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>0.07</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>5</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>5</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>4</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>4</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>m</mi><mo>\u2062</mo><msub><mi>a</mi><mi>x</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>G</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex32.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.07(0+0+\\frac{0.1}{\\sum_{\\varphi\\in G_{4}}P(\\varphi)}+\\frac{0.2%&#10;}{\\sum_{\\varphi\\in G_{3}}P(\\varphi)})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>0.07</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>0</mn><mo>+</mo><mn>0</mn><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mn>0.1</mn><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>\u03c6</mi><mo>\u2208</mo><msub><mi>G</mi><mn>4</mn></msub></mrow></msub><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mn>0.2</mn><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>\u03c6</mi><mo>\u2208</mo><msub><mi>G</mi><mn>3</mn></msub></mrow></msub><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex33.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.07(\\frac{0.1}{0.54}+\\frac{0.2}{0.4})\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mn>0.07</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>0.1</mn><mn>0.54</mn></mfrac></mstyle><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mn>0.2</mn><mn>0.4</mn></mfrac></mstyle></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex34.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=0.048\" display=\"inline\"><mrow><mi/><mo>=</mo><mn>0.048</mn></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nThe label $L_i$ is updated to $L_i'$, where $P_i' = P_i - \\lambda(x - P_i)$ and ${\\varepsilon}_i' = \\alpha {\\varepsilon}_i$, such that  $\\mu_{kL_i'}(x) \\geq w$, and minimising the distance between the interpretations as measured by the Haussdorff distance between the two neighbourhoods,\n\n", "itemtype": "equation", "pos": 22813, "prevtext": "\n\\end{exa}\n\nHaving calculated the probability of each assertion, the speaker agent makes the most probable assertion $\\theta \\in AS$.\n\n\\subsection{Updating algorithms}\nOnce the speaker agent has made assertion $\\theta$, the listener agent computes $\\mu_\\theta(x)$ based on its current label set. If $\\mu_\\theta(x) < w$, where $w$ is a parameter that can be thought of as the age of the speaker agent, the listener agent updates its label set $LA$ by moving the prototype and/or changing the threshold of the concept, until $\\mu_{\\theta}(x) = w$. Formulae  for these updates are again based on \\cite{ettie}. A label defined by $P_i$ and ${\\varepsilon}_i$ is updated to $P_i' = P_i - \\lambda(x - P_i)$ and ${\\varepsilon}_i' = \\alpha {\\varepsilon}_i$. Values for $\\lambda$ and $\\alpha$ are sought, such that $\\mu_{\\theta}'(x) = w$.\n\n\\subsubsection{Case 1: $\\theta = kL_i$}\nRecall that ${\\varepsilon}_i \\sim U(0, b_i)$, so that for $x \\in\\Omega$,\n", "index": 21, "text": "\n\\[\n\\mu_{kL_i}(x) = 1 - \\frac{||x-P_i||}{kb_i} < w \\text{ by assumption.} \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex36.m1\" class=\"ltx_Math\" alttext=\"\\mu_{kL_{i}}(x)=1-\\frac{||x-P_{i}||}{kb_{i}}&lt;w\\text{ by assumption.}\" display=\"block\"><mrow><mrow><msub><mi>\u03bc</mi><mrow><mi>k</mi><mo>\u2062</mo><msub><mi>L</mi><mi>i</mi></msub></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mrow><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mrow><mo>&lt;</mo><mrow><mi>w</mi><mo>\u2062</mo><mtext>\u00a0by assumption.</mtext></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nTo minimise the update, we set $\\mu_{kL_i'}(x) = w$, so:\n\n\n", "itemtype": "equation", "pos": 23180, "prevtext": "\n\nThe label $L_i$ is updated to $L_i'$, where $P_i' = P_i - \\lambda(x - P_i)$ and ${\\varepsilon}_i' = \\alpha {\\varepsilon}_i$, such that  $\\mu_{kL_i'}(x) \\geq w$, and minimising the distance between the interpretations as measured by the Haussdorff distance between the two neighbourhoods,\n\n", "index": 23, "text": "\\begin{align}\n\\label{eq:hmet}\n\\mathscr{H}(\\mathcal{N}_{L_i}, \\mathcal{N}_{L_i'}) &= ||P_i - P_i'|| + |{\\varepsilon}_i -{\\varepsilon}_i'|\\\\\n&= |\\lambda|||x-P_i|| + \\frac{{\\varepsilon} b_i}{b}|1-\\alpha| \\text{ (*)} \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathscr{H}(\\mathcal{N}_{L_{i}},\\mathcal{N}_{L_{i}^{\\prime}})\" display=\"inline\"><mrow><mi class=\"ltx_font_mathscript\">\u210b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mo>,</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msubsup><mi>L</mi><mi>i</mi><mo>\u2032</mo></msubsup></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=||P_{i}-P_{i}^{\\prime}||+|{\\varepsilon}_{i}-{\\varepsilon}_{i}^{%&#10;\\prime}|\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>-</mo><msubsup><mi>P</mi><mi>i</mi><mo>\u2032</mo></msubsup></mrow><mo fence=\"true\">||</mo></mrow><mo>+</mo><mrow><mo stretchy=\"false\">|</mo><mrow><msub><mi>\u03b5</mi><mi>i</mi></msub><mo>-</mo><msubsup><mi>\u03b5</mi><mi>i</mi><mo>\u2032</mo></msubsup></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex37.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=|\\lambda|||x-P_{i}||+\\frac{{\\varepsilon}b_{i}}{b}|1-\\alpha|\\text%&#10;{ (*)}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03bb</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b5</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><mi>b</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mtext>\u00a0(*)</mtext></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nwhich gives\n\n", "itemtype": "equation", "pos": 23474, "prevtext": "\n\nTo minimise the update, we set $\\mu_{kL_i'}(x) = w$, so:\n\n\n", "index": 25, "text": "\\begin{align*}\nw = \\mu_{kL_i'}(x) = 1 - \\frac{||x-P_i'||}{kb_i'} = 1 - \\frac{|1-\\lambda|||x-P_i||}{\\alpha kb_i}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex38.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle w=\\mu_{kL_{i}^{\\prime}}(x)=1-\\frac{||x-P_{i}^{\\prime}||}{kb_{i}^%&#10;{\\prime}}=1-\\frac{|1-\\lambda|||x-P_{i}||}{\\alpha kb_{i}}\" display=\"inline\"><mrow><mi>w</mi><mo>=</mo><mrow><msub><mi>\u03bc</mi><mrow><mi>k</mi><mo>\u2062</mo><msubsup><mi>L</mi><mi>i</mi><mo>\u2032</mo></msubsup></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msubsup><mi>P</mi><mi>i</mi><mo>\u2032</mo></msubsup></mrow><mo fence=\"true\">||</mo></mrow><mrow><mi>k</mi><mo>\u2062</mo><msubsup><mi>b</mi><mi>i</mi><mo>\u2032</mo></msubsup></mrow></mfrac></mstyle></mrow><mo>=</mo><mrow><mn>1</mn><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nTo update $L_i$ we will always want $\\lambda \\geq 0$, $\\alpha \\geq 1$, as we are dealing with a positive label.\n\nSubstituting $\\alpha$ into equation (*),  we obtain\n\n", "itemtype": "equation", "pos": 23612, "prevtext": "\n\nwhich gives\n\n", "index": 27, "text": "\\begin{align*}\n\\alpha &= \\frac{|1-\\lambda|||x-P_i||}{(1-w)kb_i}\\\\\n&= \\frac{(1-\\lambda)||x-P_i||}{(1-w)kb_i} \\text{\\quad since $\\lambda = 1 \\rightarrow P_i' =x$}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex39.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha\" display=\"inline\"><mi>\u03b1</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex39.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{|1-\\lambda|||x-P_{i}||}{(1-w)kb_{i}}\" display=\"inline\"><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mstyle></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex40.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{(1-\\lambda)||x-P_{i}||}{(1-w)kb_{i}}\\text{\\quad since $%&#10;\\lambda=1\\rightarrow P_{i}^{\\prime}=x$}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03bb</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mtext>\u00a0since\u00a0</mtext><mrow><mi>\u03bb</mi><mo>=</mo><mn>1</mn><mo>\u2192</mo><msubsup><mi>P</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>=</mo><mi>x</mi></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nThen if $1 - \\frac{{\\varepsilon} }{b(1-w)k} >0$, i.e. ${\\varepsilon} < b(1-w)k$, the quantity (\\ref{eq:tominimise}) can be minimised by setting $\\lambda = 0$ so $\\alpha = \\frac{||x-P_i||}{(1-w)kb_i}$. Otherwise, we have $\\alpha = 1$, $\\lambda = 1 - \\frac{(1-w)kb_i}{||x - P_i||}$. \n\nSince ${\\varepsilon}$ is a random variable, so is the choice between $\\lambda$ and $\\alpha$. We therefore need a concrete updating rule. We update $P_i$ and $b_i$ with the expected values of $\\lambda$ and $\\alpha$ respectively. ${\\varepsilon} \\sim \\text{Uniform}[0, b]$, so\n\n\n", "itemtype": "equation", "pos": 23952, "prevtext": "\n\nTo update $L_i$ we will always want $\\lambda \\geq 0$, $\\alpha \\geq 1$, as we are dealing with a positive label.\n\nSubstituting $\\alpha$ into equation (*),  we obtain\n\n", "index": 29, "text": "\\begin{align}\n\\mathscr{H}&(\\mathcal{N}_{L_i}, \\mathcal{N}_{L_i}') = |\\lambda|||x-P_i|| + \\frac{{\\varepsilon} b_i}{b}(\\frac{(1-|\\lambda|)||x-P_i||}{(1-w)kb_i} - 1)\\nonumber \\\\\n\\label{eq:tominimise}\n&= |\\lambda|||x -P_i||(1 - \\frac{{\\varepsilon}}{b(1-w)k}) + \\frac{{\\varepsilon} ||x-P_i||}{b(1-w)k} - \\frac{{\\varepsilon} b_i}{b} \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex41.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathscr{H}\" display=\"inline\"><mi class=\"ltx_font_mathscript\">\u210b</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex41.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle(\\mathcal{N}_{L_{i}},\\mathcal{N}_{L_{i}}^{\\prime})=|\\lambda|||x-P%&#10;_{i}||+\\frac{{\\varepsilon}b_{i}}{b}(\\frac{(1-|\\lambda|)||x-P_{i}||}{(1-w)kb_{i%&#10;}}-1)\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mo>,</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msub><mi>L</mi><mi>i</mi></msub><mo>\u2032</mo></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03bb</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b5</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><mi>b</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mo stretchy=\"false\">|</mo><mi>\u03bb</mi><mo stretchy=\"false\">|</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mstyle><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=|\\lambda|||x-P_{i}||(1-\\frac{{\\varepsilon}}{b(1-w)k})+\\frac{{%&#10;\\varepsilon}||x-P_{i}||}{b(1-w)k}-\\frac{{\\varepsilon}b_{i}}{b}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mi>\u03bb</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mi>\u03b5</mi><mrow><mi>b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow></mfrac></mstyle></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b5</mi><mo>\u2062</mo><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow></mrow><mrow><mi>b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow></mfrac></mstyle></mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b5</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><mi>b</mi></mfrac></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nWe can therefore calculate \n\n", "itemtype": "equation", "pos": 24851, "prevtext": "\n\nThen if $1 - \\frac{{\\varepsilon} }{b(1-w)k} >0$, i.e. ${\\varepsilon} < b(1-w)k$, the quantity (\\ref{eq:tominimise}) can be minimised by setting $\\lambda = 0$ so $\\alpha = \\frac{||x-P_i||}{(1-w)kb_i}$. Otherwise, we have $\\alpha = 1$, $\\lambda = 1 - \\frac{(1-w)kb_i}{||x - P_i||}$. \n\nSince ${\\varepsilon}$ is a random variable, so is the choice between $\\lambda$ and $\\alpha$. We therefore need a concrete updating rule. We update $P_i$ and $b_i$ with the expected values of $\\lambda$ and $\\alpha$ respectively. ${\\varepsilon} \\sim \\text{Uniform}[0, b]$, so\n\n\n", "index": 31, "text": "\\begin{align*}\nP({\\varepsilon} < b(1-w)k) & = \n\\begin{cases} \n(1-w)k & \\text{if }  (1 - w)k < 1\\\\\n1   & \\text{otherwise\\ }\n  \\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex42.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P({\\varepsilon}&lt;b(1-w)k)\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b5</mi><mo>&lt;</mo><mi>b</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex42.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\begin{cases}(1-w)k&amp;\\text{if }(1-w)k&lt;1\\\\&#10;1&amp;\\text{otherwise\\ }\\end{cases}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>1</mn></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nand\n\n", "itemtype": "equation", "pos": 25030, "prevtext": "\n\nWe can therefore calculate \n\n", "index": 33, "text": "\\begin{align*}\nE(\\alpha) & = \n\\begin{cases} \n\\frac{||x - P_i||}{b_i} + 1 - (1-w)k & \\text{if }  (1 - w)k < 1\\\\\n\\frac{||x - P_i||}{(1-w)kb_i}   & \\text{otherwise\\ }\n  \\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex43.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\alpha)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex43.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\begin{cases}\\frac{||x-P_{i}||}{b_{i}}+1-(1-w)k&amp;\\text{if }(1-w)k%&#10;&lt;1\\\\&#10;\\frac{||x-P_{i}||}{(1-w)kb_{i}}&amp;\\text{otherwise\\ }\\end{cases}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mfrac><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow><msub><mi>b</mi><mi>i</mi></msub></mfrac><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mfrac><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\n\\subsubsection{Case 2: $\\theta = \\neg kL_i$}\nBy an entirely similar argument, we obtain\n\n", "itemtype": "equation", "pos": 25226, "prevtext": "\n\nand\n\n", "index": 35, "text": "\\begin{align*}\nE(\\lambda) & = \n\\begin{cases} \n(1 - (1-w)k )(1 -  \\frac{(1-w)kb_i}{||x - P_i||} ) & \\text{if }  (1 - w)k < 1\\\\\n0   & \\text{otherwise\\ }\n  \\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex44.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex44.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\begin{cases}(1-(1-w)k)(1-\\frac{(1-w)kb_{i}}{||x-P_{i}||})&amp;\\text%&#10;{if }(1-w)k&lt;1\\\\&#10;0&amp;\\text{otherwise\\ }\\end{cases}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow></mfrac></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>w</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>k</mi></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nand\n\n", "itemtype": "equation", "pos": 25493, "prevtext": "\n\n\\subsubsection{Case 2: $\\theta = \\neg kL_i$}\nBy an entirely similar argument, we obtain\n\n", "index": 37, "text": "\\begin{align*}\nE(\\alpha) & = \n\\begin{cases} \n\\frac{||x - P_i||}{b_i} + 1 - wk & \\text{if }  wk < 1\\\\\n\\frac{||x - P_i||}{wkb_i}   & \\text{otherwise\\ }\n  \\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex45.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\alpha)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex45.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\begin{cases}\\frac{||x-P_{i}||}{b_{i}}+1-wk&amp;\\text{if }wk&lt;1\\\\&#10;\\frac{||x-P_{i}||}{wkb_{i}}&amp;\\text{otherwise\\ }\\end{cases}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mfrac><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow><msub><mi>b</mi><mi>i</mi></msub></mfrac><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mrow><mi>w</mi><mo>\u2062</mo><mi>k</mi></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>k</mi></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mfrac><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow><mrow><mi>w</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></mfrac></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": " \n\nSo at each timestep, each listener agent, for whom $\\mu_\\theta(x) < w$, updates the relevant label using the the quantities $E(\\alpha)$, $E(\\lambda)$.\n\n\\subsection{Performance metrics}\nPerformance metrics from \\cite{ettie} are used, measuring the Average Pairwise Distance between label sets (APD) and the Average Label Overlap (ALO).  APD measures the difference in label sets in the community, and ALO indicates the extent to which an agent's concepts overlap. We seek low values for each metric.\n\nAPD is calculated using the Haussdorff distance between two neighbourhoods as given in equation \\ref{eq:hmet}. The difference between the label sets of any one pair of agents is given by\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\nand\n\n", "index": 39, "text": "\\begin{align*}\nE(\\lambda) & = \n\\begin{cases} \n(1 - wk )(1 -  \\frac{wkb_i}{||x - P_i||} ) & \\text{if }  wq < 1\\\\\n0   & \\text{otherwise\\ }\n  \\end{cases}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex46.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle E(\\lambda)\" display=\"inline\"><mrow><mi>E</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bb</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex46.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\begin{cases}(1-wk)(1-\\frac{wkb_{i}}{||x-P_{i}||})&amp;\\text{if }wq&lt;%&#10;1\\\\&#10;0&amp;\\text{otherwise\\ }\\end{cases}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>w</mi><mo>\u2062</mo><mi>k</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mi>w</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><mo fence=\"true\" maxsize=\"142%\" minsize=\"142%\">||</mo></mrow></mfrac></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>q</mi></mrow><mo>&lt;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nwhere $n$ is the number of labels each agent has and $j$ and $k$ refer to distinct agents.\n\nThis is averaged over pairs of agents. There are $N$ agents, therefore $\\binom{N}{2}$ pairs, giving:\n\n", "itemtype": "equation", "pos": 26528, "prevtext": " \n\nSo at each timestep, each listener agent, for whom $\\mu_\\theta(x) < w$, updates the relevant label using the the quantities $E(\\alpha)$, $E(\\lambda)$.\n\n\\subsection{Performance metrics}\nPerformance metrics from \\cite{ettie} are used, measuring the Average Pairwise Distance between label sets (APD) and the Average Label Overlap (ALO).  APD measures the difference in label sets in the community, and ALO indicates the extent to which an agent's concepts overlap. We seek low values for each metric.\n\nAPD is calculated using the Haussdorff distance between two neighbourhoods as given in equation \\ref{eq:hmet}. The difference between the label sets of any one pair of agents is given by\n\n", "index": 41, "text": "\n\\[\nIPD = \\sum_{i = 1}^n\\mathscr{H}(\\mathcal{N}_{L_i}^j, \\mathcal{N}_{L_i}^k)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex47.m1\" class=\"ltx_Math\" alttext=\"IPD=\\sum_{i=1}^{n}\\mathscr{H}(\\mathcal{N}_{L_{i}}^{j},\\mathcal{N}_{L_{i}}^{k})\" display=\"block\"><mrow><mrow><mi>I</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>D</mi></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi class=\"ltx_font_mathscript\">\u210b</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msub><mi>L</mi><mi>i</mi></msub><mi>j</mi></msubsup><mo>,</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><msub><mi>L</mi><mi>i</mi></msub><mi>k</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nALO is the extent to which labels overlap. To calculate this, we take the maximum value of the intersection of a pair of labels, as measured by a min rule. We average this value over pairs of labels. The overlap within an individual's label set is therefore\n\n", "itemtype": "equation", "pos": 26803, "prevtext": "\n\nwhere $n$ is the number of labels each agent has and $j$ and $k$ refer to distinct agents.\n\nThis is averaged over pairs of agents. There are $N$ agents, therefore $\\binom{N}{2}$ pairs, giving:\n\n", "index": 43, "text": "\n\\[\nAPD = \\frac{2}{N(N-1)}\\sum_{k = j + 1}^N\\sum_{j = 1}^N IPD_{jk}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex48.m1\" class=\"ltx_Math\" alttext=\"APD=\\frac{2}{N(N-1)}\\sum_{k=j+1}^{N}\\sum_{j=1}^{N}IPD_{jk}\" display=\"block\"><mrow><mrow><mi>A</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><mi>D</mi></mrow><mo>=</mo><mrow><mfrac><mn>2</mn><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>N</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>I</mi><mo>\u2062</mo><mi>P</mi><mo>\u2062</mo><msub><mi>D</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\n\nAveraged across the population this is:\n", "itemtype": "equation", "pos": 27133, "prevtext": "\n\nALO is the extent to which labels overlap. To calculate this, we take the maximum value of the intersection of a pair of labels, as measured by a min rule. We average this value over pairs of labels. The overlap within an individual's label set is therefore\n\n", "index": 45, "text": "\n\\[ \nILO = \\frac{2}{n(n-1)}\\sum_{j = i + 1} ^ n \\sum_{i = 1}^n max\\{min\\{\\mu_{L_i}(x),\\mu_{L_j}(x) : x \\in \\Omega \\}\\}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex49.m1\" class=\"ltx_Math\" alttext=\"ILO=\\frac{2}{n(n-1)}\\sum_{j=i+1}^{n}\\sum_{i=1}^{n}max\\{min\\{\\mu_{L_{i}}(x),\\mu%&#10;_{L_{j}}(x):x\\in\\Omega\\}\\}\" display=\"block\"><mrow><mrow><mi>I</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><mi>O</mi></mrow><mo>=</mo><mrow><mfrac><mn>2</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><mi>n</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>i</mi></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>\u03bc</mi><msub><mi>L</mi><mi>j</mi></msub></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>:</mo><mrow><mi>x</mi><mo>\u2208</mo><mi mathvariant=\"normal\">\u03a9</mi></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06755.tex", "nexttext": "\nwhere $ILO_k$ siginifies agent $k$'s label overlap.\n\n\\subsection{Simulation process}\n\\label{sec:simproc}\nSimulations with $n = 100$ agents were run for $T = 10^4$ timesteps. Agent weights $w \\in [0.2, 0.8]$ were updated at each timestep in increments of $1/T$. When $w \\geq 0.8$, agents are reborn with randomised labels and $w = 0.2$. 20 simulations are run for each reported combination of parameters.\n\n\\cite{ettie} show that if $pp \\in [0.5, 0.6]$ then performance of the system changes from low ALO and high APD to vice versa at approximately $pp = 0.56$. We ran simulations in a slightly extended range for comparison, varying the prior probabilities $pv$, $pb$ and $pq$ of asserting the different hedges `very', `basic', and `quite'. We present results from three sets of parameters. As a baseline we run simulations with no hedges, i.e. $pv = 0$, $pb = 1$, $pq = 0$. To investigate the effects of using contraction hedges, we run simulations with parameters $pv = 0.7$, $pb = 0.2$, $pq = 0.1$. For expansion hedges, we use parameters $pv = 0.1$, $pb = 0.2$, $pq = 0.7$.\n\n\\section{RESULTS}\n\\label{sec:results}\nThe results presented show performance against the two metrics after $10^4$ simulation timesteps. By this point, the population has generally reached a steady state in which performance does not greatly change.  \n\nFigure \\ref{fig:cmpAPDI} shows the steady state of APD achieved after $10^4$ timesteps for a range of values $pp \\in [0.4, 0.6]$. Three sets of results are presented: results using unhedged assertions; results with a high prior probability of using contraction hedges; and results from simulations with a high prior probability of asserting expansion hedges, where these prior probabilities are as stated in \\ref{sec:simproc}.\n\nA high prior of asserting contracted labels reduces minimum APD achieved from $0.38$ when $pp=0.56$ or $pp = 0.6$ to  $0.29$ when $pp=0.57$ (figure \\ref{fig:cmpAPDI}). Performing a paired t-test across the 20 simulations gives the mean difference between these values as $0.097$. This difference is statistically significant with $p < 0.001$ and with 95\\% confidence interval $[0.084, 0.110]$. The median and range of results are given in figure \\ref{fig:chAPDI}. At $pp=0.57$, ALO decreases, from $0.92$ to $0.89$ (figure \\ref{fig:cmpALOP}). The mean value of this difference across the 20 simulations is $0.032$. Again, this is statistically significant with  $p < 0.001$ and 95\\% confidence interval of $[0.029, 0.035]$, further illustrated in figure \\ref{fig:chALOP}. These results imply that a high prior probability of asserting contraction hedges enables us to improve convergence between agents' label sets as well as reducing overlap within label sets slightly.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{cmpAPDIkx.pdf}\n\\caption{APD after $10^4$ timesteps. Using contraction hedges reduces the minimum APD achieved from $0.38$ at $pp = 0.56$ to $0.29$ at $pp = 0.57$. Expansion hedges reduce APD from $0.85$ to $0.73$ at $pp =0.45$}\n\\label{fig:cmpAPDI}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{chAPDI.pdf}\n\\caption{Using contraction hedges reduces minimum APD. Box and whisker plot of APD after $10^4$ timesteps for 20 simulations, for $pp = 0.56$ unhedged, $pp = 0.57$ with a high probability of contraction hedges (values of $pp$ at which minimum APD is achieved). The middle line shows median value, the box shows the 25th and 75th percentile. Whiskers show the range of data excluding outliers, and crosses show outliers.}\n\\label{fig:chAPDI}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{chALOP.pdf}\n\\caption{Using contraction hedges slightly reduces ALO. Box and whisker plot of ALO after $10^4$ timesteps for 20 simulations, for $pp = 0.57$. The middle line shows median value, the box shows the 25th and 75th percentile. Whiskers show the range of data excluding outliers, and crosses show outliers.}\n\\label{fig:chALOP}\n\\end{figure}\n\nWith a high prior probability of asserting expanded labels, lower values of ALO can be achieved when the probability of asserting positive labels is $0.45$ , decreasing to $0.02$ compared to $0.1$, figure \\ref{fig:cmpALOP}. The mean difference between these values across the 20 simulations is 0.083, which is statistically significant with $p < 0.001$ and a 95\\% confidence interval of $[0.078, 0.089]$. The data is represented in figure \\ref{fig:ehALOP}. At this value of $pp$, APD achieved is $0.73$ compared to $0.85$ for unhedged assertions, figure \\ref{fig:cmpAPDI}. The mean value of this difference across the 20 simulations is $0.12$. This figure is statistically significant with $p < 0.001$ and 95\\% confidence interval $[0.116, 0.126]$. The data is again represented in figure \\ref{fig:ehAPDI}.  A high prior probability of asserting expansion hedges therefore enables minimal overlap to be maintained at low $pp$ whilst improving convergence. \n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{cmpALOPkx.pdf}\n\\caption{Contraction hedges slightly reduce high levels of ALO. At $pp = 0.57$, ALO is reduced from $0.92$ to $0.89$. Expansion hedges reduce minimum ALO  from $0.1$ for unhedged assertions to $0.02$ for expansion hedged assertions, at $pp = 0.45$.}\n\\label{fig:cmpALOP}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{ehAPDI.pdf}\n\\caption{Expansion hedges reduce maximum APD. Box and whisker plot of APD after $10^4$ timesteps for 20 simulations, for $pp = 0.45$.  The middle line shows median value, the box shows the 25th and 75th percentile. Whiskers show the range of data excluding outliers, and crosses show outliers.}\n\\label{fig:ehAPDI}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{ehALOP.pdf}\n\\caption{Expansion hedges reduce minimum ALO. Box and whisker plot of ALO after $10^4$ timesteps for 20 simulations, for $pp = 0.45$. The middle line shows median value, the box shows the 25th and 75th percentile. Whiskers show the range of data excluding outliers, and crosses show outliers.}\n\\label{fig:ehALOP}\n\\end{figure}\n\nWe can also examine how fast the community of agents arrives at a steady state. Figure \\ref{fig:APDI56} shows that at short timescales ($t < 2000$), better convergence may be achieved allowing only unhedged assertions. In a more extreme case, figure \\ref{fig:ALOP05} shows that for $pp = 0.5$, better performance on the ALO metric is only achieved after $7500$ timesteps. Although this improvement takes a longer time to achieve, it goes together with improved performance on APD which is achieved in a similar timescale to the unhedged model \\ref{fig:APDI05}.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{APDI56.pdf}\n\\caption{APD vs time for models with no hedged assertions, contracted assertions and expanded assertions, for a prior probability of positive assertions $pp = 0.56$. Although the final value reached is lower when there is a high probability of making contracted assertions, the community of agents takes longer to reach that value. }\n\\label{fig:APDI56}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{ALOP05.pdf}\n\\caption{ALO vs time for models with no hedged assertions, contracted assertions and expanded assertions, for a prior probability of positive assertions $pp = 0.5$. Although the final value reached is lower when there is a high probability of using expansion hedges, the community of agents takes longer to reach that value, and may even reach a lower value still. }\n\\label{fig:ALOP05}\n\\end{figure}\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width = 0.35\\textwidth]{APDI05.pdf}\n\\caption{APD vs time for models with no hedged assertions, contracted assertions and expanded assertions, for a prior probability of positive assertions $pp = 0.5$. Lower APD is achieved with a high prior probability of asserting expansion hedges, in a similar timescale to the unhedged model}\n\\label{fig:APDI05}\n\\end{figure}\n\n\\section{DISCUSSION}\n\\label{sec:discussion}\nThese results show that, in a model of language development across a population, hedged assertions can improve both the level of convergence to shared language as measured by average pairwise difference between label sets (APD) and, to an extent, the discriminatory power of individuals' label sets, as measured by average label overlap (ALO). The two different types of hedges improve performance in distinct ways. If overall convergence is important, a high prior probability of asserting contraction hedges should be used to improve performance on the APD metric. Conversely, if the ability of the agents to discriminate precisely between objects in the environment is more important, then expansion hedges, together with lower probabilities of asserting positive labels, should be used to maintain low levels of ALO whilst still improving performance on APD. \n\nThe improved performance against the two metrics is tempered by the fact that the speed at which the steady state is achieved is somewhat slower than when using simply unhedged assertions. However, the improvement in APD is seen relatively quickly at $pp = 0.56$, soon after the unhedged model has reached its steady state. The improvement in ALO when using expansion hedges, for $pp = 0.5$, does not occur until after $7,500$ timesteps, well after the unhedged model  has reached its steady state. However, the improvement in performance on ALO goes together with improved performance on APD which is attained at the same speed as the in the unhedged model.\n\nIf the speed of development of shared categories is not important, the two types of hedges would be useful in different types of situation, depending whether convergence or discriminatory power is more important. This might be dependent on, for example, the structure of the underlying environment. In the current simulation, objects are presented uniformly across the space. If objects were distributed non-uniformly, perhaps clumping in various regions of the space, then perhaps the ability to discriminate precisely between different labels would be less important, since the environment provides that distinction naturally. Convergence to shared labels would then be more important.\n\nIf speed is important, using contraction hedges can still improve levels of convergence in a relatively short timeframe.\n\nThere are many parameters in the simulation that bear further investigation. The distribution of objects in the environment, as mentioned above, is likely to have an effect on performance again the two metrics. In the current simulations, hedge values of $v = 0.5$ and $h = 2$ are used. Increasing and decreasing these values could have an impact on performance, as would, perhaps, allowing agents to have difference values of $v$ and $h$. The range of $w$ allowed also affects performance. When $w = [0.01, 0.99]$, agents no longer achieve high levels of convergence at $pp > 0.55$ (results not shown). Other weight ranges may positively affect performance, however.\n\n\\section{CONCLUSIONS}\n\\label{sec:conc}\nWe have investigated the utility of hedged assertions in the development of a shared language, and shown that allowing agents to make hedged assertions improves the ability to develop common categories in two distinct ways. Firstly, using contraction hedges, i.e. words like `very', allows improved levels of convergence to shared categories, whilst slightly improving the extent to which labels overlap. Secondly, using expansion hedges, or words like `quite', enables the development of label sets that are more discriminatory of the environment and also have better levels of convergence. However, both these improvements come with a slower speed of development of shared labels. It may be possible to improve these speeds by tuning other parameters such as the age range of agents or the values of hedges used.\n\n\\ack\nMartha Lewis gratefully acknowledges support from EPSRC Grant No. EP/E501214/1\n\n\\bibliography{../phd}\n\n\n", "itemtype": "equation", "pos": 27295, "prevtext": "\n\nAveraged across the population this is:\n", "index": 47, "text": "\n\\[\nALO = \\frac{1}{N}\\sum_{k = 1}^N ILO_k\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex50.m1\" class=\"ltx_Math\" alttext=\"ALO=\\frac{1}{N}\\sum_{k=1}^{N}ILO_{k}\" display=\"block\"><mrow><mrow><mi>A</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><mi>O</mi></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>I</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><msub><mi>O</mi><mi>k</mi></msub></mrow></mrow></mrow></mrow></math>", "type": "latex"}]