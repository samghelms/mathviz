[{"file": "1601.03516.tex", "nexttext": "\nHere $p_{j}(t)$ denotes the probability of a walker to be present on node $j$ at time $t$; $A_{ij}$ is the weight of the link from node $i$ to node $j$, i.e., $A$ is the (weighted) adjacency matrix; finally, $k_j^{\\rm out}$ is the weighted out-degree of node $j$.\n\nClearly this dynamics is driven by the normalised Laplacian matrix $L$, defined as $L_{ij} = - \\delta_{ij} + A_{ij}/k_i^{\\rm out}$.\nThe Perron-Froebenius theorem guarantees that a unique stationary solution exist for the above dynamics if the network is strongly connected.\nFor an undirected network, this stationary solution is $\\pi_j=k_j/2M$, where $k_j=k_j^{\\rm out} = k_j^{\\rm in}$ is the node degree and $M$ is the total weight of the undirected links. \nFor a general directed network the stationary solution is given by the dominant (left) eigenvector of $L$, which depends on the global network properties and cannot be expressed by a simple analytical formula. \n\n\\paragraph*{Making the dynamics ergodic (when it is not).}\n\\label{ergodic} \n\nNote that for the continuous-time random walk defined above, a strongly connected graph implies an unique stationary distribution and an ergodic dynamics.\nThese criteria are a common requirement for dynamics-based methods for network analysis \\cite{Delvenne2010,Rosvall2008}.\nHowever, in a majority of real-world systems the system contains not just one but several strongly connected components (SCCs), whose sizes typically have different orders of magnitude.\nA standard solution is to address this issue by either neglecting some nodes and focusing only on the largest SCC only, or by making the system strongly connected through random teleportations \\cite{Lambiotte2012}. \nThe first solution has the advantage of not distorting the dynamics, while the second allows for the analysis of the whole system. \nWhen analyzing real-world systems in the following, we will for these reasons use the first solution if the vast majority of nodes belongs to the largest SCC, while we will opt for the second solution if the system comprises a large number of disconnected components. \n\n\\subsection{Community structure from a dynamical viewpoint}\nThe structure of a network has a strong effect on the dynamics of a diffusing random walker: in unstructured (random) networks, the diffusion process will evolve almost isotropically and the walker will quickly reach its stationary distribution.\nHowever, if the network contains structure, a walker can get trapped inside a group of nodes for a time far longer than expected. \nSuch groups of nodes thus constitute flow-retaining, \\textit{dynamical communities} in the network.\nHence a random walk dynamics can effectively be used to define a quality function for a network partition based on the persistence of the diffusion inside the groups.\nBy optimising such a quality function, we can therefore search for a modular partition of the network.\nImportant examples for such an approach include the map equation \\cite{Rosvall2008} and the Markov stability framework \\cite{Delvenne2010}, which we consider in this paper.\nNote that, as highlighted in Refs. \\cite{Rosvall2008,Schaub2012} this notion of community is markedly different to the commonly considered structural viewpoint of communities, in that we are interested in flow-retaining, rather than densely (homogeneously) connected substructures.\n\nThe Markov stability of a partition $\\mathcal{P}$ is defined as:\n\n", "itemtype": "equation", "pos": 10427, "prevtext": "\n\n\\title{Using higher-order Markov models to reveal flow-based communities in networks}\n\n\n\\author{Vsevolod Salnikov}\n\\email[E-mail: ]{vsevolod.salnikov@unamur.be}\n\\affiliation{naXys, University of Namur, Rempart de la Vierge 8, 5000 Namur, Belgium}\n\\author{Michael T. Schaub}\n\\email[E-mail: ]{michael.schaub@unamur.be}\n\\affiliation{naXys, University of Namur, Rempart de la Vierge 8, 5000 Namur, Belgium}\n\\affiliation{ICTEAM, Universit\\'e catholique de Louvain, Avenue George Lema\\^itre 4, B-1348 Louvain-la-Neuve, Belgium}\n\\author{Renaud Lambiotte}\\email[E-mail: ]{renaud.lambiotte@unamur.be}\n\\affiliation{naXys, University of Namur, Rempart de la Vierge 8, 5000 Namur, Belgium}\n\n\\begin{abstract}\nComplex systems made of interacting elements are commonly abstracted as networks, in which nodes are associated with dynamic state variables, whose evolution is driven by interactions mediated by the edges. \nMarkov processes have been the prevailing paradigm to model such a network-based dynamics, for instance in the form of random walks or other types of diffusions.\nDespite the success of this modelling perspective for numerous applications, it represents an over-simplification of several real-world systems. \nImportantly, simple Markov models lack memory in their dynamics, an assumption often not realistic in practice.\nHere, we explore possibilities to enrich the system description by means of second-order Markov models, exploiting empirical pathway information.\nWe focus on the problem of community detection and show that standard network algorithms can be generalized in order to extract novel temporal information about the system under investigation. \nWe also apply our methodology to temporal networks, where we can uncover communities shaped by the temporal correlations in the system.\nFinally, we discuss relations of the framework of second order Markov processes and the recently proposed formalism of using non-backtracking matrices for community detection.\n\\end{abstract}\n\n\\maketitle\n\n\n\\section{Introduction}\nDynamics on complex networks, such as the diffusion of information in a social networks, are commonly modelled as Markov processes.\nAn advantage of this approach is that for every (static) network with positive edge-weights we can define a corresponding Markov process by interpreting the network as the state space of a random walker, and assigning the state-transition probabilities according to the link weights.\nThis direct correspondence between the state space of the Markov process and the network enables us to examine the interplay between structure and dynamics from two sides.\nOn the one hand, one can assess how the topological properties of a network influence the dynamical process.\nOn the other hand, this coupling between topology and dynamics allows us to explore the structure of a network by means of a dynamical process. \nSpecifically, for a linear Markov process the impact of the network structure on the dynamics will be mediated by the spectral properties of the matrix governing the time-evolution of the process, e.g. the adjacency matrix or the Laplacian \\cite{Newman2010, Lambiotte2015}.\nReversely, spectral properties can be used to uncover salient structural properties of a network, such as modular organisation \\cite{Delvenne2010,Schaub2012,Newman2013}.\n\nWhile simple Markov models have been very successful in modelling dynamics of complex systems and found many applications, they have one obvious disadvantage.\nIn this class of models, the future state of the system only depends on its current state and does not account for its history. \nIn a diffusion process, for instance, the next position of a random walker only depends on the currently occupied node and its outgoing links, but not on any of the previously visited nodes. \nHowever, as it has been emphasised recently, for a broad range of networked systems, flows tend to exhibit a temporal path dependence \\cite{Rosvall2014,Scholtes2014}. \nThink of human mobility: the places a person is likely to visit next, often depend strongly on where the person came from.\nFor instance, a person coming to work from home is likely to return home afterwards \\cite{Song2010}.\nOther examples of processes with temporal memory include web traffic, journal citation flows and email cascades.\nSuch processes therefore cannot be reproduced accurately by simple Markov models.\nHowever, the impact of this temporal correlations can often be well-approximated already by second-order Markov ($\\mathcal{M}_2$) models \\cite{Rosvall2014}.\n\nImportantly, the transition probabilities to define these models can be obtained empirically by measuring pathways of interaction cascades, rendering such an approach suitable for applications like information spreading or human mobility.\n\nIn the standard Markovian network model ($\\mathcal{M}_1$), the elementary states are identified with the nodes of the original network (see Figure \\ref{fig1}).\nIn the $\\mathcal{M}_2$ model, elementary states correspond to sequences of two nodes, and thus can be identified with \\textit{directed edges} in the original network (see Figure \\ref{fig1}).\nTherefore we may think of a $\\mathcal M_2$ model alternatively as a random walk between directed edges of the original network.\nThe state space of the $\\mathcal{M}_2$ model defines a new network describing the observed dynamics, which we call here the $\\mathcal{M}_2$ or memory network. \nThe structural properties of the memory network can now be studied by many tools of network science, allowing us to uncover interesting patterns of flow in an $\\mathcal{M}_2$ model.  \n\n\\begin{figure}\n\\includegraphics{Figure1.eps}\n\\caption{\\textbf{Schematic -- dynamics on networks as Markov processes}. A process on a physical network (left) may be abstracted in a number of different ways -- often this is done via a Markov model. In a first order Markov model $\\mathcal{M}_1$ (right side, top panel), the state space is isomorphic to the physical network: every node corresponds to one state, every link indicates a transition between those states. In a second order Markov model the state space is structured like a \\textit{directed line-graph} of the original network. The states in this $\\mathcal M_2$ network can be identified with the directed edges in the original network and are connected if it is possible to traverse from one edge to another edge in  the original directed network. Note that, when projecting back these $\\mathcal M_2$ dynamics onto the physical network, the probability to move from one node to another will thus appear non-Markovian.}\n\\label{fig1}\n\\end{figure}\n\nThe purpose of this paper is to highlight how the formalism of higher order Markov models provides a simple means to extend network theoretic tools to take into account important dynamical properties as encoded in the $\\mathcal{M}_2$ representation.\nIndeed many network theoretic tools may be understood as the outcome of a matrix iteration or eigenvector computation \\cite{Estrada2010}, which can be naturally associated to a dynamical process.\n\nIn this paper we focus on the problem of community detection, though higher-order models can be equally applied to other problems, including the assessment of node centralities \\cite{Estrada2010,Rosvall2014} or the speedup (or slowdown) of spreading processes \\cite{Scholtes2014}. \nWhile Ref. \\cite{Rosvall2008} discussed how the map equation can account for higher-order flows in community detection, here our main example will be the Markov stability \\cite{Delvenne2010,Delvenne2013,Lambiotte2014} formalism, as it incorporates many commonly used community detection measures as special cases, notably, the concept of Modularity \\cite{Newman2006}, diverse Potts models \\cite{Reichardt2004}, and spectral clustering \\cite{Fiedler1975,Shi2000}.\nWe thereby highlight that all these classical algorithms can indeed be naturally generalised to account for memory effects by using $\\mathcal M_2$ networks, showing that these representations provide a general tool for the analysis of a dynamics occuring on a latent network structure. \nMoreover, as spectral clustering can be shown to be a special case of the Markov Stability formalism for long times, we can draw further connections to recently proposed techniques of graph partitioning based on non-backtracking random walks \\cite{Krzakala2013}, and discuss how these can be understood from the point of view of second order Markov processes.\nWe remark that as clustering an $\\mathcal{M}_2$ network is equivalent to finding a partition of the edges of the original system, it naturally leads to the detection of overlapping communities in the same way as the analysis of line graphs~\\cite{Evans2009}.\nThis can be a highly desirable feature, especially when analysing social networks, which tend to be organised in overlapping social circles \\cite{Friggeri2011,Ahn2010}.\n\nThe remainder of this article is organised as follows. \nInitially, we review the Markov stability formalism for community detection, a general framework to detect flow-based communities in complex networks, and particularly emphasise its properties in the case of directed networks \\cite{Lambiotte2015}. \nWe show how this quality function can be naturally generalised for the analysis of $\\mathcal{M}_2$ networks, which we illustrate by studying a flight network of the United States from the perspective of second order Markov models.\nIn this context, we also discuss the possibility to generate realistic pathway data using models of second-order Markov processes, even if only time aggregated network information is available.\nSubsequently, we propose a mechanism to extract pathway statistics to build second-order models from event-based, temporal network data, which do not contain pathway statistics \\textit{a priori}.\nUsing computer-generated data and time-resolved interactions records of school-children, we demonstrate how we can uncover communities which capture important flow-constraints imposed by the temporal activation patterns of the links.\nFinally, we draw connections between the $\\mathcal M_2$ network representation and non-backtracking random walks to uncover communities in sparse networks. \n\n\n\\section{Markov Dynamics and Community detection}\n\n\\subsection{Random walks on directed networks}\nLet us consider a continuous-time random walk on a network with $N$ nodes, governed by the following Kolmogorov forward equation:\n\n", "index": 1, "text": "\\begin{equation}\n\\label{ctrw}\n\\dot{p}_{j}(t) = - p_j(t) + \\sum_{i} p_{i}(t) \\frac{A_{ij}}{k_i^{\\rm out}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\dot{p}_{j}(t)=-p_{j}(t)+\\sum_{i}p_{i}(t)\\frac{A_{ij}}{k_{i}^{\\rm out}}.\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>p</mi><mo>\u02d9</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>-</mo><mrow><msub><mi>p</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mfrac><msub><mi>A</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msubsup><mi>k</mi><mi>i</mi><mi>out</mi></msubsup></mfrac></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nwhere $P(C,t)$ is the probability for a walker to be in community $C$ initially and at time $t$, for a system at stationarity.\nNote that as all information about the initial position is lost after infinite time, $P(C,\\infty)$ also describes the probability of two independent walkers to be in $C$. \n\n\nFor the process \\eqref{ctrw}, the Markov stability quality function can be written explicitly as:\n\n", "itemtype": "equation", "pos": 13969, "prevtext": "\nHere $p_{j}(t)$ denotes the probability of a walker to be present on node $j$ at time $t$; $A_{ij}$ is the weight of the link from node $i$ to node $j$, i.e., $A$ is the (weighted) adjacency matrix; finally, $k_j^{\\rm out}$ is the weighted out-degree of node $j$.\n\nClearly this dynamics is driven by the normalised Laplacian matrix $L$, defined as $L_{ij} = - \\delta_{ij} + A_{ij}/k_i^{\\rm out}$.\nThe Perron-Froebenius theorem guarantees that a unique stationary solution exist for the above dynamics if the network is strongly connected.\nFor an undirected network, this stationary solution is $\\pi_j=k_j/2M$, where $k_j=k_j^{\\rm out} = k_j^{\\rm in}$ is the node degree and $M$ is the total weight of the undirected links. \nFor a general directed network the stationary solution is given by the dominant (left) eigenvector of $L$, which depends on the global network properties and cannot be expressed by a simple analytical formula. \n\n\\paragraph*{Making the dynamics ergodic (when it is not).}\n\\label{ergodic} \n\nNote that for the continuous-time random walk defined above, a strongly connected graph implies an unique stationary distribution and an ergodic dynamics.\nThese criteria are a common requirement for dynamics-based methods for network analysis \\cite{Delvenne2010,Rosvall2008}.\nHowever, in a majority of real-world systems the system contains not just one but several strongly connected components (SCCs), whose sizes typically have different orders of magnitude.\nA standard solution is to address this issue by either neglecting some nodes and focusing only on the largest SCC only, or by making the system strongly connected through random teleportations \\cite{Lambiotte2012}. \nThe first solution has the advantage of not distorting the dynamics, while the second allows for the analysis of the whole system. \nWhen analyzing real-world systems in the following, we will for these reasons use the first solution if the vast majority of nodes belongs to the largest SCC, while we will opt for the second solution if the system comprises a large number of disconnected components. \n\n\\subsection{Community structure from a dynamical viewpoint}\nThe structure of a network has a strong effect on the dynamics of a diffusing random walker: in unstructured (random) networks, the diffusion process will evolve almost isotropically and the walker will quickly reach its stationary distribution.\nHowever, if the network contains structure, a walker can get trapped inside a group of nodes for a time far longer than expected. \nSuch groups of nodes thus constitute flow-retaining, \\textit{dynamical communities} in the network.\nHence a random walk dynamics can effectively be used to define a quality function for a network partition based on the persistence of the diffusion inside the groups.\nBy optimising such a quality function, we can therefore search for a modular partition of the network.\nImportant examples for such an approach include the map equation \\cite{Rosvall2008} and the Markov stability framework \\cite{Delvenne2010}, which we consider in this paper.\nNote that, as highlighted in Refs. \\cite{Rosvall2008,Schaub2012} this notion of community is markedly different to the commonly considered structural viewpoint of communities, in that we are interested in flow-retaining, rather than densely (homogeneously) connected substructures.\n\nThe Markov stability of a partition $\\mathcal{P}$ is defined as:\n\n", "index": 3, "text": "\\begin{equation}\nR(t,\\mathcal P) =\\sum_{C \\in \\mathcal{P}}  P(C,t) - P(C,\\infty)\n\\label{eq:modDeff}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"R(t,\\mathcal{P})=\\sum_{C\\in\\mathcal{P}}P(C,t)-P(C,\\infty)\" display=\"block\"><mrow><mrow><mi>R</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>C</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi></mrow></munder><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>C</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>C</mi><mo>,</mo><mi mathvariant=\"normal\">\u221e</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nwhere $e^{t L} $ denotes the matrix exponential.\nIntuitively, with increasing time the walker will be able to explore larger and larger parts of the graph. \nThe larger the time, the larger the modules that will be found in general.\nBy `zooming' through different Markov times one can thus reveal adequate scales of robust community structure, which manifest themselves as plateaux in time where the same partitions are found consistently \\cite{Schaub2012,Delmotte2011}.\nIn the limit $t \\rightarrow \\infty$, it can be shown by eigenvalue decomposition that $R(t,\\mathcal P)$ is  maximised by a bi-partition in accordance with the normalised Fiedler eigenvector, a classic method in spectral clustering~\\cite{Shi2000}. \nInterestingly, the expression for Markov stability can be rewritten as the Newman-Girvan modularity \\cite{Newman2006} of a \\textit{different} network, whose adjacency matrix is given by\n\n", "itemtype": "equation", "pos": 14483, "prevtext": "\nwhere $P(C,t)$ is the probability for a walker to be in community $C$ initially and at time $t$, for a system at stationarity.\nNote that as all information about the initial position is lost after infinite time, $P(C,\\infty)$ also describes the probability of two independent walkers to be in $C$. \n\n\nFor the process \\eqref{ctrw}, the Markov stability quality function can be written explicitly as:\n\n", "index": 5, "text": "\\begin{equation}\n\\label{Rt}\nR(t,\\mathcal P) =   \\sum_{C \\in \\mathcal P} \\sum_{i,j \\in C} \\left[ \\pi_i \\left( e^{t L} \\right)_{ij}  - \\pi_i \\pi_j \\right],\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"R(t,\\mathcal{P})=\\sum_{C\\in\\mathcal{P}}\\sum_{i,j\\in C}\\left[\\pi_{i}\\left(e^{tL%&#10;}\\right)_{ij}-\\pi_{i}\\pi_{j}\\right],\" display=\"block\"><mrow><mrow><mrow><mi>R</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>C</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi></mrow></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>\u2208</mo><mi>C</mi></mrow></munder><mrow><mo>[</mo><mrow><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mrow><mo>(</mo><msup><mi>e</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>L</mi></mrow></msup><mo>)</mo></mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>-</mo><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>\u03c0</mi><mi>j</mi></msub></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nHere $\\pi_i \\left( e^{t L} \\right)_{ij}$ is the flow of probability from $i$ to $j$ after a time interval $t$ at stationarity. \nIn this new network $Y$, the weight of a connection between two nodes is thus modulated according to its importance for the diffusion dynamics.  \nThis rewriting of Markov stability as the modularity of a different network opens the possibility to use any modularity based algorithm for the optimization of stability, too.\nFor the results in the present manuscript, we have made use of the Louvain algorithm \\cite{Blondel2008}, a fast greedy optimisation heuristic that has been shown to have a good performance in the literature.\n\nIn practice, it can be more efficient to consider (\\ref{Rt}) in the limit of small times $t \\rightarrow 0$. \nPerforming a Taylor expansion and keeping only linear terms in $t$, results in the linearised Markov stability:\n\n", "itemtype": "equation", "pos": 15556, "prevtext": "\nwhere $e^{t L} $ denotes the matrix exponential.\nIntuitively, with increasing time the walker will be able to explore larger and larger parts of the graph. \nThe larger the time, the larger the modules that will be found in general.\nBy `zooming' through different Markov times one can thus reveal adequate scales of robust community structure, which manifest themselves as plateaux in time where the same partitions are found consistently \\cite{Schaub2012,Delmotte2011}.\nIn the limit $t \\rightarrow \\infty$, it can be shown by eigenvalue decomposition that $R(t,\\mathcal P)$ is  maximised by a bi-partition in accordance with the normalised Fiedler eigenvector, a classic method in spectral clustering~\\cite{Shi2000}. \nInterestingly, the expression for Markov stability can be rewritten as the Newman-Girvan modularity \\cite{Newman2006} of a \\textit{different} network, whose adjacency matrix is given by\n\n", "index": 7, "text": "\\begin{equation}\nY_{ij}=\\dfrac{1}{2}\\left[\\pi_i \\left( e^{t L} \\right)_{ij} +\\pi_j \\left( e^{t L} \\right)_{ji}\\right].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"Y_{ij}=\\dfrac{1}{2}\\left[\\pi_{i}\\left(e^{tL}\\right)_{ij}+\\pi_{j}\\left(e^{tL}%&#10;\\right)_{ji}\\right].\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mrow><mo>(</mo><msup><mi>e</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>L</mi></mrow></msup><mo>)</mo></mrow><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>+</mo><mrow><msub><mi>\u03c0</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mrow><mo>(</mo><msup><mi>e</mi><mrow><mi>t</mi><mo>\u2062</mo><mi>L</mi></mrow></msup><mo>)</mo></mrow><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nNote that for an \\textit{undirected} network, we have $\\pi_i=k_i/2M$ and $k_i^{\\rm out}=k_i$, and one recovers the modularity of the original network for $t=1$ as well as the Potts-model heuristic \\cite{Reichardt2004} for other Markov times (see \\cite{Delvenne2010,Delvenne2013} for details).\nHowever, for \\textit{directed} networks \\eqref{Qt} is not equivalent to the directed modularity of the original network, but is given by:\n\n", "itemtype": "equation", "pos": 16570, "prevtext": "\nHere $\\pi_i \\left( e^{t L} \\right)_{ij}$ is the flow of probability from $i$ to $j$ after a time interval $t$ at stationarity. \nIn this new network $Y$, the weight of a connection between two nodes is thus modulated according to its importance for the diffusion dynamics.  \nThis rewriting of Markov stability as the modularity of a different network opens the possibility to use any modularity based algorithm for the optimization of stability, too.\nFor the results in the present manuscript, we have made use of the Louvain algorithm \\cite{Blondel2008}, a fast greedy optimisation heuristic that has been shown to have a good performance in the literature.\n\nIn practice, it can be more efficient to consider (\\ref{Rt}) in the limit of small times $t \\rightarrow 0$. \nPerforming a Taylor expansion and keeping only linear terms in $t$, results in the linearised Markov stability:\n\n", "index": 9, "text": "\\begin{equation}\n\\label{Qt}\nQ(t) =   (1-t) +  \\sum_C \\sum_{i,j \\in C} \\biggl[ t  \\frac{\\pi_iA_{ij}}{k_i^{\\rm out}}   - \\pi_i \\pi_j \\biggr].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"Q(t)=(1-t)+\\sum_{C}\\sum_{i,j\\in C}\\biggl{[}t\\frac{\\pi_{i}A_{ij}}{k_{i}^{\\rm out%&#10;}}-\\pi_{i}\\pi_{j}\\biggr{]}.\" display=\"block\"><mrow><mrow><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>C</mi></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>\u2208</mo><mi>C</mi></mrow></munder><mrow><mo maxsize=\"210%\" minsize=\"210%\">[</mo><mrow><mrow><mi>t</mi><mo>\u2062</mo><mfrac><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>A</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><msubsup><mi>k</mi><mi>i</mi><mi>out</mi></msubsup></mfrac></mrow><mo>-</mo><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>\u03c0</mi><mi>j</mi></msub></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">]</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nInterestingly, similar adjusted adjacency (or Laplacian) matrices have been proposed as means for community detection in the literature based on different reasoning~\\cite{Chung2005,Satuluri2011}.\n\nNote that, as with all applications of unsupervised algorithms, care is needed when interpreting the results. \nFor instance, the optimisation of Markov Stability for a fixed Markov time inherits the limitations of modularity maximisation, such as a resolution limit \\cite{Fortunato2006}, and a high degeneracy of optimial solutions  \\cite{Good2010}. \nNevertheless, this class of method has been applied successfully in numerous applications \\cite{Fortunato2010}. \nIndeed, some of these problems can be circumvented by carefully sweeping through different resolution parameters \\cite{Schaub2012,Schaub2012b} and finding partitions that are robust over a range of parameters \\cite{Schaub2012,Delmotte2011,Lambiotte2014,Lambiotte2010}.\nMost importantly, however, the notion of community inherent to the methods presented here is based on flows \\cite{Delvenne2010,Schaub2012,Rosvall2008}.\nThis is in contrast to methods like stochastic blockmodels (SBM), see e.g. Ref. \\cite{Holland1983,Karrer2011,Peixoto2014}, which employ a generative model for the whole network and aim at finding patterns of pairwise connections in the system, though very recent work aims to incorporate dynamical aspects within the SBM framework~\\cite{Peixoto2015}.\n\n\n\\section{Dynamical community detection using higher-order Markov models}\n\\subsection{From first to second order Markov models}\nLet us now show how we can incorporate second-order Markov models into the Markov stability framework.\nAs higher-order Markov models provide more faithful representations of the dynamics observed in real world systems, this enables us to capture more of the real flow constraints in the uncovered communities.  \nFor simplicity let us initially consider undirected networks composed of $N$ nodes and $M$ links.\nThe dynamics of a second order Markov process are encoded by the transition matrix $T({\\overrightarrow{ {ij}}} \\rightarrow {\\overrightarrow{ {jk}}})$,\nwhich describes the probability that a walker moves from node $j$ to node $k$ if it came from $i$ in the previous step.\nBy definition, this transition matrix is normalised such that $\\sum_k T({\\overrightarrow{ {ij}}} \\rightarrow {\\overrightarrow{ {jk}}}) = 1$. \n\nAs sequences of two vertices in our original network correspond to the nodes in the $\\mathcal M_2$ network, the entries in $T$ describe precisely the transitions from $\\mathcal{M}_2$-node ${\\overrightarrow{ {ij}}}$ to $\\mathcal{M}_2$-node ${\\overrightarrow{ {jk}}}$.\nThe (second-order) $\\mathcal M_2$ process on the original network is thus equivalent to a first-order Markov process, albeit on a different network: namely, the $\\mathcal{M}_2$ network composed of $2M$ nodes.\nAs each undirected link of the original network can be traversed in two distinct directions (from $i$ to $j$, and vice versa) it accounts for 2 nodes in the $\\mathcal{M}_2$ network, ${\\overrightarrow{ {ij}}}$ and ${\\overrightarrow{ {ji}}}$. \nThis implies that the $\\mathcal M_2$ network is \\textit{directed} even if the original network is undirected.\nTo see this, observe that if $k\\neq i$, there cannot be a link between ${\\overrightarrow{ {jk}}}$ and ${\\overrightarrow{ {ij}}}$, even if a transition between ${\\overrightarrow{ {ij}}}$ and ${\\overrightarrow{ {jk}}}$ exists. \nHenceforth we use Greek letters to denote $\\mathcal{M}_2$ nodes, and Latin characters to denote the nodes in the original $\\mathcal{M}_1$ network.\n\nSimilarly to (\\ref{ctrw}), we can define a continuous-time random walk on the $\\mathcal{M}_2$ network as:\n\n", "itemtype": "equation", "pos": 17156, "prevtext": "\nNote that for an \\textit{undirected} network, we have $\\pi_i=k_i/2M$ and $k_i^{\\rm out}=k_i$, and one recovers the modularity of the original network for $t=1$ as well as the Potts-model heuristic \\cite{Reichardt2004} for other Markov times (see \\cite{Delvenne2010,Delvenne2013} for details).\nHowever, for \\textit{directed} networks \\eqref{Qt} is not equivalent to the directed modularity of the original network, but is given by:\n\n", "index": 11, "text": "\\begin{equation}\nY_{ij} = \\dfrac{1}{2}\\left[\\pi_i \\frac{A_{ij}}{k_i^{\\rm out}} +\\pi_j \\frac{A_{ji}}{k_j^{\\rm out}}\\right].\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"Y_{ij}=\\dfrac{1}{2}\\left[\\pi_{i}\\frac{A_{ij}}{k_{i}^{\\rm out}}+\\pi_{j}\\frac{A_%&#10;{ji}}{k_{j}^{\\rm out}}\\right].\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><msub><mi>\u03c0</mi><mi>i</mi></msub><mo>\u2062</mo><mfrac><msub><mi>A</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msubsup><mi>k</mi><mi>i</mi><mi>out</mi></msubsup></mfrac></mrow><mo>+</mo><mrow><msub><mi>\u03c0</mi><mi>j</mi></msub><mo>\u2062</mo><mfrac><msub><mi>A</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><msubsup><mi>k</mi><mi>j</mi><mi>out</mi></msubsup></mfrac></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nwhere $p_\\alpha(t)$ is the probability of finding a walker on $\\mathcal{M}_2$ node $\\alpha$ at time $t$. \nLikewise the stationary distribution $\\pi_\\alpha$ of this process is given by the left eigenvector of the corresponding Laplacian, associated with eigenvalue $0$:\n\n", "itemtype": "equation", "pos": 20988, "prevtext": "\nInterestingly, similar adjusted adjacency (or Laplacian) matrices have been proposed as means for community detection in the literature based on different reasoning~\\cite{Chung2005,Satuluri2011}.\n\nNote that, as with all applications of unsupervised algorithms, care is needed when interpreting the results. \nFor instance, the optimisation of Markov Stability for a fixed Markov time inherits the limitations of modularity maximisation, such as a resolution limit \\cite{Fortunato2006}, and a high degeneracy of optimial solutions  \\cite{Good2010}. \nNevertheless, this class of method has been applied successfully in numerous applications \\cite{Fortunato2010}. \nIndeed, some of these problems can be circumvented by carefully sweeping through different resolution parameters \\cite{Schaub2012,Schaub2012b} and finding partitions that are robust over a range of parameters \\cite{Schaub2012,Delmotte2011,Lambiotte2014,Lambiotte2010}.\nMost importantly, however, the notion of community inherent to the methods presented here is based on flows \\cite{Delvenne2010,Schaub2012,Rosvall2008}.\nThis is in contrast to methods like stochastic blockmodels (SBM), see e.g. Ref. \\cite{Holland1983,Karrer2011,Peixoto2014}, which employ a generative model for the whole network and aim at finding patterns of pairwise connections in the system, though very recent work aims to incorporate dynamical aspects within the SBM framework~\\cite{Peixoto2015}.\n\n\n\\section{Dynamical community detection using higher-order Markov models}\n\\subsection{From first to second order Markov models}\nLet us now show how we can incorporate second-order Markov models into the Markov stability framework.\nAs higher-order Markov models provide more faithful representations of the dynamics observed in real world systems, this enables us to capture more of the real flow constraints in the uncovered communities.  \nFor simplicity let us initially consider undirected networks composed of $N$ nodes and $M$ links.\nThe dynamics of a second order Markov process are encoded by the transition matrix $T({\\overrightarrow{ {ij}}} \\rightarrow {\\overrightarrow{ {jk}}})$,\nwhich describes the probability that a walker moves from node $j$ to node $k$ if it came from $i$ in the previous step.\nBy definition, this transition matrix is normalised such that $\\sum_k T({\\overrightarrow{ {ij}}} \\rightarrow {\\overrightarrow{ {jk}}}) = 1$. \n\nAs sequences of two vertices in our original network correspond to the nodes in the $\\mathcal M_2$ network, the entries in $T$ describe precisely the transitions from $\\mathcal{M}_2$-node ${\\overrightarrow{ {ij}}}$ to $\\mathcal{M}_2$-node ${\\overrightarrow{ {jk}}}$.\nThe (second-order) $\\mathcal M_2$ process on the original network is thus equivalent to a first-order Markov process, albeit on a different network: namely, the $\\mathcal{M}_2$ network composed of $2M$ nodes.\nAs each undirected link of the original network can be traversed in two distinct directions (from $i$ to $j$, and vice versa) it accounts for 2 nodes in the $\\mathcal{M}_2$ network, ${\\overrightarrow{ {ij}}}$ and ${\\overrightarrow{ {ji}}}$. \nThis implies that the $\\mathcal M_2$ network is \\textit{directed} even if the original network is undirected.\nTo see this, observe that if $k\\neq i$, there cannot be a link between ${\\overrightarrow{ {jk}}}$ and ${\\overrightarrow{ {ij}}}$, even if a transition between ${\\overrightarrow{ {ij}}}$ and ${\\overrightarrow{ {jk}}}$ exists. \nHenceforth we use Greek letters to denote $\\mathcal{M}_2$ nodes, and Latin characters to denote the nodes in the original $\\mathcal{M}_1$ network.\n\nSimilarly to (\\ref{ctrw}), we can define a continuous-time random walk on the $\\mathcal{M}_2$ network as:\n\n", "index": 13, "text": "\\begin{equation}\n\\dot{p}_\\beta(t) = - p_{\\beta}(t) + \\sum_{\\alpha} p_\\alpha(t) T_{\\alpha \\beta} ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\dot{p}_{\\beta}(t)=-p_{\\beta}(t)+\\sum_{\\alpha}p_{\\alpha}(t)T_{\\alpha\\beta},\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>p</mi><mo>\u02d9</mo></mover><mi>\u03b2</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>-</mo><mrow><msub><mi>p</mi><mi>\u03b2</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>\u03b1</mi></munder><mrow><msub><mi>p</mi><mi>\u03b1</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>T</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\n\nNote that we can also observe how a simple $\\mathcal M_1$ Markov dynamics evolves from the point of view of an $\\mathcal M_2$ network, i.e., we can view the $\\mathcal M_1$ dynamics from the point of view of transitions between the (directed) edges of the graph.\nAs this is equivalent to lifting the $\\mathcal M_1$ dynamics into the larger $\\mathcal M_2$ state-space, we will denote this representation as a $\\mathcal M_{\\rm 1 expanded}$ network. \nIn this case it can be shown easily that $\\pi_\\alpha=w_\\alpha/W$, where $w_\\alpha$ is the weight of edge $\\alpha$ and $W = \\sum_\\alpha w_\\alpha$ \\cite{Rosvall2014,Lambiotte2015}. \nThe transition probability to any out-neighbour of $\\alpha$ on the $\\mathcal M_{\\text{1 expanded}}$ network is simply\n\n", "itemtype": "equation", "pos": 21370, "prevtext": "\nwhere $p_\\alpha(t)$ is the probability of finding a walker on $\\mathcal{M}_2$ node $\\alpha$ at time $t$. \nLikewise the stationary distribution $\\pi_\\alpha$ of this process is given by the left eigenvector of the corresponding Laplacian, associated with eigenvalue $0$:\n\n", "index": 15, "text": "\\begin{align}\n\\sum _\\alpha \\pi_{\\alpha} [T_{\\alpha\\beta} - \\delta_{\\alpha\\beta}] =0.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{\\alpha}\\pi_{\\alpha}[T_{\\alpha\\beta}-\\delta_{\\alpha\\beta}]=0.\" display=\"inline\"><mrow><mrow><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>\u03b1</mi></munder></mstyle><mrow><msub><mi>\u03c0</mi><mi>\u03b1</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><msub><mi>T</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow></msub><mo>-</mo><msub><mi>\u03b4</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow></msub></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nHere $\\sigma^{\\rm out}_\\alpha$ is the set of out-neighbours of $\\alpha$, and ${k_\\alpha^{\\rm out} = \\sum_{\\beta \\in \\sigma^{\\rm out}} w_\\beta}$ is the out-strength of $\\alpha$.\nNote that, since the original network has been undirected we have $k_\\alpha^{\\rm out}=k_j$, where $j$ is the endpoint of memory node (the directed edge) $\\alpha={\\overrightarrow{ {ij}}}$. \n\n\\subsection{Models of second-order Markov processes}\n\\label{sec:mem_models}\nWhile second order transition matrices $T$ can be directly generated from temporal pathway data, in some cases only information about the aggregated (first-order) network might be available.\nHowever, in such cases we can still create $\\mathcal M_2$ networks using a simple memory model as described in the following, calibrated by the pathway statistics of similar datasets for which this temporal information is obtainable.\nFor instance, the temporal information pathways of one Email dataset may be used to fit model-parameters to generate a second-order model for different email communication network, where only aggregated information is obtainable.\n\nThe key idea underpinning the model is to weight different types of transitions between two directed edges.\nAs illustrated in Figure \\ref{figr}, we define three different types of transitions \\cite{Rosvall2014}.\n\\begin{enumerate}\n    \\item a \\textit{return step}, in which a walker coming from ${\\overrightarrow{ {ij}}}$ jumps to ${\\overrightarrow{ {ji}}}$. In other words: a walker coming from node $i$ to $j$ returns to node $i$. \n    \\item a \\textit{triangular step}, in which a walker coming from ${\\overrightarrow{ {ij}}}$ moves to edge ${\\overrightarrow{ {jk}}}$, where $k\\neq i$ is a neighbor of $i$ .\n    \\item an \\textit{exploratory step}, in which the walker moves from ${\\overrightarrow{ {ij}}}$ to an edge ${\\overrightarrow{ {jl}}}$, whose endpoint $l$ is neither $i$, nor any of the neighbors of $i$.\n\\end{enumerate}\n\n\\begin{figure}\n\\includegraphics{FigureSchematicTempModel.eps}\n\\caption{\\textbf{Construction of a $\\mathcal M_2$ network using a second-order transition model.} \n    From each directed edge in the original network a walker can in principle perform three types of moves, which get weighted according to the parameters $r_i$: \n    a \\textit{return step} ($r_2$), a \\textit{triangular step} ($r_3$) and an  \\textit{exploratory step} ($r_{>3}$). The picture shows these different options for a generic network edge.}\n\\label{figr}\n\\end{figure}\n\nTo account for their relative importance we assign positive weights $r_2$, $r_3$ and $r_{>3}$ to the different types of transition as follows.\nLet us denote the adjacency matrix of the directed line graph associated with our network by $G$.\nThen we can decompose $G$ into three matrices $G^\\text{ret}$ (return links), $G^\\text{tri}$ (triangular), and $G^\\text{exp}$ (exploratory) each containing only the links of the respective type.\nTo obtain a weighted memory model we now define the weighted $2M \\times 2M$ adjacency matrix:\n\n", "itemtype": "equation", "pos": 22213, "prevtext": "\n\nNote that we can also observe how a simple $\\mathcal M_1$ Markov dynamics evolves from the point of view of an $\\mathcal M_2$ network, i.e., we can view the $\\mathcal M_1$ dynamics from the point of view of transitions between the (directed) edges of the graph.\nAs this is equivalent to lifting the $\\mathcal M_1$ dynamics into the larger $\\mathcal M_2$ state-space, we will denote this representation as a $\\mathcal M_{\\rm 1 expanded}$ network. \nIn this case it can be shown easily that $\\pi_\\alpha=w_\\alpha/W$, where $w_\\alpha$ is the weight of edge $\\alpha$ and $W = \\sum_\\alpha w_\\alpha$ \\cite{Rosvall2014,Lambiotte2015}. \nThe transition probability to any out-neighbour of $\\alpha$ on the $\\mathcal M_{\\text{1 expanded}}$ network is simply\n\n", "index": 17, "text": "\\begin{equation}\n\\label{mar}\nT^{\\mathcal M_1}_{\\alpha \\beta}= \n\\begin{cases}\nw_\\beta/k_\\alpha^{\\rm out}      & {\\rm for}~\\beta \\in \\sigma^{\\rm out}_\\alpha,\\cr\n0      & {\\rm otherwise} ,\n\\end{cases} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"T^{\\mathcal{M}_{1}}_{\\alpha\\beta}=\\begin{cases}w_{\\beta}/k_{\\alpha}^{\\rm out}&amp;%&#10;{\\rm for}~{}\\beta\\in\\sigma^{\\rm out}_{\\alpha},\\cr 0&amp;{\\rm otherwise},\\end{cases}\" display=\"block\"><mrow><msubsup><mi>T</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\u2133</mi><mn>1</mn></msub></msubsup><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>w</mi><mi>\u03b2</mi></msub><mo>/</mo><msubsup><mi>k</mi><mi>\u03b1</mi><mi>out</mi></msubsup></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+3.3pt\"><mi>for</mi></mpadded><mo>\u2062</mo><mi>\u03b2</mi></mrow><mo>\u2208</mo><msubsup><mi>\u03c3</mi><mi>\u03b1</mi><mi>out</mi></msubsup></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mn>0</mn></mtd><mtd columnalign=\"left\"><mrow><mi>otherwise</mi><mo>,</mo></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nfrom which we can compute the associated second order transition matrix $T^{\\rm model}$ simply by normalising each row to sum to $1$.\n\nAs can be easily verified, this definition implies that when we project the resulting walk onto the node space, we obtain a (first order) Markov process when $r_2=r_3=r_{>3}=\\text{const}$. \nWe further remark that if the dynamics is ergodic on a graph for any set of parameters, it will remain ergodic for any value of $r_2$, $r_3$ and $r_{>3}$, provided each parameter is strictly positive. \n\n\\begin{figure*}\n \\centering\n \\includegraphics{Figure2.eps}\n \\caption{\\textbf{Clustering analysis of a passenger traffic-network between airports in the US}. \\textbf{(a)} Results based on clustering the $\\mathcal{M}_{1\\text{expanded}}$ system representation. \\textbf{(b)} Clustering results obtained from the  $\\mathcal{M}_2$ system representation. In \\textbf{(a-b)} each airport is represented by a pie chart indicating the participation of the airport in different communities. For visual clarity, nodes with a community participation entropy smaller than one are displayed as smaller nodes.\n     \\textbf{(c)} Distributions of the community participation entropy across the network for the $\\mathcal{M}_{1\\text{expanded}}$ (left), $\\mathcal{M}_{2 {\\rm model}}$ (middle) and $\\mathcal{M}_2$ (right) network. \n     (All maps are created with \\href{https://github.com/andrea-cuttone/geoplotlib}{Geoplotlib} using map tiles and data from \\href{https://www.mapbox.com/map-feedback/}{Mapbox} and \\href{http://www.openstreetmap.org/copyright}{OpenStreetMap}, respectively.)}  \n\\label{airports}  \n\\end{figure*}\n\n\\subsection{Higher order Markov dynamics reveal communities in a network of flight pathways}\n\nLet us now demonstrate how second-order Markov dynamics can help to uncover the organisation of systems where pathway data are available, and compare their outcome with the community structure obtained by first-order dynamics and by  simplified models of second-order Markov dynamics, as defined in section \\ref{sec:mem_models}.\nTo do so, we consider a flight network in the United States. \nThe data used to construct the network consists of individual flight trajectories of people navigating between different airports in the US.\nFrom these trajectories one can directly obtain a $\\mathcal M_1$ or $\\mathcal M_2$ network as discussed above and in Ref.~\\cite{Rosvall2014}. \nThe main purpose of our analysis here is to illustrate the differences that may arise in community detection when considering the same mobility data from different modelling perspectives.\n\nWe analysed the modular structure of this system for the following three  scenarios:\ni) a first order Markov network ($\\mathcal{M}_{1 \\rm{expanded}}$),  viewed from the perspectives of the edges;\nii) a second order Markov network ($\\mathcal{M}_2$) where the transition probabilities are directly obtained from empirical data;\niii) a second order Markov network ($\\mathcal{M}_{2 {\\rm model}}$), where transitions are  approximated by a simple second-order transition matrix $T^\\text{model}$ (see text), whose parameters have been fitted from the data.\nIn each case, optimising the linearised stability for these different Markov models yields a clustering of the edges, which can be interpreted in terms of an overlapping community structure at the airport level. \nTo compare the different scenarios we concentrate on the results obtained for Markov time $t=1$ (see Fig.~\\ref{airports}).\nLet us also note that, for each network,  only few hardly active airports do not belong to the largest SCC. For this reason, as argued in section \\ref{ergodic}, we restrict the scope to nodes in this SCC.\nTo be more precise, we restrict the scope to the intersection of the largest SCCs of the three processes, in order to ensure that stability is well-defined for each of them.\n\nIn order to compare the communities associated to each Markov process, we first calculate the normalised variation of information  \\cite{Meila2007} between the three different partitions of  $\\mathcal{M}_2$ nodes obtained by optimising stability at $t=1$. \nBy construction, smaller values of variation of information indicate more similar community structures. \nWe obtain a variation of information of  $0.42$ between $\\mathcal{M}_2$ and $\\mathcal{M}_{1 \\rm{expanded}}$, $0.36$ between $\\mathcal{M}_2$ and $\\mathcal{M}_{2 {\\rm model}}$, and\n$0.38$ between $\\mathcal{M}_{1 \\rm{expanded}}$ and $\\mathcal{M}_{2 {\\rm model}}$. \nThese results confirm that the clusters obtained from $\\mathcal{M}_{2 {\\rm model}}$ provide an intermediate solution between $\\mathcal{M}_2$ and $\\mathcal{M}_{1 \\rm{expanded}}$, with the advantage of requiring far fewer parameters than in the $\\mathcal{M}_2$ case.\n\n\n\nAfter having found the edge-communities in each scenario, each node can be characterised by the set of group labels of its incident edges. \nIn order to quantify the apparent difference between the covers, we measure for each node the entropy of its associated group labels.\n\n", "itemtype": "equation", "pos": 25425, "prevtext": "\nHere $\\sigma^{\\rm out}_\\alpha$ is the set of out-neighbours of $\\alpha$, and ${k_\\alpha^{\\rm out} = \\sum_{\\beta \\in \\sigma^{\\rm out}} w_\\beta}$ is the out-strength of $\\alpha$.\nNote that, since the original network has been undirected we have $k_\\alpha^{\\rm out}=k_j$, where $j$ is the endpoint of memory node (the directed edge) $\\alpha={\\overrightarrow{ {ij}}}$. \n\n\\subsection{Models of second-order Markov processes}\n\\label{sec:mem_models}\nWhile second order transition matrices $T$ can be directly generated from temporal pathway data, in some cases only information about the aggregated (first-order) network might be available.\nHowever, in such cases we can still create $\\mathcal M_2$ networks using a simple memory model as described in the following, calibrated by the pathway statistics of similar datasets for which this temporal information is obtainable.\nFor instance, the temporal information pathways of one Email dataset may be used to fit model-parameters to generate a second-order model for different email communication network, where only aggregated information is obtainable.\n\nThe key idea underpinning the model is to weight different types of transitions between two directed edges.\nAs illustrated in Figure \\ref{figr}, we define three different types of transitions \\cite{Rosvall2014}.\n\\begin{enumerate}\n    \\item a \\textit{return step}, in which a walker coming from ${\\overrightarrow{ {ij}}}$ jumps to ${\\overrightarrow{ {ji}}}$. In other words: a walker coming from node $i$ to $j$ returns to node $i$. \n    \\item a \\textit{triangular step}, in which a walker coming from ${\\overrightarrow{ {ij}}}$ moves to edge ${\\overrightarrow{ {jk}}}$, where $k\\neq i$ is a neighbor of $i$ .\n    \\item an \\textit{exploratory step}, in which the walker moves from ${\\overrightarrow{ {ij}}}$ to an edge ${\\overrightarrow{ {jl}}}$, whose endpoint $l$ is neither $i$, nor any of the neighbors of $i$.\n\\end{enumerate}\n\n\\begin{figure}\n\\includegraphics{FigureSchematicTempModel.eps}\n\\caption{\\textbf{Construction of a $\\mathcal M_2$ network using a second-order transition model.} \n    From each directed edge in the original network a walker can in principle perform three types of moves, which get weighted according to the parameters $r_i$: \n    a \\textit{return step} ($r_2$), a \\textit{triangular step} ($r_3$) and an  \\textit{exploratory step} ($r_{>3}$). The picture shows these different options for a generic network edge.}\n\\label{figr}\n\\end{figure}\n\nTo account for their relative importance we assign positive weights $r_2$, $r_3$ and $r_{>3}$ to the different types of transition as follows.\nLet us denote the adjacency matrix of the directed line graph associated with our network by $G$.\nThen we can decompose $G$ into three matrices $G^\\text{ret}$ (return links), $G^\\text{tri}$ (triangular), and $G^\\text{exp}$ (exploratory) each containing only the links of the respective type.\nTo obtain a weighted memory model we now define the weighted $2M \\times 2M$ adjacency matrix:\n\n", "index": 19, "text": "\\begin{equation}\n    G^{\\text{mem}}_{\\alpha \\beta} = r_2 G^\\text{ret}_{\\alpha \\beta} + r_3 G^\\text{tri}_{\\alpha \\beta} + r_{>3} G^\\text{exp}_{\\alpha \\beta},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"G^{\\text{mem}}_{\\alpha\\beta}=r_{2}G^{\\text{ret}}_{\\alpha\\beta}+r_{3}G^{\\text{%&#10;tri}}_{\\alpha\\beta}+r_{&gt;3}G^{\\text{exp}}_{\\alpha\\beta},\" display=\"block\"><mrow><mrow><msubsup><mi>G</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow><mtext>mem</mtext></msubsup><mo>=</mo><mrow><mrow><msub><mi>r</mi><mn>2</mn></msub><mo>\u2062</mo><msubsup><mi>G</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow><mtext>ret</mtext></msubsup></mrow><mo>+</mo><mrow><msub><mi>r</mi><mn>3</mn></msub><mo>\u2062</mo><msubsup><mi>G</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow><mtext>tri</mtext></msubsup></mrow><mo>+</mo><mrow><msub><mi>r</mi><mrow><mi/><mo>&gt;</mo><mn>3</mn></mrow></msub><mo>\u2062</mo><msubsup><mi>G</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow><mtext>exp</mtext></msubsup></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nwhere $p_{i}(c)$ is its fraction of edges assigned to community $c$. \nA value $S_i=0$ indicates that the node is associated to a single community, while higher values indicate a more diverse participation. \nThe level of overlap of an edge partition can now be characterised by the distribution of entropy values on the set of nodes. \nWe observe in Figure \\ref{airports} that analyzing the $\\mathcal{M}_2$ network results in more overlapping communities than the expanded first-order model, while the $\\mathcal{M}_{2 {\\rm model}}$ network is characterized by intermediate participation values. \nSimilarly as observed for the map equation~\\cite{Rosvall2014}, accounting for memory via second order dynamics therefore uncovers communities with a stronger overlap, in agreement with empirical observations that higher-order dynamics tends to constrain flows  within these modules.\n\n\\section{Analyzing time-stamped temporal networks without pathway data.}\n\n\\subsection{Second-order Markov models of time-stamped temporal networks}\n\nNode or link activity in networked systems often exhibits non-trivial temporal patterns, such as heterogeneous inter-event times and correlations between activations times of neighbouring edges \\cite{Holme2012}. \nDifferent network representations of such temporal data can be adopted, each associated to a different notion of temporal community. \nA first, `naive' approach is to neglect the edge-timings and work with a static network representation, where the weight of each edge corresponds to an aggregation of the activity over the whole observed time interval. \nIn this case, community detection aims at grouping nodes which have the aggregated edge-weight concentrated inside modules.\n\nAlternatively, one can represent the system by a set of (coupled) adjacency matrices $A_t$, where each $A_t$ represents the system in a short-time frame of the whole observation period. \nBy applying community detection to this representation one tries to uncover meaningful structures in each time window, while enforcing some continuity between different time intervals \\cite{Mucha2010}.\nThis approach accordingly aims at tracking the evolution of communities in the course of time.  \n\nAs we now discuss, a third notion of community is naturally associated to the representation of dynamics on temporal networks as a second-order Markov process.\nIn situations when the activations of neighbouring edges present temporal correlations, the dynamics of a random walker is expected to be poorly reproduced by a first-order Markov process \\cite{Scholtes2014}. \nHowever, by finding a second-order representation of the temporal data and using the methodology introduced above, one can capture the observed temporal constraints on flow, including causal paths and a high levels of synchrony between edge activity. \n\nThe mapping from a time series  into a second-order Markov model is realized as follows.  \nWe consider a system described by an ordered set of adjacency matrices $A_t$ defining the connections between nodes at time $t \\in [1,T]$, where $T$ is the number of observations. \nThe static representation of the temporal  network is provided by the adjacency matrix $A_{\\rm static} = \\sum_t A_t$. \nEach directed edge with in $A_{\\rm static}$ defines a $\\mathcal{M}_2$ node.\nThe connection strength between $\\mathcal{M}_2$ nodes is now obtained by simulating pathways of a random walk process on the temporal network as follows. \nA walker is initially randomly assigned to a node. \nAt every time step the walker waits until at least one edge is available for transport. \nIf an edge becomes available, the walker leaves the node with probability $(1-p_{s})$ and remains on its current node with probability $p_{s}$. \nIf there are multiple possible transitions, the walker takes each edge with a probability proportional to its weight. \nThis process is repeated multiple times for the observed interval $[1,T]$ in order to generate sufficiently many trajectories.\nFrom these trajectories, one can simply construct a $\\mathcal{M}_2$ network by evaluating the transition frequencies between different edge pairs. \n\nWe remark here that several other procedures could be defined to generate $\\mathcal{M}_2$ networks, too. \nFor instance, we could account for the duration of the intervals between time steps, or define the walker's leaving probability to be proportional to the number of available contacts.\nNote that in the above construction, when $p_{s}=0$, the walker always takes the first available edge, and one recovers the dynamics studied in e.g. Ref. \\cite{delvenne2015}. \nThe use of non-zero values of $p_s$ introduces a source of randomness in the dynamics, which can prevent spurious effects such as an overly strong tendency for backtracking as observed in \\cite{Saramaki2015}. \nHowever, with increasing values of $p_s$, the original ordering of events becomes less important, and the impact of the exact timings is expected to be diluted \\cite{Gueuning2015}. \n\n\n\\subsection{Community detection in $\\mathcal M_2$ networks constructed from temporal data: an illustrative example}\n\\begin{figure*}\n  \\centering\n    \\includegraphics{FigureToyModel.eps}\n\\caption{\\textbf{Analysis of an example temporal network with 10 nodes and 3 groups. }    \n    \\textbf{(a)} shows a complete graph with 10 nodes, whose (directed) edges are divided into 3 groups, such that each node has exactly 3 outgoing edges of each type. \n    At each time-step only edges belonging to one group are active and available for transport. \n    The currently active group ceases to be active with probability $1-p_k$, and is replaced by a randomly selected group.\n    A random walker traversing the network is thus more likely to remain within the same group, the higher the probability $p_k$.\n    In  panel \\textbf{(b)}, the variation of information between the planted structure and the partition found by Markov stability in the $\\mathcal M_2$ network is displayed as a function of Markov time. We can see that there is a plateau for values of time slightly larger than $t=1$. As shown in in the inset, the method successfully uncovers the organisation into 3 modules for sufficiently large values of $p_k$, i.e., when the groups remain active long enough in time such that the walker remains trapped inside a community for non-negligible periods.} \n    \\label{ex_graph}  \n\\end{figure*} \n\n\nLet us now show that  a $\\mathcal{M}_2$ representation helps at uncovering hidden structures in temporal networks. \nAs a first illustrative example, we consider a computer-generated benchmark of a social network defined as follows. \nThe underlying structure is a complete graph, where the (directed) social interactions are divided into $g$ different, non-overlapping types, e.g., work relations, friends, etc. \nFig.~\\ref{ex_graph} A shows such a network with $N=10$ nodes and $g=3$ edge types.\nWe assume that different types of relationships dominate at different times, as often observed in empirical data \\cite{Eagle2009}. \nTherefore, at each time, all edges of one single group are simultaneously active.\nInitially, a randomly chosen group is active. \nAt each step, the currently active group remains active with probability $p_k$; with probability $1-p_k$, a new active group is randomly selected among all groups (including the currently active one). \nFor the parameters considered here, the walker thus has three outgoing edges available for transport  at each step (see Figure \\ref{ex_graph}). \nIt is important to note that for the generation of trajectories on this temporal network, a change of the probability for the walker to stay at its node $p_s$ is effectively equivalent to a change in $p_k$. \nFor the sake of simplicity, we therefore set $p_s=0$ here.\n\nClearly, the trajectories of the random walker and the corresponding structure of the $\\mathcal{M}_2$ network are affected by the value of $p_k$. \nWhen $p_k=0$, a  new active group is randomly selected at each step of the random walker. \nIn this limit, the average dynamics is equivalent to a first-order random walk on a fully connected network, and thus no underlying structure can be found.\nIncreasing  $p_k$ implies that the random walker remains for longer time periods inside one group of edges before leaving, and it is thus possible to uncover the group structure. \nThe extreme case $p_k=1$ is again trivial: the initial group remains active for all times. This case is therefore not considered in the following. \nThe results of our analysis are summarised in Fig. \\ref{ex_graph}, where we compare the uncovered communities with the planted solution into groups by means of normalised variation of information (VI). \nOur observations are twofold. \nFirst, for values of $t$ slightly larger than $t=1$, we find the planted partition with high accuracy. \nSecond, one observes that the underlying communities can be successfully found when the value of $p_k$ is sufficiently large, with a clear transition around $p_k=0.4$ (see inset in Figure \\ref{ex_graph}). \n \n\\subsection{A real-world case study: analyzing temporal interaction pattern of school children}\nTo demonstrate the utility of our approach with a real-world example, we have considered an empirical dataset from the SocioPatterns project  \\cite{Gemmetto2014}. \nThe data, described  in detail in  \\cite{Stehle2011}, consists of time-dependent face-to-face contacts, captured by wireless wearable sensors, between children and teachers in a primary school. \nIn total, the dataset is made of 77,602 contact events between 242 individuals during two consecutive days.\nAs the children belong to 10 different classes, we expect to find strong structural communities associated to these classes in the dynamic contact network.\nIn the following analysis, the pathways were generated with a probability for the walker to stay at his node at each step set to $p_s=0.05$, but similar results were obtained when varying this parameter. \n\nBy scanning through Markov times we can find several persisting partitions.\nAs validation we first identified the Markov time $t_{C=10} \\approx 0.631$ around which the algorithm robustly detects $10$ communities, and verified that the communities overlap with the partition into classes of the students. \nOne should note here that the partition into classes can in fact be uncovered even from the aggregated, weighted network associated to the data  \\cite{Stehle2011}. \n\nThe advantage of our approach becomes apparent when looking at further stable partitions found for smaller Markov times. \nFor instance, we find another robust split of the $\\mathcal{M}_2$ network at Markov time $t=0.56$ into $15$ communities. \nFor this partition most communities are still identified with classes, as can be seen in Fig.~\\ref{SPstand}. \nHowever, there are also additional modules in which students from different classes are mixed.\nThese modules display activity patterns which are highly localized in time and therefore are bound to get lost when averaging over the temporal dimension in the data.\nInterestingly, these latter communities correspond in fact to interactions taking place between students during lunch breaks.\nNotably, these interaction are not detectable from the aggregate network or when using a memoryless representation of the dynamics (e.g., the $\\mathcal M_{\\rm 1 expanded}$ network).\nBy using the approach outlined here, we can thus not only detect 'structural' communities, in which actors maintain a higher amount of interactions between each other throughout time, but also 'temporally localized' communities, which are associated to groups that interact with each other strongly over certain time-periods.\n\n\n\\begin{figure*}\n    \\includegraphics[width=\\textwidth]{Figure4_alt}\n\\caption{\\textbf{Analysis of the temporal community structure of a school network.} Two types of communities can be found by analyzing the $\\mathcal{M}_2$ network generated with $p_{stay}=0.05$. \nAround Markov time equal to $t=0.56$ we find a robust of the directed edges into $15$ communities. $10$ of these communities are 'single class communities', in the sense that most connections are concentrated in one single class (cm2a in the example shown in \\textbf{(a)}). These communities do not display a particular temporal structure in their activation patterns. This is clear from the  temporal profile of activity (bottom panel in \\textbf{(a)}), which displays the number of active links as a function of time, averaged over 2 days.   \n\\textbf{(b)} The remaining $5$ communities are temporally localized 'lunchtime communities'. While they extend over a range of class labels, connecting pupils from different groups, they are highly coherent and synchronised in time. These communities represent the lunch-time interactions between students of different classes.}  \n\\label{SPstand}  \\label{SPlunch}  \n\\end{figure*} \n\n\n\\section{Second-order models, non-backtracking walks and spectral clustering}\n\nRecently, there has been an increased interest in spectral methods based on the so-called non-backtracking matrix of a network.\nWhile standard spectral algorithms for graph partitioning tend to fail when applied to very sparse networks, Krzakala \\textit{et al.} \\cite{Krzakala2013} demonstrated how using the non-backtracking matrix one can design spectral algorithms which behave optimally right until the theoretical limit of detectability of a stochastic block model.\nAs the name suggests, the non-backtracking matrix is intimately related to the non-backtracking random walk on a network. \nThe non-backtracking random walk is a diffusion process in which a particle behaves just like a simple random walker on the network, albeit with one additional constraint: after arriving at a node the walker is not allowed to immediately return to the node from which she originated (she cannot `backtrack').\n\nInterestingly, this non-backtracking random walk can be simply phrased in terms of a memory dynamics.\nFollowing the notation of section \\ref{sec:mem_models} the non-backtracking matrix is defined on the set of $\\mathcal{M}_2$-nodes and may be simply written as\n\n", "itemtype": "equation", "pos": 30621, "prevtext": "\nfrom which we can compute the associated second order transition matrix $T^{\\rm model}$ simply by normalising each row to sum to $1$.\n\nAs can be easily verified, this definition implies that when we project the resulting walk onto the node space, we obtain a (first order) Markov process when $r_2=r_3=r_{>3}=\\text{const}$. \nWe further remark that if the dynamics is ergodic on a graph for any set of parameters, it will remain ergodic for any value of $r_2$, $r_3$ and $r_{>3}$, provided each parameter is strictly positive. \n\n\\begin{figure*}\n \\centering\n \\includegraphics{Figure2.eps}\n \\caption{\\textbf{Clustering analysis of a passenger traffic-network between airports in the US}. \\textbf{(a)} Results based on clustering the $\\mathcal{M}_{1\\text{expanded}}$ system representation. \\textbf{(b)} Clustering results obtained from the  $\\mathcal{M}_2$ system representation. In \\textbf{(a-b)} each airport is represented by a pie chart indicating the participation of the airport in different communities. For visual clarity, nodes with a community participation entropy smaller than one are displayed as smaller nodes.\n     \\textbf{(c)} Distributions of the community participation entropy across the network for the $\\mathcal{M}_{1\\text{expanded}}$ (left), $\\mathcal{M}_{2 {\\rm model}}$ (middle) and $\\mathcal{M}_2$ (right) network. \n     (All maps are created with \\href{https://github.com/andrea-cuttone/geoplotlib}{Geoplotlib} using map tiles and data from \\href{https://www.mapbox.com/map-feedback/}{Mapbox} and \\href{http://www.openstreetmap.org/copyright}{OpenStreetMap}, respectively.)}  \n\\label{airports}  \n\\end{figure*}\n\n\\subsection{Higher order Markov dynamics reveal communities in a network of flight pathways}\n\nLet us now demonstrate how second-order Markov dynamics can help to uncover the organisation of systems where pathway data are available, and compare their outcome with the community structure obtained by first-order dynamics and by  simplified models of second-order Markov dynamics, as defined in section \\ref{sec:mem_models}.\nTo do so, we consider a flight network in the United States. \nThe data used to construct the network consists of individual flight trajectories of people navigating between different airports in the US.\nFrom these trajectories one can directly obtain a $\\mathcal M_1$ or $\\mathcal M_2$ network as discussed above and in Ref.~\\cite{Rosvall2014}. \nThe main purpose of our analysis here is to illustrate the differences that may arise in community detection when considering the same mobility data from different modelling perspectives.\n\nWe analysed the modular structure of this system for the following three  scenarios:\ni) a first order Markov network ($\\mathcal{M}_{1 \\rm{expanded}}$),  viewed from the perspectives of the edges;\nii) a second order Markov network ($\\mathcal{M}_2$) where the transition probabilities are directly obtained from empirical data;\niii) a second order Markov network ($\\mathcal{M}_{2 {\\rm model}}$), where transitions are  approximated by a simple second-order transition matrix $T^\\text{model}$ (see text), whose parameters have been fitted from the data.\nIn each case, optimising the linearised stability for these different Markov models yields a clustering of the edges, which can be interpreted in terms of an overlapping community structure at the airport level. \nTo compare the different scenarios we concentrate on the results obtained for Markov time $t=1$ (see Fig.~\\ref{airports}).\nLet us also note that, for each network,  only few hardly active airports do not belong to the largest SCC. For this reason, as argued in section \\ref{ergodic}, we restrict the scope to nodes in this SCC.\nTo be more precise, we restrict the scope to the intersection of the largest SCCs of the three processes, in order to ensure that stability is well-defined for each of them.\n\nIn order to compare the communities associated to each Markov process, we first calculate the normalised variation of information  \\cite{Meila2007} between the three different partitions of  $\\mathcal{M}_2$ nodes obtained by optimising stability at $t=1$. \nBy construction, smaller values of variation of information indicate more similar community structures. \nWe obtain a variation of information of  $0.42$ between $\\mathcal{M}_2$ and $\\mathcal{M}_{1 \\rm{expanded}}$, $0.36$ between $\\mathcal{M}_2$ and $\\mathcal{M}_{2 {\\rm model}}$, and\n$0.38$ between $\\mathcal{M}_{1 \\rm{expanded}}$ and $\\mathcal{M}_{2 {\\rm model}}$. \nThese results confirm that the clusters obtained from $\\mathcal{M}_{2 {\\rm model}}$ provide an intermediate solution between $\\mathcal{M}_2$ and $\\mathcal{M}_{1 \\rm{expanded}}$, with the advantage of requiring far fewer parameters than in the $\\mathcal{M}_2$ case.\n\n\n\nAfter having found the edge-communities in each scenario, each node can be characterised by the set of group labels of its incident edges. \nIn order to quantify the apparent difference between the covers, we measure for each node the entropy of its associated group labels.\n\n", "index": 21, "text": "\\begin{equation}\nS_i = - \\sum_{c} p_{i}(c) \\ln p_{i}(c),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"S_{i}=-\\sum_{c}p_{i}(c)\\ln p_{i}(c),\" display=\"block\"><mrow><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>c</mi></munder><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nClearly this matrix describes the line graph for a memory walker with parameters set to $r_2 = 0, r_3=1, r_{>3}=1$ (see section \\ref{sec:mem_models}).\nThe associated transition matrix $ T^\\text{B}$ of the non-backtracking random walk is  simply obtained through normalisation:\n\n", "itemtype": "equation", "pos": 44802, "prevtext": "\nwhere $p_{i}(c)$ is its fraction of edges assigned to community $c$. \nA value $S_i=0$ indicates that the node is associated to a single community, while higher values indicate a more diverse participation. \nThe level of overlap of an edge partition can now be characterised by the distribution of entropy values on the set of nodes. \nWe observe in Figure \\ref{airports} that analyzing the $\\mathcal{M}_2$ network results in more overlapping communities than the expanded first-order model, while the $\\mathcal{M}_{2 {\\rm model}}$ network is characterized by intermediate participation values. \nSimilarly as observed for the map equation~\\cite{Rosvall2014}, accounting for memory via second order dynamics therefore uncovers communities with a stronger overlap, in agreement with empirical observations that higher-order dynamics tends to constrain flows  within these modules.\n\n\\section{Analyzing time-stamped temporal networks without pathway data.}\n\n\\subsection{Second-order Markov models of time-stamped temporal networks}\n\nNode or link activity in networked systems often exhibits non-trivial temporal patterns, such as heterogeneous inter-event times and correlations between activations times of neighbouring edges \\cite{Holme2012}. \nDifferent network representations of such temporal data can be adopted, each associated to a different notion of temporal community. \nA first, `naive' approach is to neglect the edge-timings and work with a static network representation, where the weight of each edge corresponds to an aggregation of the activity over the whole observed time interval. \nIn this case, community detection aims at grouping nodes which have the aggregated edge-weight concentrated inside modules.\n\nAlternatively, one can represent the system by a set of (coupled) adjacency matrices $A_t$, where each $A_t$ represents the system in a short-time frame of the whole observation period. \nBy applying community detection to this representation one tries to uncover meaningful structures in each time window, while enforcing some continuity between different time intervals \\cite{Mucha2010}.\nThis approach accordingly aims at tracking the evolution of communities in the course of time.  \n\nAs we now discuss, a third notion of community is naturally associated to the representation of dynamics on temporal networks as a second-order Markov process.\nIn situations when the activations of neighbouring edges present temporal correlations, the dynamics of a random walker is expected to be poorly reproduced by a first-order Markov process \\cite{Scholtes2014}. \nHowever, by finding a second-order representation of the temporal data and using the methodology introduced above, one can capture the observed temporal constraints on flow, including causal paths and a high levels of synchrony between edge activity. \n\nThe mapping from a time series  into a second-order Markov model is realized as follows.  \nWe consider a system described by an ordered set of adjacency matrices $A_t$ defining the connections between nodes at time $t \\in [1,T]$, where $T$ is the number of observations. \nThe static representation of the temporal  network is provided by the adjacency matrix $A_{\\rm static} = \\sum_t A_t$. \nEach directed edge with in $A_{\\rm static}$ defines a $\\mathcal{M}_2$ node.\nThe connection strength between $\\mathcal{M}_2$ nodes is now obtained by simulating pathways of a random walk process on the temporal network as follows. \nA walker is initially randomly assigned to a node. \nAt every time step the walker waits until at least one edge is available for transport. \nIf an edge becomes available, the walker leaves the node with probability $(1-p_{s})$ and remains on its current node with probability $p_{s}$. \nIf there are multiple possible transitions, the walker takes each edge with a probability proportional to its weight. \nThis process is repeated multiple times for the observed interval $[1,T]$ in order to generate sufficiently many trajectories.\nFrom these trajectories, one can simply construct a $\\mathcal{M}_2$ network by evaluating the transition frequencies between different edge pairs. \n\nWe remark here that several other procedures could be defined to generate $\\mathcal{M}_2$ networks, too. \nFor instance, we could account for the duration of the intervals between time steps, or define the walker's leaving probability to be proportional to the number of available contacts.\nNote that in the above construction, when $p_{s}=0$, the walker always takes the first available edge, and one recovers the dynamics studied in e.g. Ref. \\cite{delvenne2015}. \nThe use of non-zero values of $p_s$ introduces a source of randomness in the dynamics, which can prevent spurious effects such as an overly strong tendency for backtracking as observed in \\cite{Saramaki2015}. \nHowever, with increasing values of $p_s$, the original ordering of events becomes less important, and the impact of the exact timings is expected to be diluted \\cite{Gueuning2015}. \n\n\n\\subsection{Community detection in $\\mathcal M_2$ networks constructed from temporal data: an illustrative example}\n\\begin{figure*}\n  \\centering\n    \\includegraphics{FigureToyModel.eps}\n\\caption{\\textbf{Analysis of an example temporal network with 10 nodes and 3 groups. }    \n    \\textbf{(a)} shows a complete graph with 10 nodes, whose (directed) edges are divided into 3 groups, such that each node has exactly 3 outgoing edges of each type. \n    At each time-step only edges belonging to one group are active and available for transport. \n    The currently active group ceases to be active with probability $1-p_k$, and is replaced by a randomly selected group.\n    A random walker traversing the network is thus more likely to remain within the same group, the higher the probability $p_k$.\n    In  panel \\textbf{(b)}, the variation of information between the planted structure and the partition found by Markov stability in the $\\mathcal M_2$ network is displayed as a function of Markov time. We can see that there is a plateau for values of time slightly larger than $t=1$. As shown in in the inset, the method successfully uncovers the organisation into 3 modules for sufficiently large values of $p_k$, i.e., when the groups remain active long enough in time such that the walker remains trapped inside a community for non-negligible periods.} \n    \\label{ex_graph}  \n\\end{figure*} \n\n\nLet us now show that  a $\\mathcal{M}_2$ representation helps at uncovering hidden structures in temporal networks. \nAs a first illustrative example, we consider a computer-generated benchmark of a social network defined as follows. \nThe underlying structure is a complete graph, where the (directed) social interactions are divided into $g$ different, non-overlapping types, e.g., work relations, friends, etc. \nFig.~\\ref{ex_graph} A shows such a network with $N=10$ nodes and $g=3$ edge types.\nWe assume that different types of relationships dominate at different times, as often observed in empirical data \\cite{Eagle2009}. \nTherefore, at each time, all edges of one single group are simultaneously active.\nInitially, a randomly chosen group is active. \nAt each step, the currently active group remains active with probability $p_k$; with probability $1-p_k$, a new active group is randomly selected among all groups (including the currently active one). \nFor the parameters considered here, the walker thus has three outgoing edges available for transport  at each step (see Figure \\ref{ex_graph}). \nIt is important to note that for the generation of trajectories on this temporal network, a change of the probability for the walker to stay at its node $p_s$ is effectively equivalent to a change in $p_k$. \nFor the sake of simplicity, we therefore set $p_s=0$ here.\n\nClearly, the trajectories of the random walker and the corresponding structure of the $\\mathcal{M}_2$ network are affected by the value of $p_k$. \nWhen $p_k=0$, a  new active group is randomly selected at each step of the random walker. \nIn this limit, the average dynamics is equivalent to a first-order random walk on a fully connected network, and thus no underlying structure can be found.\nIncreasing  $p_k$ implies that the random walker remains for longer time periods inside one group of edges before leaving, and it is thus possible to uncover the group structure. \nThe extreme case $p_k=1$ is again trivial: the initial group remains active for all times. This case is therefore not considered in the following. \nThe results of our analysis are summarised in Fig. \\ref{ex_graph}, where we compare the uncovered communities with the planted solution into groups by means of normalised variation of information (VI). \nOur observations are twofold. \nFirst, for values of $t$ slightly larger than $t=1$, we find the planted partition with high accuracy. \nSecond, one observes that the underlying communities can be successfully found when the value of $p_k$ is sufficiently large, with a clear transition around $p_k=0.4$ (see inset in Figure \\ref{ex_graph}). \n \n\\subsection{A real-world case study: analyzing temporal interaction pattern of school children}\nTo demonstrate the utility of our approach with a real-world example, we have considered an empirical dataset from the SocioPatterns project  \\cite{Gemmetto2014}. \nThe data, described  in detail in  \\cite{Stehle2011}, consists of time-dependent face-to-face contacts, captured by wireless wearable sensors, between children and teachers in a primary school. \nIn total, the dataset is made of 77,602 contact events between 242 individuals during two consecutive days.\nAs the children belong to 10 different classes, we expect to find strong structural communities associated to these classes in the dynamic contact network.\nIn the following analysis, the pathways were generated with a probability for the walker to stay at his node at each step set to $p_s=0.05$, but similar results were obtained when varying this parameter. \n\nBy scanning through Markov times we can find several persisting partitions.\nAs validation we first identified the Markov time $t_{C=10} \\approx 0.631$ around which the algorithm robustly detects $10$ communities, and verified that the communities overlap with the partition into classes of the students. \nOne should note here that the partition into classes can in fact be uncovered even from the aggregated, weighted network associated to the data  \\cite{Stehle2011}. \n\nThe advantage of our approach becomes apparent when looking at further stable partitions found for smaller Markov times. \nFor instance, we find another robust split of the $\\mathcal{M}_2$ network at Markov time $t=0.56$ into $15$ communities. \nFor this partition most communities are still identified with classes, as can be seen in Fig.~\\ref{SPstand}. \nHowever, there are also additional modules in which students from different classes are mixed.\nThese modules display activity patterns which are highly localized in time and therefore are bound to get lost when averaging over the temporal dimension in the data.\nInterestingly, these latter communities correspond in fact to interactions taking place between students during lunch breaks.\nNotably, these interaction are not detectable from the aggregate network or when using a memoryless representation of the dynamics (e.g., the $\\mathcal M_{\\rm 1 expanded}$ network).\nBy using the approach outlined here, we can thus not only detect 'structural' communities, in which actors maintain a higher amount of interactions between each other throughout time, but also 'temporally localized' communities, which are associated to groups that interact with each other strongly over certain time-periods.\n\n\n\\begin{figure*}\n    \\includegraphics[width=\\textwidth]{Figure4_alt}\n\\caption{\\textbf{Analysis of the temporal community structure of a school network.} Two types of communities can be found by analyzing the $\\mathcal{M}_2$ network generated with $p_{stay}=0.05$. \nAround Markov time equal to $t=0.56$ we find a robust of the directed edges into $15$ communities. $10$ of these communities are 'single class communities', in the sense that most connections are concentrated in one single class (cm2a in the example shown in \\textbf{(a)}). These communities do not display a particular temporal structure in their activation patterns. This is clear from the  temporal profile of activity (bottom panel in \\textbf{(a)}), which displays the number of active links as a function of time, averaged over 2 days.   \n\\textbf{(b)} The remaining $5$ communities are temporally localized 'lunchtime communities'. While they extend over a range of class labels, connecting pupils from different groups, they are highly coherent and synchronised in time. These communities represent the lunch-time interactions between students of different classes.}  \n\\label{SPstand}  \\label{SPlunch}  \n\\end{figure*} \n\n\n\\section{Second-order models, non-backtracking walks and spectral clustering}\n\nRecently, there has been an increased interest in spectral methods based on the so-called non-backtracking matrix of a network.\nWhile standard spectral algorithms for graph partitioning tend to fail when applied to very sparse networks, Krzakala \\textit{et al.} \\cite{Krzakala2013} demonstrated how using the non-backtracking matrix one can design spectral algorithms which behave optimally right until the theoretical limit of detectability of a stochastic block model.\nAs the name suggests, the non-backtracking matrix is intimately related to the non-backtracking random walk on a network. \nThe non-backtracking random walk is a diffusion process in which a particle behaves just like a simple random walker on the network, albeit with one additional constraint: after arriving at a node the walker is not allowed to immediately return to the node from which she originated (she cannot `backtrack').\n\nInterestingly, this non-backtracking random walk can be simply phrased in terms of a memory dynamics.\nFollowing the notation of section \\ref{sec:mem_models} the non-backtracking matrix is defined on the set of $\\mathcal{M}_2$-nodes and may be simply written as\n\n", "index": 23, "text": "\\begin{equation}\n    B = G^{\\text{tri}} + G^{\\text{exp}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"B=G^{\\text{tri}}+G^{\\text{exp}}.\" display=\"block\"><mrow><mrow><mi>B</mi><mo>=</mo><mrow><msup><mi>G</mi><mtext>tri</mtext></msup><mo>+</mo><msup><mi>G</mi><mtext>exp</mtext></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03516.tex", "nexttext": "\nwhere $k^{\\rm out}_{\\alpha}$ is the weighted out-degree of $\\mathcal{M}_2$-node $\\alpha$.\nAs this is just a diagonally scaled version (by the degree) of the non-backtracking operator, we may employ the flow based transition matrix $T^B$ for spectral partitioning of the nodes \\cite{Newman2013a}.\nIn fact, $T^B$ is just one particular instance of a whole continuum of possible transition matrices, each with varying amounts of memory.\nWe can thus assess the effect the introduced memory has on the clustering by varying the parameters $r_i$ and performing a spectral clustering analysis.\n\n\\begin{figure}\n    \\includegraphics{FigureSpectral}\n    \\caption{\\textbf{Spectral Clustering of sparse networks using memory matrices.} The networks consist of $10^4$ nodes with a planted bipartition. The average degree of the network vs. the spectral clustering performance for classifying the \\textit{nodes} as measured by the normalised mutual information (NMI). Note that the theoretical detectability limit is given by $c^*=\\approx 3.45$ (red dashed line) \\textbf{(a)} Clustering performance based on the Adjacency matrix $A$, the non-backtracking matrix $B$, and the normalised Laplacian matrix $\\mathcal L$. \\textbf{(b)} Clustering performance based on different $\\mathcal M_{2model}$ transition matrices with different parameter settings.}\n    \\label{fig:spectral}\n\\end{figure}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLike in \\cite{Krzakala2013}, we consider the problem of spectral clustering here in the simplest possible setup, which is the detection of a bipartition of equally sized groups in a large, sparse network.\nThe networks we consider here consist of $N=10^4$ nodes, divided into two groups according to a simple stochastic block model \\cite{Krzakala2013}.\nWe denote the average degree of each node by $c$, the average degree to nodes inside its group by $c_{in}$, and the average degree to nodes outside its own group by $c_{out}$.\nNote that these quantities are coupled by the simple relation $c=(c_{in}+c_{out})/2$.\n\nSimilar to \\cite{Krzakala2013}, while keeping the ratio $c_{out}/c_{in}=0.3$ fixed, we vary the average degree $c$ and observe the results we obtain from different operators via spectral clustering.\nFollowing \\cite{Krzakala2013,Newman2013a}, each node is grouped using the following protocol.\nWe first compute the second dominant (left) eigenvector of the respective matrix operator. \nSecond, for each we sum over the eigenvector components corresponding to all of its incoming links.\nThe nodes are grouped according to the sign of this sum: if is is positive the node is assigned to group 1 if not to the second group.\nIn case the respective matrix operator is directly defined on the node space, the nodes are simply partitioned according to the signs of the eigenvector.\nNote that in contrast to the problems considered above we here look at the problem of community detection from the perspective of a hard clustering of the $\\textit{nodes}$ rather than the edges and moreover assume that there is a fixed, known number of non-overlapping node-communities.\nWe thus do not expect that using second-order transition matrices will necessarily improve the performance (for the non-overlapping node-clustering), indeed accounting for memory can also be detrimental for this purpose as we will see in the following.\nHowever, our main purpose here was not to design an improved node clustering algorithm but to better understand the connection between spectral clustering and memory matrices.\n\nIn Figure \\ref{fig:spectral}a, we initially perform a spectral clustering analysis the non-backtracking matrix $B$ \\cite{Krzakala2013}, the adjacency matrix $A$, the normalised Laplacian matrix $\\mathcal L=I - D^{-1/2}AD^{-1/2}$\nAs has been observed by Krzakala et al., the clustering based on the backtracking matrix $B$ performs clearly better than the one based on the adjacency or Laplacian matrix, in particular when the graph becomes very sparse (see Figure \\ref{fig:spectral}a).\nFigure \\ref{fig:spectral}b shows the results for the spectral clustering based on the memory walk matrices $T_{\\{r_i\\}}$ with various parameter settings $r_i$.\nThere appears to be a clear trend: the more weight there is assigned to exploratory steps, the easier it appears to decide on the node groupings.\nSpectral clustering based on the non-backtracking second-order transition matrix $T(r_2=0,r_3=1,r_{>3=1})$ performs almost as well as the clustering based on $B$ for very sparse networks.\nFor networks with a higher average degree ($c\\approx 8$), the results are even slightly better.\nAs the second eigenvector of $T$, which is used for the clustering, describes the approach of a memory dynamics towards stationarity it should not be too surprising that the results deteriorate if more memory is introduced: as very sparse graphs have a tendril like structure, additional memory can lead to a localisation of the dynamics in parts of the graph which correspond to strong 'local' bottlenecks. \nStated differently, the slowest time-scale of the diffusion may not correlated with moving from one planted (node) community to the other, but local obstacles become more important making the second eigenvector a bad predictor of the bi-partition.\n\nThis is in particular interesting as for most memory dynamics reported \\cite{Rosvall2014}, the return flow appears to be significantly large, which would imply that the dynamical constraints on the flow are much more pronounced on a local level than one may expect from the perspective of an aggregated network.\n\nThis observation appears to be aligned with the fact that many real-world systems tend to be composed of overlapping communities \\cite{Ahn2010}.\n\n\n\n\n\n\n\n\n\n\\section{Conclusions}\n\nNetwork-based models have been extremely successful for the analysis of complex systems, and have led to the discovery of structural features with profound impacts on its dynamics \\cite{Newman2006a}.\nHowever, to accurately capture the complexity of real-world interacting systems, simple network models are often not sufficient.\nFor this reason, different approaches have  been proposed recently, which increase the model dimension and enrich the network paradigm. \nOne approach that has gained prominence in the literature, is to account for the different types of interactions present in the  system by means of \nmultiplex or multilayer networks \\cite{Kivelae2014}. \nOur approach developed in the work presented here proceeds in a similar spirit: by providing a larger state space representation in the \\textit{temporal} dimension, we aim to obtain new insights about the dynamical processes taking place in the system. \nDespite their similarities (see Ref. \\cite{Lambiotte2015}), multiplex networks and higher-order Markov models differ, as the former model tends to emphasise differences in the connections of the system, while the second emphasises pathways. \n\nIn this paper, we have focused on the applicability of second-order Markov dynamics in the context of flow-based community detection. \nSecond-order Markov dynamics model real-world temporal dynamics more accurately, so the found communities are expected to better capture the actual flow constraints in the system.\nIn particular, we have shown how the Markov stability framework, and thus techniques like Potts models and spectral clustering, can be based on a second-order Markov dynamics, which is equivalent to considering  transitions  between directed edges in the original network.\nAs clustering of second order models yields a partition of the edges, one can readily interpret the results as an overlapping clustering of the nodes in the original system, which is a beneficial feature of the approach.\n\nSome practical concerns are associated with moving to a second-order model. \nNaturally, there is an increased computational cost, as the number of nodes in the second-order model is equivalent to the number of directed edges in the original network. \nHowever, as most networks are sparse, this cost tends to be outweighed by the benefits gained from a higher-order dynamical representation.\nAnother practical issue is that pathway statistics, needed to construct a second-order transition matrix directly from data, may not always be immediately accessible.\nTo make the toolkit of second order models available in such scenarios, we have presented two different strategies. \nFirst, we have analysed a simple model able to generate realistic second-order dynamics, which can be calibrated from similar datasets.\nSecond, we have demonstrated how to represent temporal network data as a second order network.\nWe have tested these two strategies by focusing on a flight network in the United States, and a (temporal) social interaction network in a school environment, respectively.\nIn both cases, the second order dynamics, even approximated, allowed us to extract temporal patterns in the data that would have been missed by an aggregated first-order model.\n\nFinally, we have highlighted the relationship between second-order Markov models and the recently introduced spectral clustering formalism based on the non-backtracking matrix.\nInterestingly, the non-backtracking matrix corresponds to a scaled version of the transition matrix of a non-backtracking random walk, which is  a special case of the second order dynamics discussed in this manuscript. \nAs we have demonstrated, this connection opens up the possibility to investigate further second order Markov processes and their relationships to spectral clustering.\nInvestigating these issues in more detail will be the subject of future work.\n\n\\section{Acknowledgments}\n\nWe acknowledge financial support from F.R.S-FNRS, ARC and from the COST Action TD1210 KnowEscape. This paper presents research results of the Belgian Network DYSCO (Dynamical Systems, Control, and Optimismtion), funded by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office.\n\n\\subsection*{Author Contributions Statement}\n\nAll authors conceived the study; V.S. and M.T.S. performed the numerical simulations and created the Figures; All authors wrote and reviewed the manuscript.\n\n\\subsection*{Competing financial interests}\n\nThe authors declare no competing financial interests.\n\n\n\\begin{thebibliography}{46}\n\\makeatletter\n\\providecommand \\@ifxundefined [1]{\n \\@ifx{#1\\undefined}\n}\n\\providecommand \\@ifnum [1]{\n \\ifnum #1\\expandafter \\@firstoftwo\n \\else \\expandafter \\@secondoftwo\n \\fi\n}\n\\providecommand \\@ifx [1]{\n \\ifx #1\\expandafter \\@firstoftwo\n \\else \\expandafter \\@secondoftwo\n \\fi\n}\n\\providecommand \\natexlab [1]{#1}\n\\providecommand \\enquote  [1]{``#1''}\n\\providecommand \\bibnamefont  [1]{#1}\n\\providecommand \\bibfnamefont [1]{#1}\n\\providecommand \\citenamefont [1]{#1}\n\\providecommand \\href@noop [0]{\\@secondoftwo}\n\\providecommand \\href [0]{\\begingroup \\@sanitize@url \\@href}\n\\providecommand \\@href[1]{\\@@startlink{#1}\\@@href}\n\\providecommand \\@@href[1]{\\endgroup#1\\@@endlink}\n\\providecommand \\@sanitize@url [0]{\\catcode `\\\\12\\catcode `\\$12\\catcode\n  `\\&12\\catcode `\\#12\\catcode `\\^12\\catcode `\\_12\\catcode `\\%12\\relax}\n\\providecommand \\@@startlink[1]{}\n\\providecommand \\@@endlink[0]{}\n\\providecommand \\url  [0]{\\begingroup\\@sanitize@url \\@url }\n\\providecommand \\@url [1]{\\endgroup\\@href {#1}{\\urlprefix }}\n\\providecommand \\urlprefix  [0]{URL }\n\\providecommand \\Eprint [0]{\\href }\n\\providecommand \\doibase [0]{http://dx.doi.org/}\n\\providecommand \\selectlanguage [0]{\\@gobble}\n\\providecommand \\bibinfo  [0]{\\@secondoftwo}\n\\providecommand \\bibfield  [0]{\\@secondoftwo}\n\\providecommand \\translation [1]{[#1]}\n\\providecommand \\BibitemOpen [0]{}\n\\providecommand \\bibitemStop [0]{}\n\\providecommand \\bibitemNoStop [0]{.\\EOS\\space}\n\\providecommand \\EOS [0]{\\spacefactor3000\\relax}\n\\providecommand \\BibitemShut  [1]{\\csname bibitem#1\\endcsname}\n\\let\\auto@bib@innerbib\\@empty\n\n\\bibitem [{\\citenamefont {Newman}(2010)}]{Newman2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.~E.~J.}\\\n  \\bibnamefont {Newman}},\\ }\\href@noop {} {\\emph {\\bibinfo {title} {{N}etworks:\n  {A}n {I}ntroduction}}}\\ (\\bibinfo  {publisher} {Oxford University Press,\n  USA},\\ \\bibinfo {year} {2010})\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Lambiotte}\\ \\emph {et~al.}(2015)\\citenamefont\n  {Lambiotte}, \\citenamefont {Salnikov},\\ and\\ \\citenamefont\n  {Rosvall}}]{Lambiotte2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}}, \\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont {Salnikov}},\n  \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Rosvall}},\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Journal of Complex\n  Networks}\\ }\\textbf {\\bibinfo {volume} {3}},\\ \\bibinfo {pages} {177}\n  (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Delvenne}\\ \\emph {et~al.}(2010)\\citenamefont\n  {Delvenne}, \\citenamefont {Yaliraki},\\ and\\ \\citenamefont\n  {Barahona}}]{Delvenne2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {Delvenne}}, \\bibinfo {author} {\\bibfnamefont {S.~N.}\\ \\bibnamefont\n  {Yaliraki}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Barahona}},\\ }\\href {\\doibase 10.1073/pnas.0903215107} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Proceedings of the National Academy of Sciences}\\\n  }\\textbf {\\bibinfo {volume} {107}},\\ \\bibinfo {pages} {12755} (\\bibinfo\n  {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Schaub}\\ \\emph\n  {et~al.}(2012{\\natexlab{a}})\\citenamefont {Schaub}, \\citenamefont {Delvenne},\n  \\citenamefont {Yaliraki},\\ and\\ \\citenamefont {Barahona}}]{Schaub2012}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.~T.}\\ \\bibnamefont\n  {Schaub}}, \\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {Delvenne}}, \\bibinfo {author} {\\bibfnamefont {S.~N.}\\ \\bibnamefont\n  {Yaliraki}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Barahona}},\\ }\\href {\\doibase 10.1371/journal.pone.0032210} {\\bibfield\n  {journal} {\\bibinfo  {journal} {PLoS ONE}\\ }\\textbf {\\bibinfo {volume} {7}},\\\n  \\bibinfo {pages} {e32210} (\\bibinfo {year} {2012}{\\natexlab{a}})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Newman}(2013{\\natexlab{a}})}]{Newman2013}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.~E.}\\ \\bibnamefont\n  {Newman}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physical Review E}\\ }\\textbf {\\bibinfo {volume} {88}},\\ \\bibinfo {pages}\n  {042822} (\\bibinfo {year} {2013}{\\natexlab{a}})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Rosvall}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Rosvall}, \\citenamefont {Esquivel}, \\citenamefont {Lancichinetti},\n  \\citenamefont {West},\\ and\\ \\citenamefont {Lambiotte}}]{Rosvall2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Rosvall}}, \\bibinfo {author} {\\bibfnamefont {A.~V.}\\ \\bibnamefont\n  {Esquivel}}, \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont\n  {Lancichinetti}}, \\bibinfo {author} {\\bibfnamefont {J.~D.}\\ \\bibnamefont\n  {West}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Nature communications}\\ }\\textbf {\\bibinfo {volume} {5}} (\\bibinfo {year}\n  {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Scholtes}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Scholtes}, \\citenamefont {Wider}, \\citenamefont {Pfitzner}, \\citenamefont\n  {Garas}, \\citenamefont {Tessone},\\ and\\ \\citenamefont\n  {Schweitzer}}]{Scholtes2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {I.}~\\bibnamefont\n  {Scholtes}}, \\bibinfo {author} {\\bibfnamefont {N.}~\\bibnamefont {Wider}},\n  \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont {Pfitzner}}, \\bibinfo\n  {author} {\\bibfnamefont {A.}~\\bibnamefont {Garas}}, \\bibinfo {author}\n  {\\bibfnamefont {C.~J.}\\ \\bibnamefont {Tessone}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {F.}~\\bibnamefont {Schweitzer}},\\ }\\href@noop {} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Nature communications}\\ }\\textbf {\\bibinfo\n  {volume} {5}} (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Song}\\ \\emph {et~al.}(2010)\\citenamefont {Song},\n  \\citenamefont {Qu}, \\citenamefont {Blumm},\\ and\\ \\citenamefont\n  {Barab\\'asi}}]{Song2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {C.}~\\bibnamefont\n  {Song}}, \\bibinfo {author} {\\bibfnamefont {Z.}~\\bibnamefont {Qu}}, \\bibinfo\n  {author} {\\bibfnamefont {N.}~\\bibnamefont {Blumm}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {A.-L.}\\ \\bibnamefont {Barab\\'asi}},\\ }\\href@noop {}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Science}\\ }\\textbf {\\bibinfo\n  {volume} {327}},\\ \\bibinfo {pages} {1018} (\\bibinfo {year}\n  {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Estrada}\\ and\\ \\citenamefont\n  {Higham}(2010)}]{Estrada2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {E.}~\\bibnamefont\n  {Estrada}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {D.~J.}\\ \\bibnamefont\n  {Higham}},\\ }\\href {\\doibase 10.1137/090761070} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {SIAM Review}\\ }\\textbf {\\bibinfo {volume} {52}},\\\n  \\bibinfo {pages} {696} (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Rosvall}\\ and\\ \\citenamefont\n  {Bergstrom}(2008)}]{Rosvall2008}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Rosvall}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {C.~T.}\\ \\bibnamefont\n  {Bergstrom}},\\ }\\href {\\doibase 10.1073/pnas.0706851105} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Proceedings of the National Academy of\n  Sciences}\\ }\\textbf {\\bibinfo {volume} {105}},\\ \\bibinfo {pages} {1118}\n  (\\bibinfo {year} {2008})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Delvenne}\\ \\emph {et~al.}(2013)\\citenamefont\n  {Delvenne}, \\citenamefont {Schaub}, \\citenamefont {Yaliraki},\\ and\\\n  \\citenamefont {Barahona}}]{Delvenne2013}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {Delvenne}}, \\bibinfo {author} {\\bibfnamefont {M.~T.}\\ \\bibnamefont\n  {Schaub}}, \\bibinfo {author} {\\bibfnamefont {S.~N.}\\ \\bibnamefont\n  {Yaliraki}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Barahona}},\\ }in\\ \\href {\\doibase 10.1007/978-1-4614-6729-8_11} {\\emph\n  {\\bibinfo {booktitle} {Dynamics On and Of Complex Networks, Volume 2}}},\\\n  \\bibinfo {series and number} {Modeling and Simulation in Science, Engineering\n  and Technology},\\ \\bibinfo {editor} {edited by\\ \\bibinfo {editor}\n  {\\bibfnamefont {A.}~\\bibnamefont {Mukherjee}}, \\bibinfo {editor}\n  {\\bibfnamefont {M.}~\\bibnamefont {Choudhury}}, \\bibinfo {editor}\n  {\\bibfnamefont {F.}~\\bibnamefont {Peruani}}, \\bibinfo {editor} {\\bibfnamefont\n  {N.}~\\bibnamefont {Ganguly}}, \\ and\\ \\bibinfo {editor} {\\bibfnamefont\n  {B.}~\\bibnamefont {Mitra}}}\\ (\\bibinfo  {publisher} {Springer New York},\\\n  \\bibinfo {year} {2013})\\ pp.\\ \\bibinfo {pages} {221--242}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Lambiotte}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Lambiotte}, \\citenamefont {Delvenne},\\ and\\ \\citenamefont\n  {Barahona}}]{Lambiotte2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}}, \\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {Delvenne}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Barahona}},\\ }\\href {\\doibase 10.1109/TNSE.2015.2391998} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Network Science and Engineering, IEEE\n  Transactions on}\\ }\\textbf {\\bibinfo {volume} {1}},\\ \\bibinfo {pages} {76}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Newman}(2006)}]{Newman2006}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.~E.~J.}\\\n  \\bibnamefont {Newman}},\\ }\\href {\\doibase 10.1073/pnas.0601602103} {\\bibfield\n   {journal} {\\bibinfo  {journal} {Proceedings of the National Academy of\n  Sciences}\\ }\\textbf {\\bibinfo {volume} {103}},\\ \\bibinfo {pages} {8577}\n  (\\bibinfo {year} {2006})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Reichardt}\\ and\\ \\citenamefont\n  {Bornholdt}(2004)}]{Reichardt2004}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont\n  {Reichardt}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {S.}~\\bibnamefont\n  {Bornholdt}},\\ }\\href {\\doibase 10.1103/PhysRevLett.93.218701} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Phys. Rev. Lett.}\\ }\\textbf {\\bibinfo\n  {volume} {93}},\\ \\bibinfo {pages} {218701} (\\bibinfo {year}\n  {2004})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Fiedler}(1975)}]{Fiedler1975}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Fiedler}},\\ }\\href {http://dml.cz/dmlcz/101357} {\\bibfield  {journal}\n  {\\bibinfo  {journal} {Czechoslovak Mathematical Journal}\\ }\\textbf {\\bibinfo\n  {volume} {25}},\\ \\bibinfo {pages} {619} (\\bibinfo {year} {1975})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Shi}\\ and\\ \\citenamefont {Malik}(2000)}]{Shi2000}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont\n  {Shi}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont {Malik}},\\\n  }\\href {\\doibase 10.1109/34.868688} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Pattern Analysis and Machine Intelligence, IEEE Transactions on}\\\n  }\\textbf {\\bibinfo {volume} {22}},\\ \\bibinfo {pages} {888 } (\\bibinfo {year}\n  {2000})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Krzakala}\\ \\emph {et~al.}(2013)\\citenamefont\n  {Krzakala}, \\citenamefont {Moore}, \\citenamefont {Mossel}, \\citenamefont\n  {Neeman}, \\citenamefont {Sly}, \\citenamefont {Zdeborov{\\'a}},\\ and\\\n  \\citenamefont {Zhang}}]{Krzakala2013}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Krzakala}}, \\bibinfo {author} {\\bibfnamefont {C.}~\\bibnamefont {Moore}},\n  \\bibinfo {author} {\\bibfnamefont {E.}~\\bibnamefont {Mossel}}, \\bibinfo\n  {author} {\\bibfnamefont {J.}~\\bibnamefont {Neeman}}, \\bibinfo {author}\n  {\\bibfnamefont {A.}~\\bibnamefont {Sly}}, \\bibinfo {author} {\\bibfnamefont\n  {L.}~\\bibnamefont {Zdeborov{\\'a}}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont\n  {P.}~\\bibnamefont {Zhang}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Proceedings of the National Academy of Sciences}\\ }\\textbf\n  {\\bibinfo {volume} {110}},\\ \\bibinfo {pages} {20935} (\\bibinfo {year}\n  {2013})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Evans}\\ and\\ \\citenamefont\n  {Lambiotte}(2009)}]{Evans2009}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {T.~S.}\\ \\bibnamefont\n  {Evans}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}},\\ }\\href {\\doibase 10.1103/PhysRevE.80.016105} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Phys. Rev. E}\\ }\\textbf {\\bibinfo {volume}\n  {80}},\\ \\bibinfo {pages} {016105} (\\bibinfo {year} {2009})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Friggeri}\\ \\emph {et~al.}(2011)\\citenamefont\n  {Friggeri}, \\citenamefont {Chelius},\\ and\\ \\citenamefont\n  {Fleury}}]{Friggeri2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont\n  {Friggeri}}, \\bibinfo {author} {\\bibfnamefont {G.}~\\bibnamefont {Chelius}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {E.}~\\bibnamefont {Fleury}},\\ }in\\\n  \\href {\\doibase 10.1109/PASSAT/SocialCom.2011.169} {\\emph {\\bibinfo\n  {booktitle} {Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third\n  Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third\n  International Conference on}}}\\ (\\bibinfo {year} {2011})\\ pp.\\ \\bibinfo\n  {pages} {258--265}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Ahn}\\ \\emph {et~al.}(2010)\\citenamefont {Ahn},\n  \\citenamefont {Bagrow},\\ and\\ \\citenamefont {Lehmann}}]{Ahn2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {Y.-Y.}\\ \\bibnamefont\n  {Ahn}}, \\bibinfo {author} {\\bibfnamefont {J.~P.}\\ \\bibnamefont {Bagrow}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {S.}~\\bibnamefont {Lehmann}},\\ }\\href\n  {\\doibase 10.1038/nature09182} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Nature}\\ }\\textbf {\\bibinfo {volume} {466}},\\ \\bibinfo {pages} {761}\n  (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Lambiotte}\\ and\\ \\citenamefont\n  {Rosvall}(2012)}]{Lambiotte2012}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Rosvall}},\\ }\\href {\\doibase 10.1103/PhysRevE.85.056107} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Phys. Rev. E}\\ }\\textbf {\\bibinfo {volume}\n  {85}},\\ \\bibinfo {pages} {056107} (\\bibinfo {year} {2012})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Delmotte}\\ \\emph {et~al.}(2011)\\citenamefont\n  {Delmotte}, \\citenamefont {Tate}, \\citenamefont {Yaliraki},\\ and\\\n  \\citenamefont {Barahona}}]{Delmotte2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont\n  {Delmotte}}, \\bibinfo {author} {\\bibfnamefont {E.~W.}\\ \\bibnamefont {Tate}},\n  \\bibinfo {author} {\\bibfnamefont {S.~N.}\\ \\bibnamefont {Yaliraki}}, \\ and\\\n  \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Barahona}},\\ }\\href@noop\n  {} {\\bibfield  {journal} {\\bibinfo  {journal} {Physical biology}\\ }\\textbf\n  {\\bibinfo {volume} {8}},\\ \\bibinfo {pages} {055010} (\\bibinfo {year}\n  {2011})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Blondel}\\ \\emph {et~al.}(2008)\\citenamefont\n  {Blondel}, \\citenamefont {Guillaume}, \\citenamefont {Lambiotte},\\ and\\\n  \\citenamefont {Lefebvre}}]{Blondel2008}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {V.~D.}\\ \\bibnamefont\n  {Blondel}}, \\bibinfo {author} {\\bibfnamefont {J.-L.}\\ \\bibnamefont\n  {Guillaume}}, \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {E.}~\\bibnamefont\n  {Lefebvre}},\\ }\\href {http://stacks.iop.org/1742-5468/2008/i=10/a=P10008}\n  {\\bibfield  {journal} {\\bibinfo  {journal} {Journal of Statistical Mechanics:\n  Theory and Experiment}\\ }\\textbf {\\bibinfo {volume} {2008}},\\ \\bibinfo\n  {pages} {P10008} (\\bibinfo {year} {2008})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Chung}(2005)}]{Chung2005}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Chung}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Annals\n  of Combinatorics}\\ }\\textbf {\\bibinfo {volume} {9}},\\ \\bibinfo {pages} {1}\n  (\\bibinfo {year} {2005})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Satuluri}\\ and\\ \\citenamefont\n  {Parthasarathy}(2011)}]{Satuluri2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont\n  {Satuluri}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {S.}~\\bibnamefont\n  {Parthasarathy}},\\ }in\\ \\href@noop {} {\\emph {\\bibinfo {booktitle}\n  {Proceedings of the 14th International Conference on Extending Database\n  Technology}}}\\ (\\bibinfo {organization} {ACM},\\ \\bibinfo {year} {2011})\\ pp.\\\n  \\bibinfo {pages} {343--354}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Fortunato}\\ and\\ \\citenamefont\n  {Barthel\\'emy.}(2006)}]{Fortunato2006}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Fortunato}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Barthel\\'emy.}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Proc. Natl. Acad. Sci. USA}\\ }\\textbf {\\bibinfo {volume} {104}},\\ \\bibinfo\n  {pages} {36} (\\bibinfo {year} {2006})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Good}\\ \\emph {et~al.}(2010)\\citenamefont {Good},\n  \\citenamefont {de~Montjoye},\\ and\\ \\citenamefont {Clauset}}]{Good2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {B.~H.}\\ \\bibnamefont\n  {Good}}, \\bibinfo {author} {\\bibfnamefont {Y.-A.}\\ \\bibnamefont\n  {de~Montjoye}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont\n  {Clauset}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Phys.\n  Rev. E}\\ }\\textbf {\\bibinfo {volume} {81}},\\ \\bibinfo {pages} {046106}\n  (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Fortunato}(2010)}]{Fortunato2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {F.}~\\bibnamefont\n  {Fortunato}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physics Reports}\\ }\\textbf {\\bibinfo {volume} {486}},\\ \\bibinfo {pages} {75}\n  (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Schaub}\\ \\emph\n  {et~al.}(2012{\\natexlab{b}})\\citenamefont {Schaub}, \\citenamefont\n  {Lambiotte},\\ and\\ \\citenamefont {Barahona}}]{Schaub2012b}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.~T.}\\ \\bibnamefont\n  {Schaub}}, \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont {Lambiotte}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Barahona}},\\ }\\href\n  {\\doibase 10.1103/PhysRevE.86.026112} {\\bibfield  {journal} {\\bibinfo\n  {journal} {Phys. Rev. E}\\ }\\textbf {\\bibinfo {volume} {86}},\\ \\bibinfo\n  {pages} {026112} (\\bibinfo {year} {2012}{\\natexlab{b}})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Lambiotte}(2010)}]{Lambiotte2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {Lambiotte}},\\ }in\\ \\href\n  {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5520347} {\\emph\n  {\\bibinfo {booktitle} {Modeling and Optimization in Mobile, Ad Hoc and\n  Wireless Networks (WiOpt), 2010 Proceedings of the 8th International\n  Symposium on}}}\\ (\\bibinfo  {publisher} {IEEE},\\ \\bibinfo {year} {2010})\\\n  pp.\\ \\bibinfo {pages} {546--553}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Holland}\\ \\emph {et~al.}(1983)\\citenamefont\n  {Holland}, \\citenamefont {Laskey},\\ and\\ \\citenamefont\n  {Leinhardt}}]{Holland1983}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {P.~W.}\\ \\bibnamefont\n  {Holland}}, \\bibinfo {author} {\\bibfnamefont {K.~B.}\\ \\bibnamefont {Laskey}},\n  \\ and\\ \\bibinfo {author} {\\bibfnamefont {S.}~\\bibnamefont {Leinhardt}},\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Social networks}\\\n  }\\textbf {\\bibinfo {volume} {5}},\\ \\bibinfo {pages} {109} (\\bibinfo {year}\n  {1983})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Karrer}\\ and\\ \\citenamefont\n  {Newman}(2011)}]{Karrer2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {B.}~\\bibnamefont\n  {Karrer}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {M.~E.}\\ \\bibnamefont\n  {Newman}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physical Review E}\\ }\\textbf {\\bibinfo {volume} {83}},\\ \\bibinfo {pages}\n  {016107} (\\bibinfo {year} {2011})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Peixoto}(2014)}]{Peixoto2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {T.~P.}\\ \\bibnamefont\n  {Peixoto}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Physical Review X}\\ }\\textbf {\\bibinfo {volume} {4}},\\ \\bibinfo {pages}\n  {011047} (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Peixoto}\\ and\\ \\citenamefont\n  {Rosvall}(2015)}]{Peixoto2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {T.~P.}\\ \\bibnamefont\n  {Peixoto}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Rosvall}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {arXiv\n  preprint arXiv:1509.04740}\\ } (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Meila}(2007)}]{Meila2007}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Meila}},\\ }\\href {\\doibase DOI: 10.1016/j.jmva.2006.11.013} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Journal of Multivariate Analysis}\\ }\\textbf\n  {\\bibinfo {volume} {98}},\\ \\bibinfo {pages} {873 } (\\bibinfo {year}\n  {2007})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Holme}\\ and\\ \\citenamefont\n  {Saram\u00c3\u00a4ki}(2012)}]{Holme2012}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {P.}~\\bibnamefont\n  {Holme}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont\n  {Saram\u00c3\u00a4ki}},\\ }\\href {\\doibase 10.1016/j.physrep.2012.03.001} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Physics Reports}\\ }\\textbf {\\bibinfo {volume}\n  {519}},\\ \\bibinfo {pages} {97 } (\\bibinfo {year} {2012})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Mucha}\\ \\emph {et~al.}(2010)\\citenamefont {Mucha},\n  \\citenamefont {Richardson}, \\citenamefont {Macon}, \\citenamefont {Porter},\\\n  and\\ \\citenamefont {Onnela}}]{Mucha2010}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {P.~J.}\\ \\bibnamefont\n  {Mucha}}, \\bibinfo {author} {\\bibfnamefont {T.}~\\bibnamefont {Richardson}},\n  \\bibinfo {author} {\\bibfnamefont {K.}~\\bibnamefont {Macon}}, \\bibinfo\n  {author} {\\bibfnamefont {M.~A.}\\ \\bibnamefont {Porter}}, \\ and\\ \\bibinfo\n  {author} {\\bibfnamefont {J.-P.}\\ \\bibnamefont {Onnela}},\\ }\\href {\\doibase\n  10.1126/science.1184819} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {Science}\\ }\\textbf {\\bibinfo {volume} {328}},\\ \\bibinfo {pages} {876}\n  (\\bibinfo {year} {2010})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Delvenne}\\ \\emph {et~al.}(2015)\\citenamefont\n  {Delvenne}, \\citenamefont {Lambiotte},\\ and\\ \\citenamefont\n  {Rocha}}]{delvenne2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {Delvenne}}, \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont {Lambiotte}},\n  \\ and\\ \\bibinfo {author} {\\bibfnamefont {L.~E.}\\ \\bibnamefont {Rocha}},\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Nature\n  communications}\\ }\\textbf {\\bibinfo {volume} {6}} (\\bibinfo {year}\n  {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Saramaki}\\ and\\ \\citenamefont\n  {Holme}(2015)}]{Saramaki2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont\n  {Saramaki}}\\ and\\ \\bibinfo {author} {\\bibfnamefont {P.}~\\bibnamefont\n  {Holme}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {arXiv:1508.00693}\\ } (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {{Gueuning}}\\ \\emph {et~al.}(2015)\\citenamefont\n  {{Gueuning}}, \\citenamefont {{Delvenne}},\\ and\\ \\citenamefont\n  {{Lambiotte}}}]{Gueuning2015}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {{Gueuning}}}, \\bibinfo {author} {\\bibfnamefont {J.-C.}\\ \\bibnamefont\n  {{Delvenne}}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {R.}~\\bibnamefont\n  {{Lambiotte}}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {arXiv:1508.04006}\\ } (\\bibinfo {year} {2015})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Eagle}\\ \\emph {et~al.}(2009)\\citenamefont {Eagle},\n  \\citenamefont {Pentland},\\ and\\ \\citenamefont {Lazer}}]{Eagle2009}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {N.}~\\bibnamefont\n  {Eagle}}, \\bibinfo {author} {\\bibfnamefont {A.~S.}\\ \\bibnamefont {Pentland}},\n  \\ and\\ \\bibinfo {author} {\\bibfnamefont {D.}~\\bibnamefont {Lazer}},\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {Proceedings of the\n  National Academy of Sciences}\\ }\\textbf {\\bibinfo {volume} {106}},\\ \\bibinfo\n  {pages} {15274} (\\bibinfo {year} {2009})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Gemmetto}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Gemmetto}, \\citenamefont {Barrat},\\ and\\ \\citenamefont\n  {Cattuto}}]{Gemmetto2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {V.}~\\bibnamefont\n  {Gemmetto}}, \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont {Barrat}}, \\\n  and\\ \\bibinfo {author} {\\bibfnamefont {C.}~\\bibnamefont {Cattuto}},\\\n  }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal} {BMC infectious\n  diseases}\\ }\\textbf {\\bibinfo {volume} {14}},\\ \\bibinfo {pages} {695}\n  (\\bibinfo {year} {2014})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Stehl{\\'e}}\\ \\emph {et~al.}(2011)\\citenamefont\n  {Stehl{\\'e}}, \\citenamefont {Voirin}, \\citenamefont {Barrat}, \\citenamefont\n  {Cattuto}, \\citenamefont {Isella}, \\citenamefont {Pinton}, \\citenamefont\n  {Quaggiotto}, \\citenamefont {Van~den Broeck}, \\citenamefont {Regis},\n  \\citenamefont {Lina} \\emph {et~al.}}]{Stehle2011}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {J.}~\\bibnamefont\n  {Stehl{\\'e}}}, \\bibinfo {author} {\\bibfnamefont {N.}~\\bibnamefont {Voirin}},\n  \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont {Barrat}}, \\bibinfo\n  {author} {\\bibfnamefont {C.}~\\bibnamefont {Cattuto}}, \\bibinfo {author}\n  {\\bibfnamefont {L.}~\\bibnamefont {Isella}}, \\bibinfo {author} {\\bibfnamefont\n  {J.-F.}\\ \\bibnamefont {Pinton}}, \\bibinfo {author} {\\bibfnamefont\n  {M.}~\\bibnamefont {Quaggiotto}}, \\bibinfo {author} {\\bibfnamefont\n  {W.}~\\bibnamefont {Van~den Broeck}}, \\bibinfo {author} {\\bibfnamefont\n  {C.}~\\bibnamefont {Regis}}, \\bibinfo {author} {\\bibfnamefont\n  {B.}~\\bibnamefont {Lina}},  \\emph {et~al.},\\ }\\href@noop {} {\\  (\\bibinfo\n  {year} {2011})}\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Newman}(2013{\\natexlab{b}})}]{Newman2013a}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Newman}},\\ }\\href@noop {} {\\bibfield  {journal} {\\bibinfo  {journal}\n  {arXiv:1308.6494}\\ } (\\bibinfo {year} {2013}{\\natexlab{b}})}\\BibitemShut\n  {NoStop}\n\\bibitem [{\\citenamefont {Newman}\\ \\emph {et~al.}(2006)\\citenamefont {Newman},\n  \\citenamefont {Barabasi},\\ and\\ \\citenamefont {Watts}}]{Newman2006a}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Newman}}, \\bibinfo {author} {\\bibfnamefont {A.-L.}\\ \\bibnamefont\n  {Barabasi}}, \\ and\\ \\bibinfo {author} {\\bibfnamefont {D.~J.}\\ \\bibnamefont\n  {Watts}},\\ }\\href@noop {} {\\emph {\\bibinfo {title} {{T}he structure and\n  dynamics of networks}}}\\ (\\bibinfo  {publisher} {Princeton University\n  Press},\\ \\bibinfo {year} {2006})\\BibitemShut {NoStop}\n\\bibitem [{\\citenamefont {Kivel{\\\"a}}\\ \\emph {et~al.}(2014)\\citenamefont\n  {Kivel{\\\"a}}, \\citenamefont {Arenas}, \\citenamefont {Barthelemy},\n  \\citenamefont {Gleeson}, \\citenamefont {Moreno},\\ and\\ \\citenamefont\n  {Porter}}]{Kivelae2014}\n  \\BibitemOpen\n  \\bibfield  {author} {\\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont\n  {Kivel{\\\"a}}}, \\bibinfo {author} {\\bibfnamefont {A.}~\\bibnamefont {Arenas}},\n  \\bibinfo {author} {\\bibfnamefont {M.}~\\bibnamefont {Barthelemy}}, \\bibinfo\n  {author} {\\bibfnamefont {J.~P.}\\ \\bibnamefont {Gleeson}}, \\bibinfo {author}\n  {\\bibfnamefont {Y.}~\\bibnamefont {Moreno}}, \\ and\\ \\bibinfo {author}\n  {\\bibfnamefont {M.~A.}\\ \\bibnamefont {Porter}},\\ }\\href@noop {} {\\bibfield\n  {journal} {\\bibinfo  {journal} {Journal of Complex Networks}\\ }\\textbf\n  {\\bibinfo {volume} {2}},\\ \\bibinfo {pages} {203} (\\bibinfo {year}\n  {2014})}\\BibitemShut {NoStop}\n\\end{thebibliography}\n\n", "itemtype": "equation", "pos": 45152, "prevtext": "\nClearly this matrix describes the line graph for a memory walker with parameters set to $r_2 = 0, r_3=1, r_{>3}=1$ (see section \\ref{sec:mem_models}).\nThe associated transition matrix $ T^\\text{B}$ of the non-backtracking random walk is  simply obtained through normalisation:\n\n", "index": 25, "text": "\\begin{equation}\n    T_{\\alpha,\\beta}^{B} = \\dfrac{B_{\\alpha \\beta}}{k^{\\rm out}_{\\alpha}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"T_{\\alpha,\\beta}^{B}=\\dfrac{B_{\\alpha\\beta}}{k^{\\rm out}_{\\alpha}},\" display=\"block\"><mrow><mrow><msubsup><mi>T</mi><mrow><mi>\u03b1</mi><mo>,</mo><mi>\u03b2</mi></mrow><mi>B</mi></msubsup><mo>=</mo><mfrac><msub><mi>B</mi><mrow><mi>\u03b1</mi><mo>\u2062</mo><mi>\u03b2</mi></mrow></msub><msubsup><mi>k</mi><mi>\u03b1</mi><mi>out</mi></msubsup></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}]