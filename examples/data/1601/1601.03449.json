[{"file": "1601.03449.tex", "nexttext": "\nwhere the coefficients $J_{ij}$ are numerically fit to match individual and pairwise frequencies ${\\langle {x_i} \\rangle}$ and ${\\langle {x_i x_j} \\rangle}$.\n\nIn the dynamical branching process the dominant causes of conflict are temporal pairwise interactions---an individual joins the current fight with some finite probability only when it sees another individual join. Fight initiation is assumed to occur at a slower timescale, when a random individual becomes aggressive. Individuals join the fight by receiving aggression from or initiating aggression against an individual already in the fight. Parameters include individual initiation parameters $p_{0i}$, each denoting the relative probability that individual $i$ begins a fight, and conditional redirection parameters $p_{ij}$, each denoting the probability that $j$ joins a fight due to $i$ having just joined.  We consider only the relative ordering of individuals joining fights, not direct interactions, and estimate parameters by fitting conditional frequencies $P_{ij}$ --- the frequency of seeing individual $j$ at any later time in a fight sequence given that $i$ appeared first.\n\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151109_fightSizeDistributions.pdf}\n\\caption{ Testing fight-joining processes fit to individual-level data:\n    Models that include social correlations (the equilibrium maximum entropy and dynamic branching process models) can reproduce the relatively long tail of the observed distribution of fight sizes, whereas assuming independent fight joining events (the independent model) cannot.\n\\label{fightSizeDistributions}\n}\n\\end{figure}\n\n\nWe test the performance of each model by its ability to predict the distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}) and correlations up to 3rd order ({Fig.~\\ref{{isingStatistics}}}) (SI, Sec. \\ref{modelevaluation}). We rule out the independent model (SI, Sec. \\ref{modelevaluation}).  We find the empirically parameterized maximum entropy (as in prior work \\cite{DanKraFla12}) and branching process models recover the observed distribution of fight sizes, indicating that these models are mechanistically consistent with the data. Because these models are well understood modeling frameworks in statistical physics, they offer a rigorous foundation for proceeding with a statistical mechanical description of the system. This allows us to define and quantify the sensitivity to perturbations and characterize criticality in a finite system.\n\nA phase transition (SI, Sec~\\ref{evalsens}) can be thought of as sensitivity that diverges in the limit of infinite number of individuals due to a collective instability. This instability is an aggregate-level property that causes perturbations to individuals to be amplified and spread to change the behavior of the entire system (SI, Sec~\\ref{collectinstab}).  While phase transitions are typically identified by examining the asymptotic behavior of the infinite limit, social systems are often not well approximated by such a ``thermodynamic'' limit.  Yet sensitivity and instability are still important concepts in these systems.  Here, in both the maximum entropy and dynamical branching models of our finite system, we find that changes to key parameters can lead quickly to increased sensitivity and instability.  We take this to be an operational definition of a ``critical point'' in a finite system (for a review of other definitions, see \\cite{Valverde2015}).\n\nWe operationalize sensitivity as the derivative of average fight size with respect to an individual's agitation, averaged over individuals.  In the equilibrium model, the control parameter associated with the average fight size ${\\langle {s} \\rangle}$ is an external ``field'' ${h_{\\mathrm{ext}}}$, which we interpret as uniformly increasing each individual's agitation, making it more likely to become involved in fights. Adding an external field to {Eq.~(\\ref{{isingModel}})}, we have $L(\\vec x) = -\\sum x_i J_{ij} x_j - {h_{\\mathrm{ext}}} \\sum x_i$. The corresponding sensitivity is equal to the susceptibility $\\chi$:\n\n", "itemtype": "equation", "pos": 4496, "prevtext": "\n\n\n\\begin{bibunit}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\title{Control of critical behavior in a small-scale social system}\n\\author{Bryan C. Daniels}\n\\affiliation{ASU-SFI Center for Biosocial Complex Systems, Arizona State University, Tempe, AZ}\n\\author{David C. Krakauer}\n\\affiliation{Santa Fe Institute, Santa Fe, NM}\n\\affiliation{ASU-SFI Center for Biosocial Complex Systems, Arizona State University, Tempe, AZ}\n\\author{Jessica C. Flack}\n\\affiliation{Santa Fe Institute, Santa Fe, NM}\n\\affiliation{ASU-SFI Center for Biosocial Complex Systems, Arizona State University, Tempe, AZ}\n\n\\begin{abstract}\n\\baselineskip16pt\nOver the last decade new technologies for making large numbers of fine-grained measurements have led to the surprising discovery that many biological systems sit near a critical point \\cite{Mora2011, Valverde2015}. These systems are potentially more adaptive in that small changes to component behavior can induce large-scale changes in aggregate structure and function. Examples include networks of neurons \\cite{Kastner2015}, ant groups cooperatively carrying a load \\cite{GelPinFon15},  and animal groups forming flocks and schools \\cite{Bialek2014}.  Accounting for criticality remains a challenge as sensitivity to perturbation suggests a lack of robustness. Furthermore, change induced by perturbation may not be adaptive. Complicating matters further critical phenomena can result from history-dependent stochastic processes \\cite{Corominas2014}. A question central to distinguishing among these conflicting views of criticality is to what degree criticality can be controlled by the components of the system \\cite{Valverde2015}. We address the control of criticality using data on conflict dynamics and fight sizes from an animal society model system (\\emph{Macaca nemestrina}, $n$=48). The system is fundamentally finite so we operationalize criticality in information theoretic terms using Fisher information and a measure of  instability. We analyze criticality using empirically-grounded equilibrium (maximum entropy) and dynamic (branching process) models of the monkeys' fight-joining behavior. We find that (1) this \\emph{heterogeneous, socially} organized system, like homogeneous, spatial systems (flocks and schools), sits near a critical point, (2) the contributions individuals make to how critical the system is can be quantified and vary, and (3) the distance from the critical point (DFC) can be controlled through biologically plausible mechanisms operating on this heterogeneity. These mechanisms include third-party policing, which dampens fight participation of the individuals with the largest effect on DFC \\cite{Flack:2005ih,Flack:2006vi,Flack:2005dg}. Control of DFC allows biological systems to balance the tradeoff between robustness and need for rapid change.\n\\end{abstract}\n\n\\maketitle\n\n\nWe analyze a time-series of fights from a large, captive pigtailed macaque group collected over multiple observation periods during a four month period (SI Sec. \\ref{EmpiricalMethods}). The data consist of a series of binary fight participation vectors $\\vec x$ of length $n$. For each vector an individual is assigned a ``1'' if it participated in that fight and a ``0'' if it did not (SI, Sec. \\ref{EmpiricalMethods}).\n\nTo study criticality in our model system we can use tools from statistical mechanics. These tools are best deployed when the study system can be described within a simple, tractable, and well understood modeling framework. Hence our first task is to assess whether our data are consistent with any of three basic, but biologically valid, fight joining models: (1) independent fight joining decisions, (2) correlated fight joining decisions  (equilibrium model), and (3) strategic, correlated fight joining decisions (dynamical branching process) (SI, Sec. \\ref{modeldescription}) \\cite{Krakauer:2011tb}.  We evaluate these models by determining how effectively each recovers a key social feature --- the distribution of fight sizes $s$ \\cite{Dedeo2010} (SI, Sec.\\ref{modeldescription})---when parameterized by the empirical data.\n\nIn the independent model individuals join fights without taking into account which others are currently fighting (SI, Sec. \\ref{modelevaluation}). \n\nThe correlated decision-making model is an equilibrium maximum entropy model that fits all pairwise correlations and corresponds to a spin-glass model \\cite{DanKraFla12}. The resulting probability distribution over possible fights has relative negative log-likelihood,\n\n", "index": 1, "text": "\\begin{equation}\n\\label{isingModel}\nL(\\vec x) = -\\sum x_i J_{ij} x_j,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"L(\\vec{x})=-\\sum x_{i}J_{ij}x_{j},\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>x</mi><mi>j</mi></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\nResults for the equilibrium model are shown in {Fig.~\\ref{{susceptibilityFigure}}}A. For fit parameters (${h_{\\mathrm{ext}}} = 0$), there is increased sensitivity compared to a noninteracting model with the same mean fight size, meaning that an amplification process is occurring that makes changes to patterns of aggression at the individual level ``visible'' at the global system level. This amplification process cannot be attributed to external events as these data were collected in a captive setting in which such disturbances were minimized (SI, Sec~\\ref{modeldescription}).\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151109_sensitivity_stability_vs_field.pdf}\n\\caption{ \\label{susceptibilityFigure}\nThe system is near a sensitive and unstable region of parameter space. (Left) The susceptibility $\\chi$, measuring the sensitivity of average fight size to an external perturbation, has a peak near the fit parameters (at ${h_{\\mathrm{ext}}} = 0$). The susceptibility is also equal to the Fisher information $F({h_{\\mathrm{ext}}})$, describing how quickly the distribution over fights becomes distinguishable as ${h_{\\mathrm{ext}}}$ is varied. (Middle) Instability of the lowest order mean-field solution is indicated by the eigenvalue $\\lambda$ becoming larger than 1. Yellow dashed lines indicate a system of the same size with independent individuals, and red dashed lines indicate a homogeneous system of the same size tuned to be marginally unstable at ${h_{\\mathrm{ext}}} = 0$.  (Right) The transition is associated with large changes in mean fight size.\n}\n\\end{figure}\n\nThe susceptibility can also be interpreted as a Fisher information, an information theoretic quantity that describes how sensitive a distribution is to the parameters that describe it (SI~\\ref{FisherInfoSection}). A large $\\chi$ implies faster learning: large susceptibility means that aggregate level statistics are informative about conflict dynamics at the individual level \\cite{Tchernookov2012,Prokopenko2011}.\n\nAnalogously to the susceptibility in the equilibrium model, we can define sensitivity in the dynamic model as how quickly fight sizes grow following perturbation of redirection probabilities $p_{ij}$:\n\n", "itemtype": "equation", "pos": 8688, "prevtext": "\nwhere the coefficients $J_{ij}$ are numerically fit to match individual and pairwise frequencies ${\\langle {x_i} \\rangle}$ and ${\\langle {x_i x_j} \\rangle}$.\n\nIn the dynamical branching process the dominant causes of conflict are temporal pairwise interactions---an individual joins the current fight with some finite probability only when it sees another individual join. Fight initiation is assumed to occur at a slower timescale, when a random individual becomes aggressive. Individuals join the fight by receiving aggression from or initiating aggression against an individual already in the fight. Parameters include individual initiation parameters $p_{0i}$, each denoting the relative probability that individual $i$ begins a fight, and conditional redirection parameters $p_{ij}$, each denoting the probability that $j$ joins a fight due to $i$ having just joined.  We consider only the relative ordering of individuals joining fights, not direct interactions, and estimate parameters by fitting conditional frequencies $P_{ij}$ --- the frequency of seeing individual $j$ at any later time in a fight sequence given that $i$ appeared first.\n\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151109_fightSizeDistributions.pdf}\n\\caption{ Testing fight-joining processes fit to individual-level data:\n    Models that include social correlations (the equilibrium maximum entropy and dynamic branching process models) can reproduce the relatively long tail of the observed distribution of fight sizes, whereas assuming independent fight joining events (the independent model) cannot.\n\\label{fightSizeDistributions}\n}\n\\end{figure}\n\n\nWe test the performance of each model by its ability to predict the distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}) and correlations up to 3rd order ({Fig.~\\ref{{isingStatistics}}}) (SI, Sec. \\ref{modelevaluation}). We rule out the independent model (SI, Sec. \\ref{modelevaluation}).  We find the empirically parameterized maximum entropy (as in prior work \\cite{DanKraFla12}) and branching process models recover the observed distribution of fight sizes, indicating that these models are mechanistically consistent with the data. Because these models are well understood modeling frameworks in statistical physics, they offer a rigorous foundation for proceeding with a statistical mechanical description of the system. This allows us to define and quantify the sensitivity to perturbations and characterize criticality in a finite system.\n\nA phase transition (SI, Sec~\\ref{evalsens}) can be thought of as sensitivity that diverges in the limit of infinite number of individuals due to a collective instability. This instability is an aggregate-level property that causes perturbations to individuals to be amplified and spread to change the behavior of the entire system (SI, Sec~\\ref{collectinstab}).  While phase transitions are typically identified by examining the asymptotic behavior of the infinite limit, social systems are often not well approximated by such a ``thermodynamic'' limit.  Yet sensitivity and instability are still important concepts in these systems.  Here, in both the maximum entropy and dynamical branching models of our finite system, we find that changes to key parameters can lead quickly to increased sensitivity and instability.  We take this to be an operational definition of a ``critical point'' in a finite system (for a review of other definitions, see \\cite{Valverde2015}).\n\nWe operationalize sensitivity as the derivative of average fight size with respect to an individual's agitation, averaged over individuals.  In the equilibrium model, the control parameter associated with the average fight size ${\\langle {s} \\rangle}$ is an external ``field'' ${h_{\\mathrm{ext}}}$, which we interpret as uniformly increasing each individual's agitation, making it more likely to become involved in fights. Adding an external field to {Eq.~(\\ref{{isingModel}})}, we have $L(\\vec x) = -\\sum x_i J_{ij} x_j - {h_{\\mathrm{ext}}} \\sum x_i$. The corresponding sensitivity is equal to the susceptibility $\\chi$:\n\n", "index": 3, "text": "\\begin{equation}\n\\frac{1}{n} \\sum_i{\\frac{d {\\langle {s} \\rangle}}{d h_i}}\n = \\chi = \\frac{1}{n} \\frac{d {\\langle {s} \\rangle}}{d {h_{\\mathrm{ext}}}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\frac{1}{n}\\sum_{i}{\\frac{d{\\langle{s}\\rangle}}{dh_{i}}}=\\chi=\\frac{1}{n}\\frac%&#10;{d{\\langle{s}\\rangle}}{d{h_{\\mathrm{ext}}}}.\" display=\"block\"><mrow><mrow><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>s</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><msub><mi>h</mi><mi>i</mi></msub></mrow></mfrac></mrow></mrow><mo>=</mo><mi>\u03c7</mi><mo>=</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>s</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><msub><mi>h</mi><mi>ext</mi></msub></mrow></mfrac></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhere $p$ adds probability uniformly to all redirection probabilities.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151120_ellStar_withMinMax_numProcs11_numSamples1e4}\n\\caption{ \n    In equilibrium (top) and dynamical (bottom) models,\n    forcing a few individuals to become simultaneously\n    aggressive leads to a more sensitive system. (Left)\n    In each model, peak sensitivity is reached when on average\n    3-5 individuals are forced. Shaded regions indicate\n    the standard deviation around the mean over different\n    realizations of the chosen individuals. Purple and\n    blue dotted lines indicate choices of forced individuals\n    that maximize and minimize the resulting mean fight size.\n    (Middle) The mean fight size.\n    (Right) The lowest-order stability\n    measured in each model, corresponding to the\n    eigenvalue $\\lambda_0$ in the equilibrium model\n    and $R_0$ in the dynamical model (SI, Sec~\\ref{collectinstab}).  A value above\n    1 in each case indicates instability to linear order.\n\\label{ellStarFigure}\n}\n\\end{figure}\n\n{Fig.~\\ref{{susceptibilityFigure}}} suggests that the system is near a transition. To quantify this statement in a biologically meaningful way we measure how sensitivity and stability vary as we force---through parameterized-simulation---some number of individuals to fight continuously (while allowing the system to consist only of the non-forced individuals). The number of individuals required to reach a peak in sensitivity corresponding to a collective instability (SI, Sec.\\ref{collectinstab}) is a measure of the \\emph{distance of the system from the critical point} (DFC). Beyond this peak lies saturation and decreasing sensitivity.\n\nIn the equilibrium model forcing is accomplished by removing the forced individuals and adding their interaction terms to the fields acting on the remaining individuals: the new fields are given by $J^*_{ii} = J_{ii} + \\sum_{\\mathrm{forced}~k} 2 J_{ik}$. In the dynamic model this is accomplished by explicitly including the forced individuals at each timestep in the simulation but only recording the behavior of the remaining individuals.  The change in sensitivity caused by forcing each individual also provides ``sensitivity scores'' that measure the extent to which each individual brings the system closer to criticality.\n\n\n\nAs shown in {Fig.~\\ref{{ellStarFigure}}}, both models predict a substantial increase in sensitivity when a few individuals are forced to be continuously involved in conflict. The system begins to saturate in sensitivity after 3-5 individuals are simultaneously forced. This result is similar to the finding that bird flocks require only a small proportion of informed individuals to correctly choose direction\\cite{COUZIN2005,LEONARD2012}. \n\nWe use perturbation theory to demonstrate that this sensitivity arises from instability in each model (SI, Sec.\\ref{stabilitySection}). The number of individuals required to reach a peak in sensitivity corresponding to an aggregate-level instability (SI, Sec.\\ref{collectinstab}) is a \\emph{biologically meaningful measure} of the \\emph{distance of the system from the critical point}.\n\nIn addition we find that individuals vary in their sensitivity scores such that forcing participation of individuals with the top two to three sensitivity scores is sufficient to move the system close to a critical point (SI, Sec.\\ref{sensitiveindividuals}).\n\n\nThese results tell us that fight involvement by the high sensitivity score individuals can be tuned two ways: through \\emph{direct tuning}, as they opportunistically or strategically increase or decrease their fight participation, and \\emph{indirect tuning}, through the actions of others that increase or decrease the frequency with which aggression is directed or redirected at these individuals (SI, Sec.\\ref{EmpiricalMethods} and SI, Secs.\\ref{tuning}). This includes through the policing mechanism in which powerful third parties to the fight intervene and impartially break it up  (SI, Sec.\\ref{EmpiricalMethods} and SI, Secs.\\ref{tuning}) \\cite{Flack:2005dg}. Policing dampens fight involvement by significantly reducing how frequently fights erupt and also by reducing the frequency of redirected aggression received, particularly by high sensitivity individuals\\cite{Flack:2005ih}. Hence DFC can in principle be controlled through policing or by the high sensitivity individuals themselves as they up or down regulate the frequency with which they join fights. \n\nAll biological systems need to balance stability and robustness with the need for rapid adaptive change. Yet many biological systems are observed to sit near a critical point, which would seem to suggest a lack of robustness. This apparent conflict can be resolved by the discovery that DFC can be tuned through realistic social mechanisms. Tuning DFC allows for switching between stability and criticality, providing a means for accessing alternative social structures that may be more appropriate if and when the environment should change\\cite{FlaErwEll13}. This discovery raises many new questions: It is one thing for tuning to be possible and another to know when to tune and whether to tune towards robustness or criticality (SI, Sec.\\ref{adaptive value}). We propose robustness is a good strategy when the environment is stable and low variance. Criticality is a good strategy when the environment is uncertain (SI, Sec.\\ref{adaptive value}). In addition for tuning to be adaptive the state of the environment must be accurately perceived by, or mirrored in, the individuals whose behavior changes DFC. This appears to be the case in our system (SI, Sec.\\ref{adaptive value}) but may present a crucial evolutionary challenge for other systems.  Future comparative studies are required to quantify the range of DFC across social groups within a species, as well as across biological systems more generally, and to study how DFC might be controlled in other systems. We can then assess whether variation in DFC and its control are correlated with rate of change in the environment and or environmental uncertainty as we expect.\n\n\n\n\n\n\n\\section*{End Notes}\\begin{itemize}\n\n\\item The authors thank Chris Ellison, Philip Poon, Eddie Lee, Eleanor Brush, Yoav Kallus, and Raissa D'Souza for helpful discussion. Partial support for this project was provided by the Templeton Foundation through grants to study complexity and the mind-brain problem, and by the Office of Army Research under contract W911NF-13-1-0340. JCF thanks Frans de Waal and the animal care staff at Yerkes National Primate Research Center for support during data collection.\n\\item BCD designed the study, built the models, analyzed and interpreted data, and wrote the paper. DCK contributed to model development, analysis, and interpretation, and wrote the paper. JCF designed the study, collected the data, contributed to model development, analysis, and interpretation, and wrote the paper.\nCorrespondence and requests for materials should be addressed to Bryan Daniels (bryan.daniels.1@asu.edu).\n\n\n\\end{itemize}\n\n\n\n\\putbib\n\\end{bibunit}\n\n\\begin{bibunit}\n\n\\clearpage\n\n\n\n\n\n\\begin{center}\n\\textbf{Supplementary Information}\n\\\\~\\\\\nControl of critical behavior in a small-scale social system\n\\\\\nBryan C. Daniels, David C. Krakauer, Jessica C. Flack\n\\end{center}\n\n\\section{Empirical Methods}\n\\label{EmpiricalMethods}\n\\subsection{Ethics statement}\nThe data collection protocol was approved by the Emory University Institutional Animal Care and Use Committee and all data were collected in accordance with its guidelines for the ethical treatment of nonhuman study subjects.\n\n\\subsection{Study system}\nThe data were collected by JCF in 1998 from a large group of captive pigtailed macaques (\\emph{Macaca nemestrina}) socially-housed at the Yerkes National Primate Center in Lawrenceville, Georgia. Pigtailed macaques are indigenous to south East Asia and live in multi-male, multi-female societies characterized by female matrilines and male group transfer upon onset of puberty~\\cite{Caldecott:1986uk}. Pigtailed macaques breed all year. Females develop swellings when in \\OE strus. Macaque societies more generally are characterized by social learning at the individual level, social structures that arise from nonlinear processes and feed back to influence individual behavior, frequent non-kin interactions and multiplayer conflict interactions, the cost and benefits of which can be quantified at the individual and social network levels~\\cite {Flack:2007ir, Flack:2006jh, Flack:2006vi, Flack:2005ih, Flack:2005dg, Thierry:2004tj}.\n\nThe study group contained $n = 48$ socially-mature individuals (we exclude non-mature individuals because their behavioral strategies are still developing and so are non-stationary over short timescales) and 84 individuals in total. Socially-mature males were at least 48 months and socially-mature females were at least 36 months by study start. These thresholds correspond to approximate onset of social maturity in pigtailed macaques. The study group had a demographic structure approximating wild populations and subadult and adult males were regularly removed to mimic emigration occurring in wild populations.  All individuals, except 8 (4 males, 4 females), were either natal to the group or had been in the group since formation. The group was housed in an indoor-outdoor facility, the outdoor compound of which was 125 x 65 ft.\n\nPigtailed macaques have frequent conflict and employ targeted intervention and repair strategies for managing conflict \\cite{Flack:2005dg}. Data on social dynamics and conflict were collected from this group over a stable, four month period. Operational definitions are provided below in SI Sec.\\ref{op}.\n\n\\subsection{Operational definitions}\n\\label{op}\n\\emph{Fight}: includes any interaction in which one individual threatens or aggresses a second individual. A conflict was considered terminated if no aggression or withdrawal response (fleeing, crouching, screaming, running away, submission signals) was exhibited by any of the conflict  participants for \\emph{two minutes} from the last such event. A fight can involve multiple individuals. Third parties can become involved in pair-wise conflict through intervention or redirection, or when a family member of a conflict participant attacks a fourth-party. Fights in this data set ranged in size from 2 to 31 individuals, counting only the socially-mature animals. Fights can be represented as small networks that grow and shrink as pair-wise and triadic interactions become active or terminate until there are no more individuals fighting under the above described two minute criterion. In addition to aggressors, a conflict can include individuals who show no aggression or submission (\\emph{e.g.} third-parties who simply approach the conflict or show affiliative / submissive behavior upon approaching, and recipients of aggression who show no response to aggression (typically, threats) by another individual). Because conflicts involve multiple actors, two or more individuals can participate in the same conflict but not interact directly.\n\nIn this study only information about fight composition (which individuals were involved) is used.  Only fights that included two or more socially-mature individuals were used in the analysis; the data includes $N = 994$ such fights.  We do not consider internal aspects of the fight, such as who does what to whom, except for the order of each individual's first involvement in the fight (used to estimate time-ordered conditional probabilities for use in the dynamical branching process model). Time data were collected on fight onset and termination but are not used in these analyses.\n\n\\emph{Power}: The degree of consensus among individuals in the group about whether an individual is capable of using force successfully~\\cite{Flack:2006jh,Brush2013}. In previous works we showed that consensus can be quantified by taking into account the total number of subordination signals an individual receives and multiplying this quantity by a measure of the diversity of signals received from its population of signalers (quantified by computing the Shannon entropy of the vector of signals received by individual \\emph{i}) \\cite{Flack:2006jh}. In pigtailed macaque societies, the subordination signal is the silent bared teeth display~\\cite{Flack:2007ir} emitted outside the conflict context during pass-byes and affiliative interactions. The distribution of power in our study group is heavy tailed, such that a few individuals are disproportionately powerful.\n\n\\emph{Policing}: A policing intervention is an impartial intervention performed by a third party into an ongoing conflict~\\cite{Flack:2005dg}. Three males and one female perform the majority of effective policing interventions but only the three males (Eo, Qs, Fo) specialize on policing~\\cite{Krakauer:2011tb}. These four individuals occupy the top four spots in the power distribution~\\cite{Flack:2005dg, Brush2013}.\n\n\\emph{Redirection}: A redirection occurs when an aggressor, recipient, or intervener directs aggression at a third (or fourth) individual who was not its original target or attacker. The target of the redirection may not have been involved in the fight until the redirection, or may have been involved in the fight but interacting with individuals other than the redirecting individual. \n\n\\subsection{Data collection protocol}\n\\label{DataCollectionSection}\nThe data were collected by a trained observer (J.C.~Flack). The observer spent roughly 100 hours prior to data collection learning to recognize individuals and accurately code their behavior from the observation tower above the monkey compound. Accuracy was validated by a second trained observer (F.B.M.~de Waal). JCF also evaluated coding accuracy using video. Coding accuracy was nearly 100$\\%$. \n\nDuring observations all individuals were confined to the outdoor portion of the compound and were visible to the observer. The $\\approx150$ hours of observations occurred for up to eight hours daily between 1,100 and 2,000 hours over a twenty-week period from June through October 1998, and were evenly distributed over the day. Conflict and signaling data were collected using all-occurrence sampling in which the entire conflict event is followed from start to finish and all participants and their behavior are recorded.\n\nProvisioning occurred before observations and once during observations at approximately the same time each day. The group was stable during the data collection period (defined as no reversals in status signaling interactions resulting in a change to an individual's power score; see Ref.~\\cite{Flack:2006jh}). \n\n\\section{Notes on model descriptions and justification}\n\\label{modeldescription}\nWe first evaluate which of three basic, empirically-grounded fight joining models explain our macroscopic observable, the distribution of fight sizes. We only accept a model if it is both consistent with the measured, microscopic data and can recover in simulation the observed, measured macroscopic output. Hence all of our models are closely tethered to the measured data and biological details of our model system.\n\nIt is important to realize that the parameters in the maximum entropy and branching models come from the microscopic data. The models do not assume prescribed values for parameters but are perhaps better viewed as hypotheses about the ways in which the measured, microscopic detail is connected to observed macroscopic patterns.\n\nAll models assume that events external to the system do not create correlations in behavior.  The data were collected in a controlled, captive setting designed to minimize the influence of external events, and we have no evidence for important, consistent external forcers of conflict.\n\n\\subsection{Independent model description}The independent model assumes individuals do not respond to each other but instead join fights without regard to who else is fighting.  In this case, perturbations to individual conflict behavior would have no additional effect on group behavior.\n\nThe independent model fails to recover both the observed distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}) and the observed significant pairwise correlations ({Fig.~\\ref{{isingStatistics}}}).\n\n\\subsection{Pairwise maximum entropy model description}Individuals sometimes randomly join fights and sometimes the decision to fight reflects strategic interactions at a pairwise level\\cite{Dedeo2010}. We capture this interpretation of the microscopic data using a maximum entropy approach, which corresponds to the spin-glass model of magnetic systems in physics.\nBecause the model is parameterized by the data it is empirically grounded and serves as a valid biological hypothesis.  However we note that it is less mechanistically specific than the branching process described below: spin-glass interactions are not directional or time-ordered, but rather operate symmetrically and over the timescale of an entire fight bout.\n\nThe pairwise maximum entropy model, with parameters fit from the microscopic data, recovers well the distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}). The good performance of the model leads to the prediction that the sensitivity $\\chi$ is about twice that of a system with the same conflict frequencies but no strategic interactions.\n\n\\subsection{Branching process description}Another reasonable interpretation of the microscopic data is that the random component of fight joining decisions is very small and the decision to fight reflects strategic interactions at a pairwise level. This leads to a branching process model that, with parameters fit from the microscopic data, also recovers the observed distribution of fight sizes. The collective behavior produced by this model can be simply understood in terms of a single parameter, the branching ratio. Additionally, branching process models like this one have been used in previous work to explore other aspects of conflict dynamics in this system, including the role of policing and other forms of third-party intervention in the infectivity of aggression \\cite{Krakauer:2011tb}.\n\n\\section{Notes on model inference}\n\n\\subsection{Independent model inference}\n\\label{independentInference}\nThe independent model consists of individuals participating in conflict randomly,  with the frequencies of individual appearance equal to their empirically measured, heterogeneous values $f_i = {\\langle {x_i} \\rangle}$.  Naively, this can be written as a relative negative log-likelihood\\footnote{The relative negative log-likelihood $L(x)$ of state $x$ is related to the likelihood $p(x)$ by $p(x) = \\exp(-L(x))/Z$, where $Z$ is a normalization constant set by the constraint that the sum of likelihoods over all states is one.  In statistical physics, $Z$ is the partition function and $L(x)$ is proportional to the free energy of state $x$.} $L^{\\mathrm{ind}}(x) = \\sum_{i} - h_i x_{i}$, and is equivalent to a maximum entropy model that matches only the frequencies $f_i$.\n\nHowever, as detailed in SI Sec~\\ref{op}, a fight was operationalized for these analyses as involving two or more\nsocially-mature individuals. (Observed fights that involved only juveniles and 0 or 1 mature individuals are therefore excluded.)\nCorrespondingly, we forbid our models from producing fights of size smaller than two. We treat this as an additional constraint on the model. The resulting maximum entropy model is then the one in which the likelihood of states with fewer than two individuals present is taken to zero.  This corresponds to a relative negative log-likelihood\n\\begin{eqnarray}\n\\label{constrainedIndependentEnergy}\nL^{\\mathrm{ind}}_{\\alpha \\rightarrow \\infty} &=&\n\\lim_{\\alpha \\rightarrow \\infty} \\left[\n\\sum_i h_i x_i\n+ \\alpha ~ \\Theta \\left( 2 - \\sum_j x_j \\right) \\right],\n\\end{eqnarray}\nwhere $\\Theta(z)$ is 0 when $z \\leq 0$ and 1 when $z > 0$.\n\nIn the unconstrained case ($\\alpha = 0$), we can easily solve for $h_i$:\n\\begin{eqnarray}\n\\label{unconstrainedIndependentEnergy}\nL^{\\mathrm{ind}}_{\\alpha = 0} &=& \\sum_i h_i x_i                         \\\\\n\\label{fieldsEqn}\nh_i &=& - \\log \\left( \\frac{{\\langle {x_i} \\rangle}_{\\alpha = 0}}\n{1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}} \\right)    .\n\\end{eqnarray}\nWe must now solve numerically for $h_i$ to match\nthe empirically measured $f_i = {\\langle {x_i} \\rangle} = {\\langle {x_i} \\rangle}_{\\alpha \\rightarrow \\infty}$.\nTo accomplish this, note that the unconstrained model\nwill have modified statistics:\n\\begin{eqnarray}\n\\label{correctionEqn}\n{\\langle {x_i} \\rangle}_{\\alpha = 0} &=& ( 1 - f_0 - f_1 ) {\\langle {x_i} \\rangle} \n                            + f_{i1} \\\\\n{\\langle {x_i x_j} \\rangle}_{\\alpha = 0} &=& ( 1 - f_0 - f_1 ) {\\langle {x_i x_j} \\rangle},\n\\nonumber\n\\end{eqnarray}\nwhere $f_0$ is the frequency of size zero fights,\n$f_{i1}$ is the frequency of size one fights consisting\nsolely of individual $i$, and\n$f_1 = \\sum{f_{i1}}$ is the overall frequency of\nsize one fights (all measured in the unconstrained model).\nIn terms of unconstrained individual frequencies, these are\n\\begin{eqnarray}\nf_0 &=& \\prod_i (1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}) \\\\\nf_{i1} &=& {\\langle {x_i} \\rangle}_{\\alpha = 0} \\frac{f_0}{1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}}.\n\\end{eqnarray}\nWe use an iterative\nprocedure to solve equations~(\\ref{correctionEqn})\nfor ${\\langle {x_i} \\rangle}_{\\alpha = 0}$, which are then used in {Eq.~(\\ref{{fieldsEqn}})}\nto find the fields.  Finally, samples from the independent model [{Eq.~(\\ref{{constrainedIndependentEnergy}})}] are produced by sampling using {Eq.~(\\ref{{unconstrainedIndependentEnergy}})} and simply discarding samples in which fewer than 2 individuals appear.  For our data, this results in discarding about 17\\% of samples produced with {Eq.~(\\ref{{unconstrainedIndependentEnergy}})}.\n\n\\subsection{Pairwise maximum entropy model inference}\n\\label{IsingModelSection}\n\nWe next constrain our equilibrium maximum entropy model to match the frequencies of appearance of both individuals and pairs of individuals. This model is known to be the spin-glass Ising model \\cite{SchBerSeg06}, with relative negative log-likelihood\n\n", "itemtype": "equation", "pos": 11077, "prevtext": "\n\nResults for the equilibrium model are shown in {Fig.~\\ref{{susceptibilityFigure}}}A. For fit parameters (${h_{\\mathrm{ext}}} = 0$), there is increased sensitivity compared to a noninteracting model with the same mean fight size, meaning that an amplification process is occurring that makes changes to patterns of aggression at the individual level ``visible'' at the global system level. This amplification process cannot be attributed to external events as these data were collected in a captive setting in which such disturbances were minimized (SI, Sec~\\ref{modeldescription}).\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151109_sensitivity_stability_vs_field.pdf}\n\\caption{ \\label{susceptibilityFigure}\nThe system is near a sensitive and unstable region of parameter space. (Left) The susceptibility $\\chi$, measuring the sensitivity of average fight size to an external perturbation, has a peak near the fit parameters (at ${h_{\\mathrm{ext}}} = 0$). The susceptibility is also equal to the Fisher information $F({h_{\\mathrm{ext}}})$, describing how quickly the distribution over fights becomes distinguishable as ${h_{\\mathrm{ext}}}$ is varied. (Middle) Instability of the lowest order mean-field solution is indicated by the eigenvalue $\\lambda$ becoming larger than 1. Yellow dashed lines indicate a system of the same size with independent individuals, and red dashed lines indicate a homogeneous system of the same size tuned to be marginally unstable at ${h_{\\mathrm{ext}}} = 0$.  (Right) The transition is associated with large changes in mean fight size.\n}\n\\end{figure}\n\nThe susceptibility can also be interpreted as a Fisher information, an information theoretic quantity that describes how sensitive a distribution is to the parameters that describe it (SI~\\ref{FisherInfoSection}). A large $\\chi$ implies faster learning: large susceptibility means that aggregate level statistics are informative about conflict dynamics at the individual level \\cite{Tchernookov2012,Prokopenko2011}.\n\nAnalogously to the susceptibility in the equilibrium model, we can define sensitivity in the dynamic model as how quickly fight sizes grow following perturbation of redirection probabilities $p_{ij}$:\n\n", "index": 5, "text": "\\begin{equation}\n    \\frac{1}{n(n-1)}\\sum_i \\sum_{j \\neq i} \\frac{d{\\langle {s} \\rangle}}{dp_{ij}}\n    \\equiv \\chi_\\mathrm{dyn}\n    = \\frac{1}{n(n-1)} \\frac{ d{\\langle {s} \\rangle} }{ dp },\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\frac{1}{n(n-1)}\\sum_{i}\\sum_{j\\neq i}\\frac{d{\\langle{s}\\rangle}}{dp_{ij}}%&#10;\\equiv\\chi_{\\mathrm{dyn}}=\\frac{1}{n(n-1)}\\frac{d{\\langle{s}\\rangle}}{dp},\" display=\"block\"><mrow><mrow><mrow><mfrac><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>i</mi></mrow></munder><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>s</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mfrac></mrow></mrow></mrow><mo>\u2261</mo><msub><mi>\u03c7</mi><mi>dyn</mi></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>s</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>p</mi></mrow></mfrac></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\nAs in the independent model, the likelihood of fights with fewer than two individuals is taken to zero:\n\n", "itemtype": "equation", "pos": 33550, "prevtext": "\nwhere $p$ adds probability uniformly to all redirection probabilities.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151120_ellStar_withMinMax_numProcs11_numSamples1e4}\n\\caption{ \n    In equilibrium (top) and dynamical (bottom) models,\n    forcing a few individuals to become simultaneously\n    aggressive leads to a more sensitive system. (Left)\n    In each model, peak sensitivity is reached when on average\n    3-5 individuals are forced. Shaded regions indicate\n    the standard deviation around the mean over different\n    realizations of the chosen individuals. Purple and\n    blue dotted lines indicate choices of forced individuals\n    that maximize and minimize the resulting mean fight size.\n    (Middle) The mean fight size.\n    (Right) The lowest-order stability\n    measured in each model, corresponding to the\n    eigenvalue $\\lambda_0$ in the equilibrium model\n    and $R_0$ in the dynamical model (SI, Sec~\\ref{collectinstab}).  A value above\n    1 in each case indicates instability to linear order.\n\\label{ellStarFigure}\n}\n\\end{figure}\n\n{Fig.~\\ref{{susceptibilityFigure}}} suggests that the system is near a transition. To quantify this statement in a biologically meaningful way we measure how sensitivity and stability vary as we force---through parameterized-simulation---some number of individuals to fight continuously (while allowing the system to consist only of the non-forced individuals). The number of individuals required to reach a peak in sensitivity corresponding to a collective instability (SI, Sec.\\ref{collectinstab}) is a measure of the \\emph{distance of the system from the critical point} (DFC). Beyond this peak lies saturation and decreasing sensitivity.\n\nIn the equilibrium model forcing is accomplished by removing the forced individuals and adding their interaction terms to the fields acting on the remaining individuals: the new fields are given by $J^*_{ii} = J_{ii} + \\sum_{\\mathrm{forced}~k} 2 J_{ik}$. In the dynamic model this is accomplished by explicitly including the forced individuals at each timestep in the simulation but only recording the behavior of the remaining individuals.  The change in sensitivity caused by forcing each individual also provides ``sensitivity scores'' that measure the extent to which each individual brings the system closer to criticality.\n\n\n\nAs shown in {Fig.~\\ref{{ellStarFigure}}}, both models predict a substantial increase in sensitivity when a few individuals are forced to be continuously involved in conflict. The system begins to saturate in sensitivity after 3-5 individuals are simultaneously forced. This result is similar to the finding that bird flocks require only a small proportion of informed individuals to correctly choose direction\\cite{COUZIN2005,LEONARD2012}. \n\nWe use perturbation theory to demonstrate that this sensitivity arises from instability in each model (SI, Sec.\\ref{stabilitySection}). The number of individuals required to reach a peak in sensitivity corresponding to an aggregate-level instability (SI, Sec.\\ref{collectinstab}) is a \\emph{biologically meaningful measure} of the \\emph{distance of the system from the critical point}.\n\nIn addition we find that individuals vary in their sensitivity scores such that forcing participation of individuals with the top two to three sensitivity scores is sufficient to move the system close to a critical point (SI, Sec.\\ref{sensitiveindividuals}).\n\n\nThese results tell us that fight involvement by the high sensitivity score individuals can be tuned two ways: through \\emph{direct tuning}, as they opportunistically or strategically increase or decrease their fight participation, and \\emph{indirect tuning}, through the actions of others that increase or decrease the frequency with which aggression is directed or redirected at these individuals (SI, Sec.\\ref{EmpiricalMethods} and SI, Secs.\\ref{tuning}). This includes through the policing mechanism in which powerful third parties to the fight intervene and impartially break it up  (SI, Sec.\\ref{EmpiricalMethods} and SI, Secs.\\ref{tuning}) \\cite{Flack:2005dg}. Policing dampens fight involvement by significantly reducing how frequently fights erupt and also by reducing the frequency of redirected aggression received, particularly by high sensitivity individuals\\cite{Flack:2005ih}. Hence DFC can in principle be controlled through policing or by the high sensitivity individuals themselves as they up or down regulate the frequency with which they join fights. \n\nAll biological systems need to balance stability and robustness with the need for rapid adaptive change. Yet many biological systems are observed to sit near a critical point, which would seem to suggest a lack of robustness. This apparent conflict can be resolved by the discovery that DFC can be tuned through realistic social mechanisms. Tuning DFC allows for switching between stability and criticality, providing a means for accessing alternative social structures that may be more appropriate if and when the environment should change\\cite{FlaErwEll13}. This discovery raises many new questions: It is one thing for tuning to be possible and another to know when to tune and whether to tune towards robustness or criticality (SI, Sec.\\ref{adaptive value}). We propose robustness is a good strategy when the environment is stable and low variance. Criticality is a good strategy when the environment is uncertain (SI, Sec.\\ref{adaptive value}). In addition for tuning to be adaptive the state of the environment must be accurately perceived by, or mirrored in, the individuals whose behavior changes DFC. This appears to be the case in our system (SI, Sec.\\ref{adaptive value}) but may present a crucial evolutionary challenge for other systems.  Future comparative studies are required to quantify the range of DFC across social groups within a species, as well as across biological systems more generally, and to study how DFC might be controlled in other systems. We can then assess whether variation in DFC and its control are correlated with rate of change in the environment and or environmental uncertainty as we expect.\n\n\n\n\n\n\n\\section*{End Notes}\\begin{itemize}\n\n\\item The authors thank Chris Ellison, Philip Poon, Eddie Lee, Eleanor Brush, Yoav Kallus, and Raissa D'Souza for helpful discussion. Partial support for this project was provided by the Templeton Foundation through grants to study complexity and the mind-brain problem, and by the Office of Army Research under contract W911NF-13-1-0340. JCF thanks Frans de Waal and the animal care staff at Yerkes National Primate Research Center for support during data collection.\n\\item BCD designed the study, built the models, analyzed and interpreted data, and wrote the paper. DCK contributed to model development, analysis, and interpretation, and wrote the paper. JCF designed the study, collected the data, contributed to model development, analysis, and interpretation, and wrote the paper.\nCorrespondence and requests for materials should be addressed to Bryan Daniels (bryan.daniels.1@asu.edu).\n\n\n\\end{itemize}\n\n\n\n\\putbib\n\\end{bibunit}\n\n\\begin{bibunit}\n\n\\clearpage\n\n\n\n\n\n\\begin{center}\n\\textbf{Supplementary Information}\n\\\\~\\\\\nControl of critical behavior in a small-scale social system\n\\\\\nBryan C. Daniels, David C. Krakauer, Jessica C. Flack\n\\end{center}\n\n\\section{Empirical Methods}\n\\label{EmpiricalMethods}\n\\subsection{Ethics statement}\nThe data collection protocol was approved by the Emory University Institutional Animal Care and Use Committee and all data were collected in accordance with its guidelines for the ethical treatment of nonhuman study subjects.\n\n\\subsection{Study system}\nThe data were collected by JCF in 1998 from a large group of captive pigtailed macaques (\\emph{Macaca nemestrina}) socially-housed at the Yerkes National Primate Center in Lawrenceville, Georgia. Pigtailed macaques are indigenous to south East Asia and live in multi-male, multi-female societies characterized by female matrilines and male group transfer upon onset of puberty~\\cite{Caldecott:1986uk}. Pigtailed macaques breed all year. Females develop swellings when in \\OE strus. Macaque societies more generally are characterized by social learning at the individual level, social structures that arise from nonlinear processes and feed back to influence individual behavior, frequent non-kin interactions and multiplayer conflict interactions, the cost and benefits of which can be quantified at the individual and social network levels~\\cite {Flack:2007ir, Flack:2006jh, Flack:2006vi, Flack:2005ih, Flack:2005dg, Thierry:2004tj}.\n\nThe study group contained $n = 48$ socially-mature individuals (we exclude non-mature individuals because their behavioral strategies are still developing and so are non-stationary over short timescales) and 84 individuals in total. Socially-mature males were at least 48 months and socially-mature females were at least 36 months by study start. These thresholds correspond to approximate onset of social maturity in pigtailed macaques. The study group had a demographic structure approximating wild populations and subadult and adult males were regularly removed to mimic emigration occurring in wild populations.  All individuals, except 8 (4 males, 4 females), were either natal to the group or had been in the group since formation. The group was housed in an indoor-outdoor facility, the outdoor compound of which was 125 x 65 ft.\n\nPigtailed macaques have frequent conflict and employ targeted intervention and repair strategies for managing conflict \\cite{Flack:2005dg}. Data on social dynamics and conflict were collected from this group over a stable, four month period. Operational definitions are provided below in SI Sec.\\ref{op}.\n\n\\subsection{Operational definitions}\n\\label{op}\n\\emph{Fight}: includes any interaction in which one individual threatens or aggresses a second individual. A conflict was considered terminated if no aggression or withdrawal response (fleeing, crouching, screaming, running away, submission signals) was exhibited by any of the conflict  participants for \\emph{two minutes} from the last such event. A fight can involve multiple individuals. Third parties can become involved in pair-wise conflict through intervention or redirection, or when a family member of a conflict participant attacks a fourth-party. Fights in this data set ranged in size from 2 to 31 individuals, counting only the socially-mature animals. Fights can be represented as small networks that grow and shrink as pair-wise and triadic interactions become active or terminate until there are no more individuals fighting under the above described two minute criterion. In addition to aggressors, a conflict can include individuals who show no aggression or submission (\\emph{e.g.} third-parties who simply approach the conflict or show affiliative / submissive behavior upon approaching, and recipients of aggression who show no response to aggression (typically, threats) by another individual). Because conflicts involve multiple actors, two or more individuals can participate in the same conflict but not interact directly.\n\nIn this study only information about fight composition (which individuals were involved) is used.  Only fights that included two or more socially-mature individuals were used in the analysis; the data includes $N = 994$ such fights.  We do not consider internal aspects of the fight, such as who does what to whom, except for the order of each individual's first involvement in the fight (used to estimate time-ordered conditional probabilities for use in the dynamical branching process model). Time data were collected on fight onset and termination but are not used in these analyses.\n\n\\emph{Power}: The degree of consensus among individuals in the group about whether an individual is capable of using force successfully~\\cite{Flack:2006jh,Brush2013}. In previous works we showed that consensus can be quantified by taking into account the total number of subordination signals an individual receives and multiplying this quantity by a measure of the diversity of signals received from its population of signalers (quantified by computing the Shannon entropy of the vector of signals received by individual \\emph{i}) \\cite{Flack:2006jh}. In pigtailed macaque societies, the subordination signal is the silent bared teeth display~\\cite{Flack:2007ir} emitted outside the conflict context during pass-byes and affiliative interactions. The distribution of power in our study group is heavy tailed, such that a few individuals are disproportionately powerful.\n\n\\emph{Policing}: A policing intervention is an impartial intervention performed by a third party into an ongoing conflict~\\cite{Flack:2005dg}. Three males and one female perform the majority of effective policing interventions but only the three males (Eo, Qs, Fo) specialize on policing~\\cite{Krakauer:2011tb}. These four individuals occupy the top four spots in the power distribution~\\cite{Flack:2005dg, Brush2013}.\n\n\\emph{Redirection}: A redirection occurs when an aggressor, recipient, or intervener directs aggression at a third (or fourth) individual who was not its original target or attacker. The target of the redirection may not have been involved in the fight until the redirection, or may have been involved in the fight but interacting with individuals other than the redirecting individual. \n\n\\subsection{Data collection protocol}\n\\label{DataCollectionSection}\nThe data were collected by a trained observer (J.C.~Flack). The observer spent roughly 100 hours prior to data collection learning to recognize individuals and accurately code their behavior from the observation tower above the monkey compound. Accuracy was validated by a second trained observer (F.B.M.~de Waal). JCF also evaluated coding accuracy using video. Coding accuracy was nearly 100$\\%$. \n\nDuring observations all individuals were confined to the outdoor portion of the compound and were visible to the observer. The $\\approx150$ hours of observations occurred for up to eight hours daily between 1,100 and 2,000 hours over a twenty-week period from June through October 1998, and were evenly distributed over the day. Conflict and signaling data were collected using all-occurrence sampling in which the entire conflict event is followed from start to finish and all participants and their behavior are recorded.\n\nProvisioning occurred before observations and once during observations at approximately the same time each day. The group was stable during the data collection period (defined as no reversals in status signaling interactions resulting in a change to an individual's power score; see Ref.~\\cite{Flack:2006jh}). \n\n\\section{Notes on model descriptions and justification}\n\\label{modeldescription}\nWe first evaluate which of three basic, empirically-grounded fight joining models explain our macroscopic observable, the distribution of fight sizes. We only accept a model if it is both consistent with the measured, microscopic data and can recover in simulation the observed, measured macroscopic output. Hence all of our models are closely tethered to the measured data and biological details of our model system.\n\nIt is important to realize that the parameters in the maximum entropy and branching models come from the microscopic data. The models do not assume prescribed values for parameters but are perhaps better viewed as hypotheses about the ways in which the measured, microscopic detail is connected to observed macroscopic patterns.\n\nAll models assume that events external to the system do not create correlations in behavior.  The data were collected in a controlled, captive setting designed to minimize the influence of external events, and we have no evidence for important, consistent external forcers of conflict.\n\n\\subsection{Independent model description}The independent model assumes individuals do not respond to each other but instead join fights without regard to who else is fighting.  In this case, perturbations to individual conflict behavior would have no additional effect on group behavior.\n\nThe independent model fails to recover both the observed distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}) and the observed significant pairwise correlations ({Fig.~\\ref{{isingStatistics}}}).\n\n\\subsection{Pairwise maximum entropy model description}Individuals sometimes randomly join fights and sometimes the decision to fight reflects strategic interactions at a pairwise level\\cite{Dedeo2010}. We capture this interpretation of the microscopic data using a maximum entropy approach, which corresponds to the spin-glass model of magnetic systems in physics.\nBecause the model is parameterized by the data it is empirically grounded and serves as a valid biological hypothesis.  However we note that it is less mechanistically specific than the branching process described below: spin-glass interactions are not directional or time-ordered, but rather operate symmetrically and over the timescale of an entire fight bout.\n\nThe pairwise maximum entropy model, with parameters fit from the microscopic data, recovers well the distribution of fight sizes ({Fig.~\\ref{{fightSizeDistributions}}}). The good performance of the model leads to the prediction that the sensitivity $\\chi$ is about twice that of a system with the same conflict frequencies but no strategic interactions.\n\n\\subsection{Branching process description}Another reasonable interpretation of the microscopic data is that the random component of fight joining decisions is very small and the decision to fight reflects strategic interactions at a pairwise level. This leads to a branching process model that, with parameters fit from the microscopic data, also recovers the observed distribution of fight sizes. The collective behavior produced by this model can be simply understood in terms of a single parameter, the branching ratio. Additionally, branching process models like this one have been used in previous work to explore other aspects of conflict dynamics in this system, including the role of policing and other forms of third-party intervention in the infectivity of aggression \\cite{Krakauer:2011tb}.\n\n\\section{Notes on model inference}\n\n\\subsection{Independent model inference}\n\\label{independentInference}\nThe independent model consists of individuals participating in conflict randomly,  with the frequencies of individual appearance equal to their empirically measured, heterogeneous values $f_i = {\\langle {x_i} \\rangle}$.  Naively, this can be written as a relative negative log-likelihood\\footnote{The relative negative log-likelihood $L(x)$ of state $x$ is related to the likelihood $p(x)$ by $p(x) = \\exp(-L(x))/Z$, where $Z$ is a normalization constant set by the constraint that the sum of likelihoods over all states is one.  In statistical physics, $Z$ is the partition function and $L(x)$ is proportional to the free energy of state $x$.} $L^{\\mathrm{ind}}(x) = \\sum_{i} - h_i x_{i}$, and is equivalent to a maximum entropy model that matches only the frequencies $f_i$.\n\nHowever, as detailed in SI Sec~\\ref{op}, a fight was operationalized for these analyses as involving two or more\nsocially-mature individuals. (Observed fights that involved only juveniles and 0 or 1 mature individuals are therefore excluded.)\nCorrespondingly, we forbid our models from producing fights of size smaller than two. We treat this as an additional constraint on the model. The resulting maximum entropy model is then the one in which the likelihood of states with fewer than two individuals present is taken to zero.  This corresponds to a relative negative log-likelihood\n\\begin{eqnarray}\n\\label{constrainedIndependentEnergy}\nL^{\\mathrm{ind}}_{\\alpha \\rightarrow \\infty} &=&\n\\lim_{\\alpha \\rightarrow \\infty} \\left[\n\\sum_i h_i x_i\n+ \\alpha ~ \\Theta \\left( 2 - \\sum_j x_j \\right) \\right],\n\\end{eqnarray}\nwhere $\\Theta(z)$ is 0 when $z \\leq 0$ and 1 when $z > 0$.\n\nIn the unconstrained case ($\\alpha = 0$), we can easily solve for $h_i$:\n\\begin{eqnarray}\n\\label{unconstrainedIndependentEnergy}\nL^{\\mathrm{ind}}_{\\alpha = 0} &=& \\sum_i h_i x_i                         \\\\\n\\label{fieldsEqn}\nh_i &=& - \\log \\left( \\frac{{\\langle {x_i} \\rangle}_{\\alpha = 0}}\n{1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}} \\right)    .\n\\end{eqnarray}\nWe must now solve numerically for $h_i$ to match\nthe empirically measured $f_i = {\\langle {x_i} \\rangle} = {\\langle {x_i} \\rangle}_{\\alpha \\rightarrow \\infty}$.\nTo accomplish this, note that the unconstrained model\nwill have modified statistics:\n\\begin{eqnarray}\n\\label{correctionEqn}\n{\\langle {x_i} \\rangle}_{\\alpha = 0} &=& ( 1 - f_0 - f_1 ) {\\langle {x_i} \\rangle} \n                            + f_{i1} \\\\\n{\\langle {x_i x_j} \\rangle}_{\\alpha = 0} &=& ( 1 - f_0 - f_1 ) {\\langle {x_i x_j} \\rangle},\n\\nonumber\n\\end{eqnarray}\nwhere $f_0$ is the frequency of size zero fights,\n$f_{i1}$ is the frequency of size one fights consisting\nsolely of individual $i$, and\n$f_1 = \\sum{f_{i1}}$ is the overall frequency of\nsize one fights (all measured in the unconstrained model).\nIn terms of unconstrained individual frequencies, these are\n\\begin{eqnarray}\nf_0 &=& \\prod_i (1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}) \\\\\nf_{i1} &=& {\\langle {x_i} \\rangle}_{\\alpha = 0} \\frac{f_0}{1 - {\\langle {x_i} \\rangle}_{\\alpha = 0}}.\n\\end{eqnarray}\nWe use an iterative\nprocedure to solve equations~(\\ref{correctionEqn})\nfor ${\\langle {x_i} \\rangle}_{\\alpha = 0}$, which are then used in {Eq.~(\\ref{{fieldsEqn}})}\nto find the fields.  Finally, samples from the independent model [{Eq.~(\\ref{{constrainedIndependentEnergy}})}] are produced by sampling using {Eq.~(\\ref{{unconstrainedIndependentEnergy}})} and simply discarding samples in which fewer than 2 individuals appear.  For our data, this results in discarding about 17\\% of samples produced with {Eq.~(\\ref{{unconstrainedIndependentEnergy}})}.\n\n\\subsection{Pairwise maximum entropy model inference}\n\\label{IsingModelSection}\n\nWe next constrain our equilibrium maximum entropy model to match the frequencies of appearance of both individuals and pairs of individuals. This model is known to be the spin-glass Ising model \\cite{SchBerSeg06}, with relative negative log-likelihood\n\n", "index": 7, "text": "\\begin{equation}\nL^{\\mathrm{SG}}_{\\alpha = 0}(x) = \\sum_{ij} - x_i J_{ij} x_{j}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"L^{\\mathrm{SG}}_{\\alpha=0}(x)=\\sum_{ij}-x_{i}J_{ij}x_{j}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>L</mi><mrow><mi>\u03b1</mi><mo>=</mo><mn>0</mn></mrow><mi>SG</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder><mo>-</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>x</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\n\n\nThe statistics we fit in the equilibrium model are the individual and pairwise frequencies of appearance:\n\\begin{eqnarray}\nf_{i} &=& {\\langle {x_i} \\rangle} = \\frac{N(x_i)}{N}, \\\\\nf_{ij} &=& {\\langle {x_i x_j} \\rangle} = \\frac{N(x_i,x_j)}{N} ~~~~ \\mathrm{for} ~ i \\neq j,\n\\end{eqnarray}\nwith $N(x_i)$ and $N(x_i,x_j)$ representing, respectively, the observed number of appearances in unique fights of the individual $i$ and the pair $i,j$.\n\nWe would like to fit the individual and pairwise frequencies of appearance to the precision that the data supports.  As a measure of the goodness of fit, we use the average of normalized residuals\n\\begin{eqnarray}\n\\label{isingCost}\n{\\langle {\\chi^2_{\\mathrm{SG}}} \\rangle} &=& \\frac{2}{n(n+1)} \\sum_{i} \\sum_{j \\geq i}\n\\frac{ (f_{ij}^{\\mathrm{data}} - f_{ij}^{\\mathrm{model}})^2 }\n{ \\sigma_{f_{ij}}^2 },\n\\end{eqnarray}\nwhere\n\n", "itemtype": "equation", "pos": 33751, "prevtext": "\n\nAs in the independent model, the likelihood of fights with fewer than two individuals is taken to zero:\n\n", "index": 9, "text": "\\begin{equation}\n\\label{IsingE}\nL^{\\mathrm{SG}}_{\\alpha \\rightarrow \\infty}(x) = \\lim_{\\alpha \\rightarrow \\infty}\n\\sum_{ij} - x_i J_{ij} x_{j} + \\alpha ~ \\Theta \\left( 2 - \\sum_k x_k \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"L^{\\mathrm{SG}}_{\\alpha\\rightarrow\\infty}(x)=\\lim_{\\alpha\\rightarrow\\infty}%&#10;\\sum_{ij}-x_{i}J_{ij}x_{j}+\\alpha~{}\\Theta\\left(2-\\sum_{k}x_{k}\\right).\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>L</mi><mrow><mi>\u03b1</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow><mi>SG</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>\u03b1</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></munder></mrow><mo>-</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>x</mi><mi>j</mi></msub></mrow></mrow><mo>+</mo><mrow><mpadded width=\"+3.3pt\"><mi>\u03b1</mi></mpadded><mo>\u2062</mo><mi mathvariant=\"normal\">\u0398</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mn>2</mn><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>k</mi></munder><msub><mi>x</mi><mi>k</mi></msub></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nis the expected variance of each residual due to finite $N$,\nand repeated indices are understood as individual frequencies: $f_{ii} = f_i$.  A good fit is expected to have ${\\langle {\\chi^2} \\rangle} \\approx 1$.\n\nTo perform fitting, we use a simplified method that starts with the mean field solution and varies a single parameter corresponding to weighting a non-interacting prior. Specifically, we make use of the $L_2$-regularized mean field entropy of Ref.~\\cite{BarCoc13}.  The regularization consists of a Gaussian prior with a form designed to make the mean-field case easily solvable, corresponding to an additional term in the relative negative log likelihood\n\n", "itemtype": "equation", "pos": 34827, "prevtext": "\n\n\n\nThe statistics we fit in the equilibrium model are the individual and pairwise frequencies of appearance:\n\\begin{eqnarray}\nf_{i} &=& {\\langle {x_i} \\rangle} = \\frac{N(x_i)}{N}, \\\\\nf_{ij} &=& {\\langle {x_i x_j} \\rangle} = \\frac{N(x_i,x_j)}{N} ~~~~ \\mathrm{for} ~ i \\neq j,\n\\end{eqnarray}\nwith $N(x_i)$ and $N(x_i,x_j)$ representing, respectively, the observed number of appearances in unique fights of the individual $i$ and the pair $i,j$.\n\nWe would like to fit the individual and pairwise frequencies of appearance to the precision that the data supports.  As a measure of the goodness of fit, we use the average of normalized residuals\n\\begin{eqnarray}\n\\label{isingCost}\n{\\langle {\\chi^2_{\\mathrm{SG}}} \\rangle} &=& \\frac{2}{n(n+1)} \\sum_{i} \\sum_{j \\geq i}\n\\frac{ (f_{ij}^{\\mathrm{data}} - f_{ij}^{\\mathrm{model}})^2 }\n{ \\sigma_{f_{ij}}^2 },\n\\end{eqnarray}\nwhere\n\n", "index": 11, "text": "\\begin{equation}\n\\sigma_{f_{ij}}^2 = \\frac{ f_{ij} (1-f_{ij}) }{ N }\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\sigma_{f_{ij}}^{2}=\\frac{f_{ij}(1-f_{ij})}{N}\" display=\"block\"><mrow><msubsup><mi>\u03c3</mi><msub><mi>f</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><msub><mi>f</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mi>N</mi></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhere $\\gamma$ is the strength of the prior, which favors interactions\n$J_{ij}$ that are smaller in magnitude.\nThe mean field solution under this regularization is \\cite{BarCoc13}\n\\begin{eqnarray} \\nonumber\nJ^{\\mathrm{MF}}_{ij} &=& \\frac{J'_{ij}}\n{\\sqrt{f_i(1-f_i)f_j(1-f_j)}}, ~~ i \\neq j \\\\\nJ^{\\mathrm{MF}}_{ii} &=& \\sum_{j\\neq i} J^{\\mathrm{MF}}_{ij} \\left(\n(f_{ij} - f_i f_j)\\frac{f_i - \\frac{1}{2}} {f_i(1-f_i)} - f_j\n\\right),\n\\label{JMF}\n\\end{eqnarray}\nwhere $J'$ is the matrix that has the same eigenvectors $v_q$\nas the correlation matrix\n\n", "itemtype": "equation", "pos": 35580, "prevtext": "\nis the expected variance of each residual due to finite $N$,\nand repeated indices are understood as individual frequencies: $f_{ii} = f_i$.  A good fit is expected to have ${\\langle {\\chi^2} \\rangle} \\approx 1$.\n\nTo perform fitting, we use a simplified method that starts with the mean field solution and varies a single parameter corresponding to weighting a non-interacting prior. Specifically, we make use of the $L_2$-regularized mean field entropy of Ref.~\\cite{BarCoc13}.  The regularization consists of a Gaussian prior with a form designed to make the mean-field case easily solvable, corresponding to an additional term in the relative negative log likelihood\n\n", "index": 13, "text": "\\begin{equation}\nL_{\\mathrm{prior}} = \\gamma \\sum_i \\sum_{j > i} J_{ij}^2 f_i(1-f_i)f_j(1-f_j),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"L_{\\mathrm{prior}}=\\gamma\\sum_{i}\\sum_{j&gt;i}J_{ij}^{2}f_{i}(1-f_{i})f_{j}(1-f_{%&#10;j}),\" display=\"block\"><mrow><mrow><msub><mi>L</mi><mi>prior</mi></msub><mo>=</mo><mrow><mi>\u03b3</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>&gt;</mo><mi>i</mi></mrow></munder><mrow><msubsup><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mn>2</mn></msubsup><mo>\u2062</mo><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nand eigenvalues $j_q = 1/\\hat c_q$, where $\\hat c_q$ are\nregularized versions of $C$'s eigenvalues $c_q$:\n\n", "itemtype": "equation", "pos": 36238, "prevtext": "\nwhere $\\gamma$ is the strength of the prior, which favors interactions\n$J_{ij}$ that are smaller in magnitude.\nThe mean field solution under this regularization is \\cite{BarCoc13}\n\\begin{eqnarray} \\nonumber\nJ^{\\mathrm{MF}}_{ij} &=& \\frac{J'_{ij}}\n{\\sqrt{f_i(1-f_i)f_j(1-f_j)}}, ~~ i \\neq j \\\\\nJ^{\\mathrm{MF}}_{ii} &=& \\sum_{j\\neq i} J^{\\mathrm{MF}}_{ij} \\left(\n(f_{ij} - f_i f_j)\\frac{f_i - \\frac{1}{2}} {f_i(1-f_i)} - f_j\n\\right),\n\\label{JMF}\n\\end{eqnarray}\nwhere $J'$ is the matrix that has the same eigenvectors $v_q$\nas the correlation matrix\n\n", "index": 15, "text": "\\begin{equation}\nC = \\frac{f_{ij} - f_i f_j}{\\sqrt{f_i(1-f_i)f_j(1-f_j)}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"C=\\frac{f_{ij}-f_{i}f_{j}}{\\sqrt{f_{i}(1-f_{i})f_{j}(1-f_{j})}}\" display=\"block\"><mrow><mi>C</mi><mo>=</mo><mfrac><mrow><msub><mi>f</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub></mrow></mrow><msqrt><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msqrt></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\nThis regularization is typically used in a Bayesian sense to avoid overfitting, where a typical value of the regularization strength is $\\gamma = 1/(10 N f^2 (1-f)^2)$, with $N$ the number of samples and $f = n^{-1} \\sum_i f_i$ the average individual frequency \\cite{BarCoc13}.  Avoiding overfitting, however, still typically requires either enormous $N$ (e.g.~\\cite{SchBerSeg06}) or restricting the effective number of fit parameters via an expansion (e.g.~\\cite{BarCoc13}).  In our case, $N$ is fundamentally limited in that we are describing a stable social epoch of finite duration.  In addition, typical high-temperature expansions cannot easily incorporate the restriction that fights have a minimum number of participants [the $\\alpha$ term in {Eq.~(\\ref{{IsingE}})}].\n\n\n\n\n\n\n\nAlternatively one can treat $\\gamma$ as a fitting parameter that interpolates between the mean-field solution (which we find overestimates the strength of interactions) and the case of independent individuals. Although it is not \\textit{a priori} obvious that varying this single parameter will be enough to fit the observed statistics within expected statistical fluctuations, we find that this is true for our data.  Numerically sampling from the distribution defined by {Eq.~(\\ref{{IsingE}})} with the regularized mean-field $J$ from {Eq.~(\\ref{{JMF}})}, we minimize ${\\langle {\\chi^2} \\rangle}$ from {Eq.~(\\ref{{isingCost}})} as a function of $\\gamma$.  Sampling is performed using a standard Metropolis Markov Chain Monte Carlo approach.  In evaluating the fit, we choose the number of samples to scale with the number of data samples, using $N_\\mathrm{samples} = 20 N$.\n\nAs a simple check that this inference approach is not biased to find more sensitive systems, we infer a pairwise model using data produced by the independent model and compare its susceptibility to the known exact value [{Eq.~(\\ref{{suscFreq}})}] in {Fig.~\\ref{{fitJFreq}}}.  The resulting inferred model has susceptibility that stays close to the true value for small ${h_{\\mathrm{ext}}}$ and remains smaller than the true value for larger ${h_{\\mathrm{ext}}}$.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.80]{figures/150318_susceptibility_fitJfreq.pdf}\n\\caption{\nPerforming the second-order maximum entropy fitting procedure\non an amount of data equal to the observed fights drawn from\na noninteracting model produces a flat susceptibility curve comparable to the\nknown exact susceptibility for this case.\n\\label{fitJFreq}\n}\n\\end{figure}\n\n\\subsection{Branching process inference}\n\\label{BranchingProcessSection}\n\nIn the branching process model, we use time-ordered appearance data, fitting the time-ordered conditional appearance probabilities\n\n", "itemtype": "equation", "pos": 36433, "prevtext": "\nand eigenvalues $j_q = 1/\\hat c_q$, where $\\hat c_q$ are\nregularized versions of $C$'s eigenvalues $c_q$:\n\n", "index": 17, "text": "\\begin{equation}\n\\hat c_q = \\frac{1}{2} \\left( c_q - \\gamma +\n\\sqrt{(c_q - \\gamma)^2 + 4 \\gamma} \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\hat{c}_{q}=\\frac{1}{2}\\left(c_{q}-\\gamma+\\sqrt{(c_{q}-\\gamma)^{2}+4\\gamma}%&#10;\\right).\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi>c</mi><mo stretchy=\"false\">^</mo></mover><mi>q</mi></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><msub><mi>c</mi><mi>q</mi></msub><mo>-</mo><mi>\u03b3</mi></mrow><mo>+</mo><msqrt><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>c</mi><mi>q</mi></msub><mo>-</mo><mi>\u03b3</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mn>4</mn><mo>\u2062</mo><mi>\u03b3</mi></mrow></mrow></msqrt></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhere $N(x_i^t, x_j^T)$ counts the number of times individual $j$ appears in the same fight bout as individual $i$, but at a later time $T > t$.\\footnote{Note that this is different than previous work in Inductive Game Theory \\cite{DeDKraFla10}:\nthere (time directed) correlations were measured between individual appearances in separate fight bouts, whereas here we measure correlations within fight bouts.}\n\nThe parameters we vary in the heterogeneous branching process model are the single-step conditional probabilities $p_{ij}$, which measure the probability that individual $j$ appears in step $t+1$ of the branching process given that individual $i$ appeared in step $t$. Being probabilities, $p_{ij}$ are constrained to values $0 \\leq p_{ij} \\leq 1$.  (Note that the branching model is thus limited in the extent to which it can represent inhibitory interactions, \\emph{e.g.} if $i$'s involvement in the fight deters $j$ from joining.)  We modify this constrained optimization problem into an unconstrained one by defining $\\bar p_{ij} = | \\tanh^{-1} p_{ij} |$ and performing the optimization over the (unconstrained) $\\bar p_{ij}$ parameters.\n\nIn the branching process simulation, the first individual to join each fight bout is chosen randomly with probability proportional to the frequency with which each individual appears at the beginning of fights in the data.  At each subsequent time step in the branching process, each individual $j$ who has not yet been activated in the current fight has a probability of joining equal to the sum of $p_{ij}$ for all $i$ active in the previous time step.  The fight bout concludes when no individuals are active in a given time step.  As discussed above, fight bouts that do not grow beyond a single individual are discarded.\n\nAnalogously to the case of the equilibrium maximum entropy model, the branching process parameters are fit by minimizing\n\n", "itemtype": "equation", "pos": 39269, "prevtext": "\n\nThis regularization is typically used in a Bayesian sense to avoid overfitting, where a typical value of the regularization strength is $\\gamma = 1/(10 N f^2 (1-f)^2)$, with $N$ the number of samples and $f = n^{-1} \\sum_i f_i$ the average individual frequency \\cite{BarCoc13}.  Avoiding overfitting, however, still typically requires either enormous $N$ (e.g.~\\cite{SchBerSeg06}) or restricting the effective number of fit parameters via an expansion (e.g.~\\cite{BarCoc13}).  In our case, $N$ is fundamentally limited in that we are describing a stable social epoch of finite duration.  In addition, typical high-temperature expansions cannot easily incorporate the restriction that fights have a minimum number of participants [the $\\alpha$ term in {Eq.~(\\ref{{IsingE}})}].\n\n\n\n\n\n\n\nAlternatively one can treat $\\gamma$ as a fitting parameter that interpolates between the mean-field solution (which we find overestimates the strength of interactions) and the case of independent individuals. Although it is not \\textit{a priori} obvious that varying this single parameter will be enough to fit the observed statistics within expected statistical fluctuations, we find that this is true for our data.  Numerically sampling from the distribution defined by {Eq.~(\\ref{{IsingE}})} with the regularized mean-field $J$ from {Eq.~(\\ref{{JMF}})}, we minimize ${\\langle {\\chi^2} \\rangle}$ from {Eq.~(\\ref{{isingCost}})} as a function of $\\gamma$.  Sampling is performed using a standard Metropolis Markov Chain Monte Carlo approach.  In evaluating the fit, we choose the number of samples to scale with the number of data samples, using $N_\\mathrm{samples} = 20 N$.\n\nAs a simple check that this inference approach is not biased to find more sensitive systems, we infer a pairwise model using data produced by the independent model and compare its susceptibility to the known exact value [{Eq.~(\\ref{{suscFreq}})}] in {Fig.~\\ref{{fitJFreq}}}.  The resulting inferred model has susceptibility that stays close to the true value for small ${h_{\\mathrm{ext}}}$ and remains smaller than the true value for larger ${h_{\\mathrm{ext}}}$.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.80]{figures/150318_susceptibility_fitJfreq.pdf}\n\\caption{\nPerforming the second-order maximum entropy fitting procedure\non an amount of data equal to the observed fights drawn from\na noninteracting model produces a flat susceptibility curve comparable to the\nknown exact susceptibility for this case.\n\\label{fitJFreq}\n}\n\\end{figure}\n\n\\subsection{Branching process inference}\n\\label{BranchingProcessSection}\n\nIn the branching process model, we use time-ordered appearance data, fitting the time-ordered conditional appearance probabilities\n\n", "index": 19, "text": "\\begin{equation}\nP_{ij} = \\frac{ N(x_i^t, x_j^T) }{ N(x_i) },\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"P_{ij}=\\frac{N(x_{i}^{t},x_{j}^{T})}{N(x_{i})},\" display=\"block\"><mrow><mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>x</mi><mi>i</mi><mi>t</mi></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhere\n\n", "itemtype": "equation", "pos": 41247, "prevtext": "\nwhere $N(x_i^t, x_j^T)$ counts the number of times individual $j$ appears in the same fight bout as individual $i$, but at a later time $T > t$.\\footnote{Note that this is different than previous work in Inductive Game Theory \\cite{DeDKraFla10}:\nthere (time directed) correlations were measured between individual appearances in separate fight bouts, whereas here we measure correlations within fight bouts.}\n\nThe parameters we vary in the heterogeneous branching process model are the single-step conditional probabilities $p_{ij}$, which measure the probability that individual $j$ appears in step $t+1$ of the branching process given that individual $i$ appeared in step $t$. Being probabilities, $p_{ij}$ are constrained to values $0 \\leq p_{ij} \\leq 1$.  (Note that the branching model is thus limited in the extent to which it can represent inhibitory interactions, \\emph{e.g.} if $i$'s involvement in the fight deters $j$ from joining.)  We modify this constrained optimization problem into an unconstrained one by defining $\\bar p_{ij} = | \\tanh^{-1} p_{ij} |$ and performing the optimization over the (unconstrained) $\\bar p_{ij}$ parameters.\n\nIn the branching process simulation, the first individual to join each fight bout is chosen randomly with probability proportional to the frequency with which each individual appears at the beginning of fights in the data.  At each subsequent time step in the branching process, each individual $j$ who has not yet been activated in the current fight has a probability of joining equal to the sum of $p_{ij}$ for all $i$ active in the previous time step.  The fight bout concludes when no individuals are active in a given time step.  As discussed above, fight bouts that do not grow beyond a single individual are discarded.\n\nAnalogously to the case of the equilibrium maximum entropy model, the branching process parameters are fit by minimizing\n\n", "index": 21, "text": "\\begin{equation}\n\\label{branchingCost}\n{\\langle {\\chi^2_{\\mathrm{Branching}}} \\rangle} = \\frac{1}{n(n-1)} \\sum_i \\sum_{j \\neq i} \\frac{ \\left(\nP_{ij}^{\\mathrm{data}}\n- P_{ij}^{\\mathrm{model}} \\right)^2 }{ \\sigma_{P_{ij}}^2 },\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"{\\langle{\\chi^{2}_{\\mathrm{Branching}}}\\rangle}=\\frac{1}{n(n-1)}\\sum_{i}\\sum_{%&#10;j\\neq i}\\frac{\\left(P_{ij}^{\\mathrm{data}}-P_{ij}^{\\mathrm{model}}\\right)^{2}}%&#10;{\\sigma_{P_{ij}}^{2}},\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msubsup><mi>\u03c7</mi><mi>Branching</mi><mn>2</mn></msubsup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>i</mi></mrow></munder><mfrac><msup><mrow><mo>(</mo><mrow><msubsup><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mi>data</mi></msubsup><mo>-</mo><msubsup><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mi>model</mi></msubsup></mrow><mo>)</mo></mrow><mn>2</mn></msup><msubsup><mi>\u03c3</mi><msub><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mn>2</mn></msubsup></mfrac></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\n\n\n\nWe use a standard Levenberg-Marquardt algorithm ({\\tt scipy.optimize.leastsq}) that uses individual residuals and a lowest-order approximation for the Jacobian with respect to parameters. We find that restarting the Levenberg-Marquardt routine every 10 steps (effectively resetting its damping parameter to avoid unnecessarily small steps arising from its assumption of a non-stochastic objective function) produces faster convergence with fewer samples required for each estimate of the residuals and Jacobian. Minimization is stopped once ${\\langle {\\chi^2} \\rangle}$ defined in {Eq.~(\\ref{{branchingCost}})} falls below 1.  In addition, we find that switching between simple gradient descent steps and Levenberg-Marquardt minimizations allows for more efficient fitting of larger $P_{ij}$.\n\nThe resulting inferred redirection probabilities $p_{ij}$ are visualized in {Fig.~\\ref{{branchingGraph}}}.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.75]{figures/150122_thresholded_branching_graph.pdf}\n\\caption{ A visualization of the inferred branching process graph.\nIn the full branching process model, all possible directed pairwise\ninteractions are included, but here we visualize the most important\ninteractions by displaying those with triggering probabilities $> 0.09$.\nThe thickness of each arrow corresponds to the probability of\ntriggering, with the thickest\nlines correspond to a probability of about 1/3: for instance, when Yg appears, Pr\nwill be triggered by Yg to join with probability of about 1/3.\n\\label{branchingGraph}\n}\n\\end{figure}\n\n\\section{Notes on model evaluation}\n\\label{modelevaluation}\n\nTo check the performance of each of our models, we first compare statistics computed with the model to those computed on out-of-sample data.  The results for a single choice of in-sample data are shown in Fig.~\\ref{fittingScorecardFigure}.  Half of the fights are randomly chosen as in-sample data, with the remaining treated as out-of-sample data to be predicted.  We see that the independent model does not capture second- or third-order statistics nor the distribution of fight sizes, while both the equilibrium and dynamic models capture these to produce predictions that are roughly as accurate as using out-of-sample data.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.6]{figures/fittingScorecardFigure.pdf}\n\\caption{\nThe degree of fit for the noninteracting model (green),\nmaximum entropy pairwise model (blue), and\nbranching process model (red) to out-of-sample data, compared\nto the same for the in-sample data (indigo) to which the models are fit.\nFor each model, $10^5$ samples were taken to evaluate predicted\nstatistics.  Also shown on each plot is the Pearson correlation $\\rho$ between predicted and out-of-sample statistics (for individual, pairwise, and triplet statistics) or the Kullback-Leibler divergence $D_{\\mathrm{KL}}$ between predicted and out-of-sample distributions (for fight sizes).  (To avoid problems with large fight sizes that are never observed, $D_{\\mathrm{KL}}$ is calculated only using fights of size $\\leq 12$.)\n\\label{fittingScorecardFigure}\n}\n\\end{figure}\n\nSecond, we can check that residuals lie within the bounds of expected statistical fluctuations from finite sampling.  Shown in Table~\\ref{goodnessOfFitTable}, the equilibrium and dynamic models have squared residuals that are below but near the expected value ${\\langle \\chi \\rangle}^2 = 1$, whereas the independent model is inadequate to describe the statistics.  This is visualized in more detail with the distribution of residuals in {Fig.~\\ref{{isingStatistics}}}.\n\n\\begin{table}\n\\begin{center}\n\\caption{\n\\label{goodnessOfFitTable}\nGoodness of fit to data for the three models,\ncalculated using {Eq.~(\\ref{{isingCost}})} for the independent and pairwise maximum entropy models and {Eq.~(\\ref{{branchingCost}})} for the dynamic branching model.\nWith ${\\langle {\\chi^2} \\rangle} \\sim 1$, the equilibrium pairwise and dynamic branching models fit the data roughly within the precision afforded by the data.\nOverfitting, which would be indicated by ${\\langle {\\chi^2} \\rangle} \\ll 1$, is avoided by\nusing constrained minimization in the case of the spin-glass model\n(see Sec.~\\ref{IsingModelSection}) and by ending minimization once\n${\\langle {\\chi^2} \\rangle} \\leq 1$ in the case of the branching model\n(see Sec.~\\ref{BranchingProcessSection}).}\n\\begin{tabular}{  l | l | l | l }\n& \\emph{Independent model}\n& \\emph{Equilibrium pairwise model}\n& \\emph{Dynamic branching model}                        \\\\\n\\hline\nRandom half of data\n&  ${\\langle {\\chi^2} \\rangle} = 1.134 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.459 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.414 $                              \\\\\nAll data\n&  ${\\langle {\\chi^2} \\rangle} = 1.822 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.597 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.462 $                              \\\\\n\\end{tabular}\n\\end{center}\n\\end{table}\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.80]{figures/isingStatistics.pdf}\n\\caption{\nSecond- and third-order statistics in the conflict data.  Second-order\nstatistics (left) clearly violate the null expectation for a\nfirst-order independent model (dotted line), while third-order statistics (right)\nlie within expected fluctuations from a second-order model (dotted line).\n$f_{ijk}$ is the empirical frequency with which each triplet appears in fights,\n$f^\\mathrm{SG}_{ijk}$ is this frequency in the pairwise equilibrium model, and\n$\\sigma_{ijk} = \\sqrt{f_{ijk}(1-f_{ijk})/N}$ is the expected standard deviation.\n\\label{isingStatistics}\n}\n\\end{figure}\n\nWe find no evidence of significant higher order correlations in the data ({Fig.~\\ref{{isingStatistics}}}) and we therefore do not explore models with interactions of higher order. We note however that the resolution of higher order correlations is limited by the finite number of observed fights and relatively small frequency of individual participation. This cannot easily be remedied by collecting more data as the system is not at equilibrium over longer timescales. To deal with this, we must restrict the data we use in the analyses to collection windows defined by ``socially stable periods'' (SI, Sec~\\ref{EmpiricalMethods}).\n\n\n\\section{Notes on evaluating sensitivity and stability}\n\\label{evalsens}\nPhase transitions are typically identified as conditions under which the varying of a control parameter causes large-scale changes in the behavior of a system, in a way that sensitivity per individual (measured by, \\emph{e.g.}, specific heat or susceptibility) grows arbitrarily large with growing system size. This becomes possible only when there is a collective instability, meaning that the effective size of the perturbation (that starts, say, with a single individual) does not shrink as it spreads through the system but stays of constant size or grows (potentially affecting all individuals).  Thus in a finite system, the combination of a peak in sensitivity and collective instability can be used as an indicator of a phase-transition-like state.\n\n\\subsection{Sensitivity as Fisher information}\nIn our finite system the notion of diverging sensitivity is arguably more accurately described in terms of information theory. Even when the idea of a phase transition becomes fuzzy in a finite system, the Fisher information measures something adaptively important: the degree to which individual scale perturbations are visible at the global scale, or, equivalently,  the connection between the behavior of any individual and the behavior of the whole \\cite{Tchernookov2012,Prokopenko2011}.\n\n\\subsection{Analytical results for sensitivity in the independent model}\n\nHere we show that the sensitivity (susceptibility) to increased aggression in the independent model can be efficiently solved numerically.  This is used to make a comparison with the pairwise equilibrium model in {Fig.~\\ref{{susceptibilityFigure}}}.\n\nFirst, in the more analytically straightforward case in which we allow fights of size zero and one ($\\alpha = 0$; see section \\ref{independentInference}), the average fight size and susceptibility are\n\\begin{eqnarray}\n{\\langle {s} \\rangle}_{\\alpha = 0} &=&\n\\sum_i \\left(1 + \\exp( h_i - {h_{\\mathrm{ext}}} ) \\right)^{-1}               \\\\\n\\chi_0 = \\frac{\\partial {\\langle {s} \\rangle}_{\\alpha = 0} }{\\partial {h_{\\mathrm{ext}}}}\n&=& \\sum_i {\\text{sech}}^2 (h_i - {h_{\\mathrm{ext}}}).\n\\end{eqnarray}\nThe partition functions of the constrained and unconstrained models,\ndefined such that\n\\begin{eqnarray}\np(\\vec x)_{\\alpha = 0} &=& \\exp[ - L_{\\alpha = 0}(\\vec x) ] / Z_0  \\\\\np(\\vec x)_{\\alpha \\rightarrow \\infty} &=&\n \\exp[ -L_{\\alpha \\rightarrow \\infty}(\\vec x) ] / Z_\\infty,\n\\end{eqnarray}\nare given by\n\\begin{eqnarray}\nZ_0 &=& \\prod_i (1 + \\exp h_i) \\\\\nZ_\\infty &=& Z_0 - 1 - \\sum_i \\exp h_i.\n\\end{eqnarray}\nIn terms of these values, when fights of size zero and one are forbidden\n($\\alpha \\rightarrow \\infty$), the average fight size and susceptibility become\n\\begin{eqnarray}\n{\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty} &=&\n\\frac{Z_0}{Z_\\infty} {\\langle {s} \\rangle}_{\\alpha = 0}\n- \\frac{\\sum_i \\exp h_i}{Z_\\infty}                               \\\\\n\\chi_\\infty = \\frac{\\partial {\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty} }\n{\\partial {h_{\\mathrm{ext}}}}\n&=& \\frac{Z_0}{Z_\\infty}\n\\frac{\\partial {\\langle {s} \\rangle}_{\\alpha = 0} }{\\partial {h_{\\mathrm{ext}}}}\n- \\frac{\\sum_i \\exp h_i}{Z_\\infty}\n+ \\frac{Z_0}{Z_\\infty} {\\langle {s} \\rangle}_{\\alpha = 0}^2\n- {\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty}^2. \\label{suscFreq}\n\\end{eqnarray}\n\n\n\\subsection{Operationalizing collective instability in the branching process model}\n\\label{collectinstab}\nCollective instability is straightforward to understand in a branching model. In an infinite system, this model has a well-defined phase transition when $R_0$, the average number of other individuals triggered when a single individual becomes active, is equal to 1. This also corresponds to the point at which the system is maximally sensitive to changes in parameters. The fact that this ``local'' amplification factor is also indicative of a global transition relies on the infinite limit:  In a finite system, cascades will be shortened when they reach individuals that have already been activated, and maximal sensitivity will happen at some $R_0 > 1$ \\cite{Beg07}.  We thus think of $R_0$ as measuring a ``local'' or lowest-order stability.\nIn the heterogeneous branching process model, this linear stability of the peaceful state is indicated by the largest eigenvalue $R_0$ of the redirection probability matrix $p_{ij}$.\n\nWe note that in the branching model, as opposed to the equilibrium model, increasing activation will always eventually lead to instability.\n\n\\subsection{Operationalizing collective instability in the pairwise equilibrium model}\n\\label{stabilitySection}\n\nIn an infinite system, the pairwise equilibrium model also has a phase transition under the condition of local instability, with a corresponding diverging sensitivity.  In this case, instability can be quantified using the mean-field solution, connecting with a high-temperature expansion of spin-glass models.\n\nOne way to think about the continuous phase transition in an infinite spin-glass model is that it is the point at which the high temperature mean-field solution becomes unstable. Mean-field solutions are characterized by frequencies $\\vec f$ of individual appearance ($f_i = {\\langle {x_i} \\rangle}$) that satisfy the self-consistency equation \\cite{Sta71}\n\n", "itemtype": "equation", "pos": 41494, "prevtext": "\nwhere\n\n", "index": 23, "text": "\\begin{equation}\n\\sigma_{P_{ij}}^2 = \\frac{ P_{ij} (1-P_{ij}) }{ N(x_i) }.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\sigma_{P_{ij}}^{2}=\\frac{P_{ij}(1-P_{ij})}{N(x_{i})}.\" display=\"block\"><mrow><mrow><msubsup><mi>\u03c3</mi><msub><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>P</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>N</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nIntuitively, individual $i$'s frequency of fighting is determined by the mean ``field'' it feels as a result of others' fighting.  The function $F_i$ encodes how $i$ reacts to its environment, translating the mean fighting frequencies $i$ sees into its own mean frequency.  When {Eq.~(\\ref{{meanFieldEqn}})} holds for every individual using a single set of frequencies $\\vec f$, this defines the mean field solution.\n\nNow imagine perturbing fighting frequencies $\\vec f$ by a small $\\Delta \\vec f$.  This will typically no longer be a solution of {Eq.~(\\ref{{meanFieldEqn}})}.  But if we repeatedly apply the function $F$ to $\\vec f + \\Delta \\vec f$, we can imagine two possibilities: we might end up back at $\\vec f$ (so that $\\lim_{n\\rightarrow \\infty} F^n(\\vec f + \\Delta \\vec f) = \\vec f$), or we might get further and further from $\\vec f$.  We will call the first case a ``stable'' mean field solution and the second case ``unstable''.\n\nFor small perturbations $\\Delta \\vec f$, we can distinguish these two cases\nby taking a derivative to perform a linear stability analysis. Specifically,\n\n", "itemtype": "equation", "pos": 53108, "prevtext": "\n\n\n\n\nWe use a standard Levenberg-Marquardt algorithm ({\\tt scipy.optimize.leastsq}) that uses individual residuals and a lowest-order approximation for the Jacobian with respect to parameters. We find that restarting the Levenberg-Marquardt routine every 10 steps (effectively resetting its damping parameter to avoid unnecessarily small steps arising from its assumption of a non-stochastic objective function) produces faster convergence with fewer samples required for each estimate of the residuals and Jacobian. Minimization is stopped once ${\\langle {\\chi^2} \\rangle}$ defined in {Eq.~(\\ref{{branchingCost}})} falls below 1.  In addition, we find that switching between simple gradient descent steps and Levenberg-Marquardt minimizations allows for more efficient fitting of larger $P_{ij}$.\n\nThe resulting inferred redirection probabilities $p_{ij}$ are visualized in {Fig.~\\ref{{branchingGraph}}}.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.75]{figures/150122_thresholded_branching_graph.pdf}\n\\caption{ A visualization of the inferred branching process graph.\nIn the full branching process model, all possible directed pairwise\ninteractions are included, but here we visualize the most important\ninteractions by displaying those with triggering probabilities $> 0.09$.\nThe thickness of each arrow corresponds to the probability of\ntriggering, with the thickest\nlines correspond to a probability of about 1/3: for instance, when Yg appears, Pr\nwill be triggered by Yg to join with probability of about 1/3.\n\\label{branchingGraph}\n}\n\\end{figure}\n\n\\section{Notes on model evaluation}\n\\label{modelevaluation}\n\nTo check the performance of each of our models, we first compare statistics computed with the model to those computed on out-of-sample data.  The results for a single choice of in-sample data are shown in Fig.~\\ref{fittingScorecardFigure}.  Half of the fights are randomly chosen as in-sample data, with the remaining treated as out-of-sample data to be predicted.  We see that the independent model does not capture second- or third-order statistics nor the distribution of fight sizes, while both the equilibrium and dynamic models capture these to produce predictions that are roughly as accurate as using out-of-sample data.\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.6]{figures/fittingScorecardFigure.pdf}\n\\caption{\nThe degree of fit for the noninteracting model (green),\nmaximum entropy pairwise model (blue), and\nbranching process model (red) to out-of-sample data, compared\nto the same for the in-sample data (indigo) to which the models are fit.\nFor each model, $10^5$ samples were taken to evaluate predicted\nstatistics.  Also shown on each plot is the Pearson correlation $\\rho$ between predicted and out-of-sample statistics (for individual, pairwise, and triplet statistics) or the Kullback-Leibler divergence $D_{\\mathrm{KL}}$ between predicted and out-of-sample distributions (for fight sizes).  (To avoid problems with large fight sizes that are never observed, $D_{\\mathrm{KL}}$ is calculated only using fights of size $\\leq 12$.)\n\\label{fittingScorecardFigure}\n}\n\\end{figure}\n\nSecond, we can check that residuals lie within the bounds of expected statistical fluctuations from finite sampling.  Shown in Table~\\ref{goodnessOfFitTable}, the equilibrium and dynamic models have squared residuals that are below but near the expected value ${\\langle \\chi \\rangle}^2 = 1$, whereas the independent model is inadequate to describe the statistics.  This is visualized in more detail with the distribution of residuals in {Fig.~\\ref{{isingStatistics}}}.\n\n\\begin{table}\n\\begin{center}\n\\caption{\n\\label{goodnessOfFitTable}\nGoodness of fit to data for the three models,\ncalculated using {Eq.~(\\ref{{isingCost}})} for the independent and pairwise maximum entropy models and {Eq.~(\\ref{{branchingCost}})} for the dynamic branching model.\nWith ${\\langle {\\chi^2} \\rangle} \\sim 1$, the equilibrium pairwise and dynamic branching models fit the data roughly within the precision afforded by the data.\nOverfitting, which would be indicated by ${\\langle {\\chi^2} \\rangle} \\ll 1$, is avoided by\nusing constrained minimization in the case of the spin-glass model\n(see Sec.~\\ref{IsingModelSection}) and by ending minimization once\n${\\langle {\\chi^2} \\rangle} \\leq 1$ in the case of the branching model\n(see Sec.~\\ref{BranchingProcessSection}).}\n\\begin{tabular}{  l | l | l | l }\n& \\emph{Independent model}\n& \\emph{Equilibrium pairwise model}\n& \\emph{Dynamic branching model}                        \\\\\n\\hline\nRandom half of data\n&  ${\\langle {\\chi^2} \\rangle} = 1.134 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.459 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.414 $                              \\\\\nAll data\n&  ${\\langle {\\chi^2} \\rangle} = 1.822 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.597 $\n&  ${\\langle {\\chi^2} \\rangle} = 0.462 $                              \\\\\n\\end{tabular}\n\\end{center}\n\\end{table}\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.80]{figures/isingStatistics.pdf}\n\\caption{\nSecond- and third-order statistics in the conflict data.  Second-order\nstatistics (left) clearly violate the null expectation for a\nfirst-order independent model (dotted line), while third-order statistics (right)\nlie within expected fluctuations from a second-order model (dotted line).\n$f_{ijk}$ is the empirical frequency with which each triplet appears in fights,\n$f^\\mathrm{SG}_{ijk}$ is this frequency in the pairwise equilibrium model, and\n$\\sigma_{ijk} = \\sqrt{f_{ijk}(1-f_{ijk})/N}$ is the expected standard deviation.\n\\label{isingStatistics}\n}\n\\end{figure}\n\nWe find no evidence of significant higher order correlations in the data ({Fig.~\\ref{{isingStatistics}}}) and we therefore do not explore models with interactions of higher order. We note however that the resolution of higher order correlations is limited by the finite number of observed fights and relatively small frequency of individual participation. This cannot easily be remedied by collecting more data as the system is not at equilibrium over longer timescales. To deal with this, we must restrict the data we use in the analyses to collection windows defined by ``socially stable periods'' (SI, Sec~\\ref{EmpiricalMethods}).\n\n\n\\section{Notes on evaluating sensitivity and stability}\n\\label{evalsens}\nPhase transitions are typically identified as conditions under which the varying of a control parameter causes large-scale changes in the behavior of a system, in a way that sensitivity per individual (measured by, \\emph{e.g.}, specific heat or susceptibility) grows arbitrarily large with growing system size. This becomes possible only when there is a collective instability, meaning that the effective size of the perturbation (that starts, say, with a single individual) does not shrink as it spreads through the system but stays of constant size or grows (potentially affecting all individuals).  Thus in a finite system, the combination of a peak in sensitivity and collective instability can be used as an indicator of a phase-transition-like state.\n\n\\subsection{Sensitivity as Fisher information}\nIn our finite system the notion of diverging sensitivity is arguably more accurately described in terms of information theory. Even when the idea of a phase transition becomes fuzzy in a finite system, the Fisher information measures something adaptively important: the degree to which individual scale perturbations are visible at the global scale, or, equivalently,  the connection between the behavior of any individual and the behavior of the whole \\cite{Tchernookov2012,Prokopenko2011}.\n\n\\subsection{Analytical results for sensitivity in the independent model}\n\nHere we show that the sensitivity (susceptibility) to increased aggression in the independent model can be efficiently solved numerically.  This is used to make a comparison with the pairwise equilibrium model in {Fig.~\\ref{{susceptibilityFigure}}}.\n\nFirst, in the more analytically straightforward case in which we allow fights of size zero and one ($\\alpha = 0$; see section \\ref{independentInference}), the average fight size and susceptibility are\n\\begin{eqnarray}\n{\\langle {s} \\rangle}_{\\alpha = 0} &=&\n\\sum_i \\left(1 + \\exp( h_i - {h_{\\mathrm{ext}}} ) \\right)^{-1}               \\\\\n\\chi_0 = \\frac{\\partial {\\langle {s} \\rangle}_{\\alpha = 0} }{\\partial {h_{\\mathrm{ext}}}}\n&=& \\sum_i {\\text{sech}}^2 (h_i - {h_{\\mathrm{ext}}}).\n\\end{eqnarray}\nThe partition functions of the constrained and unconstrained models,\ndefined such that\n\\begin{eqnarray}\np(\\vec x)_{\\alpha = 0} &=& \\exp[ - L_{\\alpha = 0}(\\vec x) ] / Z_0  \\\\\np(\\vec x)_{\\alpha \\rightarrow \\infty} &=&\n \\exp[ -L_{\\alpha \\rightarrow \\infty}(\\vec x) ] / Z_\\infty,\n\\end{eqnarray}\nare given by\n\\begin{eqnarray}\nZ_0 &=& \\prod_i (1 + \\exp h_i) \\\\\nZ_\\infty &=& Z_0 - 1 - \\sum_i \\exp h_i.\n\\end{eqnarray}\nIn terms of these values, when fights of size zero and one are forbidden\n($\\alpha \\rightarrow \\infty$), the average fight size and susceptibility become\n\\begin{eqnarray}\n{\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty} &=&\n\\frac{Z_0}{Z_\\infty} {\\langle {s} \\rangle}_{\\alpha = 0}\n- \\frac{\\sum_i \\exp h_i}{Z_\\infty}                               \\\\\n\\chi_\\infty = \\frac{\\partial {\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty} }\n{\\partial {h_{\\mathrm{ext}}}}\n&=& \\frac{Z_0}{Z_\\infty}\n\\frac{\\partial {\\langle {s} \\rangle}_{\\alpha = 0} }{\\partial {h_{\\mathrm{ext}}}}\n- \\frac{\\sum_i \\exp h_i}{Z_\\infty}\n+ \\frac{Z_0}{Z_\\infty} {\\langle {s} \\rangle}_{\\alpha = 0}^2\n- {\\langle {s} \\rangle}_{\\alpha \\rightarrow \\infty}^2. \\label{suscFreq}\n\\end{eqnarray}\n\n\n\\subsection{Operationalizing collective instability in the branching process model}\n\\label{collectinstab}\nCollective instability is straightforward to understand in a branching model. In an infinite system, this model has a well-defined phase transition when $R_0$, the average number of other individuals triggered when a single individual becomes active, is equal to 1. This also corresponds to the point at which the system is maximally sensitive to changes in parameters. The fact that this ``local'' amplification factor is also indicative of a global transition relies on the infinite limit:  In a finite system, cascades will be shortened when they reach individuals that have already been activated, and maximal sensitivity will happen at some $R_0 > 1$ \\cite{Beg07}.  We thus think of $R_0$ as measuring a ``local'' or lowest-order stability.\nIn the heterogeneous branching process model, this linear stability of the peaceful state is indicated by the largest eigenvalue $R_0$ of the redirection probability matrix $p_{ij}$.\n\nWe note that in the branching model, as opposed to the equilibrium model, increasing activation will always eventually lead to instability.\n\n\\subsection{Operationalizing collective instability in the pairwise equilibrium model}\n\\label{stabilitySection}\n\nIn an infinite system, the pairwise equilibrium model also has a phase transition under the condition of local instability, with a corresponding diverging sensitivity.  In this case, instability can be quantified using the mean-field solution, connecting with a high-temperature expansion of spin-glass models.\n\nOne way to think about the continuous phase transition in an infinite spin-glass model is that it is the point at which the high temperature mean-field solution becomes unstable. Mean-field solutions are characterized by frequencies $\\vec f$ of individual appearance ($f_i = {\\langle {x_i} \\rangle}$) that satisfy the self-consistency equation \\cite{Sta71}\n\n", "index": 25, "text": "\\begin{equation}\n\\label{meanFieldEqn}\nf_i = F_i(\\vec f) \\equiv\n\\left[ 1 + \\exp \\left(J_{ii} + 2 \\sum_{j \\neq i} J_{ij} f_j\\right) \\right]^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"f_{i}=F_{i}(\\vec{f})\\equiv\\left[1+\\exp\\left(J_{ii}+2\\sum_{j\\neq i}J_{ij}f_{j}%&#10;\\right)\\right]^{-1}.\" display=\"block\"><mrow><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>=</mo><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2261</mo><msup><mrow><mo>[</mo><mrow><mn>1</mn><mo>+</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>i</mi></mrow></munder><mrow><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>]</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nand to converge back to $\\vec f$ for every perturbation, we must have that the updated perturbation along each direction\nhas shrunk.  This corresponds to a condition on the eigenvalues\n$\\lambda_\\alpha$\nof the derivative matrix $M_{ij} \\equiv \\partial F_i / \\partial f_j$;\nthe state is stable if\n\n", "itemtype": "equation", "pos": 54363, "prevtext": "\nIntuitively, individual $i$'s frequency of fighting is determined by the mean ``field'' it feels as a result of others' fighting.  The function $F_i$ encodes how $i$ reacts to its environment, translating the mean fighting frequencies $i$ sees into its own mean frequency.  When {Eq.~(\\ref{{meanFieldEqn}})} holds for every individual using a single set of frequencies $\\vec f$, this defines the mean field solution.\n\nNow imagine perturbing fighting frequencies $\\vec f$ by a small $\\Delta \\vec f$.  This will typically no longer be a solution of {Eq.~(\\ref{{meanFieldEqn}})}.  But if we repeatedly apply the function $F$ to $\\vec f + \\Delta \\vec f$, we can imagine two possibilities: we might end up back at $\\vec f$ (so that $\\lim_{n\\rightarrow \\infty} F^n(\\vec f + \\Delta \\vec f) = \\vec f$), or we might get further and further from $\\vec f$.  We will call the first case a ``stable'' mean field solution and the second case ``unstable''.\n\nFor small perturbations $\\Delta \\vec f$, we can distinguish these two cases\nby taking a derivative to perform a linear stability analysis. Specifically,\n\n", "index": 27, "text": "\\begin{equation}\nF_i(\\vec f + \\Delta \\vec f) \\approx F_i(\\vec f)\n+ \\sum_j \\frac{\\partial F_i}{\\partial f_j} \\Delta f_j,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"F_{i}(\\vec{f}+\\Delta\\vec{f})\\approx F_{i}(\\vec{f})+\\sum_{j}\\frac{\\partial F_{i%&#10;}}{\\partial f_{j}}\\Delta f_{j},\" display=\"block\"><mrow><mrow><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>+</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">\u2192</mo></mover></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">\u2192</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>F</mi><mi>i</mi></msub></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>f</mi><mi>j</mi></msub></mrow></mfrac><mo>\u2062</mo><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nThus the eigenvalue $\\lambda$ with largest magnitude determines stability.\n\nWe can write this derivative matrix $M$ more explicitly by taking the\nderivative of {Eq.~(\\ref{{meanFieldEqn}})} and assuming that we are at the\nfixed point $(\\vec f = F(\\vec f))$:\n\\begin{eqnarray} \\nonumber\nM_{ij} &=& \\frac{\\partial F_i}{\\partial f_j} \\\\ \\nonumber\n&=& -2 (1 - \\delta_{ij}) J_{ij}\n\\exp \\left(h_i + 2 \\sum_{j \\neq i} J_{ij} f_j\\right) f_i^2 \\\\ \\nonumber\n&=& -2 (1 - \\delta_{ij}) J_{ij} \\frac{1 - f_i}{f_i} f_i^2 \\\\\n&=& -2 (1 - \\delta_{ij}) J_{ij} f_i (1 - f_i).\n\\label{Meqn}\n\\end{eqnarray}\n\nThus $M$ is a matrix analogous to $p_{ij}$ in the branching process model in that its spectrum is informative about how perturbations grow or shrink. Specifically, we use the magnitude $\\lambda$ of the largest eigenvalue of $M$ as a measure of stability of the system.  When $\\lambda > 1$, we expect the system to be unstable to perturbation.\n\nThis condition on the stability of mean field theory can be shown to be equivalent to the condition that identifies the spin-glass transition in an infinite system.\n\n\n\n\n\nSpecifically, instability of the high-temperature mean-field expansion happens only below the spin-glass temperature \\cite{MezParVir87,Geo04}. To lowest order in $1/T$ (corresponding to lowest order in $J_{ij}$ or $1/N$), the mean-field free energy has the form (following \\cite{GeoYed91})\n\n", "itemtype": "equation", "pos": 54793, "prevtext": "\nand to converge back to $\\vec f$ for every perturbation, we must have that the updated perturbation along each direction\nhas shrunk.  This corresponds to a condition on the eigenvalues\n$\\lambda_\\alpha$\nof the derivative matrix $M_{ij} \\equiv \\partial F_i / \\partial f_j$;\nthe state is stable if\n\n", "index": 29, "text": "\\begin{equation}\n| \\lambda_\\alpha | < 1 ~~~~ \\forall ~ \\alpha.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"|\\lambda_{\\alpha}|&lt;1~{}~{}~{}~{}\\forall~{}\\alpha.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><msub><mi>\u03bb</mi><mi>\u03b1</mi></msub><mo stretchy=\"false\">|</mo></mrow><mo>&lt;</mo><mrow><mn>1</mn><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2005</mo><mrow><mo rspace=\"5.8pt\">\u2200</mo><mi>\u03b1</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhich when differentiated produces the self-consistency equation\n(\\ref{meanFieldEqn}).  Taking a second derivative,\n\n", "itemtype": "equation", "pos": 56258, "prevtext": "\nThus the eigenvalue $\\lambda$ with largest magnitude determines stability.\n\nWe can write this derivative matrix $M$ more explicitly by taking the\nderivative of {Eq.~(\\ref{{meanFieldEqn}})} and assuming that we are at the\nfixed point $(\\vec f = F(\\vec f))$:\n\\begin{eqnarray} \\nonumber\nM_{ij} &=& \\frac{\\partial F_i}{\\partial f_j} \\\\ \\nonumber\n&=& -2 (1 - \\delta_{ij}) J_{ij}\n\\exp \\left(h_i + 2 \\sum_{j \\neq i} J_{ij} f_j\\right) f_i^2 \\\\ \\nonumber\n&=& -2 (1 - \\delta_{ij}) J_{ij} \\frac{1 - f_i}{f_i} f_i^2 \\\\\n&=& -2 (1 - \\delta_{ij}) J_{ij} f_i (1 - f_i).\n\\label{Meqn}\n\\end{eqnarray}\n\nThus $M$ is a matrix analogous to $p_{ij}$ in the branching process model in that its spectrum is informative about how perturbations grow or shrink. Specifically, we use the magnitude $\\lambda$ of the largest eigenvalue of $M$ as a measure of stability of the system.  When $\\lambda > 1$, we expect the system to be unstable to perturbation.\n\nThis condition on the stability of mean field theory can be shown to be equivalent to the condition that identifies the spin-glass transition in an infinite system.\n\n\n\n\n\nSpecifically, instability of the high-temperature mean-field expansion happens only below the spin-glass temperature \\cite{MezParVir87,Geo04}. To lowest order in $1/T$ (corresponding to lowest order in $J_{ij}$ or $1/N$), the mean-field free energy has the form (following \\cite{GeoYed91})\n\n", "index": 31, "text": "\\begin{equation}\nA = \\sum_i f_i \\log f_i + (1-f_i) \\log (1-f_i) - \\sum_i \\sum_{j \\neq i} J_{ij} f_i f_j - \\sum_i J_{ii} f_i,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"A=\\sum_{i}f_{i}\\log f_{i}+(1-f_{i})\\log(1-f_{i})-\\sum_{i}\\sum_{j\\neq i}J_{ij}f%&#10;_{i}f_{j}-\\sum_{i}J_{ii}f_{i},\" display=\"block\"><mrow><mrow><mi>A</mi><mo>=</mo><mrow><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><msub><mi>f</mi><mi>i</mi></msub></mrow></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2260</mo><mi>i</mi></mrow></munder><mrow><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>f</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msub><mi>f</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhich defines stability to this order when all eigenvalues of $\\Lambda_{ij}$ are positive \\cite{Geo04}. Because $f_i(1-f_i)>0$, this condition is the same as all eigenvalues of $f_i(1-f_i)\\Lambda_{ij} = \\delta_{ij} - M_{ij}$ being positive (where $M$ is defined in {Eq.~(\\ref{{Meqn}})}), which is in turn equivalent to the above condition that all eigenvalues of $M_{ij}$ are less than 1.\n\nTo create a homogeneous finite system poised at the transition defined by the eigenvalue $\\lambda$ (shown as the red dotted curve in {Fig.~\\ref{{susceptibilityFigure}}}), we define a homogeneous positive $h$ and negative $J$ that make each individual's frequency $f = 1/2$ and $\\lambda = 1$.  \n\n\n\n\n\\section{Notes on quantifying DFC}\n\\label{sensitiveindividuals}\nAs described in the main text, by simulating forcing some number of individuals to be involved in every fight we can quantify distance from the critical point by measuring changes to sensitivity and collective instability.  We measure this distance in units natural to the system by forcing a subset of individuals to join fights and measuring the sensitivity of the remaining individuals.\n\nThe number of individuals (or, in principle, subgroups) that must be forced to reach peak sensitivity provides an operational definition of DFC. We find three to five individuals is sufficient and we find individual variation in sensitivity scores. In both the equilibrium and branching process models individuals with higher sensitivity scores are those who (by definition) exert greater influence on how far the system sits from the critical point.\n\nWe find that individuals whose simulated forcing causes the largest increase in average fight sizes are also those who cause the largest increase in sensitivity, as might be expected in this system with largely excitatory interactions.  In each model, this sensitivity score depends on the individual's place within the overall network structure, measuring both its direct influence on inducing others to fight and indirect influence through those it induces to fight.\n\n\n\n\\subsection{Tuning mechanisms}\n\\label{tuning}\nThe sensitivity scores generated by each model are capturing different underlying tuning mechanisms. In the case of the branching process model, the model captures the spread of fight-joining through direct interactions: one individual through its behavior triggers the involvement of a second individual. Hence this model only allows that the target individuals, through their own fight joining decisions, can up or down regulate their fight involvement. When a high sensitivity individual up or down regulates its own behavior moving the system respectively closer to or further from the critical point, we call this \\emph{direct tuning}.\n\nThe equilibrium model, on the other hand, is agnostic to cause, recording any pairwise correlation in fight joining regardless of which individual triggered the joining event. As such it captures the full space of behavioral mechanisms leading to fight-joining---individuals can become involved in fights by up regulating their own fight involvement and \\emph{also} through changes to third-party behavior. For example, policing (by third-parties to the fight) and other conflict management mechanisms reduce the frequency of redirected and directed aggression in the system, and as such can dampen the fight joining behavior of the target individual. When a third party, like a policer, up or down regulates the behavior of high sensitivity individuals we call this \\emph{indirect tuning}.\n\n\\subsection{Tune towards robustness or towards criticality?}\n\\label{adaptive value}\nA natural question raised by the discoveries that DFC can be tuned and that there are behavioral mechanisms in place that in principle allow this tuning is whether to tune towards robustness (increase DFC) or criticality (decrease DFC). This decision depends on three factors: (1) the adaptive utility of criticality--when does it make sense to sit near the critical point?, (2) the true state of the environment, and (3) the perceived state of the environment---the accuracy with which system components can detect and encode the environmental state.\n\nThe consequences of being near or at the critical point is that information can propagate quickly, with small changes to component behavior inducing large-scale changes in both structure and function. Hence criticality allows the system to more easily reconfigure. How does this work? Moving towards criticality changes the distribution of fight sizes such that there are more large fights. Reconfiguration becomes more likely with large fights because large fights cost more\\cite{Dedeo2010} and costly conflict can lead to changes in alliances, coalitions and the power structure, which controls the cost of conflict management\\cite{Flack:2006jh,Brush2013}. \n\nWe predict that reconfiguration is adaptive when the environment, after having been stable for some time, becomes uncertain. Hence when the state of the environment is stable or very slowly changing and represented by a delta function, the optimal choice (we propose) is to increase DFC. When the environment is uncertain--that is, when it is not clear what the distribution of environmental states is, the system should decrease DFC.\n\nFor tuning to be adaptive, the state of the environment must also be correctly perceived by the tuning agent(s). To make this clear, consider the following: a flock of birds in search of food with high and low sensitivity individuals. Some individuals in the flock have poor eyesight and so misjudge the location of food and others have good eyesight. If the high sensitivity birds are also those with poor eyesight, the system may be inappropriately driven away from food sources. If on the other hand the good eyesight birds are also highly sensitive, the system will be appropriately driven towards food. In a similar way, tuning DFC will require accurate perception of the most beneficial change. \\emph{Hence in order for DFC to be tunable and for that tuning to be adaptive in a biological system these two types of heterogeneity must be aligned: high sensitivity score individuals must also be good detectors of environmental state}. Neither of these types of heterogeneity has received much attention in the collective behavior, criticality, or biological phase transition literatures. Consequently little is known about how common it is for these types of heterogeneity to be aligned or whether there are in some systems mechanisms to bring them into alignment.\n\nIn our model system, both types of heterogeneity appear to be aligned. Results of earlier work\\cite{Flack:2005ih,Flack:2006jh}, suggest the individuals with the highest sensitivity scores also are those whose ``health state\" signals the state of the larger social environment. The idea is as follows: the ``health state'' of individuals (healthy or compromised) builds up over a history of affiliative and agonistic social interactions with other group members and hence is a slow variable\\cite{FlaErwEll13}. The health state of the high sensitivity individuals serves as a proxy for system state because these individuals are among the weakest in the system (lowest 10 percent of the power distribution) and hence register stressful periods more visibly than the other group  members \\cite{FlackHammerKrak2012}. \n\nWhen these animals are healthy, the system can be said to be in a stable, low variance period. When these individuals are stressed above some baseline level, social dynamics are becoming uncertain. In either case, when aggression during a fight ``reaches them'', they move the system closer to the critical point \\emph{because of their position in the aggression network as represented by the spin glass and branching process models}. Aggression is less likely to reach them when the policing mechanism is functional and more likely to reach them when the policing mechanism has been disabled \\cite{Flack:2006jh}.\n\nIn {Fig.~\\ref{{ellStarFigure}}}, the magenta and blue lines demonstrate the potential heterogeneity of responses when different individuals are forced.  The magenta lines demonstrate the effect of forcing individuals in an order that maximizes the resulting average fight size at each step, and blue in an order that minimizes it. The individuals are re-sorted each time another is forced as this can affect the order (for instance, forcing one individual in a strongly-correlated clique can decrease the effect of forcing other individuals in that clique).  In {Fig.~\\ref{{ellStarFigure2}}}, we contrast the case in which individuals are sorted by their effect on the original, unperturbed state of the system. The qualitative results are the same as in {Fig.~\\ref{{ellStarFigure}}}.\n\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151204_ellStar_withUnperturbedMaxOrdering_numProcs21_numSamples1e4.pdf}\n\\caption{ \nSame as {Fig.~\\ref{{ellStarFigure}}}, except that the magenta and blue lines here show results when forced individuals are chosen as those with the largest and smallest effect on the mean fight size of remaining individuals when forced in the otherwise unperturbed system.  ({Fig.~\\ref{{ellStarFigure}}} reperforms this optimization after adding each individual.)\n\\label{ellStarFigure2}\n}\n\\end{figure}\n\n\\section{Thermodynamic derivatives and Fisher information in the equilibrium model}\n\\label{FisherInfoSection}\nQuite generally for equilibrium models, it can be shown that the Fisher information is deeply related to important thermodynamic derivatives.\nThe Fisher information is defined as \\cite{CovTho91}\n\n", "itemtype": "equation", "pos": 56514, "prevtext": "\nwhich when differentiated produces the self-consistency equation\n(\\ref{meanFieldEqn}).  Taking a second derivative,\n\n", "index": 33, "text": "\\begin{equation}\n\\frac{\\partial^2 A}{\\partial m_i \\partial m_j} =\n    \\delta_{ij} \\frac{1}{f_i(1-f_i)}\n    - (1 - \\delta_{ij}) 2 J_{ij} \\equiv \\Lambda_{ij},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial^{2}A}{\\partial m_{i}\\partial m_{j}}=\\delta_{ij}\\frac{1}{f_{i}(1%&#10;-f_{i})}-(1-\\delta_{ij})2J_{ij}\\equiv\\Lambda_{ij},\" display=\"block\"><mrow><mrow><mfrac><mrow><msup><mo>\u2202</mo><mn>2</mn></msup><mo>\u2061</mo><mi>A</mi></mrow><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>\u2062</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>m</mi><mi>j</mi></msub></mrow></mrow></mfrac><mo>=</mo><mrow><mrow><msub><mi>\u03b4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mfrac><mn>1</mn><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>f</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mn>2</mn><mo>\u2062</mo><msub><mi>J</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow><mo>\u2261</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhere $\\mu$ parameterizes a distribution $p(x)$ describing the  behavior of a system, and $x$ represents any number of relevant measurable system state variables. Generalized to multiple parameters, the Fisher information matrix is a fundamental object in information geometry, and forms a Riemannian metric that becomes singular precisely at phase transitions \\cite{Cro07,Prokopenko2011}. ${\\mathcal{I}}(\\mu)$ is typically used to measure the amount of information about $\\mu$ that can be inferred from draws from $p(x)$. Conversely, if we view individuals as controlling local parameters $\\mu$, ${\\mathcal{I}}(\\mu)$ measures the degree of control individuals have on group behavior. Then phase transitions, having diverging ${\\mathcal{I}}$ as $N \\rightarrow \\infty$, correspond to individuals having arbitrarily large effects. But even at finite $N$, ${\\mathcal{I}}$ measures the amplification of individual information to the global scale. In this sense, ${\\mathcal{I}}$  becomes a straightforward, useful measure of the degree to which a  system's behavior is ``collective.''\n\nAnother intuitive meaning comes in terms of the Kullback-Leibler divergence: ${\\mathcal{I}}(\\mu)$ represents how quickly the KL-divergence increases as $\\mu$ is changed, such that\n\n", "itemtype": "equation", "pos": 66310, "prevtext": "\nwhich defines stability to this order when all eigenvalues of $\\Lambda_{ij}$ are positive \\cite{Geo04}. Because $f_i(1-f_i)>0$, this condition is the same as all eigenvalues of $f_i(1-f_i)\\Lambda_{ij} = \\delta_{ij} - M_{ij}$ being positive (where $M$ is defined in {Eq.~(\\ref{{Meqn}})}), which is in turn equivalent to the above condition that all eigenvalues of $M_{ij}$ are less than 1.\n\nTo create a homogeneous finite system poised at the transition defined by the eigenvalue $\\lambda$ (shown as the red dotted curve in {Fig.~\\ref{{susceptibilityFigure}}}), we define a homogeneous positive $h$ and negative $J$ that make each individual's frequency $f = 1/2$ and $\\lambda = 1$.  \n\n\n\n\n\\section{Notes on quantifying DFC}\n\\label{sensitiveindividuals}\nAs described in the main text, by simulating forcing some number of individuals to be involved in every fight we can quantify distance from the critical point by measuring changes to sensitivity and collective instability.  We measure this distance in units natural to the system by forcing a subset of individuals to join fights and measuring the sensitivity of the remaining individuals.\n\nThe number of individuals (or, in principle, subgroups) that must be forced to reach peak sensitivity provides an operational definition of DFC. We find three to five individuals is sufficient and we find individual variation in sensitivity scores. In both the equilibrium and branching process models individuals with higher sensitivity scores are those who (by definition) exert greater influence on how far the system sits from the critical point.\n\nWe find that individuals whose simulated forcing causes the largest increase in average fight sizes are also those who cause the largest increase in sensitivity, as might be expected in this system with largely excitatory interactions.  In each model, this sensitivity score depends on the individual's place within the overall network structure, measuring both its direct influence on inducing others to fight and indirect influence through those it induces to fight.\n\n\n\n\\subsection{Tuning mechanisms}\n\\label{tuning}\nThe sensitivity scores generated by each model are capturing different underlying tuning mechanisms. In the case of the branching process model, the model captures the spread of fight-joining through direct interactions: one individual through its behavior triggers the involvement of a second individual. Hence this model only allows that the target individuals, through their own fight joining decisions, can up or down regulate their fight involvement. When a high sensitivity individual up or down regulates its own behavior moving the system respectively closer to or further from the critical point, we call this \\emph{direct tuning}.\n\nThe equilibrium model, on the other hand, is agnostic to cause, recording any pairwise correlation in fight joining regardless of which individual triggered the joining event. As such it captures the full space of behavioral mechanisms leading to fight-joining---individuals can become involved in fights by up regulating their own fight involvement and \\emph{also} through changes to third-party behavior. For example, policing (by third-parties to the fight) and other conflict management mechanisms reduce the frequency of redirected and directed aggression in the system, and as such can dampen the fight joining behavior of the target individual. When a third party, like a policer, up or down regulates the behavior of high sensitivity individuals we call this \\emph{indirect tuning}.\n\n\\subsection{Tune towards robustness or towards criticality?}\n\\label{adaptive value}\nA natural question raised by the discoveries that DFC can be tuned and that there are behavioral mechanisms in place that in principle allow this tuning is whether to tune towards robustness (increase DFC) or criticality (decrease DFC). This decision depends on three factors: (1) the adaptive utility of criticality--when does it make sense to sit near the critical point?, (2) the true state of the environment, and (3) the perceived state of the environment---the accuracy with which system components can detect and encode the environmental state.\n\nThe consequences of being near or at the critical point is that information can propagate quickly, with small changes to component behavior inducing large-scale changes in both structure and function. Hence criticality allows the system to more easily reconfigure. How does this work? Moving towards criticality changes the distribution of fight sizes such that there are more large fights. Reconfiguration becomes more likely with large fights because large fights cost more\\cite{Dedeo2010} and costly conflict can lead to changes in alliances, coalitions and the power structure, which controls the cost of conflict management\\cite{Flack:2006jh,Brush2013}. \n\nWe predict that reconfiguration is adaptive when the environment, after having been stable for some time, becomes uncertain. Hence when the state of the environment is stable or very slowly changing and represented by a delta function, the optimal choice (we propose) is to increase DFC. When the environment is uncertain--that is, when it is not clear what the distribution of environmental states is, the system should decrease DFC.\n\nFor tuning to be adaptive, the state of the environment must also be correctly perceived by the tuning agent(s). To make this clear, consider the following: a flock of birds in search of food with high and low sensitivity individuals. Some individuals in the flock have poor eyesight and so misjudge the location of food and others have good eyesight. If the high sensitivity birds are also those with poor eyesight, the system may be inappropriately driven away from food sources. If on the other hand the good eyesight birds are also highly sensitive, the system will be appropriately driven towards food. In a similar way, tuning DFC will require accurate perception of the most beneficial change. \\emph{Hence in order for DFC to be tunable and for that tuning to be adaptive in a biological system these two types of heterogeneity must be aligned: high sensitivity score individuals must also be good detectors of environmental state}. Neither of these types of heterogeneity has received much attention in the collective behavior, criticality, or biological phase transition literatures. Consequently little is known about how common it is for these types of heterogeneity to be aligned or whether there are in some systems mechanisms to bring them into alignment.\n\nIn our model system, both types of heterogeneity appear to be aligned. Results of earlier work\\cite{Flack:2005ih,Flack:2006jh}, suggest the individuals with the highest sensitivity scores also are those whose ``health state\" signals the state of the larger social environment. The idea is as follows: the ``health state'' of individuals (healthy or compromised) builds up over a history of affiliative and agonistic social interactions with other group members and hence is a slow variable\\cite{FlaErwEll13}. The health state of the high sensitivity individuals serves as a proxy for system state because these individuals are among the weakest in the system (lowest 10 percent of the power distribution) and hence register stressful periods more visibly than the other group  members \\cite{FlackHammerKrak2012}. \n\nWhen these animals are healthy, the system can be said to be in a stable, low variance period. When these individuals are stressed above some baseline level, social dynamics are becoming uncertain. In either case, when aggression during a fight ``reaches them'', they move the system closer to the critical point \\emph{because of their position in the aggression network as represented by the spin glass and branching process models}. Aggression is less likely to reach them when the policing mechanism is functional and more likely to reach them when the policing mechanism has been disabled \\cite{Flack:2006jh}.\n\nIn {Fig.~\\ref{{ellStarFigure}}}, the magenta and blue lines demonstrate the potential heterogeneity of responses when different individuals are forced.  The magenta lines demonstrate the effect of forcing individuals in an order that maximizes the resulting average fight size at each step, and blue in an order that minimizes it. The individuals are re-sorted each time another is forced as this can affect the order (for instance, forcing one individual in a strongly-correlated clique can decrease the effect of forcing other individuals in that clique).  In {Fig.~\\ref{{ellStarFigure2}}}, we contrast the case in which individuals are sorted by their effect on the original, unperturbed state of the system. The qualitative results are the same as in {Fig.~\\ref{{ellStarFigure}}}.\n\n\n\n\\begin{figure}\n\\centering\n\\includegraphics[scale=0.85]{figures/151204_ellStar_withUnperturbedMaxOrdering_numProcs21_numSamples1e4.pdf}\n\\caption{ \nSame as {Fig.~\\ref{{ellStarFigure}}}, except that the magenta and blue lines here show results when forced individuals are chosen as those with the largest and smallest effect on the mean fight size of remaining individuals when forced in the otherwise unperturbed system.  ({Fig.~\\ref{{ellStarFigure}}} reperforms this optimization after adding each individual.)\n\\label{ellStarFigure2}\n}\n\\end{figure}\n\n\\section{Thermodynamic derivatives and Fisher information in the equilibrium model}\n\\label{FisherInfoSection}\nQuite generally for equilibrium models, it can be shown that the Fisher information is deeply related to important thermodynamic derivatives.\nThe Fisher information is defined as \\cite{CovTho91}\n\n", "index": 35, "text": "\\begin{equation}\n\\label{FisherEqn}\n{\\mathcal{I}}(\\mu) = \\int\n\n\n\\left(\\frac{\\partial \\log p(x)}{\\partial \\mu}\\right)^{\\raisebox{-2pt}{$\\scriptstyle 2$}} p(x) \\, \\mathrm{d}x,\n\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{I}}(\\mu)=\\int\\par&#10;\\par&#10;\\left(\\frac{\\partial\\log p(x)}{\\partial\\mu}%&#10;\\right)^{\\raisebox{-2.0pt}{$\\scriptstyle 2$}}p(x)\\,\\mathrm{d}x,\\par&#10;\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msup><mrow><mo>(</mo><mfrac><mrow><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>log</mi></mrow><mo>\u2061</mo><mi>p</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>)</mo></mrow><mpadded depth=\"+2.0pt\" height=\"-2.0pt\" voffset=\"-2.0pt\"><mn mathsize=\"70%\">2</mn></mpadded></msup><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>d</mo><mi>x</mi></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nThus the Fisher information measures how quickly the modified distribution becomes distinguishable from the original as $\\mu$ is varied, and if logs are taken with base 2, ${\\mathcal{I}}(\\mu)$ has units of bits per [unit of $\\mu$]$^2$.\n\nIn the case of an equilibrium system described by a Boltzmann distribution, the Fisher information with respect to a local field $\\mu$ is particularly simple, equal to the derivative of the mean of its conjugate variable $x_\\mu$, the generalized susceptibility ${\\ensuremath{\\mathcal{{I}}}}(\\mu) = \\frac{\\partial}{\\partial \\mu} {\\langle { x_\\mu } \\rangle}$.  This example provides a clear link between thermodynamics and information theory.  (Yet the Fisher information  measure is not limited to equilibrium models, generalizing to dynamic out-of-equilibrium systems by simply interpreting $p(x)$ in {Eq.~(\\ref{{FisherEqn}})}  as a distribution over relevant output measurements given some known initial conditions.)\n\nThis connection between Fisher information and thermodynamic derivatives is well-established \\cite{Prokopenko2011}.  Assume we have a system whose distribution over possible states $x$ takes the form of a Boltzmann distribution:\n\n", "itemtype": "equation", "pos": 67760, "prevtext": "\nwhere $\\mu$ parameterizes a distribution $p(x)$ describing the  behavior of a system, and $x$ represents any number of relevant measurable system state variables. Generalized to multiple parameters, the Fisher information matrix is a fundamental object in information geometry, and forms a Riemannian metric that becomes singular precisely at phase transitions \\cite{Cro07,Prokopenko2011}. ${\\mathcal{I}}(\\mu)$ is typically used to measure the amount of information about $\\mu$ that can be inferred from draws from $p(x)$. Conversely, if we view individuals as controlling local parameters $\\mu$, ${\\mathcal{I}}(\\mu)$ measures the degree of control individuals have on group behavior. Then phase transitions, having diverging ${\\mathcal{I}}$ as $N \\rightarrow \\infty$, correspond to individuals having arbitrarily large effects. But even at finite $N$, ${\\mathcal{I}}$ measures the amplification of individual information to the global scale. In this sense, ${\\mathcal{I}}$  becomes a straightforward, useful measure of the degree to which a  system's behavior is ``collective.''\n\nAnother intuitive meaning comes in terms of the Kullback-Leibler divergence: ${\\mathcal{I}}(\\mu)$ represents how quickly the KL-divergence increases as $\\mu$ is changed, such that\n\n", "index": 37, "text": "\\begin{equation}\nD_\\mathrm{KL} \\left( p(x|\\mu) || p(x|\\mu + \\Delta \\mu) \\right)\n= {\\mathcal{I}}(\\mu) (\\Delta \\mu)^2 / 2 + O(\\Delta \\mu^4).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"D_{\\mathrm{KL}}\\left(p(x|\\mu)||p(x|\\mu+\\Delta\\mu)\\right)={\\mathcal{I}}(\\mu)(%&#10;\\Delta\\mu)^{2}/2+O(\\Delta\\mu^{4}).\" display=\"block\"><mrow><msub><mi>D</mi><mi>KL</mi></msub><mrow><mo>(</mo><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mo stretchy=\"false\">|</mo><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>+</mo><mi mathvariant=\"normal\">\u0394</mi><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow><mo>)</mo></mrow><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0394</mi><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>/</mo><mn>2</mn><mo>+</mo><mi>O</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0394</mi><msup><mi>\u03bc</mi><mn>4</mn></msup><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nTaking a derivative of $\\log p(x)$,\n\\begin{eqnarray}\n\\frac{ \\partial \\log p(x) }{ \\partial \\mu } &=&\n- \\frac{ \\partial L(x) }{ \\partial \\mu }\n+ Z^{-1} \\sum_x \\frac{ \\partial L(x) }{ \\partial \\mu } e^{- L(x)} \\\\\n&=& \\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle\n- \\frac{ \\partial L(x) }{ \\partial \\mu },\n\\end{eqnarray}\nwhich, when inserted in {Eq.~(\\ref{{FisherEqn}})}, gives\n\n", "itemtype": "equation", "pos": 69099, "prevtext": "\nThus the Fisher information measures how quickly the modified distribution becomes distinguishable from the original as $\\mu$ is varied, and if logs are taken with base 2, ${\\mathcal{I}}(\\mu)$ has units of bits per [unit of $\\mu$]$^2$.\n\nIn the case of an equilibrium system described by a Boltzmann distribution, the Fisher information with respect to a local field $\\mu$ is particularly simple, equal to the derivative of the mean of its conjugate variable $x_\\mu$, the generalized susceptibility ${\\ensuremath{\\mathcal{{I}}}}(\\mu) = \\frac{\\partial}{\\partial \\mu} {\\langle { x_\\mu } \\rangle}$.  This example provides a clear link between thermodynamics and information theory.  (Yet the Fisher information  measure is not limited to equilibrium models, generalizing to dynamic out-of-equilibrium systems by simply interpreting $p(x)$ in {Eq.~(\\ref{{FisherEqn}})}  as a distribution over relevant output measurements given some known initial conditions.)\n\nThis connection between Fisher information and thermodynamic derivatives is well-established \\cite{Prokopenko2011}.  Assume we have a system whose distribution over possible states $x$ takes the form of a Boltzmann distribution:\n\n", "index": 39, "text": "\\begin{equation}\np(x) = Z^{-1} e^{- L(x)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"p(x)=Z^{-1}e^{-L(x)}.\" display=\"block\"><mrow><mrow><mrow><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>Z</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nThis shows that Fisher information is equal to the variance of the derivative of $L$. We can further relate this to thermodynamic derivatives by noting that $L$ is typically linearly dependent on certain ``fields'' (\\emph{e.g.} pressure or magnetic field), with derivatives that correspond to measurable macroscopic properties (\\emph{e.g.} volume or magnetization).  This linearity allows us to write the Fisher information even more simply:\nwhen\n$\\langle \\partial^2 L / \\partial \\mu^2 \\rangle = 0$,\n\n", "itemtype": "equation", "pos": 69551, "prevtext": "\nTaking a derivative of $\\log p(x)$,\n\\begin{eqnarray}\n\\frac{ \\partial \\log p(x) }{ \\partial \\mu } &=&\n- \\frac{ \\partial L(x) }{ \\partial \\mu }\n+ Z^{-1} \\sum_x \\frac{ \\partial L(x) }{ \\partial \\mu } e^{- L(x)} \\\\\n&=& \\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle\n- \\frac{ \\partial L(x) }{ \\partial \\mu },\n\\end{eqnarray}\nwhich, when inserted in {Eq.~(\\ref{{FisherEqn}})}, gives\n\n", "index": 41, "text": "\\begin{equation}\n\\label{Fij2}\n{\\mathcal{I}}(\\mu) = \\left \\langle \\left( \\frac{ \\partial L }{ \\partial \\mu } \\right)^2 \\right \\rangle\n- \\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle^2.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{I}}(\\mu)=\\left\\langle\\left(\\frac{\\partial L}{\\partial\\mu}\\right)^{2}%&#10;\\right\\rangle-\\left\\langle\\frac{\\partial L}{\\partial\\mu}\\right\\rangle^{2}.\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>\u27e8</mo><msup><mrow><mo>(</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>)</mo></mrow><mn>2</mn></msup><mo>\u27e9</mo></mrow><mo>-</mo><msup><mrow><mo>\u27e8</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u27e9</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n(To see this, explicitly take the derivative of the expectation value:\n\n", "itemtype": "equation", "pos": 70269, "prevtext": "\nThis shows that Fisher information is equal to the variance of the derivative of $L$. We can further relate this to thermodynamic derivatives by noting that $L$ is typically linearly dependent on certain ``fields'' (\\emph{e.g.} pressure or magnetic field), with derivatives that correspond to measurable macroscopic properties (\\emph{e.g.} volume or magnetization).  This linearity allows us to write the Fisher information even more simply:\nwhen\n$\\langle \\partial^2 L / \\partial \\mu^2 \\rangle = 0$,\n\n", "index": 43, "text": "\\begin{equation}\n\\label{FijSimple}\n{\\mathcal{I}}(\\mu) = - \\frac{ \\partial }{ \\partial \\mu }\n\\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{I}}(\\mu)=-\\frac{\\partial}{\\partial\\mu}\\left\\langle\\frac{\\partial L}{%&#10;\\partial\\mu}\\right\\rangle.\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u27e8</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u27e9</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\nwhich is equal to $-{\\mathcal{I}}(\\mu)$ from Eq.~(\\ref{Fij2}) when the last term is zero.)\n\nConnecting this result to our equilibrium model, the susceptibility and specific heat are related to the Fisher information with respect to external field ${h_{\\mathrm{ext}}}$ and temperature $T$:\n\n", "itemtype": "equation", "pos": 70513, "prevtext": "\n(To see this, explicitly take the derivative of the expectation value:\n\n", "index": 45, "text": "\\begin{equation}\n\\frac{ \\partial }{ \\partial \\mu }\n\\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle\n= \\frac{ \\partial }{ \\partial \\mu } \\left[ Z^{-1} \\sum_x \\exp(-L(x))\n\\frac{ \\partial L(x) }{ \\partial \\mu} \\right]\n\n\n\n\n\n= - \\left \\langle \\left( \\frac{ \\partial L }{ \\partial \\mu } \\right)^2 \\right \\rangle\n+ \\left \\langle \\frac{ \\partial L }{ \\partial \\mu } \\right \\rangle^2\n+ \\left \\langle\n\\frac{ \\partial^2 L }{ \\partial \\mu^2 } \\right \\rangle,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial}{\\partial\\mu}\\left\\langle\\frac{\\partial L}{\\partial\\mu}\\right%&#10;\\rangle=\\frac{\\partial}{\\partial\\mu}\\left[Z^{-1}\\sum_{x}\\exp(-L(x))\\frac{%&#10;\\partial L(x)}{\\partial\\mu}\\right]\\par&#10;\\par&#10;\\par&#10;\\par&#10;\\par&#10;=-\\left\\langle\\left%&#10;(\\frac{\\partial L}{\\partial\\mu}\\right)^{2}\\right\\rangle+\\left\\langle\\frac{%&#10;\\partial L}{\\partial\\mu}\\right\\rangle^{2}+\\left\\langle\\frac{\\partial^{2}L}{%&#10;\\partial\\mu^{2}}\\right\\rangle,\" display=\"block\"><mrow><mrow><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>\u27e8</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u27e9</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mo>\u2202</mo><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u2062</mo><mrow><mo>[</mo><mrow><msup><mi>Z</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>x</mi></munder><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2062</mo><mfrac><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>-</mo><mrow><mo>\u27e8</mo><msup><mrow><mo>(</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>)</mo></mrow><mn>2</mn></msup><mo>\u27e9</mo></mrow></mrow><mo>+</mo><msup><mrow><mo>\u27e8</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>\u03bc</mi></mrow></mfrac><mo>\u27e9</mo></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo>\u27e8</mo><mfrac><mrow><msup><mo>\u2202</mo><mn>2</mn></msup><mo>\u2061</mo><mi>L</mi></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msup><mi>\u03bc</mi><mn>2</mn></msup></mrow></mfrac><mo>\u27e9</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 71280, "prevtext": "\nwhich is equal to $-{\\mathcal{I}}(\\mu)$ from Eq.~(\\ref{Fij2}) when the last term is zero.)\n\nConnecting this result to our equilibrium model, the susceptibility and specific heat are related to the Fisher information with respect to external field ${h_{\\mathrm{ext}}}$ and temperature $T$:\n\n", "index": 47, "text": "\\begin{equation}\n{\\mathcal{I}}({h_{\\mathrm{ext}}}) = \\frac{\\partial {\\langle {s} \\rangle}}{\\partial {h_{\\mathrm{ext}}}} = \\chi.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{I}}({h_{\\mathrm{ext}}})=\\frac{\\partial{\\langle{s}\\rangle}}{\\partial{%&#10;h_{\\mathrm{ext}}}}=\\chi.\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>h</mi><mi>ext</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>s</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>h</mi><mi>ext</mi></msub></mrow></mfrac><mo>=</mo><mi>\u03c7</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03449.tex", "nexttext": "\n\nThe amount of change in the entire distribution over fights is expressed in terms of a single ``order parameter,'' the average fight size in the case of varying ${h_{\\mathrm{ext}}}$ (and the average energy in the case of varying $1/T$). This implies that if one is trying to infer small changes in the external field ${h_{\\mathrm{ext}}}$ by watching the composition of fights, one loses nothing by simply recording the fight sizes.\n\n\n\n\n\n\n\\putbib\n\\end{bibunit}\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 71423, "prevtext": "\n\n", "index": 49, "text": "\\begin{equation}\n{\\mathcal{I}}(1/T) = -\\frac{1}{T^2} \\frac{\\partial {\\langle {E} \\rangle}}{\\partial T} = C_s.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{I}}(1/T)=-\\frac{1}{T^{2}}\\frac{\\partial{\\langle{E}\\rangle}}{\\partial&#10;T%&#10;}=C_{s}.\" display=\"block\"><mrow><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>/</mo><mi>T</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mfrac><mn>1</mn><msup><mi>T</mi><mn>2</mn></msup></mfrac><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>E</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>T</mi></mrow></mfrac></mrow></mrow><mo>=</mo><msub><mi>C</mi><mi>s</mi></msub></mrow><mo>.</mo></mrow></math>", "type": "latex"}]