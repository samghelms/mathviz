[{"file": "1601.07857.tex", "nexttext": "\nwhere $p_i(z)$ is the posterior for the $i$th galaxy, assumed to be\nnormalized.  The requirement that 1\\% of galaxies have $z_s$ within\ntheir 1\\% CI, etc, then translates into a requirement that $c$ be\nuniformly distributed from 0 to 1 (we drop the $i$ subscript when\nreferring to collective properties of the $c_i$).  We test for this by\ncomputing the empirical cumulative distribution function $\\hat{F}(c)$,\nwhich should equal $c$.  Graphically, plotting $\\hat{F}(c)$ resembles\na q-q plot in which $\\hat{F}$ is expected to match $c$, i.e., fall on\na line through the origin with a slope of one. Overconfidence\ncorresponds to $\\hat{F}(c)$ falling below this line (too few galaxies\nhave $z_s$ within a given CI).  The statistical significance of such a\ndeparture can be measured with a Kolmogorov-Smirnov (KS) test.  Of\ncourse, it is also possible for this test to reveal {\\it\n  under}confidence.  In either case, the method detects inaccurate\nerror budgets.\n\n\\section{Applying the test}\n\nWe tested the $p(z)$ estimated by two template-based photometric\nredshift codes, BPZ \\citep{BPZ} and EAZY \\citep{Brammer08}.  We are\nprimarily interested in testing template methods because empirical\nmethods should yield calibrated $p(z)$ by design.  Because template\nmethods purport to yield redshifts beyond the magnitude limit at which\n$p(z)$ can be directly constructed from the photometric and\nspectroscopic data, they are the methods for which an independent test\nof $p(z)$ is most desirable.  The test results will be data-dependent\nand must be interpreted accordingly.  For example, any overconfidence\nin the underlying photometry will contribute to overconfidence in\n$p(z)$, and this contribution will be magnitude- and\nredshift-dependent.  We therefore run each code on the same data, the\nHubble Deep Field North (HDFN) seven-band photometry with 127\nspectroscopic redshifts \\citep{FS99} that ships with EAZY and shipped\nwith earlier versions of BPZ.  We run each code with the default\ntemplates and priors that are shipped with the code.\n\n\\subsection{BPZ}\n\nWe used BPZ version 1.99.3 with default templates and priors and the\nINTERP value set to 2 on the command line as recommended in the\ndocumentation. The resulting $\\hat{F}(c)$ plot\n(Figure~\\ref{fig-hdfn-bpz}, middle curve) shows substantial\noverconfidence; the largest departure from the ideal distribution is\nwhere only 46\\% of galaxies have true redshift within their 89\\% CI.\nThis is highly significant ($p<10^{-15}$) according to the KS test.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{bpz-hdfn.png}}}\n\n\\caption{The $\\hat{F}(c)$ plot for HDFN data using the BPZ code shows\n  substantial overconfidence overall (solid curve, $p< 10^{-15}$),\n  with some magnitude dependence (dashed curves).\n\\label{fig-hdfn-bpz}}\n\\end{figure}\n\nNext, we tested the magnitude dependence of this overconfidence by\nbreaking the sample into roughly equal bright ($I<22.5$) and faint\n($I>22.5$) subsamples. The faint subsample falls on the upper curve in\nFigure~\\ref{fig-hdfn-bpz}, and the bright subsample falls on the lower\ncurve; in other words, there is more overconfidence in the brighter\ngalaxies.  A KS test indicates that the difference between the bright\nand faint distributions is not significant ($p = 0.44$). However,\nmagnitude dependence will be a recurring issue so a few points should\nbe clarified now. First, magnitude-dependent overconfidence does not\nautomatically imply a problem in the photometric redshift algorithm,\nbecause uncertainties in the underlying photometry are already\nmagnitude-dependent. Second, our method probes {\\it how well the\n  uncertainty has been assessed} rather than the uncertainties\nthemselves, so one should not assume that faint galaxies will be more\nproblematic.  Indeed, Figure~\\ref{fig-hdfn-bpz} shows that faint\ngalaxies perform better.  Photometry provides a useful analogy: faint\ngalaxies have larger photometric uncertainties than bright galaxies,\nbut the faint-galaxy uncertainty budget is probably more accurate\nbecause it is dominated by well-modeled photon noise rather than\npoorly modeled uncertainties in background subtraction, calibration,\nand color terms.  In fact, because photometry uncertainties propagate\ninto photometric redshift uncertainties, it is tempting to offer this\nas an explanation for the overconfidence pattern seen in\nFigure~\\ref{fig-hdfn-bpz}.  However, the HDFN is a carefully\ncalibrated and well-tested catalog, and we develop a more compelling\nexplanation below.\n\nThird, magnitude is correlated with redshift so disentangling the two\nvariables may be difficult. If the magnitude trend here is really a\nredshift trend in disguise, splitting by redshift should reveal a\ngreater divergence between subsamples, and low-redshift (bright)\ngalaxies should have the most overconfidence.  In fact, splitting by\nredshift shows the opposite in both respects, leading us to believe\nthat magnitude is indeed the explanatory variable.  An important\nconceptual point here is that use of a Bayesian prior on redshift\nprevents us from expecting all subsamples split by redshift to follow\nthe $\\hat{F}(c)=c$ relation. In a Bayesian framework, priors can and\nshould degrade the performance of some subsets in order to improve\noverall performance. As an everyday example, consider the batting\naverages of baseball players one month into the season. With each\nplayer having few at-bats, their averages vary widely, and applying a\nprior on batting average greatly improves our estimate of their\n``true'' batting averages.  But if, at the end of the season, we find\nthe players with the best ``true'' batting averages and look back at\nour Bayesian estimate one month into the season, we will find that the\nprior biased their averages low; this was unavoidable if we were to\nimprove the one-month estimates overall.  Similarly, high-redshift\nsubsamples must not be tested in isolation, and in this paper we do\nnot plot $\\hat{F}(c)$ for subsamples split by redshift, even if we do\na redshift split to check whether a magnitude trend could be a\nredshift trend in disguise.\n\n\n\nWe also tested BPZ using the test data it ships with, a catalog of 57\ngalaxies with spectroscopic redshift and seven-band photometry from\nthe Hubble Ultra Deep Field (HUDF) catalog produced by \\citet{Coe06}.\nWe found trends similar to those illustrated here for the HDFN data,\nsuggesting that overconfidence is a general feature of the $p(z)$\noutput by BPZ.  A plausible mechanism for this is that BPZ, like most\ntemplate codes, propagates uncertainty from the photometry only, and\nnot from the templates. This would also explain why overconfidence is\ngreater for bright galaxies; their smaller photometric uncertainties\nimply that template uncertainties are a larger share of the\nuncertainty budget.  Further supporting this picture, we found that\nlimiting the template set by turning off interpolation between\ntemplates (setting the INTERP parameter to 0) exacerbated the\noverconfidence.  Increasing the INTERP parameter beyond 2 had little\neffect, presumably because SEDs vary in ways that cannot be captured\nwith interpolation between the default templates.\n\nThe issue of template uncertainty was recognized by\n\\citet{Fernandez02}, who explored an empirical fix of convolving\n$p_i(z)$ with a Gaussian smoothing kernel.  Although they cautioned\nthat more sophisticated noise modeling would be required as data sets\nexpanded in terms of both redshift and raw numbers, this approach\nperformed well when they applied it to HDFN data.  They assumed that\nthe kernel width should scale as $(1+z)$ and then optimized the\nprefactor by maximizing $p_i(z_s)$ for bright galaxies.  This yielded\na kernel with $\\sigma=0.065(1+z)$; this kernel is ``optimal'' in the\nsense that it mimics the effect of galaxy SEDs varying from the\ntemplate set used in their analysis, at the wavelengths used in their\nanalysis, better than other kernels in its family.  Smoothing with\nthis kernel broadens $p_i(z)$ for each galaxy, but more so for bright\ngalaxies because faint galaxies already have broad $p_i(z)$ due to\ntheir photometric uncertainties.  \\citet{Fernandez02} tested the\nperformance of this procedure with a version of the $\\hat{F}(c)$ test,\nverifying (in our notation) $\\hat{F}(0.683)$, $\\hat{F}(0.954)$, and\n$\\hat{F}(0.997)$.  \n\nBPZ does have two parameters that nearly serve this function.  The\nCONVOLVE\\_P parameter, if set, smooths $p_i(z)$ with a Gaussian of\nfixed width $\\sigma=0.03$.  According to comments in the code the\npurpose of this feature is to combine multiple close peaks; for our\npurposes we can consider it as injecting a bit of template noise, but\nFigure~\\ref{fig-hdfn-bpz} already includes this bit of smoothing\nbecause CONVOLVE\\_P is turned on by default. Therefore $\\sigma=0.03$\nis too little smoothing to prevent overconfidence, at least for the\ndata sets presented here.  The other potentially relevant BPZ\nparameter is MIN\\_RMS, which according to the comments represents\n``intrinsic photo-z rms'' (presumably due to the true SEDs of galaxies\nvarying from the templates). In version 1.99.3 MIN\\_RMS is set to 0.05\n(0.067 if the older ``CWWSB'' template set is used) but it does {\\it\n  not} affect the $p(z)$ written out to disk.  It is used only to\ndetermine a few quantities derived from $p(z)$, such as upper and\nlower redshift limits and the fraction of the area under $p_i(z)$ that\nis near the highest peak.\n\nWe therefore use a post-processing step to smooth the $p_i(z)$\nproduced by BPZ in order to test the efficacy of the approach\nsuggested by \\citet{Fernandez02}.  In the absence of strong evidence\nthat a redshift-dependent kernel is necessary, we tested\nredshift-independent kernels of various widths.  We found that a\nGaussian kernel with $\\sigma=0.11$ was optimal in the sense of\nbalancing overconfidence with underconfidence, as seen in\nFigure~\\ref{fig-bpz2}.  The resulting $\\hat{F}(c)$ is marginally\nconsistent with uniformity for the overall sample and the faint\nsubsample ($p=0.07$ and 0.04 respectively), and entirely consistent\nfor the bright subsample ($p=0.89$).  Given the median redshift (0.75)\nof the HUDF spectroscopic sample, this agrees well with the\n$\\sigma=0.065(1+z)$ derived by \\citet{Fernandez02} for the HDFN\nsample.  We performed the same tests on the $p_i(z)$ output by BPZ for\nthe HUDF sample and found the same result.  Thus, smoothing $p_i(z)$\nwith a standard kernel may be an adequate substitute for modeling\ntemplate noise in many situations.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{bpz-hdfn-smooth.png}}}\n\\caption{The $\\hat{F}(c)$ plot for HDFN data using the BPZ code plus\n  post-hoc $p_i(z)$ smoothing with a Gaussian kernel with\n  $\\sigma=0.11$.  All the resulting distributions are at least\n  marginally consistent with uniformity, suggesting that \n smoothing $p_i(z)$ is a reasonable substitute for modeling template noise in BPZ.  \n \\label{fig-bpz2}}\n\\end{figure}\n\n\\subsection{EAZY}\\label{subsec-EAZY}\n\n\n\n\n\nThe EAZY code models template uncertainties as a function of\nrest-frame wavelength.  This approach, called the template error\nfunction, has several virtues.  First, there is strong physical\nmotivation for assuming that template variance is a function of\nrest-frame wavelength \\citep{HH10}.  Second, any effect that depends\non rest-frame wavelength propagates into $p_i(z)$ in a filter- and\nredshift-dependent way that cannot be fully mimicked by simply\nbroadening $p_i(z)$.  For example, consider a bimodal $p_i(z)$ with\ntwo similar well-separated peaks.  The smoothing approach will blindly\nbroaden both peaks, but the template error function may effectively\nbroaden one peak much more than the other, according to the relevant\nrest-frame template uncertainties.  \\citet{Brammer08} calibrate their\ntemplate error function using a bright galaxy subsample with known\nspectroscopic redshifts, and provide the tools to recalibrate the\nerror function if desired.\n\nEAZY ships with the HDFN data, and Figure~\\ref{fig-eazy} shows the\nresulting $\\hat{F}(c)$.  For the entire sample (solid curve), there is\nonly a modest amount of overconfidence, with a maximum deviation of\n0.167 from the identity relation (78\\% of galaxies are within their\n94\\% CI).  According to the KS test, this meets standard criteria for\nstatistical significance, but it is not overwhelming ($p=0.0029$).\nSplitting into roughly equal subsamples by magnitude (dashed lines)\nreveals a substantial magnitude dependence, with overconfidence on the\nfaint subsample and a bit of underconfidence on the bright subsample.\nTo check whether this magnitude dependence could really be a redshift\ndependence, we split by redshift and find an even larger difference,\nin the sense of even more underconfidence for low-redshift galaxies\nthan for bright galaxies.  This implies that redshift could be the\ndriving variable here; and as explained above, redshift variations in\nthese tests could simply reflect the workings of the Bayesian prior on\nredshift.  Thus, the magnitude dependence may be a feature rather than\na flaw.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{eazy-hdfn.png}}}\n\\caption{When applied to the HDFN (solid curve), EAZY produces $p(z)$\n  that are only slightly overconfident (but this is statistically\n  significant: $p=0.0029$). The magnitude trend is inconsistent with\n  unmodeled template uncertainty, and could be a redshift\n  effect. \\label{fig-eazy}}\n\\end{figure}\n\nThe relatively good performance of the overall sample and the lack of\noverconfidence in the bright subsample indicate that the template\nerror function is generally serving its purpose in EAZY.  Some\noverconfidence remains in the overall sample, but the good performance\nof the bright subsample suggests that this is not due to\noverconfidence in the templates. The remaining overconfidence may stem\nfrom other aspects of the algorithm or from the photometry; for\nexample, unmodeled uncertainties in deblending or local background\nvariations may affect faint galaxies more than bright galaxies and\nthereby fit this pattern. Investigating this hypothesis is beyond the\nscope of this paper, but we offer some recommendations in\nSection~\\ref{sec-discussion}.\n\n\\section{Application to Deep Lens Survey}\\label{sec-DLS}\n\nThe Deep Lens Survey \\citep[DLS; ][]{DLS02,Wittman06} is a\nground-based 20 deg$^2$ {\\it BVRz} survey that provides a counterpoint\nto the HDFN and HUDF samples in terms of photometric uncertainties\n(larger from the ground) and filter set (DLS uses a minimal filter set\nto maximize the area covered).  \\citet[hereafter ST13]{Schmidt13}\ndescribe the DLS photometric redshifts and verify them using\n$\\sim 10^4$ spectroscopic redshifts in a 1 deg$^2$ overlap region with\nthe Prism Multi-object Survey \\citep[PRIMUS,][]{Primus}.  ST13 tested\nthe fraction of galaxies with spectroscopic redshift within six\ndifferent CI and did not find systematic under- or overconfidence.\nHowever, our $\\hat{F}(c)$ test on these data (Figure~\\ref{fig-dls})\nreveals substantial overconfidence.  The maximum departure from the\ndesired line is nearly 0.30---only 53\\% of the galaxies are within\ntheir 82\\% CI---which a KS test deems overwhelmingly significant\n($p<10^{-300}$).  Because of the large sample size---8719 galaxies\nafter applying all the cuts applied by ST13---all departures visible\nin the DLS plots in this paper are significant.\n\nThe difference between the ST13 results and ours lies in the\ndefinition of CI. ST13 integrated around the highest peak and\nintegrated symmetrically (in terms of area under $p_i(z)$) around that\npeak.  Therefore, their CI are not HPD CI and should not be used to\nprobe for overconfidence, as explained in Section~\\ref{sec-HPDCI}.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{bpz-dls.png}}}\n\\caption{The $\\hat{F}(I^p)$ plot for BPZ applied to DLS photometry of\n  the PRIMUS spectroscopic sample shows overconfidence\n  ($p<10^{-300}$), preferentially in the brighter galaxies.  This\n  suggests the need to model template uncertainties.\\label{fig-dls}}\n\\end{figure}\n\nNext, we probe for trends by splitting the data into subsamples.  We\nfound no visible difference in subsamples split by spectroscopic\nredshift and only small differences in subsamples split by galaxy\nspectral type (as determined by BPZ).  We did find a modest trend with\nmagnitude, with brighter galaxies showing more overconfidence\n(Figure~\\ref{fig-dls}, dashed curves), the same trend exhibited by BPZ\non the HDFN and HUDF data.  The sign of the magnitude trend, along\nwith the lack of a redshift trend, again points to template noise.  We\ntherefore tried the $p_i(z)$ smoothing approach with a series of\nkernel widths, and in Figure~\\ref{fig-dls-smooth} we plot the results\nusing $\\sigma=0.055$ to illustrate the difficulty of defining an\n``optimal'' kernel. The $\\sigma=0.055$ kernel shown here provides a\nquick way to remove most of the overconfidence, but leaves a\ndiscrepancy in the tails: 92.7\\% of galaxies are within their 97.2\\%\nCI ($p\\approx 10^{-15}$).  A broader kernel would reduce the\ndiscrepancy in the tails, but would also introduce {\\it\n  under}confidence elsewhere in the plot. Choosing the kernel by the\nsole criterion of minimizing the deviation between $\\hat{F}(c)$ and\n$c$ may not be wise here because the bright subsample is already\ngenerally underconfident after smoothing, {\\it except} in the\ntails. This suggests that template noise has been ``modeled'' about as\nwell as it can be with a Gaussian smoothing kernel, and that an\noptimal kernel would include heavier tails.  Note also the remaining\noverconfidence in the {\\it faint} galaxies: this suggests that some\nphotometric uncertainties remain unmodeled.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{bpz-dls-smoothed.png}}}\n\\caption{The $\\hat{F}(c)$ plot for BPZ+DLS with $p_i(z)$ smoothing\n  using $\\sigma=0.055$.  The smoothing provides a good approximation\n  to the desired behavior, with a small magnitude trend.  All\n  departures from the line are statistically significant.\n\\label{fig-dls-smooth}}\n\\end{figure}\n\nWe also ran EAZY on the DLS data.  The $\\hat{F}(c)$ curve\n(Figure~\\ref{fig-dlseazy}) is much better than for BPZ on the same\ndata, but still departs significantly from the desired distribution in\nplaces (93.2\\% of galaxies are within their 96.8\\% CI,\n$p=\\approx 10^{-10}$). There is also some {\\it under}confidence where\nthe empirical curves pass above the diagonal line in\nFigure~\\ref{fig-dlseazy}.  \n\nAlthough the EAZY and smoothed BPZ results have many dissimilarities\n(e.g., opposite magnitude trends), they both have a kink in the curve\nat $c\\approx 0.8$: spectroscopic redshifts too frequently land very\nfar from the $p(z)$ peak.  This suggests non-Gaussian wings in the\nphotometric uncertainties (from, e.g., deblending), the template\nuncertainties, or both.  As discussed at the end of\nSection~\\ref{subsec-EAZY}, these two sources of uncertainty can be\ndecoupled by modeling the photometric uncertainties---including heavy\ntails---via simulations and repeat visits.  Photometric redshift\noutliers can be substantially reduced simply by folding this\nheavy-tailed photometric model into a standard code such as BPZ\n\\citep{Wittman07}.  Outliers remaining after this process are likely\ndue to non-Gaussian template uncertainties.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{EAZY_DLS.png}}}\n\\caption{The $\\hat{F}(c)$ plot for EAZY applied to DLS photometry of\n  the PRIMUS spectroscopic sample shows a relatively small (but\n  significant) amount of overconfidence (93.2\\% of galaxies are within\n  their 96.8\\% CI, $p\\approx 10^{-10}$).  As with the smoothed BPZ\n  results, the remaining overconfidence is primarily in the tails,\n  suggesting that template uncertainty is not the cause of the\n  overconfidence.\\label{fig-dlseazy}}\n\\end{figure}\n\nFinally, we note that the DLS results presented so far could reflect\ndifferences between EAZY and BPZ other than the template error\nfunction:\n\\begin{itemize}\n\\item EAZY fits for a linear combination of templates with nonnegative\n  coefficients, while BPZ considers templates separately (but\n  interpolates between successive templates).\n\\item BPZ has a type-dependent prior while EAZY does not. We ran EAZY\n  on the DLS data using a prior as similar as possible to the ST13 BPZ\n  prior, but due to this restriction the priors cannot be the same.\n\\item We also used different templates. For EAZY we used the EAZY 1.0\n  templates 1--6, whereas the BPZ $p_i(z)$ we downloaded from the DLS\n  data release website\\footnote{\\url{http://dls.physics.ucdavis.edu}}\n  resulted from the more highly tuned ST13 templates.\n\\end{itemize}\nWe therefore tested whether the template error function is the primary\nfactor responsible for reduced overconfidence in EAZY by running EAZY\non the DLS data with the template error function turned off.  We\nobtained an $\\hat{F}(c)$ distribution remarkably similar to the BPZ\ndistribution shown in Figure~\\ref{fig-dls}, indicating that the\ntemplate error function is indeed the primary cause of reduced\noverconfidence.  Even with the template error function on,\noverconfidence rose when we restricted or eliminated EAZY's linear\ncombination feature.  This suggests that two conditions must be met\nfor appropriate confidence.  First, the available templates must be\nable to match the gross features of the observations, either by\ncombining many generic templates as EAZY does by default, or by\ntweaking a smaller number of templates as ST13 did before applying BPZ\nto the DLS.  Second, spectral energy variations on finer wavelength\nscales can be modeled via the template error function.\n\n\n\\section{Summary and discussion}\\label{sec-discussion}\n\nApplications of photometric redshifts increasingly use each galaxy's\nprobability density function $p_i(z)$ rather than a single point\nestimate, and rightly so. However, tests of photometric redshift\naccuracy generally compare only the highest $p_i(z)$ peak to the\nspectroscopic redshift.  This can lead to the false conclusion that a\ngalaxy is a ``catastrophic outlier'' when in fact it is entirely\npredictable that a spectroscopic redshift sometimes falls on the\nsecond-highest peak, or in even lower-probability regions.  We have\ndefined a way to test all parts of $p_i(z)$ using the empirical\ncumulative distribution function $\\hat{F}$.  This test determines the\ncollective consistency of the $p(z)$ with the spectroscopic redshifts\nin way that probes specifically for the known failure mode of\noverconfidence.  The test complements rather than replaces traditional\ntests because the latter are still necessary for measuring differences\nin terms of redshift.\n\nWe find that the $p(z)$ produced by BPZ (and presumably most other\ntemplate methods) suffer from substantial overconfidence (e.g. only\n32\\% of galaxies have true redshift within their 92\\% CI) because they\ndo not account for variation in galaxy SEDs, so-called template\nnoise. One code that does model template noise, EAZY, produced $p(z)$\nwith substantially less overconfidence, on each of two data sets that\ndiffer widely in terms of filter set and depth.  Multiple independent\narguments suggest that the improved performance is due to template\nuncertainty modeling rather than other differences between the codes.\nFirst, the most marked difference between BPZ and EAZY is with {\\it\n  bright} galaxies, for which template noise is a larger fraction of\nthe uncertainty budget and for which priors should be relatively\nunimportant.  Second, smoothing the BPZ $p_i(z)$---a crude model of\nthe effect of template uncertainty---greatly reduces the BPZ\noverconfidence. Third, we turned the template uncertainty modeling off\nin EAZY and found overconfidence similar to BPZ.\n\nThe practical impact of this overconfidence is not immediately\napparent from statements about the percentage of galaxies within a\ngiven CI.  On an individual galaxy level, the practical impact is that\nthe true redshift is not as well constrained as the $p_i(z)$ would\nindicate, and we can quantify this by specifying the amount of\n$p_i(z)$ smoothing required to eliminate the overconfidence (to the\nextent possible with smoothing rather than with more sophisticated\nmodeling). We found that smoothing the BPZ $p_i(z)$ with $\\sigma=0.09$\nis adequate for the HUDF data set, and $\\sigma\\approx 0.06$ is\nadequate for the DLS; both numbers are consistent with the suggestion\nof $\\sigma=0.065(1+z)$ by \\citet{Fernandez02}. The ``optimal'' kernel\nwidth may depend on filter set and other data details, as it reflects\nhow much the SEDs vary from the templates at the rest wavelengths most\nheavily probed by the data, but $\\sigma=0.065(1+z)$ seems to work with\na variety of deep optical surveys.  A fixed kernel does have the\nflexibility to work with varying numbers of filters, because it has\nappropriately less impact on the already-broad $p_i(z)$ produced by\nsurveys with few filters.\n\nFor sets of galaxies such as a $z_{p}$ bin used in cosmic shear, the\npractical effect of overconfidence is that the true redshift\ndistribution of the set is likely to be broader than the summed\n$p_i(z)$.  For a hypothetical distribution of galaxies centered at\n$z=1$ and with $\\sigma_z=0.2$, to first order the effect of smoothing\nwith a $\\sigma=0.065(1+z)$ kernel will be to broaden the bin to\n$\\sigma_z=0.24$. For weak lensing tomography with a next-generation\nimaging survey like LSST \\citep{LSST}, \\citet{Ma2006} report that the\nwidth of the redshift bins must be known to better than 0.01 to avoid\nsubstantial degradation of dark energy parameter constraints (where\nsubstantial degradation is defined as parameter constraints 1.5 times\nlooser than in the case with perfect knowledge of the bin width).\nAccurate modeling of template uncertainty is therefore likely to be\nimportant in achieving the full potential of such surveys.  In doing\nso, we must avoid the traditional anti-overconfidence tactic of\nmultiplying the error bars by some factor in order to adopt a\n``conservative'' estimate.  Broadening $p(z)$ too much\n(underconfidence) results in overestimating the width of a redshift\nbin, which is equally harmful to much of the downstream science.\n\nAlthough we have focused on smoothing the $p_i(z)$ as a convenient\nfix, template variance at a given rest wavelength propagates into\ndifferent observed filters at different redshifts.  Physical modeling\nof this process is therefore better than smoothing in principle.  In\neither case, correcting this source of overconfidence helps expose\nother issues with the overall uncertainty budget.  This is best\nillustrated by the comparison between Figures~\\ref{fig-dls} and\n\\ref{fig-dls-smooth}: an excess of spectroscopic redshifts very far\nfrom the $p(z)$ peaks is clearly visible in the upper right corner of\nFigure~\\ref{fig-dls-smooth} but is masked by the much larger\noverconfidence trend in Figure~\\ref{fig-dls-smooth}.  This pattern of\noutliers appears across a variety of codes and data sets, and points to\nthe need to model heavy tails in probability distributions, including\nthat of the underlying photometry.  For large data sets and surveys we\nrecommend decoupling photometric uncertainty from other issues by\nconducting targeted simulations and repeat observations to carefully\ncalibrate the photometric uncertainty model.  Better photometric\nuncertainty modeling will yield better photometric redshifts\n\\citep{Wittman07}, and in turn will enable photometric redshift\nconfidence calibration to focus on physical modeling components such\nas templates.  Because the photometric noise contribution is strongly\nmagnitude-dependent, both types of modeling will be necessary to\nunderstand a survey over its full magnitude range.\n\nThe probability tails are potentially important for downstream\nscience, because a small leakage of high-redshift galaxies into a\nlow-redshift bin could add substantially to the naturally low lensing\nsignal in that bin, while a small leakage in the other direction can\nsubstantially change the inferred luminosity function at high\nredshifts.  Tracking these details requires tools other than the\noverconfidence test; for example, the leakage can be mapped with a\n$z_s$ vs. $z_p$ plot in which $z_p$ is rendered as a cloud\ncorresponding to $p(z)$.  In the end, the true redshift distribution\nof a photometric redshift bin may best be constrained by methods that\nare independent of any photometric redshift algorithm \\citep[e.g. the\ncross-correlation method,][]{Newman08}.\n\nThe overall uncertainty budget is strongly magnitude-dependent, so\ntests performed with bright spectroscopic samples should be\ninterpreted carefully.  Obtaining a truly representative spectroscopic\nsubsample is difficult; for example, the PRIMUS spectroscopy in the\nDLS field has a 50\\% redshift success rate at $R\\approx 21.5$\n\\citep{Cool13} while the DLS photometry goes much deeper than\nthat. Our conclusions regarding template uncertainty are robust,\nhowever, because the spectroscopic sample is most complete for bright\ngalaxies, where template variance is the largest fraction of the\nuncertainty budget.  \n\n\n\\section*{Acknowledgements}\n\nWe thank Sam Schmidt for valuable discussions and help with running\nEAZY on the DLS data.  We also thank Paul Baines and Karen Ng for\nuseful discussions, and the anonymous referee for helpful feedback.\nThe DLS was made possible by support from Lucent Technologies and NSF\ngrants AST 04-41072 and AST 01-34753.\n\n\\bibliographystyle{mnras}\n\\bibliography{ms}\n\n\n", "itemtype": "equation", "pos": 11129, "prevtext": "\n\n\\title[Overconfidence in Photometric Redshifts]{Overconfidence in\n  Photometric Redshift Estimation}\n\n\\author[David Wittman et al.]{David Wittman,$^{1,2}$ Ramya Bhaskar,$^{1}$ and Ryan Tobin$^{1,3}$ \\\\\n$^{1}$Physics Department, University of California, Davis, CA 95616\\\\\n$^{2}$Instituto de Astrof\\'{i}sica e Ci\\^{e}ncias do Espa\\c{c}o,\nFaculdade de Ci\\^{e}ncias, Universidade de Lisboa, Lisbon, Portugal\\\\\n$^{3}$Current address: Department of Physics and Astronomy,\n  University of Hawaii, Honolulu, HI 96822}\n\n\\maketitle\n\n\\begin{abstract} \n  We describe a new test of photometric redshift performance given a\n  spectroscopic redshift sample.  This test complements the\n  traditional comparison of redshift {\\it differences} by testing\n  whether the probability density functions $p(z)$ have the correct\n  {\\it width}.  We test two photometric redshift codes, BPZ and EAZY,\n  on each of two data sets and find that BPZ is consistently\n  overconfident (the $p(z)$ are too narrow) while EAZY produces\n  approximately the correct level of confidence.  We show that this is\n  because EAZY models the uncertainty in its spectral energy\n  distribution templates, and that post-hoc smoothing of the BPZ\n  $p(z)$ provides a reasonable substitute for detailed modeling of\n  template uncertainties.  Either remedy still leaves a small surplus\n  of galaxies with spectroscopic redshift very far from the peaks.\n  Thus, better modeling of low-probability tails will be needed for\n  high-precision work such as dark energy constraints with the Large\n  Synoptic Survey Telescope and other large surveys.\n\\end{abstract}\n\n\\begin{keywords}\nsurveys---galaxies: photometry---methods: statistical\n\\end{keywords}\n\n\\section{Introduction}\n\nPhotometric redshifts are of key importance to current and future\ngalaxy surveys.  A variety of methods have been demonstrated, falling\nbroadly into two categories: empirical and template-based.  Empirical\nmethods predict redshifts from photometry by directly using the known\nspectroscopic redshifts of a subsample spanning the color and\nmagnitude range of the main photometric sample.  Template methods use\nmodels of galaxy spectral energy distributions (SEDs), which enable\nprediction of redshifts beyond the magnitude limit of the\nspectroscopic sample.  See \\citet{HH10} and \\citet{Dahlen2013zphot}\nfor overviews and performance comparisons.\n\n\n\n\n\n\n\n\n\n\n\nUntil recently, photometric redshift performance comparisons\n\\citep{Hogg98,HH08,HH10} have been based on casting the photometric\nredshift of a galaxy as a single number, but this glosses over some of\nthe complexity inherent in these predictions.  For example, a deep\nsurvey with a small number of filters is bound to encounter\ndegeneracies in which both low- and high-redshift models are\nacceptable for some galaxies.  Forcing a photometric redshift\nalgorithm to choose only the single most likely model thus generates\nsome wildly inaccurate redshift estimates, which are called\n``catastrophic outliers.''  Capturing all the photometric redshift\ninformation in a probability density function $p(z)$ greatly reduces\nor eliminates these outliers \\citep{Fernandez02}.  Even if a\nparticular $p(z)$ is not multiply peaked, it may be asymmetric, so\nthat using the full $p(z)$ rather than a point estimate reduces bias\n\\citep{Mandelbaum08} and thus reduces systematic errors on downstream\nscience such as dark energy parameter estimation \\citep{Wittman09}.\n\nThe works cited above established that the $p(z)$ paradigm offers\nbetter performance than point estimates, but point estimates are still\nmore easily checked against spectroscopic redshift, by tabulating the\nmean and scatter in the quantity $z_s-z_p$ (spectroscopic redshift\nminus photometric redshift).  The $p(z)$ paradigm offers no obvious\ngeneralization of this procedure.  Indeed, codes that work internally\nwith $p(z)$ often default to outputting a single error estimate for\neach galaxy.  \\citet{HH08} found that these error estimates are not\npredictive of the real errors, but this may simply reflect the\nunderlying complexity of $p(z)$.  The extensive performance comparison\nof \\citet{Dahlen2013zphot} did use $p(z)$ to derive 68\\% and 95\\%\nconfidence intervals, and found that most codes are\noverconfident---their confidence intervals are too narrow.  In this\npaper we present a tool for systematically testing overconfidence, and\nwe show why the $p(z)$ output by template codes can be substantially\noverconfident.  One limitation of our test is that spectroscopic\nsubsamples may not be representative of the full photometric sample.\nHowever, this limitation also affects verification of point estimates,\nand is therefore separable from the question of how to assess the\nquality of $p(z)$---which are often broad, asymmetric, and/or\nmultimodal functions---against the delta functions represented by\nspectroscopic redshifts.\n\n\\section{Measuring overconfidence}\n\n\\subsection{Conceptual explanation}\\label{sec-HPDCI}\n\nBy its nature, $p(z)$ cannot be verified on a galaxy-by-galaxy basis,\njust as a single coin toss cannot determine whether a coin is fair.  A\nlarge sample, accordingly, does support $p(z)$ verification.  A sample\nof 1000 galaxies, for example, {\\it should} contain of order 10\ngalaxies whose spectroscopic redshift is in tension with the\nphotometric redshift at the 99\\% level.  If too many galaxies exhibit\nthis much tension, the photometric redshifts collectively can be\ndeemed overconfident, as they predict the spectroscopic redshifts with\nmore precision than is supported by evidence.  Similarly, if too few\ngalaxies in the sample exhibit this much tension, the photometric\nredshifts collectively can be deemed underconfident.\n\nIn practice, overconfidence is far more common than underconfidence,\nwhen estimating almost anything.  This may be due to the nature of\nerror budgets: humans use judgment to identify the most salient\nsources of uncertainty worthy of quantification, whereas\n``subdominant'' sources of uncertainty have little effect when added\nin quadrature and therefore do not merit quantification.  Sources of\nuncertainty that initially do not seem salient may never be folded\ninto the budget even if their true contribution is substantial.  For\nexample, most photometry codes base their uncertainties on photon\nnoise and neglect sky modeling uncertainties.  Neglecting this source\nof noise is justified in many cases, but the general pattern is to\nunderrepresent some sources of noise without any compensating\noverrepresentation of other sources, so the final result is often\noverconfident.\n\nWe can check for overconfidence by asking whether 50\\% of galaxies\nhave their spectroscopic redshift within their 50\\% credible\ninterval\\footnote{Bayesian statisticians use this term when speaking\n  of Bayesian posteriors, and reserve the term {\\it confidence\n    interval} for the likelihood.  This distinction does not often\n  appear in the astronomy literature.}  (CI), 90\\% have spectroscopic\nredshift within their 90\\% CI, etc.  Such checks do appear in the\nliterature \\citep[e.g., ][]{Schmidt13,Dahlen2013zphot}, but are\nusually implemented without a key feature that greatly assists with\nthe interpretation.  This key feature was evident already in the\npioneering work of \\citet{Fernandez02}; here we explain it in more\ndetail, use it to implement a systematic confidence test, and show how\nthis test can lead to insight about the photometric redshift\nalgorithms themselves.\n\nFor a confidence test, it is crucial that we choose the highest probability\ndensity (HPD) CI for any given credibility level. To see why, consider\nFigure~\\ref{fig-pzexample}, which shows a hypothetical posterior\n$p(z)$. We could define a 20\\% CI by, say, starting at $z=0$ and\nintegrating the area under the posterior curve until we reach 20\\% of\nthe total area under the curve, and indeed 20\\% of galaxies should\nhave spectroscopic redshift within the 20\\% CI as defined this\nway. However, testing CIs defined this way would not test\noverconfidence---the tendency for $p(z)$ to be too sharply peaked.  We\ntherefore define the 20\\% CI by lowering a threshold from the peak\ndownward until the area under the parts of the curve intersected by\nthe threshold equals 20\\% of the total area; this is the HPD 20\\% CI.\n\n\\begin{figure}\n\\centerline{\\resizebox{3.5in}{!}{\\includegraphics{HPD.png}}}\n\\caption{Five illustrative highest probability density credible\n  intervals. The darkest shade indicates the HPD 20\\% CI, the next\n  darkest shade (in combination with the first) indicates the HPD 40\\%\n  CI, and so on, with white comprising the final 20\\%. The horizontal\n  dashed lines indicate that the corresponding, possibly disjoint,\n  redshift intervals have been identified starting from the peak by\n  lowering a threshold and using the points where $p(z)$ crosses the\n  threshold. \\label{fig-pzexample}}\n\\end{figure}\n\nThe same process leads to the 40\\%, 60\\%, and 80\\% CI in\nFigure~\\ref{fig-pzexample} covering multiple separated redshift\nintervals.  This is the only way to maintain the highest probability\ndensity and thereby probe for overconfidence.  To illustrate, imagine\nthis galaxy has $z_s=1.2$, a result that we should judge to be very\nunlikely given this $p(z)$. This indeed falls outside the HPD 99\\% CI,\nbut falls inside the 50\\% CI if we define the CI by integrating only\nin a single contiguous region around the highest peak.  The latter\ndefinition of CI gives us a false sense that the photometric redshift\nprediction was borne out.  An example with two equal peaks is\nadmittedly extreme, but the same principle is at work with unequal\npeaks or even a single asymmetric peak.  Most confidence checks in the\nliterature to date have not used the HPD CI, but authors should begin\ndoing so; Section~\\ref{sec-DLS} shows that results can differ\nsubstantially when not using the HPD CI.  For the remainder of the\npaper, references to CI should be understood as HPD CI unless\notherwise stated.\n\n\n\n\n\n\n\\subsection{Implementation}\n\nWe want to know how many galaxies in a data set have $z_s$ within\ntheir 1\\% CI, how many within their 2\\% CI, etc. Computationally, this\nimplies a loop over credibility levels, with each iteration containing\na loop over galaxies to check whether each galaxy meets the criterion.\nHowever, it is computationally more efficient to perform a one-time\ncalculation for each galaxy, to find the CI that just barely includes\nthe spectroscopic redshift.  Referring again to\nFigure~\\ref{fig-pzexample}, imagine that we have not yet calculated\nany CI but we know the value of $z_s$. We simply draw a horizontal\nline through $p(z_s)$ to identify the relevant redshift intervals and\ncompute the area under the curve in those intervals to find the\ncredible level that just includes $z_s$.  Recording that this\nthreshold credibility is, say, 32\\% is a highly efficient way of\nrecording that this galaxy does not have $z_s$ within its 1\\% CI, nor\nits 2\\% CI, nor its 3\\% CI, etc, but does have $z_s$ within its 32\\%\nCI, and its 33\\% CI, and its 34\\% CI, etc.\n\nThe implentation is thus quite simple. We compute the threshold\ncredibility $c_i$ for the $i$th galaxy with:\n\n", "index": 1, "text": "\\begin{equation}\nc_i = \\sum_{z \\in p_i(z) \\ge p_i(z_{s,i})} p_i(z)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"c_{i}=\\sum_{z\\in p_{i}(z)\\geq p_{i}(z_{s,i})}p_{i}(z)\" display=\"block\"><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>z</mi><mo>\u2208</mo><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>z</mi><mrow><mi>s</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></munder><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}]