[{"file": "1601.04131.tex", "nexttext": "\nwhere $s^{(m)}$ is the transmitted symbols originated from the same bit sequence\nacross the (re)transmissions, and $n^{(m)}\\sim\\mathcal{CN}(0,\\sigma^2)$ is the\nadditive noise.\nThe Rician channel can be modeled as~\\cite[(2.55)]{tse2005fundamentals}\n\n", "itemtype": "equation", "pos": 8620, "prevtext": "\n\n\n\n\n\n\n\n\\title{Statistical Analysis of a Posteriori Channel and Noise Distribution\nBased on HARQ Feedback}\n\n\n\n\n\n\n\n\n\n\n\n\\author{\n  Wenhao Wu,~\\IEEEmembership{Student Member,~IEEE,}\n  Hans Mittelmann,\n  Zhi Ding,~\\IEEEmembership{Fellow,~IEEE}\n}\n\n\n\\maketitle\n\n\n\n\\begin{abstract}\n  In response to a comment on one of our manuscript, this work studies the\n  posterior channel and noise distributions conditioned on the NACKs and ACKs of\n  all previous transmissions in HARQ system with statistical approaches. Our main\n  result is that, unless the coherence interval (time or frequency) is large as\n  in block-fading assumption, the posterior distribution of the channel and\n  noise either remains almost identical to the prior distribution, or it mostly\n  follows the same class of distribution as the prior one. In the latter case,\n  the difference between the posterior and prior distribution can be modeled as\n  some parameter mismatch, which has little impact on certain type of\n  applications.\n\\end{abstract}\n\n\n\\begin{IEEEkeywords}\n  HARQ, posterior distributions, statistical analysis.\n\\end{IEEEkeywords}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\\section{Introduction}\n\\label{sec:intro}\nIn our recent manuscript~\\cite{wu2015modulation}, we studied the Modulation\nDiversity (MoDiv) design problem based on Hybrid Automatic Repeat reQuest (HARQ)\nChase-Combining (CC) protocol. In this work, we approximate the bit\nerror rate (BER) based on prior fading channel and noise distributions after\neach round of (re)transmission. One would argue that the need for the\n$m$-th (re)transmission implies that all previous transmissions have failed,\nthus the posterior channel and noise distribution would no longer be the same as\nthe prior distribution. Consequently, it is natural to wonder when and how the\nposterior information, namely HARQ NACKs/ACKs, affects the channel and noise\ndistribution.\n\nThere are a few works highlighting this difference between the prior and\nthe posterior\ndistributions~\\cite{gu2006modeling}\\cite{long2012analysis}\\cite{alkurd2015modeling},\nsuggesting that adopting the prior distribution may lead to an overoptimistic\nestimation on the performance of HARQ.\nOn the other hand, there are also abundant works about HARQ in fading channels\nthat do not consider the posterior distribution, such as constellation\nrearrangement~\\cite{harvind2005symbol}, power\nallocation~\\cite{chaitanya2014adaptive}, rate selection~\\cite{jin2011optimal}\nand so forth. As far as we know, it remains an open question\nunder what conditions it is suitable or not to exploit the posterior distribution.\n\nIn this work, we study the posterior distribution of fading channels and noises\nin a practical LDPC-coded HARQ system under the general a priori assumptions of\nRician fading channel and circularly symmetric complex Gaussian (CSCG)\nadditive noises. By analyzing the posterior distribution with a series of three\nhypothesis tests on numerically generated channel and noise samples, we\ndemonstrate that the posterior distribution may not significantly differ from\nthe prior one, especially when each HARQ packet, or transport block (TB) in LTE\nterminology, experiences a few independent fading channel instances. \nMoreover, even when the coherence interval is large so that the instances of\nfading channels corresponding to each TB are more correlated, the posterior\ndistribution may still follow the same type of distribution as the prior one\nexcept for some differences in parameters. This minor difference has negligible\nimpact on specific applications such as modulation diversity (MoDiv)\ndesign~\\cite{wu2015modulation}\\cite{harvind2005symbol}. To the best of our\nknowledge, the statistical approaches taken by this work to study the posterior fading channel and noise\ndistribution in HARQ systems has not been reported in existing literature.\n\nThe rest of the paper is organized as follows:\nSection~\\ref{sec:backgrounds} discusses a few\npractical considerations why it may not be proper to adopt the posterior\ndistribution in the studies of HARQ system. Section~\\ref{sec:model_data}\ndescribes our system model and how we generate the fading channel/noise samples\ncorresponding to the posterior distribution for our hypothesis tests.\nIn Section~\\ref{sec:tests}, we construct three hypothesis tests to analyze the\nposterior fading channel/noise distribution. The numerical results are provided\nin Section~\\ref{sec:numerical}. Finally, Section~\\ref{sec:conclusion} concludes\nthis work.\n\n\n\n\n\\section{Backgrounds}\n\\label{sec:backgrounds}\n\nOne apparent reason why posterior distribution is not preferable is\ninfeasibility, as a posterior analysis for HARQ system is usually too difficult\nunless one rely on some very restrictive, less practical settings and assumptions. For instance, \\cite{gu2006modeling} characterize the failure of\ntransmissions with effective SNR and rate criteria, which on its own is a\nsimplification and only numerical results are presented. Considering PAM\nconstellations and maximum ratio combining (MRC),\n\\cite{long2012analysis}\\cite{alkurd2015modeling} attempts to explicitly\nformulate the error probability. However, the error probability based on $Q$\nfunction is an approximation, especially for practical high-order QAM\nmodulations, and their analysis is based on instantaneous CSI and does not scale\nwell for large number of retransmissions. In practice, a transmission failure is\ndeclared by the cyclic redundancy check (CRC) when an error in the forward error\ncorrection (FEC) decoding result is detected. Such a complex event is difficult\nto characterize, let alone deriving a posterior channel distribution from it.\n\nThere is one questionable assumption common to all these works considering the\nposterior distribution in HARQ.\nThe channel corresponding to a TB is always characterized by a single scalar\neffective SNR value, i.e. the entire TB experience a single instance of the\nfading channel and/or additive noise. As a practical example, in LTE system,\neach TB can be mapped to a maximum of 110 resource blocks (RB) of\n0.5ms$\\times$180kHz~\\cite[Table 7.1.7.2.1-1]{ts36.213}.\nIn the propagation condition~\\cite[Table B.2-3]{ts36.141}, the coherence time\ncould be as small as $\\tau_c\\approx 1 / (4 \\times 300\\mbox{Hz}) =\n0.833\\mbox{ms}$ and the coherence bandwidth could be $B_c\\approx 1 / (2 \\times\n5000\\mbox{ns}) = 100\\mbox{kHz}$~\\cite[Table 2.1]{tse2005fundamentals}.\nConsequently, each RB roughly experiences independent fading components and the\nunivariate fading/noise instance per TB assumption is not satisfied. On the\nother hand, if each TB experiences $N_{IF}$ independent fading channel\ninstances, then the posterior channel/noise distribution should be defined over\n$\\mathcal{O}(m\\times N_{IF})$ complex variables, which easily becomes\nintractable.\n\nThe generalization from the abovementioned restrictive settings and assumptions \nwhich facilitates a posterior analysis for HARQ leads to the\nsecond---more essential but less obvious---reason why posterior distribution is\nnot always worthy of exploiting: questionable necessity. In the rest part of\nthis work, we will demonstrate that, in a more general and practical HARQ system, the\nposterior channel and noise distributions may not differ significantly from the\nprior ones, or the difference is too little to have visible\nimpact on certain applications.\n\n\\section{System Model and Data Generation}\n\\label{sec:model_data}\n\n\\subsection{Notations}\n\\label{subsec:notation}\nWe adopt the following notations throughout this work. $\\Re\\{\\cdot\\}$ and\n$\\Im\\{\\cdot\\}$ represent the real and imaginary part of a complex matrix.\n$[\\mathbf{A};\\mathbf{B}]$ and $[\\mathbf{A},\\mathbf{B}]$ represent vertical and\nhorizontal concatenation of matrix $\\mathbf{A}$ and $\\mathbf{B}$, respectively. Multivariate Gaussian distribution, \nmultivariate CSCG distribution and chi-squared distribution with $d$\ndegree-of-freedom are denoted with $\\mathcal{N}(\\cdot)$, $\\mathcal{CN}(\\cdot)$\nand $\\chi_d^2$. $\\mathbf{0}_l$, $\\mathbf{1}_l$ and $\\mathbf{I}_l$ denote the\n$l$-dimensional all-0 vectors, $l$-dimensional all-1 vectors and\n$l$-by-$l$-dimensional identity matrix. $|\\cdot|$ and $\\|\\cdot\\|_F$ represent\nthe deterministic and Frobenius norm of a matrix. $\\mbox{diag}(\\mathbf{a})$\nrepresent the diagonal matrix whose diagonal elements are defined by vector\n$\\mathbf{a}$.\n\n\\subsection{System Model}\n\\label{subsec:model}\nWe consider a simple Type-I HARQ system with Chase Combining (CC) under Rician\nfading channel and additive CSCG noise assumption. The received signal of the\n$m$-th retransmission ($m=0$ represents the original transmission) is\n\n", "index": 1, "text": "\\begin{equation}\n  y^{(m)} = h^{(m)}s^{(m)} + n^{(m)}, \\quad\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"y^{(m)}=h^{(m)}s^{(m)}+n^{(m)},\\quad\" display=\"block\"><mrow><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><mrow><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><msup><mi>s</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>+</mo><msup><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mrow><mo rspace=\"12.5pt\">,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere $K$ is the Rician factor, $\\beta$ is the mean power, and $\\theta$ is the\nphase of the line-of-sight (LOS) component. We also assume that $n^{(m)}$ is\nindependent across different samples and $h^{(m)}$ is independent across different\n(re)transmissions. Assuming all previous $m$ decoding attempt have failed,\nafter the $m$-th retransmission, the receiver makes another decoding attempt by\ncombining the $m + 1$ TBs received so far using a maximum likelihood (ML)\ndetector, until $m > M$ where the HARQ transmission fails.\n\n\\subsection{Data Generation}\nTo analyze the posterior distribution of the fading channels and\nnoises, we generate the channel/noise samples with a LDPC-coded\nsystem~\\cite{hochwald2003achieving}\\cite{valenti2007coded}. We assume that each\nTB contains 1 complete LDPC frame. Another tuning parameter, namely the number of independent fading channels per TB denoted as $N_{IF}$, is added\nto this system in order to test the impact of coherence interval on the\nposterior distribution. As shown in Fig.~\\ref{fig:model}, for different $m$, we\nrandomly generate a set of LDPC sessions, each consists of a encoding bit sequence and the\nfading channel/noise samples corresponding to the $(m+1)$ TBs. The LDPC-decoder\nthen classify the LDPC sessions into two subsets based on whether the receiver\nsends a NACK (decoding failure) or ACK (decoding success) after the $m$-th\nretransmission, which represent the two classes of posterior distributions we\nare interested in.\n\nWithin each TB, the $N_{IF}$ independent fading\nchannel instances are periodically mapped to the $L_s$ symbols. Among the $L_s$\nnoise samples, we randomly sample $N_{IF}$ in such a manner that the\ncorresponding channel samples represent the $N_{IF}$ independent fading\nchannel instances completely. In this way we make sure that the number of\nchannel samples and that of the noise samples are equally $N_{IF}$.\nConsequently, within each failed/successful HARQ session, a total number of\n$(m+1)\\times N_{IF}$ groups of fading channels/noises are sampled. This groups of samples are then zipped across the\n$(m+1)$ (re)transmissions to construct $N_{IF}$ records, each represented as a\n$2(m+1)$-dimensional complex vector, or equivalently a $4(m+1)$-dimensional\nreal vector, in the form of\n\n", "itemtype": "equation", "pos": 8944, "prevtext": "\nwhere $s^{(m)}$ is the transmitted symbols originated from the same bit sequence\nacross the (re)transmissions, and $n^{(m)}\\sim\\mathcal{CN}(0,\\sigma^2)$ is the\nadditive noise.\nThe Rician channel can be modeled as~\\cite[(2.55)]{tse2005fundamentals}\n\n", "index": 3, "text": "\\begin{align}\n  h^{(m)} = \\sqrt{\\frac{K}{K+1}\\beta}e^{j\\theta} +\n  \\sqrt{\\frac{1}{K+1}}\\mathcal{CN}(0,\\beta)\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle h^{(m)}=\\sqrt{\\frac{K}{K+1}\\beta}e^{j\\theta}+\\sqrt{\\frac{1}{K+1}%&#10;}\\mathcal{CN}(0,\\beta)\" display=\"inline\"><mrow><msup><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><mrow><msqrt><mrow><mstyle displaystyle=\"true\"><mfrac><mi>K</mi><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow></mfrac></mstyle><mo>\u2062</mo><mi>\u03b2</mi></mrow></msqrt><mo>\u2062</mo><msup><mi>e</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>\u03b8</mi></mrow></msup></mrow><mo>+</mo><mrow><msqrt><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow></mfrac></mstyle></msqrt><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": " \nwhere $\\mathbf{h}^{(m)} = [h^{(0)},\\ldots,h^{(m)}]$, $\\mathbf{n}^{(m)} =\n[n^{(0)},\\ldots,n^{(m)}]$.\n\nIn the next section, we carry out our hypothesis\ntests over a dataset of $n$ records of $\\mathbf{x}$, which is organized into a $4(m+1)$-by-$n$ matrix\n$\\mathbf{X} = [\\mathbf{x}_1, \\ldots, \\mathbf{x}_n]$. For notational convenience\nwe also decompose $X$ into four $(m+1)$-by-$n$ block matrices, i.e.\n$\\mathbf{X} = [\\mathbf{X}_{h,R}; \\mathbf{X}_{h,I}; \\mathbf{X}_{n, R};\n\\mathbf{X}_{n, I}]$, which represent the real and imaginary part of the channel\nand noise samples, respectively.\n\n\\begin{figure}[!t]\n  \\centering\n  \\includegraphics[width=4.0in]{data.eps}\n  \\caption{The generation of datasets for the analysis on the posterior\n  distribution of the fading channels and noises.}\n  \\label{fig:model}\n\\end{figure}\n\n\\section{Design of Hypothesis Tests}\n\\label{sec:tests}\nIn this section, we construct a series of three binary hypothesis tests to see\nwhether or on what conditions there is a significant difference between the\nposterior and the prior joint distribution of the fading channel and noise.\nThe first test examines whether the posterior data and noise samples follow the same\ngeneral type of distributions as the Rician channel and CSCG noise, i.e. whether\n$\\mathbf{x}$ follows Multi-Variate Normal (MVN) distribution. Once the MVN\ndistribution is verified, the likelihood of $\\mathbf{X}$ can be evaluated,\ntherefore a second test could further verify whether the distribution of\n$\\mathbf{x}$ is exactly the same as the prior distribution, i.e. whether the MVN\nparameters such as the mean and covariance matches those defined for the prior\ndistribution. Should the second test fail, we fall back to a third test, which\nchecks whether the distribution of $\\mathbf{x}$ still suggests an i.i.d Rician\nfading channel and CSCG noise model, though with potentially different parameters\n$\\sigma^2$, $K$, $\\beta$ and $\\theta$ from the prior distribution. If so, the ML estimation of these four parameters could provide some insight into the difference between the\nposterior and prior distributions. These three hypothesis tests are detailed as\nfollows.\n\n\\subsection{Test 1: Multi-Variate Normality (MVN) Test}\nThe first test is literally defined as:\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $K$ is the Rician factor, $\\beta$ is the mean power, and $\\theta$ is the\nphase of the line-of-sight (LOS) component. We also assume that $n^{(m)}$ is\nindependent across different samples and $h^{(m)}$ is independent across different\n(re)transmissions. Assuming all previous $m$ decoding attempt have failed,\nafter the $m$-th retransmission, the receiver makes another decoding attempt by\ncombining the $m + 1$ TBs received so far using a maximum likelihood (ML)\ndetector, until $m > M$ where the HARQ transmission fails.\n\n\\subsection{Data Generation}\nTo analyze the posterior distribution of the fading channels and\nnoises, we generate the channel/noise samples with a LDPC-coded\nsystem~\\cite{hochwald2003achieving}\\cite{valenti2007coded}. We assume that each\nTB contains 1 complete LDPC frame. Another tuning parameter, namely the number of independent fading channels per TB denoted as $N_{IF}$, is added\nto this system in order to test the impact of coherence interval on the\nposterior distribution. As shown in Fig.~\\ref{fig:model}, for different $m$, we\nrandomly generate a set of LDPC sessions, each consists of a encoding bit sequence and the\nfading channel/noise samples corresponding to the $(m+1)$ TBs. The LDPC-decoder\nthen classify the LDPC sessions into two subsets based on whether the receiver\nsends a NACK (decoding failure) or ACK (decoding success) after the $m$-th\nretransmission, which represent the two classes of posterior distributions we\nare interested in.\n\nWithin each TB, the $N_{IF}$ independent fading\nchannel instances are periodically mapped to the $L_s$ symbols. Among the $L_s$\nnoise samples, we randomly sample $N_{IF}$ in such a manner that the\ncorresponding channel samples represent the $N_{IF}$ independent fading\nchannel instances completely. In this way we make sure that the number of\nchannel samples and that of the noise samples are equally $N_{IF}$.\nConsequently, within each failed/successful HARQ session, a total number of\n$(m+1)\\times N_{IF}$ groups of fading channels/noises are sampled. This groups of samples are then zipped across the\n$(m+1)$ (re)transmissions to construct $N_{IF}$ records, each represented as a\n$2(m+1)$-dimensional complex vector, or equivalently a $4(m+1)$-dimensional\nreal vector, in the form of\n\n", "index": 5, "text": "\\begin{align}\n  \\mathbf{x} = \\left[\\Re\\{\\mathbf{h}^{(m)}\\}; \\Im\\{\\mathbf{h}^{(m)}\\}; \n  \\Re\\{\\mathbf{n}^{(m)}\\}; \\Im\\{\\mathbf{n}^{(m)}\\}\\right]\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{x}=\\left[\\Re\\{\\mathbf{h}^{(m)}\\};\\Im\\{\\mathbf{h}^{(m)}\\};%&#10;\\Re\\{\\mathbf{n}^{(m)}\\};\\Im\\{\\mathbf{n}^{(m)}\\}\\right]\" display=\"inline\"><mrow><mi>\ud835\udc31</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi mathvariant=\"normal\">\u211c</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><msup><mi>\ud835\udc21</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">}</mo></mrow></mrow><mo>;</mo><mrow><mi mathvariant=\"normal\">\u2111</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><msup><mi>\ud835\udc21</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">}</mo></mrow></mrow><mo>;</mo><mrow><mi mathvariant=\"normal\">\u211c</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><msup><mi>\ud835\udc27</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">}</mo></mrow></mrow><mo>;</mo><mrow><mi mathvariant=\"normal\">\u2111</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><msup><mi>\ud835\udc27</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">}</mo></mrow></mrow><mo>]</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nHere we do not make any assumptions on the mean and covariance matrix of\n$\\mathbf{x}$. As there are a wide variety of MVN tests with different\ncharacteristics~\\cite{mecklin2005monte} which may well reach contradictory\nconclusions over a same dataset, we adopt the the R package\n`MVN'~\\cite{korkmaz2014mvn} which implements three popular MVN tests,\nnamely Mardia's test, Henze-Zirkler(HZ)'s test and Royston's test.\n\n\\subsection{Test 2: Parameter Matching Test}\nIf Test 1 accept the null hypothesis $H_0$, we can\nperform a second test to see whether $\\mathbf{x}$ has an identical distribution\nas the prior assumption. Specifically, assuming that $\\mathbf{x}$ is MVN\ndistributed,\n\n", "itemtype": "equation", "pos": 13749, "prevtext": " \nwhere $\\mathbf{h}^{(m)} = [h^{(0)},\\ldots,h^{(m)}]$, $\\mathbf{n}^{(m)} =\n[n^{(0)},\\ldots,n^{(m)}]$.\n\nIn the next section, we carry out our hypothesis\ntests over a dataset of $n$ records of $\\mathbf{x}$, which is organized into a $4(m+1)$-by-$n$ matrix\n$\\mathbf{X} = [\\mathbf{x}_1, \\ldots, \\mathbf{x}_n]$. For notational convenience\nwe also decompose $X$ into four $(m+1)$-by-$n$ block matrices, i.e.\n$\\mathbf{X} = [\\mathbf{X}_{h,R}; \\mathbf{X}_{h,I}; \\mathbf{X}_{n, R};\n\\mathbf{X}_{n, I}]$, which represent the real and imaginary part of the channel\nand noise samples, respectively.\n\n\\begin{figure}[!t]\n  \\centering\n  \\includegraphics[width=4.0in]{data.eps}\n  \\caption{The generation of datasets for the analysis on the posterior\n  distribution of the fading channels and noises.}\n  \\label{fig:model}\n\\end{figure}\n\n\\section{Design of Hypothesis Tests}\n\\label{sec:tests}\nIn this section, we construct a series of three binary hypothesis tests to see\nwhether or on what conditions there is a significant difference between the\nposterior and the prior joint distribution of the fading channel and noise.\nThe first test examines whether the posterior data and noise samples follow the same\ngeneral type of distributions as the Rician channel and CSCG noise, i.e. whether\n$\\mathbf{x}$ follows Multi-Variate Normal (MVN) distribution. Once the MVN\ndistribution is verified, the likelihood of $\\mathbf{X}$ can be evaluated,\ntherefore a second test could further verify whether the distribution of\n$\\mathbf{x}$ is exactly the same as the prior distribution, i.e. whether the MVN\nparameters such as the mean and covariance matches those defined for the prior\ndistribution. Should the second test fail, we fall back to a third test, which\nchecks whether the distribution of $\\mathbf{x}$ still suggests an i.i.d Rician\nfading channel and CSCG noise model, though with potentially different parameters\n$\\sigma^2$, $K$, $\\beta$ and $\\theta$ from the prior distribution. If so, the ML estimation of these four parameters could provide some insight into the difference between the\nposterior and prior distributions. These three hypothesis tests are detailed as\nfollows.\n\n\\subsection{Test 1: Multi-Variate Normality (MVN) Test}\nThe first test is literally defined as:\n\n", "index": 7, "text": "\\begin{align}\n  \\mbox{(Test 1) } \\begin{array}{ll}H_0: & \\mathbf{x}\\mbox{ follows MVN\n  distribution.} \\\\ H_1: & \\mbox{Otherwise.} \\end{array}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mbox{(Test 1) }\\begin{array}[]{ll}H_{0}:&amp;\\mathbf{x}\\mbox{ %&#10;follows MVN&#10;distribution.}\\\\&#10;H_{1}:&amp;\\mbox{Otherwise.}\\end{array}\" display=\"inline\"><mrow><mtext>(Test 1)\u00a0</mtext><mo>\u2062</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>\ud835\udc31</mi><mo>\u2062</mo><mtext>\u00a0follows MVN\ndistribution.</mtext></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mtext>Otherwise.</mtext></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere\n\\begin{subequations}\n  \n", "itemtype": "equation", "pos": 14582, "prevtext": "\nHere we do not make any assumptions on the mean and covariance matrix of\n$\\mathbf{x}$. As there are a wide variety of MVN tests with different\ncharacteristics~\\cite{mecklin2005monte} which may well reach contradictory\nconclusions over a same dataset, we adopt the the R package\n`MVN'~\\cite{korkmaz2014mvn} which implements three popular MVN tests,\nnamely Mardia's test, Henze-Zirkler(HZ)'s test and Royston's test.\n\n\\subsection{Test 2: Parameter Matching Test}\nIf Test 1 accept the null hypothesis $H_0$, we can\nperform a second test to see whether $\\mathbf{x}$ has an identical distribution\nas the prior assumption. Specifically, assuming that $\\mathbf{x}$ is MVN\ndistributed,\n\n", "index": 9, "text": "\\begin{align}\n  \\mbox{(Test 2) } \\begin{array}{ll}H_0: & \\mathbf{x}\\sim\n  \\mathcal{N}(\\bm{\\mu}_0, \\mathbf{\\Sigma}_0) \\\\ H_1: &\n  \\mbox{Otherwise.}\n  \\end{array}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mbox{(Test 2) }\\begin{array}[]{ll}H_{0}:&amp;\\mathbf{x}\\sim\\mathcal{%&#10;N}(\\bm{\\mu}_{0},\\mathbf{\\Sigma}_{0})\\\\&#10;H_{1}:&amp;\\mbox{Otherwise.}\\end{array}\" display=\"inline\"><mrow><mtext>(Test 2)\u00a0</mtext><mo>\u2062</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>\ud835\udc31</mi><mo>\u223c</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udf41</mi><mn>0</mn></msub><mo>,</mo><msub><mi>\ud835\udeba</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mtext>Otherwise.</mtext></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": ".\n  \\label{eq:mu0Sigma0}\n\\end{subequations}\n\n\nThe following proposition reduces Test 2 into a chi-squared test:\n\\begin{proposition}\n  \\label{prop:test2}\n  Test 2 is equivalent to the following hypothesis test:\n  \n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere\n\\begin{subequations}\n  \n", "index": 11, "text": "\\begin{align}\n    \\bm{\\mu}_0 & =\n    \\left[\\sqrt{\\frac{K}{K+1}\\beta}\\cos\\theta\\mathbf{1}_{(m+1)};\n    \\sqrt{\\frac{K}{K+1}\\beta}\\sin\\theta\\mathbf{1}_{(m+1)};\n    \\mathbf{0}_{2(m+1)}\\right]\n    \\\\\n    \\mathbf{\\Sigma}_0 & =\n    \\mbox{diag}\\left(\\left[\\frac{\\beta}{2(K+1)}\\mathbf{1}_{2(m+1)},\n    \\frac{\\sigma^2}{2}\\mathbf{1}_{2(m+1)}\\right]\\right) \n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\bm{\\mu}_{0}\" display=\"inline\"><msub><mi>\ud835\udf41</mi><mn>0</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left[\\sqrt{\\frac{K}{K+1}\\beta}\\cos\\theta\\mathbf{1}_{(m+1)};%&#10;\\sqrt{\\frac{K}{K+1}\\beta}\\sin\\theta\\mathbf{1}_{(m+1)};\\mathbf{0}_{2(m+1)}\\right]\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo>[</mo><mrow><msqrt><mrow><mstyle displaystyle=\"true\"><mfrac><mi>K</mi><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow></mfrac></mstyle><mo>\u2062</mo><mi>\u03b2</mi></mrow></msqrt><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msub></mrow></mrow></mrow><mo>;</mo><mrow><msqrt><mrow><mstyle displaystyle=\"true\"><mfrac><mi>K</mi><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow></mfrac></mstyle><mo>\u2062</mo><mi>\u03b2</mi></mrow></msqrt><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msub></mrow></mrow></mrow><mo>;</mo><msub><mn/><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>]</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{\\Sigma}_{0}\" display=\"inline\"><msub><mi>\ud835\udeba</mi><mn>0</mn></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\mbox{diag}\\left(\\left[\\frac{\\beta}{2(K+1)}\\mathbf{1}_{2(m+1)},%&#10;\\frac{\\sigma^{2}}{2}\\mathbf{1}_{2(m+1)}\\right]\\right)\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mtext>diag</mtext><mo>\u2062</mo><mrow><mo>(</mo><mrow><mo>[</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>\u03b2</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>,</mo><mrow><mstyle displaystyle=\"true\"><mfrac><msup><mi>\u03c3</mi><mn>2</mn></msup><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msub></mrow><mo>]</mo></mrow><mo>)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  as $n\\rightarrow\\infty$, where\n  \n", "itemtype": "equation", "pos": 15355, "prevtext": ".\n  \\label{eq:mu0Sigma0}\n\\end{subequations}\n\n\nThe following proposition reduces Test 2 into a chi-squared test:\n\\begin{proposition}\n  \\label{prop:test2}\n  Test 2 is equivalent to the following hypothesis test:\n  \n", "index": 13, "text": "\\begin{align}\n    \\mbox{(Test 2(W)) } \\begin{array}{ll}H_0: & -2\\ln(\\Lambda_2) \\sim\n    \\chi_{2(m+1)(4m+7)}^2 \\\\ H_1: & \\mbox{Otherwise.}\n    \\end{array}\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mbox{(Test 2(W)) }\\begin{array}[]{ll}H_{0}:&amp;-2\\ln(\\Lambda_{2})%&#10;\\sim\\chi_{2(m+1)(4m+7)}^{2}\\\\&#10;H_{1}:&amp;\\mbox{Otherwise.}\\end{array}\" display=\"inline\"><mrow><mtext>(Test 2(W))\u00a0</mtext><mo>\u2062</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>\u223c</mo><msubsup><mi>\u03c7</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>4</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>+</mo><mn>7</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mn>2</mn></msubsup></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mtext>Otherwise.</mtext></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  in which $\\hat{\\bm{\\Sigma}}$, $\\hat{\\bm{\\mu}}$ are the ML estimation of the\n  covariance matrix and mean of $\\mathbf{x}$ from $\\mathbf{X}$, respectively.\n\\end{proposition}\n\\begin{proof}\n  See Appendix.\n\\end{proof}\n\n\\subsection{Test 3: Relaxed Parameter Matching Test}\nIf Test 1 suggests that $\\mathbf{x}$ follows MVN\ndistribution, but Test 2 suggests that it is not identical to\nthe prior distribution, one would wonder whether the distribution of\n$\\mathbf{x}$ is still in a manageable form. A natural ``guess'' is that in this\nposterior distribution, the channels and noises across the $(m+1)$\n(re)transmissions are still i.i.d Rician fading and CSCG distributed,\nrespectively, except that the parameters $\\sigma^2$, $K$, $\\beta$ and $\\theta$\nare different from the prior distribution. In that case, we can examine the\nML estimation of these parameters to see how different they are\nfrom the prior assumption, and whether certain applications are robust against\nthis parameter mismatch between the posterior and prior distribution. This test\nis formulated as follows. Assuming that $\\mathbf{x}$ is MVN distributed,\n\n", "itemtype": "equation", "pos": 15558, "prevtext": "\n  as $n\\rightarrow\\infty$, where\n  \n", "index": 15, "text": "\\begin{align}\n    -2\\ln(\\Lambda_2) & =\n    2n(m+1)\\ln\\left(\\frac{\\beta\\sigma^2}{4(K+1)}\\right)\n    +\n    \\frac{2(K+1)(\\|\\mathbf{X}_{h,R}\\|_F^2 + \\|\\mathbf{X}_{h,I}\\|_F^2)}{\\beta}\n    \\notag \\\\ &+\n    \\frac{2(\\|\\mathbf{X}_{n,R}\\|_F^2 + \\|\\mathbf{X}_{n,I}\\|_F^2)}{\\sigma^2}\n    - n\\ln|\\hat{\\mathbf{\\Sigma}}| - 4n(m+1)\\\\\n    \\hat{\\mathbf{\\Sigma}} & = \\frac{1}{n}(\\mathbf{X}\n    -\\hat{\\bm{\\mu}}\\mathbf{1}_n^T)(\\mathbf{X}\n    -\\hat{\\bm{\\mu}}\\mathbf{1}_n^T)^T,\\;\\hat{\\bm{\\mu}} =\n    \\frac{1}{n}\\mathbf{X}\\mathbf{1}_n,\\label{eq:sigma_mu_ml}\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-2\\ln(\\Lambda_{2})\" display=\"inline\"><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=2n(m+1)\\ln\\left(\\frac{\\beta\\sigma^{2}}{4(K+1)}\\right)+\\frac{2(K+%&#10;1)(\\|\\mathbf{X}_{h,R}\\|_{F}^{2}+\\|\\mathbf{X}_{h,I}\\|_{F}^{2})}{\\beta}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b2</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow><mrow><mn>4</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mi>\u03b2</mi></mfrac></mstyle></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\frac{2(\\|\\mathbf{X}_{n,R}\\|_{F}^{2}+\\|\\mathbf{X}_{n,I}\\|_{F}^{2%&#10;})}{\\sigma^{2}}-n\\ln|\\hat{\\mathbf{\\Sigma}}|-4n(m+1)\" display=\"inline\"><mrow><mrow><mo>+</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msup><mi>\u03c3</mi><mn>2</mn></msup></mfrac></mstyle></mrow><mo>-</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>-</mo><mrow><mn>4</mn><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\mathbf{\\Sigma}}\" display=\"inline\"><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{n}(\\mathbf{X}-\\hat{\\bm{\\mu}}\\mathbf{1}_{n}^{T})(\\mathbf%&#10;{X}-\\hat{\\bm{\\mu}}\\mathbf{1}_{n}^{T})^{T},\\;\\hat{\\bm{\\mu}}=\\frac{1}{n}\\mathbf{%&#10;X}\\mathbf{1}_{n},\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>n</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc17</mi><mo>-</mo><mrow><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>T</mi></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc17</mi><mo>-</mo><mrow><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>T</mi></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>n</mi></mfrac></mstyle><mo>\u2062</mo><msub><mi>\ud835\udc17\ud835\udfcf</mi><mi>n</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere $\\tilde{\\bm{\\mu}}_0$ and $\\tilde{\\mathbf{\\Sigma}}_0$ are defined as in\nEq.~\\eqref{eq:mu0Sigma0} with $\\sigma^2$, $K$, $\\beta$, $\\theta$ replaced by\nunknown parameters $\\tilde{\\sigma}^2$, $\\tilde{K}$, $\\tilde{\\beta}$ and\n$\\tilde{\\theta}$, respectively.\n\nSimilar to Proposition~\\ref{prop:test2}, the following proposition reduces Test\n3 to a chi-squared test:\n\\begin{proposition}\n  \\label{prop:test3}\n  Test 3 is equivalent to the following hypothesis test:\n  \n", "itemtype": "equation", "pos": 17224, "prevtext": "\n  in which $\\hat{\\bm{\\Sigma}}$, $\\hat{\\bm{\\mu}}$ are the ML estimation of the\n  covariance matrix and mean of $\\mathbf{x}$ from $\\mathbf{X}$, respectively.\n\\end{proposition}\n\\begin{proof}\n  See Appendix.\n\\end{proof}\n\n\\subsection{Test 3: Relaxed Parameter Matching Test}\nIf Test 1 suggests that $\\mathbf{x}$ follows MVN\ndistribution, but Test 2 suggests that it is not identical to\nthe prior distribution, one would wonder whether the distribution of\n$\\mathbf{x}$ is still in a manageable form. A natural ``guess'' is that in this\nposterior distribution, the channels and noises across the $(m+1)$\n(re)transmissions are still i.i.d Rician fading and CSCG distributed,\nrespectively, except that the parameters $\\sigma^2$, $K$, $\\beta$ and $\\theta$\nare different from the prior distribution. In that case, we can examine the\nML estimation of these parameters to see how different they are\nfrom the prior assumption, and whether certain applications are robust against\nthis parameter mismatch between the posterior and prior distribution. This test\nis formulated as follows. Assuming that $\\mathbf{x}$ is MVN distributed,\n\n", "index": 17, "text": "\\begin{align}\n  \\mbox{(Test 3) } \\begin{array}{ll}H_0: & \\mathbf{x}\\sim\n  \\mathcal{N}(\\tilde{\\bm{\\mu}}_0, \\tilde{\\mathbf{\\Sigma}}_0)\n  \\\\\n  H_1:\n  &\n  \\mbox{Otherwise.}\n  \\end{array}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mbox{(Test 3) }\\begin{array}[]{ll}H_{0}:&amp;\\mathbf{x}\\sim\\mathcal{%&#10;N}(\\tilde{\\bm{\\mu}}_{0},\\tilde{\\mathbf{\\Sigma}}_{0})\\\\&#10;H_{1}:&amp;\\mbox{Otherwise.}\\end{array}\" display=\"inline\"><mrow><mtext>(Test 3)\u00a0</mtext><mo>\u2062</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>\ud835\udc31</mi><mo>\u223c</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">~</mo></mover><mn>0</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">~</mo></mover><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mtext>Otherwise.</mtext></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  as $n\\rightarrow\\infty$, where\n  \n", "itemtype": "equation", "pos": 17883, "prevtext": "\nwhere $\\tilde{\\bm{\\mu}}_0$ and $\\tilde{\\mathbf{\\Sigma}}_0$ are defined as in\nEq.~\\eqref{eq:mu0Sigma0} with $\\sigma^2$, $K$, $\\beta$, $\\theta$ replaced by\nunknown parameters $\\tilde{\\sigma}^2$, $\\tilde{K}$, $\\tilde{\\beta}$ and\n$\\tilde{\\theta}$, respectively.\n\nSimilar to Proposition~\\ref{prop:test2}, the following proposition reduces Test\n3 to a chi-squared test:\n\\begin{proposition}\n  \\label{prop:test3}\n  Test 3 is equivalent to the following hypothesis test:\n  \n", "index": 19, "text": "\\begin{align}\n    \\mbox{(Test 3(W)) } \\begin{array}{ll}H_0: & -2\\ln(\\Lambda_3) \\sim\n    \\chi_{2(m+1)(4m+7)-4}^2 \\\\ H_1: & \\mbox{Otherwise.}\n    \\end{array}\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mbox{(Test 3(W)) }\\begin{array}[]{ll}H_{0}:&amp;-2\\ln(\\Lambda_{3})%&#10;\\sim\\chi_{2(m+1)(4m+7)-4}^{2}\\\\&#10;H_{1}:&amp;\\mbox{Otherwise.}\\end{array}\" display=\"inline\"><mrow><mtext>(Test 3(W))\u00a0</mtext><mo>\u2062</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>0</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>\u223c</mo><msubsup><mi>\u03c7</mi><mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>4</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>+</mo><mn>7</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mn>4</mn></mrow><mn>2</mn></msubsup></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>:</mo><mi/></mrow></mtd><mtd columnalign=\"left\"><mtext>Otherwise.</mtext></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  in which\n  \n", "itemtype": "equation", "pos": 18088, "prevtext": "\n  as $n\\rightarrow\\infty$, where\n  \n", "index": 21, "text": "\\begin{align}\n    -2\\ln(\\Lambda_3) & =\n    2n(m+1)\\ln\\left(\\frac{\\hat{\\beta} \\hat{\\sigma}^2} {4(\\hat{K}+1)}\\right) -\n    n\\ln|\\hat{\\mathbf{\\Sigma}}|\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-2\\ln(\\Lambda_{3})\" display=\"inline\"><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=2n(m+1)\\ln\\left(\\frac{\\hat{\\beta}\\hat{\\sigma}^{2}}{4(\\hat{K}+1)}%&#10;\\right)-n\\ln|\\hat{\\mathbf{\\Sigma}}|\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mover accent=\"true\"><mi>\u03b2</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msup></mrow><mrow><mn>4</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>K</mi><mo stretchy=\"false\">^</mo></mover><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>-</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  are the ML estimation of $\\tilde{\\sigma}^2$, $\\tilde{K}$, $\\tilde{\\beta}$ and\n  $\\tilde{\\theta}$, respectively. The sample mean of the real and imaginary part\n  and the sample variance of $h$ are evaluated as\n  \\begin{subequations}\n    \n", "itemtype": "equation", "pos": 18264, "prevtext": "\n  in which\n  \n", "index": 23, "text": "\\begin{align}\n    \\hat{\\sigma}^2 = \\frac{\\|\\mathbf{X}_{n,R}\\|_F^2 +\n    \\|\\mathbf{X}_{n,I}\\|_F^2}{n(m+1)} ,\\; \n    \\hat{K} = \\frac{\\bar{h}_R^2 + \\bar{h}_I^2}{\\bar{\\sigma}^2_h},\\;\n    \\hat{\\beta} = (\\hat{K} + 1)\\bar{\\sigma}^2_h ,\\;\n    \\hat{\\theta} =\n    \\arctan\\frac{\\bar{h}_I}{\\bar{h}_R}, \\label{eq:beta_sigma_ml}\n  \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\hat{\\sigma}^{2}=\\frac{\\|\\mathbf{X}_{n,R}\\|_{F}^{2}+\\|\\mathbf{X}_%&#10;{n,I}\\|_{F}^{2}}{n(m+1)},\\;\\hat{K}=\\frac{\\bar{h}_{R}^{2}+\\bar{h}_{I}^{2}}{\\bar%&#10;{\\sigma}^{2}_{h}},\\;\\hat{\\beta}=(\\hat{K}+1)\\bar{\\sigma}^{2}_{h},\\;\\hat{\\theta}%&#10;=\\arctan\\frac{\\bar{h}_{I}}{\\bar{h}_{R}},\" display=\"inline\"><mrow><mrow><mrow><msup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msup><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mrow><mover accent=\"true\"><mi>K</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>R</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>I</mi><mn>2</mn></msubsup></mrow><msubsup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>h</mi><mn>2</mn></msubsup></mfrac></mstyle></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mrow><mover accent=\"true\"><mi>\u03b2</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>K</mi><mo stretchy=\"false\">^</mo></mover><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>h</mi><mn>2</mn></msubsup></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mover accent=\"true\"><mi>\u03b8</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mi>arctan</mi><mo>\u2061</mo><mstyle displaystyle=\"true\"><mfrac><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>I</mi></msub><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>R</mi></msub></mfrac></mstyle></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n  \\end{subequations}\n\\end{proposition}\n\\begin{proof}\n  See Appendix.\n\\end{proof}\n\n\\section{Numerical Results}\n\\label{sec:numerical}\n\n\\subsection{Simulation Settings}\nIn our simulation, the Rician channel is specified with $\\beta = 8$, $K = 1$ and\n$\\theta = 0$. Each LDPC code word of length $L=2400$ is mapped to 64-QAM\nconstellation with the same Gray mapping for all (re)transmissions, therefore\neach TB consists of $L_s = 400$ symbols. The posterior fading channel and noise\ndistribution is analyzed at $N_{IF} = 400, 100, 10, 1$ and $m = 0, 1, 2, 3$. For\neach pair of $(N_{IF}, m)$, we choose $\\sigma^2$ such that around 50\\% of HARQ\nsessions fail and randomly generate $n\\approx 10000$ records of $\\mathbf{x}$\nfor both the failed and successful sessions. \n\nThe detailed parameters for each dataset are listed in\nTable~\\ref{tab:settings}.\n\\begin{table}[!t]\n  \\caption{Parameters for each numerically generated dataset.}\n  \\label{tab:settings}\n  \\centering\n  \\begin{tabular}{c|ccccc}\n    \\hline\n    Dataset & $N_{IF}$ & $m$ & $n_{F}$ & $n_{S}$ & $\\sigma^2$ \\\\\n    \\hline\n    1 & 400 & 0 & 10000 & 10000 & 0.13183 \\\\\n    2 & 400 & 1 & 9600  & 10400 & 0.35892 \\\\\n    3 & 400 & 2 & 9600 & 10400 & 0.58479 \\\\\n    4 & 400 & 3 & 9600 & 10400 & 0.84421 \\\\\n    \\hline\n    5 & 100 & 0 & 10100 & 9900 & 0.13552 \\\\\n    6 & 100 & 1 & 10300 & 9700 & 0.37154 \\\\\n    7 & 100 & 2 & 10100 & 9900 & 0.59772 \\\\\n    8 & 100 & 3 & 10200 & 9800 & 0.83946 \\\\\n    \\hline\n    9 & 10 & 0 & 10240 & 9760 & 0.13804 \\\\\n    10 & 10 & 1 & 9980 & 10020 & 0.37154 \\\\\n    11 & 10 & 2 & 9970 & 10030 & 0.60534 \\\\\n    12 & 10 & 3 & 10200 & 9800 & 0.84140 \\\\\n    \\hline\n    13 & 1 & 0 & 10232 & 9768 & 0.18408 \\\\\n    14 & 1 & 1 & 9834 & 10166 & 0.40738 \\\\\n    15 & 1 & 2 & 9915 & 10085 & 0.64565 \\\\\n    16 & 1 & 3 & 9628 & 10372 & 0.86099 \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\subsection{Hypothesis Test Results}\nThe $p$-values of Test 1 over all datasets are shown in Table~\\ref{tab:test1}.\nFor $N_{IF} = 1$, the posterior distribution indeed appears to be of different\ntype from the prior distribution. However, for $N_{IF} = 10, 100, 400$, there is\nstrong evidence indicating that the fading channels and noises still follow MVN\ndistribution. This is especially true for larger $N_{IF}$ (100, 400) where all\nthe three MVN tests support the null hypothesis, and the failed sessions\nin which we are more interested since they are supposed to be used in the\nposterior analysis.\n\nThe $p$-values of Test 2 and Test 3 are shown in Table~\\ref{tab:test23}. As we can see, for larger $N_{IF}$\n (100, 400), Test 2 suggests that the posterior distribution are likely to be\nthe same as the prior distribution. For intermediate $N_{IF} = 10$, although\nTest 2 rejects the null hypothesis, in 3 of the 4 failed sessions Test 3\nindicates that the posterior distribution can be still viewed as independent Rician fading\nchannels and CSCG noises. A closer look at the ML estimation results\nin Table~\\ref{tab:ML} reveals that the posterior $\\hat{\\beta}$ and\n$\\hat{\\theta}$ are almost the same as the prior ones. However, the posterior\nRician channel has smaller $\\hat{\\beta}$ and $\\hat{K}$ for the failed sessions,\nand larger ones for the successful sessions, as compared to the prior\nparameters.\nIn general, this gap increases as $N_{IF}$ and $m$ decreases. Finally, when\n$N_{IF} = 1$, despite the rejection of MVN hypothesis so that Test 2 and Test 3\nare meaningless, the ML estimation in Eq.~\\eqref{eq:beta_sigma_ml} still serves\nas the empirical mean square of the fading channel and the noises. The noise\npower is still almost the same as the prior distribution, while the channel\npower is much smaller and much larger for the failed and successful\nsessions, respectively, than the prior one.\n\n\\begin{table}[!t]\n  \\caption{Test 1: MVN tests. The $p$-values\n  correponding to rejected null hypotheses ($p < 0.01$) are colored red.}\n  \\label{tab:test1}\n  \\centering\n  \\begin{tabular}{c|cc|c|c|cc|c|c}\n    \\hline\n    \\multirow{2}{*}{Dataset}  & \\multicolumn{4}{c|}{Failed sessions} &\n    \\multicolumn{4}{c}{Successful sessions} \\\\\n    \\cline{2-9}\n    & Mardia-skew & Mardia-kurt & HZ & Royston & Mardia-skew & Mardia-kurt & HZ\n    & Royston \\\\\n    \\hline\n    1 & 0.03707 & 0.5945 & 0.1044 &\n    0.09758 & 0.3086 & 0.3285 & 0.1810 &\n    0.5405\n    \\\\\n    2 & 0.2869 & 0.6188 & 0.9854 &\n    0.2496 & 0.7373 & 0.7304 & 0.8650 &\n    0.2439\n    \\\\\n    3 & 0.7019 & 0.05709 & 0.9187 &\n    0.4361 & 0.7523 & 0.1693 & 0.7661 &\n    0.1821\n    \\\\\n    4 & 0.7590 & 0.7925 & 0.5395 &\n    0.2098 & 0.6935 & 0.4394 & 0.9345 & 0.8580\n    \\\\\n    \\hline\n    5 & 0.2720 & 0.1313 & 0.2117 &\n    0.9635 & 0.6373 & 0.7678 & 0.1052 & 0.1444\n    \\\\\n    6 & 0.8645 & 0.2425 & 0.4166 &\n    0.7259 & 0.5645 & 0.7191 & 0.1495 &\n    0.9247 \\\\\n    7 & 0.6248 & 0.9021 & 0.9473 &\n    0.4020 & 0.1583 & 0.7446 & 0.4879 &\n    0.8501\n    \\\\\n    8 & 0.1308 & 0.7417 & 0.8127 &\n    0.1612 & 0.9160 & 0.5376 & 0.3666 &\n    0.3905 \\\\\n    \\hline\n    9 & {\\color{red}}{6.172e-10} & 0.02679 & {\\color{red}}{8.639e-13} &\n    0.01571 & {\\color{red}}{7.459e-20} & 0.04260 & {\\color{red}}{6.661e-16} & {\\color{red}}{2.562e-4} \\\\\n    10 & {\\color{red}}{9.934e-4} & 0.3654 & 0.01845 &\n    0.02896 & {\\color{red}}{7.720e-8} & 0.8683 & {\\color{red}}{2.494e-4} & 0.01850 \\\\\n    11 & 0.3692 & 0.03412 & 0.4131 &\n    0.7423 & 0.1039 & 0.1747 & 0.5589 &\n    0.8595 \\\\\n    12 & 0.6141 & 0.9034 & 0.7274 &\n    0.04015 & 0.8693 & 0.1940 & 0.6021 &\n    0.4035\n    \\\\\n    \\hline\n    13 & {\\color{red}}{1.414e-229} & {\\color{red}}{9.191e-6} & {\\color{red}}{0} & {\\color{red}}{2.753e-27} &\n    {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{1.646e-22} \\\\\n    14 & {\\color{red}}{5.118e-236} & {\\color{red}}{4.239e-8} & {\\color{red}}{0} & {\\color{red}}{2.613e-22} &\n    {\\color{red}}{5.620e-269} & {\\color{red}}{1.800e-7} & {\\color{red}}{0} & {\\color{red}}{3.049e-12}\n    \\\\\n    15 & {\\color{red}}{5.052e-156} & {\\color{red}}{6.174e-10} & {\\color{red}}{0} & {\\color{red}}{2.596e-14} &\n    {\\color{red}}{3.303e-243} & 0.01597 & {\\color{red}}{0} & {\\color{red}}{3.497e-10}\n    \\\\\n    16 & {\\color{red}}{3.235e-131} & {\\color{red}}{3.478e-10} & {\\color{red}}{0} & {\\color{red}}{2.356e-13} &\n    {\\color{red}}{2.006e-173} & 0.9775 & {\\color{red}}{0} & {\\color{red}}{1.130e-6} \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\begin{table}[!t]\n  \\caption{Test 2 and Test 3, parameter matching tests (exact and relaxed).\n  The $p$-values correponding to rejected null hypotheses ($p < 0.01$) are\n  colored red.}\n  \\label{tab:test23}\n  \\centering\n  \\begin{tabular}{c|c|c|c|c}\n    \\hline\n    \\multirow{2}{*}{Dataset} &  \\multicolumn{2}{c|}{Failed sessions} &\n    \\multicolumn{2}{c}{Successful sessions} \\\\\n    \\cline{2-5}\n    & Test 2 & Test 3 & Test 2 & Test 3 \\\\\n    \\hline\n    1 & 0.1350 & 0.2781 & 0.04330 & 0.3123 \\\\\n    2 & 0.1614 & 0.5014 & 0.9206 & 0.9258 \\\\\n    3 & 0.1125 & 0.1436 & 0.1333 & 0.2081 \\\\\n    4 & 0.4806 & 0.4941 & 0.9758 & 0.9734 \\\\\n    \\hline\n    5 & 0.01253 & 0.04575 & {\\color{red}}{1.358e-11} & {\\color{red}}{7.713e-3} \\\\\n    6 & 0.06204 & 0.3005 & 0.02778 & 0.6205 \\\\\n    7 & 0.2207 & 0.6941 & 0.3504 & 0.7882 \\\\\n    8 & 0.4434 & 0.9241 & 0.01312 & 0.2772 \\\\\n    \\hline\n    9 & {\\color{red}}{0} & {\\color{red}}{5.236e-4} & {\\color{red}}{0} & {\\color{red}}{6.890e-10} \\\\\n    10 & {\\color{red}}{0} & 0.02033 & {\\color{red}}{0} & {\\color{red}}{1.264e-5} \\\\\n    11 & {\\color{red}}{0} & 0.3848 & {\\color{red}}{0} & {\\color{red}}{6.695e-8} \\\\\n    12 & {\\color{red}}{0} & 0.3573 & {\\color{red}}{0} & {\\color{red}}{6.697e-3} \\\\\n    \\hline\n    13 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    14 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    15 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    16 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n\n\\begin{table}[!t]\n  \\caption{The ML estimation of the parameters of Rician channel and CSCG\n  noise from Test 3.}\n  \\label{tab:ML}\n  \\centering\n  \\begin{tabular}{c|cccc|cccc}\n    \\hline\n    \\multirow{2}{*}{Dataset}  & \\multicolumn{4}{c|}{Failed sessions} &\n    \\multicolumn{4}{c}{Successful sessions} \\\\\n    \\cline{2-9}\n    & $\\hat{\\beta}$ & $\\hat{K}$ & $\\hat{\\theta}$ & $\\hat{\\sigma}^2$\n    & $\\hat{\\beta}$ & $\\hat{K}$ & $\\hat{\\theta}$ & $\\hat{\\sigma}^2$ \\\\\n    \\hline\n    1 & 7.830 & 0.9883 & 6.391e-3 &\n    0.1330 & 8.137 & 1.015 & -9.221e-3 & 0.1284\n    \\\\\n    2 & 7.902 & 0.9899 & -6.634e-3 &\n    0.3664 & 8.063 & 1.017 & -2.772e-3 & 0.3572 \\\\\n    3 & 7.936 & 0.9920 & 4.855e-3 &\n    0.5904 & 8.027 & 1.010 & -8.987e-3 & 0.5797\n    \\\\\n    4 & 8.017 & 0.9954 & -6.380e-3 &\n    0.8479 & 8.011 & 1.013 & -1.333e-3 & 0.8468 \\\\\n    \\hline\n    5 & 7.831 & 0.9793 & 1.878e-3 &\n    0.1381 & 8.505 & 1.078 & -3.657e-3 & 0.1336\n    \\\\\n    6 & 7.827 & 0.9952 & -4.889e-3\n    & 0.3733  & 8.232 & 1.017 & -0.01006 & 0.3683\n    \\\\\n    7 & 7.854 & 0.9692 & -3.902e-3 &\n    0.6032 & 8.158 & 1.022 & -7.301e-3 & 0.5987\n    \\\\\n    8 & 7.822 & 0.9765 & -3.594e-3 &\n    0.8413 & 8.194 & 1.035 & 2.162e-4 & 0.8369 \\\\\n    \\hline\n    9 & 6.760 & 0.8111 & -3.474e-3 &\n    0.1418 & 9.262 & 1.261 & 4.441e-3 & 0.1373\n    \\\\\n    10 & 6.965 & 0.8721 & -3.151e-3 &\n    0.3726 & 9.046 & 1.142 & 6.379e-3 & 0.3740\n    \\\\\n    11 & 7.105 & 0.8999 & -2.120e-3 &\n    0.6079 & 8.936 & 1.118 & 1.622e-3 & 0.6039 \\\\\n    12 & 7.240 & 0.9198 & 4.991e-4 &\n    0.8442 & 8.758 & 1.078 & 6.637e-3 & 0.8363 \\\\\n    \\hline\n    13 & 2.958 & 0.6028 & 0.01418 &\n    0.1860 & 13.20 & 2.101 & -5.829e-3 & 0.1876\n    \\\\\n    14 & 4.206 & 0.7147 & -5.320e-3 &\n    0.4027 & 11.67 & 1.522 & -2.713e-3 & 0.4038 \\\\\n    15 & 4.911 & 0.7668 & -3.975e-4 &\n    0.6421 & 11.06 & 1.381 & 2.002e-3 & 0.6428 \\\\\n    16 & 5.247 & 0.7996 & 1.944e-3 &\n    0.8598 & 10.56 & 1.305 & -2.141e-3 & 0.8551 \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\subsection{The Impact of Parameter Mismatch on MoDiv Design}\nFor the intermediate $N_{IF} = 10$, the hypothesis tests results suggest that\nthe difference between the posterior and prior distribution can be viewed\nmostly as a parameter mismatch and the main difference is on the channel power\n$\\beta$ and Rician factor $K$. As an example of how this parameter will affect\ncertain type of application, we consider the Modulation Diversity (MoDiv) design\nproblem in~\\cite{wu2015modulation}\\cite{harvind2005symbol}. we compare the\nMoDiv design based on prior distribution ($\\beta = 8$ and $K = 1$) and that\nbased on an artificial posterior distribution for the failed sessions ($\\beta =\n6.5$ and $K = 0.8$), and compare their actual BER performance over the\nartificial posterior distribution.\nThe simulation results are shown in Fig.~\\ref{fig:mismatch}.\nDespite that the gap in $K$ and $\\beta$ between the two distributions is larger\nthan suggested by Table~\\ref{tab:test23}, there is hardly any difference in BER\nperformance, suggesting that MoDiv design is an application somehow robust\nagainst the difference between the posterior and prior distribution.\n\n\\begin{figure}[htb]\n  \\begin{minipage}[b]{.48\\linewidth}\n    \\centering\n    \\centerline{\\includegraphics[width=7cm]{BER_noise_power_mismatch_montecarlo_64QAM_23.eps}}\n    \\centerline{(a) $m=1,2$}\\medskip\n  \\end{minipage}\n  \\hfill\n  \\begin{minipage}[b]{0.48\\linewidth}\n    \\centering\n    \\centerline{\\includegraphics[width=7cm]{BER_noise_power_mismatch_montecarlo_64QAM_45.eps}}\n    \\centerline{(b) $m=3,4$}\\medskip\n  \\end{minipage}\n  \\caption{The Monte-Carlo simulated uncoded BER for different $m$. NM$m$ and\n  CR$m$ are two benchmark modulation diversity schemes. QAPM$m$ represents the\n  QAP-based MoDiv scheme designed using prior distribution but tested on the\n  posterior distribution, while QAP$m$ represents the QAP-based MoDiv scheme\n  designed and tested on the posterior distribution.}\n  \\label{fig:mismatch}\n\\end{figure}\n\n\\subsection{Remarks}\nThese numerical results demonstrate that, except when $N_{IF}$ is very small,\nthe posterior distribution conditioned on the failure of all previous HARQ\ntransmissions is not so different from the prior distribution, or this\ndifference is too trivial to affect certain type of applications. \nIn many existing works on HARQ, no assumption on $N_{IF}$ or the coherence\ninterval is made except that the channels are independent across\nretransmissions, and no FEC/CRC scheme or transport block structure is\nspecified. Attempt to use the posterior distribution is likely to be unfounded.\nOn the other hand, when we introduce more general, practical assumptions to the\nHARQ systems being studied, it is usually difficult, if not impossible, to\nderive the posterior distribution.\n\n\\section{Conclusion}\n\\label{sec:conclusion}\nThis work investigates the posterior fading channel and noise distribution in\na HARQ system conditioned on the HARQ feedbacks. We design three hypothesis tests,\ndemonstrating with channel and noise samples generated from a practical\nLDPC-coded HARQ system that, unless the coherence interval is large or the\nnumber of independent fading instances per TB is small, the posterior distribution is\nnot so different from the prior distribution, or the difference is so small that\nit has negligible effect on certain types of applications. To some extend, this\nwork justifies the seemingly lax use of prior distribution in many existing\nworks about HARQ.\n\n\\appendix[Proof for Proposition~\\ref{prop:test2} and\nProposition~\\ref{prop:test3}]\n\\label{append:proof}\nThe proof is simply an adoption of Wilks' theorem~\\cite{wilks1938large}. The\nlog-likelihood of observing $\\mathbf{X}$ under MVN distribution\n$\\mathcal{N}(\\bm{\\mu}, \\mathbf{\\Sigma})$ is\n\n", "itemtype": "equation", "pos": 18831, "prevtext": "\n  are the ML estimation of $\\tilde{\\sigma}^2$, $\\tilde{K}$, $\\tilde{\\beta}$ and\n  $\\tilde{\\theta}$, respectively. The sample mean of the real and imaginary part\n  and the sample variance of $h$ are evaluated as\n  \\begin{subequations}\n    \n", "index": 25, "text": "\\begin{align}\n      & \\bar{h}_R =\n      \\frac{\\mathbf{1}_{m+1}^T\\mathbf{X}_{h,R}\\mathbf{1}_n} {n(m+1)} ,\\;\n      \\bar{h}_I = \\frac{\\mathbf{1}_{m+1}^T\\mathbf{X}_{h,I}\\mathbf{1}_n}\n      {n(m+1)},\\\\\n      & \\bar{\\sigma}^2_h = \\frac{\\|\\mathbf{X}_{h,R} -\n      \\bar{h}_R\\mathbf{1}_{m+1}\\mathbf{1}_{n}^T\\|_F^2 +\n      \\|\\mathbf{X}_{h,I} -\n      \\bar{h}_I\\mathbf{1}_{m+1}\\mathbf{1}_{n}^T\\|_F^2}{n(m+1)}\n    \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\bar{h}_{R}=\\frac{\\mathbf{1}_{m+1}^{T}\\mathbf{X}_{h,R}\\mathbf{1}_%&#10;{n}}{n(m+1)},\\;\\bar{h}_{I}=\\frac{\\mathbf{1}_{m+1}^{T}\\mathbf{X}_{h,I}\\mathbf{1%&#10;}_{n}}{n(m+1)},\" display=\"inline\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>R</mi></msub><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mn>\ud835\udfcf</mn><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mi>n</mi></msub></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo rspace=\"5.3pt\">,</mo><mrow><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>I</mi></msub><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mn>\ud835\udfcf</mn><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mi>n</mi></msub></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\bar{\\sigma}^{2}_{h}=\\frac{\\|\\mathbf{X}_{h,R}-\\bar{h}_{R}\\mathbf{%&#10;1}_{m+1}\\mathbf{1}_{n}^{T}\\|_{F}^{2}+\\|\\mathbf{X}_{h,I}-\\bar{h}_{I}\\mathbf{1}_%&#10;{m+1}\\mathbf{1}_{n}^{T}\\|_{F}^{2}}{n(m+1)}\" display=\"inline\"><mrow><msubsup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>h</mi><mn>2</mn></msubsup><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mrow><mo>\u2225</mo><mrow><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>R</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>T</mi></msubsup></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><mrow><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>-</mo><mrow><msub><mover accent=\"true\"><mi>h</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>I</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfcf</mn><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>T</mi></msubsup></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere $C$ is a constant. The parameter space $\\Theta = \\{(\\bm{\\mu},\n\\mathbf{\\Sigma})\\}$ has a dimension of $2(m+1)(4m+7)$. Its supremum\n\n", "itemtype": "equation", "pos": 32945, "prevtext": "\n  \\end{subequations}\n\\end{proposition}\n\\begin{proof}\n  See Appendix.\n\\end{proof}\n\n\\section{Numerical Results}\n\\label{sec:numerical}\n\n\\subsection{Simulation Settings}\nIn our simulation, the Rician channel is specified with $\\beta = 8$, $K = 1$ and\n$\\theta = 0$. Each LDPC code word of length $L=2400$ is mapped to 64-QAM\nconstellation with the same Gray mapping for all (re)transmissions, therefore\neach TB consists of $L_s = 400$ symbols. The posterior fading channel and noise\ndistribution is analyzed at $N_{IF} = 400, 100, 10, 1$ and $m = 0, 1, 2, 3$. For\neach pair of $(N_{IF}, m)$, we choose $\\sigma^2$ such that around 50\\% of HARQ\nsessions fail and randomly generate $n\\approx 10000$ records of $\\mathbf{x}$\nfor both the failed and successful sessions. \n\nThe detailed parameters for each dataset are listed in\nTable~\\ref{tab:settings}.\n\\begin{table}[!t]\n  \\caption{Parameters for each numerically generated dataset.}\n  \\label{tab:settings}\n  \\centering\n  \\begin{tabular}{c|ccccc}\n    \\hline\n    Dataset & $N_{IF}$ & $m$ & $n_{F}$ & $n_{S}$ & $\\sigma^2$ \\\\\n    \\hline\n    1 & 400 & 0 & 10000 & 10000 & 0.13183 \\\\\n    2 & 400 & 1 & 9600  & 10400 & 0.35892 \\\\\n    3 & 400 & 2 & 9600 & 10400 & 0.58479 \\\\\n    4 & 400 & 3 & 9600 & 10400 & 0.84421 \\\\\n    \\hline\n    5 & 100 & 0 & 10100 & 9900 & 0.13552 \\\\\n    6 & 100 & 1 & 10300 & 9700 & 0.37154 \\\\\n    7 & 100 & 2 & 10100 & 9900 & 0.59772 \\\\\n    8 & 100 & 3 & 10200 & 9800 & 0.83946 \\\\\n    \\hline\n    9 & 10 & 0 & 10240 & 9760 & 0.13804 \\\\\n    10 & 10 & 1 & 9980 & 10020 & 0.37154 \\\\\n    11 & 10 & 2 & 9970 & 10030 & 0.60534 \\\\\n    12 & 10 & 3 & 10200 & 9800 & 0.84140 \\\\\n    \\hline\n    13 & 1 & 0 & 10232 & 9768 & 0.18408 \\\\\n    14 & 1 & 1 & 9834 & 10166 & 0.40738 \\\\\n    15 & 1 & 2 & 9915 & 10085 & 0.64565 \\\\\n    16 & 1 & 3 & 9628 & 10372 & 0.86099 \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\subsection{Hypothesis Test Results}\nThe $p$-values of Test 1 over all datasets are shown in Table~\\ref{tab:test1}.\nFor $N_{IF} = 1$, the posterior distribution indeed appears to be of different\ntype from the prior distribution. However, for $N_{IF} = 10, 100, 400$, there is\nstrong evidence indicating that the fading channels and noises still follow MVN\ndistribution. This is especially true for larger $N_{IF}$ (100, 400) where all\nthe three MVN tests support the null hypothesis, and the failed sessions\nin which we are more interested since they are supposed to be used in the\nposterior analysis.\n\nThe $p$-values of Test 2 and Test 3 are shown in Table~\\ref{tab:test23}. As we can see, for larger $N_{IF}$\n (100, 400), Test 2 suggests that the posterior distribution are likely to be\nthe same as the prior distribution. For intermediate $N_{IF} = 10$, although\nTest 2 rejects the null hypothesis, in 3 of the 4 failed sessions Test 3\nindicates that the posterior distribution can be still viewed as independent Rician fading\nchannels and CSCG noises. A closer look at the ML estimation results\nin Table~\\ref{tab:ML} reveals that the posterior $\\hat{\\beta}$ and\n$\\hat{\\theta}$ are almost the same as the prior ones. However, the posterior\nRician channel has smaller $\\hat{\\beta}$ and $\\hat{K}$ for the failed sessions,\nand larger ones for the successful sessions, as compared to the prior\nparameters.\nIn general, this gap increases as $N_{IF}$ and $m$ decreases. Finally, when\n$N_{IF} = 1$, despite the rejection of MVN hypothesis so that Test 2 and Test 3\nare meaningless, the ML estimation in Eq.~\\eqref{eq:beta_sigma_ml} still serves\nas the empirical mean square of the fading channel and the noises. The noise\npower is still almost the same as the prior distribution, while the channel\npower is much smaller and much larger for the failed and successful\nsessions, respectively, than the prior one.\n\n\\begin{table}[!t]\n  \\caption{Test 1: MVN tests. The $p$-values\n  correponding to rejected null hypotheses ($p < 0.01$) are colored red.}\n  \\label{tab:test1}\n  \\centering\n  \\begin{tabular}{c|cc|c|c|cc|c|c}\n    \\hline\n    \\multirow{2}{*}{Dataset}  & \\multicolumn{4}{c|}{Failed sessions} &\n    \\multicolumn{4}{c}{Successful sessions} \\\\\n    \\cline{2-9}\n    & Mardia-skew & Mardia-kurt & HZ & Royston & Mardia-skew & Mardia-kurt & HZ\n    & Royston \\\\\n    \\hline\n    1 & 0.03707 & 0.5945 & 0.1044 &\n    0.09758 & 0.3086 & 0.3285 & 0.1810 &\n    0.5405\n    \\\\\n    2 & 0.2869 & 0.6188 & 0.9854 &\n    0.2496 & 0.7373 & 0.7304 & 0.8650 &\n    0.2439\n    \\\\\n    3 & 0.7019 & 0.05709 & 0.9187 &\n    0.4361 & 0.7523 & 0.1693 & 0.7661 &\n    0.1821\n    \\\\\n    4 & 0.7590 & 0.7925 & 0.5395 &\n    0.2098 & 0.6935 & 0.4394 & 0.9345 & 0.8580\n    \\\\\n    \\hline\n    5 & 0.2720 & 0.1313 & 0.2117 &\n    0.9635 & 0.6373 & 0.7678 & 0.1052 & 0.1444\n    \\\\\n    6 & 0.8645 & 0.2425 & 0.4166 &\n    0.7259 & 0.5645 & 0.7191 & 0.1495 &\n    0.9247 \\\\\n    7 & 0.6248 & 0.9021 & 0.9473 &\n    0.4020 & 0.1583 & 0.7446 & 0.4879 &\n    0.8501\n    \\\\\n    8 & 0.1308 & 0.7417 & 0.8127 &\n    0.1612 & 0.9160 & 0.5376 & 0.3666 &\n    0.3905 \\\\\n    \\hline\n    9 & {\\color{red}}{6.172e-10} & 0.02679 & {\\color{red}}{8.639e-13} &\n    0.01571 & {\\color{red}}{7.459e-20} & 0.04260 & {\\color{red}}{6.661e-16} & {\\color{red}}{2.562e-4} \\\\\n    10 & {\\color{red}}{9.934e-4} & 0.3654 & 0.01845 &\n    0.02896 & {\\color{red}}{7.720e-8} & 0.8683 & {\\color{red}}{2.494e-4} & 0.01850 \\\\\n    11 & 0.3692 & 0.03412 & 0.4131 &\n    0.7423 & 0.1039 & 0.1747 & 0.5589 &\n    0.8595 \\\\\n    12 & 0.6141 & 0.9034 & 0.7274 &\n    0.04015 & 0.8693 & 0.1940 & 0.6021 &\n    0.4035\n    \\\\\n    \\hline\n    13 & {\\color{red}}{1.414e-229} & {\\color{red}}{9.191e-6} & {\\color{red}}{0} & {\\color{red}}{2.753e-27} &\n    {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{1.646e-22} \\\\\n    14 & {\\color{red}}{5.118e-236} & {\\color{red}}{4.239e-8} & {\\color{red}}{0} & {\\color{red}}{2.613e-22} &\n    {\\color{red}}{5.620e-269} & {\\color{red}}{1.800e-7} & {\\color{red}}{0} & {\\color{red}}{3.049e-12}\n    \\\\\n    15 & {\\color{red}}{5.052e-156} & {\\color{red}}{6.174e-10} & {\\color{red}}{0} & {\\color{red}}{2.596e-14} &\n    {\\color{red}}{3.303e-243} & 0.01597 & {\\color{red}}{0} & {\\color{red}}{3.497e-10}\n    \\\\\n    16 & {\\color{red}}{3.235e-131} & {\\color{red}}{3.478e-10} & {\\color{red}}{0} & {\\color{red}}{2.356e-13} &\n    {\\color{red}}{2.006e-173} & 0.9775 & {\\color{red}}{0} & {\\color{red}}{1.130e-6} \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\begin{table}[!t]\n  \\caption{Test 2 and Test 3, parameter matching tests (exact and relaxed).\n  The $p$-values correponding to rejected null hypotheses ($p < 0.01$) are\n  colored red.}\n  \\label{tab:test23}\n  \\centering\n  \\begin{tabular}{c|c|c|c|c}\n    \\hline\n    \\multirow{2}{*}{Dataset} &  \\multicolumn{2}{c|}{Failed sessions} &\n    \\multicolumn{2}{c}{Successful sessions} \\\\\n    \\cline{2-5}\n    & Test 2 & Test 3 & Test 2 & Test 3 \\\\\n    \\hline\n    1 & 0.1350 & 0.2781 & 0.04330 & 0.3123 \\\\\n    2 & 0.1614 & 0.5014 & 0.9206 & 0.9258 \\\\\n    3 & 0.1125 & 0.1436 & 0.1333 & 0.2081 \\\\\n    4 & 0.4806 & 0.4941 & 0.9758 & 0.9734 \\\\\n    \\hline\n    5 & 0.01253 & 0.04575 & {\\color{red}}{1.358e-11} & {\\color{red}}{7.713e-3} \\\\\n    6 & 0.06204 & 0.3005 & 0.02778 & 0.6205 \\\\\n    7 & 0.2207 & 0.6941 & 0.3504 & 0.7882 \\\\\n    8 & 0.4434 & 0.9241 & 0.01312 & 0.2772 \\\\\n    \\hline\n    9 & {\\color{red}}{0} & {\\color{red}}{5.236e-4} & {\\color{red}}{0} & {\\color{red}}{6.890e-10} \\\\\n    10 & {\\color{red}}{0} & 0.02033 & {\\color{red}}{0} & {\\color{red}}{1.264e-5} \\\\\n    11 & {\\color{red}}{0} & 0.3848 & {\\color{red}}{0} & {\\color{red}}{6.695e-8} \\\\\n    12 & {\\color{red}}{0} & 0.3573 & {\\color{red}}{0} & {\\color{red}}{6.697e-3} \\\\\n    \\hline\n    13 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    14 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    15 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    16 & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} & {\\color{red}}{0} \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n\n\\begin{table}[!t]\n  \\caption{The ML estimation of the parameters of Rician channel and CSCG\n  noise from Test 3.}\n  \\label{tab:ML}\n  \\centering\n  \\begin{tabular}{c|cccc|cccc}\n    \\hline\n    \\multirow{2}{*}{Dataset}  & \\multicolumn{4}{c|}{Failed sessions} &\n    \\multicolumn{4}{c}{Successful sessions} \\\\\n    \\cline{2-9}\n    & $\\hat{\\beta}$ & $\\hat{K}$ & $\\hat{\\theta}$ & $\\hat{\\sigma}^2$\n    & $\\hat{\\beta}$ & $\\hat{K}$ & $\\hat{\\theta}$ & $\\hat{\\sigma}^2$ \\\\\n    \\hline\n    1 & 7.830 & 0.9883 & 6.391e-3 &\n    0.1330 & 8.137 & 1.015 & -9.221e-3 & 0.1284\n    \\\\\n    2 & 7.902 & 0.9899 & -6.634e-3 &\n    0.3664 & 8.063 & 1.017 & -2.772e-3 & 0.3572 \\\\\n    3 & 7.936 & 0.9920 & 4.855e-3 &\n    0.5904 & 8.027 & 1.010 & -8.987e-3 & 0.5797\n    \\\\\n    4 & 8.017 & 0.9954 & -6.380e-3 &\n    0.8479 & 8.011 & 1.013 & -1.333e-3 & 0.8468 \\\\\n    \\hline\n    5 & 7.831 & 0.9793 & 1.878e-3 &\n    0.1381 & 8.505 & 1.078 & -3.657e-3 & 0.1336\n    \\\\\n    6 & 7.827 & 0.9952 & -4.889e-3\n    & 0.3733  & 8.232 & 1.017 & -0.01006 & 0.3683\n    \\\\\n    7 & 7.854 & 0.9692 & -3.902e-3 &\n    0.6032 & 8.158 & 1.022 & -7.301e-3 & 0.5987\n    \\\\\n    8 & 7.822 & 0.9765 & -3.594e-3 &\n    0.8413 & 8.194 & 1.035 & 2.162e-4 & 0.8369 \\\\\n    \\hline\n    9 & 6.760 & 0.8111 & -3.474e-3 &\n    0.1418 & 9.262 & 1.261 & 4.441e-3 & 0.1373\n    \\\\\n    10 & 6.965 & 0.8721 & -3.151e-3 &\n    0.3726 & 9.046 & 1.142 & 6.379e-3 & 0.3740\n    \\\\\n    11 & 7.105 & 0.8999 & -2.120e-3 &\n    0.6079 & 8.936 & 1.118 & 1.622e-3 & 0.6039 \\\\\n    12 & 7.240 & 0.9198 & 4.991e-4 &\n    0.8442 & 8.758 & 1.078 & 6.637e-3 & 0.8363 \\\\\n    \\hline\n    13 & 2.958 & 0.6028 & 0.01418 &\n    0.1860 & 13.20 & 2.101 & -5.829e-3 & 0.1876\n    \\\\\n    14 & 4.206 & 0.7147 & -5.320e-3 &\n    0.4027 & 11.67 & 1.522 & -2.713e-3 & 0.4038 \\\\\n    15 & 4.911 & 0.7668 & -3.975e-4 &\n    0.6421 & 11.06 & 1.381 & 2.002e-3 & 0.6428 \\\\\n    16 & 5.247 & 0.7996 & 1.944e-3 &\n    0.8598 & 10.56 & 1.305 & -2.141e-3 & 0.8551 \\\\\n    \\hline\n  \\end{tabular}\n\\end{table}\n  \n\\subsection{The Impact of Parameter Mismatch on MoDiv Design}\nFor the intermediate $N_{IF} = 10$, the hypothesis tests results suggest that\nthe difference between the posterior and prior distribution can be viewed\nmostly as a parameter mismatch and the main difference is on the channel power\n$\\beta$ and Rician factor $K$. As an example of how this parameter will affect\ncertain type of application, we consider the Modulation Diversity (MoDiv) design\nproblem in~\\cite{wu2015modulation}\\cite{harvind2005symbol}. we compare the\nMoDiv design based on prior distribution ($\\beta = 8$ and $K = 1$) and that\nbased on an artificial posterior distribution for the failed sessions ($\\beta =\n6.5$ and $K = 0.8$), and compare their actual BER performance over the\nartificial posterior distribution.\nThe simulation results are shown in Fig.~\\ref{fig:mismatch}.\nDespite that the gap in $K$ and $\\beta$ between the two distributions is larger\nthan suggested by Table~\\ref{tab:test23}, there is hardly any difference in BER\nperformance, suggesting that MoDiv design is an application somehow robust\nagainst the difference between the posterior and prior distribution.\n\n\\begin{figure}[htb]\n  \\begin{minipage}[b]{.48\\linewidth}\n    \\centering\n    \\centerline{\\includegraphics[width=7cm]{BER_noise_power_mismatch_montecarlo_64QAM_23.eps}}\n    \\centerline{(a) $m=1,2$}\\medskip\n  \\end{minipage}\n  \\hfill\n  \\begin{minipage}[b]{0.48\\linewidth}\n    \\centering\n    \\centerline{\\includegraphics[width=7cm]{BER_noise_power_mismatch_montecarlo_64QAM_45.eps}}\n    \\centerline{(b) $m=3,4$}\\medskip\n  \\end{minipage}\n  \\caption{The Monte-Carlo simulated uncoded BER for different $m$. NM$m$ and\n  CR$m$ are two benchmark modulation diversity schemes. QAPM$m$ represents the\n  QAP-based MoDiv scheme designed using prior distribution but tested on the\n  posterior distribution, while QAP$m$ represents the QAP-based MoDiv scheme\n  designed and tested on the posterior distribution.}\n  \\label{fig:mismatch}\n\\end{figure}\n\n\\subsection{Remarks}\nThese numerical results demonstrate that, except when $N_{IF}$ is very small,\nthe posterior distribution conditioned on the failure of all previous HARQ\ntransmissions is not so different from the prior distribution, or this\ndifference is too trivial to affect certain type of applications. \nIn many existing works on HARQ, no assumption on $N_{IF}$ or the coherence\ninterval is made except that the channels are independent across\nretransmissions, and no FEC/CRC scheme or transport block structure is\nspecified. Attempt to use the posterior distribution is likely to be unfounded.\nOn the other hand, when we introduce more general, practical assumptions to the\nHARQ systems being studied, it is usually difficult, if not impossible, to\nderive the posterior distribution.\n\n\\section{Conclusion}\n\\label{sec:conclusion}\nThis work investigates the posterior fading channel and noise distribution in\na HARQ system conditioned on the HARQ feedbacks. We design three hypothesis tests,\ndemonstrating with channel and noise samples generated from a practical\nLDPC-coded HARQ system that, unless the coherence interval is large or the\nnumber of independent fading instances per TB is small, the posterior distribution is\nnot so different from the prior distribution, or the difference is so small that\nit has negligible effect on certain types of applications. To some extend, this\nwork justifies the seemingly lax use of prior distribution in many existing\nworks about HARQ.\n\n\\appendix[Proof for Proposition~\\ref{prop:test2} and\nProposition~\\ref{prop:test3}]\n\\label{append:proof}\nThe proof is simply an adoption of Wilks' theorem~\\cite{wilks1938large}. The\nlog-likelihood of observing $\\mathbf{X}$ under MVN distribution\n$\\mathcal{N}(\\bm{\\mu}, \\mathbf{\\Sigma})$ is\n\n", "index": 27, "text": "\\begin{align}\n  \\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X})) =\n  -\\frac{n}{2}\\ln|\\mathbf{\\Sigma}|-\n  \\frac{1}{2}\\mbox{tr}(\\mathbf{\\Sigma}^{-1}(\\mathbf{X}\n  -\\bm{\\mu}\\mathbf{1}_n^H)(\\mathbf{X} -\\bm{\\mu}\\mathbf{1}_n^H)^H) + C  \n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X}))=-\\frac{n}{2}\\ln|%&#10;\\mathbf{\\Sigma}|-\\frac{1}{2}\\mbox{tr}(\\mathbf{\\Sigma}^{-1}(\\mathbf{X}-\\bm{\\mu}%&#10;\\mathbf{1}_{n}^{H})(\\mathbf{X}-\\bm{\\mu}\\mathbf{1}_{n}^{H})^{H})+C\" display=\"inline\"><mrow><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mn>2</mn></mfrac></mstyle><mi>ln</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mtext>tr</mtext><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udeba</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc17</mi><mo>-</mo><mi>\ud835\udf41</mi><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>H</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc17</mi><mo>-</mo><mi>\ud835\udf41</mi><msubsup><mn>\ud835\udfcf</mn><mi>n</mi><mi>H</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mi>H</mi></msup><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mi>C</mi></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere $\\hat{\\bm{\\mu}}, \\hat{\\mathbf{\\Sigma}}$ are defined in\nEq.~(\\ref{eq:sigma_mu_ml}).\n\nUnder the null hypothesis of Test 2, the parameter space $\\Theta_0^{(T2)}$ has 0\ndimensionality, the supremum of log-likelihood is\n\n", "itemtype": "equation", "pos": 33319, "prevtext": "\nwhere $C$ is a constant. The parameter space $\\Theta = \\{(\\bm{\\mu},\n\\mathbf{\\Sigma})\\}$ has a dimension of $2(m+1)(4m+7)$. Its supremum\n\n", "index": 29, "text": "\\begin{align}\n  \\sup \\{\\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X}))\\} & =\n  \\ln(L(\\hat{\\bm{\\mu}}, \\hat{\\mathbf{\\Sigma}}|\\mathbf{X})) \\notag\\\\\n  & = -\\frac{n}{2}\\ln|\\hat{\\mathbf{\\Sigma}}| - 2n(m+1) + C\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sup\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X}))\\}\" display=\"inline\"><mrow><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\ln(L(\\hat{\\bm{\\mu}},\\hat{\\mathbf{\\Sigma}}|\\mathbf{X}))\" display=\"inline\"><mrow><mo>=</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">^</mo></mover><mo>,</mo><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=-\\frac{n}{2}\\ln|\\hat{\\mathbf{\\Sigma}}|-2n(m+1)+C\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mi>n</mi><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mi>C</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\ntherefore according to Wilks' theorem, as $n\\rightarrow\\infty$ \n\n", "itemtype": "equation", "pos": 33753, "prevtext": "\nwhere $\\hat{\\bm{\\mu}}, \\hat{\\mathbf{\\Sigma}}$ are defined in\nEq.~(\\ref{eq:sigma_mu_ml}).\n\nUnder the null hypothesis of Test 2, the parameter space $\\Theta_0^{(T2)}$ has 0\ndimensionality, the supremum of log-likelihood is\n\n", "index": 31, "text": "\\begin{align}\n  & \\sup \\{\\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\n  \\mathbf{\\Sigma})\\in \\Theta_0^{(T2)}\\} \\notag \\\\\n  = & \\ln(L(\\bm{\\mu}_0,\n  \\mathbf{\\Sigma}_0|\\mathbf{X})) \\notag \\\\\n  = & -n(m+1)\n  \\ln\\left(\\frac{\\beta \\sigma^2}{4(K+1)}\\right) -\n  \\frac{(K+1)(\\|\\mathbf{X}_{h,R}\\|_F^2 + \\|\\mathbf{X}_{h,I}\\|_F^2)}{\\beta} -\n  \\frac{\\|\\mathbf{X}_{n,R}\\|_F^2 + \\|\\mathbf{X}_{n,I}\\|_F^2}{\\sigma^2}\n  + C\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sup\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},%&#10;\\mathbf{\\Sigma})\\in\\Theta_{0}^{(T2)}\\}\" display=\"inline\"><mrow><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\">:</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><msubsup><mi mathvariant=\"normal\">\u0398</mi><mn>0</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>\u2062</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">}</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\" display=\"inline\"><mo>=</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\ln(L(\\bm{\\mu}_{0},\\mathbf{\\Sigma}_{0}|\\mathbf{X}))\" display=\"inline\"><mrow><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udf41</mi><mn>0</mn></msub><mo>,</mo><msub><mi>\ud835\udeba</mi><mn>0</mn></msub><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\" display=\"inline\"><mo>=</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle-n(m+1)\\ln\\left(\\frac{\\beta\\sigma^{2}}{4(K+1)}\\right)-\\frac{(K+1)%&#10;(\\|\\mathbf{X}_{h,R}\\|_{F}^{2}+\\|\\mathbf{X}_{h,I}\\|_{F}^{2})}{\\beta}-\\frac{\\|%&#10;\\mathbf{X}_{n,R}\\|_{F}^{2}+\\|\\mathbf{X}_{n,I}\\|_{F}^{2}}{\\sigma^{2}}+C\" display=\"inline\"><mrow><mrow><mrow><mo>-</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03b2</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow><mrow><mn>4</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow></mrow><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>h</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mi>\u03b2</mi></mfrac></mstyle><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mrow><mo>\u2225</mo><msub><mi>\ud835\udc17</mi><mrow><mi>n</mi><mo>,</mo><mi>I</mi></mrow></msub><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow><msup><mi>\u03c3</mi><mn>2</mn></msup></mfrac></mstyle></mrow><mo>+</mo><mi>C</mi></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n\nUnder the null hypothesis of Test 3, the parameter space $\\Theta_0^{(T3)}$\nhas a dimensionality of 4, the supremum of log-likelihood is\n\n", "itemtype": "equation", "pos": 34247, "prevtext": "\ntherefore according to Wilks' theorem, as $n\\rightarrow\\infty$ \n\n", "index": 33, "text": "\\begin{align}\n  -2\\ln(\\Lambda_2) &= 2\\left(\\sup \\{\\ln(L(\\bm{\\mu},\n  \\mathbf{\\Sigma}|\\mathbf{X}))\\} - \\sup \\{\\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\n  \\mathbf{\\Sigma})\\in \\Theta_0^{(T2)}\\}\\right) \\notag \\\\\n  &\\sim \\chi_{2(m+1)(4m+7)}^2\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-2\\ln(\\Lambda_{2})\" display=\"inline\"><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=2\\left(\\sup\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X}))\\}-\\sup%&#10;\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\\mathbf{\\Sigma})\\in%&#10;\\Theta_{0}^{(T2)}\\}\\right)\" display=\"inline\"><mrow><mo>=</mo><mn>2</mn><mrow><mo>(</mo><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mo>-</mo><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\">:</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><msubsup><mi mathvariant=\"normal\">\u0398</mi><mn>0</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>\u2062</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">}</mo></mrow><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\chi_{2(m+1)(4m+7)}^{2}\" display=\"inline\"><mrow><mi/><mo>\u223c</mo><msubsup><mi>\u03c7</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>4</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>+</mo><mn>7</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mn>2</mn></msubsup></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\nwhere $\\hat{\\bm{\\mu}}_0 $, $\\hat{\\mathbf{\\Sigma}}_0 $ are defined as in\nEq.~\\eqref{eq:mu0Sigma0} with $\\sigma^2$, $K$, $\\beta$, $\\theta$ replaced by\nthe ML estimation $\\hat{\\sigma}^2$, $\\hat{K}$,\n$\\hat{\\beta}$, $\\hat{\\theta}$, respectively. Similar to the case of Test 2,\nas $n\\rightarrow\\infty$\n\n", "itemtype": "equation", "pos": 34649, "prevtext": "\n\nUnder the null hypothesis of Test 3, the parameter space $\\Theta_0^{(T3)}$\nhas a dimensionality of 4, the supremum of log-likelihood is\n\n", "index": 35, "text": "\\begin{align}\n  & \\sup \\{\\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\n  \\mathbf{\\Sigma})\\in \\Theta_0^{(T3)}\\} \\notag \\\\\n  = & \\ln(L(\\hat{\\bm{\\mu}}_0,\n  \\hat{\\mathbf{\\Sigma}}_0|\\mathbf{X})) \\notag \\\\\n  = & -n(m+1)\\ln\\left(\\frac{\\hat{\\beta} \\hat{\\sigma}^2} {4(\\hat{K}+1)}\\right) -\n    2n(m+1) + C\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sup\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},%&#10;\\mathbf{\\Sigma})\\in\\Theta_{0}^{(T3)}\\}\" display=\"inline\"><mrow><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\">:</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><msubsup><mi mathvariant=\"normal\">\u0398</mi><mn>0</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>\u2062</mo><mn>3</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">}</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\" display=\"inline\"><mo>=</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\ln(L(\\hat{\\bm{\\mu}}_{0},\\hat{\\mathbf{\\Sigma}}_{0}|\\mathbf{X}))\" display=\"inline\"><mrow><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>\ud835\udf41</mi><mo stretchy=\"false\">^</mo></mover><mn>0</mn></msub><mo>,</mo><msub><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">^</mo></mover><mn>0</mn></msub><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\" display=\"inline\"><mo>=</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle-n(m+1)\\ln\\left(\\frac{\\hat{\\beta}\\hat{\\sigma}^{2}}{4(\\hat{K}+1)}%&#10;\\right)-2n(m+1)+C\" display=\"inline\"><mrow><mrow><mrow><mo>-</mo><mrow><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mover accent=\"true\"><mi>\u03b2</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><msup><mover accent=\"true\"><mi>\u03c3</mi><mo stretchy=\"false\">^</mo></mover><mn>2</mn></msup></mrow><mrow><mn>4</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>K</mi><mo stretchy=\"false\">^</mo></mover><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow></mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mi>C</mi></mrow></math>", "type": "latex"}, {"file": "1601.04131.tex", "nexttext": "\n\\bibliographystyle{IEEEtran}\n\n\\bibliography{IEEEabrv,./refs.bib}\n\n\n\n\n", "itemtype": "equation", "pos": 35265, "prevtext": "\nwhere $\\hat{\\bm{\\mu}}_0 $, $\\hat{\\mathbf{\\Sigma}}_0 $ are defined as in\nEq.~\\eqref{eq:mu0Sigma0} with $\\sigma^2$, $K$, $\\beta$, $\\theta$ replaced by\nthe ML estimation $\\hat{\\sigma}^2$, $\\hat{K}$,\n$\\hat{\\beta}$, $\\hat{\\theta}$, respectively. Similar to the case of Test 2,\nas $n\\rightarrow\\infty$\n\n", "index": 37, "text": "\\begin{align}\n  -2\\ln(\\Lambda_3) &= 2\\left(\\sup \\{\\ln(L(\\bm{\\mu},\n  \\mathbf{\\Sigma}|\\mathbf{X}))\\} - \\sup \\{\\ln(L(\\bm{\\mu}, \\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\n  \\mathbf{\\Sigma})\\in \\Theta_0^{(T3)}\\}\\right) \\notag \\\\\n  &\\sim \\chi_{2(m+1)(4m+7) - 4}^2\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-2\\ln(\\Lambda_{3})\" display=\"inline\"><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u039b</mi><mn>3</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=2\\left(\\sup\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X}))\\}-\\sup%&#10;\\{\\ln(L(\\bm{\\mu},\\mathbf{\\Sigma}|\\mathbf{X})):\\,(\\bm{\\mu},\\mathbf{\\Sigma})\\in%&#10;\\Theta_{0}^{(T3)}\\}\\right)\" display=\"inline\"><mrow><mo>=</mo><mn>2</mn><mrow><mo>(</mo><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mo>-</mo><mo movablelimits=\"false\">sup</mo><mrow><mo stretchy=\"false\">{</mo><mi>ln</mi><mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc17</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"4.2pt\">:</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><msubsup><mi mathvariant=\"normal\">\u0398</mi><mn>0</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>\u2062</mo><mn>3</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">}</mo></mrow><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\chi_{2(m+1)(4m+7)-4}^{2}\" display=\"inline\"><mrow><mi/><mo>\u223c</mo><msubsup><mi>\u03c7</mi><mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>4</mn><mo>\u2062</mo><mi>m</mi></mrow><mo>+</mo><mn>7</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mn>4</mn></mrow><mn>2</mn></msubsup></mrow></math>", "type": "latex"}]