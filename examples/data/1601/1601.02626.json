[{"file": "1601.02626.tex", "nexttext": "\n\nAs illustrated in {Figure~\\ref{{MarkovFig}}}, it is always possible to model this relation between ${\\bf x}_0$ and ${\\bf x}_1$ as resulting from a \nMarkov process, where ${\\bf x}_1$ is causally determined by a combination of ${\\bf x}_0$ and random effects.\nIf we write the marginal distributions from {equation~(\\ref{{MargDistEq}})}\nas vectors ${\\bf p}^{(0)}$ and ${\\bf p}^{(1)}$, this Markov process is defined by\n\n", "itemtype": "equation", "pos": 17139, "prevtext": "\n\\pdfoptionalwaysusepdfpagebox=5\n\n\n\n\\title{Improved Measures of Integrated Information}\n\n\\author{Max Tegmark}\n\n\\address{Dept.~of Physics \\& MIT Kavli Institute, Massachusetts Institute of Technology, Cambridge, MA 02139}\n\\address{Theiss Research, La Jolla, CA 92037}\n\n\n\\date{\\today}\n\n\n\n\n\\vspace{10mm}\n\n\\begin{abstract}\nAlthough there is growing interest in measuring integrated information in computational and cognitive systems, current methods for doing so in practice are computationally unfeasible.\nExisting and novel integration measures are investigated and classified by various desirable properties. \nA simple taxonomy of $\\Phi$-measures is presented where they are each characterized by their choice of factorization method (5 options),  choice of probability distributions to compare ($3\\times 4$ options) and choice of measure for comparing probability distributions (5 options). When requiring the $\\Phi$-measures to satisfy a minimum of attractive properties, these hundreds of options reduce to a mere handful, some of which turn out to be identical.\nUseful exact and approximate formulas are derived that can be applied to real-world data from laboratory experiments without posing unreasonable computational demands.\n\\end{abstract} \n  \n\\maketitle\n\n\\section{Introduction}\n\\label{IntroSec}\n\n\n\nWhat makes an information-processing system conscious in the sense of having a subjective experience?\nAlthough many scientists used to view this topic as beyond the reach of science, the study of Neural Correlates of Consciousness (NCCs) has become quite mainstream in the neuroscience community in recent years --- see, {\\frenchspacing\\it e.g.},  \\cite{rees2002neural,metzinger2000neural}.\nTo move beyond correlation to causation \\cite{chalmers1995facing}, neuroscientists have begun searching for a theory of consciousness that can predict what physical phenomena cause consciousness (defined as subjective experience \\cite{chalmers1995facing}) to occur. Dehaene \\cite{dehaene2014toward} reviews a number of candidate theories currently under active discussion, including the {\\it Nonlinear Ignition} model (NI) \\cite{dehaene2011conscious,shadlen2011consciousness}, \nthe {\\it Global Neuronal Workspace} (GNW) model \n\\cite{dehaene2001towards,shanahan2005applying,dehaene1998neuronal}\nand {\\it Integrated Information Theory} (IIT) \\cite{tononi2008consciousness,oizumi2014phenomenology}.\nRapid progress in artificial intelligence is further fueling interest in such theories and how they can be generalized  \nto apply not only to biological systems, but also to engineered systems such as computers and robots and ultimately arbitrary arrangements of elementary particles \\cite{tegmark2014consciousness}.\n\n\nAlthough there is still no consensus on necessary and sufficient conditions for a physical system to be conscious, there is broad agreement that it needs to be able to store and process information in a way that is somehow {\\it integrated}, \nnot consisting of nearly independent parts. As emphasized by Tononi \\cite{tononi2008consciousness}, it must be impossible to decompose a conscious system into nearly independent parts --- otherwise these parts would feel like two separate conscious entities. \nWhile integration as a {\\it necessary} condition for consciousness is rather uncontroversial, IIT goes further and makes the bold and controversial claim that it is also a {\\it sufficient} condition for consciousness, using an elaborate mathematical integration definition \\cite{oizumi2014phenomenology}.\n\n\n\n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|cccccccccccccc|}\n\\hline\n&\t\t\t\t\t\t\t\t\t\t\t&$\\phi^{2.0}$&$\\phi^{2.0'}$&$\\phi^{2.0''}$&$\\phi^{3.0}$&$\\phi^M$&$\\phi^B$&$\\phi^M_{kk'}$&$\\phi^{oakk}$&$\\phi^{opkk}$&$\\phi^{otsk}$&$\\phi^{ofuk}$&$\\phi^{nask}$&$\\phi^{mask}$&$\\phi^{xfkk}$\\\\\n\\hline\n\\parbox[t]{2mm}{\\multirow{4}{*}{\\rotatebox[origin=c]{90}{Major}}}\n&Always {\\bf non-negative}\t\t\t\t\t\t\t&  y&  y&  y&  y&  y&{\\bf N}&  y&  y&  y&  y&  y&  y&  y&  y\\\\\n&Always {\\bf finite} even for $\\infty$-dimensional system\t&{\\bf N}&  y&  y&{\\bf N}&  y&  y&  y&  y&  y&  y&  y&{\\bf N}&  y&  y\\\\\n&Vanishes for {\\bf deterministic} system\t (drawback)\t\t&  n&  n&  n&  n&  n&  n&  n&  n&  n&  n&  n&  n&  n&{\\bf Y}\\\\\n&Vanishes for {\\bf separable} system\t\t\t\t\t&  y&  y&  y&  y&  y&{\\bf N}&  y&  y&  y&{\\bf N}&  y&  y&  y&  y\\\\\n\\hline\n\\parbox[t]{2mm}{\\multirow{4}{*}{\\rotatebox[origin=c]{90}{Minor}}}\n&Vanishes for {\\bf afferent} system\t\t\t\t\t&  y&  y&  y&  y&{\\bf N}&{\\bf N}&{\\bf N}&  y&{\\bf N}&{\\bf N}&{\\bf N}&  y&  y&{\\bf N}\\\\\n&Vanishes for {\\bf efferent} system\t\t\t\t\t&  y&  y&  y&  y&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}&  y&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}\\\\\n&{\\bf State-dependent}\t\t\t\t\t\t\t\t&  y&  y&  y&  y&{\\bf N}&{\\bf N}&  y&  y&  y&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}& y\\\\\n&Based on {\\bf symmetric} probability distance\t\t\t&{\\bf N}&{\\bf N}&{\\bf N}&  y&{\\bf N}&{\\bf N}&  n&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}&{\\bf N}\\\\\n\\hline\n&Intuitively {\\bf interpretatable}\t\t\t\t\t\t&2&2&2&2&2&0&2&2&2&0&1&0&0&0\\\\\n&Computationally {\\bf tractable}\t\t\t\t\t\t&1&2&2&0&2&2&2&2&2&2&2&1&2&2\\\\\n\n\n\\hline\n\\end{tabular}\n\\caption{Properties of different integration measures. All but the third are desirable properties;\ncapitalized N/Y (no/yes) indicate when an integration measure lacks a desirable property or has an undesirable one.\nThe first four properties are generally agreed to be important, while the \nsecond set of four have been argued to be important by some authors.\n$\\phi^{\\rm M}\\equiv\\phi^{\\rm otuk}$ and \n$\\phi^{\\rm M}_{kk'}\\equiv\\phi^{\\rm ofkk}_{kk'}$. \n\\label{PropertyTable}\n}\n}\n\\end{table*}\n\n\n\n\n\n\n\\begin{table*}\n{\\footnotesize\n\n\\begin{tabular}{|l|l|l|}\n\\hline\n\nName&\t\tDefinition&Formula for Gaussian variables\\\\\n\\hline\n$\\phi^{\\rm otuk}\\>(\\phi^M)$\t&$I({\\bf x}^A,{\\bf x}^B)-I({\\bf x}_0^A,{\\bf x}_0^B)$\t\t\t\t&${1\\over 2}\\log {|{\\bf T}_A| |{\\bf T}_B| |{\\bf C}|\\over |{\\bf T}| |{\\bf C}_A| |{\\bf C}_B|}$\\\\\n$\\phi^B$\t\t\t&$I({\\bf x}_0,{\\bf x}_1) - I({\\bf x}^A_0,{\\bf x}^A_1) - I({\\bf x}^B_0,{\\bf x}^B_1)$\t&${1\\over 2}\\log {|{\\bf C}|^2 |{\\bf T}_A| |{\\bf T}_B|\\over |{\\bf T}| |{\\bf C}_A|^2|{\\bf C}_B|^2}$\\\\\n\n$\\phi^{\\rm otsk}$\t&$I({\\bf x}^A,{\\bf x}^B)$\t\t\t\t\t\t\t&${1\\over 2}\\log {|{\\bf T}_A| |{\\bf T}_B|\\over |{\\bf T}|}$\\\\\n$\\phi^{\\rm ofsk}$\t&$I({\\bf x}_1^A,{\\bf x}_1^B)$\t \t\t\t\t\t\t&${1\\over 2}\\log {|{\\bf C}_A| |{\\bf C}_B|\\over |{\\bf C}|}$\\\\\n$\\phi^{\\rm ofuk}$\t&$-\\sum\\limits_{jj'} p_{\\cdot\\cdot jj'}\\log\\sum\\limits_{ii'}{p_{i\\cdot j\\cdot}p_{\\cdot i'\\cdot j'}p_{ii'\\cdot\\cdot}\\over p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}p_{\\cdot\\cdot jj'}}$\t&${1\\over 2}\\left[\\ln{|{\\bf C}_q|\\over|{\\bf C}|}+{\\hbox{tr}\\,} {\\bf C}_q^{-1}{\\bf C}-n\\right]$,\\quad${\\bf C}_q\\equiv{\\widehat{\\bf A}}{\\bf C}{\\widehat{\\bf A}}^t+{\\widehat{\\mathbf\\Sigma}}$\\\\\n\n\n$\\phi^{\\rm ofkk}_{kk'}\\>(\\phi^M_{kk'})$\t&$\\sum\\limits_{jj'}{p_{kk'jj'}\\over p_{kk'\\cdot\\cdot}}\\log{p_{kk'jj'}p_{k\\cdot\\cdot\\cdot}p_{\\cdot k'\\cdot\\cdot}\\over p_{kk'\\cdot\\cdot}p_{k'\\cdot j\\cdot}p_{\\cdot k'\\cdot j'}}$\n\t&${1\\over 2}\\left[{\\bf x}_0^t({\\widehat{\\bf A}}-{\\bf A}){{\\widehat{\\mathbf\\Sigma}}}^{-1}({\\widehat{\\bf A}}-{\\bf A}){\\bf x}+\\ln{|{\\mathbf\\Sigma}_A|\\,|{\\mathbf\\Sigma}_B|\\over|{\\mathbf\\Sigma}|}+{\\hbox{tr}\\,}{{\\widehat{\\mathbf\\Sigma}}}^{-1}{\\mathbf\\Sigma}-n\\right]$\\\\\n$\\phi^{\\rm oakk}_{kk'}$\t\t&$\\sum\\limits_j{p_{kk'j\\cdot}\\over p_{kk'\\cdot\\cdot}}\\log{p_{kk'j\\cdot}p_{k\\cdot\\cdot\\cdot}\\over p_{kk'\\cdot\\cdot}p_{k\\cdot j\\cdot}}$\t&${1\\over 2}\\left[\\Delta{\\bf m}^t{\\bar{\\mathbf\\Sigma}}_A^{-1}\\Delta{\\bf m}+\\ln{|{\\bar{\\mathbf\\Sigma}}_A|\\over|{\\mathbf\\Sigma}_A|}+{\\hbox{tr}\\,} {\\bar{\\mathbf\\Sigma}}_A^{-1}{\\mathbf\\Sigma}_A-n_A\\right]$,\\quad$\\Delta{\\bf m}\\equiv({\\bf A}_A-{\\widehat{\\bf A}}_A){\\bf x}_0^A+{\\bf A}_B{\\bf x}_0^B$\\\\\n\n$\\phi^{\\rm opkk}_{kk'}$\t&$\\sum\\limits_i{p_{i\\cdot kk'}\\over p_{\\cdot\\cdot kk'}}\\log{p_{i\\cdot kk'}p_{\\cdot\\cdot k\\cdot}\\over p_{\\cdot\\cdot kk'}p_{i\\cdot k\\cdot}}$&${1\\over 2}\\left[\\Delta{\\bf m}^t\\tilde{{\\bar{\\mathbf\\Sigma}}}_A^{-1}\\Delta{\\bf m}+\\ln{|\\tilde{{\\bar{\\mathbf\\Sigma}}}_A|\\over|\\tilde{{\\mathbf\\Sigma}}_A|}+{\\hbox{tr}\\,}\\tilde{{\\bar{\\mathbf\\Sigma}}}_A^{-1}\\tilde{{\\mathbf\\Sigma}}_A-n_A\\right]$,\\quad$\\Delta{\\bf m}\\equiv({\\tilde{{\\bf A}}}_A-\\hat{\\tilde{{\\bf A}}}_A){\\bf x}_0^A+{\\tilde{{\\bf A}}}_B{\\bf x}_1^B$\\\\\n\n\\hline\n\n\n\n\n\n\n\n$\\phi^{\\rm xfkk}_{kk'}$\t&$I({\\bf x}_1^A,{\\bf x}_1^B|{\\bf x}_0=kk')$\t\t\t\t&${1\\over 2}\\log {|{\\mathbf\\Sigma}_A| |{\\mathbf\\Sigma}_B| \\over |{\\mathbf\\Sigma}|}$\\\\\n\n\n\n\n\n\\hline\n$\\phi^{\\rm nask}$\t&$-\\sum\\limits_j p_{\\cdot\\cdot j\\cdot}\\log\\sum\\limits_{ii'}{p_{ii'j\\cdot}p_{i\\cdot\\cdot\\cdot}\\over n_B p_{ii'\\cdot\\cdot}p_{\\cdot\\cdot j\\cdot}}$&$\\infty$\\\\\n$\\phi^{\\rm nakk}_k$\t&$-\\sum\\limits_j {p_{k\\cdot j\\cdot}\\over p_{k\\cdot\\cdot\\cdot}} \\log\\sum\\limits_{i'}{p_{ki'j\\cdot}p_{k\\cdot\\cdot\\cdot}\\over n_B p_{ki'\\cdot\\cdot}p_{k\\cdot j\\cdot}}$&$\\infty$\\\\\n\n$\\phi^{\\rm npsk}$\t&$-\\sum\\limits_i p_{i\\cdot\\cdot\\cdot}\\log\\sum\\limits_{jj'}{p_{i\\cdot jj'}p_{\\cdot\\cdot j\\cdot}\\over n_B p_{\\cdot\\cdot jj'}p_{i\\cdot\\cdot\\cdot}}$&$\\infty$\\\\\n$\\phi^{\\rm npkk}_k$\t&$-\\sum\\limits_i {p_{i\\cdot k\\cdot}\\over p_{\\cdot\\cdot k\\cdot}} \\log\\sum\\limits_{j'}{p_{i\\cdot kj'}p_{\\cdot\\cdot k\\cdot}\\over n_B p_{\\cdot\\cdot kj'}p_{i\\cdot k\\cdot}}$&$\\infty$\\\\\n\n\\hline\n$\\phi^{\\rm mask}$\t&$-\\sum\\limits_j p_{\\cdot\\cdot j\\cdot}\\log\\sum\\limits_{ii'}{p_{ii'j\\cdot}p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}\\over p_{ii'\\cdot\\cdot}p_{\\cdot\\cdot j\\cdot}}$\t&${1\\over 2}\\left[\\ln{|{\\bf C}_q|\\over|{\\bf C}_A|}+{\\hbox{tr}\\,} {\\bf C}_q^{-1}{\\bf C}_A-n_A\\right]$,\\quad${\\bf C}_q\\equiv{\\mathbf\\Sigma}_A+{\\bf A}_A{\\bf C}_A{\\bf A}_A^t+{\\bf A}_{AB}{\\bf C}_B{\\bf A}_{AB}^t$\\\\\n\n$\\phi^{\\rm makk}_k$\t&$-\\sum\\limits_j {p_{k\\cdot j\\cdot}\\over p_{k\\cdot\\cdot\\cdot}} \\log\\sum\\limits_{i'}{p_{ki'j\\cdot}p_{k\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}\\over p_{ki'\\cdot\\cdot}p_{k\\cdot j\\cdot}}$&${1\\over 2}\\left[\\Delta{\\bf m}^t{\\bar{\\mathbf\\Sigma}}_A^{-1}\\Delta{\\bf m}+\\ln{|{\\bar{\\mathbf\\Sigma}}_A|\\over|{\\mathbf\\Sigma}_A|}+{\\hbox{tr}\\,} {\\bar{\\mathbf\\Sigma}}_A^{-1}{\\mathbf\\Sigma}_A-n_A\\right]$,\\quad$\\Delta{\\bf m}\\equiv({\\widehat{\\bf A}}_A-{\\bf A}_A){\\bf x}_0^A$\\\\\n$\\phi^{\\rm mpsk}$\t&$-\\sum\\limits_i p_{i\\cdot\\cdot\\cdot}\\log\\sum\\limits_{jj'}{p_{i\\cdot jj'}p_{\\cdot\\cdot j\\cdot}p_{\\cdot\\cdot\\cdot j'}\\over p_{\\cdot\\cdot jj'}p_{i\\cdot\\cdot\\cdot}}$&${1\\over 2}\\left[\\ln{|{\\bf C}_q|\\over|{\\bf C}_A|}+{\\hbox{tr}\\,} {\\bf C}_q^{-1}{\\bf C}_A-n_A\\right]$,\\quad${\\bf C}_q\\equiv{\\tilde{\\mathbf\\Sigma}}_A+{\\tilde{{\\bf A}}}_A{\\bf C}_A{\\tilde{{\\bf A}}}_A^t+{\\tilde{{\\bf A}}}_{AB}{\\bf C}_B{\\tilde{{\\bf A}}}_{AB}^t$\\\\\n$\\phi^{\\rm mpkk}_k$\t&$-\\sum\\limits_i {p_{i\\cdot k\\cdot}\\over p_{\\cdot\\cdot k\\cdot}} \\log\\sum\\limits_{j'}{p_{i\\cdot kj'}p_{\\cdot\\cdot k\\cdot}p_{\\cdot\\cdot\\cdot j'}\\over p_{\\cdot\\cdot kj'}p_{i\\cdot k\\cdot}}$\t&${1\\over 2}\\left[\\Delta{\\bf m}^t\\tilde{{\\bar{\\mathbf\\Sigma}}}_A^{-1}\\Delta{\\bf m}+\\ln{|\\tilde{{\\bar{\\mathbf\\Sigma}}}_A|\\over|{\\tilde{\\mathbf\\Sigma}}_A|}+{\\hbox{tr}\\,} \\tilde{{\\bar{\\mathbf\\Sigma}}}_A^{-1}{\\tilde{\\mathbf\\Sigma}}_A-n_A\\right]$,\\quad$\\Delta{\\bf m}\\equiv(\\hat{{\\tilde{{\\bf A}}}}_A-{\\tilde{{\\bf A}}}_A){\\bf x}_1^A$\\\\\n\n\n\n\\hline\n$\\phi^{2.0}$\t\t\t&$\\min\\{\\phi^{\\rm nakk},\\phi^{\\rm npkk}\\}$&$\\infty$\\\\\n$\\phi^{2.0'}$\t\t\t&$\\min\\{\\phi^{\\rm makk},\\phi^{\\rm mpkk}\\}$&\\\\\n$\\phi^{2.0''}$\t\t\t&$\\min\\{\\phi^{\\rm oakk},\\phi^{\\rm opkk}\\}$&\\\\\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\hline\n\\end{tabular}\n\\caption{Integration $\\phi$ for different measures.\n${\\bf A}\\equiv{\\bf B}^t{\\bf C}^{-1}$, ${\\bf A}_b\\equiv{\\bf B}{\\bf C}^{-1}={\\mathbf\\Sigma}{\\bf A}^t{\\mathbf\\Sigma}_b^{-1}$,\n${\\mathbf\\Sigma}\\equiv{\\bf C}-{\\bf B}^t{\\bf C}^{-1}{\\bf B}={\\bf C}-{\\bf A}{\\bf C}{\\bf A}^t$ and\n${\\mathbf\\Sigma}_b\\equiv{\\bf C}-{\\bf B}{\\bf C}^{-1}{\\bf B}^t={\\bf C}-{\\bf A}_b{\\bf C}{\\bf A}_b^t= [{\\bf C}^{-1}+{\\bf A}^t{\\mathbf\\Sigma}^{-1}{\\bf A}]^{-1}={\\bf C}-{\\bf C}{\\bf A}^t{\\bf C}^{-1}{\\bf A}{\\bf C}.$}\n\\label{MeasureTable}\n}\n\\end{table*}\n\n\nAs neuroscience data improves in quantity and quality, it is timely to resolve this controversy  \nby testing the many experimental predictions that IIT makes \\cite{oizumi2014phenomenology} with state-of-the-art laboratory measurements.\nUnfortunately, such tests have been hampered by the fact that the integration measure proposed by IIT is computationally infeasible to evaluate for large systems, growing super-exponentially with the system's information content.\nThis has lead to the development of various alternative integration measures that are simpler to compute. For example, \nBarrett \\& Seth \\cite{barrett2011practical} proposed an attractive integration measure that is easier to compute from neuroscience data, but whose interpretation is complicated by the fact that it can be negative in some cases. \n\\cite{casali2013theoretically} used an integration measure inspired by complexity theory to successfully predict who was\nconscious in a sample including patients who were awake, in deep sleep, dreaming, sedated and with \nlocked-in syndrome. Even the team behind IIT has updated their integration measure twice through successive refinements of their theory \\cite{tononi2008consciousness,oizumi2014phenomenology}.\nDespite these definitional and computational challenges, interest in measuring integration is growing, not only in neuroscience but also in other fields, ranging from physics \\cite{tegmark2014consciousness} to the study of collective intelligence in social networks \\cite{engel2015groups}.\n\n\n\nIt is therefore interesting and timely to do a comprehensive investigation of existing and novel integration measures, classifying them by various desirable properties. This is the goal of the present paper, as summarized in {Table~\\ref{{PropertyTable}}} and {Table~\\ref{{MeasureTable}}}.\nThe rest of this paper is organized as follows. \nIn {Section~\\ref{{MeasureSec}}}, we investigate general integration measures and their properties.\nIn {Section~\\ref{{GaussianSec}}}, we derive useful formulas for many of these measures that can be applied to the sort of time-series data with continuous variables that is \ntypically measured in laboratory experiments.\nWe explore further algorithmic speedups and approximations in {Section~\\ref{{ApproximationSec}}} and summarize our conclusions in {Section~\\ref{{ConclusionsSec}}}.\n\n\n\n\n\\section{Measures of integration}\n\\label{MeasureSec}\n\nFollowing Tononi \\cite{tononi2008consciousness}, we will use the symbol $\\Phi$ to denote integrated information.\nAll measures of $\\Phi$ aim to quantify the extent to which a system is interconnected, \nyielding $\\Phi=0$ if the system consists of two independent parts, and a larger $\\Phi$ the more the parts affect each other.\nMathematically,  all $\\Phi$-measures are defined in a two-step process:\n\\begin{enumerate}\n\\item Given an imaginary cut that partitions the system into two parts, define\na measure $\\phi$ of how much these two parts affect each other.  {Table~\\ref{{MeasureTable}}} lists many $\\phi$-options.\n\\item Define $\\Phi$ as the $\\phi$-value for the ``cruelest cut\" that minimizes $\\phi$.\nA major numerical challenge is that the number of cuts to be \nminimized over grows super-exponentially with the number of bits in the system.\nA further challenge in this step is how to best handle cuts splitting the system into parts of unequal size.\n\\end{enumerate}\n\nBefore delving into the many different options for defining $\\Phi$, let us first introduce convenient notation \ngeneral enough to describe all proposed integration measures, as illustrated in {Figure~\\ref{{MarkovFig}}}.\n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{markov.pdf}}\n\\caption{We model the time-evolution of the system state as a Markov process defined by a transition matrix ${\\bf M}$:\nwhen the (possibly unknown) system state evolves from ${\\bf x}_0$ to ${\\bf x}_1$, the corresponding probability distribution\nevolves from ${\\bf p}_0$ to ${\\bf p}_1\\equiv{\\bf M}{\\bf p}_0$.\nAll competing definitions of $\\Phi$ quantify the inability to tensor factorize ${\\bf M}$, which corresponds to approximating the system\nas two disconnected parts A and B that do not affect one another.\n\\label{MarkovFig}\n}\n\\end{figure}\n\n\\subsection{Interpreting evolution as a Markov process}\n\nConsider two random vectors ${\\bf x}_0$ and ${\\bf x}_1$ whose joint probability distribution is \n$p({\\bf x}_0,{\\bf x}_1).$ We will interpret them as the state of a time-dependent system ${\\bf x}(t)$ at two separate times\n$t_0$ and $t_1$.\nFor example, if these are two vectors of 5 bits each, then $p$ is a table of $2^{10}$ numbers giving the probability of each possible bit string, while if these are two vectors in 3D space, then $p$ is a function of 6 real continuous variables. \nWe obtain the marginal distribution $p^{(n)}({\\bf x}_n)$ for the ${n^{\\rm th}}$ vector, where $n=0$ or $n=1$, by summing/integrating $p$ over the other vector. \n\nBelow we will often find it convenient to denote these vectors as single indices $i={\\bf x}_0$ and $j={\\bf x}_1$. For example, this allows us to write the marginal distribution $p_0({\\bf x}_0)$\nas $\\sum_j p_{ij},$ \nwhere the sum over $j$ is to be interpreted as summation/integration over all allowed values of ${\\bf x}_1$.\nWe also adopt the notation where replacing an index by a dot means that this index is to be summed/integrated over.\nThis lets us write the marginal distributions $p^{(0)}({\\bf x}_0)$ and $p^{(1)}({\\bf x}_1)$ as\n\n", "index": 1, "text": "\\begin{equation}\\label{{MargDistEq}}\np^{(0)}_i = p_{i\\cdot}\\quad\\hbox{and}\\quad p^{(1)}_j = p_{\\cdot j}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"p^{(0)}_{i}=p_{i\\cdot}\\quad\\hbox{and}\\quad p^{(1)}_{j}=p_{\\cdot j}\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><msubsup><mi>p</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><msub><mi>p</mi><mrow><mi/><mo>\u22c5</mo><mi>j</mi></mrow></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere the Markov matrix $M_{ji}$ specifies the probability that a state $i$ transitions to a state $j$, \nand satisfies the conditions $M_{ji}\\ge 0$ (non-negative transition probabilities)\nand $M_{\\cdot i}=1$ (unit column sums, guaranteeing probability conservation).\nThe standard rule for conditional probabilities gives\n\\begin{eqnarray}\\label{{ConditionalProbEq}}\np_{ij}&=&P({\\bf x}_0=i\\>\\&\\>{\\bf x}_1=j) = \\nonumber\\\\\n&=&P({\\bf x}_0=i) P({\\bf x}_1=j|x_0=i) = p^{(0)}_i M_{ji},\n\\end{eqnarray}\nwhich uniquely determines the Markov matrix as\n\n", "itemtype": "equation", "pos": 17674, "prevtext": "\n\nAs illustrated in {Figure~\\ref{{MarkovFig}}}, it is always possible to model this relation between ${\\bf x}_0$ and ${\\bf x}_1$ as resulting from a \nMarkov process, where ${\\bf x}_1$ is causally determined by a combination of ${\\bf x}_0$ and random effects.\nIf we write the marginal distributions from {equation~(\\ref{{MargDistEq}})}\nas vectors ${\\bf p}^{(0)}$ and ${\\bf p}^{(1)}$, this Markov process is defined by\n\n", "index": 3, "text": "\\begin{equation}\\label{{MarkovEq}}\n{\\bf p}^{(1)} = {\\bf M}{\\bf p}^{(0)},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"{\\bf p}^{(1)}={\\bf M}{\\bf p}^{(0)},\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc29</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msup><mi>\ud835\udc0c\ud835\udc29</mi><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhich is seen to satisfy the Markov requirements $M_{ji}\\ge 0$ and $M_{\\cdot i}=1$.\n\n\nNote that any system obeying the laws of classical physics can be accurately modeled as a Markov process as long as the time step $\\Delta t\\equiv t_1-t_0$ is sufficiently short (defining ${\\bf x}(t)$ as the position in phase space). If the process has ``memory\" such that the next state depends not only on the current state but also on some finite number of past states, it can re reformulated\nas a standard memoryless Markov process by simply expanding the definition of the state ${\\bf x}$ to include elements of the past.\n\n\n\\subsection{A taxonomy of integration measures}\n\n\n\nWe will now see that this Markov process interpretation allows us create a simple taxonomy of integration measures $\\phi$ that quantify the interaction between two subsystems. The idea is to approximate the Markov process by a {\\it separable} Markov process that does not mix information between subsystems, and  to define the integration as a measure of how bad the best such approximation is.\nConsider the system ${\\bf x}$ as being composed of two subsystems ${\\bf x}^A$ and ${\\bf x}^B$, so that\nthe elements of the vector ${\\bf x}$ are simply the union of the elements of ${\\bf x}^A$ and ${\\bf x}^B$, and let us define\nthe probability distribution\n\n", "itemtype": "equation", "pos": 18303, "prevtext": "\nwhere the Markov matrix $M_{ji}$ specifies the probability that a state $i$ transitions to a state $j$, \nand satisfies the conditions $M_{ji}\\ge 0$ (non-negative transition probabilities)\nand $M_{\\cdot i}=1$ (unit column sums, guaranteeing probability conservation).\nThe standard rule for conditional probabilities gives\n\\begin{eqnarray}\\label{{ConditionalProbEq}}\np_{ij}&=&P({\\bf x}_0=i\\>\\&\\>{\\bf x}_1=j) = \\nonumber\\\\\n&=&P({\\bf x}_0=i) P({\\bf x}_1=j|x_0=i) = p^{(0)}_i M_{ji},\n\\end{eqnarray}\nwhich uniquely determines the Markov matrix as\n\n", "index": 5, "text": "\\begin{equation}\\label{{MarkovMatrixEq}}\nM_{ji}={p_{ij}\\over p^{(0)}_i} = {p_{ij}\\over p_{i\\cdot}},\n\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"M_{ji}={p_{ij}\\over p^{(0)}_{i}}={p_{ij}\\over p_{i\\cdot}},\\par&#10;\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msubsup><mi>p</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup></mfrac><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nThe Markov matrix of {equation~(\\ref{{MarkovMatrixEq}})} then takes the form\n\n", "itemtype": "equation", "pos": 19735, "prevtext": "\nwhich is seen to satisfy the Markov requirements $M_{ji}\\ge 0$ and $M_{\\cdot i}=1$.\n\n\nNote that any system obeying the laws of classical physics can be accurately modeled as a Markov process as long as the time step $\\Delta t\\equiv t_1-t_0$ is sufficiently short (defining ${\\bf x}(t)$ as the position in phase space). If the process has ``memory\" such that the next state depends not only on the current state but also on some finite number of past states, it can re reformulated\nas a standard memoryless Markov process by simply expanding the definition of the state ${\\bf x}$ to include elements of the past.\n\n\n\\subsection{A taxonomy of integration measures}\n\n\n\nWe will now see that this Markov process interpretation allows us create a simple taxonomy of integration measures $\\phi$ that quantify the interaction between two subsystems. The idea is to approximate the Markov process by a {\\it separable} Markov process that does not mix information between subsystems, and  to define the integration as a measure of how bad the best such approximation is.\nConsider the system ${\\bf x}$ as being composed of two subsystems ${\\bf x}^A$ and ${\\bf x}^B$, so that\nthe elements of the vector ${\\bf x}$ are simply the union of the elements of ${\\bf x}^A$ and ${\\bf x}^B$, and let us define\nthe probability distribution\n\n", "index": 7, "text": "\\begin{equation}\\label{{ptensorDefEq}}\np_{ii'jj'}\\equiv P({\\bf x}^A_0=i\\>\\&\\>{\\bf x}^B_0=i'\\>\\&\\>{\\bf x}^A_1=j\\>\\&\\>{\\bf x}^B_1=j').\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"p_{ii^{\\prime}jj^{\\prime}}\\equiv P({\\bf x}^{A}_{0}=i\\&gt;\\&amp;\\&gt;{\\bf x}^{B}_{0}=i^{%&#10;\\prime}\\&gt;\\&amp;\\&gt;{\\bf x}^{A}_{1}=j\\&gt;\\&amp;\\&gt;{\\bf x}^{B}_{1}=j^{\\prime}).\" display=\"block\"><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>\u2261</mo><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>A</mi></msubsup><mo>=</mo><mpadded width=\"+2.2pt\"><mi>i</mi></mpadded><mo rspace=\"4.7pt\">&amp;</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>B</mi></msubsup><mo>=</mo><mpadded width=\"+2.2pt\"><msup><mi>i</mi><mo>\u2032</mo></msup></mpadded><mo rspace=\"4.7pt\">&amp;</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>A</mi></msubsup><mo>=</mo><mpadded width=\"+2.2pt\"><mi>j</mi></mpadded><mo rspace=\"4.7pt\">&amp;</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>B</mi></msubsup><mo>=</mo><msup><mi>j</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nThe Markov process of {equation~(\\ref{{MarkovEq}})} is separable if the Markov matrix ${\\bf M}$ is a tensor product \n${\\bf M}^A{\\otimes}{\\bf M}^B$, {\\frenchspacing\\it i.e.}, if\n\n", "itemtype": "equation", "pos": 19960, "prevtext": "\nThe Markov matrix of {equation~(\\ref{{MarkovMatrixEq}})} then takes the form\n\n", "index": 9, "text": "\\begin{equation}\\label{{MarkovMatrixEq2}}\nM_{jj'ii'}={p_{ii'jj'}\\over p_{ii'\\cdot\\cdot}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"M_{jj^{\\prime}ii^{\\prime}}={p_{ii^{\\prime}jj^{\\prime}}\\over p_{ii^{\\prime}%&#10;\\cdot\\cdot}}.\" display=\"block\"><mrow><mrow><msub><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nfor Markov matrices ${\\bf M}^A$ and ${\\bf M}^B$ that determine the evolution of ${\\bf x}^A$ and ${\\bf x}^B$.\n\n\nIf our system is integrated so that ${\\bf M}$ cannot be factored as in {equation~(\\ref{{MarkovTensorEq}})}, we can nonetheless choose to approximate ${\\bf M}$ by a matrix of the factorizable form \n${\\bf M}^A{\\otimes}{\\bf M}^B$. If we retain the initial probability distribution $p_{ii'\\cdot\\cdot}$ for ${\\bf x}_0$ but replace the correct Markov matrix ${\\bf M}$ by the separable approximation ${\\bf M}^A{\\otimes}{\\bf M}^B$, then {equation~(\\ref{{MarkovMatrixEq2}})} shows that the probability distribution\n\n", "itemtype": "equation", "pos": 20242, "prevtext": "\nThe Markov process of {equation~(\\ref{{MarkovEq}})} is separable if the Markov matrix ${\\bf M}$ is a tensor product \n${\\bf M}^A{\\otimes}{\\bf M}^B$, {\\frenchspacing\\it i.e.}, if\n\n", "index": 11, "text": "\\begin{equation}\\label{{MarkovTensorEq}}\nM_{jj'ii'}= M^A_{ji}M^B_{j'i'}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"M_{jj^{\\prime}ii^{\\prime}}=M^{A}_{ji}M^{B}_{j^{\\prime}i^{\\prime}}\" display=\"block\"><mrow><msub><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>\u2062</mo><msubsup><mi>M</mi><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n gets replaced by the probability distribution $q_{ii'jj'}$ given by\n\n", "itemtype": "equation", "pos": 20946, "prevtext": "\nfor Markov matrices ${\\bf M}^A$ and ${\\bf M}^B$ that determine the evolution of ${\\bf x}^A$ and ${\\bf x}^B$.\n\n\nIf our system is integrated so that ${\\bf M}$ cannot be factored as in {equation~(\\ref{{MarkovTensorEq}})}, we can nonetheless choose to approximate ${\\bf M}$ by a matrix of the factorizable form \n${\\bf M}^A{\\otimes}{\\bf M}^B$. If we retain the initial probability distribution $p_{ii'\\cdot\\cdot}$ for ${\\bf x}_0$ but replace the correct Markov matrix ${\\bf M}$ by the separable approximation ${\\bf M}^A{\\otimes}{\\bf M}^B$, then {equation~(\\ref{{MarkovMatrixEq2}})} shows that the probability distribution\n\n", "index": 13, "text": "\\begin{equation}\\label{{pDefEq}}\n p_{ii'jj'}=M_{jj'ii'} \\>p_{ii'\\cdot\\cdot}\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"p_{ii^{\\prime}jj^{\\prime}}=M_{jj^{\\prime}ii^{\\prime}}\\&gt;p_{ii^{\\prime}\\cdot\\cdot}\" display=\"block\"><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mrow><mpadded width=\"+2.2pt\"><msub><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub></mpadded><mo>\u2062</mo><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhich is an approximation of $p_{ii'jj'}$.\nIf ${\\bf M}$ is factorizable (meaning that there is no integration), we can factor ${\\bf M}$ such that the two probability distributions $q_{ii'jj'}$ and $p_{ii'jj'}$ are equal and, conversely, if \nthe two probability distributions are different, we can use how different they are as an integration measure $\\phi$.\n\nTo define an integration measure $\\phi$ in this spirit, we thus need to make four different choices, which collectively specify it fully and determine where the $\\phi$-measure belongs in our taxonomy:\n\\begin{enumerate}\n\\item Choose a recipe defining an approximate factorization ${\\bf M}\\approx{\\bf M}^A{\\otimes}{\\bf M}^B$.\n\\item Choose which probability distributions $p$ and $q$ to compare for exact and approximate ${\\bf M}$ (the distribution for ${\\bf x}$, ${\\bf x}_1$ or ${\\bf x}_1^A$, say).\n\\item Choose what to treat as known about \n\n$p_{ii'\\cdot\\cdot}$\nwhen computing these probability distributions.\n\\item Choose a metric for how different the two probability distributions $p$ and $q$ are.\n\\end{enumerate}\nThese four options are described in Tables~\\ref{FactorizationTable}, \\ref{ComparisonTable} and \\ref{MetricTable}, and we will now explore them in detail.\n\n\n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|l|l|}\n\\hline\nCode&Factorization method\t\t\t\t\t\t&$M^A_{ji}$\t\t\t\t\t\t\t\t\t\t\t\t\t&$M^B_{j'i'}$\t\t\t\t\t\t\t\t\t\t\t\t&$\\tilde{M}^A_{ij}$\t\t\t\t\t\t\t\t\t\t\t\t\t&$\\tilde{M}^B_{i'j'}$\t\t&State-dependent?\\\\\n\\hline\nn&Noising \t\t\t\t\t\t\t\t\t&${1\\over n_B}\\sum\\limits_{i'}{p_{ii'j\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t\t\t&${1\\over n_A}\\sum\\limits_i{p_{ii'\\cdot j'}\\over p_{ii'\\cdot\\cdot}}$\t\t&${1\\over n_B}\\sum\\limits_{j'}{p_{i\\cdot jj'}\\over p_{\\cdot\\cdot jj'}}$\t\t\t&${1\\over n_A}\\sum\\limits_j{p_{\\cdot i'jj'}\\over p_{\\cdot\\cdot jj'}}$\t\t&N\\\\\nm&Mild noising \t\t\t\t\t\t\t\t&$\\sum\\limits_{i'}{p_{ii'j\\cdot}p_{\\cdot i'\\cdot\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t&$\\sum\\limits_i{p_{ii'\\cdot j'}p_{i\\cdot\\cdot\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t&$\\sum\\limits_{j'}{p_{i\\cdot jj'}p_{\\cdot\\cdot\\cdot j'}\\over p_{\\cdot\\cdot jj'}}$\t&$\\sum\\limits_j{p_{\\cdot i'jj'}p_{\\cdot\\cdot j\\cdot}\\over p_{\\cdot\\cdot jj'}}$\t&N\\\\\no&Optimal not knowing state ${\\bf x}_0$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot i'\\cdot\\cdot}}$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{\\cdot\\cdot j\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot\\cdot\\cdot j'}}$\t\t\t\t\t&N\\\\\nx&Optimal given ${\\bf x}_0$  \t\t\t\t\t\t\t&${p_{kk'j\\cdot}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t\t&${p_{kk'\\cdot j'}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{kk'j\\cdot}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t\t&${p_{kk'\\cdot j'}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t&Y\\\\\na&Optimal given ${\\bf x}_0$, on average\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot i'\\cdot\\cdot}}$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{\\cdot\\cdot j\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot\\cdot\\cdot j'}}$\t\t\t\t\t&N\\\\\n\\hline\n\\end{tabular}\n\\caption{Different options for approximate factorizations ${\\bf M}\\approx{\\bf M}^A{\\otimes}{\\bf M}^B$ and $\\tilde{{\\bf M}}\\approx\\tilde{{\\bf M}}^A{\\otimes}\\tilde{{\\bf M}}^B$\n\\label{FactorizationTable}\n}\n}\n\\end{table*}\n\n\n\\subsection{Options for approximately factoring ${\\bf M}$}\n\\label{FactorizationSec}\n\n\n{Table~\\ref{{FactorizationTable}}} lists five factoring options which all have attractive features, and we will now describe each in turn.\n\n\\subsubsection{Approximately factoring ${\\bf M}$ using noising}\n\nThe first option corresponds to the ``noising'' method used in IIT \\cite{tononi2008consciousness}: \nthe time evolution of one part of the system (${\\bf x}^A$, say) is determined from the past state ${\\bf x}^A_0$ alone, \ntreating ${\\bf x}^B_0$ as random noise with some probability distribution $p^{(B0)}$ that is independent of ${\\bf x}^A_0$.\nIn other words, we replace the initial probability distribution \n$p^{(0)}_{ii'}=p_{ii'\\cdot\\cdot}$ by the separable distribution\n$p^{(0)}_{ii'}=p^{(A0)}_i p^{(B0)}_{i'}$.\nWe will now see that if we start with {equation~(\\ref{{MarkovEq}})}, {\\frenchspacing\\it i.e.}, the Markov equation ${\\bf p}^{(1)} = {\\bf M}{\\bf p}^{(0)}$, then this noising prescription gives\n${\\bf p}^{(A1)} = {\\bf M}^A{\\bf p}^{(A0)}$ for a particular matrix ${\\bf M}^A$.\n {Equation~(\\ref{{MarkovEq}})} states that\n\n", "itemtype": "equation", "pos": 21107, "prevtext": "\n gets replaced by the probability distribution $q_{ii'jj'}$ given by\n\n", "index": 15, "text": "\\begin{equation}\\label{{qdefEq}}\nq_{ii'jj'} = M^A_{ji}M^B_{j'i'} \\>p_{ii'\\cdot\\cdot}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"q_{ii^{\\prime}jj^{\\prime}}=M^{A}_{ji}M^{B}_{j^{\\prime}i^{\\prime}}\\&gt;p_{ii^{%&#10;\\prime}\\cdot\\cdot}\" display=\"block\"><mrow><msub><mi>q</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>\u2062</mo><mpadded width=\"+2.2pt\"><msubsup><mi>M</mi><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup></mpadded><mo>\u2062</mo><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nand substituting the separable ``noising'' form of $p^{(0)}_{ii'}$ from above gives\n\n", "itemtype": "equation", "pos": 25483, "prevtext": "\nwhich is an approximation of $p_{ii'jj'}$.\nIf ${\\bf M}$ is factorizable (meaning that there is no integration), we can factor ${\\bf M}$ such that the two probability distributions $q_{ii'jj'}$ and $p_{ii'jj'}$ are equal and, conversely, if \nthe two probability distributions are different, we can use how different they are as an integration measure $\\phi$.\n\nTo define an integration measure $\\phi$ in this spirit, we thus need to make four different choices, which collectively specify it fully and determine where the $\\phi$-measure belongs in our taxonomy:\n\\begin{enumerate}\n\\item Choose a recipe defining an approximate factorization ${\\bf M}\\approx{\\bf M}^A{\\otimes}{\\bf M}^B$.\n\\item Choose which probability distributions $p$ and $q$ to compare for exact and approximate ${\\bf M}$ (the distribution for ${\\bf x}$, ${\\bf x}_1$ or ${\\bf x}_1^A$, say).\n\\item Choose what to treat as known about \n\n$p_{ii'\\cdot\\cdot}$\nwhen computing these probability distributions.\n\\item Choose a metric for how different the two probability distributions $p$ and $q$ are.\n\\end{enumerate}\nThese four options are described in Tables~\\ref{FactorizationTable}, \\ref{ComparisonTable} and \\ref{MetricTable}, and we will now explore them in detail.\n\n\n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|l|l|}\n\\hline\nCode&Factorization method\t\t\t\t\t\t&$M^A_{ji}$\t\t\t\t\t\t\t\t\t\t\t\t\t&$M^B_{j'i'}$\t\t\t\t\t\t\t\t\t\t\t\t&$\\tilde{M}^A_{ij}$\t\t\t\t\t\t\t\t\t\t\t\t\t&$\\tilde{M}^B_{i'j'}$\t\t&State-dependent?\\\\\n\\hline\nn&Noising \t\t\t\t\t\t\t\t\t&${1\\over n_B}\\sum\\limits_{i'}{p_{ii'j\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t\t\t&${1\\over n_A}\\sum\\limits_i{p_{ii'\\cdot j'}\\over p_{ii'\\cdot\\cdot}}$\t\t&${1\\over n_B}\\sum\\limits_{j'}{p_{i\\cdot jj'}\\over p_{\\cdot\\cdot jj'}}$\t\t\t&${1\\over n_A}\\sum\\limits_j{p_{\\cdot i'jj'}\\over p_{\\cdot\\cdot jj'}}$\t\t&N\\\\\nm&Mild noising \t\t\t\t\t\t\t\t&$\\sum\\limits_{i'}{p_{ii'j\\cdot}p_{\\cdot i'\\cdot\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t&$\\sum\\limits_i{p_{ii'\\cdot j'}p_{i\\cdot\\cdot\\cdot}\\over p_{ii'\\cdot\\cdot}}$\t&$\\sum\\limits_{j'}{p_{i\\cdot jj'}p_{\\cdot\\cdot\\cdot j'}\\over p_{\\cdot\\cdot jj'}}$\t&$\\sum\\limits_j{p_{\\cdot i'jj'}p_{\\cdot\\cdot j\\cdot}\\over p_{\\cdot\\cdot jj'}}$\t&N\\\\\no&Optimal not knowing state ${\\bf x}_0$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot i'\\cdot\\cdot}}$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{\\cdot\\cdot j\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot\\cdot\\cdot j'}}$\t\t\t\t\t&N\\\\\nx&Optimal given ${\\bf x}_0$  \t\t\t\t\t\t\t&${p_{kk'j\\cdot}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t\t&${p_{kk'\\cdot j'}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{kk'j\\cdot}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t\t&${p_{kk'\\cdot j'}\\over p_{kk'\\cdot\\cdot}}$\t\t\t\t\t\t\t&Y\\\\\na&Optimal given ${\\bf x}_0$, on average\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot i'\\cdot\\cdot}}$\t\t\t\t\t&${p_{i\\cdot j\\cdot}\\over p_{\\cdot\\cdot j\\cdot}}$\t\t\t\t\t\t\t&${p_{\\cdot i'\\cdot j'}\\over p_{\\cdot\\cdot\\cdot j'}}$\t\t\t\t\t&N\\\\\n\\hline\n\\end{tabular}\n\\caption{Different options for approximate factorizations ${\\bf M}\\approx{\\bf M}^A{\\otimes}{\\bf M}^B$ and $\\tilde{{\\bf M}}\\approx\\tilde{{\\bf M}}^A{\\otimes}\\tilde{{\\bf M}}^B$\n\\label{FactorizationTable}\n}\n}\n\\end{table*}\n\n\n\\subsection{Options for approximately factoring ${\\bf M}$}\n\\label{FactorizationSec}\n\n\n{Table~\\ref{{FactorizationTable}}} lists five factoring options which all have attractive features, and we will now describe each in turn.\n\n\\subsubsection{Approximately factoring ${\\bf M}$ using noising}\n\nThe first option corresponds to the ``noising'' method used in IIT \\cite{tononi2008consciousness}: \nthe time evolution of one part of the system (${\\bf x}^A$, say) is determined from the past state ${\\bf x}^A_0$ alone, \ntreating ${\\bf x}^B_0$ as random noise with some probability distribution $p^{(B0)}$ that is independent of ${\\bf x}^A_0$.\nIn other words, we replace the initial probability distribution \n$p^{(0)}_{ii'}=p_{ii'\\cdot\\cdot}$ by the separable distribution\n$p^{(0)}_{ii'}=p^{(A0)}_i p^{(B0)}_{i'}$.\nWe will now see that if we start with {equation~(\\ref{{MarkovEq}})}, {\\frenchspacing\\it i.e.}, the Markov equation ${\\bf p}^{(1)} = {\\bf M}{\\bf p}^{(0)}$, then this noising prescription gives\n${\\bf p}^{(A1)} = {\\bf M}^A{\\bf p}^{(A0)}$ for a particular matrix ${\\bf M}^A$.\n {Equation~(\\ref{{MarkovEq}})} states that\n\n", "index": 17, "text": "\\begin{equation}\\label{{MarkovEq2}}\np^{(1)}_{jj'}=\\sum_{ii'}M_{jj'ii'}p^{(0)}_{ii'}\\>,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"p^{(1)}_{jj^{\\prime}}=\\sum_{ii^{\\prime}}M_{jj^{\\prime}ii^{\\prime}}p^{(0)}_{ii^%&#10;{\\prime}}\\&gt;,\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></munder><mrow><msub><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub><mo>\u2062</mo><mpadded width=\"+2.2pt\"><msubsup><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup></mpadded></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere we have defined\n\n", "itemtype": "equation", "pos": 25669, "prevtext": "\nand substituting the separable ``noising'' form of $p^{(0)}_{ii'}$ from above gives\n\n", "index": 19, "text": "\\begin{equation}\\label{{NoisingDerivationEq}}\np^{(A1)}_{j}\\equiv p^{(1)}_{j\\cdot}=\\sum_{ii'}M_{j\\cdot ii'}p^{(A0)}_i p^{(B0)}_{i'}\n= \\sum_iM^A_{ji} p^{(A0)}_{i}\\>,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"p^{(A1)}_{j}\\equiv p^{(1)}_{j\\cdot}=\\sum_{ii^{\\prime}}M_{j\\cdot ii^{\\prime}}p^%&#10;{(A0)}_{i}p^{(B0)}_{i^{\\prime}}=\\sum_{i}M^{A}_{ji}p^{(A0)}_{i}\\&gt;,\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2261</mo><msubsup><mi>p</mi><mrow><mi>j</mi><mo>\u2063</mo><mo>\u22c5</mo></mrow><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></munder><mrow><msub><mi>M</mi><mrow><mrow><mi>j</mi><mo>\u22c5</mo><mi>i</mi></mrow><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub><mo>\u2062</mo><msubsup><mi>p</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><msubsup><mi>p</mi><msup><mi>i</mi><mo>\u2032</mo></msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>B</mi><mo>\u2062</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>\u2062</mo><mpadded width=\"+2.2pt\"><msubsup><mi>p</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup></mpadded></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nIIT chooses the noise to have maximum entropy, {\\frenchspacing\\it i.e.}, a uniform distribution over the $n_B$ possible states of subsystem B \\cite{tononi2008consciousness}: \n\n", "itemtype": "equation", "pos": 25870, "prevtext": "\nwhere we have defined\n\n", "index": 21, "text": "\\begin{equation}\\label{{NoisedMAeq}}\nM^A_{ji}\\equiv\\sum_{i'}M_{j\\cdot ii'} p^{(B0)}_{i'}=\\sum_{i'}{p_{ii'j\\cdot}p^{(B0)}_{i'}\\over p_{ii'\\cdot\\cdot}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"M^{A}_{ji}\\equiv\\sum_{i^{\\prime}}M_{j\\cdot ii^{\\prime}}p^{(B0)}_{i^{\\prime}}=%&#10;\\sum_{i^{\\prime}}{p_{ii^{\\prime}j\\cdot}p^{(B0)}_{i^{\\prime}}\\over p_{ii^{%&#10;\\prime}\\cdot\\cdot}}.\" display=\"block\"><mrow><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>\u2261</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msup><mi>i</mi><mo>\u2032</mo></msup></munder><mrow><msub><mi>M</mi><mrow><mrow><mi>j</mi><mo>\u22c5</mo><mi>i</mi></mrow><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow></msub><mo>\u2062</mo><msubsup><mi>p</mi><msup><mi>i</mi><mo>\u2032</mo></msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>B</mi><mo>\u2062</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msup><mi>i</mi><mo>\u2032</mo></msup></munder><mfrac><mrow><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub><mo>\u2062</mo><msubsup><mi>p</mi><msup><mi>i</mi><mo>\u2032</mo></msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>B</mi><mo>\u2062</mo><mn>0</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mfrac></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n{Table~\\ref{{FactorizationTable}}} lists the ${\\bf M}^A$-matrix corresponding to this noising choice as well as the analogous ${\\bf M}^B$-matrix.\n\n\\subsubsection{Approximately factoring ${\\bf M}$ using mild noising}\n\nOne drawback of this choice is that uniform distributions are undefined for continuous variables such as measured voltages, because they cannot be normalized.\nThis means that any $\\phi$-measure based on this noising factorization is undefined and useless for continuous systems.\nThis problem can be solved by adopting another natural choice for the noise distribution:\n\n", "itemtype": "equation", "pos": 26211, "prevtext": "\nIIT chooses the noise to have maximum entropy, {\\frenchspacing\\it i.e.}, a uniform distribution over the $n_B$ possible states of subsystem B \\cite{tononi2008consciousness}: \n\n", "index": 23, "text": "\\begin{equation}\\label{{IITnoisedMAeq}}\np^{(0B)}_{i'} = {1\\over n_B}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"p^{(0B)}_{i^{\\prime}}={1\\over n_{B}}.\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><msup><mi>i</mi><mo>\u2032</mo></msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>0</mn><mo>\u2062</mo><mi>B</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mfrac><mn>1</mn><msub><mi>n</mi><mi>B</mi></msub></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n{\\frenchspacing\\it i.e.}, simply the marginal distribution for ${\\bf x}^B_0$.\nWe term this option ``mild noising'', since the noise is less extreme (its entropy is lower) than with the previous noising option.\n{Table~\\ref{{FactorizationTable}}} lists the ${\\bf M}^A$-matrix corresponding to this mild noising choice as well as the analogous ${\\bf M}^B$-matrix.\n\n\\subsubsection{Optimally factoring ${\\bf M}$}\n\nA drawback of both factorizations that we have considered so far is that they might overestimate integration: there may exist an alternative factorization that is better in the sense of giving a smaller $\\phi$.\nThe natural way to remedy this problem is to define $\\phi$ by minimizing over all factorizations. \nThis elegantly unifies with the fact that capital $\\Phi$ is defined by minimizing over all partitions of the system into two parts:\nwe can capture both minimizations by simply saying ``minimize over all factorizations\", since the choice of a tensor factorization includes a choice of partition.\n\n\n\n\nIn practice, the definition of the optimal factorization depends on what we optimize. \nWe discuss various options below, and identify three particularly natural choices which are listed in {Table~\\ref{{FactorizationTable}}}.\nThe first option makes the approximate probability distribution $q_{ii'jj'}$ as similar as possible to $p_{ii'jj'}$, where similarity is quantified by KL-divergence.\nThe second option treats the present state ${\\bf x}_0$ as known and makes the conditional probability distribution for the future state ${\\bf x}_1$ as similar as possible to the correct distribution.\nThis factorization thus depends on the state and hence on time, whereas all the others we have considered are state-dependent. \nThe third option is the factorization that minimizes this state-dependent $\\phi$ {\\it on average}; we will prove below that this factorization is identical to the first option.\n\n\nIn summary, {Table~\\ref{{FactorizationTable}}} lists five factorization options that each have various attractive features; options 3 and 5 turn out to be identical. \nIt is easy to show that if the Markov matrix ${\\bf M}$ is factorizable (which means that the probability distribution is separable as $p_{ii'jj'}=p^A_{ij}p^B_{i'j'}$),\nthen all five factorizations coincide, all giving $M^A_{ji}=p^A_{ji}/p^A_{i\\cdot}$ and $M^B_{j'i'}=p^A_{i'j'}/p^A_{i'\\cdot}$.\nThis means that they will all agree on when $\\phi=0$; otherwise the noising factorizations will yield higher $\\phi$ than an optimized factorization.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|}\n\\hline\n&\t\t\t\t\t\t\t\t\t\t\t&\t\t\t\t\t&\t\t\t&\\multicolumn{3}{c|}{Conditioning option}\\\\\n\\cline{5-7}\n\n\t&\t\t\t\t\t\t\t\t\t\t&\t\t\t\t\t&\t\t\t&${\\bf x}_t$ unknown\t\t\t\t&${\\bf x}_t$-distribution separable\t\t\t\t&${\\bf x}_t$ known\\\\\nCode&Comparison option\t\t\t\t\t\t\t&$p$\t\t\t\t&$q$\t\t&$q^u$ ($p^{(0)}_{ij}=p_{ii'\\cdot\\cdot}$)\t&$q^s$ ($p^{(0)}_{ij}=p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}$)\t\t&$q^k$ ($p^{(0)}_{ij}=\\delta_{ik}\\delta_{i'k'}$)\\\\\n\\hline\nt\t&Two-time state\t\t\t\t\t\t\t\t&$p_{ii'jj'}$\\\t\t\t&$q_{ii'jj'}$\t&$M^A_{ji}M^B_{j'i'}p^{(0)}_{ii'}$\t&$\\left(M^A_{ji}p^{(0)}_{i\\cdot}\\right)\\left(M^B_{j'i'}p^{(0)}_{\\cdot i'}\\right)$\t&$M^A_{ji}\\delta_{ik}M^B_{j'i'}\\delta_{i'k'}$\\\\\nf\t&Future state\t\t\t\t\t\t\t\t&$p_{\\cdot\\cdot jj'}$\t\t&$q_{\\cdot\\cdot jj'}$\t&$\\sum\\limits_{ii'}M^A_{ji}M^B_{j'i'}p^{(0)}_{ii'}$\t\t&$\\left(\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}\\right)\\left(\\sum\\limits_{i'}M^B_{j'i'}p^{(0)}_{\\cdot i'}\\right)$\t&$M^A_{jk}M^B_{j'k'}$\\\\\na\t&Future state of subsystem A\t\t\t\t\t&$p_{\\cdot\\cdot j\\cdot}$\t&$q_{\\cdot\\cdot j\\cdot}$\t\t&$\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}$\t&$\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}$\t&$M^A_{jk}$\\\\\np\t&Past state of subsystem A\t\t\t\t\t\t&$p_{i\\cdot \\cdot\\cdot}$\t&$\\tilde{q}_{i\\cdot \\cdot\\cdot}$\t&$\\sum\\limits_j\\tilde{M}^A_{ij}p^{(1)}_{j\\cdot}$\t&$\\sum\\limits_j\\tilde{M}^A_{ij}p^{(1)}_{j\\cdot}$\t&$\\tilde{M}^A_{ik}$\\\\\n\\hline\n\\end{tabular}\n\\caption{Different options for which probability distributions $p$ and $q$ to compare.\nThe last three columns specify the formula for $q$ for the three conditioning options we consider: when the state ${\\bf x}_0$ is unknown (u), has a separable probability distribution (s) and is known  (k), respectively.\n\\label{ComparisonTable}\n}\n}\n\\end{table*}\n\n\n\n\n\\subsection{Options for which probability distributions to compare}\n\\label{ComparisonSec}\n\n{Table~\\ref{{ComparisonTable}}} lists four options for which probability distributions $p$ and $q$ to compare. \nArguably the most natural option is to simply compare the full distributions $p_{ii'jj'}$ and $q_{ii'jj'}$ that  describe our knowledge of the system at both times (the present state and the future state).\nAnother obvious option is to merely compare the predictions, {\\frenchspacing\\it i.e.}, the probability distributions \n$p_{\\cdot\\cdot jj'}$ and $q_{\\cdot\\cdot jj'}$ for the future state.\nA third interesting option is to compare merely the predictions for one of the two subsystems (which we without loss of generality can take to be subsystem A), thus comparing $p_{\\cdot\\cdot j\\cdot}$ and $q_{\\cdot\\cdot j\\cdot}$.\n\nGenerally, the less we compare, the easier it is to get a low $\\phi$-value. \nTo see this, consider a system where $A$ affects $B$ but $B$ has no effect on $A$.\nWe could, for example, consider $A$ to be photoreceptor cells in your your retina and $B$ to be the rest of your brain.\nThen the second comparison option (``f\") in {Table~\\ref{{ComparisonTable}}} would give $\\phi>0$ because we predict the future of your brain worse if we ignore the information flow from your retina, \nwhile the third comparison option (``a\") in the table would give $\\phi=0$ because the rest of your brain does not help predict the future of your retina.\nIn other words,  comparison option ``a'' makes $\\phi$ vanish for {\\it afferent} pathways, where information flows only inward toward the rest of the system.\n\nIIT argues that any good $\\phi$-measure indeed {\\it should} vanish for afferent pathways, because a system can only be conscious if it can have effects on itself --- other systems that it is affected by without affecting will act merely as parts of its unconscious outside world \\cite{tononi2008consciousness}.\nAnalogously, IIT argues that any good $\\phi$-measure should vanish also for {\\it efferent} pathways,\nwhere information flows only outward away from the rest of the system.\nThe argument is that other systems that the conscious system affects without being affected by will again be unconscious, acting merely as unconscious parts of the outside world as far as the conscious system is concerned.\n\nOption ``p'' in {Table~\\ref{{ComparisonTable}}} has this property of $\\phi$ vanishing for efferent pathways.\nIt is simply the time-reverse of option ``a'', \nquantifying the ability of $x^A_1$ to determine its past cause $x^A_0$ instead of \nquantifying the ability of $x^A_0$ to determine its future effect $x^A_1$.\n\nTo formalize this, consider that there is nothing in the probability distribution $p_{ii'jj'}$ that breaks time-reversal symmetry and says that causation goes from $t_0$ to $t_1$ rather than vice versa. \nIn complete analogy with our formalism above, we can therefore define a time-reversed Markov process\n$\\tilde{{\\bf M}}$ whereby the future determines the past according to the time-reverse of {equation~(\\ref{{MarkovEq}})}:\n\n", "itemtype": "equation", "pos": 26882, "prevtext": "\n{Table~\\ref{{FactorizationTable}}} lists the ${\\bf M}^A$-matrix corresponding to this noising choice as well as the analogous ${\\bf M}^B$-matrix.\n\n\\subsubsection{Approximately factoring ${\\bf M}$ using mild noising}\n\nOne drawback of this choice is that uniform distributions are undefined for continuous variables such as measured voltages, because they cannot be normalized.\nThis means that any $\\phi$-measure based on this noising factorization is undefined and useless for continuous systems.\nThis problem can be solved by adopting another natural choice for the noise distribution:\n\n", "index": 25, "text": "\\begin{equation}\\label{{MildMAeq}}\np^{(0B)}_{i'}=p_{\\cdot i'\\cdot\\cdot},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"p^{(0B)}_{i^{\\prime}}=p_{\\cdot i^{\\prime}\\cdot\\cdot},\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><msup><mi>i</mi><mo>\u2032</mo></msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>0</mn><mo>\u2062</mo><mi>B</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><msub><mi>p</mi><mrow><mrow><mi/><mo>\u22c5</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere equations{~(\\ref{{MarkovMatrixEq2}})} and{~(\\ref{{qdefEq}})} get replaced  by\n\n", "itemtype": "equation", "pos": 34316, "prevtext": "\n{\\frenchspacing\\it i.e.}, simply the marginal distribution for ${\\bf x}^B_0$.\nWe term this option ``mild noising'', since the noise is less extreme (its entropy is lower) than with the previous noising option.\n{Table~\\ref{{FactorizationTable}}} lists the ${\\bf M}^A$-matrix corresponding to this mild noising choice as well as the analogous ${\\bf M}^B$-matrix.\n\n\\subsubsection{Optimally factoring ${\\bf M}$}\n\nA drawback of both factorizations that we have considered so far is that they might overestimate integration: there may exist an alternative factorization that is better in the sense of giving a smaller $\\phi$.\nThe natural way to remedy this problem is to define $\\phi$ by minimizing over all factorizations. \nThis elegantly unifies with the fact that capital $\\Phi$ is defined by minimizing over all partitions of the system into two parts:\nwe can capture both minimizations by simply saying ``minimize over all factorizations\", since the choice of a tensor factorization includes a choice of partition.\n\n\n\n\nIn practice, the definition of the optimal factorization depends on what we optimize. \nWe discuss various options below, and identify three particularly natural choices which are listed in {Table~\\ref{{FactorizationTable}}}.\nThe first option makes the approximate probability distribution $q_{ii'jj'}$ as similar as possible to $p_{ii'jj'}$, where similarity is quantified by KL-divergence.\nThe second option treats the present state ${\\bf x}_0$ as known and makes the conditional probability distribution for the future state ${\\bf x}_1$ as similar as possible to the correct distribution.\nThis factorization thus depends on the state and hence on time, whereas all the others we have considered are state-dependent. \nThe third option is the factorization that minimizes this state-dependent $\\phi$ {\\it on average}; we will prove below that this factorization is identical to the first option.\n\n\nIn summary, {Table~\\ref{{FactorizationTable}}} lists five factorization options that each have various attractive features; options 3 and 5 turn out to be identical. \nIt is easy to show that if the Markov matrix ${\\bf M}$ is factorizable (which means that the probability distribution is separable as $p_{ii'jj'}=p^A_{ij}p^B_{i'j'}$),\nthen all five factorizations coincide, all giving $M^A_{ji}=p^A_{ji}/p^A_{i\\cdot}$ and $M^B_{j'i'}=p^A_{i'j'}/p^A_{i'\\cdot}$.\nThis means that they will all agree on when $\\phi=0$; otherwise the noising factorizations will yield higher $\\phi$ than an optimized factorization.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|}\n\\hline\n&\t\t\t\t\t\t\t\t\t\t\t&\t\t\t\t\t&\t\t\t&\\multicolumn{3}{c|}{Conditioning option}\\\\\n\\cline{5-7}\n\n\t&\t\t\t\t\t\t\t\t\t\t&\t\t\t\t\t&\t\t\t&${\\bf x}_t$ unknown\t\t\t\t&${\\bf x}_t$-distribution separable\t\t\t\t&${\\bf x}_t$ known\\\\\nCode&Comparison option\t\t\t\t\t\t\t&$p$\t\t\t\t&$q$\t\t&$q^u$ ($p^{(0)}_{ij}=p_{ii'\\cdot\\cdot}$)\t&$q^s$ ($p^{(0)}_{ij}=p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}$)\t\t&$q^k$ ($p^{(0)}_{ij}=\\delta_{ik}\\delta_{i'k'}$)\\\\\n\\hline\nt\t&Two-time state\t\t\t\t\t\t\t\t&$p_{ii'jj'}$\\\t\t\t&$q_{ii'jj'}$\t&$M^A_{ji}M^B_{j'i'}p^{(0)}_{ii'}$\t&$\\left(M^A_{ji}p^{(0)}_{i\\cdot}\\right)\\left(M^B_{j'i'}p^{(0)}_{\\cdot i'}\\right)$\t&$M^A_{ji}\\delta_{ik}M^B_{j'i'}\\delta_{i'k'}$\\\\\nf\t&Future state\t\t\t\t\t\t\t\t&$p_{\\cdot\\cdot jj'}$\t\t&$q_{\\cdot\\cdot jj'}$\t&$\\sum\\limits_{ii'}M^A_{ji}M^B_{j'i'}p^{(0)}_{ii'}$\t\t&$\\left(\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}\\right)\\left(\\sum\\limits_{i'}M^B_{j'i'}p^{(0)}_{\\cdot i'}\\right)$\t&$M^A_{jk}M^B_{j'k'}$\\\\\na\t&Future state of subsystem A\t\t\t\t\t&$p_{\\cdot\\cdot j\\cdot}$\t&$q_{\\cdot\\cdot j\\cdot}$\t\t&$\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}$\t&$\\sum\\limits_i M^A_{ji}p^{(0)}_{i\\cdot}$\t&$M^A_{jk}$\\\\\np\t&Past state of subsystem A\t\t\t\t\t\t&$p_{i\\cdot \\cdot\\cdot}$\t&$\\tilde{q}_{i\\cdot \\cdot\\cdot}$\t&$\\sum\\limits_j\\tilde{M}^A_{ij}p^{(1)}_{j\\cdot}$\t&$\\sum\\limits_j\\tilde{M}^A_{ij}p^{(1)}_{j\\cdot}$\t&$\\tilde{M}^A_{ik}$\\\\\n\\hline\n\\end{tabular}\n\\caption{Different options for which probability distributions $p$ and $q$ to compare.\nThe last three columns specify the formula for $q$ for the three conditioning options we consider: when the state ${\\bf x}_0$ is unknown (u), has a separable probability distribution (s) and is known  (k), respectively.\n\\label{ComparisonTable}\n}\n}\n\\end{table*}\n\n\n\n\n\\subsection{Options for which probability distributions to compare}\n\\label{ComparisonSec}\n\n{Table~\\ref{{ComparisonTable}}} lists four options for which probability distributions $p$ and $q$ to compare. \nArguably the most natural option is to simply compare the full distributions $p_{ii'jj'}$ and $q_{ii'jj'}$ that  describe our knowledge of the system at both times (the present state and the future state).\nAnother obvious option is to merely compare the predictions, {\\frenchspacing\\it i.e.}, the probability distributions \n$p_{\\cdot\\cdot jj'}$ and $q_{\\cdot\\cdot jj'}$ for the future state.\nA third interesting option is to compare merely the predictions for one of the two subsystems (which we without loss of generality can take to be subsystem A), thus comparing $p_{\\cdot\\cdot j\\cdot}$ and $q_{\\cdot\\cdot j\\cdot}$.\n\nGenerally, the less we compare, the easier it is to get a low $\\phi$-value. \nTo see this, consider a system where $A$ affects $B$ but $B$ has no effect on $A$.\nWe could, for example, consider $A$ to be photoreceptor cells in your your retina and $B$ to be the rest of your brain.\nThen the second comparison option (``f\") in {Table~\\ref{{ComparisonTable}}} would give $\\phi>0$ because we predict the future of your brain worse if we ignore the information flow from your retina, \nwhile the third comparison option (``a\") in the table would give $\\phi=0$ because the rest of your brain does not help predict the future of your retina.\nIn other words,  comparison option ``a'' makes $\\phi$ vanish for {\\it afferent} pathways, where information flows only inward toward the rest of the system.\n\nIIT argues that any good $\\phi$-measure indeed {\\it should} vanish for afferent pathways, because a system can only be conscious if it can have effects on itself --- other systems that it is affected by without affecting will act merely as parts of its unconscious outside world \\cite{tononi2008consciousness}.\nAnalogously, IIT argues that any good $\\phi$-measure should vanish also for {\\it efferent} pathways,\nwhere information flows only outward away from the rest of the system.\nThe argument is that other systems that the conscious system affects without being affected by will again be unconscious, acting merely as unconscious parts of the outside world as far as the conscious system is concerned.\n\nOption ``p'' in {Table~\\ref{{ComparisonTable}}} has this property of $\\phi$ vanishing for efferent pathways.\nIt is simply the time-reverse of option ``a'', \nquantifying the ability of $x^A_1$ to determine its past cause $x^A_0$ instead of \nquantifying the ability of $x^A_0$ to determine its future effect $x^A_1$.\n\nTo formalize this, consider that there is nothing in the probability distribution $p_{ii'jj'}$ that breaks time-reversal symmetry and says that causation goes from $t_0$ to $t_1$ rather than vice versa. \nIn complete analogy with our formalism above, we can therefore define a time-reversed Markov process\n$\\tilde{{\\bf M}}$ whereby the future determines the past according to the time-reverse of {equation~(\\ref{{MarkovEq}})}:\n\n", "index": 27, "text": "\\begin{equation}\\label{{ReverseMarkovEq}}\n{\\bf p}^{(0)}=\\tilde{{\\bf M}}{\\bf p}^{(1)},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"{\\bf p}^{(0)}=\\tilde{{\\bf M}}{\\bf p}^{(1)},\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc29</mi><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><mover accent=\"true\"><mi>\ud835\udc0c</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msup><mi>\ud835\udc29</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nand\n\n", "itemtype": "equation", "pos": 34501, "prevtext": "\nwhere equations{~(\\ref{{MarkovMatrixEq2}})} and{~(\\ref{{qdefEq}})} get replaced  by\n\n", "index": 29, "text": "\\begin{equation}\\label{{ReverseMarkovMatrixEq}}\n\\tilde{M}_{ii'jj'}={p_{ii'jj'}\\over p_{\\cdot\\cdot jj'}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\tilde{M}_{ii^{\\prime}jj^{\\prime}}={p_{ii^{\\prime}jj^{\\prime}}\\over p_{\\cdot%&#10;\\cdot jj^{\\prime}}}\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><msub><mi>p</mi><mrow><mo>\u22c5</mo><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></mrow></mrow></msub></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nThis time reversal symmetry doubles the number of $q$-options we could list in \n {Table~\\ref{{ComparisonTable}}} to six in total, augmenting  \n $q_{ii'jj'}$,  $q_{\\cdot\\cdot jj'}$ and  $q_{\\cdot\\cdot j\\cdot}$ \n by \n$\\tilde{q}_{ii'jj'}$,  $\\tilde{q}_{\\cdot\\cdot jj'}$ and  $\\tilde{q}_{\\cdot\\cdot j\\cdot}$.\nIn the interest of brevity, we have chosen to only list $\\tilde{q}_{\\cdot\\cdot j\\cdot}$, because of its\nability to kill $\\phi$ for  efferent pathways --- the formulas for the two omitted options are trivially  analogous to those listed. \n\n\n\n\\subsection{Options for what to treat as known about the current state}\n\\label{ConditioningSec}\n\nAbove we listed options for which probabilities $p$ and $q$ to compare to compute $\\phi$. \nTo complete our specification of these probabilities, we need to choose between various options for our knowledge of the present state;\nthe three rightmost columns of {Table~\\ref{{ComparisonTable}}} correspond to three interesting choices.\n\nThe first option is where the state is unknown, described simply by the probability distribution we have used above:\n\n", "itemtype": "equation", "pos": 34624, "prevtext": "\nand\n\n", "index": 31, "text": "\\begin{equation}\\label{{qtildeDefEq}}\n\\tilde{q}_{ii'jj'}=\\tilde{M}^A_{ij}\\tilde{M}^B_{i'j'}p^{(1)}_{jj'}\\>.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\tilde{q}_{ii^{\\prime}jj^{\\prime}}=\\tilde{M}^{A}_{ij}\\tilde{M}^{B}_{i^{\\prime}%&#10;j^{\\prime}}p^{(1)}_{jj^{\\prime}}\\&gt;.\" display=\"block\"><mrow><mrow><msub><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mrow><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mi>A</mi></msubsup><mo>\u2062</mo><msubsup><mover accent=\"true\"><mi>M</mi><mo stretchy=\"false\">~</mo></mover><mrow><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup><mo>\u2062</mo><mpadded width=\"+2.2pt\"><msubsup><mi>p</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup></mpadded></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nThis corresponds to us knowing ${\\bf M}$, the mechanism by which the state evolves, but not knowing its current state ${\\bf x}_0$. \nNote that a generic Markov process eventually converges to a unique stationary state ${\\bf p}={\\bf p}^{(0)}={\\bf p}^{(1)}$ which, since it \nsatisfies ${\\bf M}{\\bf p}={\\bf p}$, can be computed directly from ${\\bf M}$ as the unique eigenvector whose eigenvalue is unity. This means that if we consider a system that has been evolving for a significantly long time, its full two-time distribution $p_{ii'jj'}$ is determined by ${\\bf M}$ alone; conversely, $p_{ii'jj'}$ determines ${\\bf M}$ through {equation~(\\ref{{MarkovMatrixEq2}})}.\nAlternatively, if $p_{ii'jj'}$ is measured empirically from a time-series ${\\bf x}_t$ which is then used to compute ${\\bf M}$, \nwe can use {equation~(\\ref{{UnknownStateOptionEq}})} to describe our knowledge of the state at a random time. \n\nA second option is to assume that we know the initial probability distributions for  ${\\bf x}^A_0$ and ${\\bf x}^B_0$, but know nothing about any correlations between them.\nThis corresponds to replacing {equation~(\\ref{{UnknownStateOptionEq}})} by the separable distribution\n\n", "itemtype": "equation", "pos": 35839, "prevtext": "\nThis time reversal symmetry doubles the number of $q$-options we could list in \n {Table~\\ref{{ComparisonTable}}} to six in total, augmenting  \n $q_{ii'jj'}$,  $q_{\\cdot\\cdot jj'}$ and  $q_{\\cdot\\cdot j\\cdot}$ \n by \n$\\tilde{q}_{ii'jj'}$,  $\\tilde{q}_{\\cdot\\cdot jj'}$ and  $\\tilde{q}_{\\cdot\\cdot j\\cdot}$.\nIn the interest of brevity, we have chosen to only list $\\tilde{q}_{\\cdot\\cdot j\\cdot}$, because of its\nability to kill $\\phi$ for  efferent pathways --- the formulas for the two omitted options are trivially  analogous to those listed. \n\n\n\n\\subsection{Options for what to treat as known about the current state}\n\\label{ConditioningSec}\n\nAbove we listed options for which probabilities $p$ and $q$ to compare to compute $\\phi$. \nTo complete our specification of these probabilities, we need to choose between various options for our knowledge of the present state;\nthe three rightmost columns of {Table~\\ref{{ComparisonTable}}} correspond to three interesting choices.\n\nThe first option is where the state is unknown, described simply by the probability distribution we have used above:\n\n", "index": 33, "text": "\\begin{equation}\\label{{UnknownStateOptionEq}}\np^{(0)}_{ij}=p_{ii'\\cdot\\cdot}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"p^{(0)}_{ij}=p_{ii^{\\prime}\\cdot\\cdot}\" display=\"block\"><mrow><msubsup><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nand can be advantageous for $\\phi$-measures that would conflate integration with initial correlations between the subsystems.\n\nA third option, advocated by IIT \\cite{tononi2008consciousness}, is to treat the current state as known:\n\n", "itemtype": "equation", "pos": 37111, "prevtext": "\nThis corresponds to us knowing ${\\bf M}$, the mechanism by which the state evolves, but not knowing its current state ${\\bf x}_0$. \nNote that a generic Markov process eventually converges to a unique stationary state ${\\bf p}={\\bf p}^{(0)}={\\bf p}^{(1)}$ which, since it \nsatisfies ${\\bf M}{\\bf p}={\\bf p}$, can be computed directly from ${\\bf M}$ as the unique eigenvector whose eigenvalue is unity. This means that if we consider a system that has been evolving for a significantly long time, its full two-time distribution $p_{ii'jj'}$ is determined by ${\\bf M}$ alone; conversely, $p_{ii'jj'}$ determines ${\\bf M}$ through {equation~(\\ref{{MarkovMatrixEq2}})}.\nAlternatively, if $p_{ii'jj'}$ is measured empirically from a time-series ${\\bf x}_t$ which is then used to compute ${\\bf M}$, \nwe can use {equation~(\\ref{{UnknownStateOptionEq}})} to describe our knowledge of the state at a random time. \n\nA second option is to assume that we know the initial probability distributions for  ${\\bf x}^A_0$ and ${\\bf x}^B_0$, but know nothing about any correlations between them.\nThis corresponds to replacing {equation~(\\ref{{UnknownStateOptionEq}})} by the separable distribution\n\n", "index": 35, "text": "\\begin{equation}\\label{{SeparableStateOptionEq}}\np^{(0)}_{ij}=p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"p^{(0)}_{ij}=p_{i\\cdot\\cdot\\cdot}p_{\\cdot i^{\\prime}\\cdot\\cdot},\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u22ef</mi></mrow></msub><mo>\u2062</mo><msub><mi>p</mi><mrow><mrow><mi/><mo>\u22c5</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n{\\frenchspacing\\it i.e.}, we know with certainty that the current state ${\\bf x}_0=kk'$ for some constants $k$ and $k'$.\nIIT argues that this is the correct option from the vantage point of a conscious system which, by definition, knows its own state.\n\n\nA natural fourth option is a more extreme version of the first: treating the state not merely as unknown, with \n$p^{(0)}$ given by its ensemble distribution, but completely unknown, with a uniform distribution:\n\n", "itemtype": "equation", "pos": 37464, "prevtext": "\nand can be advantageous for $\\phi$-measures that would conflate integration with initial correlations between the subsystems.\n\nA third option, advocated by IIT \\cite{tononi2008consciousness}, is to treat the current state as known:\n\n", "index": 37, "text": "\\begin{equation}\\label{{KnownStateOptionEq}}\np^{(0)}_{ij}=\\delta_{ik}\\delta_{i'k'},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"p^{(0)}_{ij}=\\delta_{ik}\\delta_{i^{\\prime}k^{\\prime}},\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><msub><mi>\u03b4</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><msub><mi>\u03b4</mi><mrow><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>k</mi><mo>\u2032</mo></msup></mrow></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nAlthough straightforward enough to use in our formulas, we have chosen not to include this option in {Table~\\ref{{ComparisonTable}}} because it is rather inappropriate for most physical systems. For continuous variables such as voltages, it becomes undefined. For brains, such maximum-entropy states never occur: they would have typical neurons firing about half the time, corresponding to much more extreme ``on\" behavior than during an epileptic seizure. \n\nFinally, please note that if we choose to determine the past rather than the future \n(the ``p\"-option from the previous section and {Table~\\ref{{ComparisonTable}}}), then all the choices we have described should be applied \nto $p^{(1)}_{ij}$ rather than $p^{(0)}_{ij}$.\n \n \n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|l|}\n\\hline\nCode&Metric\t\t&Definition\t\t\t\t\t\t\t&Positivity\t&Monotonicity\t&Interpretability\t&Tractability\t&Symmetry\\\\\n\\hline\nk&$d_{KL}({\\bf p},{\\bf q})$\t&$\\sum\\limits_\\alpha p_\\alpha \\log {p_\\alpha\\over q_\\alpha}$\t\t&Y&Y&Y&Y&N\\\\\n1&$d_1({\\bf p},{\\bf q})$\t\t&$\\sum\\limits_\\alpha |p_\\alpha-q_\\alpha|$\t\t\t\t\t&Y&Y&(Y)&N&Y\\\\\n2&$d_2({\\bf p},{\\bf q})$\t\t&$\\left[\\sum\\limits_\\alpha(p_\\alpha-q_\\alpha)^2\\right]^{1/2}$\t&Y&Y&(N)&(Y)&Y\\\\\nh&$d_H({\\bf p},{\\bf q})$\t\t&$\\cos^{-1}\\sum\\limits_\\alpha (p_\\alpha q_\\alpha)^{1/2}$\t\t&Y&Y&Y&N&Y\\\\\ne&$d_{EM}({\\bf p},{\\bf q})$\t&$\\min\\limits_{f_{\\alpha\\beta}\\ge 0}\\sum\\limits_{\\alpha\\beta}f_{\\alpha\\beta}d_{\\alpha\\beta}; \\quad f_{\\alpha\\cdot}=p_\\alpha, f_{\\cdot\\beta}=q_\\beta$\t&Y&Y&Y&N&Y\\\\\n\n\n\n\n\n\n\n\\hline\n\\end{tabular}\n\\caption{Different options for measuring the difference $d$ between two probability distributions ${\\bf p}$ and ${\\bf q}$.\nIn the text, we considered options where ${\\bf p}$ and ${\\bf q}$ had one, two or four indices, but in  this table, we have for simplicity combined all indices into a single Greek index $\\alpha$.\n\\label{MetricTable}\n}\n}\n\\end{table*}\n\n\n\\subsection{Options for comparing probability distributions}\n\nThe options in the past three sections uniquely specify two probability distributions ${\\bf p}$ and ${\\bf q}$, and we want the integration $\\phi$ to quantify how different they are from one another:\n\n", "itemtype": "equation", "pos": 38028, "prevtext": "\n{\\frenchspacing\\it i.e.}, we know with certainty that the current state ${\\bf x}_0=kk'$ for some constants $k$ and $k'$.\nIIT argues that this is the correct option from the vantage point of a conscious system which, by definition, knows its own state.\n\n\nA natural fourth option is a more extreme version of the first: treating the state not merely as unknown, with \n$p^{(0)}$ given by its ensemble distribution, but completely unknown, with a uniform distribution:\n\n", "index": 39, "text": "\\begin{equation}\\label{{UniformStateOptionEq}}\np^{(0)}_{ij}=\\hbox{constant}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"p^{(0)}_{ij}=\\hbox{constant}.\" display=\"block\"><mrow><mrow><msubsup><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mtext>constant</mtext></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nfor some distance measure $d$ that is larger the worse ${\\bf q}$ approximates ${\\bf p}$.\n\nThere are a number of properties that we may consider desirable for $d$ to quantify integration:\n\\begin{enumerate}\n\\item {\\bf Positivity:} $d({\\bf p},{\\bf q})\\ge 0$, with equality if and only if ${\\bf p}={\\bf q}$.\n\\item {\\bf Monotonicity:} The more different ${\\bf q}$ is from ${\\bf p}$ in some intuitive sense, the larger $d({\\bf p},{\\bf q})$ gets.\n\\item {\\bf Interpretability:} $d({\\bf p},{\\bf q})$ can be intuitively interpreted, for example in terms of information theory.\n\\item {\\bf Tractability:} $d({\\bf p},{\\bf q})$ is easy to compute numerically. Ideally, the optimal factorizations from {Section~\\ref{{FactorizationSec}}} can be found analytically rather than through time-consuming numerical minimization. \n\\item {\\bf Symmetry:} $d({\\bf p},{\\bf q})=d({\\bf q},{\\bf p})$.\n\\end{enumerate}\nAny distance measure $d$ meets the mathematical requirements of being a {\\it metric} on the space of probability distributions if it obeys positivity, symmetry and the triangle inequality $d({\\bf p},{\\bf q})\\le d({\\bf p},{\\bf r})+d({\\bf r},{\\bf q})$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{Table~\\ref{{MetricTable}}} lists five interesting probability distribution distance measures $d({\\bf p},{\\bf q})$ from the literature together with their definitions and properties.\nAll these measures are seen to have the positivity and monotonicity, \nand all except the first are also symmetric and true metrics. \n\n\nWe will now discuss them one by one in greater detail.\n\nThe distance $d_{KL}$ is the \nKullback-Leibler divergence, and measures how many bits of information are lost when ${\\bf q}$ is used to approximate ${\\bf p}$, in the sense that if you developed an optimal data compression algorithm to compress data drawn from a probability distribution ${\\bf q}$, it would on average require $d_{KL}({\\bf p},{\\bf q})$ more bits to compress data drawn from a probability distribution ${\\bf p}$ than if the algorithm had been optimized for ${\\bf p}$ \\cite{kullback1951information}. \n\n$d_1$ and $d_2$ measure the distance between the vectors ${\\bf p}$ and ${\\bf q}$ using \nthe $L_1$-norm and $L_2$-norm, respectively. The former is particularly natural for probability distributions ${\\bf p}$, since they all have $L_1$ norm of unity: $d_1(0,{\\bf p})=p_.=1$. \nIf is easy to see that \n$0\\le d_1({\\bf p},{\\bf q})\\le 2$ and \n$0\\le d_2({\\bf p},{\\bf q})\\le \\sqrt{2}$.\n\nThe measure $d_H$ is the Hilbert-space distance: if, for each probability distribution, we define a corresponding wavefunction $\\psi_i\\equiv p_i^{1/2}$, then all wavefunctions lie on a unit hyperspere since they all have unit length: \n $<\\psi|\\psi>=p_.=1$.\nThe distance $d_H$ is simply the angle between two wavefunctions, {\\frenchspacing\\it i.e.}., the distance along the great circle on the hypersphere that connects the two, so $d_H({\\bf p},{\\bf q})\\le \\pi/2$.\nIt is also the geodesic distance of the Fisher metric, hence a natural ``coordinate free\" distance measure on the manifold of all probability distributions.\n\nThe measure $d_H$ is the Earth-Movers distance \\cite{rubner1998metric}. If we imagine piles of earth scattered across the space ${\\bf x}$, with $p({\\bf x})$ specifying the fraction of the\nearth that is in each location, then $d_{EM}$ is the average distance that you need to move earth to turn the distribution $p({\\bf x})$ into $q({\\bf x})$. The quantity $d_{ij}$ in the definition in {Table~\\ref{{MetricTable}}}\n\nspecifies the distance between points $i$ and  $j$ in this space. For example, if ${\\bf x}$ is a 3D Euclidean space, this may be chosen to be simply the Euclidean metric, while if ${\\bf x}$ is a bit string, $d_{ij}$ may be chosen to be the $L_1$ ``Manhattan distance\", {\\frenchspacing\\it i.e.}, the number of bit flips required to transform one bit string into another. \nIIT 3.0 argues that the earth mover's distance $d_{EM}$ is the most appropriate measure $d$ on conceptual grounds (whereas IIT 2.0 advocated $d_{KL}$). Unfortunately, $d_{EM}$ rates poorly on the tractability criterion. It's definition involves a linear programming problem \nwhich needs to be solved numerically, and even with the fastest algorithms currently available, the computation grows faster than quadratically with the number of system states --- which in turn grows exponentially with the number of bits. For continuous variables ${\\bf x}$, the number of states and hence the computational time is formally infinite. \n\n\n\n\n\n\n\n\n\n\n\n\\section{Taxonomy results}\n\n\n\\subsection{Optimal factorization with $d_{KL}$}\n\nOur taxonomy of integration measures is determined by four choices: of factorization, variable selection, conditioning and distance measure.\nAlthough we have now explored these four choices one at a time, there are important interplays between them that we must examine.\nFirst of all, the three optimal factorization options in {Table~\\ref{{FactorizationTable}}} depend on what is being optimized, so let us now explore which of these optimizations are feasible and interesting to perform in practice and let us find out what the corresponding factorizations and $\\phi$-measures are.\n\nThe mathematics problem we wish to solve is \n\n", "itemtype": "equation", "pos": 40261, "prevtext": "\nAlthough straightforward enough to use in our formulas, we have chosen not to include this option in {Table~\\ref{{ComparisonTable}}} because it is rather inappropriate for most physical systems. For continuous variables such as voltages, it becomes undefined. For brains, such maximum-entropy states never occur: they would have typical neurons firing about half the time, corresponding to much more extreme ``on\" behavior than during an epileptic seizure. \n\nFinally, please note that if we choose to determine the past rather than the future \n(the ``p\"-option from the previous section and {Table~\\ref{{ComparisonTable}}}), then all the choices we have described should be applied \nto $p^{(1)}_{ij}$ rather than $p^{(0)}_{ij}$.\n \n \n\\begin{table*}\n{\\footnotesize\n\\begin{tabular}{|l|l|l|l|l|l|l|l|}\n\\hline\nCode&Metric\t\t&Definition\t\t\t\t\t\t\t&Positivity\t&Monotonicity\t&Interpretability\t&Tractability\t&Symmetry\\\\\n\\hline\nk&$d_{KL}({\\bf p},{\\bf q})$\t&$\\sum\\limits_\\alpha p_\\alpha \\log {p_\\alpha\\over q_\\alpha}$\t\t&Y&Y&Y&Y&N\\\\\n1&$d_1({\\bf p},{\\bf q})$\t\t&$\\sum\\limits_\\alpha |p_\\alpha-q_\\alpha|$\t\t\t\t\t&Y&Y&(Y)&N&Y\\\\\n2&$d_2({\\bf p},{\\bf q})$\t\t&$\\left[\\sum\\limits_\\alpha(p_\\alpha-q_\\alpha)^2\\right]^{1/2}$\t&Y&Y&(N)&(Y)&Y\\\\\nh&$d_H({\\bf p},{\\bf q})$\t\t&$\\cos^{-1}\\sum\\limits_\\alpha (p_\\alpha q_\\alpha)^{1/2}$\t\t&Y&Y&Y&N&Y\\\\\ne&$d_{EM}({\\bf p},{\\bf q})$\t&$\\min\\limits_{f_{\\alpha\\beta}\\ge 0}\\sum\\limits_{\\alpha\\beta}f_{\\alpha\\beta}d_{\\alpha\\beta}; \\quad f_{\\alpha\\cdot}=p_\\alpha, f_{\\cdot\\beta}=q_\\beta$\t&Y&Y&Y&N&Y\\\\\n\n\n\n\n\n\n\n\\hline\n\\end{tabular}\n\\caption{Different options for measuring the difference $d$ between two probability distributions ${\\bf p}$ and ${\\bf q}$.\nIn the text, we considered options where ${\\bf p}$ and ${\\bf q}$ had one, two or four indices, but in  this table, we have for simplicity combined all indices into a single Greek index $\\alpha$.\n\\label{MetricTable}\n}\n}\n\\end{table*}\n\n\n\\subsection{Options for comparing probability distributions}\n\nThe options in the past three sections uniquely specify two probability distributions ${\\bf p}$ and ${\\bf q}$, and we want the integration $\\phi$ to quantify how different they are from one another:\n\n", "index": 41, "text": "\\begin{equation}\\label{{phiDefEq}}\n\\phi\\equiv d({\\bf p},{\\bf q})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\phi\\equiv d({\\bf p},{\\bf q})\" display=\"block\"><mrow><mi>\u03d5</mi><mo>\u2261</mo><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo>,</mo><mi>\ud835\udc2a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n{\\frenchspacing\\it i.e.}, minimizing $d({\\bf p},{\\bf q})$ over ${\\bf M}^A$ and ${\\bf M}^B$ given the constraints that \n${\\bf M}^A$ and ${\\bf M}^B$ are markov Matrices: $M^A_{\\cdot j}=1$, $M^B_{\\cdot j'}=1$, $M^A_{ij}\\ge 0$ and $M^B_{i'j'}\\ge 0$.\n{Table~\\ref{{ComparisonTable}}} specifies the options for how ${\\bf p}$ and ${\\bf q}$ are computed and how ${\\bf q}$ depends on ${\\bf M}^A$ and ${\\bf M}^B$, while {Table~\\ref{{MetricTable}}} specifies the options for computing the distance measure $d$.\nWe enforce the column sum constraints using Lagrange multipliers, minimizing \n\n", "itemtype": "equation", "pos": 45517, "prevtext": "\nfor some distance measure $d$ that is larger the worse ${\\bf q}$ approximates ${\\bf p}$.\n\nThere are a number of properties that we may consider desirable for $d$ to quantify integration:\n\\begin{enumerate}\n\\item {\\bf Positivity:} $d({\\bf p},{\\bf q})\\ge 0$, with equality if and only if ${\\bf p}={\\bf q}$.\n\\item {\\bf Monotonicity:} The more different ${\\bf q}$ is from ${\\bf p}$ in some intuitive sense, the larger $d({\\bf p},{\\bf q})$ gets.\n\\item {\\bf Interpretability:} $d({\\bf p},{\\bf q})$ can be intuitively interpreted, for example in terms of information theory.\n\\item {\\bf Tractability:} $d({\\bf p},{\\bf q})$ is easy to compute numerically. Ideally, the optimal factorizations from {Section~\\ref{{FactorizationSec}}} can be found analytically rather than through time-consuming numerical minimization. \n\\item {\\bf Symmetry:} $d({\\bf p},{\\bf q})=d({\\bf q},{\\bf p})$.\n\\end{enumerate}\nAny distance measure $d$ meets the mathematical requirements of being a {\\it metric} on the space of probability distributions if it obeys positivity, symmetry and the triangle inequality $d({\\bf p},{\\bf q})\\le d({\\bf p},{\\bf r})+d({\\bf r},{\\bf q})$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n{Table~\\ref{{MetricTable}}} lists five interesting probability distribution distance measures $d({\\bf p},{\\bf q})$ from the literature together with their definitions and properties.\nAll these measures are seen to have the positivity and monotonicity, \nand all except the first are also symmetric and true metrics. \n\n\nWe will now discuss them one by one in greater detail.\n\nThe distance $d_{KL}$ is the \nKullback-Leibler divergence, and measures how many bits of information are lost when ${\\bf q}$ is used to approximate ${\\bf p}$, in the sense that if you developed an optimal data compression algorithm to compress data drawn from a probability distribution ${\\bf q}$, it would on average require $d_{KL}({\\bf p},{\\bf q})$ more bits to compress data drawn from a probability distribution ${\\bf p}$ than if the algorithm had been optimized for ${\\bf p}$ \\cite{kullback1951information}. \n\n$d_1$ and $d_2$ measure the distance between the vectors ${\\bf p}$ and ${\\bf q}$ using \nthe $L_1$-norm and $L_2$-norm, respectively. The former is particularly natural for probability distributions ${\\bf p}$, since they all have $L_1$ norm of unity: $d_1(0,{\\bf p})=p_.=1$. \nIf is easy to see that \n$0\\le d_1({\\bf p},{\\bf q})\\le 2$ and \n$0\\le d_2({\\bf p},{\\bf q})\\le \\sqrt{2}$.\n\nThe measure $d_H$ is the Hilbert-space distance: if, for each probability distribution, we define a corresponding wavefunction $\\psi_i\\equiv p_i^{1/2}$, then all wavefunctions lie on a unit hyperspere since they all have unit length: \n $<\\psi|\\psi>=p_.=1$.\nThe distance $d_H$ is simply the angle between two wavefunctions, {\\frenchspacing\\it i.e.}., the distance along the great circle on the hypersphere that connects the two, so $d_H({\\bf p},{\\bf q})\\le \\pi/2$.\nIt is also the geodesic distance of the Fisher metric, hence a natural ``coordinate free\" distance measure on the manifold of all probability distributions.\n\nThe measure $d_H$ is the Earth-Movers distance \\cite{rubner1998metric}. If we imagine piles of earth scattered across the space ${\\bf x}$, with $p({\\bf x})$ specifying the fraction of the\nearth that is in each location, then $d_{EM}$ is the average distance that you need to move earth to turn the distribution $p({\\bf x})$ into $q({\\bf x})$. The quantity $d_{ij}$ in the definition in {Table~\\ref{{MetricTable}}}\n\nspecifies the distance between points $i$ and  $j$ in this space. For example, if ${\\bf x}$ is a 3D Euclidean space, this may be chosen to be simply the Euclidean metric, while if ${\\bf x}$ is a bit string, $d_{ij}$ may be chosen to be the $L_1$ ``Manhattan distance\", {\\frenchspacing\\it i.e.}, the number of bit flips required to transform one bit string into another. \nIIT 3.0 argues that the earth mover's distance $d_{EM}$ is the most appropriate measure $d$ on conceptual grounds (whereas IIT 2.0 advocated $d_{KL}$). Unfortunately, $d_{EM}$ rates poorly on the tractability criterion. It's definition involves a linear programming problem \nwhich needs to be solved numerically, and even with the fastest algorithms currently available, the computation grows faster than quadratically with the number of system states --- which in turn grows exponentially with the number of bits. For continuous variables ${\\bf x}$, the number of states and hence the computational time is formally infinite. \n\n\n\n\n\n\n\n\n\n\n\n\\section{Taxonomy results}\n\n\n\\subsection{Optimal factorization with $d_{KL}$}\n\nOur taxonomy of integration measures is determined by four choices: of factorization, variable selection, conditioning and distance measure.\nAlthough we have now explored these four choices one at a time, there are important interplays between them that we must examine.\nFirst of all, the three optimal factorization options in {Table~\\ref{{FactorizationTable}}} depend on what is being optimized, so let us now explore which of these optimizations are feasible and interesting to perform in practice and let us find out what the corresponding factorizations and $\\phi$-measures are.\n\nThe mathematics problem we wish to solve is \n\n", "index": 43, "text": "\\begin{equation}\\label{{MinimizationEq}}\n\\phi\\equiv\\min_{{\\bf M}^A,{\\bf M}^B} d({\\bf p},{\\bf q})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\phi\\equiv\\min_{{\\bf M}^{A},{\\bf M}^{B}}d({\\bf p},{\\bf q})\" display=\"block\"><mrow><mi>\u03d5</mi><mo>\u2261</mo><mrow><mrow><munder><mi>min</mi><mrow><msup><mi>\ud835\udc0c</mi><mi>A</mi></msup><mo>,</mo><msup><mi>\ud835\udc0c</mi><mi>B</mi></msup></mrow></munder><mo>\u2061</mo><mi>d</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo>,</mo><mi>\ud835\udc2a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nand need to check afterwards that all elements of ${\\bf M}^A$ and ${\\bf M}^B$ come out to be non-negative (we will see that this is indeed the case).\n\nAs mentioned, numerical tractability is a key issue for integration measures. This means that it is valuable if  the Lagrange minimization can be rapidly solved analytically rather than slowly by numerical means, since this needs to be done separately for large numbers of possible system partitions. We find that there is only one $d$-option out of the above-mentioned five for which the optimization over ${\\bf M}$-factorizations can be solved analytically: the KL-divergence $d_{KL}$. The runner-up for tractability is $d_2$, for which everything can be solved analytically except for a final column normalization step, but the resulting formulas are cumbersome and unilluminating, falling foul of the interpretability criterion. Although $d_{KL}$ lacks the symmetry property, it has the above-mentioned positivity, monotonicity and interpretability properties, and we will now show that it also has the tractability property.\n\nLet us begin with the $q$-options in the upper left corner of {Table~\\ref{{ComparisonTable}}}, {\\frenchspacing\\it i.e.}, comparing the two-time distributions treating the present state as unknown.\nSubstituting {equation~(\\ref{{qdefEq}})} into the definition of $d_{KL}$ from {Table~\\ref{{MetricTable}}}\n\ngives\n\\begin{eqnarray}\\label{{SeparableKLphiEq}}\n&&d_{KL}({\\bf p},{\\bf q})=\\sum_{ii'jj'} p_{ii'jj'} \\log{p_{ii'jj'}\\over p_{ii'\\cdot\\cdot} M^A_{ji}M^B_{j'i'}}=\\\\\n&&S({\\bf x}_0)-S({\\bf x})-\\sum_{ij}p_{i\\cdot j\\cdot}\\log M^A_{ji}-\\sum_{i'j'}p_{\\cdot i'\\cdot j'}\\log M^B_{j'i'},\\nonumber\n\\end{eqnarray}\nwhere the entropy for a random variable ${\\bf x}$ with probability distribution ${\\bf p}$ is given by Shannon's formula \\cite{shannon1948mathematical}\n\n", "itemtype": "equation", "pos": 46206, "prevtext": "\n{\\frenchspacing\\it i.e.}, minimizing $d({\\bf p},{\\bf q})$ over ${\\bf M}^A$ and ${\\bf M}^B$ given the constraints that \n${\\bf M}^A$ and ${\\bf M}^B$ are markov Matrices: $M^A_{\\cdot j}=1$, $M^B_{\\cdot j'}=1$, $M^A_{ij}\\ge 0$ and $M^B_{i'j'}\\ge 0$.\n{Table~\\ref{{ComparisonTable}}} specifies the options for how ${\\bf p}$ and ${\\bf q}$ are computed and how ${\\bf q}$ depends on ${\\bf M}^A$ and ${\\bf M}^B$, while {Table~\\ref{{MetricTable}}} specifies the options for computing the distance measure $d$.\nWe enforce the column sum constraints using Lagrange multipliers, minimizing \n\n", "index": 45, "text": "\\begin{equation}\\label{{LagrangeEq}}\n{\\cal L}\\equiv d({\\bf p},{\\bf q}) -\\sum_i \\lambda_i (M^A_{\\cdot i}-1)-\\sum_{i'} \\mu_{i'} (M^B_{\\cdot i'}-1),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"{\\cal L}\\equiv d({\\bf p},{\\bf q})-\\sum_{i}\\lambda_{i}(M^{A}_{\\cdot i}-1)-\\sum_%&#10;{i^{\\prime}}\\mu_{i^{\\prime}}(M^{B}_{\\cdot i^{\\prime}}-1),\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2112</mi><mo>\u2261</mo><mrow><mrow><mi>d</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo>,</mo><mi>\ud835\udc2a</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>\u03bb</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>M</mi><mrow><mi/><mo>\u22c5</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msup><mi>i</mi><mo>\u2032</mo></msup></munder><mrow><msub><mi>\u03bc</mi><msup><mi>i</mi><mo>\u2032</mo></msup></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>M</mi><mrow><mi/><mo>\u22c5</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nTo avoid a profusion of notation, we will often write as the argument of $S$ a random variable rather than its probability distribution.\nFor convenience, we will take all logarithms to be in base 2 for discrete distributions (so that entropies are measure in units of bits) and in base $e$ for continuous Gaussian distributions (so that equations get simpler).  In the latter case, where the entropy is based on the natural logarithm,  entropy is measured in ``nits\" which equal $1/\\ln 2\\approx 1.44$ bits.\n\nSubstituting {equation~(\\ref{{SeparableKLphiEq}})} into {equation~(\\ref{{LagrangeEq}})} and requiring vanishing derivatives with respect to $M^A_{ij}$, $M^B_{i'j'}$, $\\lambda_j$ and $\\mu_{j'}$ shows that the solution to our minimization problem is \n\n", "itemtype": "equation", "pos": 48204, "prevtext": "\nand need to check afterwards that all elements of ${\\bf M}^A$ and ${\\bf M}^B$ come out to be non-negative (we will see that this is indeed the case).\n\nAs mentioned, numerical tractability is a key issue for integration measures. This means that it is valuable if  the Lagrange minimization can be rapidly solved analytically rather than slowly by numerical means, since this needs to be done separately for large numbers of possible system partitions. We find that there is only one $d$-option out of the above-mentioned five for which the optimization over ${\\bf M}$-factorizations can be solved analytically: the KL-divergence $d_{KL}$. The runner-up for tractability is $d_2$, for which everything can be solved analytically except for a final column normalization step, but the resulting formulas are cumbersome and unilluminating, falling foul of the interpretability criterion. Although $d_{KL}$ lacks the symmetry property, it has the above-mentioned positivity, monotonicity and interpretability properties, and we will now show that it also has the tractability property.\n\nLet us begin with the $q$-options in the upper left corner of {Table~\\ref{{ComparisonTable}}}, {\\frenchspacing\\it i.e.}, comparing the two-time distributions treating the present state as unknown.\nSubstituting {equation~(\\ref{{qdefEq}})} into the definition of $d_{KL}$ from {Table~\\ref{{MetricTable}}}\n\ngives\n\\begin{eqnarray}\\label{{SeparableKLphiEq}}\n&&d_{KL}({\\bf p},{\\bf q})=\\sum_{ii'jj'} p_{ii'jj'} \\log{p_{ii'jj'}\\over p_{ii'\\cdot\\cdot} M^A_{ji}M^B_{j'i'}}=\\\\\n&&S({\\bf x}_0)-S({\\bf x})-\\sum_{ij}p_{i\\cdot j\\cdot}\\log M^A_{ji}-\\sum_{i'j'}p_{\\cdot i'\\cdot j'}\\log M^B_{j'i'},\\nonumber\n\\end{eqnarray}\nwhere the entropy for a random variable ${\\bf x}$ with probability distribution ${\\bf p}$ is given by Shannon's formula \\cite{shannon1948mathematical}\n\n", "index": 47, "text": "\\begin{equation}\\label{{SdefEq}}\nS({\\bf x})=-\\sum_i p_i\\log p_i.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"S({\\bf x})=-\\sum_{i}p_{i}\\log p_{i}.\" display=\"block\"><mrow><mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><msub><mi>p</mi><mi>i</mi></msub></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n\n\n\n\nWe recognize these equations as simply the Markov matrix estimator from {equation~(\\ref{{MarkovMatrixEq}})} applied separately to subsystems A and B after marginalizing over the other system. \nSubstituting this back into {equation~(\\ref{{qdefEq}})} gives \n\n", "itemtype": "equation", "pos": 49041, "prevtext": "\nTo avoid a profusion of notation, we will often write as the argument of $S$ a random variable rather than its probability distribution.\nFor convenience, we will take all logarithms to be in base 2 for discrete distributions (so that entropies are measure in units of bits) and in base $e$ for continuous Gaussian distributions (so that equations get simpler).  In the latter case, where the entropy is based on the natural logarithm,  entropy is measured in ``nits\" which equal $1/\\ln 2\\approx 1.44$ bits.\n\nSubstituting {equation~(\\ref{{SeparableKLphiEq}})} into {equation~(\\ref{{LagrangeEq}})} and requiring vanishing derivatives with respect to $M^A_{ij}$, $M^B_{i'j'}$, $\\lambda_j$ and $\\mu_{j'}$ shows that the solution to our minimization problem is \n\n", "index": 49, "text": "\\begin{equation}\\label{{OptimalSeparableMarkovEq}}\nM^A_{ji}={p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}},\n\\quad\nM^B_{j'i'}={p_{\\cdot i'\\cdot j'}\\over p_{\\cdot i'\\cdot\\cdot}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"M^{A}_{ji}={p_{i\\cdot j\\cdot}\\over p_{i\\cdot\\cdot\\cdot}},\\quad M^{B}_{j^{%&#10;\\prime}i^{\\prime}}={p_{\\cdot i^{\\prime}\\cdot j^{\\prime}}\\over p_{\\cdot i^{%&#10;\\prime}\\cdot\\cdot}}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u22c5</mo><mi>j</mi></mrow><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u22ef</mi></mrow></msub></mfrac></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msubsup><mi>M</mi><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mi/><mo>\u22c5</mo><mrow><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u22c5</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></mrow></msub><msub><mi>p</mi><mrow><mrow><mi/><mo>\u22c5</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mfrac></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nSubstituting this back into\nthe definition of $d_{KL}$ \n\ngives the extremely simple result that the integration is \n\\begin{eqnarray}\\label{{MarkovPhiEq}}\n\\phi^{otuk}({\\bf p}) &=& \n\\sum_{ii'jj'} p_{ii'jj'} \n\\log{p_{ii'jj'}  p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot} \\over p_{ii'\\cdot\\cdot} p_{i\\cdot j\\cdot} p_{\\cdot i'\\cdot j'}}\\nonumber\\\\\n&=&I({\\bf x}^A,{\\bf x}^B) - I({\\bf x}^A_0,{\\bf x}^B_0),\n\\end{eqnarray}\nwhere the mutual information between two random variables is given in terms of entropies by the standard definition\n\n", "itemtype": "equation", "pos": 49492, "prevtext": "\n\n\n\n\nWe recognize these equations as simply the Markov matrix estimator from {equation~(\\ref{{MarkovMatrixEq}})} applied separately to subsystems A and B after marginalizing over the other system. \nSubstituting this back into {equation~(\\ref{{qdefEq}})} gives \n\n", "index": 51, "text": "\\begin{equation}\\label{{OptimalqEq}}\nq_{ii'jj'} = {p_{ii'\\cdot\\cdot} p_{i\\cdot j\\cdot} p_{\\cdot i'\\cdot j'}\\over p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"q_{ii^{\\prime}jj^{\\prime}}={p_{ii^{\\prime}\\cdot\\cdot}p_{i\\cdot j\\cdot}p_{\\cdot&#10;i%&#10;^{\\prime}\\cdot j^{\\prime}}\\over p_{i\\cdot\\cdot\\cdot}p_{\\cdot i^{\\prime}\\cdot%&#10;\\cdot}}.\" display=\"block\"><mrow><mrow><msub><mi>q</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub><mo>\u2062</mo><msub><mi>p</mi><mrow><mrow><mi>i</mi><mo>\u22c5</mo><mi>j</mi></mrow><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub><mo>\u2062</mo><msub><mi>p</mi><mrow><mi/><mo>\u22c5</mo><mrow><msup><mi>i</mi><mo>\u2032</mo></msup><mo>\u22c5</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></mrow></msub></mrow><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u22ef</mi></mrow></msub><mo>\u2062</mo><msub><mi>p</mi><mrow><mrow><mi/><mo>\u22c5</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n\nSince we will be deriving a large number of different $\\phi$-measures that we do not with to conflate with one another, we superscript each one with four code letters denoting the four taxonomical choices that define it. \nThese letter codes are \n\\begin{enumerate}\n\\item Factorization: n/m/o/x/a\n\\item comparison: t/f/a/p\n\\item conditioning: u/s/k\n\\item measure: k/1/2/h/e\n\\end{enumerate}\nand are defined in Tables~\\ref{FactorizationTable}, \\ref{ComparisonTable} and \\ref{MeasureTable}. For example, the integration measure $\\phi^{otuk}$ from {equation~(\\ref{{MarkovPhiEq}})} denotes optimized (o) factorization comparing the two-time (t) probability distributions with the current state unknown (u) and KL-divergence (k). \n\nAlthough we derived this optimal factorization for by comparing the two-time distribution (option t) for an unknown state (option u) , an analogous calculation leads to the exact same optimal factorization for the options a$+$u, s$+$f and a$+$s. The option  t$+$s is undefined and the option\nf$+$u gives messy equations I have been unable to solve analytically.\nIt is therefore reasonable to view {equation~(\\ref{{OptimalSeparableMarkovEq}})}\nas {\\it the} optimal factorization when the state is unknown (option o), and for the remainder of this paper, we will simply define the o-option as using \nthe factorization given by {equation~(\\ref{{OptimalSeparableMarkovEq}})}.\n\nNote that our result in {equation~(\\ref{{MarkovPhiEq}})} involves a time-asymmetry, singling out $t_0$ rather than $t_1$ in the second term.\nThis is because we chose to interpret our Markov process as operating {\\it forward} in time, determining the state at $t_1$ from the state at $t_0$.\nAs we discussed in {Section~\\ref{{ComparisonSec}}}, we could equally well have done the opposite, using the Markov process $\\tilde{M}$ operating {\\it backward} in time, which would have yielded the alternative \nintegration measure \n\n", "itemtype": "equation", "pos": 50193, "prevtext": "\nSubstituting this back into\nthe definition of $d_{KL}$ \n\ngives the extremely simple result that the integration is \n\\begin{eqnarray}\\label{{MarkovPhiEq}}\n\\phi^{otuk}({\\bf p}) &=& \n\\sum_{ii'jj'} p_{ii'jj'} \n\\log{p_{ii'jj'}  p_{i\\cdot\\cdot\\cdot}p_{\\cdot i'\\cdot\\cdot} \\over p_{ii'\\cdot\\cdot} p_{i\\cdot j\\cdot} p_{\\cdot i'\\cdot j'}}\\nonumber\\\\\n&=&I({\\bf x}^A,{\\bf x}^B) - I({\\bf x}^A_0,{\\bf x}^B_0),\n\\end{eqnarray}\nwhere the mutual information between two random variables is given in terms of entropies by the standard definition\n\n", "index": 53, "text": "\\begin{equation}\\label{{IdefEq}}\nI({\\bf x}^A,{\\bf x}^B) \\equiv S({\\bf x}^A)+S({\\bf x}^B)-S({\\bf x}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"I({\\bf x}^{A},{\\bf x}^{B})\\equiv S({\\bf x}^{A})+S({\\bf x}^{B})-S({\\bf x}).\" display=\"block\"><mrow><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc31</mi><mi>A</mi></msup><mo>,</mo><msup><mi>\ud835\udc31</mi><mi>B</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2261</mo><mrow><mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc31</mi><mi>A</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc31</mi><mi>B</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nIn practice, one usually estimates all statistical properties from a time-series that is assumed to be stationary.\nThis means that $I({\\bf x}^A_0,{\\bf x}^B_0)=I({\\bf x}^A_1,{\\bf x}^B_1)$, so that the these two integration measures become identical.\n\n\n\n\\subsection{Comparison with the Barrett/Seth integration measure}\n\nIt is interesting to compare our result in {equation~(\\ref{{MarkovPhiEq}})} with the popular integration measure \n\n", "itemtype": "equation", "pos": 52229, "prevtext": "\n\nSince we will be deriving a large number of different $\\phi$-measures that we do not with to conflate with one another, we superscript each one with four code letters denoting the four taxonomical choices that define it. \nThese letter codes are \n\\begin{enumerate}\n\\item Factorization: n/m/o/x/a\n\\item comparison: t/f/a/p\n\\item conditioning: u/s/k\n\\item measure: k/1/2/h/e\n\\end{enumerate}\nand are defined in Tables~\\ref{FactorizationTable}, \\ref{ComparisonTable} and \\ref{MeasureTable}. For example, the integration measure $\\phi^{otuk}$ from {equation~(\\ref{{MarkovPhiEq}})} denotes optimized (o) factorization comparing the two-time (t) probability distributions with the current state unknown (u) and KL-divergence (k). \n\nAlthough we derived this optimal factorization for by comparing the two-time distribution (option t) for an unknown state (option u) , an analogous calculation leads to the exact same optimal factorization for the options a$+$u, s$+$f and a$+$s. The option  t$+$s is undefined and the option\nf$+$u gives messy equations I have been unable to solve analytically.\nIt is therefore reasonable to view {equation~(\\ref{{OptimalSeparableMarkovEq}})}\nas {\\it the} optimal factorization when the state is unknown (option o), and for the remainder of this paper, we will simply define the o-option as using \nthe factorization given by {equation~(\\ref{{OptimalSeparableMarkovEq}})}.\n\nNote that our result in {equation~(\\ref{{MarkovPhiEq}})} involves a time-asymmetry, singling out $t_0$ rather than $t_1$ in the second term.\nThis is because we chose to interpret our Markov process as operating {\\it forward} in time, determining the state at $t_1$ from the state at $t_0$.\nAs we discussed in {Section~\\ref{{ComparisonSec}}}, we could equally well have done the opposite, using the Markov process $\\tilde{M}$ operating {\\it backward} in time, which would have yielded the alternative \nintegration measure \n\n", "index": 55, "text": "\\begin{equation}\\label{{BackwardMarkovPhiEq}}\n\\phi^{o\\tilde{t}uk}({\\bf p}) = I({\\bf x}^A,{\\bf x}^B) - I({\\bf x}^A_1,{\\bf x}^B_1).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"\\phi^{o\\tilde{t}uk}({\\bf p})=I({\\bf x}^{A},{\\bf x}^{B})-I({\\bf x}^{A}_{1},{\\bf&#10;x%&#10;}^{B}_{1}).\" display=\"block\"><mrow><mrow><mrow><msup><mi>\u03d5</mi><mrow><mi>o</mi><mo>\u2062</mo><mover accent=\"true\"><mi>t</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>k</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc31</mi><mi>A</mi></msup><mo>,</mo><msup><mi>\ud835\udc31</mi><mi>B</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>A</mi></msubsup><mo>,</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>B</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nproposed by Barrett \\& Seth \\cite{barrett2011practical}.\nThe intuition behind this definition is to take the amount of information that a system predicts about its future and subtract of the information predicted by both of its subsystems.\nUnfortunately, the result can sometimes go negative, violating the desirable positivity property and making the $\\phi_B$ difficult to interpret\\footnote{This predicament has independently been pointed out by Masafumi Oizumi, priv. comm.}.\nConsider the simple example of two independent bits that never change. \nIf they start out perfectly correlated, then they will remain perfectly correlated, giving \n$I({\\bf x}_0,{\\bf x}_1)=I({\\bf x}^A_0,{\\bf x}^A_1)=I({\\bf x}^B_0,{\\bf x}^B_1)=1$ and \nintegrated information $\\phi_B({\\bf p})=-1$.\n\nBy substituting {equation~(\\ref{{IdefEq}})} into equations{~(\\ref{{MarkovPhiEq}})} and{~(\\ref{{BarrettPhiEq}})}, we find that \n\n", "itemtype": "equation", "pos": 52807, "prevtext": "\nIn practice, one usually estimates all statistical properties from a time-series that is assumed to be stationary.\nThis means that $I({\\bf x}^A_0,{\\bf x}^B_0)=I({\\bf x}^A_1,{\\bf x}^B_1)$, so that the these two integration measures become identical.\n\n\n\n\\subsection{Comparison with the Barrett/Seth integration measure}\n\nIt is interesting to compare our result in {equation~(\\ref{{MarkovPhiEq}})} with the popular integration measure \n\n", "index": 57, "text": "\\begin{equation}\\label{{BarrettPhiEq}}\n\\phi^B({\\bf p}) = I({\\bf x}_0,{\\bf x}_1) - I({\\bf x}^A_0,{\\bf x}^A_1) - I({\\bf x}^B_0,{\\bf x}^B_1)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"\\phi^{B}({\\bf p})=I({\\bf x}_{0},{\\bf x}_{1})-I({\\bf x}^{A}_{0},{\\bf x}^{A}_{1}%&#10;)-I({\\bf x}^{B}_{0},{\\bf x}^{B}_{1})\" display=\"block\"><mrow><mrow><msup><mi>\u03d5</mi><mi>B</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc31</mi><mn>0</mn></msub><mo>,</mo><msub><mi>\ud835\udc31</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>A</mi></msubsup><mo>,</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>A</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>B</mi></msubsup><mo>,</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>B</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nIn other words, we can make the Barrett/Seth measure non-negative by adding back any initial mutual information between the two subsystems.\nWhen this is done, it becomes the integration measure we derived, therefore having a simple information-theoretic interpretation: \nit is the KL-divergence between the actual probability distribution ${\\bf p}$ and the best separable approximation, which is guaranteed to be non-negative.\n\n\\subsection{Optimal state-dependent factorization}\n\nLet us now turn to factorization option ``x\", optimized knowing the current state.\nConsider some conscious observer (perhaps the system itself) who knows nothing about the system except its dynamics (encoded in ${\\bf M}$) and its state at the present instant, encoded in ${\\bf x}_0=kk'$. \nWhat can this observer say about the system state at earlier and later times? \nHow integrated will this observer feel that the system is? \nTo answer this question, we simply want to find the best approximate factorization of the conditional future state\n$M_{jj'kk'}$ (or the past state $M_{kk'ii'}$), where $k$ and $k'$ are known constants. \n\nTo gain intuition for this, let us temporarily write this conditional distribution as $p_{ii'}$, suppressing the known parameters $kk'$ for simplicity.\nGiven an arbitrary bivariate probability distribution $p_{ii'}$, what is best separarable approximation $q_{ii'}\\equiv a_i b_{i'}$ in the sense that it minimizes\n$d_{KL}({\\bf p},{\\bf q})$? \nBy minimizing $d_{KL}({\\bf p},{\\bf q})$ using Lagrange multipliers, one easily obtains the long-known result that \n$a_i=p_{i.}$, $b_{i'}=p_{.i'}$ and $d_{KL}({\\bf p},{\\bf q})=I$, the mutual information of ${\\bf p}$.\nIn other words, even if we had never heard of marginal distributions or mutual information, we could derive them all from  $d_{KL}$:\nthe best factorization simply uses the marginal distributions, and the mutual information of a bivariate distribution is simply the KL-measure of how non-separable it is.\n\nThis means that the optimal factorization given $k$ and $k'$ is simply the one giving the marginal conditional distributions\n\n", "itemtype": "equation", "pos": 53862, "prevtext": "\nproposed by Barrett \\& Seth \\cite{barrett2011practical}.\nThe intuition behind this definition is to take the amount of information that a system predicts about its future and subtract of the information predicted by both of its subsystems.\nUnfortunately, the result can sometimes go negative, violating the desirable positivity property and making the $\\phi_B$ difficult to interpret\\footnote{This predicament has independently been pointed out by Masafumi Oizumi, priv. comm.}.\nConsider the simple example of two independent bits that never change. \nIf they start out perfectly correlated, then they will remain perfectly correlated, giving \n$I({\\bf x}_0,{\\bf x}_1)=I({\\bf x}^A_0,{\\bf x}^A_1)=I({\\bf x}^B_0,{\\bf x}^B_1)=1$ and \nintegrated information $\\phi_B({\\bf p})=-1$.\n\nBy substituting {equation~(\\ref{{IdefEq}})} into equations{~(\\ref{{MarkovPhiEq}})} and{~(\\ref{{BarrettPhiEq}})}, we find that \n\n", "index": 59, "text": "\\begin{equation}\\label{{BarrettComparisonEq}}\n\\phi^B({\\bf p}) =\\phi^{otuk}({\\bf p})-I({\\bf x}_0^A,{\\bf x}_0^B).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"\\phi^{B}({\\bf p})=\\phi^{otuk}({\\bf p})-I({\\bf x}_{0}^{A},{\\bf x}_{0}^{B}).\" display=\"block\"><mrow><mrow><mrow><msup><mi>\u03d5</mi><mi>B</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msup><mi>\u03d5</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>u</mi><mo>\u2062</mo><mi>k</mi></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc29</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>A</mi></msubsup><mo>,</mo><msubsup><mi>\ud835\udc31</mi><mn>0</mn><mi>B</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nand the corresponding integration is simply\n\n", "itemtype": "equation", "pos": 56089, "prevtext": "\nIn other words, we can make the Barrett/Seth measure non-negative by adding back any initial mutual information between the two subsystems.\nWhen this is done, it becomes the integration measure we derived, therefore having a simple information-theoretic interpretation: \nit is the KL-divergence between the actual probability distribution ${\\bf p}$ and the best separable approximation, which is guaranteed to be non-negative.\n\n\\subsection{Optimal state-dependent factorization}\n\nLet us now turn to factorization option ``x\", optimized knowing the current state.\nConsider some conscious observer (perhaps the system itself) who knows nothing about the system except its dynamics (encoded in ${\\bf M}$) and its state at the present instant, encoded in ${\\bf x}_0=kk'$. \nWhat can this observer say about the system state at earlier and later times? \nHow integrated will this observer feel that the system is? \nTo answer this question, we simply want to find the best approximate factorization of the conditional future state\n$M_{jj'kk'}$ (or the past state $M_{kk'ii'}$), where $k$ and $k'$ are known constants. \n\nTo gain intuition for this, let us temporarily write this conditional distribution as $p_{ii'}$, suppressing the known parameters $kk'$ for simplicity.\nGiven an arbitrary bivariate probability distribution $p_{ii'}$, what is best separarable approximation $q_{ii'}\\equiv a_i b_{i'}$ in the sense that it minimizes\n$d_{KL}({\\bf p},{\\bf q})$? \nBy minimizing $d_{KL}({\\bf p},{\\bf q})$ using Lagrange multipliers, one easily obtains the long-known result that \n$a_i=p_{i.}$, $b_{i'}=p_{.i'}$ and $d_{KL}({\\bf p},{\\bf q})=I$, the mutual information of ${\\bf p}$.\nIn other words, even if we had never heard of marginal distributions or mutual information, we could derive them all from  $d_{KL}$:\nthe best factorization simply uses the marginal distributions, and the mutual information of a bivariate distribution is simply the KL-measure of how non-separable it is.\n\nThis means that the optimal factorization given $k$ and $k'$ is simply the one giving the marginal conditional distributions\n\n", "index": 61, "text": "\\begin{equation}\\label{{OptimalFactorizationEq2}}\nM^A_{ji}={p_{kk' j\\cdot}\\over p_{kk'\\cdot\\cdot}},\n\\quad\nM^B_{j'i'}={p_{kk'\\cdot j'}\\over p_{kk'\\cdot\\cdot}},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"M^{A}_{ji}={p_{kk^{\\prime}j\\cdot}\\over p_{kk^{\\prime}\\cdot\\cdot}},\\quad M^{B}_%&#10;{j^{\\prime}i^{\\prime}}={p_{kk^{\\prime}\\cdot j^{\\prime}}\\over p_{kk^{\\prime}%&#10;\\cdot\\cdot}},\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>M</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>i</mi></mrow><mi>A</mi></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mrow><mi>k</mi><mo>\u2062</mo><msup><mi>k</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2063</mo><mo>\u22c5</mo></mrow></msub><msub><mi>p</mi><mrow><mrow><mi>k</mi><mo>\u2062</mo><msup><mi>k</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mfrac></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msubsup><mi>M</mi><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>i</mi><mo>\u2032</mo></msup></mrow><mi>B</mi></msubsup><mo>=</mo><mfrac><msub><mi>p</mi><mrow><mrow><mi>k</mi><mo>\u2062</mo><msup><mi>k</mi><mo>\u2032</mo></msup></mrow><mo>\u22c5</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><msub><mi>p</mi><mrow><mrow><mi>k</mi><mo>\u2062</mo><msup><mi>k</mi><mo>\u2032</mo></msup></mrow><mo>\u2063</mo><mrow><mi/><mo>\u22c5</mo><mo>\u22c5</mo></mrow></mrow></msub></mfrac></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n$\\phi^{xtkk}$ is identical.\nWe can alternatively obtain this result directly from {equation~(\\ref{{MarkovPhiEq}})} by noting that the $I({\\bf x}^A_0,{\\bf x}^B_0)$-term vanishes now that the state ${\\bf x}_0$ is known.\n\nThis result highlights a striking and arguably undesirable feature of measures based on the x-factorization option: they vanish for \nany deterministic system! If the system is deterministic and the present state ${\\bf x}_0$ is known, then the future state ${\\bf x}_1$ is also known, so all entropies in \n{equation~(\\ref{{ConditionedForwardMarkovPhiEq}})} vanish and we obtain $\\phi=0$.\nWith $\\phi$-measures based on x-factorization,  the only source of integration is therefore correlated noise generated by the system.\n\n\\subsection{Minimizing integration on average}\n\nLet us now turn to our final factorization option,  ``a\", where we pick the state-independent factorization \nthat minimizes integration on average.\nGiven the present state ${\\bf x}_0=kk'$, let us compare the exact and approximate future probability distributions\n\\begin{eqnarray}\\label{{ConditionalComparisonEq}}\np_{jj'}&=&P({\\bf x}_1=jj'|{\\bf x}_0=kk')={\\bf M}_{kk'jj'},\\\\\nq_{jj'}&=&P({\\bf x}_1^A=j|{\\bf x}_0^A=k)P({\\bf x}_1^B=j'|{\\bf x}_0^B=k')={\\bf M}^A_{kj}{\\bf M}^B_{k'j'}\\nonumber\n\\end{eqnarray}\nby computing their KL-divergence $\\phi=d_{KL}(p,q)$.\nThe answer clearly depends on the present state $kk'$, and we saw in the previous section what happens when we minimize separately for each state $kk'$.\nLet us now instead average $d_{KL}(p,q)$ over all current states and find the state-independent factorization that minimizes this average:\n\\begin{eqnarray}\\label{{AverageDerivationEq}}\n{\\langle{d_{KL}(p,q)}\\rangle}\n&=&\\sum_{kk'}P({\\bf x}_0=kk')\\>d_{KL}(p,q)|{\\bf x}_0=kk'\\nonumber\\\\\n&=&\\sum_{kk'}p_{kk'\\cdot\\cdot}\\sum_{jj'}{\\bf M}_{kk'jj'}\\log{{\\bf M}_{kk'jj'}\\over {\\bf M}^A_{kj}{\\bf M}^B_{k'j'}}.\n\\end{eqnarray}\nSubstituting {equation~(\\ref{{MarkovMatrixEq2}})} shows that this expression is identical to that from {equation~(\\ref{{SeparableKLphiEq}})}, so minimizing it gives the exact same optimal factors\n${\\bf M}^A$ and ${\\bf M}^B$ and the exact same minimum $\\phi$.\nThe comparison option ``t\" gives the same result as well, \nso in conclusion, although they appear quite different from their definitions, the factorization options ``o\" and ``a\" are in fact identical.\n\n\n\n\n\n\n\n\\subsection{The full taxonomy}\n\nNow that we have derived the explicit form of all our factorization options, we can complete our integration measure classification.\nOur taxonomy is determined by four choices: of factorization (n/m/o/x/a), variable selection (t/f/a/p), conditioning (u/s/k) and distance measure (k/1/2/h/e). Although this nominally gives $5\\times 4\\times 3\\times 5=300$ different integration measures, most of these options turn out to be zero, undefined or identical to other options.\\footnote{For noising factorizations (factorization options n and m), subsystem $B$ is randomized, so the only well-defined options are\n$\\phi^{nas*}$, $\\phi^{nak*}$, $\\phi^{nps*}$, $\\phi^{nap*}$, \n$\\phi^{mas*}$, $\\phi^{mak*}$, $\\phi^{mps*}$ and $\\phi^{map*}$, \nwhere $*$ denotes any option for the distance measure.\n\nFor $o$-factorization, it is straightforward to show that \n$\\phi^{oau*}=\\phi^{oas*}=\\phi^{opu*}=\\phi^{ops*}=0$ and $\\phi^{otk*}=\\phi^{ofk*}$.\n\nFor $x$-factorization, $\\phi^{xt**}$ is undefined and\none easily shows that $\\phi^{xak*}=\\phi^{xpk*}=0$, \n$\\phi^{xau*}=\\phi^{xaf*}$\nand\n$\\phi^{xpu*}=\\phi^{xpf*}$. We interpret k-conditioning as ${\\bf x}_0$ being known for o-factorization and as ${\\bf x}_0^A$ being known for noising factorizations, since the reverse options vanish and are undefined, respectively.\n}\n\nWhereas there are strong interactions between the factorization, variable selection and conditioning, we can freely choose any of the 5 distance measures independently of the other choices without changing whether $\\phi$ vanishes or is well-defined.\nWe consider the option k (KL-divergence) by default below since it results in the simplest and most intuitive formulas; the formulas for the other options are straightforward to derive by combining Tables III, IV and~V. \nThis leaves us with only the 20 separate options shown in {Table~\\ref{{MeasureTable}}} to consider.\n\n\n\\subsection{Which integration measures are best?}\n \\label{BestSec}\n \n {Table~\\ref{{PropertyTable}}} summarizes the desirable and undesirable traits for each of these integration measures, showing that merely a handful lack any major drawbacks. Let us now rate the various options in more detail.\n \nFor the choice of {\\bf probability distance measure} (k/1/2/h/e), option ``e\" (the Earth-Mover's distance $d_{EM}$ used in \n$\\phi^{3.0}$ \\cite{oizumi2014phenomenology}) remains an attractive candidate for discrete distributions with small number of bits, but is otherwise computationally unfeasible as we discussed above. All options in {Table~\\ref{{PropertyTable}}} except $\\phi^{3.0}$ therefore use option ``k\" (the KL-divergence). Note that whether it is an advantage \nfor the probability distance measure to be symmetric (as advocated in \\cite{oizumi2014phenomenology}) depends on the \ninterpretational context. For example, there is nothing asymmetric about the mutual information that ends up defining $\\phi^{\\rm M}$ in {Table~\\ref{{MeasureTable}}}.\n\nFor the choice of {\\bf factorization} (n/m/o/x/a), we can quickly dispense with option ``a'' (for being identical to ``o'') and option ``x'' (because it has the highly undesirable property of always vanishing for deterministic systems).\nWhich of the remaining options (n/m/o) is preferable depends on other choices.\nIf one wishes to use a distance measure other than the KL-divergence,  then the noising options ``n'' or ``m'' are computationally preferable, since the optimal factorization ``o'' can no longer be found analytically. Otherwise, ``m'' is arguably inferior to ``o'' because it is no simpler to evaluate and can overestimate the integration as described above.\nIf one has a philosophical preference for the factorization depending only on the mechanism ${\\bf M}$ and not on any other information about state probabilities, then ``n'' is the only choice. If one wishes to consider continuous systems, on the other hand, ``n'' is undefined.\nIn summary, the best factorizations are therefore``o'' and ``n'', depending ones preferences.\nIn practice, numerical experiments show that ``n'', `m'' and ``o'' usually give quite similar $\\phi$-values for a wide range of ${\\bf M}$-matrices and probability distributions, so the choice between the three is a relatively minor one.\n\n \n  \n\n  \n\n  \n\n\nTurning now to the choice {\\bf variable selection} and {\\bf conditioning}, \n{Table~\\ref{{PropertyTable}}} shows that many of the otherwise well-defined integration measures from \n{Table~\\ref{{MeasureTable}}} have serious flaws.\n\nNeither $\\phi^{\\rm otsk}$ and $\\phi^{\\rm ofsk}$ are guaranteed to vanish for separable systems, which means that we cannot in good conscience interpret them as measures of integration.\nNumerical experiments show that $\\phi^{\\rm nask}$, $\\phi^{\\rm npsk}$, $\\phi^{\\rm mask}$ and $\\phi^{\\rm npsk}$ tend to be extremely small in practice ($\\phi^{\\rm mask}$ is plotted in {Figure~\\ref{{IntegrationFig}}}). This is because they differ little from \nthe corresponding measures using optimal factorization ($\\phi^{\\rm oask}$ and $\\phi^{\\rm opsk}$), which always vanish. In other words, they are not really measures of  integration,  \nmerely measures of how suboptimal the factorizations $``n\"$ and $``m\"$ are.\nFor brevity, we have included merely three of these six flawed measures in {Table~\\ref{{PropertyTable}}}.\n\n{Figure~\\ref{{IntegrationFig}}} shows that $\\phi^{\\rm ofuk}$ also tends to be much smaller than some other integration measures.\nWe can intuitively understand this by recalling that $\\phi^{\\rm oauk}=0$, which means that optimal factorization lets us predict the future marginal distributions for A and B perfectly. Since $\\phi^{\\rm ofuk}$ quantifies the inability of optimal factorization to predict the full future distribution, we expect that it will at most be of the order of  $I({\\bf x}_1^A,{\\bf x}_1^B)$,  the extent to which this distribution is not separable (determined by its marginal distributions). \nFor randomly generated probability distributions as in {Figure~\\ref{{IntegrationFig}}}), one can show that $I({\\bf x}_1^A,{\\bf x}_1^B)\\to 1-1/2\\ln 2\\approx 0.28$ bits in the limit where $n\\to\\infty$, and numerical experiments indicate that $\\phi^{\\rm ofuk}$ is never much larger than this value for any $p$.\n\n\n\n\n\n\n\n\n \n   \n\n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{integration.pdf}}\n\\caption{Numerical comparison of different integration measures, averaged over 3,000 random trials. In the bottom panel, all elements of $p$ are independently drawn from a uniform distribution and normalized to sum to unity.\nIn the top panel, only $p^{(0)}$ is randomly generated, and ${\\bf M}$ is defined so as to swap the two subsystems, \n\\protect{\\frenchspacing\\it i.e.}, \n$M_{jj'ii'}=\\delta_{ij'}\\delta_{i'j}$.\n\\label{IntegrationFig}\n}\n\\end{figure}\n\nDispensing with flawed/problematic $\\phi$-measures narrows our list of remaining top candidates to merely eight:\n$\\phi^{\\rm otuk}$, $\\phi^{\\rm ofkk}$,\n $\\phi^{\\rm oakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm nakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm makk}$ and $\\phi^{\\rm opkk}$.\n Morover, the last six can be elegantly combined into merely three even better ones.\n As we discussed above, they have the advantage that they vanish for either afferent or efferent systems.\n \nBy following the prescription of \\cite{tononi2008consciousness} and taking the minimum of two such complementary measures, we can construct an even better one one that vanishes for {\\it both} afferent and efferent systems.\nAll three of these improved measures are listed in {Table~\\ref{{MeasureTable}}}.\nThe first is $\\phi^{2.0}\\equiv\\min\\{\\phi^{\\rm nakk},\\phi^{\\rm npkk}\\}$, corresponding to the measure of IIT2.0.\nThe second is $\\phi^{2.0'}\\equiv\\min\\{\\phi^{\\rm makk},\\phi^{\\rm mpkk}\\}$, which has the advantage of remaining defined even for continuous variables.\nThe third is $\\phi^{2.0''}\\equiv\\min\\{\\phi^{\\rm makk},\\phi^{\\rm mpkk}\\}$, which uses the optimal factorization.\n\n   \n \\subsection{How large can $\\phi$ get?}\n \n In summary, our taxonomy of $\\phi$-measures produces merely a handful of truly attractive options: \n $\\phi^{2.0}$,  $\\phi^{2.0'}$,  $\\phi^{2.0''}$,  $\\phi^{3.0}$, $\\phi^M$ and $\\phi^M_{kk'}$.\n{Figure~\\ref{{IntegrationFig}}} shows examples of what they evaluate to numerically.\nThe lower panel shows that for randomly generated probability distributions, none of them exceed \n$1-1/2\\ln 2\\approx 0.28$ bits on average, which as mentioned above is the mutual information in a random bivariate distribution.\nHowever, $\\phi^{2.0}$,  $\\phi^{2.0'}$,  $\\phi^{2.0''}$,  $\\phi^M$ and $\\phi^M_{kk'}$ can get arbitrarily large for some systems, as illustrated in the top panel, growing logarithmically with the size $n$ of the subsystems A and B.\nIn other words, the maximum integration is of order the number of subsystem bits. \nFor the example shown where the dynamics merely swaps the two subsystems, we we obtain $\\phi^{2.0}=\\log_2 n$, because noising gives $M^A = 1/n$, $q = 1/n^2$ and $p$ is a Kronecker $\\delta$. \n$\\phi^{M}$ and $\\phi^M_{kk'}$ are seen to give about twice the integration for this example.\n\nNote that although this dynamics ${\\bf M}$ that merely swaps the subsystems has such a large $\\phi$-value only for this particular cut that separates the systems being swapped. There is a different cut where $\\phi=0$: simply define the new subsystems A' and B' to be the first and second halves of the A and B-systems. The swapping can be carried out internally within A' and B', revealing that there is no integration and upper-case $\\Phi=0$.\n\nHowever, there are plenty of systems for which even the true integration $\\Phi$ grows like the number of subsystem bits, $\\log_2 n$.\nA simple example accomplishing this (in the spirit of the random coding example in \\cite{tegmark2014consciousness}) is when\nthe $n^4$ probabilities $p_{ii'jj'}$ are all set to zero except for a randomly selected subset of $n^2$ of them that are set to $1/n^2$.\nNow $\\phi^M\\sim\\log_2 n$ even when minimized over all bipartitions of the $2\\log_2 n$ bits in the system.\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n \n\\section{The $n\\to\\infty$ limit of continuous variables}\n\\label{GaussianSec}\n\nAll our previous results are fully general, applying regardless of whether the variables are discrete \n(such as bits that equal zero or one) or continuous (such as voltages or other variables measured in \nfMRI, EEG, MEG or electrophysiology studies). We can view the latter as the $n\\to\\infty$ limit of the former, since a single real number can be represented as an infinite string of bits.\nIn this section, we will focus on the continuous case and see how our previous formulas can be greatly simplified by assuming Gaussianity.\nWe therefore replace $i$, $i'$, $j$ and $j'$ in all our formulas by \n${\\bf x}_0^A$, ${\\bf x}_0^B$, ${\\bf x}_1^A$ and ${\\bf x}_1^A$, respectively, and replace all sums by integrals.\n\n\\subsection{How Gaussianity gives linearity}\n\nTo make things tractable, we will make one strong but very useful assumption: that ${\\bf x}$ has a Gaussian distribution.\nThe most general $d$-dimensional multivariate Gaussian distribution is parametrized by its mean vector ${\\bf m}\\equiv{\\langle{{\\bf x}}\\rangle}$ and covariance matrix ${\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^t}\\rangle}-{\\bf m}{\\bf m}^t$ and takes the form\n\n", "itemtype": "equation", "pos": 56307, "prevtext": "\nand the corresponding integration is simply\n\n", "index": 63, "text": "\\begin{equation}\\label{{ConditionedForwardMarkovPhiEq}}\n\\phi^{xfkk} =I({\\bf x}_1^A,{\\bf x}_1^B|{\\bf x}_0).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"\\phi^{xfkk}=I({\\bf x}_{1}^{A},{\\bf x}_{1}^{B}|{\\bf x}_{0}).\" display=\"block\"><mrow><msup><mi>\u03d5</mi><mrow><mi>x</mi><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mi>k</mi></mrow></msup><mo>=</mo><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>A</mi></msubsup><mo>,</mo><msubsup><mi>\ud835\udc31</mi><mn>1</mn><mi>B</mi></msubsup><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc31</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nso we are making the assumption that there is some ${\\bf m}$ and ${\\bf T}$ such that $p({\\bf x})=g({\\bf x};{\\bf m},{\\bf T})$.\nLet us write ${\\bf m}$ and ${\\bf T}$ as \n\n", "itemtype": "equation", "pos": 70042, "prevtext": "\n$\\phi^{xtkk}$ is identical.\nWe can alternatively obtain this result directly from {equation~(\\ref{{MarkovPhiEq}})} by noting that the $I({\\bf x}^A_0,{\\bf x}^B_0)$-term vanishes now that the state ${\\bf x}_0$ is known.\n\nThis result highlights a striking and arguably undesirable feature of measures based on the x-factorization option: they vanish for \nany deterministic system! If the system is deterministic and the present state ${\\bf x}_0$ is known, then the future state ${\\bf x}_1$ is also known, so all entropies in \n{equation~(\\ref{{ConditionedForwardMarkovPhiEq}})} vanish and we obtain $\\phi=0$.\nWith $\\phi$-measures based on x-factorization,  the only source of integration is therefore correlated noise generated by the system.\n\n\\subsection{Minimizing integration on average}\n\nLet us now turn to our final factorization option,  ``a\", where we pick the state-independent factorization \nthat minimizes integration on average.\nGiven the present state ${\\bf x}_0=kk'$, let us compare the exact and approximate future probability distributions\n\\begin{eqnarray}\\label{{ConditionalComparisonEq}}\np_{jj'}&=&P({\\bf x}_1=jj'|{\\bf x}_0=kk')={\\bf M}_{kk'jj'},\\\\\nq_{jj'}&=&P({\\bf x}_1^A=j|{\\bf x}_0^A=k)P({\\bf x}_1^B=j'|{\\bf x}_0^B=k')={\\bf M}^A_{kj}{\\bf M}^B_{k'j'}\\nonumber\n\\end{eqnarray}\nby computing their KL-divergence $\\phi=d_{KL}(p,q)$.\nThe answer clearly depends on the present state $kk'$, and we saw in the previous section what happens when we minimize separately for each state $kk'$.\nLet us now instead average $d_{KL}(p,q)$ over all current states and find the state-independent factorization that minimizes this average:\n\\begin{eqnarray}\\label{{AverageDerivationEq}}\n{\\langle{d_{KL}(p,q)}\\rangle}\n&=&\\sum_{kk'}P({\\bf x}_0=kk')\\>d_{KL}(p,q)|{\\bf x}_0=kk'\\nonumber\\\\\n&=&\\sum_{kk'}p_{kk'\\cdot\\cdot}\\sum_{jj'}{\\bf M}_{kk'jj'}\\log{{\\bf M}_{kk'jj'}\\over {\\bf M}^A_{kj}{\\bf M}^B_{k'j'}}.\n\\end{eqnarray}\nSubstituting {equation~(\\ref{{MarkovMatrixEq2}})} shows that this expression is identical to that from {equation~(\\ref{{SeparableKLphiEq}})}, so minimizing it gives the exact same optimal factors\n${\\bf M}^A$ and ${\\bf M}^B$ and the exact same minimum $\\phi$.\nThe comparison option ``t\" gives the same result as well, \nso in conclusion, although they appear quite different from their definitions, the factorization options ``o\" and ``a\" are in fact identical.\n\n\n\n\n\n\n\n\\subsection{The full taxonomy}\n\nNow that we have derived the explicit form of all our factorization options, we can complete our integration measure classification.\nOur taxonomy is determined by four choices: of factorization (n/m/o/x/a), variable selection (t/f/a/p), conditioning (u/s/k) and distance measure (k/1/2/h/e). Although this nominally gives $5\\times 4\\times 3\\times 5=300$ different integration measures, most of these options turn out to be zero, undefined or identical to other options.\\footnote{For noising factorizations (factorization options n and m), subsystem $B$ is randomized, so the only well-defined options are\n$\\phi^{nas*}$, $\\phi^{nak*}$, $\\phi^{nps*}$, $\\phi^{nap*}$, \n$\\phi^{mas*}$, $\\phi^{mak*}$, $\\phi^{mps*}$ and $\\phi^{map*}$, \nwhere $*$ denotes any option for the distance measure.\n\nFor $o$-factorization, it is straightforward to show that \n$\\phi^{oau*}=\\phi^{oas*}=\\phi^{opu*}=\\phi^{ops*}=0$ and $\\phi^{otk*}=\\phi^{ofk*}$.\n\nFor $x$-factorization, $\\phi^{xt**}$ is undefined and\none easily shows that $\\phi^{xak*}=\\phi^{xpk*}=0$, \n$\\phi^{xau*}=\\phi^{xaf*}$\nand\n$\\phi^{xpu*}=\\phi^{xpf*}$. We interpret k-conditioning as ${\\bf x}_0$ being known for o-factorization and as ${\\bf x}_0^A$ being known for noising factorizations, since the reverse options vanish and are undefined, respectively.\n}\n\nWhereas there are strong interactions between the factorization, variable selection and conditioning, we can freely choose any of the 5 distance measures independently of the other choices without changing whether $\\phi$ vanishes or is well-defined.\nWe consider the option k (KL-divergence) by default below since it results in the simplest and most intuitive formulas; the formulas for the other options are straightforward to derive by combining Tables III, IV and~V. \nThis leaves us with only the 20 separate options shown in {Table~\\ref{{MeasureTable}}} to consider.\n\n\n\\subsection{Which integration measures are best?}\n \\label{BestSec}\n \n {Table~\\ref{{PropertyTable}}} summarizes the desirable and undesirable traits for each of these integration measures, showing that merely a handful lack any major drawbacks. Let us now rate the various options in more detail.\n \nFor the choice of {\\bf probability distance measure} (k/1/2/h/e), option ``e\" (the Earth-Mover's distance $d_{EM}$ used in \n$\\phi^{3.0}$ \\cite{oizumi2014phenomenology}) remains an attractive candidate for discrete distributions with small number of bits, but is otherwise computationally unfeasible as we discussed above. All options in {Table~\\ref{{PropertyTable}}} except $\\phi^{3.0}$ therefore use option ``k\" (the KL-divergence). Note that whether it is an advantage \nfor the probability distance measure to be symmetric (as advocated in \\cite{oizumi2014phenomenology}) depends on the \ninterpretational context. For example, there is nothing asymmetric about the mutual information that ends up defining $\\phi^{\\rm M}$ in {Table~\\ref{{MeasureTable}}}.\n\nFor the choice of {\\bf factorization} (n/m/o/x/a), we can quickly dispense with option ``a'' (for being identical to ``o'') and option ``x'' (because it has the highly undesirable property of always vanishing for deterministic systems).\nWhich of the remaining options (n/m/o) is preferable depends on other choices.\nIf one wishes to use a distance measure other than the KL-divergence,  then the noising options ``n'' or ``m'' are computationally preferable, since the optimal factorization ``o'' can no longer be found analytically. Otherwise, ``m'' is arguably inferior to ``o'' because it is no simpler to evaluate and can overestimate the integration as described above.\nIf one has a philosophical preference for the factorization depending only on the mechanism ${\\bf M}$ and not on any other information about state probabilities, then ``n'' is the only choice. If one wishes to consider continuous systems, on the other hand, ``n'' is undefined.\nIn summary, the best factorizations are therefore``o'' and ``n'', depending ones preferences.\nIn practice, numerical experiments show that ``n'', `m'' and ``o'' usually give quite similar $\\phi$-values for a wide range of ${\\bf M}$-matrices and probability distributions, so the choice between the three is a relatively minor one.\n\n \n  \n\n  \n\n  \n\n\nTurning now to the choice {\\bf variable selection} and {\\bf conditioning}, \n{Table~\\ref{{PropertyTable}}} shows that many of the otherwise well-defined integration measures from \n{Table~\\ref{{MeasureTable}}} have serious flaws.\n\nNeither $\\phi^{\\rm otsk}$ and $\\phi^{\\rm ofsk}$ are guaranteed to vanish for separable systems, which means that we cannot in good conscience interpret them as measures of integration.\nNumerical experiments show that $\\phi^{\\rm nask}$, $\\phi^{\\rm npsk}$, $\\phi^{\\rm mask}$ and $\\phi^{\\rm npsk}$ tend to be extremely small in practice ($\\phi^{\\rm mask}$ is plotted in {Figure~\\ref{{IntegrationFig}}}). This is because they differ little from \nthe corresponding measures using optimal factorization ($\\phi^{\\rm oask}$ and $\\phi^{\\rm opsk}$), which always vanish. In other words, they are not really measures of  integration,  \nmerely measures of how suboptimal the factorizations $``n\"$ and $``m\"$ are.\nFor brevity, we have included merely three of these six flawed measures in {Table~\\ref{{PropertyTable}}}.\n\n{Figure~\\ref{{IntegrationFig}}} shows that $\\phi^{\\rm ofuk}$ also tends to be much smaller than some other integration measures.\nWe can intuitively understand this by recalling that $\\phi^{\\rm oauk}=0$, which means that optimal factorization lets us predict the future marginal distributions for A and B perfectly. Since $\\phi^{\\rm ofuk}$ quantifies the inability of optimal factorization to predict the full future distribution, we expect that it will at most be of the order of  $I({\\bf x}_1^A,{\\bf x}_1^B)$,  the extent to which this distribution is not separable (determined by its marginal distributions). \nFor randomly generated probability distributions as in {Figure~\\ref{{IntegrationFig}}}), one can show that $I({\\bf x}_1^A,{\\bf x}_1^B)\\to 1-1/2\\ln 2\\approx 0.28$ bits in the limit where $n\\to\\infty$, and numerical experiments indicate that $\\phi^{\\rm ofuk}$ is never much larger than this value for any $p$.\n\n\n\n\n\n\n\n\n \n   \n\n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{integration.pdf}}\n\\caption{Numerical comparison of different integration measures, averaged over 3,000 random trials. In the bottom panel, all elements of $p$ are independently drawn from a uniform distribution and normalized to sum to unity.\nIn the top panel, only $p^{(0)}$ is randomly generated, and ${\\bf M}$ is defined so as to swap the two subsystems, \n\\protect{\\frenchspacing\\it i.e.}, \n$M_{jj'ii'}=\\delta_{ij'}\\delta_{i'j}$.\n\\label{IntegrationFig}\n}\n\\end{figure}\n\nDispensing with flawed/problematic $\\phi$-measures narrows our list of remaining top candidates to merely eight:\n$\\phi^{\\rm otuk}$, $\\phi^{\\rm ofkk}$,\n $\\phi^{\\rm oakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm nakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm makk}$ and $\\phi^{\\rm opkk}$.\n Morover, the last six can be elegantly combined into merely three even better ones.\n As we discussed above, they have the advantage that they vanish for either afferent or efferent systems.\n \nBy following the prescription of \\cite{tononi2008consciousness} and taking the minimum of two such complementary measures, we can construct an even better one one that vanishes for {\\it both} afferent and efferent systems.\nAll three of these improved measures are listed in {Table~\\ref{{MeasureTable}}}.\nThe first is $\\phi^{2.0}\\equiv\\min\\{\\phi^{\\rm nakk},\\phi^{\\rm npkk}\\}$, corresponding to the measure of IIT2.0.\nThe second is $\\phi^{2.0'}\\equiv\\min\\{\\phi^{\\rm makk},\\phi^{\\rm mpkk}\\}$, which has the advantage of remaining defined even for continuous variables.\nThe third is $\\phi^{2.0''}\\equiv\\min\\{\\phi^{\\rm makk},\\phi^{\\rm mpkk}\\}$, which uses the optimal factorization.\n\n   \n \\subsection{How large can $\\phi$ get?}\n \n In summary, our taxonomy of $\\phi$-measures produces merely a handful of truly attractive options: \n $\\phi^{2.0}$,  $\\phi^{2.0'}$,  $\\phi^{2.0''}$,  $\\phi^{3.0}$, $\\phi^M$ and $\\phi^M_{kk'}$.\n{Figure~\\ref{{IntegrationFig}}} shows examples of what they evaluate to numerically.\nThe lower panel shows that for randomly generated probability distributions, none of them exceed \n$1-1/2\\ln 2\\approx 0.28$ bits on average, which as mentioned above is the mutual information in a random bivariate distribution.\nHowever, $\\phi^{2.0}$,  $\\phi^{2.0'}$,  $\\phi^{2.0''}$,  $\\phi^M$ and $\\phi^M_{kk'}$ can get arbitrarily large for some systems, as illustrated in the top panel, growing logarithmically with the size $n$ of the subsystems A and B.\nIn other words, the maximum integration is of order the number of subsystem bits. \nFor the example shown where the dynamics merely swaps the two subsystems, we we obtain $\\phi^{2.0}=\\log_2 n$, because noising gives $M^A = 1/n$, $q = 1/n^2$ and $p$ is a Kronecker $\\delta$. \n$\\phi^{M}$ and $\\phi^M_{kk'}$ are seen to give about twice the integration for this example.\n\nNote that although this dynamics ${\\bf M}$ that merely swaps the subsystems has such a large $\\phi$-value only for this particular cut that separates the systems being swapped. There is a different cut where $\\phi=0$: simply define the new subsystems A' and B' to be the first and second halves of the A and B-systems. The swapping can be carried out internally within A' and B', revealing that there is no integration and upper-case $\\Phi=0$.\n\nHowever, there are plenty of systems for which even the true integration $\\Phi$ grows like the number of subsystem bits, $\\log_2 n$.\nA simple example accomplishing this (in the spirit of the random coding example in \\cite{tegmark2014consciousness}) is when\nthe $n^4$ probabilities $p_{ii'jj'}$ are all set to zero except for a randomly selected subset of $n^2$ of them that are set to $1/n^2$.\nNow $\\phi^M\\sim\\log_2 n$ even when minimized over all bipartitions of the $2\\log_2 n$ bits in the system.\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n \n\\section{The $n\\to\\infty$ limit of continuous variables}\n\\label{GaussianSec}\n\nAll our previous results are fully general, applying regardless of whether the variables are discrete \n(such as bits that equal zero or one) or continuous (such as voltages or other variables measured in \nfMRI, EEG, MEG or electrophysiology studies). We can view the latter as the $n\\to\\infty$ limit of the former, since a single real number can be represented as an infinite string of bits.\nIn this section, we will focus on the continuous case and see how our previous formulas can be greatly simplified by assuming Gaussianity.\nWe therefore replace $i$, $i'$, $j$ and $j'$ in all our formulas by \n${\\bf x}_0^A$, ${\\bf x}_0^B$, ${\\bf x}_1^A$ and ${\\bf x}_1^A$, respectively, and replace all sums by integrals.\n\n\\subsection{How Gaussianity gives linearity}\n\nTo make things tractable, we will make one strong but very useful assumption: that ${\\bf x}$ has a Gaussian distribution.\nThe most general $d$-dimensional multivariate Gaussian distribution is parametrized by its mean vector ${\\bf m}\\equiv{\\langle{{\\bf x}}\\rangle}$ and covariance matrix ${\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^t}\\rangle}-{\\bf m}{\\bf m}^t$ and takes the form\n\n", "index": 65, "text": "\\begin{equation}\\label{{GaussianpEq}}\ng[{\\bf x};{\\bf m},{\\bf T}]\\equiv{1\\over (2\\pi)^{d/2} |{\\bf T}|^{1/2}}e^{-{1\\over 2}({\\bf x}-{\\bf m})^t{\\bf T}^{-1}({\\bf x}-{\\bf m})},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"g[{\\bf x};{\\bf m},{\\bf T}]\\equiv{1\\over(2\\pi)^{d/2}|{\\bf T}|^{1/2}}e^{-{1\\over&#10;2%&#10;}({\\bf x}-{\\bf m})^{t}{\\bf T}^{-1}({\\bf x}-{\\bf m})},\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mi>\ud835\udc31</mi><mo>;</mo><mi>\ud835\udc26</mi><mo>,</mo><mi>\ud835\udc13</mi><mo stretchy=\"false\">]</mo></mrow></mrow><mo>\u2261</mo><mrow><mfrac><mn>1</mn><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>d</mi><mo>/</mo><mn>2</mn></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">|</mo><mi>\ud835\udc13</mi><mo stretchy=\"false\">|</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc31</mi><mo>-</mo><mi>\ud835\udc26</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>t</mi></msup><mo>\u2062</mo><msup><mi>\ud835\udc13</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc31</mi><mo>-</mo><mi>\ud835\udc26</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere ${\\bf m}_i$ and ${\\bf C}_i$ are the mean and covariance of ${\\bf x}_i$, respectively.\n\nInterpreting the sum in the denominator of {equation~(\\ref{{MarkovMatrixEq2}})} as an integral and evaluating it\\footnote{\n The following well-known matrix identities are useful in the derivation of  this and other matrix results in this paper:\n \n", "itemtype": "equation", "pos": 70396, "prevtext": "\nso we are making the assumption that there is some ${\\bf m}$ and ${\\bf T}$ such that $p({\\bf x})=g({\\bf x};{\\bf m},{\\bf T})$.\nLet us write ${\\bf m}$ and ${\\bf T}$ as \n\n", "index": 67, "text": "\\begin{equation}\\label{{Meq2}}\n{\\bf m}=\n\\left(\n\\begin{tabular}{c}\n${\\bf m}_0$\\\\\n${\\bf m}_1$\n\\end{tabular}\n\\right),\n\\quad\n{\\bf T}=\n\\left(\n\\begin{tabular}{cc}\n${\\bf C}_0$&${\\bf B}$\\\\\n${\\bf B}^t$&${\\bf C}_1$\n\\end{tabular}\n\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m1\" class=\"ltx_Math\" alttext=\"{\\bf m}=\\left(\\begin{tabular}[]{c}${\\bf m}_{0}$\\\\&#10;${\\bf m}_{1}$\\end{tabular}\\right),\\quad{\\bf T}=\\left(\\begin{tabular}[]{cc}${%&#10;\\bf C}_{0}$&amp;${\\bf B}$\\\\&#10;${\\bf B}^{t}$&amp;${\\bf C}_{1}$\\end{tabular}\\right),\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc26</mi><mo>=</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc26</mi><msub><mi/><mn>0</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc26</mi><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>\ud835\udc13</mi><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc02</mi><msub><mi/><mn>0</mn></msub></mtd><mtd columnalign=\"center\"><mi>\ud835\udc01</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc01</mi><msup><mi/><mi>t</mi></msup></mtd><mtd columnalign=\"center\"><mi>\ud835\udc02</mi><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n \n", "itemtype": "equation", "pos": 70978, "prevtext": "\nwhere ${\\bf m}_i$ and ${\\bf C}_i$ are the mean and covariance of ${\\bf x}_i$, respectively.\n\nInterpreting the sum in the denominator of {equation~(\\ref{{MarkovMatrixEq2}})} as an integral and evaluating it\\footnote{\n The following well-known matrix identities are useful in the derivation of  this and other matrix results in this paper:\n \n", "index": 69, "text": "\\begin{equation}\\label{{BlockDeterminantEq}}\n \\left|\n\\begin{tabular}{cc}\n{\\bf A}&{\\bf B}\\\\\n{\\bf C}&{\\bf D}\n\\end{tabular}\n\\right|\n= |{\\bf A}{\\bf D}-{\\bf A}{\\bf C}{\\bf A}^{-1}{\\bf B}|,\n\\end{equation}\n", "mathml": "", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 71177, "prevtext": "\n \n", "index": 71, "text": "\\begin{equation}\\label{{BlockInverseEq}}\n\\left(\\!\\!\n\\begin{tabular}{cc}\n{\\bf A}&{\\bf B}\\\\\n{\\bf C}&{\\bf D}\n\\end{tabular}\n\\!\\!\\right)^{-1}\\!\\!\\!\\!\\!\\!\n=\n\\left(\\!\\!\n\\begin{tabular}{cc}\n$[{\\bf A}-{\\bf B}{\\bf D}^{-1}{\\bf C}]^{-1}$&$-{\\bf A}^{-1}{\\bf B}[{\\bf D}-{\\bf C}{\\bf A}^{-1}{\\bf B}]^{-1}$\\\\\n$[{\\bf D}-{\\bf C}{\\bf A}^{-1}{\\bf B}]^{-1}{\\bf C}{\\bf A}^{-1}$&$[{\\bf D}-{\\bf C}{\\bf A}^{-1}{\\bf B}]^{-1}$\n\\end{tabular}\n\\!\\!\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\left(\\!\\!\\begin{tabular}[]{cc}{\\bf A}&amp;{\\bf B}\\\\&#10;{\\bf C}&amp;{\\bf D}\\end{tabular}\\!\\!\\right)^{-1}\\!\\!\\!\\!\\!\\!=\\left(\\!\\!\\begin{%&#10;tabular}[]{cc}$[{\\bf A}-{\\bf B}{\\bf D}^{-1}{\\bf C}]^{-1}$&amp;$-{\\bf A}^{-1}{\\bf B%&#10;}[{\\bf D}-{\\bf C}{\\bf A}^{-1}{\\bf B}]^{-1}$\\\\&#10;$[{\\bf D}-{\\bf C}{\\bf A}^{-1}{\\bf B}]^{-1}{\\bf C}{\\bf A}^{-1}$&amp;$[{\\bf D}-{\\bf C%&#10;}{\\bf A}^{-1}{\\bf B}]^{-1}$\\end{tabular}\\!\\!\\right),\" display=\"block\"><mrow><mrow><mpadded width=\"-10.2pt\"><msup><mrow><mo rspace=\"0pt\">(</mo><mpadded width=\"-3.4pt\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mtext>\ud835\udc00</mtext></mtd><mtd columnalign=\"center\"><mtext>\ud835\udc01</mtext></mtd></mtr><mtr><mtd columnalign=\"center\"><mtext>\ud835\udc02</mtext></mtd><mtd columnalign=\"center\"><mtext>\ud835\udc03</mtext></mtd></mtr></mtable></mpadded><mo>)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mpadded><mo>=</mo><mrow><mo rspace=\"0pt\">(</mo><mpadded width=\"-3.4pt\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mo stretchy=\"false\">[</mo><mi>\ud835\udc00</mi><mo>-</mo><mi>\ud835\udc01\ud835\udc03</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc02</mi><mo stretchy=\"false\">]</mo><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd><mtd columnalign=\"center\"><mo>-</mo><mi>\ud835\udc00</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc01</mi><mo stretchy=\"false\">[</mo><mi>\ud835\udc03</mi><mo>-</mo><mi>\ud835\udc02\ud835\udc00</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc01</mi><mo stretchy=\"false\">]</mo><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mo stretchy=\"false\">[</mo><mi>\ud835\udc03</mi><mo>-</mo><mi>\ud835\udc02\ud835\udc00</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc01</mi><mo stretchy=\"false\">]</mo><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc02\ud835\udc00</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd><mtd columnalign=\"center\"><mo stretchy=\"false\">[</mo><mi>\ud835\udc03</mi><mo>-</mo><mi>\ud835\udc02\ud835\udc00</mi><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi>\ud835\udc01</mi><mo stretchy=\"false\">]</mo><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr></mtable></mpadded><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\n}\ngives\n\n", "itemtype": "equation", "pos": 71618, "prevtext": "\n\n", "index": 73, "text": "\\begin{equation}\\label{{WoodburyEq}}\n[{\\bf A}+{\\bf B}{\\bf D}^{-1}{\\bf C}]^{-1}={\\bf A}^{-1}-{\\bf A}^{-1}{\\bf B}[{\\bf D}+{\\bf C}{\\bf A}^{-1}{\\bf B}]{\\bf C}{\\bf A}^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"[{\\bf A}+{\\bf B}{\\bf D}^{-1}{\\bf C}]^{-1}={\\bf A}^{-1}-{\\bf A}^{-1}{\\bf B}[{%&#10;\\bf D}+{\\bf C}{\\bf A}^{-1}{\\bf B}]{\\bf C}{\\bf A}^{-1}.\" display=\"block\"><mrow><mrow><msup><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\ud835\udc00</mi><mo>+</mo><mrow><msup><mi>\ud835\udc01\ud835\udc03</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\ud835\udc02</mi></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><msup><mi>\ud835\udc00</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>-</mo><mrow><msup><mi>\ud835\udc00</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\ud835\udc01</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>\ud835\udc03</mi><mo>+</mo><mrow><msup><mi>\ud835\udc02\ud835\udc00</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\ud835\udc01</mi></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><msup><mi>\ud835\udc02\ud835\udc00</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere\n\\begin{eqnarray}\\label{{Aeq}}\n{\\bf A}&\\equiv&{\\bf B}^t{\\bf C}_0^{-1},\\\\\n{\\mathbf\\Sigma}&\\equiv&{\\bf C}_1-{\\bf B}^t{\\bf C}_0^{-1}{\\bf B}={\\bf C}_1-{\\bf A}{\\bf C}_0{\\bf A}^t.\\label{Seq}\n\\end{eqnarray}\nThis encodes the well-known result that the conditional distribution ${\\bf x}_1|{\\bf x}_0$ for Gaussian variables is Gaussian with \nmean ${\\bf m}_1+{\\bf B}{\\bf C}_0^{-1}({\\bf x}_0-{\\bf m}_0)$ and covariance matrix ${\\bf C}_1-{\\bf B}^t{\\bf C}_0^{-1}{\\bf B}$.\nThese equations embody a remarkable simplicity that we can exploit. \nFirst of all, the covariance matrix ${\\mathbf\\Sigma}$ is independent of ${\\bf x}_0$, which allows us to interpret \n${\\bf x}_1$ as simply a function of ${\\bf x}_0$ plus a random noise vector ${\\bf n}$ that is independent of ${\\bf x}_0$. \nSecond, this function is affine, involving simply a linear term plus a constant.\nIn other words, we can write \n\n", "itemtype": "equation", "pos": 71809, "prevtext": "\n}\ngives\n\n", "index": 75, "text": "\\begin{equation}\\label{{ContinuousMarkovEq}}\n\n{\\bf M}({\\bf x}_1,{\\bf x}_0)=g[{\\bf x}_1;{\\bf m}_1+{\\bf A}({\\bf x}_0-{\\bf m}_0),{\\mathbf\\Sigma}],\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf M}({\\bf x}_{1},{\\bf x}_{0})=g[{\\bf x}_{1};{\\bf m}_{1}+{\\bf A}({\\bf x%&#10;}_{0}-{\\bf m}_{0}),{\\mathbf{\\Sigma}}],\" display=\"block\"><mrow><mrow><mrow><mi>\ud835\udc0c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc31</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc31</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>\ud835\udc31</mi><mn>1</mn></msub><mo>;</mo><mrow><msub><mi>\ud835\udc26</mi><mn>1</mn></msub><mo>+</mo><mrow><mi>\ud835\udc00</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc31</mi><mn>0</mn></msub><mo>-</mo><msub><mi>\ud835\udc26</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo><mi>\ud835\udeba</mi><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere the noise vector ${\\bf n}$ satisfies\n\n\n", "itemtype": "equation", "pos": 72848, "prevtext": "\nwhere\n\\begin{eqnarray}\\label{{Aeq}}\n{\\bf A}&\\equiv&{\\bf B}^t{\\bf C}_0^{-1},\\\\\n{\\mathbf\\Sigma}&\\equiv&{\\bf C}_1-{\\bf B}^t{\\bf C}_0^{-1}{\\bf B}={\\bf C}_1-{\\bf A}{\\bf C}_0{\\bf A}^t.\\label{Seq}\n\\end{eqnarray}\nThis encodes the well-known result that the conditional distribution ${\\bf x}_1|{\\bf x}_0$ for Gaussian variables is Gaussian with \nmean ${\\bf m}_1+{\\bf B}{\\bf C}_0^{-1}({\\bf x}_0-{\\bf m}_0)$ and covariance matrix ${\\bf C}_1-{\\bf B}^t{\\bf C}_0^{-1}{\\bf B}$.\nThese equations embody a remarkable simplicity that we can exploit. \nFirst of all, the covariance matrix ${\\mathbf\\Sigma}$ is independent of ${\\bf x}_0$, which allows us to interpret \n${\\bf x}_1$ as simply a function of ${\\bf x}_0$ plus a random noise vector ${\\bf n}$ that is independent of ${\\bf x}_0$. \nSecond, this function is affine, involving simply a linear term plus a constant.\nIn other words, we can write \n\n", "index": 77, "text": "\\begin{equation}\\label{{LinearEq}}\n{\\bf x}_1={\\bf m}_1+{\\bf A}({\\bf x}_0-{\\bf m}_0)+{\\bf n},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m1\" class=\"ltx_Math\" alttext=\"{\\bf x}_{1}={\\bf m}_{1}+{\\bf A}({\\bf x}_{0}-{\\bf m}_{0})+{\\bf n},\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc31</mi><mn>1</mn></msub><mo>=</mo><mrow><msub><mi>\ud835\udc26</mi><mn>1</mn></msub><mo>+</mo><mrow><mi>\ud835\udc00</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc31</mi><mn>0</mn></msub><mo>-</mo><msub><mi>\ud835\udc26</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\ud835\udc27</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nIt is worth reflecting on how remarkable this is, since it is easy to overlook. \nThe future state ${\\bf x}_1$ of a system can depend on the present state ${\\bf x}_0$ in some arbitrarily complicated non-linear way. Moreover, for a generic Markov process, the scatter of ${\\bf x}_1$ around its mean will depend strongly on ${\\bf x}_0$. Yet as long as all probability distributions are Gaussian, which is often a useful approximation for laboratory data, both of these complications vanish and we are left with the simple linear dynamics of {equation~(\\ref{{LinearEq}})}.\n\n\n\n\n\n\\subsection{Autoregressive processes}\n\nLet us now briefly review the formalism of so-called autoregressive processes and how it relates to our problem at hand.\nA simple special case of the above is where the random process is {\\it stationary}, {\\frenchspacing\\it i.e.}, where the statistical properties are independent of time. This implies that ${\\bf m}_i={\\bf m}$ and ${\\bf C}_i={\\bf C}$ for some ${\\bf m}$ and ${\\bf C}$ that are independent of $i$.\nFor a stationary process, it is convenient to redefine new zero-mean variables ${\\bf x}_i'\\equiv{\\bf x}_i-{\\bf m}$. Dropping the prime for simplicity, this allows us to rewrite {equation~(\\ref{{LinearEq}})} as\n\n", "itemtype": "equation", "pos": 73000, "prevtext": "\nwhere the noise vector ${\\bf n}$ satisfies\n\n\n", "index": 79, "text": "\\begin{equation}\\label{{nEq}}\n{\\langle{{\\bf n}}\\rangle}=0,\\quad{\\langle{{\\bf n}{\\bf x}^t}\\rangle}=0,\\quad{\\langle{{\\bf n}{\\bf n}^t}\\rangle}={\\mathbf\\Sigma}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E40.m1\" class=\"ltx_Math\" alttext=\"{\\langle{{\\bf n}}\\rangle}=0,\\quad{\\langle{{\\bf n}{\\bf x}^{t}}\\rangle}=0,\\quad{%&#10;\\langle{{\\bf n}{\\bf n}^{t}}\\rangle}={\\mathbf{\\Sigma}}.\" display=\"block\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc27</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mn>0</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc27\ud835\udc31</mi><mi>t</mi></msup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mn>0</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc27\ud835\udc27</mi><mi>t</mi></msup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mi>\ud835\udeba</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere the noise vectors ${\\bf n}_i$ have vanishing mean and vanishing correlations between different times, {\\frenchspacing\\it i.e.}, ${\\langle{{\\bf n}_i{\\bf n}_j^t}\\rangle}=\\delta_{ij}{\\mathbf\\Sigma}$.\n\nThe covariance matrix between vectors at two subsequent times is therefore\n\n", "itemtype": "equation", "pos": 74408, "prevtext": "\nIt is worth reflecting on how remarkable this is, since it is easy to overlook. \nThe future state ${\\bf x}_1$ of a system can depend on the present state ${\\bf x}_0$ in some arbitrarily complicated non-linear way. Moreover, for a generic Markov process, the scatter of ${\\bf x}_1$ around its mean will depend strongly on ${\\bf x}_0$. Yet as long as all probability distributions are Gaussian, which is often a useful approximation for laboratory data, both of these complications vanish and we are left with the simple linear dynamics of {equation~(\\ref{{LinearEq}})}.\n\n\n\n\n\n\\subsection{Autoregressive processes}\n\nLet us now briefly review the formalism of so-called autoregressive processes and how it relates to our problem at hand.\nA simple special case of the above is where the random process is {\\it stationary}, {\\frenchspacing\\it i.e.}, where the statistical properties are independent of time. This implies that ${\\bf m}_i={\\bf m}$ and ${\\bf C}_i={\\bf C}$ for some ${\\bf m}$ and ${\\bf C}$ that are independent of $i$.\nFor a stationary process, it is convenient to redefine new zero-mean variables ${\\bf x}_i'\\equiv{\\bf x}_i-{\\bf m}$. Dropping the prime for simplicity, this allows us to rewrite {equation~(\\ref{{LinearEq}})} as\n\n", "index": 81, "text": "\\begin{equation}\\label{{LinearEq2}}\n{\\bf x}_{i+1}={\\bf A}{\\bf x}_{i}+{\\bf n}_i,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E41.m1\" class=\"ltx_Math\" alttext=\"{\\bf x}_{i+1}={\\bf A}{\\bf x}_{i}+{\\bf n}_{i},\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc31</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><msub><mi>\ud835\udc00\ud835\udc31</mi><mi>i</mi></msub><mo>+</mo><msub><mi>\ud835\udc27</mi><mi>i</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nEven if the random process is not stationary initially, it will eventually converge to a stationary state where covariance is time-independent as long as all eigenvalues of ${\\bf A}$ have magnitude below unity, so that memory of the past gets exponentially damped over time.\nOnce the covariance has become time-independent, {equation~(\\ref{{Teq1}})} implies that ${\\bf C}={\\bf A}{\\bf C}{\\bf A}^t+{\\mathbf\\Sigma}$. \nThis is known as the Lyapunov equation, and is readily solved by special-purpose techniques or, rapidly enough, by simply iterating it to convergence.\nIf we write the covariance matrix ${\\langle{{\\bf x}{\\bf x}^t}\\rangle}$ measured from actual time series data as\n\n", "itemtype": "equation", "pos": 74782, "prevtext": "\nwhere the noise vectors ${\\bf n}_i$ have vanishing mean and vanishing correlations between different times, {\\frenchspacing\\it i.e.}, ${\\langle{{\\bf n}_i{\\bf n}_j^t}\\rangle}=\\delta_{ij}{\\mathbf\\Sigma}$.\n\nThe covariance matrix between vectors at two subsequent times is therefore\n\n", "index": 83, "text": "\\begin{equation}\\label{{Teq1}}\n{\\langle{{\\bf x}{\\bf x}^t}\\rangle}\\equiv \\left(\n\\begin{tabular}{c@{\\hskip 5mm}c}\n${\\bf C}$&${\\bf C}{\\bf A}^t$\\\\\n${\\bf A}{\\bf C}$&${\\bf A}{\\bf C}{\\bf A}^t+{\\mathbf\\Sigma}$\n\\end{tabular}\n\\right),\n\\quad\n{\\bf x}\\equiv\n\\left(\n\\begin{tabular}{c}\n${\\bf x}_0$\\\\\n${\\bf x}_1$\n\\end{tabular}\n\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E42.m1\" class=\"ltx_Math\" alttext=\"{\\langle{{\\bf x}{\\bf x}^{t}}\\rangle}\\equiv\\left(\\begin{tabular}[]{c@{\\hskip 5%&#10;mm}c}${\\bf C}$\u00a0\u00a0\u00a0\u00a0\u00a0&amp;${\\bf C}{\\bf A}^{t}$\\\\&#10;${\\bf A}{\\bf C}$\u00a0\u00a0\u00a0\u00a0\u00a0&amp;${\\bf A}{\\bf C}{\\bf A}^{t}+{\\mathbf{\\Sigma}}$\\end{%&#10;tabular}\\right),\\quad{\\bf x}\\equiv\\left(\\begin{tabular}[]{c}${\\bf x}_{0}$\\\\&#10;${\\bf x}_{1}$\\end{tabular}\\right).\" display=\"block\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc31\ud835\udc31</mi><mi>t</mi></msup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>\u2261</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc02</mi><mrow/></mtd><mtd columnalign=\"center\"><mi>\ud835\udc02\ud835\udc00</mi><msup><mi/><mi>t</mi></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc00\ud835\udc02</mi><mrow/></mtd><mtd columnalign=\"center\"><mi>\ud835\udc00\ud835\udc02\ud835\udc00</mi><msup><mi/><mi>t</mi></msup><mo>+</mo><mi>\ud835\udeba</mi></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>\ud835\udc31</mi><mo>\u2261</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc31</mi><msub><mi/><mn>0</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc31</mi><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nthen equating it with {equation~(\\ref{{Teq1}})} lets us compute the matrices we need from the data:\n\\begin{eqnarray}\\label{{Aeq2}}\n{\\bf A}&=&{\\bf B}^t{\\bf C}^{-1},\\\\\n{\\mathbf\\Sigma}&=&{\\bf C}-{\\bf A}{\\bf C}{\\bf A}^t={\\bf C}-{\\bf B}^t{\\bf C}^{-1}{\\bf B}.\\label{Seq2}\n\\end{eqnarray}\nThese equations hold regardless of whether the probability distributions are Gaussian or not. \nIf the noise ${\\bf n}$ is Gaussian, then all distributions will be Gaussian in the steady state, so this is an alternative way of deriving \nequations~{~(\\ref{{ASeq}})} and~{~(\\ref{{Seq}})} (without the subscripts).\n\nIn {Section~\\ref{{ComparisonSec}}}, we saw how we can equally well interpret our system as a Markov process operating backward in time, where the future causes the past. Repeating the above derivation for this case, we can write \n\n", "itemtype": "equation", "pos": 75795, "prevtext": "\nEven if the random process is not stationary initially, it will eventually converge to a stationary state where covariance is time-independent as long as all eigenvalues of ${\\bf A}$ have magnitude below unity, so that memory of the past gets exponentially damped over time.\nOnce the covariance has become time-independent, {equation~(\\ref{{Teq1}})} implies that ${\\bf C}={\\bf A}{\\bf C}{\\bf A}^t+{\\mathbf\\Sigma}$. \nThis is known as the Lyapunov equation, and is readily solved by special-purpose techniques or, rapidly enough, by simply iterating it to convergence.\nIf we write the covariance matrix ${\\langle{{\\bf x}{\\bf x}^t}\\rangle}$ measured from actual time series data as\n\n", "index": 85, "text": "\\begin{equation}\\label{{Teq2}}\n{\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^t}\\rangle}=\n\\left(\n\\begin{tabular}{cc}\n${\\bf C}$&${\\bf B}$\\\\\n${\\bf B}^t$&${\\bf C}$\n\\end{tabular}\n\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E43.m1\" class=\"ltx_Math\" alttext=\"{\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^{t}}\\rangle}=\\left(\\begin{tabular}[]{cc}$%&#10;{\\bf C}$&amp;${\\bf B}$\\\\&#10;${\\bf B}^{t}$&amp;${\\bf C}$\\end{tabular}\\right),\" display=\"block\"><mrow><mrow><mi>\ud835\udc13</mi><mo>\u2261</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc31\ud835\udc31</mi><mi>t</mi></msup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc02</mi></mtd><mtd columnalign=\"center\"><mi>\ud835\udc01</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc01</mi><msup><mi/><mi>t</mi></msup></mtd><mtd columnalign=\"center\"><mi>\ud835\udc02</mi></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere\n\\begin{eqnarray}\\label{{AtildeEq}}\n{\\tilde{{\\bf A}}}&=&{\\bf B}{\\bf C}^{-1}={\\mathbf\\Sigma}{\\bf A}^t{\\tilde{\\mathbf\\Sigma}}^{-1},\\\\\n{\\tilde{\\mathbf\\Sigma}}&=&{\\bf C}-{\\bf B}{\\bf C}^{-1}{\\bf B}^t={\\bf C}-{\\tilde{{\\bf A}}}{\\bf C}{\\tilde{{\\bf A}}}^t,\\label{StildeEq}\\\\\n&=& [{\\bf C}^{-1}+{\\bf A}^t{\\mathbf\\Sigma}^{-1}{\\bf A}]^{-1}={\\bf C}-{\\bf C}{\\bf A}^t{\\bf C}^{-1}{\\bf A}{\\bf C}.\\nonumber\n\\end{eqnarray}\n\n\n\n\\subsection{Optimal factorization}\n\nIn summary, a Markov process ${\\bf p}_1={\\bf M}{\\bf p}$ can be described much more simply when all probability distributions are Gaussian: instead of keeping track of the infinite-dimensional matrix ${\\bf M}$ or the infinite-dimensional rank-4 tensor ${\\bf p}$, we merely need to keep track of the finite-dimensional covariance matrix ${\\bf T}$, from which we can compute and quantify the deterministic and causal parts of the dynamics as the matrices ${\\bf A}$ and ${\\mathbf\\Sigma}$, respectively.\n\nLet us now translate the rest of our results from our integration taxonomy into this simpler formalism.\nTo separate out the effects occurring within and between the subsystems A and B, let us name the corresponding blocks of the ${\\bf A}$-matrix and the\nmatrix ${\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^t}\\rangle}$ from {equation~(\\ref{{Meq2}})} as follows:\n\\begin{eqnarray}\\label{{ApartsDefEq}}\n{\\bf A}&=&\n\\left(\n\\begin{tabular}{ll}\n${\\bf A}_A$\t\t&${\\bf A}_{AB}$\\\\\n${\\bf A}_{BA}$\t&${\\bf A}_B$\n\\end{tabular}\n\\right)\\!\\!,\\\\\n{\\bf T}&=&\n\\left(\n\\begin{tabular}{llll}\n${\\bf C}_A$\t\t&${\\bf C}_{AB}$\t\t&${\\bf B}_A$\t\t&${\\bf B}_{AB}$\\\\\n${\\bf C}_{AB}^t$\t&${\\bf C}_B$\t\t\t&${\\bf B}_{BA}$\t&${\\bf B}_B$\\\\\n${\\bf B}_A^t$\t\t&${\\bf B}_{BA}^t$\t\t&${\\bf C}_A$\t\t&${\\bf C}_{AB}$\\\\\n${\\bf B}_{AB}^t$\t&${\\bf B}_B^t$\t\t&${\\bf C}_{AB}^t$\t&${\\bf C}_B$\n\\end{tabular}\n\\right)\\!\\!,\n\\>\\>\n{\\bf x}=\n\\left(\n\\begin{tabular}{l}\n${\\bf x}^A_0$\\\\\n${\\bf x}^B_0$\\\\\n${\\bf x}^A_1$\\\\\n${\\bf x}^B_1$\n\\end{tabular}\n\\right)\\!\\!.\n\\end{eqnarray}\nAnalogously to how {equation~(\\ref{{MarkovMatrixEq2}})} gave us {equation~(\\ref{{ContinuousMarkovEq}})}, \n{equation~(\\ref{{OptimalSeparableMarkovEq}})} now gives the optimal factorization\n\\begin{eqnarray}\\label{{ContinuousMarkovEq2}}\n\n{\\bf M}^A({\\bf x}_1^A,{\\bf x}_0^A)&=&g[{\\bf x}_1^A;{\\widehat{\\bf A}}_A{\\bf x}_0^A,{\\widehat{\\mathbf\\Sigma}}_A],\\\\\n{\\bf M}^B({\\bf x}_1^B,{\\bf x}_0^B)&=&g[{\\bf x}_1^B;{\\widehat{\\bf A}}_B{\\bf x}_0^B,{\\widehat{\\mathbf\\Sigma}}_B],\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\\label{{ASeq}}\n{\\widehat{\\bf A}}_A&\\equiv&{\\bf B}_A^t{\\bf C}_A^{-1},\\quad {\\widehat{\\mathbf\\Sigma}}_A\\equiv{\\bf C}_A-{\\bf B}_A^t{\\bf C}_A^{-1}{\\bf B}_A,\\\\\n{\\widehat{\\bf A}}_B&\\equiv&{\\bf B}_B^t{\\bf C}_B^{-1},\\quad {\\widehat{\\mathbf\\Sigma}}_B\\equiv{\\bf C}_B-{\\bf B}_B^t{\\bf C}_B^{-1}{\\bf B}_B.\n\\end{eqnarray}\nIn other words, the ``o''-factorization approximates ${\\bf x}_1={\\bf A}{\\bf x}_0+{\\bf n}$ by\n\n", "itemtype": "equation", "pos": 76806, "prevtext": "\nthen equating it with {equation~(\\ref{{Teq1}})} lets us compute the matrices we need from the data:\n\\begin{eqnarray}\\label{{Aeq2}}\n{\\bf A}&=&{\\bf B}^t{\\bf C}^{-1},\\\\\n{\\mathbf\\Sigma}&=&{\\bf C}-{\\bf A}{\\bf C}{\\bf A}^t={\\bf C}-{\\bf B}^t{\\bf C}^{-1}{\\bf B}.\\label{Seq2}\n\\end{eqnarray}\nThese equations hold regardless of whether the probability distributions are Gaussian or not. \nIf the noise ${\\bf n}$ is Gaussian, then all distributions will be Gaussian in the steady state, so this is an alternative way of deriving \nequations~{~(\\ref{{ASeq}})} and~{~(\\ref{{Seq}})} (without the subscripts).\n\nIn {Section~\\ref{{ComparisonSec}}}, we saw how we can equally well interpret our system as a Markov process operating backward in time, where the future causes the past. Repeating the above derivation for this case, we can write \n\n", "index": 87, "text": "\\begin{equation}\\label{{BackwardLinearEq}}\n{\\bf x}_{i-1}={\\tilde{{\\bf A}}}{\\bf x}_{i}+{\\bf n}_i,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E44.m1\" class=\"ltx_Math\" alttext=\"{\\bf x}_{i-1}={\\tilde{{\\bf A}}}{\\bf x}_{i}+{\\bf n}_{i},\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc31</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc00</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><msub><mi>\ud835\udc31</mi><mi>i</mi></msub></mrow><mo>+</mo><msub><mi>\ud835\udc27</mi><mi>i</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere the noise vector ${\\widehat{\\bf n}}$ has zero mean and covariance matrix\n\n", "itemtype": "equation", "pos": 79748, "prevtext": "\nwhere\n\\begin{eqnarray}\\label{{AtildeEq}}\n{\\tilde{{\\bf A}}}&=&{\\bf B}{\\bf C}^{-1}={\\mathbf\\Sigma}{\\bf A}^t{\\tilde{\\mathbf\\Sigma}}^{-1},\\\\\n{\\tilde{\\mathbf\\Sigma}}&=&{\\bf C}-{\\bf B}{\\bf C}^{-1}{\\bf B}^t={\\bf C}-{\\tilde{{\\bf A}}}{\\bf C}{\\tilde{{\\bf A}}}^t,\\label{StildeEq}\\\\\n&=& [{\\bf C}^{-1}+{\\bf A}^t{\\mathbf\\Sigma}^{-1}{\\bf A}]^{-1}={\\bf C}-{\\bf C}{\\bf A}^t{\\bf C}^{-1}{\\bf A}{\\bf C}.\\nonumber\n\\end{eqnarray}\n\n\n\n\\subsection{Optimal factorization}\n\nIn summary, a Markov process ${\\bf p}_1={\\bf M}{\\bf p}$ can be described much more simply when all probability distributions are Gaussian: instead of keeping track of the infinite-dimensional matrix ${\\bf M}$ or the infinite-dimensional rank-4 tensor ${\\bf p}$, we merely need to keep track of the finite-dimensional covariance matrix ${\\bf T}$, from which we can compute and quantify the deterministic and causal parts of the dynamics as the matrices ${\\bf A}$ and ${\\mathbf\\Sigma}$, respectively.\n\nLet us now translate the rest of our results from our integration taxonomy into this simpler formalism.\nTo separate out the effects occurring within and between the subsystems A and B, let us name the corresponding blocks of the ${\\bf A}$-matrix and the\nmatrix ${\\bf T}\\equiv{\\langle{{\\bf x}{\\bf x}^t}\\rangle}$ from {equation~(\\ref{{Meq2}})} as follows:\n\\begin{eqnarray}\\label{{ApartsDefEq}}\n{\\bf A}&=&\n\\left(\n\\begin{tabular}{ll}\n${\\bf A}_A$\t\t&${\\bf A}_{AB}$\\\\\n${\\bf A}_{BA}$\t&${\\bf A}_B$\n\\end{tabular}\n\\right)\\!\\!,\\\\\n{\\bf T}&=&\n\\left(\n\\begin{tabular}{llll}\n${\\bf C}_A$\t\t&${\\bf C}_{AB}$\t\t&${\\bf B}_A$\t\t&${\\bf B}_{AB}$\\\\\n${\\bf C}_{AB}^t$\t&${\\bf C}_B$\t\t\t&${\\bf B}_{BA}$\t&${\\bf B}_B$\\\\\n${\\bf B}_A^t$\t\t&${\\bf B}_{BA}^t$\t\t&${\\bf C}_A$\t\t&${\\bf C}_{AB}$\\\\\n${\\bf B}_{AB}^t$\t&${\\bf B}_B^t$\t\t&${\\bf C}_{AB}^t$\t&${\\bf C}_B$\n\\end{tabular}\n\\right)\\!\\!,\n\\>\\>\n{\\bf x}=\n\\left(\n\\begin{tabular}{l}\n${\\bf x}^A_0$\\\\\n${\\bf x}^B_0$\\\\\n${\\bf x}^A_1$\\\\\n${\\bf x}^B_1$\n\\end{tabular}\n\\right)\\!\\!.\n\\end{eqnarray}\nAnalogously to how {equation~(\\ref{{MarkovMatrixEq2}})} gave us {equation~(\\ref{{ContinuousMarkovEq}})}, \n{equation~(\\ref{{OptimalSeparableMarkovEq}})} now gives the optimal factorization\n\\begin{eqnarray}\\label{{ContinuousMarkovEq2}}\n\n{\\bf M}^A({\\bf x}_1^A,{\\bf x}_0^A)&=&g[{\\bf x}_1^A;{\\widehat{\\bf A}}_A{\\bf x}_0^A,{\\widehat{\\mathbf\\Sigma}}_A],\\\\\n{\\bf M}^B({\\bf x}_1^B,{\\bf x}_0^B)&=&g[{\\bf x}_1^B;{\\widehat{\\bf A}}_B{\\bf x}_0^B,{\\widehat{\\mathbf\\Sigma}}_B],\n\\end{eqnarray}\nwhere\n\\begin{eqnarray}\\label{{ASeq}}\n{\\widehat{\\bf A}}_A&\\equiv&{\\bf B}_A^t{\\bf C}_A^{-1},\\quad {\\widehat{\\mathbf\\Sigma}}_A\\equiv{\\bf C}_A-{\\bf B}_A^t{\\bf C}_A^{-1}{\\bf B}_A,\\\\\n{\\widehat{\\bf A}}_B&\\equiv&{\\bf B}_B^t{\\bf C}_B^{-1},\\quad {\\widehat{\\mathbf\\Sigma}}_B\\equiv{\\bf C}_B-{\\bf B}_B^t{\\bf C}_B^{-1}{\\bf B}_B.\n\\end{eqnarray}\nIn other words, the ``o''-factorization approximates ${\\bf x}_1={\\bf A}{\\bf x}_0+{\\bf n}$ by\n\n", "index": 89, "text": "\\begin{equation}\\label{{xhDefEq}}\n{\\widehat{{\\bf x}}}_1\\equiv\n\\left(\n\\begin{tabular}{l}\n${\\widehat{{\\bf x}}}^A_1$\\\\\n${\\widehat{{\\bf x}}}^B_1$\\\\\n\\end{tabular}\n\\right)\n\\equiv{\\widehat{\\bf A}}{\\bf x}_0+{\\widehat{\\bf n}},\n\\quad\n{\\widehat{\\bf A}}\\equiv\n\\left(\n\\begin{tabular}{cc}\n${\\widehat{\\bf A}}_A$\t&$0$\\\\\n$0$\t\t&${\\widehat{\\bf A}}_B$\n\\end{tabular}\n\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E45.m1\" class=\"ltx_Math\" alttext=\"{\\widehat{{\\bf x}}}_{1}\\equiv\\left(\\begin{tabular}[]{l}${\\widehat{{\\bf x}}}^{A%&#10;}_{1}$\\\\&#10;${\\widehat{{\\bf x}}}^{B}_{1}$\\\\&#10;\\end{tabular}\\right)\\equiv{\\widehat{\\bf A}}{\\bf x}_{0}+{\\widehat{\\bf n}},\\quad%&#10;{\\widehat{\\bf A}}\\equiv\\left(\\begin{tabular}[]{cc}${\\widehat{\\bf A}}_{A}$&amp;$0$%&#10;\\\\&#10;$0$&amp;${\\widehat{\\bf A}}_{B}$\\end{tabular}\\right),\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>\ud835\udc31</mi><mo>^</mo></mover><mn>1</mn></msub><mo>\u2261</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mover accent=\"true\"><mi>\ud835\udc31</mi><mo>^</mo></mover><msup><mi/><mi>A</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"left\"><mover accent=\"true\"><mi>\ud835\udc31</mi><mo>^</mo></mover><msup><mi/><mi>B</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2261</mo><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc00</mi><mo>^</mo></mover><mo>\u2062</mo><msub><mi>\ud835\udc31</mi><mn>0</mn></msub></mrow><mo>+</mo><mover accent=\"true\"><mi>\ud835\udc27</mi><mo>^</mo></mover></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mover accent=\"true\"><mi>\ud835\udc00</mi><mo>^</mo></mover><mo>\u2261</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mover accent=\"true\"><mi>\ud835\udc00</mi><mo>^</mo></mover><msub><mi/><mi>A</mi></msub></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mover accent=\"true\"><mi>\ud835\udc00</mi><mo>^</mo></mover><msub><mi/><mi>B</mi></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nWe see that tensor factorization in the previous section now corresponds to the matrices\n${\\bf A}$ and ${\\mathbf\\Sigma}$ being block-diagonal.\n\n\n\\subsection{Noising factorization}\n\n{Equation~(\\ref{{LinearEq2}})} tells us that\n\n", "itemtype": "equation", "pos": 80197, "prevtext": "\nwhere the noise vector ${\\widehat{\\bf n}}$ has zero mean and covariance matrix\n\n", "index": 91, "text": "\\begin{equation}\\label{{ShDefEq}}\n{\\widehat{\\mathbf\\Sigma}}\\equiv\n\\left(\n\\begin{tabular}{cc}\n${\\widehat{\\mathbf\\Sigma}}_A$\t&$0$\\\\\n$0$\t\t&${\\widehat{\\mathbf\\Sigma}}_B$\n\\end{tabular}\n\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E46.m1\" class=\"ltx_Math\" alttext=\"{\\widehat{\\mathbf{\\Sigma}}}\\equiv\\left(\\begin{tabular}[]{cc}${\\widehat{\\mathbf%&#10;{\\Sigma}}}_{A}$&amp;$0$\\\\&#10;$0$&amp;${\\widehat{\\mathbf{\\Sigma}}}_{B}$\\end{tabular}\\right).\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udeba</mi><mo>^</mo></mover><mo>\u2261</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mover accent=\"true\"><mi>\ud835\udeba</mi><mo>^</mo></mover><msub><mi/><mi>A</mi></msub></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mover accent=\"true\"><mi>\ud835\udeba</mi><mo>^</mo></mover><msub><mi/><mi>B</mi></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nThe idea with noising is to take the terms ${\\bf A}_{AB}{\\bf x}^B_0$ and ${\\bf A}_{BA}{\\bf x}^A_0$ and reinterpret them not as signal but as noise, with zero mean and uncorrelated with anything else.\nThe noising option ``n'' is unfortunately undefined for this continuous-variable case, because it says to use a uniform distribution for these noised versions of ${\\bf x}_0^A$ and ${\\bf x}_0^B$, which has infinite variance and hence gives, {\\frenchspacing\\it e.g.},  ${\\langle{{\\bf x}^B_0{{\\bf x}^B_0}^t}\\rangle}=\\infty$ when ${\\bf x}_0^B$ is noised.\nThe mild noising option ``m'', however, remains well-defined, saying to use the actual distributions for these noised versions of ${\\bf x}_0^A$ and ${\\bf x}_0^B$, hence giving ${\\langle{{\\bf x}^A_0{{\\bf x}^A_0}^t}\\rangle}={\\bf C}_A$ and ${\\langle{{\\bf x}^B_0{{\\bf x}^B_0}^t}\\rangle}={\\bf C}_B$ when these variables are noised.\n\nComputing the first and second moments of {equation~(\\ref{{NoisingxEq}})} therefore tells us that \n``m''-factorization approximates ${\\bf x}_1={\\bf A}{\\bf x}_0+{\\bf n}$ by\n\n", "itemtype": "equation", "pos": 80627, "prevtext": "\nWe see that tensor factorization in the previous section now corresponds to the matrices\n${\\bf A}$ and ${\\mathbf\\Sigma}$ being block-diagonal.\n\n\n\\subsection{Noising factorization}\n\n{Equation~(\\ref{{LinearEq2}})} tells us that\n\n", "index": 93, "text": "\\begin{equation}\\label{{NoisingxEq}}\n\\left(\n\\begin{tabular}{c}\n${\\bf x}^A_1$\\\\\n${\\bf x}^B_1$\n\\end{tabular}\n\\right)={\\bf A}{\\bf x}_0+{\\bf n}=\n\\left(\n\\begin{tabular}{c}\n${\\bf A}_A{\\bf x}^A_0+{\\bf A}_{AB}{\\bf x}^B_0+{\\bf n}^A$\\\\\n${\\bf A}_B{\\bf x}^B_0+{\\bf A}_{BA}{\\bf x}^A_0+{\\bf n}^B$\n\\end{tabular}\n\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47.m1\" class=\"ltx_Math\" alttext=\"\\left(\\begin{tabular}[]{c}${\\bf x}^{A}_{1}$\\\\&#10;${\\bf x}^{B}_{1}$\\end{tabular}\\right)={\\bf A}{\\bf x}_{0}+{\\bf n}=\\left(\\begin{%&#10;tabular}[]{c}${\\bf A}_{A}{\\bf x}^{A}_{0}+{\\bf A}_{AB}{\\bf x}^{B}_{0}+{\\bf n}^{%&#10;A}$\\\\&#10;${\\bf A}_{B}{\\bf x}^{B}_{0}+{\\bf A}_{BA}{\\bf x}^{A}_{0}+{\\bf n}^{B}$\\end{%&#10;tabular}\\right).\" display=\"block\"><mrow><mrow><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc31</mi><msup><mi/><mi>A</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc31</mi><msup><mi/><mi>B</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mrow><msub><mi>\ud835\udc00\ud835\udc31</mi><mn>0</mn></msub><mo>+</mo><mi>\ud835\udc27</mi></mrow><mo>=</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mi>A</mi></msub><mi>\ud835\udc31</mi><msup><mi/><mi>A</mi></msup><msub><mi/><mn>0</mn></msub><mo>+</mo><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msub><mi>\ud835\udc31</mi><msup><mi/><mi>B</mi></msup><msub><mi/><mn>0</mn></msub><mo>+</mo><mi>\ud835\udc27</mi><msup><mi/><mi>A</mi></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mi>B</mi></msub><mi>\ud835\udc31</mi><msup><mi/><mi>B</mi></msup><msub><mi/><mn>0</mn></msub><mo>+</mo><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>B</mi><mo>\u2062</mo><mi>A</mi></mrow></msub><mi>\ud835\udc31</mi><msup><mi/><mi>A</mi></msup><msub><mi/><mn>0</mn></msub><mo>+</mo><mi>\ud835\udc27</mi><msup><mi/><mi>B</mi></msup></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere the noise vector ${\\bar{\\bf n}}$ has zero mean and covariance matrix\n\n", "itemtype": "equation", "pos": 81999, "prevtext": "\nThe idea with noising is to take the terms ${\\bf A}_{AB}{\\bf x}^B_0$ and ${\\bf A}_{BA}{\\bf x}^A_0$ and reinterpret them not as signal but as noise, with zero mean and uncorrelated with anything else.\nThe noising option ``n'' is unfortunately undefined for this continuous-variable case, because it says to use a uniform distribution for these noised versions of ${\\bf x}_0^A$ and ${\\bf x}_0^B$, which has infinite variance and hence gives, {\\frenchspacing\\it e.g.},  ${\\langle{{\\bf x}^B_0{{\\bf x}^B_0}^t}\\rangle}=\\infty$ when ${\\bf x}_0^B$ is noised.\nThe mild noising option ``m'', however, remains well-defined, saying to use the actual distributions for these noised versions of ${\\bf x}_0^A$ and ${\\bf x}_0^B$, hence giving ${\\langle{{\\bf x}^A_0{{\\bf x}^A_0}^t}\\rangle}={\\bf C}_A$ and ${\\langle{{\\bf x}^B_0{{\\bf x}^B_0}^t}\\rangle}={\\bf C}_B$ when these variables are noised.\n\nComputing the first and second moments of {equation~(\\ref{{NoisingxEq}})} therefore tells us that \n``m''-factorization approximates ${\\bf x}_1={\\bf A}{\\bf x}_0+{\\bf n}$ by\n\n", "index": 95, "text": "\\begin{equation}\\label{{NoisingxhDefEq}}\n{\\bar{{\\bf x}}}_1\\equiv\n\\left(\n\\begin{tabular}{l}\n${\\bar{{\\bf x}}}^A_1$\\\\\n${\\bar{{\\bf x}}}^B_1$\\\\\n\\end{tabular}\n\\right)\n\\equiv{\\bar{\\bf A}}{\\bf x}_0+{\\bar{\\bf n}},\n\\quad\n{\\bar{\\bf A}}\\equiv\n\\left(\n\\begin{tabular}{cc}\n${\\bf A}_A$\t&$0$\\\\\n$0$\t\t&${\\bf A}_B$\n\\end{tabular}\n\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m1\" class=\"ltx_Math\" alttext=\"{\\bar{{\\bf x}}}_{1}\\equiv\\left(\\begin{tabular}[]{l}${\\bar{{\\bf x}}}^{A}_{1}$\\\\&#10;${\\bar{{\\bf x}}}^{B}_{1}$\\\\&#10;\\end{tabular}\\right)\\equiv{\\bar{\\bf A}}{\\bf x}_{0}+{\\bar{\\bf n}},\\quad{\\bar{%&#10;\\bf A}}\\equiv\\left(\\begin{tabular}[]{cc}${\\bf A}_{A}$&amp;$0$\\\\&#10;$0$&amp;${\\bf A}_{B}$\\end{tabular}\\right),\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>\ud835\udc31</mi><mo stretchy=\"false\">\u00af</mo></mover><mn>1</mn></msub><mo>\u2261</mo><mrow><mo>(</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mover accent=\"true\"><mi>\ud835\udc31</mi><mo stretchy=\"false\">\u00af</mo></mover><msup><mi/><mi>A</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"left\"><mover accent=\"true\"><mi>\ud835\udc31</mi><mo stretchy=\"false\">\u00af</mo></mover><msup><mi/><mi>B</mi></msup><msub><mi/><mn>1</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2261</mo><mrow><mrow><mover accent=\"true\"><mi>\ud835\udc00</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>\u2062</mo><msub><mi>\ud835\udc31</mi><mn>0</mn></msub></mrow><mo>+</mo><mover accent=\"true\"><mi>\ud835\udc27</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mover accent=\"true\"><mi>\ud835\udc00</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>\u2261</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mi>A</mi></msub></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mi>B</mi></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nNote that in contrast to the ``o''-factorization of {equation~(\\ref{{xhDefEq}})}, \nthe ``m''-factorization has no tildes on the ${\\bf A}_A$ and ${\\bf A}_B$-matrices in {equation~(\\ref{{NoisingxhDefEq}})}.\n\n\n\\subsection{Results}\n\nWe now have all the tools we need to derive the Gaussian versions of the $\\phi$-formulas in {Table~\\ref{{MeasureTable}}}.\nStarting with {equation~(\\ref{{IdefEq}})}, interpreting the sum in {equation~(\\ref{{SdefEq}})} as an integral and performing it when $p$ is the Gaussian distribution of  {equation~(\\ref{{GaussianpEq}})}\ngives the well-known formula\n\n", "itemtype": "equation", "pos": 82407, "prevtext": "\nwhere the noise vector ${\\bar{\\bf n}}$ has zero mean and covariance matrix\n\n", "index": 97, "text": "\\begin{equation}\\label{{NoisingShDefEq}}\n{\\bar{\\mathbf\\Sigma}}\\equiv\n\\left(\n\\begin{tabular}{cc}\n${\\mathbf\\Sigma}_A+{\\bf A}_{AB}{\\bf C}_B{\\bf A}_{AB}^t$\t&$0$\\\\\n$0$\t\t\t\t\t\t\t&${\\mathbf\\Sigma}_B+{\\bf A}_{BA}{\\bf C}_A{\\bf A}_{BA}^t$\n\\end{tabular}\n\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m1\" class=\"ltx_Math\" alttext=\"{\\bar{\\mathbf{\\Sigma}}}\\equiv\\left(\\begin{tabular}[]{cc}${\\mathbf{\\Sigma}}_{A}%&#10;+{\\bf A}_{AB}{\\bf C}_{B}{\\bf A}_{AB}^{t}$&amp;$0$\\\\&#10;$0$&amp;${\\mathbf{\\Sigma}}_{B}+{\\bf A}_{BA}{\\bf C}_{A}{\\bf A}_{BA}^{t}$\\end{%&#10;tabular}\\right).\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>\ud835\udeba</mi><mo stretchy=\"false\">\u00af</mo></mover><mo>\u2261</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udeba</mi><msub><mi/><mi>A</mi></msub><mo>+</mo><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msub><mi>\ud835\udc02</mi><msub><mi/><mi>B</mi></msub><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow></msub><msup><mi/><mi>t</mi></msup></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi>\ud835\udeba</mi><msub><mi/><mi>B</mi></msub><mo>+</mo><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>B</mi><mo>\u2062</mo><mi>A</mi></mrow></msub><mi>\ud835\udc02</mi><msub><mi/><mi>A</mi></msub><mi>\ud835\udc00</mi><msub><mi/><mrow><mi>B</mi><mo>\u2062</mo><mi>A</mi></mrow></msub><msup><mi/><mi>t</mi></msup></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nfor the mutual information between two multivariate Gaussian random variables.\nThis immediately gives the five matrix formulas for $\\phi^{\\rm M}$, $\\phi^{\\rm B}$, $\\phi^{\\rm otsk}$, $\\phi^{\\rm ofsk}$ and $\\phi^{\\rm xfkk}$ in the right column of  {Table~\\ref{{MeasureTable}}}.\n\nStarting with the  KL-divergence definition $d_{\\rm KL}(p,q)\\equiv\\sum_i p_i\\log{p_i\\over q_i}$ from {Table~\\ref{{MetricTable}}}, we again interpret the sum as an integral and use \n{equation~(\\ref{{GaussianpEq}})}. This gives the well-known formula \n\\begin{eqnarray}\\label{{GaussianKLeq}}\n&&D_{KL}(f_p,f_q)=\\nonumber\\\\\n&&{1\\over 2}\\left[\\Delta{\\bf m}^t{\\bf C}_q^{-1}\\Delta{\\bf m} + {\\hbox{tr}\\,} {\\bf C}_q^{-1}{\\bf C}_p +\\ln{|{\\bf C}_q|\\over|{\\bf C}_p|}-n\\right]\n\\end{eqnarray}\nfor the KL-divergence between two Gaussian probability distributions $f_p$ and $f_q$ with means ${\\bf m}_i$ and covariance matrices ${\\bf C}_i$ $(i=p,q)$,  \nwhere $\\Delta{\\bf m}\\equiv{\\bf m}_p-{\\bf m}_q$.\nThe first term in {equation~(\\ref{{GaussianKLeq}})} thus represents the mismatch between the means and the\nremainder (which is also guaranteed to be nonnegative) represents the mismatch between the covariances.\n\nFor $\\phi^{\\rm ofuk}$, the future distribution $p({\\bf x}_1)$ with mean zero and covarance matrix ${\\bf C}$ is approximated by\nthe distribution $q({\\bf x}_1)$ that has mean zero and covariance matrix ${\\widehat{\\bf A}}{\\bf C}{\\widehat{\\bf A}}^t+{\\widehat{\\mathbf\\Sigma}}$, which follows from \nequations{~(\\ref{{xhDefEq}})} and{~(\\ref{{ShDefEq}})}.\nSubstituting these means and covariance matrices into {equation~(\\ref{{GaussianKLeq}})} gives the matrix formula for $\\phi^{\\rm ofuk}$ in {Table~\\ref{{MeasureTable}}}.\nFor $\\phi^{\\rm mask}$,  both means again vanish, but now the future distribution $p({\\bf x}_1^A)$ has covariance matrix ${\\bf C}_A$ while the approximation\n$q({\\bf x}_1^A)$  has covariance matrix ${\\mathbf\\Sigma}_A+{\\bf A}_A{\\bf C}_A{\\bf A}_A^t+{\\bf A}_{AB}{\\bf C}_B{\\bf A}_{AB}^t $, which follows from \nequations{~(\\ref{{NoisingxhDefEq}})} and{~(\\ref{{NoisingShDefEq}})}.\n\nFor the remaining options in {Table~\\ref{{MeasureTable}}}, {\\frenchspacing\\it i.e.},\n$\\phi^{\\rm ofkk}$, $\\phi^{\\rm oakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm makk}$ and $\\phi^{\\rm mpkk}$, the means do not vanish, since they \nreflect information about the known state.\nFor $\\phi^{\\rm ofkk}$, the future distribution $p({\\bf x}_1)$ with mean ${\\bf A}{\\bf x}_0$ and covariance matrix ${\\mathbf\\Sigma}$ is approximated by\nthe distribution $q({\\bf x}_1)$ that has mean ${\\widehat{\\bf A}}{\\bf x}_0$ and and covariance matrix ${\\widehat{\\mathbf\\Sigma}}$, so {equation~(\\ref{{GaussianKLeq}})} gives the matrix formula for $\\phi^{\\rm ofkk}$ in the table.\nFor $\\phi^{\\rm oakk}$,  the future distribution $p({\\bf x}_1^A)$ has mean ${\\bf A}_A{\\bf x}_0^A+A_B{\\bf x}_0^B$ and and covariance matrix ${\\mathbf\\Sigma}$, while the approximation\n$q({\\bf x}_1^A)$  has mean ${\\widehat{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\widehat{\\mathbf\\Sigma}}_A$.\nFinally, for $\\phi^{\\rm makk}$,  the future distribution \n$p({\\bf x}_1^A)$ with mean ${\\widehat{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\widehat{\\mathbf\\Sigma}}_A$ is approximated by \n$q({\\bf x}_1^A)$ with mean ${\\bar{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\bar{\\mathbf\\Sigma}}_A$. \nThe time-reversed measures \n$\\phi^{\\rm opkk}$, $\\phi^{\\rm mpsk}$ and $\\phi^{\\rm mpkk}$ are identical to \n$\\phi^{\\rm oakk}$, $\\phi^{\\rm mask}$ and $\\phi^{\\rm makk}$, but with ${\\bf A}$ and ${\\mathbf\\Sigma}$ replaced by their time-reversed versions ${\\tilde{{\\bf A}}}$ and ${\\tilde{\\mathbf\\Sigma}}$ from {equation~(\\ref{{AtildeEq}})}.\n\n\n\\section{Graph-theory approximation to make computations feasible}\n\\label{ApproximationSec}\n\n\\subsection{The problem}\n\n\nThe $\\phi$-formulas for discrete variables in the left column of {Table~\\ref{{MeasureTable}}} require working with the\n$n\\times n$ matrix ${\\bf M}$, where $n=2^b$ for a system of $b$ bits.\nIn other words, the time to evaluate $\\phi$ for a given cut grows exponentially with the system size $b$, which becomes computationally prohibitive even for modest system sizes such as 100 bits --- let alone the set of neurons in the human brain with $b\\sim 10^{11}$. Even 300 bits give $n$ greater than the number of particles in our universe.\n\nWhen the system state is described not by bits but continuous variables  (such as voltages or other variables measured in \nfMRI, EEG, MEG or electrophysiology studies), things get even worse, since represending even a single variable requires an infinite number of bits. However,  \\cite{barrett2011practical} pointed out that the Gaussian approximation radically simplifies things, and we saw in {Section~\\ref{{GaussianSec}}} how $\\phi$ can then be computed dramatically faster.\nNot only does the infinity problem go away for most measures in {Table~\\ref{{MeasureTable}}}, but the formulas in the right column are exponentially faster to evaluate than those in the left column even when each bit is replaced by a separate real number! This is because if there are $b$ real numbers, the $n\\times n$ matrix ${\\bf T}$ has $n=2b$, not $n=2^b$. \nThis means that $\\phi$ can now be computed in polynomial time, more specifically $O(b^3)$ time, since \nthe slowest matrix operations in {Table~\\ref{{MeasureTable}}} scale as $O(n^3)$.\n\nUnfortunately, even after this exponential speedup in computing $\\phi$, computing the upper-case version $\\Phi$ is still exponentially slow. This is because $\\Phi$ is the minimum of $\\phi$ over the exponentially many ways of splitting the system into two parts. Even if we limit ourselves to symmetric bipartitions, there number of ways to split an even number  $n$ elements into two parts of size $n/2$ is \n\n", "itemtype": "equation", "pos": 83254, "prevtext": "\nNote that in contrast to the ``o''-factorization of {equation~(\\ref{{xhDefEq}})}, \nthe ``m''-factorization has no tildes on the ${\\bf A}_A$ and ${\\bf A}_B$-matrices in {equation~(\\ref{{NoisingxhDefEq}})}.\n\n\n\\subsection{Results}\n\nWe now have all the tools we need to derive the Gaussian versions of the $\\phi$-formulas in {Table~\\ref{{MeasureTable}}}.\nStarting with {equation~(\\ref{{IdefEq}})}, interpreting the sum in {equation~(\\ref{{SdefEq}})} as an integral and performing it when $p$ is the Gaussian distribution of  {equation~(\\ref{{GaussianpEq}})}\ngives the well-known formula\n\n", "index": 99, "text": "\\begin{equation}\\label{{GaussianIeq}}\nI({\\bf x}_A,{\\bf x}_B)={1\\over 2}\\log{ |{\\bf T}_A|\\,|{\\bf T}_B|\\over |{\\bf T}|}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E50.m1\" class=\"ltx_Math\" alttext=\"I({\\bf x}_{A},{\\bf x}_{B})={1\\over 2}\\log{|{\\bf T}_{A}|\\,|{\\bf T}_{B}|\\over|{%&#10;\\bf T}|}\" display=\"block\"><mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc31</mi><mi>A</mi></msub><mo>,</mo><msub><mi>\ud835\udc31</mi><mi>B</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mi>log</mi><mo>\u2061</mo><mfrac><mrow><mrow><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc13</mi><mi>A</mi></msub><mo rspace=\"4.2pt\" stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc13</mi><mi>B</mi></msub><mo stretchy=\"false\">|</mo></mrow></mrow><mrow><mo stretchy=\"false\">|</mo><mi>\ud835\udc13</mi><mo stretchy=\"false\">|</mo></mrow></mfrac></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere we have used Stirling's approximation $n!\\approx\\sqrt{2\\pi n}(n/e)^n$.\nIn other words, examining all symmetric bipartitions is pretty much as exponentially painful as examining all $2^n$ bipartitions, because most bipartitions are close to symmetric.\n \n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{graphs.pdf}}\n\\caption{Illustration of our fast $\\Phi$-approximation for an $n=16$ example. \nThe structure of the ${\\bf A}$-matrix can be visualized either as a grid (top four examples) where each pixel color shows the value of the corresponding element $A_{ij}$ ranging from the smallest (black) to the largest (white), or as a graph (bottom examples) showing all non-zero matrix elements.\nOur method zeros all matrix elements $|A_{ij}|<\\epsilon$ below the threshold $\\epsilon$ that makes the largest connected graph component involve merely half of the elements, which in the matrix picture means that there is a permutation of the elements (rows and columns) rendering the matrix block-diagonal (middle right). Whereas it would take exponentially long to try all matrix permutations, graph connectivity can be determined in polynomial time, thus enabling us to rapidly find a good approximation for the ``cruelest cut'' bipartition.\n\\label{GraphsFig}\n}\n\\end{figure}\n\n\\subsection{An approximate solution}\n\nBeing able to compute $\\Phi$ approximately is clearly better than not being able to compute it at all. \nIn this spirit, let us explore an approximation that exponentially accelerates the computation of $\\Phi$.\nStarting with the linear dynamics ${\\bf x}_{i+1}={\\bf A}{\\bf x}+{\\bf n}$\nfrom {equation~(\\ref{{LinearEq2}})},\nlet us motivate our approximation by considering the case where the noise is ${\\bf n}$ uncorrelated (where ${\\mathbf\\Sigma}$ is diagonal) so that it introduces no correlations between the two systems, regardless of the cut. This means that the only source of integration can be the ${\\bf A}$-matrix transferring information between the two subsystems.\nLet us visualize this information flow as a directed graph ({Figure~\\ref{{GraphsFig}}}, bottom), where each node represents a variable \n$i$ and each edge represents a non-zero element $A_{ij}$, {\\frenchspacing\\it i.e.}, non-zero information flow from element $j$ to element $i$. \nIf this graph consists of two disconnected parts A and B of equal size, as in the lower right corner of {Figure~\\ref{{GraphsFig}}}, then we clearly have $\\Phi=0$, since there is no information flow and hence no integration between these two parts. In other words, if we permute the elements so that all elements of A precede all elements of B, the matrix ${\\bf A}$ becomes block-diagonal ({Figure~\\ref{{GraphsFig}}}, middle right), for which all integration measures in the right column of {Table~\\ref{{MeasureTable}}} will give $\\phi=0$.\n\nNote that before the elements were permuted ({Figure~\\ref{{GraphsFig}}}, top right), this fact that $\\phi=0$ was less obvious.\nMoreover, examining all $n!$ permutations (or all $\\left({n\\atop n/2}\\right)$ symmetric bipartitions) would have been an enormously inefficient way of finding that best bipartition for which $\\phi$ vanishes. In contrast, finding the connected components of a graph is quite simple, as is evident from staring at {Figure~\\ref{{GraphsFig}}}, with complexity between $O(n)$ and $O(n^2)$.\nThis means that if we know that $\\Phi=0$, then we can find the best bipartition (``cruelest cut\") easily, in polynomial time.\n\nLet us now define an approximation taking advantage of this idea: \n{\\it replace all unimportant elements $|A_{ij}|<\\epsilon$ by zero, and adjust $\\epsilon$ so that the largest connected component has size as close as possible to $n/2$.} \nLetting this largest connected component define our approximation of the best bipartition, we now compute its $\\phi$-value and use this as our approximation for $\\Phi$.\n\n\nNote that this approximation can be trivially generalized to asymmetric bipartitions.\nIn practice, we determine $\\epsilon$ by using the interval halving method. A final technical point is that we have two separate definitions of graph connectivity to choose between: weak and strong. A graph is {\\it strongly connected} if you can move between any pair of elements following the directional arrows on the edges. This means that every element can (at least through intermediaries) affect and be affected by every other element, precisely capturing the integration spirit of \\cite{tononi2008consciousness}. \nStrong connectivity is therefore the logical choice when using our approximation to compute\n $\\Phi^{2.0}$, $\\Phi^{2.0'}$, $\\Phi^{2.0''}$, since it will reflect their property that integration vanishes for afferent and efferent pathways.\n A graph is {\\it weakly connected} if you can move between any pair of elements ignoring edge arrows --- in other words, if it simply looks connected when drawn.\nUsing weak connectivity is arguably the better approximation for the $\\Phi$-measures that do not vanish for afferent/efferent pathways, and numerical experiments confirm this.\n \n\n\n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{approximation.pdf}}\n\\caption{How well our fast $\\Phi$-approximation works for 7,000 simulations of the n=16 $\\Phi^M$-example described in the text.\nWhereas it is seen to be excellent at finding the best bipartition when not all are comparably good,\n(\\protect{\\frenchspacing\\it i.e.}, when $\\Phi_{\\rm max}/\\Phi_{\\rm in}\\gg 1$),  the approximation is seen to overestimate $\\Phi$ by up to 15\\% (the median) when there is no clear winner (left side). From top to bottom, the three curves show the 95th, 50th and 5th percentiles of the overestimation factor. The shaded region delimits the largest overestimation possible, when $\\Phi_{\\rm appox}=\\Phi_{\\rm max}$.\n\\label{ApproximationFig}\n}\n\\end{figure}\n\n{Figure~\\ref{{ApproximationFig}}} illustrates the accuracy of our approximation.\nFor this example,  we randomly\\footnote{We generate ${\\bf A}$-matrices by first computing\n\n", "itemtype": "equation", "pos": 89107, "prevtext": "\nfor the mutual information between two multivariate Gaussian random variables.\nThis immediately gives the five matrix formulas for $\\phi^{\\rm M}$, $\\phi^{\\rm B}$, $\\phi^{\\rm otsk}$, $\\phi^{\\rm ofsk}$ and $\\phi^{\\rm xfkk}$ in the right column of  {Table~\\ref{{MeasureTable}}}.\n\nStarting with the  KL-divergence definition $d_{\\rm KL}(p,q)\\equiv\\sum_i p_i\\log{p_i\\over q_i}$ from {Table~\\ref{{MetricTable}}}, we again interpret the sum as an integral and use \n{equation~(\\ref{{GaussianpEq}})}. This gives the well-known formula \n\\begin{eqnarray}\\label{{GaussianKLeq}}\n&&D_{KL}(f_p,f_q)=\\nonumber\\\\\n&&{1\\over 2}\\left[\\Delta{\\bf m}^t{\\bf C}_q^{-1}\\Delta{\\bf m} + {\\hbox{tr}\\,} {\\bf C}_q^{-1}{\\bf C}_p +\\ln{|{\\bf C}_q|\\over|{\\bf C}_p|}-n\\right]\n\\end{eqnarray}\nfor the KL-divergence between two Gaussian probability distributions $f_p$ and $f_q$ with means ${\\bf m}_i$ and covariance matrices ${\\bf C}_i$ $(i=p,q)$,  \nwhere $\\Delta{\\bf m}\\equiv{\\bf m}_p-{\\bf m}_q$.\nThe first term in {equation~(\\ref{{GaussianKLeq}})} thus represents the mismatch between the means and the\nremainder (which is also guaranteed to be nonnegative) represents the mismatch between the covariances.\n\nFor $\\phi^{\\rm ofuk}$, the future distribution $p({\\bf x}_1)$ with mean zero and covarance matrix ${\\bf C}$ is approximated by\nthe distribution $q({\\bf x}_1)$ that has mean zero and covariance matrix ${\\widehat{\\bf A}}{\\bf C}{\\widehat{\\bf A}}^t+{\\widehat{\\mathbf\\Sigma}}$, which follows from \nequations{~(\\ref{{xhDefEq}})} and{~(\\ref{{ShDefEq}})}.\nSubstituting these means and covariance matrices into {equation~(\\ref{{GaussianKLeq}})} gives the matrix formula for $\\phi^{\\rm ofuk}$ in {Table~\\ref{{MeasureTable}}}.\nFor $\\phi^{\\rm mask}$,  both means again vanish, but now the future distribution $p({\\bf x}_1^A)$ has covariance matrix ${\\bf C}_A$ while the approximation\n$q({\\bf x}_1^A)$  has covariance matrix ${\\mathbf\\Sigma}_A+{\\bf A}_A{\\bf C}_A{\\bf A}_A^t+{\\bf A}_{AB}{\\bf C}_B{\\bf A}_{AB}^t $, which follows from \nequations{~(\\ref{{NoisingxhDefEq}})} and{~(\\ref{{NoisingShDefEq}})}.\n\nFor the remaining options in {Table~\\ref{{MeasureTable}}}, {\\frenchspacing\\it i.e.},\n$\\phi^{\\rm ofkk}$, $\\phi^{\\rm oakk}$, $\\phi^{\\rm opkk}$, $\\phi^{\\rm makk}$ and $\\phi^{\\rm mpkk}$, the means do not vanish, since they \nreflect information about the known state.\nFor $\\phi^{\\rm ofkk}$, the future distribution $p({\\bf x}_1)$ with mean ${\\bf A}{\\bf x}_0$ and covariance matrix ${\\mathbf\\Sigma}$ is approximated by\nthe distribution $q({\\bf x}_1)$ that has mean ${\\widehat{\\bf A}}{\\bf x}_0$ and and covariance matrix ${\\widehat{\\mathbf\\Sigma}}$, so {equation~(\\ref{{GaussianKLeq}})} gives the matrix formula for $\\phi^{\\rm ofkk}$ in the table.\nFor $\\phi^{\\rm oakk}$,  the future distribution $p({\\bf x}_1^A)$ has mean ${\\bf A}_A{\\bf x}_0^A+A_B{\\bf x}_0^B$ and and covariance matrix ${\\mathbf\\Sigma}$, while the approximation\n$q({\\bf x}_1^A)$  has mean ${\\widehat{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\widehat{\\mathbf\\Sigma}}_A$.\nFinally, for $\\phi^{\\rm makk}$,  the future distribution \n$p({\\bf x}_1^A)$ with mean ${\\widehat{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\widehat{\\mathbf\\Sigma}}_A$ is approximated by \n$q({\\bf x}_1^A)$ with mean ${\\bar{\\bf A}}_A{\\bf x}_0^A$ and  covariance matrix ${\\bar{\\mathbf\\Sigma}}_A$. \nThe time-reversed measures \n$\\phi^{\\rm opkk}$, $\\phi^{\\rm mpsk}$ and $\\phi^{\\rm mpkk}$ are identical to \n$\\phi^{\\rm oakk}$, $\\phi^{\\rm mask}$ and $\\phi^{\\rm makk}$, but with ${\\bf A}$ and ${\\mathbf\\Sigma}$ replaced by their time-reversed versions ${\\tilde{{\\bf A}}}$ and ${\\tilde{\\mathbf\\Sigma}}$ from {equation~(\\ref{{AtildeEq}})}.\n\n\n\\section{Graph-theory approximation to make computations feasible}\n\\label{ApproximationSec}\n\n\\subsection{The problem}\n\n\nThe $\\phi$-formulas for discrete variables in the left column of {Table~\\ref{{MeasureTable}}} require working with the\n$n\\times n$ matrix ${\\bf M}$, where $n=2^b$ for a system of $b$ bits.\nIn other words, the time to evaluate $\\phi$ for a given cut grows exponentially with the system size $b$, which becomes computationally prohibitive even for modest system sizes such as 100 bits --- let alone the set of neurons in the human brain with $b\\sim 10^{11}$. Even 300 bits give $n$ greater than the number of particles in our universe.\n\nWhen the system state is described not by bits but continuous variables  (such as voltages or other variables measured in \nfMRI, EEG, MEG or electrophysiology studies), things get even worse, since represending even a single variable requires an infinite number of bits. However,  \\cite{barrett2011practical} pointed out that the Gaussian approximation radically simplifies things, and we saw in {Section~\\ref{{GaussianSec}}} how $\\phi$ can then be computed dramatically faster.\nNot only does the infinity problem go away for most measures in {Table~\\ref{{MeasureTable}}}, but the formulas in the right column are exponentially faster to evaluate than those in the left column even when each bit is replaced by a separate real number! This is because if there are $b$ real numbers, the $n\\times n$ matrix ${\\bf T}$ has $n=2b$, not $n=2^b$. \nThis means that $\\phi$ can now be computed in polynomial time, more specifically $O(b^3)$ time, since \nthe slowest matrix operations in {Table~\\ref{{MeasureTable}}} scale as $O(n^3)$.\n\nUnfortunately, even after this exponential speedup in computing $\\phi$, computing the upper-case version $\\Phi$ is still exponentially slow. This is because $\\Phi$ is the minimum of $\\phi$ over the exponentially many ways of splitting the system into two parts. Even if we limit ourselves to symmetric bipartitions, there number of ways to split an even number  $n$ elements into two parts of size $n/2$ is \n\n", "index": 101, "text": "\\begin{equation}\\label{{StirlingEq}}\n\\left({n\\atop n/2}\\right)={n!\\over (n/2)!^2}\n\\approx \\sqrt{2\\over\\pi n} 2^n,\n\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E51.m1\" class=\"ltx_Math\" alttext=\"\\left({n\\atop n/2}\\right)={n!\\over(n/2)!^{2}}\\approx\\sqrt{2\\over\\pi n}2^{n},\\par&#10;\" display=\"block\"><mrow><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>n</mi><mrow><mi>n</mi><mo>/</mo><mn>2</mn></mrow></mfrac><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi>n</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow><msup><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>n</mi><mo>/</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow><mn>2</mn></msup></mfrac><mo>\u2248</mo><mrow><msqrt><mfrac><mn>2</mn><mrow><mi>\u03c0</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac></msqrt><mo>\u2062</mo><msup><mn>2</mn><mi>n</mi></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02626.tex", "nexttext": "\nwhere ${\\bf A}_0$, ${\\bf A}_1$ and ${\\bf A}_2$ are random matrices (whose elements are independent Gaussian random variables with zero mean), each normalized to have their largest eigenvalue equal to unity. We then renormalize ${\\bf A}$ so that its largest eigenvalue equals 0.99.\nThe parameter $\\eta$ controls the typical level of integration: $\\eta=0$ gives $\\Phi=0$ since ${\\bf A}$ is block-diagonal, whereas $\\eta\\to\\infty$ gives minimal integration, with no special cut put in by hand; $\\eta$ is randomly chosen to be $0.1$, $0.3$, $0.5$, $0.7$, $1$, $2$ or $10$ with equal probability. Once we have generated ${\\bf A}$, we compute ${\\bf C}$ as the solution to the Lyapunov equation ${\\bf C}={\\bf A}{\\bf C}{\\bf A}^t+{\\mathbf\\Sigma}$ with ${\\mathbf\\Sigma}={\\bf I}$.\n} \ngenerate 7,000 different $16\\times 16$ matrices ${\\bf A}$ and compute $\\Phi^M$ both exactly (as the minimum of $\\phi^M$\nover all $\\left({16\\atop 8}\\right)=12,870$ symmetric bipartitions) and using our approximation.\n\n\nFor comparison, we also compute the maximum $\\Phi^M_{\\rm max}$ over the bipartitions.\nThe ratio $\\Phi_{\\rm max}/\\Phi\\ge 1$ (where $\\Phi\\equiv\\Phi_{\\rm min}$) \nquantifies how relatively decomposable a system is, whereas the ratio \n$\\Phi_{\\rm approx}/\\Phi\\ge 1$ quantifies how well our approximation works, with a value of unity signifying that it is perfect and found the optimal bipartition.\n{Figure~\\ref{{ApproximationFig}}} plots these two quantities against each other, and reveals that they are strongly related. For fairly separable systems, the approximation tends to be excellent: it gives exactly the correct answer \n95\\% of the time when $\\Phi_{\\rm max}/\\Phi>2$\nand\n99.96\\% of the time when $\\Phi_{\\rm max}/\\Phi>3$.\n\nWhen $\\Phi_{\\rm max}/\\Phi{\\mathrel{{\\hbox to 0pt{{\\lower 3pt\\hbox{$\\mathchar\"218$}}\\hss}}    \\raise 2.0pt\\hbox{$\\mathchar\"13C$}}} 2$, on the other hand, so that there is less of a clear winner among the bipartitions, our approximation is seen to overestimate the true $\\Phi$-value by up to 15\\%  on average (this is the median). \n\n\n\\section{Conclusions}\n\\label{ConclusionsSec}\n\n\nMotivated by the  growing interest in measuring integrated information $\\Phi$ in computational and cognitive systems, we have presented a simple taxonomy of $\\Phi$-measures where they are each characterized by their choice of factorization method (5 options),  choice of probability distributions to compare ($3\\times 4$ options) and choice of measure for comparing probability distributions (5 options). \nWe classify all the integration measures revealed in this taxonomy by various desirable properties,  as summarized in {Table~\\ref{{PropertyTable}}}.\nWhen requiring the $\\Phi$-measures to satisfy a minimum of attractive properties, the hundreds of options reduce to a mere handful, some of which turn out to be identical. All leading contenders are summarized in {Table~\\ref{{MeasureTable}}}.\n\nUnfortunately, these most general integration measures are unfeasible to evaluate in practice, with the computational cost growing doubly exponentially with $b$, the number of bits in the system:\nthey involve a Markov matrix of size $n=2^b$, and they also involve minimizing over approximately \n$N=2^n=2^{2^b}$ bipartitions.\nGeneralizing the pioneering work of \\cite{barrett2011practical}, we derive formulas for the Gaussian case that are exponentially faster, involving manipulations of a matrix whose size grows as $2b$ rather than $2^b$\nwith the number of variables $b$.\nMoreover, we show how the second exponential can also be avoided using an approximation using graph theory, thus reducing the computational cost from doubly exponential to merely polynomial in the system size $b$. \n\n\n\\subsection{Which $\\Phi$-measures are best?}\n\nAs described in detail in {Section~\\ref{{BestSec}}}, six $\\Phi$-measures stand out from the taxonomy of hundreds of measures as particularly attractive:\n$\\Phi^{\\rm M}$, \n$\\Phi^{\\rm M}_{kk'}$,\n$\\Phi^{3.0}$,\n$\\Phi^{2.0}$,\n$\\Phi^{2.0'}$ and\n$\\Phi^{2.0''}$.\n$\\Phi^{\\rm M}$ retains all the attractive features of the Barrett/Seth measure $\\Phi^B$ and adds further improvements: it is guaranteed to vanish for separable systems and to never be negative.\nIf state-dependence is viewed as desirable, then its cousin $\\Phi^{\\rm M}_{kk'}$ adds that feature too.\n\n$\\Phi^{\\rm 3.0}$ is the measure advocated by IIT3.0 and has the many attractive features described in\n\\cite{oizumi2014phenomenology}. It has the drawback of being the slowest of all the measures to evaluate numerically: its definition involves a linear programming problem which needs to be solved numerically, and even with the fastest algorithms currently available, the computation for a given bipartition grows faster than quadratically with the number of system states --- which in turn grows exponentially with the number of bits, and is infinite for continuous variables.\n\nThe remaining three top measures, $\\Phi^{2.0}$, $\\Phi^{2.0'}$ and $\\Phi^{2.0''}$, share with \n$\\Phi^{\\rm 3.0}$ the arguably desirable feature of vanishing for afferent and efferent systems, but are much quicker to compute.\n$\\Phi^{\\rm 2.0}$ is the measure advocated by IIT2.0 \\cite{tononi2008consciousness} and elegantly depends only on the system's dynamics and present state, not on any assumptions about which states are more probable. Its drawback of being infinite for continuous variables is overcome by its cousin $\\Phi^{\\rm 2.0'}$. \n\nA potential philosophical objection to both $\\Phi^{\\rm 2.0}$ and $\\Phi^{\\rm 2.0'}$ is that \nthey are arguably not measures of  integration,  but measures of how suboptimal the factorizations $``n\"$ and $``m\"$ are, since they would both vanish if an optimal factorization were used --- the measure $\\Phi^{\\rm 2.0''}$ eliminates this concern.\n\n\n\n\n\\subsection{Outlook}\n\nAlthough the results in this paper will hopefully prove useful, there is ample worthwhile work left to do on integration measures.\n\nOne major open question is how to best handle asymmetric partitions. We deliberately sidestepped this challenge in the present paper, since it is independent of our results, which is why the subtle normalization issue raised by \n\\cite{tononi2008consciousness}, \\cite{barrett2011practical} and \\cite{oizumi2014phenomenology} never entered. \nThe crux is that if we apply any of the measures in our taxonomy with an asymmetric bipartition, the resulting $\\phi$-value will tend to get small when any of the two subsystems is very small,\n\nso simply defining $\\Phi$ as the minimum of $\\phi$ over all bipartitions (symmetric or not) makes no sense.\nIIT3.0 makes an interesting proposal for how to handle asymmetric partitions, and it is worthwhile exploring whether there are other atttractive options as well. \n\n\nAnother foundational question is whether our taxonomy can be placed on a firmer logical footing. Although \nour classification based on  factorization, comparison, conditioning and measure may seem sensible an exhaustive, it is interesting to consider whether one or several $\\Phi$-measures can be rigorously derived from a small set of attractive axioms alone, in the same spirit as Claude Shannon derived his famous entropy formula,\n{equation~(\\ref{{SdefEq}})}.\n\nA more practical question involves exploring ways of generalizing and further improving our graph-theory-based approximation for exponential speedup. \nOne obvious generalization would involve taking into advantage of the structure of ${\\mathbf\\Sigma}$ (which our method ignored) and the effect of ${\\bf x}$ (for those $\\Phi$-measures that are state-dependent). \nAnother interesting opportunity is to generalize from continuous Gaussian systems to arbitrary discrete systems.\nFor example, if the system consists of $b$ different bits coupled by a nonlinear network of gates, \none can apply a similar graph-theory approach by defining a $b\\times b$ coupling matrix ${\\bf A}_{ij}$ that in some way quantifies how strongly \nflipping the $j^{\\rm th}$ bit would affects the $i^{\\rm th}$ bit at the next timestep.\n    \nLast but not least, a veritable goldmine of data is becoming available in neuroscience and other fields, and it will be fascinating to measure $\\Phi$ for these emerging data sets. In particular, the exponentially faster $\\Phi$-measures we have proposed will hopefully facilitate quantitative tests of  theories of consciousness.\n\n\n\n\\bigskip\n\\noindent\n{\\bf Acknowledgements:} The author would like to thank Meia Chita-Tegmark and Henry Lin for stimulating conversations, useful suggestions and  proofreading help.\n\nThis research was supported by ARO grant W911NF-15-1-0300.\n\n\\bibliography{phi}\n\n\n\n", "itemtype": "equation", "pos": 95224, "prevtext": "\nwhere we have used Stirling's approximation $n!\\approx\\sqrt{2\\pi n}(n/e)^n$.\nIn other words, examining all symmetric bipartitions is pretty much as exponentially painful as examining all $2^n$ bipartitions, because most bipartitions are close to symmetric.\n \n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{graphs.pdf}}\n\\caption{Illustration of our fast $\\Phi$-approximation for an $n=16$ example. \nThe structure of the ${\\bf A}$-matrix can be visualized either as a grid (top four examples) where each pixel color shows the value of the corresponding element $A_{ij}$ ranging from the smallest (black) to the largest (white), or as a graph (bottom examples) showing all non-zero matrix elements.\nOur method zeros all matrix elements $|A_{ij}|<\\epsilon$ below the threshold $\\epsilon$ that makes the largest connected graph component involve merely half of the elements, which in the matrix picture means that there is a permutation of the elements (rows and columns) rendering the matrix block-diagonal (middle right). Whereas it would take exponentially long to try all matrix permutations, graph connectivity can be determined in polynomial time, thus enabling us to rapidly find a good approximation for the ``cruelest cut'' bipartition.\n\\label{GraphsFig}\n}\n\\end{figure}\n\n\\subsection{An approximate solution}\n\nBeing able to compute $\\Phi$ approximately is clearly better than not being able to compute it at all. \nIn this spirit, let us explore an approximation that exponentially accelerates the computation of $\\Phi$.\nStarting with the linear dynamics ${\\bf x}_{i+1}={\\bf A}{\\bf x}+{\\bf n}$\nfrom {equation~(\\ref{{LinearEq2}})},\nlet us motivate our approximation by considering the case where the noise is ${\\bf n}$ uncorrelated (where ${\\mathbf\\Sigma}$ is diagonal) so that it introduces no correlations between the two systems, regardless of the cut. This means that the only source of integration can be the ${\\bf A}$-matrix transferring information between the two subsystems.\nLet us visualize this information flow as a directed graph ({Figure~\\ref{{GraphsFig}}}, bottom), where each node represents a variable \n$i$ and each edge represents a non-zero element $A_{ij}$, {\\frenchspacing\\it i.e.}, non-zero information flow from element $j$ to element $i$. \nIf this graph consists of two disconnected parts A and B of equal size, as in the lower right corner of {Figure~\\ref{{GraphsFig}}}, then we clearly have $\\Phi=0$, since there is no information flow and hence no integration between these two parts. In other words, if we permute the elements so that all elements of A precede all elements of B, the matrix ${\\bf A}$ becomes block-diagonal ({Figure~\\ref{{GraphsFig}}}, middle right), for which all integration measures in the right column of {Table~\\ref{{MeasureTable}}} will give $\\phi=0$.\n\nNote that before the elements were permuted ({Figure~\\ref{{GraphsFig}}}, top right), this fact that $\\phi=0$ was less obvious.\nMoreover, examining all $n!$ permutations (or all $\\left({n\\atop n/2}\\right)$ symmetric bipartitions) would have been an enormously inefficient way of finding that best bipartition for which $\\phi$ vanishes. In contrast, finding the connected components of a graph is quite simple, as is evident from staring at {Figure~\\ref{{GraphsFig}}}, with complexity between $O(n)$ and $O(n^2)$.\nThis means that if we know that $\\Phi=0$, then we can find the best bipartition (``cruelest cut\") easily, in polynomial time.\n\nLet us now define an approximation taking advantage of this idea: \n{\\it replace all unimportant elements $|A_{ij}|<\\epsilon$ by zero, and adjust $\\epsilon$ so that the largest connected component has size as close as possible to $n/2$.} \nLetting this largest connected component define our approximation of the best bipartition, we now compute its $\\phi$-value and use this as our approximation for $\\Phi$.\n\n\nNote that this approximation can be trivially generalized to asymmetric bipartitions.\nIn practice, we determine $\\epsilon$ by using the interval halving method. A final technical point is that we have two separate definitions of graph connectivity to choose between: weak and strong. A graph is {\\it strongly connected} if you can move between any pair of elements following the directional arrows on the edges. This means that every element can (at least through intermediaries) affect and be affected by every other element, precisely capturing the integration spirit of \\cite{tononi2008consciousness}. \nStrong connectivity is therefore the logical choice when using our approximation to compute\n $\\Phi^{2.0}$, $\\Phi^{2.0'}$, $\\Phi^{2.0''}$, since it will reflect their property that integration vanishes for afferent and efferent pathways.\n A graph is {\\it weakly connected} if you can move between any pair of elements ignoring edge arrows --- in other words, if it simply looks connected when drawn.\nUsing weak connectivity is arguably the better approximation for the $\\Phi$-measures that do not vanish for afferent/efferent pathways, and numerical experiments confirm this.\n \n\n\n\n\\begin{figure}[phbt]\n\\centerline{\\includegraphics[width=88mm]{approximation.pdf}}\n\\caption{How well our fast $\\Phi$-approximation works for 7,000 simulations of the n=16 $\\Phi^M$-example described in the text.\nWhereas it is seen to be excellent at finding the best bipartition when not all are comparably good,\n(\\protect{\\frenchspacing\\it i.e.}, when $\\Phi_{\\rm max}/\\Phi_{\\rm in}\\gg 1$),  the approximation is seen to overestimate $\\Phi$ by up to 15\\% (the median) when there is no clear winner (left side). From top to bottom, the three curves show the 95th, 50th and 5th percentiles of the overestimation factor. The shaded region delimits the largest overestimation possible, when $\\Phi_{\\rm appox}=\\Phi_{\\rm max}$.\n\\label{ApproximationFig}\n}\n\\end{figure}\n\n{Figure~\\ref{{ApproximationFig}}} illustrates the accuracy of our approximation.\nFor this example,  we randomly\\footnote{We generate ${\\bf A}$-matrices by first computing\n\n", "index": 103, "text": "\\begin{equation}\\label{{AsimulationEq}}\n{\\bf A}=\n\\eta{\\bf A}_0+\n\\left(\n\\begin{tabular}{cc}\n${\\bf A}_1$&$0$\\\\\n$0$&${\\bf A}_2$\n\\end{tabular}\n\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E52.m1\" class=\"ltx_Math\" alttext=\"{\\bf A}=\\eta{\\bf A}_{0}+\\left(\\begin{tabular}[]{cc}${\\bf A}_{1}$&amp;$0$\\\\&#10;$0$&amp;${\\bf A}_{2}$\\end{tabular}\\right),\" display=\"block\"><mrow><mrow><mi>\ud835\udc00</mi><mo>=</mo><mrow><mrow><mi>\u03b7</mi><mo>\u2062</mo><msub><mi>\ud835\udc00</mi><mn>0</mn></msub></mrow><mo>+</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mn>1</mn></msub></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi>\ud835\udc00</mi><msub><mi/><mn>2</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}]