[{"file": "1601.07258.tex", "nexttext": "\n\t\t where ${\\bf \\Sigma}_{w_d}$, commonly known as the scatter matrix, is equal to rank(${\\bf \\Sigma}_{w_d}$) $\\Gamma{((2+n-2)/2\\beta)}/\\Gamma{((2+n)/2\\beta)}$ times the covariance matrix of $w_d$, $\\beta \\in (0,1]$, and $K$ is a normalizing constant. For $\\beta = 1$, we obtain the probability distribution for the well-known multivariate Gaussian distribution. In the following we briefly provide a background regarding the multivariate generalized Gaussian distribution.\n\t\t \n\t\t \\par A linear transformation of the multivariate generalized Gaussian random vector is also a multivariate generalized Gaussian random vector.\n\t\t \\begin{proposition}\\cite{frahm2004generalized} \n\t\t \tLet $u$ be the a $n \\times 1$ multivariate generalized Gaussian random vector with mean $\\mu_u \\in \\mathbb{R}^n$, and scatter matrix, ${\\bf \\Sigma}_{u} \\in \\mathbb{R}^{n \\times n}$. Let $A$ be a $l \\times n$ full rank matrix. Then the $l \\times 1$ random vector, $v = Au$ has the multivariate generalized Gaussian distribution with mean $\\mu_v = A\\mu_u \\in \\mathbb{R}^l$, and scatter matrix, ${\\bf \\Sigma}_{v} = A{\\bf \\Sigma}_{u}A^T \\in \\mathbb{R}^{l \\times l}$. \t\n\t\t \\end{proposition}\n\t\t If $v$ is a univariate generalized Gaussian random variable, then the probability of $v$ falling in the range of $[\\delta-\\mu_v, \\delta+\\mu_v]$, for $\\delta \\geq 0$, can be found in terms of lower incomplete gamma function.\n\t\t \\begin{proposition}\n\t\t \tIf $v$ is a univariate generalized Gaussian random variable with mean $\\mu_v \\in \\mathbb{R}$ and scatter matrix, ${\\bf \\Sigma}_{v} \\in \\mathbb{R}$, then the probability of $v$ falling in the range of $[-\\delta+\\mu_v, \\delta+\\mu_v]$, for $\\delta \\geq 0$, is given by,\n\t\t \t\n", "itemtype": "equation", "pos": 14132, "prevtext": "\n\t\n\t\n\t\n\t\\title{Fast Integral Image Estimation at 1\\% measurement rate}\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\\author{Kuldeep~Kulkarni,\n\t\tPavan~Turaga\n\t\t\\IEEEcompsocitemizethanks{\\IEEEcompsocthanksitem K. Kulkarni and P. Turaga are with the School of Arts, Media and Engineering and School of Electrical, Computer and Energy Engineering, Arizona State University. Email: kkulkar1@asu.edu, pturaga@asu.edu.\\protect\\\\\n\t\t\t\n\t\t\t\n\t\t}\n\t\t\\thanks{}}\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\n\t\\IEEEcompsoctitleabstractindextext{\n\t\\begin{abstract}\n\t\tWe propose a framework called {\\bf ReFInE} to directly obtain integral image estimates from a very small number of spatially multiplexed measurements of the scene without iterative reconstruction of any auxiliary image, and demonstrate their practical utility in visual object tracking. Specifically, we design measurement matrices which are tailored to facilitate extremely fast estimation of the integral image, by using a single-shot linear operation on the measured vector. Leveraging a prior model for the images, we formulate a nuclear norm minimization problem with second order conic constraints to jointly obtain the measurement matrix and the linear operator. Through qualitative and quantitative experiments, we show that high quality integral image estimates can be obtained using our framework at very low measurement rates. Further, on a standard dataset of 50 videos, we present object tracking results which are comparable to the state-of-the-art methods, even at an extremely low measurement rate of 1\\%.\n\t\\end{abstract}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\\begin{keywords}\n\t\t\tSpatial-multiplexing cameras, Nuclear-norm minimization, Low sensing rates, Tracking, Integral Images \n\t\t\\end{keywords}}\n\t\t\n\t\t\n\t\t\n\t\t\\maketitle\n\t\t\n\t\t\n\t\t\n\t\t\\IEEEdisplaynotcompsoctitleabstractindextext\n\t\t\n\t\t\\IEEEpeerreviewmaketitle\n\t\n\t\t\\section{Introduction}\n\t\tIn this paper, we study the problem of obtaining integral image estimates from emerging flexible programmable imaging devices. These novel imaging devices, often considered under the broad umbrella of spatial-multiplexing cameras (SMCs)\\cite{nayar2006programmable,SPC,sankaranarayanan2012cs} provide a number of benefits in reducing the amount of sensing for portable and resource constrained acquisition. The imaging architectures in these cameras employ spatial light modulators like digital micromirror arrays to optically compute projections of the scene. Mathematically, the projections are given by $y = \\phi x$, where $x \\in \\mathbb{R}^n$ is the image, $y \\in \\mathbb{R}^m$, known as the measurement vector, denotes the set of sensed projections and $\\phi \\in \\mathbb{R}^{m \\times n}$ is called measurement matrix defined by the set of multiplexing patterns. The nature of  the acquisition framework enables us to deploy SMCs in resource constrained settings, wherein one can employ $m << n$ number of photon detectors to sense otherwise high-resolution imagery \\cite{SPC,CSLDS} and obtain a very small number of measurements. Later, a reconstruction algorithm is used to recover the image $x$. However, reconstructing $x$ from $y$ when $m < n$ is an ill-posed problem. Researchers in the past have attempted to provide solutions by carefully designing the measurement matrix $\\phi$ in the hope of easier recovery of $x$ from $y$. Recent compressive sensing (CS) theory provides one possible solution to tackle the above mentioned ill-posed problem. According to CS theory, a signal can be recovered perfectly from a small number of $m$ $=$ $\\mathcal{O}$($s$ log($\\frac{n}{s}$)) such pseudo-random (PR) multiplexed measurements, where $s$ is the sparsity of the signal. However, a significant research shows that high-quality reconstruction is computationally intensive \\cite{donoho2006compressed,candes2006near,tropp2007signal,needell2009cosamp}. Hence, despite the promise of CS-based SMCs \\cite{SPC,sankaranarayanan2012cs}, the computational bottleneck of non-linear, iterative reconstruction has withheld their wide-spread adoption in applications which require fast inference of objects, actions, and scenes. This has led to researchers exploring the option of tackling inference problems directly from these pseudo-random multiplexed measurements \\cite{CSLDS,EPFL,Rectex,Davenport1,CLearning,kulkarni2015reconstruction,lohit2015reconstruction} (more on these later in the section in related work). However, the `universal' nature of such measurements has made it challenging to devise new or adopt existing computer vision algorithms to solve the inference problem at hand.\n\t\t\\noindent\n\t\t\\par \n\t\tThe need to acquire as less data as possible combined with the limitations of pseudo-random multiplexers props us to outline the following goal. The goal of this paper is to propose a novel sensing framework for SMCs such that acquired measurements satisfy the following properties. 1) The measurements are not random in nature but are tailored for a particular application. 2) The number of measurements is 2 orders less than the number of pixels, so that SMCs based on our framework can be employed in resource constrained applications. 3) A simple linear operation on the measurement vector $y$ yields a `proxy' representation (e.g integral images, gradient images) from which the required features are extracted for the application in hand, thus avoiding the computationally expensive iterative and non-linear reconstruction.\n\t\t\\noindent\n\t\t\\par\n\t\tIn this paper, we focus on one such `proxy' representation, integral images. Integral images are extremely attractive representation since Haar-like features and box-filtered image outputs can be computed from integral images with a small and fixed number of  floating point operations in constant time \\cite{viola2004robust}. These advantages have led to their widespread use in real time applications like face detection \\cite{viola2004robust}, pedestrian detection \\cite{dollar2010fastest}, object tracking \\cite{grabner2006real,zhang2012real,babenko2011robust,kalal2010pn} and  object segmentation \\cite{ramakanth2013seamseg}. \n\t\t\n\t\t\\noindent\n\t\t\\par\n\t\tInstead of setting a fixed number of measurements, we formulate an optimization problem to minimize the number of measurements while incorporating the other two (1 and 3) properties of measurements (as mentioned above) in the constraints. Minimizing the number of measurements is akin to minimizing the rank of the measurement matrix. In more concrete terms, the problem is posed to jointly minimize the rank of the measurement matrix, $\\phi$ and learn the linear operator, $\\mathcal{L}$ which when applied on the measurement vector yields the approximate integral image, with the probabilistic constraint that the error between the approximate integral image and the exact integral image is within allowable limits with high probability. By controlling the allowable error limit, we can obtain measurement matrix of the desired rank. Incorporating a wavelet domain prior model for natural images combined with a relaxation (explained in section 2) allows us to convert the probabilistic constraint into a series of second conic constraints. Rank minimization is a NP-hard problem. Relaxing the objective function to nuclear norm allows to use off-the-shelf convex optimization tools to solve the problem and obtain the measurement matrix and the linear operator.\n\t    \n\t    \\noindent\n\t\t\\par{{\\bf Contributions:}}\n\t\t\\textbf{1)}  The main contribution of the paper is a novel framework to recover estimates of integral images from a small number of spatially multiplexed measurements without iterative reconstruction of any auxillary image. We dub the framework {\\bf ReFInE} (Reconstruction-Free Integral Image Estimation). \\textbf{2)} Leveraging the MGGD (multivariate generalized Gaussian distribution) prior model for the vector of detailed wavelet coefficients of natural images, we propose a nuclear norm minimization formulation to obtain a new specialized measurement matrix. We term the measurements acquired with such a measurement matrix, as {\\bf ReFInE} measurements. \\textbf{3)} On a large dataset of 4952 images, we present qualitative and  quantitative results to show that high quality estimates of integral images and box-filtered outputs can be recovered from  {\\bf ReFInE} measurements in real-time. \\textbf{4)}  We show object tracking results, which are comparable to state-of-the-art methods, on a challenging dataset of 50 videos to demonstrate the utility of the box-filtered output estimates in tackling inference problems from SMCs at 1\\% measurement rate.\n\t    \n\t    \\noindent\n\t\t\\par{{\\bf Related Work:}}\n\t\tThe related previous works in literature follow one of the two themes. Some attempt to tackle inference problems directly from PR measurements without optimizing for the measurement matrix for the inference task at hand, some others attempt to optimize measurement matrix for a particular signal model so as to minimize reconstruction error.\n\t\n\t\t\\par\n\t\t\\textbf{a) Design of measurement matrix:} \n\t\tA closely related work can be found in \\cite{duarte2009learning}, wherein a framework is proposed to jointly optimize for a measurement matrix and an overcomplete sparsifying dictionary for small patches of images. Results suggest that better reconstruction results can be obtained using this strategy. However, learning global dictionaries for entire images is not possible, and hence the framework is not scalable. Goldstein {\\textit{et al.}} \\cite{goldstein2013stone} designed measurement matrices called `STOne' Transform which facilitate fast low resolution `previews' just by direct reconstruction, and the hope is that `previews' are of high enough quality so that conventional methods for inference tasks can be applied. Assuming a multi-resolutional signal model for natural images, Chang {\\textit{et al.}} \\cite{chang2009informative} proposed an algorithm to obtain measurements which have the maximum mutual information with natural images. \n\t\t\\noindent\n\t\t\\par\n\t\t\\textbf{b) Inference problems from CS videos:} A LDS (Linear Dynamical System) based approach was proposed by Sankaranarayanan {\\textit{et al.}} \\cite{CSLDS} to model CS videos and recover the LDS parameters directly from PR measurements. However, the method is sensitive to spatial and view transforms. Calderbank {\\textit{et al.}} \\cite{CLearning} theoretically proved that one can learn classifiers directly from PR measurements, and that with high probability the performance of the linear kernel support vector machine (SVM) classifier operating on the CS measurements is similar to that of the the best linear threshold classifier operating on the original data. A reconstruction-free framework was proposed by Thirumalai {\\textit{et al.}} \\cite{EPFL} to compute optical flow based on correlation estimation between two images, directly from PR measurements. Davenport {\\textit{et al.}} \\cite{Davenport} proposed a measurement domain based correlation filter approach for target classification. Here, the trained filters are first projected onto PR patterns to obtain `smashed filters', and then the PR measurements of the test examples are correlated with these smashed filters. Recently, Kulkarni {\\textit{et al.}} \\cite{kulkarni2015reconstruction} and Lohit {\\textit{et al.}} \\cite{lohit2015reconstruction} extended the `smashed filter' approach to action recognition and face recognition respectively, and demonstrated the feasibility and scalability of tackling difficult inference tasks in computer vision directly from PR measurements.\n\t\t  \n\t\t\\section{Background}\n        \\noindent\n\t\tIn this section, we provide a brief background on the probability model for natural images, which we rely on in the paper, and introduce notations required to set up the optimization problem to derive measurement matrix and above referred linear operator.\n\t\t \\noindent\n\t\t \\par{{\\bf Probability Model of natural images:}}\n\t\t There is a rich body of literature which deals with statistical modeling of natural images. We refer to some works which are related to the probability model we use in the paper. Many successful probability models for wavelet coefficients fall under the broad umbrella of Gaussian scale mixtures (GSM) \\cite{andrews1974scale}, \\cite{wainwright1999scale}. Typically the coefficient space is partitioned into overlapping blocks, and each block is modeled independently as a GSM, which captures the local dependencies. This implicitly gives rise to a global model of the wavelet coefficients. Building on this framework, Lyu {\\textit{et al.}} \\cite{lyu2009modeling} proposed a field of Gaussian scale mixtures (FoGSM) to explicitly model the subbands of wavelet coefficients, while treating each subband independently. However, incorporating such a general model for wavelet coefficient vector makes it very difficult to compute the distribution for even simple functions like a linear function of the wavelet coefficient vector. Therefore, it is vital to assume a prior model which can lead to tractable computation of the distribution. It is well-known that marginal distributions of detailed wavelet coefficients follow generalized Gaussian distribution \\cite{mallat1989theory}. We extend this notion to multi-dimensions and model the vector of detailed wavelet coefficients by multivariate generalized Gaussian distribution (MGGD).\n\t\t \\noindent\n\t\t \\par\n\t\t To put it formally, let ${\\bf U}^{T} \\in \\mathbb{R}^{n \\times n}$ be the orthogonal matrix representing the $\\log_2(n)$ level wavelet transform, so that $x = {\\bf U}w$, where $w \\in \\mathbb{R}^n$ is the corresponding wavelet coefficient vector. Without loss of generality, we assume that all entries in the first row of ${\\bf U}^{T}$ are $1/\\sqrt{n}$ so that the first entry in $w$ corresponds to $\\sqrt{n}$ times the mean of all entries in $x$. Also we denote the rest $n-1$ rows in ${\\bf U}^{T}$ by ${\\bf U}_{2:n}^{T}$. Now we can write $w = [\\sqrt{n}\\bar{x}, w_d]$, where $\\bar{x}$ is the mean of $x$ and $w_d$ is the vector of detailed coefficients. As explained above, the probability distribution of $w_d$ (MGGD) is given by \n\t\t \n", "index": 1, "text": "\\begin{equation}\n\t\t \\label{MGGD}\n\t\t f(w) = K|{\\bf \\Sigma}_{w_d}|^{-0.5}exp(-(w_d^{T}{\\bf \\Sigma}_{w_d}^{-1} w_d)^\\beta),\n\t\t \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"f(w)=K|{\\bf\\Sigma}_{w_{d}}|^{-0.5}exp(-(w_{d}^{T}{\\bf\\Sigma}_{w_{d}}^{-1}w_{d}%&#10;)^{\\beta}),\" display=\"block\"><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>K</mi><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udeba</mi><msub><mi>w</mi><mi>d</mi></msub></msub><mo stretchy=\"false\">|</mo></mrow><mrow><mo>-</mo><mn>0.5</mn></mrow></msup><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>w</mi><mi>d</mi><mi>T</mi></msubsup><mo>\u2062</mo><msubsup><mi>\ud835\udeba</mi><msub><mi>w</mi><mi>d</mi></msub><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi>w</mi><mi>d</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mi>\u03b2</mi></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \n\t\t \\end{proposition} \n\t\t where $\\gamma(.,.)$ is the lower incomplete gamma function, and $\\Gamma(.)$ is the ordinary gamma function.\n\t\t\n\t\t\n        \\noindent\t\n\t\t\\par{{\\bf Preliminaries:}}\n\t\tLet ${\\bf H} \\in \\mathbb{R}^{n \\times n}$  be the block Toeplitz matrix representing the integral operation so that the integral image, $I = {\\bf H}x  \\in \\mathbb{R}^{n}$, and $h_i^{T}$ for $i = 1,..,n$ be the rows of ${\\bf H}$. Hence, $I_i$ equals $h_i^{T}x$. We wish to recover the approximate integral image, $\\hat{I}$ from the measured vector $y = \\phi x$, just by applying a linear operator $\\mathcal{L}$ on $y$, so that $\\hat{I} = \\mathcal{L}y$. For reasons which will be apparent soon, we assume $\\mathcal{L} = {\\bf H}(\\phi^d)^{T}$, where $\\phi^d \\in \\mathbb{R}^{m \\times n} $ such that rank$(\\phi^d)$ = rank$(\\phi)$. We call $\\phi^d$ as the dual of $\\phi$. Thus by construction $\\mathcal{L} \\in \\mathbb{R}^{n \\times m}$. The value at location $i$ in the approximate integral image is given by $\\hat{I}_i = h_i^{T}(\\phi^d)^{T}\\phi x$. The distortion in integral image at location $i$ is given by $d_i = \\hat{I}_i - I_i = h_i^{T}((\\phi^d)^{T}\\phi x - x)$. Noting ${\\bf Q} = (\\phi^d)^{T}\\phi$, and $n \\times n$ identity matrix by ${\\bf I}$, the distortions can be compactly written as $d_i = h_i^{T}({\\bf Q}-{\\bf I})x$. We call ${\\bf d} = [d_1,...,d_n]$ as distortion vector. \n\t    \n\t    \n\t\t\\section{Optimization problem}\n\t\tOur aim is to search for a measurement matrix $\\phi$ of minimum rank such that distortions, $d_i$ are within allowable limits for all $i$, jointly, with high probability. ${\\bf Q}$ by construction is the product of two matrices of identical ranks, $\\phi$ and $(\\phi^d)^T$. Hence, we have the relation, rank(${\\bf Q}$) = rank($\\phi$). Inspired by the phase-lifting technique used in \\cite{candes2013phaselift} and \\cite{hegdenumax}, instead of minimizing the rank of $\\phi$, we minimize the rank of ${\\bf Q}$. Now, we can formally state the optimization problem as follows.\n\n\t\t\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\t\t where ${\\bf \\Sigma}_{w_d}$, commonly known as the scatter matrix, is equal to rank(${\\bf \\Sigma}_{w_d}$) $\\Gamma{((2+n-2)/2\\beta)}/\\Gamma{((2+n)/2\\beta)}$ times the covariance matrix of $w_d$, $\\beta \\in (0,1]$, and $K$ is a normalizing constant. For $\\beta = 1$, we obtain the probability distribution for the well-known multivariate Gaussian distribution. In the following we briefly provide a background regarding the multivariate generalized Gaussian distribution.\n\t\t \n\t\t \\par A linear transformation of the multivariate generalized Gaussian random vector is also a multivariate generalized Gaussian random vector.\n\t\t \\begin{proposition}\\cite{frahm2004generalized} \n\t\t \tLet $u$ be the a $n \\times 1$ multivariate generalized Gaussian random vector with mean $\\mu_u \\in \\mathbb{R}^n$, and scatter matrix, ${\\bf \\Sigma}_{u} \\in \\mathbb{R}^{n \\times n}$. Let $A$ be a $l \\times n$ full rank matrix. Then the $l \\times 1$ random vector, $v = Au$ has the multivariate generalized Gaussian distribution with mean $\\mu_v = A\\mu_u \\in \\mathbb{R}^l$, and scatter matrix, ${\\bf \\Sigma}_{v} = A{\\bf \\Sigma}_{u}A^T \\in \\mathbb{R}^{l \\times l}$. \t\n\t\t \\end{proposition}\n\t\t If $v$ is a univariate generalized Gaussian random variable, then the probability of $v$ falling in the range of $[\\delta-\\mu_v, \\delta+\\mu_v]$, for $\\delta \\geq 0$, can be found in terms of lower incomplete gamma function.\n\t\t \\begin{proposition}\n\t\t \tIf $v$ is a univariate generalized Gaussian random variable with mean $\\mu_v \\in \\mathbb{R}$ and scatter matrix, ${\\bf \\Sigma}_{v} \\in \\mathbb{R}$, then the probability of $v$ falling in the range of $[-\\delta+\\mu_v, \\delta+\\mu_v]$, for $\\delta \\geq 0$, is given by,\n\t\t \t\n", "index": 3, "text": "\\begin{equation}\n\t\t \t\\mathbb{P}(|v - \\mu_v| \\leq \\delta) = 2\\gamma\\left(\\frac{1}{2\\beta}, \\left(\\frac{\\delta}{{\\bf \\Sigma}_{v}} \\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}} \\right)^{2\\beta} \\right),\n\t\t \t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{P}(|v-\\mu_{v}|\\leq\\delta)=2\\gamma\\left(\\frac{1}{2\\beta},\\left(\\frac{%&#10;\\delta}{{\\bf\\Sigma}_{v}}\\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{%&#10;2\\beta})}}\\right)^{2\\beta}\\right),\" display=\"block\"><mrow><mi>\u2119</mi><mrow><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">|</mo><mi>v</mi><mo>-</mo><msub><mi>\u03bc</mi><mi>v</mi></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><mi>\u03b4</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mn>2</mn><mi>\u03b3</mi><mrow><mo>(</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></mfrac><mo>,</mo><msup><mrow><mo>(</mo><mfrac><mi>\u03b4</mi><msub><mi>\ud835\udeba</mi><mi>v</mi></msub></mfrac><msqrt><mfrac><mrow><mi mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mfrac><mn>3</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></msqrt><mo>)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></msup><mo>)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\n\t\twhere $\\delta_i \\ge 0$ denotes the allowable limit of distortion at  location $i$ of integral image, and $0 < \\epsilon < 1$. Once ${\\bf Q}^{*}$ is found, we show later in the section that the SVD decomposition of ${\\bf Q}^{*}$ allows us to write ${\\bf Q}^{*}$ as a product of two matrices of identical ranks, thus yielding both the measurement matrix, $\\phi^{*}$ and the desired linear operator, $\\mathcal{L}^{*}$. The constraint in (\\ref{opti2}) is a probabilistic one. Hence to compute it, one needs to assume a statistical prior model for $x$. Using the model in \\ref{MGGD}, and its properties given in proposition (1) and (2), we arrive at a solvable optimization problem.    \n\t    \n\t   \n\t    \\noindent\n\t\t\\par{{\\bf Computation of probabilistic constraint in (\\ref{opti2}):}}\n\t\tSubstituting for $x$, we can write the distortion at location $i$ as $d_i = h_i^{T}({\\bf Q}-{\\bf I}){\\bf U}w$. We let all the entries in the first row of $\\phi$ and $\\phi^d$ to be equal to $1/\\sqrt{n}$, so that one of the $m$  measurements is exactly equal to $\\sqrt{n}\\bar{x}$. Further, we denote the rest $m-1$ rows of the two matrices by $\\phi_{2:m}$ and $\\phi^d_{2:m}$. Now, if we restrict $\\phi_{2:m}$ and $\\phi^{d}_{2:m}$ to be respectively equal to ${\\bf C} {\\bf U}_{2:n}^{T}$ and  ${\\bf D} {\\bf U}_{2:n}^{T}$ for some ${\\bf C}$, ${\\bf D}$ in $\\mathbb{R}^{m-1 \\times n-1}$, then from basic linear algebra we can show that $d_i = h_i^{T}({\\bf P}-{\\bf I}){\\bf U}_{2:n}^{T}w_d$,\n\t\twhere ${\\bf P} = (\\phi^d_{2:m})^T\\phi_{2:m}$. It is easy to see that ${\\bf Q} = {\\bf P} + \\frac{1}{n}{\\bf O}$, and rank(${\\bf Q}$) = rank(${\\bf P}$) + 1, where ${\\bf O}$ is the matrix with all its entries equal to unity (see Appendix A for details). Hence we can replace the objective function in (\\ref{opti2}) by rank($\\bf P$). Rank minimization is a non-convex problem. Hence we relax the objective function to nuclear norm, as is done typically. To compute the constraint in (\\ref{opti2}), one needs to first compute the joint probability of ${\\bf d} = [d_1,..,d_n]$, and then compute a $n$ dimensional definite integral. Now that $d_i$'s are linear combinations of $w_d$, it follows from proposition 1, that ${\\bf d}$ also has a multivariate generalized Gaussian distribution. However, no closed form for the definite integral is known. Hence, we relax the constraint by decoupling it into $n$ independent constraints, each enforcing the constraint that the distortion at a specific location is to be within allowable limits with high probability, independent of the distortions at other locations. The optimization with relaxed constraints is thus given by \n\t\n\t\t\n", "itemtype": "equation", "pos": 18192, "prevtext": " \n\t\t \\end{proposition} \n\t\t where $\\gamma(.,.)$ is the lower incomplete gamma function, and $\\Gamma(.)$ is the ordinary gamma function.\n\t\t\n\t\t\n        \\noindent\t\n\t\t\\par{{\\bf Preliminaries:}}\n\t\tLet ${\\bf H} \\in \\mathbb{R}^{n \\times n}$  be the block Toeplitz matrix representing the integral operation so that the integral image, $I = {\\bf H}x  \\in \\mathbb{R}^{n}$, and $h_i^{T}$ for $i = 1,..,n$ be the rows of ${\\bf H}$. Hence, $I_i$ equals $h_i^{T}x$. We wish to recover the approximate integral image, $\\hat{I}$ from the measured vector $y = \\phi x$, just by applying a linear operator $\\mathcal{L}$ on $y$, so that $\\hat{I} = \\mathcal{L}y$. For reasons which will be apparent soon, we assume $\\mathcal{L} = {\\bf H}(\\phi^d)^{T}$, where $\\phi^d \\in \\mathbb{R}^{m \\times n} $ such that rank$(\\phi^d)$ = rank$(\\phi)$. We call $\\phi^d$ as the dual of $\\phi$. Thus by construction $\\mathcal{L} \\in \\mathbb{R}^{n \\times m}$. The value at location $i$ in the approximate integral image is given by $\\hat{I}_i = h_i^{T}(\\phi^d)^{T}\\phi x$. The distortion in integral image at location $i$ is given by $d_i = \\hat{I}_i - I_i = h_i^{T}((\\phi^d)^{T}\\phi x - x)$. Noting ${\\bf Q} = (\\phi^d)^{T}\\phi$, and $n \\times n$ identity matrix by ${\\bf I}$, the distortions can be compactly written as $d_i = h_i^{T}({\\bf Q}-{\\bf I})x$. We call ${\\bf d} = [d_1,...,d_n]$ as distortion vector. \n\t    \n\t    \n\t\t\\section{Optimization problem}\n\t\tOur aim is to search for a measurement matrix $\\phi$ of minimum rank such that distortions, $d_i$ are within allowable limits for all $i$, jointly, with high probability. ${\\bf Q}$ by construction is the product of two matrices of identical ranks, $\\phi$ and $(\\phi^d)^T$. Hence, we have the relation, rank(${\\bf Q}$) = rank($\\phi$). Inspired by the phase-lifting technique used in \\cite{candes2013phaselift} and \\cite{hegdenumax}, instead of minimizing the rank of $\\phi$, we minimize the rank of ${\\bf Q}$. Now, we can formally state the optimization problem as follows.\n\n\t\t\n", "index": 5, "text": "\\begin{equation}\\label{opti2}\n\t\t\\begin{split}\n\t\t\\underset{{\\bf Q}}{\\text{minimize}} \\quad \\mathrm{rank}({\\bf Q}) \\quad \\quad \\quad \\quad \\quad \\\\\n\t\t\\text{s.t} \\quad \\mathbb{P} (|d_1| \\le \\delta_1,..,|d_i| \\leq \\delta_i.., |d_n| \\leq \\delta_n ) \\geq 1-\\epsilon,\n\t\t\\end{split}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\underset{{\\bf Q}}{\\text{minimize}}\\quad\\mathrm{rank%&#10;}({\\bf Q})\\\\&#10;\\displaystyle\\text{s.t}\\quad\\mathbb{P}(|d_{1}|\\leq\\delta_{1},..,|d_{i}|\\leq%&#10;\\delta_{i}..,|d_{n}|\\leq\\delta_{n})\\geq 1-\\epsilon,\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc10</mo></munder><mo separator=\"true\">\u2003</mo><mrow><mi>rank</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc10</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mtext>s.t</mtext><mo separator=\"true\">\u2003</mo><mi>\u2119</mi><mrow><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">|</mo><msub><mi>d</mi><mn>1</mn></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msub><mi>\u03b4</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mo stretchy=\"false\">|</mo><msub><mi>d</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msub><mi>\u03b4</mi><mi>i</mi></msub><mo>.</mo><mo>.</mo><mo>,</mo><mo stretchy=\"false\">|</mo><msub><mi>d</mi><mi>n</mi></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msub><mi>\u03b4</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2265</mo><mn>1</mn><mo>-</mo><mi>\u03f5</mi><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \n\t\tNow, $d_i = h_i^{T}({\\bf P}-{\\bf I}){\\bf U}_{2:n}^{T}w_d$, is a linear combination of the entries of $w_d$. From the proposition 2, $d_i$ has a one-dimensional generalized Gaussian distribution with zero mean and scatter parameter, $\\left\\lVert{{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T  ({\\bf P}-{\\bf I})^T h_i}\\right\\rVert$, and the probability in equation \\ref{opti3} can be explicitly written as follows.\n\t\t\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\t\twhere $\\delta_i \\ge 0$ denotes the allowable limit of distortion at  location $i$ of integral image, and $0 < \\epsilon < 1$. Once ${\\bf Q}^{*}$ is found, we show later in the section that the SVD decomposition of ${\\bf Q}^{*}$ allows us to write ${\\bf Q}^{*}$ as a product of two matrices of identical ranks, thus yielding both the measurement matrix, $\\phi^{*}$ and the desired linear operator, $\\mathcal{L}^{*}$. The constraint in (\\ref{opti2}) is a probabilistic one. Hence to compute it, one needs to assume a statistical prior model for $x$. Using the model in \\ref{MGGD}, and its properties given in proposition (1) and (2), we arrive at a solvable optimization problem.    \n\t    \n\t   \n\t    \\noindent\n\t\t\\par{{\\bf Computation of probabilistic constraint in (\\ref{opti2}):}}\n\t\tSubstituting for $x$, we can write the distortion at location $i$ as $d_i = h_i^{T}({\\bf Q}-{\\bf I}){\\bf U}w$. We let all the entries in the first row of $\\phi$ and $\\phi^d$ to be equal to $1/\\sqrt{n}$, so that one of the $m$  measurements is exactly equal to $\\sqrt{n}\\bar{x}$. Further, we denote the rest $m-1$ rows of the two matrices by $\\phi_{2:m}$ and $\\phi^d_{2:m}$. Now, if we restrict $\\phi_{2:m}$ and $\\phi^{d}_{2:m}$ to be respectively equal to ${\\bf C} {\\bf U}_{2:n}^{T}$ and  ${\\bf D} {\\bf U}_{2:n}^{T}$ for some ${\\bf C}$, ${\\bf D}$ in $\\mathbb{R}^{m-1 \\times n-1}$, then from basic linear algebra we can show that $d_i = h_i^{T}({\\bf P}-{\\bf I}){\\bf U}_{2:n}^{T}w_d$,\n\t\twhere ${\\bf P} = (\\phi^d_{2:m})^T\\phi_{2:m}$. It is easy to see that ${\\bf Q} = {\\bf P} + \\frac{1}{n}{\\bf O}$, and rank(${\\bf Q}$) = rank(${\\bf P}$) + 1, where ${\\bf O}$ is the matrix with all its entries equal to unity (see Appendix A for details). Hence we can replace the objective function in (\\ref{opti2}) by rank($\\bf P$). Rank minimization is a non-convex problem. Hence we relax the objective function to nuclear norm, as is done typically. To compute the constraint in (\\ref{opti2}), one needs to first compute the joint probability of ${\\bf d} = [d_1,..,d_n]$, and then compute a $n$ dimensional definite integral. Now that $d_i$'s are linear combinations of $w_d$, it follows from proposition 1, that ${\\bf d}$ also has a multivariate generalized Gaussian distribution. However, no closed form for the definite integral is known. Hence, we relax the constraint by decoupling it into $n$ independent constraints, each enforcing the constraint that the distortion at a specific location is to be within allowable limits with high probability, independent of the distortions at other locations. The optimization with relaxed constraints is thus given by \n\t\n\t\t\n", "index": 7, "text": "\\begin{equation}\\label{opti3}\n\t\t\\begin{split}\n\t\t\\underset{{\\bf P}}{\\text{minimize}} \\quad\n\t\t\\left\\lVert{\\bf{P}}\\right\\rVert_* \\quad \\quad \\quad \\quad \\\\\n\t\t\\text{s.t} \\quad\n\t\t\\mathbb{P} (|d_i| \\le \\delta_i) \\geq 1-\\epsilon, \\quad  i = 1,..,n.\n\t\t\\end{split}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\underset{{\\bf P}}{\\text{minimize}}\\quad\\left\\lVert{%&#10;\\bf{P}}\\right\\rVert_{*}\\\\&#10;\\displaystyle\\text{s.t}\\quad\\mathbb{P}(|d_{i}|\\leq\\delta_{i})\\geq 1-\\epsilon,%&#10;\\quad i=1,..,n.\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo mathsize=\"70%\" separator=\"true\" stretchy=\"false\">\u2003</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mtext>s.t</mtext><mo separator=\"true\">\u2003</mo><mi>\u2119</mi><mrow><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">|</mo><msub><mi>d</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo><mo>\u2264</mo><msub><mi>\u03b4</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2265</mo><mn>1</mn><mo>-</mo><mi>\u03f5</mi><mo rspace=\"12.5pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\n\tThe optimization problem now can be rewritten as \n\t\t\n", "itemtype": "equation", "pos": 21804, "prevtext": " \n\t\tNow, $d_i = h_i^{T}({\\bf P}-{\\bf I}){\\bf U}_{2:n}^{T}w_d$, is a linear combination of the entries of $w_d$. From the proposition 2, $d_i$ has a one-dimensional generalized Gaussian distribution with zero mean and scatter parameter, $\\left\\lVert{{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T  ({\\bf P}-{\\bf I})^T h_i}\\right\\rVert$, and the probability in equation \\ref{opti3} can be explicitly written as follows.\n\t\t\n", "index": 9, "text": "\\begin{equation}\\label{probconst}\n\t\t\\scriptsize{\\begin{split}\n\t\t\t\\mathbb{P} (|d_i| \\le \\delta_i) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\\\\n\t\t\t= 2 \\gamma \\left(\\frac{1}{2\\beta},\\left(\\frac{\\delta_i}{\\left\\lVert{{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T{\\bf P}^T h_i-{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T h_i}\\right\\rVert_2}\\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}} \\right)^{2\\beta}\\right).\n\t\t\t\\end{split}}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\scriptsize{\\begin{split}\\displaystyle\\mathbb{P}(|d_{i}|\\leq\\delta_{i})\\\\&#10;\\displaystyle=2\\gamma\\left(\\frac{1}{2\\beta},\\left(\\frac{\\delta_{i}}{\\left%&#10;\\lVert{{\\bf\\Sigma}^{1/2}_{w_{d}}{\\bf U}_{2:n}^{T}{\\bf P}^{T}h_{i}-{\\bf\\Sigma}^%&#10;{1/2}_{w_{d}}{\\bf U}_{2:n}^{T}h_{i}}\\right\\rVert_{2}}\\sqrt{\\frac{\\Gamma(\\frac{%&#10;3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}}\\right)^{2\\beta}\\right).\\end{split}}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mi mathsize=\"70%\">\u2119</mi><mrow><mo maxsize=\"70%\" minsize=\"70%\">(</mo><mo maxsize=\"70%\" minsize=\"70%\">|</mo><msub><mi mathsize=\"70%\">d</mi><mi mathsize=\"70%\">i</mi></msub><mo maxsize=\"70%\" minsize=\"70%\">|</mo><mo mathsize=\"70%\" stretchy=\"false\">\u2264</mo><msub><mi mathsize=\"70%\">\u03b4</mi><mi mathsize=\"70%\">i</mi></msub><mo maxsize=\"70%\" minsize=\"70%\">)</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo mathsize=\"70%\" stretchy=\"false\">=</mo><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b3</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mn mathsize=\"70%\">1</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac><mo mathsize=\"70%\" stretchy=\"false\">,</mo><msup><mrow><mo>(</mo><mrow><mfrac><msub><mi mathsize=\"70%\">\u03b4</mi><mi mathsize=\"70%\">i</mi></msub><msub><mrow><mo fence=\"true\">\u2225</mo><mrow><mrow><msubsup><mi mathsize=\"70%\">\ud835\udeba</mi><msub><mi mathsize=\"70%\">w</mi><mi mathsize=\"70%\">d</mi></msub><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">/</mo><mn mathsize=\"70%\">2</mn></mrow></msubsup><mo>\u2062</mo><msubsup><mi mathsize=\"70%\">\ud835\udc14</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">:</mo><mi mathsize=\"70%\">n</mi></mrow><mi mathsize=\"70%\">T</mi></msubsup><mo>\u2062</mo><msup><mi mathsize=\"70%\">\ud835\udc0f</mi><mi mathsize=\"70%\">T</mi></msup><mo>\u2062</mo><msub><mi mathsize=\"70%\">h</mi><mi mathsize=\"70%\">i</mi></msub></mrow><mo mathsize=\"70%\" stretchy=\"false\">-</mo><mrow><msubsup><mi mathsize=\"70%\">\ud835\udeba</mi><msub><mi mathsize=\"70%\">w</mi><mi mathsize=\"70%\">d</mi></msub><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">/</mo><mn mathsize=\"70%\">2</mn></mrow></msubsup><mo>\u2062</mo><msubsup><mi mathsize=\"70%\">\ud835\udc14</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">:</mo><mi mathsize=\"70%\">n</mi></mrow><mi mathsize=\"70%\">T</mi></msubsup><mo>\u2062</mo><msub><mi mathsize=\"70%\">h</mi><mi mathsize=\"70%\">i</mi></msub></mrow></mrow><mo fence=\"true\">\u2225</mo></mrow><mn mathsize=\"70%\">2</mn></msub></mfrac><mo>\u2062</mo><msqrt><mfrac><mrow><mi mathsize=\"70%\" mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo maxsize=\"70%\" minsize=\"70%\">(</mo><mfrac><mn mathsize=\"70%\">3</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac><mo maxsize=\"70%\" minsize=\"70%\">)</mo></mrow></mrow><mrow><mi mathsize=\"70%\" mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo maxsize=\"70%\" minsize=\"70%\">(</mo><mfrac><mn mathsize=\"70%\">1</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac><mo maxsize=\"70%\" minsize=\"70%\">)</mo></mrow></mrow></mfrac></msqrt></mrow><mo>)</mo></mrow><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></msup><mo>)</mo></mrow></mrow></mrow><mo mathsize=\"70%\" stretchy=\"false\">.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " We compactly write ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T{\\bf P}^T h_i$ as $\\mathcal{A}_i({\\bf P})$, ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T h_i$ as $b_i$  and $\\frac{\\delta_i}{(\\gamma^{-1}(\\frac{1}{2\\beta},\\frac{1-\\epsilon}{2}))^{\\frac{1}{2\\beta}}} \\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}}$ as $\\Delta_i$. Plugging above in equation (\\ref{probconst}), and rearranging terms, we have \n\t\t\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\tThe optimization problem now can be rewritten as \n\t\t\n", "index": 11, "text": "\\begin{align*}\\label{opti4_con}\n\t\\underset{{\\bf P}}{\\text{minimize}}\n\t\t\t\\left\\lVert{\\bf{P}}\\right\\rVert_* \\quad   \\quad \\text{s.t}  \\quad \\quad \\quad \\quad \\quad \\quad \\quad \n\t\t\t\\\\\n\t\t{\\scriptsize 2 \\gamma \\left(\\frac{1}{2\\beta},\\left(\\frac{\\delta_i}{\\left\\lVert{{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T{\\bf P}^T h_i-{\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T h_i}\\right\\rVert_2}\\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}} \\right)^{2\\beta}\\right)} \\\\ \\geq 1-\\epsilon  \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad.\n\t    \\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\underset{{\\bf P}}{\\text{minimize}}\\left\\lVert{\\bf{P}}\\right%&#10;\\rVert_{*}\\quad\\quad\\text{s.t}\" display=\"inline\"><mrow><mrow><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mtext>s.t</mtext></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\scriptsize 2\\gamma\\left(\\frac{1}{2\\beta},\\left(\\frac{\\delta_{i}%&#10;}{\\left\\lVert{{\\bf\\Sigma}^{1/2}_{w_{d}}{\\bf U}_{2:n}^{T}{\\bf P}^{T}h_{i}-{\\bf%&#10;\\Sigma}^{1/2}_{w_{d}}{\\bf U}_{2:n}^{T}h_{i}}\\right\\rVert_{2}}\\sqrt{\\frac{%&#10;\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}}\\right)^{2\\beta}\\right)}\" display=\"inline\"><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b3</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mn mathsize=\"70%\">1</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac></mstyle><mo mathsize=\"70%\" stretchy=\"false\">,</mo><msup><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><msub><mi mathsize=\"70%\">\u03b4</mi><mi mathsize=\"70%\">i</mi></msub><msub><mrow><mo fence=\"true\">\u2225</mo><mrow><mrow><msubsup><mi mathsize=\"70%\">\ud835\udeba</mi><msub><mi mathsize=\"70%\">w</mi><mi mathsize=\"70%\">d</mi></msub><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">/</mo><mn mathsize=\"70%\">2</mn></mrow></msubsup><mo>\u2062</mo><msubsup><mi mathsize=\"70%\">\ud835\udc14</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">:</mo><mi mathsize=\"70%\">n</mi></mrow><mi mathsize=\"70%\">T</mi></msubsup><mo>\u2062</mo><msup><mi mathsize=\"70%\">\ud835\udc0f</mi><mi mathsize=\"70%\">T</mi></msup><mo>\u2062</mo><msub><mi mathsize=\"70%\">h</mi><mi mathsize=\"70%\">i</mi></msub></mrow><mo mathsize=\"70%\" stretchy=\"false\">-</mo><mrow><msubsup><mi mathsize=\"70%\">\ud835\udeba</mi><msub><mi mathsize=\"70%\">w</mi><mi mathsize=\"70%\">d</mi></msub><mrow><mn mathsize=\"70%\">1</mn><mo mathsize=\"70%\" stretchy=\"false\">/</mo><mn mathsize=\"70%\">2</mn></mrow></msubsup><mo>\u2062</mo><msubsup><mi mathsize=\"70%\">\ud835\udc14</mi><mrow><mn mathsize=\"70%\">2</mn><mo mathsize=\"70%\" stretchy=\"false\">:</mo><mi mathsize=\"70%\">n</mi></mrow><mi mathsize=\"70%\">T</mi></msubsup><mo>\u2062</mo><msub><mi mathsize=\"70%\">h</mi><mi mathsize=\"70%\">i</mi></msub></mrow></mrow><mo fence=\"true\">\u2225</mo></mrow><mn mathsize=\"70%\">2</mn></msub></mfrac></mstyle><mo>\u2062</mo><msqrt><mstyle displaystyle=\"true\"><mfrac><mrow><mi mathsize=\"70%\" mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo maxsize=\"70%\" minsize=\"70%\">(</mo><mfrac><mn mathsize=\"70%\">3</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac><mo maxsize=\"70%\" minsize=\"70%\">)</mo></mrow></mrow><mrow><mi mathsize=\"70%\" mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo maxsize=\"70%\" minsize=\"70%\">(</mo><mfrac><mn mathsize=\"70%\">1</mn><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></mfrac><mo maxsize=\"70%\" minsize=\"70%\">)</mo></mrow></mrow></mfrac></mstyle></msqrt></mrow><mo>)</mo></mrow><mrow><mn mathsize=\"70%\">2</mn><mo>\u2062</mo><mi mathsize=\"70%\">\u03b2</mi></mrow></msup><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\geq 1-\\epsilon\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad%&#10;\\quad\\quad\\quad\\quad.\" display=\"inline\"><mrow><mrow><mi/><mo>\u2265</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03f5</mi></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003</mo><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\n\t\tWe can rewrite the problem in conic form as below.\n\n\t\t\n", "itemtype": "equation", "pos": 23396, "prevtext": " We compactly write ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T{\\bf P}^T h_i$ as $\\mathcal{A}_i({\\bf P})$, ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T h_i$ as $b_i$  and $\\frac{\\delta_i}{(\\gamma^{-1}(\\frac{1}{2\\beta},\\frac{1-\\epsilon}{2}))^{\\frac{1}{2\\beta}}} \\sqrt{\\frac{\\Gamma(\\frac{3}{2\\beta})}{\\Gamma(\\frac{1}{2\\beta})}}$ as $\\Delta_i$. Plugging above in equation (\\ref{probconst}), and rearranging terms, we have \n\t\t\n", "index": 13, "text": "\\begin{equation}\\label{opti4}\n\t\t\\begin{split}\n\t\t\\underset{{\\bf P}}{\\text{minimize}} \\quad\n\t\t\\left\\lVert{\\bf{P}}\\right\\rVert_* \\quad \\quad \\quad \\quad \\\\\n\t\t\\text{s.t} \\quad\n\t\t\\left\\lVert{\\mathcal{A}_i({\\bf P})-b_i}\\right\\rVert_2 \\le \\Delta_i \\quad i = 1,..,n. \\\\\n\t\t\\end{split}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\underset{{\\bf P}}{\\text{minimize}}\\quad\\left\\lVert{%&#10;\\bf{P}}\\right\\rVert_{*}\\\\&#10;\\displaystyle\\text{s.t}\\quad\\left\\lVert{\\mathcal{A}_{i}({\\bf P})-b_{i}}\\right%&#10;\\rVert_{2}\\leq\\Delta_{i}\\quad i=1,..,n.\\\\&#10;\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo mathsize=\"70%\" separator=\"true\" stretchy=\"false\">\u2003</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mtext>s.t</mtext><mo separator=\"true\">\u2003</mo><msub><mrow><mo fence=\"true\">\u2225</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><msub><mi>b</mi><mi>i</mi></msub><mo fence=\"true\">\u2225</mo></mrow><mn>2</mn></msub><mo>\u2264</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub><mo separator=\"true\">\u2003</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \n\t\twhere $\\mathcal{K}_i$ is a second order cone $\\mathcal{K}_i = \\{(x_i,t_i) \\in \\mathbb{R}^{n+1} : \\left\\lVert{x_i}\\right\\rVert \\le t_i \\}$. Let ${\\bf b} = [b_1,..,b_n]$, and ${\\mathcal{A}({\\bf P}) = [\\mathcal{A}_1({\\bf P}),..,\\mathcal{A}_n({\\bf P})]}$. Let $\\mathcal{A}^*$  denote the adjoint of the linear operator $\\mathcal{A}$.\n\t\tIt is easy to recognize that the optimization above is a convex problem, since nuclear norm is convex and the constraints enforce finite bounds on the norms of affine functions of the decision variable, ${\\bf {P}}$ and hence are also convex.\n\t\tEven though the constraints are second-order cone constraints, the standard second order conic programming methods cannot be used to solve $(P1)$ since nuclear norm is non-smooth. The nuclear norm is smoothened by the addition of a square of Forbenius norm of the matrix, and is replaced by $\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2$, where $\\tau > 0$. The optimization problem with the smoothened objective function is given in \\ref{opti6}. \n\t\t\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\t\tWe can rewrite the problem in conic form as below.\n\n\t\t\n", "index": 15, "text": "\\begin{equation}\\label{opti5}\n\t\t\\begin{split}\n\t\t(P1) \\quad \\underset{\\bf{P}}{\\text{minimize}} \\quad\n\t\t\\left\\lVert{\\bf{P}}\\right\\rVert_* \\quad \\quad \\text{s.t} \\\\\n\t    \\left[\n\t\t\\begin{array}{lr}\n\t\tb_i-\\mathcal{A}_i(\\bf{P}) \\\\\n\t\t\\Delta_i \n\t\t\\end{array}\n\t\t\\right] \\in \\mathcal{K}_i, \\quad  i = 1,..,n,\n         \\end{split}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle(P1)\\quad\\underset{\\bf{P}}{\\text{minimize}}\\quad%&#10;\\left\\lVert{\\bf{P}}\\right\\rVert_{*}\\quad\\quad\\text{s.t}\\\\&#10;\\displaystyle\\left[\\begin{array}[]{lr}b_{i}-\\mathcal{A}_{i}(\\bf{P})\\\\&#10;\\Delta_{i}\\end{array}\\right]\\in\\mathcal{K}_{i},\\quad i=1,..,n,\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>P</mi><mo>\u2062</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo separator=\"true\">\u2003</mo><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo separator=\"true\">\u2003</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub><mo separator=\"true\">\u2003\u2003</mo><mtext>s.t</mtext></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>b</mi><mi>i</mi></msub><mo>-</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mtd><mtd/></mtr></mtable><mo>]</mo></mrow><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mi>i</mi></msub><mo rspace=\"12.5pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \n\t\tRecently, many algorithms \\cite{liu2012implementable,cai2010singular} have been developed to tackle nuclear norm minimization problem of this form in the context of matrix completion. We use SVT (singular value thresholding)  algorithm \\cite{cai2010singular} to solve $(P2)$.\n    \\par{{\\bf SVT iteration to solve ($P2$):}}\n    Here, we first briefly describe the SVT algorithm for smoothened nuclear norm minimization with general convex constraints, and later we show how we adapt the same to our problem $P2$ which has $n$ second-order constraints. Let the smoothened nuclear norm with general convex constraints, be given as below.\n    \t\n", "itemtype": "equation", "pos": -1, "prevtext": " \n\t\twhere $\\mathcal{K}_i$ is a second order cone $\\mathcal{K}_i = \\{(x_i,t_i) \\in \\mathbb{R}^{n+1} : \\left\\lVert{x_i}\\right\\rVert \\le t_i \\}$. Let ${\\bf b} = [b_1,..,b_n]$, and ${\\mathcal{A}({\\bf P}) = [\\mathcal{A}_1({\\bf P}),..,\\mathcal{A}_n({\\bf P})]}$. Let $\\mathcal{A}^*$  denote the adjoint of the linear operator $\\mathcal{A}$.\n\t\tIt is easy to recognize that the optimization above is a convex problem, since nuclear norm is convex and the constraints enforce finite bounds on the norms of affine functions of the decision variable, ${\\bf {P}}$ and hence are also convex.\n\t\tEven though the constraints are second-order cone constraints, the standard second order conic programming methods cannot be used to solve $(P1)$ since nuclear norm is non-smooth. The nuclear norm is smoothened by the addition of a square of Forbenius norm of the matrix, and is replaced by $\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2$, where $\\tau > 0$. The optimization problem with the smoothened objective function is given in \\ref{opti6}. \n\t\t\n", "index": 17, "text": "\\begin{equation}\\label{opti6}\n\t\t\\begin{split}\n\t\t(P2) \\quad\n\t\t\\underset{\\bf{P}}{\\text{minimize}} \\quad\n\t\t\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2 \\quad \\quad \\quad \\\\\n\t\t\\text{s.t}\n\t\t\\left[\n\t\t\\begin{array}{lr}\n\t\tb_i-\\mathcal{A}_i(\\bf{P}) \\\\\n\t\t\\Delta_i \n\t\t\\end{array}\n\t\t\\right] \\in \\mathcal{K}_i, \\quad \\quad  i = 1,..,n.\n\t\t\\end{split}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle(P2)\\quad\\underset{\\bf{P}}{\\text{minimize}}\\quad\\tau%&#10;\\left\\lVert{\\bf{P}}\\right\\rVert_{*}+\\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert%&#10;_{F}^{2}\\\\&#10;\\displaystyle\\text{s.t}\\left[\\begin{array}[]{lr}b_{i}-\\mathcal{A}_{i}(\\bf{P})%&#10;\\\\&#10;\\Delta_{i}\\end{array}\\right]\\in\\mathcal{K}_{i},\\quad\\quad i=1,..,n.\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>P</mi><mo>\u2062</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo mathsize=\"70%\" mathvariant=\"bold\" separator=\"true\" stretchy=\"false\">\u2003</mo><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo mathsize=\"70%\" mathvariant=\"bold\" separator=\"true\" stretchy=\"false\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mtext>s.t</mtext><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>b</mi><mi>i</mi></msub><mo>-</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mtd><mtd/></mtr></mtable><mo>]</mo></mrow><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mi>i</mi></msub><mo rspace=\"22.5pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \nwhere $f_i({\\bf P})\\le0$,  $i=1,..,n$ denote the $n$ convex constraints. Let $\\mathcal{F}({\\bf P}) = [f_1({\\bf P}),..,f_n({{\\bf P}})]$. The SVT algorithm for the \\ref{opti7} with the modified objective function is given as below.\n \n", "itemtype": "equation", "pos": -1, "prevtext": " \n\t\tRecently, many algorithms \\cite{liu2012implementable,cai2010singular} have been developed to tackle nuclear norm minimization problem of this form in the context of matrix completion. We use SVT (singular value thresholding)  algorithm \\cite{cai2010singular} to solve $(P2)$.\n    \\par{{\\bf SVT iteration to solve ($P2$):}}\n    Here, we first briefly describe the SVT algorithm for smoothened nuclear norm minimization with general convex constraints, and later we show how we adapt the same to our problem $P2$ which has $n$ second-order constraints. Let the smoothened nuclear norm with general convex constraints, be given as below.\n    \t\n", "index": 19, "text": "\\begin{equation}\\label{opti7}\n    \t\\begin{split}\n \\underset{\\bf{P}}{\\text{minimize}} \\quad\n    \t\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2 \\quad \\quad \\quad \\quad \\\\\n    \t\\text{s.t}  \\quad\n    \t f_i({\\bf P}) \\le 0, \\quad  i = 1,..,n,\n    \t\\end{split}\n    \t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\underset{\\bf{P}}{\\text{minimize}}\\quad\\tau\\left%&#10;\\lVert{\\bf{P}}\\right\\rVert_{*}+\\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_{F}^%&#10;{2}\\\\&#10;\\displaystyle\\text{s.t}\\quad f_{i}({\\bf P})\\leq 0,\\quad i=1,..,n,\\end{split}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><munder accentunder=\"true\"><mtext>minimize</mtext><mo>\ud835\udc0f</mo></munder><mo mathsize=\"70%\" mathvariant=\"bold\" separator=\"true\" stretchy=\"false\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mtext>s.t</mtext><mo separator=\"true\">\u2003</mo><msub><mi>f</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2264</mo><mn>0</mn><mo rspace=\"12.5pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nwhere ${\\bf z}^k$ is a short form for $[{\\bf z_1}^k,..,{\\bf z_n}^k]$, and $P_i({\\bf q})$ denotes the projection of ${\\bf q}$ onto the convex set defined by the constraint $f_i({\\bf P}) \\le 0$. Let ${\\bf z_i}^k = [{\\bf y_i}^k, s_i^k]$, so that the vector ${\\bf y_i}^k$ denotes the first $n$ elements of ${\\bf z_i}^k$ and $s_i^k$ denotes the last element of ${\\bf z_i}^k$. Let ${\\bf y}^k$ be a short form for $[{\\bf y_1}^k,..,{\\bf y_n}^k]$, and $s^k$ is a short form for $[s_1^k,..,s_n^k]$. To obtain a  explicit form of the update equations in \\ref{uzawa1} for our problem, $P1$, let us consider the first equation of the same. $\\mathcal{F}(\\bf{P})$ for $P1$ is given by $[b_1 - \\mathcal{A}_1({\\bf P}), \\Delta_1,..,b_n - \\mathcal{A}_n({\\bf P}),\\Delta_n]^T$. We substitute for $\\mathcal{F}({\\bf P})$, and after removal of the terms not involving ${\\bf P}$, we have\n\n", "itemtype": "equation", "pos": 26738, "prevtext": " \nwhere $f_i({\\bf P})\\le0$,  $i=1,..,n$ denote the $n$ convex constraints. Let $\\mathcal{F}({\\bf P}) = [f_1({\\bf P}),..,f_n({{\\bf P}})]$. The SVT algorithm for the \\ref{opti7} with the modified objective function is given as below.\n \n", "index": 21, "text": "\\begin{equation}\\label{uzawa1}\n \\begin{rcases}\n \\begin{array}{lr}\n \\begin{array}{lr}\n {\\bf P}^k = \\underset{\\bf{P}} {\\operatornamewithlimits{arg\\ min}} \\quad  {\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2 + \\langle {\\bf z}^{k-1}, \\mathcal{F}({\\bf P}) \\rangle}\n \\end{array} \\\\\n \\begin{array}{lr}\n {\\bf z_i}^k\n \\end{array}\n = P_i\\left({\\bf z_i}^{k-1}  + \\eta^{k}f_i({\\bf P}^k) \\right), \\quad  i = 1,..,n\n \\end{array}\n \\end{rcases}\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\begin{rcases}\\begin{array}[]{lr}\\begin{array}[]{lr}{\\bf P}^{k}=\\underset{\\bf{%&#10;P}}{\\operatornamewithlimits{arg\\ min}}\\quad{\\tau\\left\\lVert{\\bf{P}}\\right%&#10;\\rVert_{*}+\\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_{F}^{2}+\\langle{\\bf z}^{%&#10;k-1},\\mathcal{F}({\\bf P})\\rangle}\\end{array}\\\\&#10;\\begin{array}[]{lr}{\\bf z_{i}}^{k}\\end{array}=P_{i}\\left({\\bf z_{i}}^{k-1}+%&#10;\\eta^{k}f_{i}({\\bf P}^{k})\\right),\\quad i=1,..,n\\end{array}\\end{rcases}\" display=\"block\"><mrow><mtable columnspacing=\"5pt\" displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mtable columnspacing=\"5pt\" displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+5pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mo>\ud835\udc0f</mo></munder><mo mathvariant=\"bold\" separator=\"true\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"false\"><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc33</mi><mrow><mi>\ud835\udc24</mi><mo>-</mo><mn>\ud835\udfcf</mn></mrow></msup><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow></mtd><mtd/></mtr></mtable></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mtable columnspacing=\"5pt\" displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mmultiscripts><mi>\ud835\udc33</mi><mi>\ud835\udc22</mi><none/><none/><mi>k</mi></mmultiscripts></mtd><mtd/></mtr></mtable><mo>=</mo><msub><mi>P</mi><mi>i</mi></msub><mrow><mo>(</mo><mmultiscripts><mi>\ud835\udc33</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo>+</mo><msup><mi>\u03b7</mi><mi>k</mi></msup><msub><mi>f</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo stretchy=\"false\">)</mo></mrow><mo>)</mo></mrow><mo rspace=\"12.5pt\">,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mi>n</mi></mrow></mtd><mtd/></mtr></mtable></mtd><mtd/></mtr></mtable><mo>}</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nEquation \\ref{uzawa2} can be rewritten as below.\n\n", "itemtype": "equation", "pos": 28088, "prevtext": "\nwhere ${\\bf z}^k$ is a short form for $[{\\bf z_1}^k,..,{\\bf z_n}^k]$, and $P_i({\\bf q})$ denotes the projection of ${\\bf q}$ onto the convex set defined by the constraint $f_i({\\bf P}) \\le 0$. Let ${\\bf z_i}^k = [{\\bf y_i}^k, s_i^k]$, so that the vector ${\\bf y_i}^k$ denotes the first $n$ elements of ${\\bf z_i}^k$ and $s_i^k$ denotes the last element of ${\\bf z_i}^k$. Let ${\\bf y}^k$ be a short form for $[{\\bf y_1}^k,..,{\\bf y_n}^k]$, and $s^k$ is a short form for $[s_1^k,..,s_n^k]$. To obtain a  explicit form of the update equations in \\ref{uzawa1} for our problem, $P1$, let us consider the first equation of the same. $\\mathcal{F}(\\bf{P})$ for $P1$ is given by $[b_1 - \\mathcal{A}_1({\\bf P}), \\Delta_1,..,b_n - \\mathcal{A}_n({\\bf P}),\\Delta_n]^T$. We substitute for $\\mathcal{F}({\\bf P})$, and after removal of the terms not involving ${\\bf P}$, we have\n\n", "index": 23, "text": "\\begin{equation}\\label{uzawa2}\n{\\bf P}^k = \\underset{\\bf{P}} {\\operatornamewithlimits{arg\\ min}} \\quad  {\\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert_F^2 + \\langle {\\bf y}^{k-1}, {\\bf b}- \\mathcal{A}({\\bf P}) \\rangle}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"{\\bf P}^{k}=\\underset{\\bf{P}}{\\operatornamewithlimits{arg\\ min}}\\quad{\\tau%&#10;\\left\\lVert{\\bf{P}}\\right\\rVert_{*}+\\frac{1}{2}\\left\\lVert{\\bf{P}}\\right\\rVert%&#10;_{F}^{2}+\\langle{\\bf y}^{k-1},{\\bf b}-\\mathcal{A}({\\bf P})\\rangle}.\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+5pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mo>\ud835\udc0f</mo></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc32</mi><mrow><mi>\ud835\udc24</mi><mo>-</mo><mn>\ud835\udfcf</mn></mrow></msup><mo>,</mo><mrow><mi>\ud835\udc1b</mi><mo>-</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nRemoving the terms not involving ${\\bf P}$ and noting that $\\langle{\\bf P}, \\mathcal{A}^*({\\bf y}^{k-1}) \\rangle = \\langle{\\bf y}^{k-1}, \\mathcal{A}({\\bf P}) \\rangle$, we have the following.\n\n", "itemtype": "equation", "pos": 28409, "prevtext": "\nEquation \\ref{uzawa2} can be rewritten as below.\n\n", "index": 25, "text": "\\begin{align*}\\label{uzawa2}\n{\\bf P}^k = \\underset{\\bf{P}} {\\operatornamewithlimits{arg\\ min}} \\quad  \\tau\\left\\lVert{{\\bf P}}\\right\\rVert_* + \\frac{1}{2}\\left\\lVert{{\\bf P} - \\mathcal{A}^*({\\bf y}^{k-1})}\\right\\rVert_F^2 \\\\ - \\frac{1}{2}\\left\\lVert{\\mathcal{A}^*({\\bf y}^{k-1})}\\right\\rVert_F^2 + \\langle{\\bf P}, \\mathcal{A}^*({\\bf y}^{k-1}) \\rangle \\\\ + \\langle {\\bf y}^{k-1}, {\\bf b} \\rangle - \\langle{\\bf y}^{k-1}, \\mathcal{A}({\\bf P}) \\rangle.\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\bf P}^{k}=\\underset{\\bf{P}}{\\operatornamewithlimits{arg\\ min}}%&#10;\\quad\\tau\\left\\lVert{{\\bf P}}\\right\\rVert_{*}+\\frac{1}{2}\\left\\lVert{{\\bf P}-%&#10;\\mathcal{A}^{*}({\\bf y}^{k-1})}\\right\\rVert_{F}^{2}\" display=\"inline\"><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+5pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mo>\ud835\udc0f</mo></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mrow><mi>\ud835\udc0f</mi><mo>-</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mi>\ud835\udc24</mi><mo>-</mo><mn>\ud835\udfcf</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle-\\frac{1}{2}\\left\\lVert{\\mathcal{A}^{*}({\\bf y}^{k-1})}\\right%&#10;\\rVert_{F}^{2}+\\langle{\\bf P},\\mathcal{A}^{*}({\\bf y}^{k-1})\\rangle\" display=\"inline\"><mrow><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\">\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\langle{\\bf y}^{k-1},{\\bf b}\\rangle-\\langle{\\bf y}^{k-1},%&#10;\\mathcal{A}({\\bf P})\\rangle.\" display=\"inline\"><mrow><mrow><mrow><mo>+</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo>,</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>-</mo><mrow><mo stretchy=\"false\">\u27e8</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo>,</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "    \nBefore we write down the solution to equation \\ref{uzawa3}, we first define  $\\mathcal{D}_\\tau$, the singular value shrinkage operator.  Consider the SVD of a matrix ${\\bf X}$, given by ${\\bf X} = {\\bf W}{\\bf \\Sigma V}^T$. Then for $\\tau \\ge 0$, the singular value shrinkage operator, $\\mathcal{D}_\\tau$ is given by $\\mathcal{D}_\\tau({\\bf X}) = {\\bf W}\\mathcal{D}_\\tau({\\bf \\Sigma}){\\bf V}^T,\n\\mathcal{D}_\\tau({\\bf \\Sigma}) = diag(\\{(\\sigma_i-\\tau)_+\\})$,\nwhere $t_+$ = max(0,$t$).  The solution to equation \\ref{uzawa3} is given by ${\\bf P}^k = \\mathcal{D}_\\tau(\\mathcal{A}^*({\\bf y}^{k-1}))$. Now, it remains to calculate $\\mathcal{A}^*({\\bf y}^{k-1})$. We achieve it according to the following. Consider $\\langle \\mathcal{A}^*({\\bf y}^{k-1}), {\\bf P} \\rangle$.\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nRemoving the terms not involving ${\\bf P}$ and noting that $\\langle{\\bf P}, \\mathcal{A}^*({\\bf y}^{k-1}) \\rangle = \\langle{\\bf y}^{k-1}, \\mathcal{A}({\\bf P}) \\rangle$, we have the following.\n\n", "index": 27, "text": "\\begin{equation}\\label{uzawa3}\n{\\bf P}^k = \\underset{\\bf{P}} {\\operatornamewithlimits{arg\\ min}} \\quad  \\tau\\left\\lVert{\\bf{P}}\\right\\rVert_* +  \\frac{1}{2}\\left\\lVert{{\\bf P} - \\mathcal{A}^*({\\bf y}^{k-1})}\\right\\rVert_F^2.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"{\\bf P}^{k}=\\underset{\\bf{P}}{\\operatornamewithlimits{arg\\ min}}\\quad\\tau\\left%&#10;\\lVert{\\bf{P}}\\right\\rVert_{*}+\\frac{1}{2}\\left\\lVert{{\\bf P}-\\mathcal{A}^{*}(%&#10;{\\bf y}^{k-1})}\\right\\rVert_{F}^{2}.\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><munder accentunder=\"true\"><mrow><mpadded width=\"+5pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>min</mi></mrow><mo>\ud835\udc0f</mo></munder><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><msub><mrow><mo fence=\"true\">\u2225</mo><mi>\ud835\udc0f</mi><mo fence=\"true\">\u2225</mo></mrow><mo>*</mo></msub></mrow><mo>+</mo><mrow><mfrac><mn>\ud835\udfcf</mn><mn>\ud835\udfd0</mn></mfrac><mo>\u2062</mo><msubsup><mrow><mo fence=\"true\">\u2225</mo><mrow><mi>\ud835\udc0f</mi><mo>-</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mi>\ud835\udc24</mi><mo>-</mo><mn>\ud835\udfcf</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\">\u2225</mo></mrow><mi>\ud835\udc05</mi><mn>\ud835\udfd0</mn></msubsup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nHence, we have $\\mathcal{A}^*({\\bf y}^{k-1}) = \\sum_{i=1}^{n}\\mathcal{A}_i^*({\\bf y_i}^{k-1})$. Thus, the first equation of SVT iteration for our problem is given by \n\n", "itemtype": "equation", "pos": 30070, "prevtext": "    \nBefore we write down the solution to equation \\ref{uzawa3}, we first define  $\\mathcal{D}_\\tau$, the singular value shrinkage operator.  Consider the SVD of a matrix ${\\bf X}$, given by ${\\bf X} = {\\bf W}{\\bf \\Sigma V}^T$. Then for $\\tau \\ge 0$, the singular value shrinkage operator, $\\mathcal{D}_\\tau$ is given by $\\mathcal{D}_\\tau({\\bf X}) = {\\bf W}\\mathcal{D}_\\tau({\\bf \\Sigma}){\\bf V}^T,\n\\mathcal{D}_\\tau({\\bf \\Sigma}) = diag(\\{(\\sigma_i-\\tau)_+\\})$,\nwhere $t_+$ = max(0,$t$).  The solution to equation \\ref{uzawa3} is given by ${\\bf P}^k = \\mathcal{D}_\\tau(\\mathcal{A}^*({\\bf y}^{k-1}))$. Now, it remains to calculate $\\mathcal{A}^*({\\bf y}^{k-1})$. We achieve it according to the following. Consider $\\langle \\mathcal{A}^*({\\bf y}^{k-1}), {\\bf P} \\rangle$.\n\n", "index": 29, "text": "\\begin{align*}\n \\langle  {\\bf P}, \\mathcal{A}^*({\\bf y}^{k-1}) \\rangle \\\\\n= \\langle \\mathcal{A}({\\bf P}), {\\bf y}^{k-1} \\rangle\n=  \\sum_{i=1}^{n} \\langle \\mathcal{A}_i({\\bf P}), {\\bf y_i}^{k-1} \\rangle \\\\\n=   \\sum_{i=1}^{n}\\langle {\\bf P} , \\mathcal{A}_i^*({ {\\bf y_i}^{k-1}}) \\rangle \n= \\langle {\\bf P}, \\sum_{i=1}^{n}\\mathcal{A}_i^*({\\bf y_i}^{k-1}) \\rangle\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\langle{\\bf P},\\mathcal{A}^{*}({\\bf y}^{k-1})\\rangle\" display=\"inline\"><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>*</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\langle\\mathcal{A}({\\bf P}),{\\bf y}^{k-1}\\rangle=\\sum_{i=1}^{n}%&#10;\\langle\\mathcal{A}_{i}({\\bf P}),{\\bf y_{i}}^{k-1}\\rangle\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msup><mi>\ud835\udc32</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mmultiscripts><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{i=1}^{n}\\langle{\\bf P},\\mathcal{A}_{i}^{*}({{\\bf y_{i}}^{k%&#10;-1}})\\rangle=\\langle{\\bf P},\\sum_{i=1}^{n}\\mathcal{A}_{i}^{*}({\\bf y_{i}}^{k-1%&#10;})\\rangle\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mmultiscripts><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mmultiscripts><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nUsing basic linear algebra,  it can be shown that $\\mathcal{A}_i^*({\\bf y_i}^{k-1}) = {\\bf U}_{2:n}(\\Sigma_{w_d}^{1/2})^T {\\bf y_i}^{k-1} h_i^T$ (see Appendix B for details).\n\\par We now provide the projection onto the convex cone $\\mathcal{K}_i$. The projection operator, $P_{\\mathcal{K}_i}$ as derived in \\cite{fukushima2002smoothing} is given as follows.\n\t\t\n\t\t\n", "itemtype": "equation", "pos": 30610, "prevtext": "\nHence, we have $\\mathcal{A}^*({\\bf y}^{k-1}) = \\sum_{i=1}^{n}\\mathcal{A}_i^*({\\bf y_i}^{k-1})$. Thus, the first equation of SVT iteration for our problem is given by \n\n", "index": 31, "text": "\\begin{equation}\n{\\bf P}^k = \\mathcal{D}_\\tau\\left(\\sum_{i=1}^{n}\\mathcal{A}_i^*({\\bf y_i}^{k-1})\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"{\\bf P}^{k}=\\mathcal{D}_{\\tau}\\left(\\sum_{i=1}^{n}\\mathcal{A}_{i}^{*}({\\bf y_{%&#10;i}}^{k-1})\\right).\" display=\"block\"><mrow><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mi>\u03c4</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mmultiscripts><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\n\t\t\n\t\tTo solve $(P2)$, starting with\n\t\t$\\left[\n\t\t\\begin{array}{lr}\n\t\t{\\bf y}^0_i \\\\\n\t\ts^0_i\n\t\t\\end{array}\n\t\t\\right] = {\\bf 0}$ for all $i = 1,..n$, the $k^{th}$ SVT iteration is given by (\\ref{uzawa}).\n\t\t\n", "itemtype": "equation", "pos": 31094, "prevtext": "\nUsing basic linear algebra,  it can be shown that $\\mathcal{A}_i^*({\\bf y_i}^{k-1}) = {\\bf U}_{2:n}(\\Sigma_{w_d}^{1/2})^T {\\bf y_i}^{k-1} h_i^T$ (see Appendix B for details).\n\\par We now provide the projection onto the convex cone $\\mathcal{K}_i$. The projection operator, $P_{\\mathcal{K}_i}$ as derived in \\cite{fukushima2002smoothing} is given as follows.\n\t\t\n\t\t\n", "index": 33, "text": "\\begin{equation}\n\t\tP_{\\mathcal{K}_i} : (x,t) \\mapsto \n\t\t\\begin{array}{lr}\n\t\t(x,t),  \\quad \\quad \\quad \\quad \\quad \\quad \\left\\lVert{x}\\right\\rVert \\le t, \\\\\n\t\t\\frac{\\left\\lVert{x}\\right\\rVert+t}{2\\left\\lVert{x}\\right\\rVert} (x,\\left\\lVert{x}\\right\\rVert), \\quad -\\left\\lVert{x}\\right\\rVert \\le t \\le \\left\\lVert{x}\\right\\rVert,   \\\\\n\t\t(0,0), \\quad \\quad \\quad \\quad \\quad \\quad    t \\le -\\left\\lVert{x}\\right\\rVert.  \n\t\t\\end{array}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"P_{\\mathcal{K}_{i}}:(x,t)\\mapsto\\begin{array}[]{lr}(x,t),\\quad\\quad\\quad\\quad%&#10;\\quad\\quad\\left\\lVert{x}\\right\\rVert\\leq t,\\\\&#10;\\frac{\\left\\lVert{x}\\right\\rVert+t}{2\\left\\lVert{x}\\right\\rVert}(x,\\left\\lVert%&#10;{x}\\right\\rVert),\\quad-\\left\\lVert{x}\\right\\rVert\\leq t\\leq\\left\\lVert{x}%&#10;\\right\\rVert,\\\\&#10;(0,0),\\quad\\quad\\quad\\quad\\quad\\quad t\\leq-\\left\\lVert{x}\\right\\rVert.\\end{array}\" display=\"block\"><mrow><msub><mi>P</mi><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mi>i</mi></msub></msub><mo>:</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u21a6</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"62.5pt\">,</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow></mrow><mo>\u2264</mo><mi>t</mi></mrow><mo>,</mo></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mrow><mfrac><mrow><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow><mo>+</mo><mi>t</mi></mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mo>-</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow></mrow></mrow><mo>\u2264</mo><mi>t</mi><mo>\u2264</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow></mrow><mo>,</mo></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"62.5pt\">,</mo><mi>t</mi></mrow><mo>\u2264</mo><mrow><mo>-</mo><mrow><mo fence=\"true\">\u2225</mo><mi>x</mi><mo fence=\"true\">\u2225</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd><mtd/></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\n\t\twhere, $\\mathcal{A}^*_i$ are the adjoints of linear operators $\\mathcal{A}_i$.\n\t\tFor the iterations (\\ref{uzawa}) to converge, we need to choose the step sizes, $\\eta^k \\le \\frac{2}{\\left\\lVert{\\mathcal{A}}\\right\\rVert_2^2}$, where $\\left\\lVert{\\mathcal{A}}\\right\\rVert_2$ is the spectral norm of the linear transformation $\\mathcal{A}$ \\cite{cai2010singular}.\n\t\t\n\t\tOnce the solution ${\\bf P}^*$ is found, using the relation noted earlier in the section, we have ${\\bf Q}^* = {\\bf P}^* + \\frac{1}{n} {\\bf O}$. Having obtained ${\\bf Q}^*$, the task now is to express it into a product of two matrices of identical ranks. This is done almost trivially as follows. Noting the singular value decomposition of ${\\bf Q^*}$ as ${\\bf Q^*} = {\\bf W}_{M}{\\bf \\Sigma}_{M}{\\bf V}^{T}_{M}$, where ${\\bf \\Sigma}_{M} =  diag\\{\\lambda_1,..,\\lambda_M\\}$ denote the diagonal matrix with the non-zero singular values arranged along its diagonal, and ${\\bf W}_{M}$ and ${\\bf V}^{T}_{M}$ are the matrices whose columns are the left and right singular vectors respectively. We can choose $\\phi^* = {\\bf \\Sigma}_{M}^{1/2} {\\bf V}^{T}_{M}$, so that $((\\phi^d)^{*})^{T} = {\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M}$ and rank($\\phi^*$) = rank($(\\phi^d)^*$) = rank(${\\bf Q}^*$). We, henceforth refer to $\\phi^{*}$ as {\\bf ReFInE} $\\phi$, and the corresponding measurements, $y = \\phi^{*}x$ as {\\bf ReFInE} measurements.  The desired linear operator $\\mathcal{L}^{*}$ is given by ${\\bf H}{\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M}$. By construction, the approximate integral image $\\hat{I}$ is given by $\\hat{I} = \\mathcal{L}^{*}y = ({\\bf H}{\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M})y$.\n\t\t\n\t\t\\par{{\\bf Computational Complexity:}}\n\t\tSince the length of the image $x$ is $n$, the number of entries in ${\\bf P}$ is $n^2$. Hence, the dimension of the optimization problem $P2$ is $n^2$. This means that if we are to optimize for a measurement matrix to operate on an image of size, $256 \\times 256$, the dimension of the optimization problem would be $2^{32}$! Optimizing over a large number of variables is computationally expensive, if not impractical. Hence we propose the following suboptimal solution to obtain the measurement matrix. We divide the image into non-overlapping blocks of fixed size, and sense each block using a measurement matrix, optimized for this fixed size, independently of other blocks. Let the image, $x$ be divided into $B$ blocks, $x_1, x_2, .. ,x_B$, each of a fixed size, $f \\times f$, and $\\phi_f \\in \\mathcal{R}^{m \\times f^2}$ be the measurement matrix optimized for images of size $f \\times f$, and $(\\phi^d_f)^T$ be the corresponding dual matrix. Then the `{\\bf ReFInE}' measurements, $y$ are given by the following,\n    \n", "itemtype": "equation", "pos": 31746, "prevtext": "\n\t\t\n\t\tTo solve $(P2)$, starting with\n\t\t$\\left[\n\t\t\\begin{array}{lr}\n\t\t{\\bf y}^0_i \\\\\n\t\ts^0_i\n\t\t\\end{array}\n\t\t\\right] = {\\bf 0}$ for all $i = 1,..n$, the $k^{th}$ SVT iteration is given by (\\ref{uzawa}).\n\t\t\n", "index": 35, "text": "\\begin{equation}\\label{uzawa}\n\t\t\\begin{rcases}\n\t\t\\begin{array}{lr}\n\t\t\\begin{array}{lr}\n\t\t{\\bf P}^k = \\mathcal{D}_\\tau\\left(\\sum\\limits_{i=1}^{n}{\\bf U}_{2:n}(\\Sigma_{w_d}^{1/2})^T {\\bf y_i}^{k-1} h_i^T\\right) \n\t\t\\end{array} \\\\\n\t\t\\left[\n\t\t\\begin{array}{lr}\n\t\t{\\bf y}^k_i \\\\\n\t\ts^k_i\n\t\t\\end{array}\n\t\t\\right] = P_{\\mathcal{K}_i}\\left(\\left[\\begin{array}{lr}\n\t\t{\\bf y}^{k-1}_i \\\\\n\t\ts^{k-1}_i\n\t\t\\end{array}\\right] + \\eta^k \\left[\n\t\t\\begin{array}{lr}\n\t\tb_i-\\mathcal{A}_i({\\bf P}^k) \\\\\n\t\t-\\Delta_i \n\t\t\\end{array}\n\t\t\\right]    \\right),\n\t\t\\end{array}\n\t\t\\end{rcases}\n\t\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\begin{rcases}\\begin{array}[]{lr}\\begin{array}[]{lr}{\\bf P}^{k}=\\mathcal{D}_{%&#10;\\tau}\\left(\\sum\\limits_{i=1}^{n}{\\bf U}_{2:n}(\\Sigma_{w_{d}}^{1/2})^{T}{\\bf y_%&#10;{i}}^{k-1}h_{i}^{T}\\right)\\end{array}\\\\&#10;\\left[\\begin{array}[]{lr}{\\bf y}^{k}_{i}\\\\&#10;s^{k}_{i}\\end{array}\\right]=P_{\\mathcal{K}_{i}}\\left(\\left[\\begin{array}[]{lr}%&#10;{\\bf y}^{k-1}_{i}\\\\&#10;s^{k-1}_{i}\\end{array}\\right]+\\eta^{k}\\left[\\begin{array}[]{lr}b_{i}-\\mathcal{%&#10;A}_{i}({\\bf P}^{k})\\\\&#10;-\\Delta_{i}\\end{array}\\right]\\right),\\end{array}\\end{rcases}\" display=\"block\"><mrow><mtable columnspacing=\"5pt\" displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mtable columnspacing=\"5pt\" displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo>=</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi><mi>\u03c4</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"false\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><msub><mi>\ud835\udc14</mi><mrow><mn>2</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><msub><mi>w</mi><mi>d</mi></msub><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mmultiscripts><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi><none/><none/><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo>\u2062</mo><msubsup><mi>h</mi><mi>i</mi><mi>T</mi></msubsup></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mtd><mtd/></mtr></mtable></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><msubsup><mi>\ud835\udc32</mi><mi>i</mi><mi>k</mi></msubsup></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><msubsup><mi>s</mi><mi>i</mi><mi>k</mi></msubsup></mtd><mtd/></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><msub><mi>P</mi><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mi>i</mi></msub></msub><mo>\u2062</mo><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><msubsup><mi>\ud835\udc32</mi><mi>i</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><msubsup><mi>s</mi><mi>i</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mtd><mtd/></mtr></mtable><mo>]</mo></mrow><mo>+</mo><mrow><msup><mi>\u03b7</mi><mi>k</mi></msup><mo>\u2062</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>b</mi><mi>i</mi></msub><mo>-</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc0f</mi><mi>k</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mo>-</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mtd><mtd/></mtr></mtable><mo>]</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd/></mtr></mtable></mtd><mtd/></mtr></mtable><mo>}</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "    \nOnce the measurements, $y$ are obtained, the integral image, $\\hat{I}$ is given by \n\n", "itemtype": "equation", "pos": -1, "prevtext": "\n\t\twhere, $\\mathcal{A}^*_i$ are the adjoints of linear operators $\\mathcal{A}_i$.\n\t\tFor the iterations (\\ref{uzawa}) to converge, we need to choose the step sizes, $\\eta^k \\le \\frac{2}{\\left\\lVert{\\mathcal{A}}\\right\\rVert_2^2}$, where $\\left\\lVert{\\mathcal{A}}\\right\\rVert_2$ is the spectral norm of the linear transformation $\\mathcal{A}$ \\cite{cai2010singular}.\n\t\t\n\t\tOnce the solution ${\\bf P}^*$ is found, using the relation noted earlier in the section, we have ${\\bf Q}^* = {\\bf P}^* + \\frac{1}{n} {\\bf O}$. Having obtained ${\\bf Q}^*$, the task now is to express it into a product of two matrices of identical ranks. This is done almost trivially as follows. Noting the singular value decomposition of ${\\bf Q^*}$ as ${\\bf Q^*} = {\\bf W}_{M}{\\bf \\Sigma}_{M}{\\bf V}^{T}_{M}$, where ${\\bf \\Sigma}_{M} =  diag\\{\\lambda_1,..,\\lambda_M\\}$ denote the diagonal matrix with the non-zero singular values arranged along its diagonal, and ${\\bf W}_{M}$ and ${\\bf V}^{T}_{M}$ are the matrices whose columns are the left and right singular vectors respectively. We can choose $\\phi^* = {\\bf \\Sigma}_{M}^{1/2} {\\bf V}^{T}_{M}$, so that $((\\phi^d)^{*})^{T} = {\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M}$ and rank($\\phi^*$) = rank($(\\phi^d)^*$) = rank(${\\bf Q}^*$). We, henceforth refer to $\\phi^{*}$ as {\\bf ReFInE} $\\phi$, and the corresponding measurements, $y = \\phi^{*}x$ as {\\bf ReFInE} measurements.  The desired linear operator $\\mathcal{L}^{*}$ is given by ${\\bf H}{\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M}$. By construction, the approximate integral image $\\hat{I}$ is given by $\\hat{I} = \\mathcal{L}^{*}y = ({\\bf H}{\\bf W}_{M} {\\bf \\Sigma}^{1/2}_{M})y$.\n\t\t\n\t\t\\par{{\\bf Computational Complexity:}}\n\t\tSince the length of the image $x$ is $n$, the number of entries in ${\\bf P}$ is $n^2$. Hence, the dimension of the optimization problem $P2$ is $n^2$. This means that if we are to optimize for a measurement matrix to operate on an image of size, $256 \\times 256$, the dimension of the optimization problem would be $2^{32}$! Optimizing over a large number of variables is computationally expensive, if not impractical. Hence we propose the following suboptimal solution to obtain the measurement matrix. We divide the image into non-overlapping blocks of fixed size, and sense each block using a measurement matrix, optimized for this fixed size, independently of other blocks. Let the image, $x$ be divided into $B$ blocks, $x_1, x_2, .. ,x_B$, each of a fixed size, $f \\times f$, and $\\phi_f \\in \\mathcal{R}^{m \\times f^2}$ be the measurement matrix optimized for images of size $f \\times f$, and $(\\phi^d_f)^T$ be the corresponding dual matrix. Then the `{\\bf ReFInE}' measurements, $y$ are given by the following,\n    \n", "index": 37, "text": "\\begin{equation}\n\ty = \\begin{bmatrix}\n\ty_1  \\\\\n\ty_2  \\\\\n\t\\vdots  \\\\\n\ty_B\n\t\\end{bmatrix}  =\n\t\\begin{bmatrix}\n \\phi_{f} & {\\bf 0} & \\cdots & {\\bf 0} \\\\\n\t{\\bf 0} &  \\phi_{f}  & \\cdots & {\\bf 0} \\\\\n\t\t\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n\t{\\bf 0} & {\\bf 0} & \\cdots &  \\phi_{f} \n\t\\end{bmatrix} \t\\begin{bmatrix}\n\tx_1  \\\\\n\tx_2  \\\\\n\t\\vdots  \\\\\n    x_B\n\t\\end{bmatrix}. \n\t\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"y=\\begin{bmatrix}y_{1}\\\\&#10;y_{2}\\\\&#10;\\vdots\\\\&#10;y_{B}\\end{bmatrix}=\\begin{bmatrix}\\phi_{f}&amp;{\\bf 0}&amp;\\cdots&amp;{\\bf 0}\\\\&#10;{\\bf 0}&amp;\\phi_{f}&amp;\\cdots&amp;{\\bf 0}\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;{\\bf 0}&amp;{\\bf 0}&amp;\\cdots&amp;\\phi_{f}\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\&#10;x_{2}\\\\&#10;\\vdots\\\\&#10;x_{B}\\end{bmatrix}.\" display=\"block\"><mrow><mrow><mi>y</mi><mo>=</mo><mrow><mo>[</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mi>B</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>\u03d5</mi><mi>f</mi></msub></mtd><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mn/></mtd></mtr><mtr><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><msub><mi>\u03d5</mi><mi>f</mi></msub></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mn/></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msub><mi>\u03d5</mi><mi>f</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow><mo>\u2062</mo><mrow><mo>[</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>x</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>x</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>x</mi><mi>B</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " \n\t\t\n\t\t\\section{Experiments}\n\n\t\tBefore we can conduct experiments to evaluate our framework, we first need to estimate the parameters of the probability model in \\ref{MGGD}.\n\t\tEstimating parameters of the probability model and optimizing measurement matrices for any arbitrary large sized image blocks is not practical since the former task requires an enormous amount of image data and the latter requires prohibitive amount of memory and computational resources. Hence, we fix the block size to be $32 \\times 32$ images. The scatter matrix ${\\bf \\Sigma}_{w_d}$ is a scalar multiple of the covariance matrix of $w_d$. Hence it suffices to compute the covariance matrix. To this end, we first downsample all the 5011 training images in PASCAL VOC 2007 dataset \\cite{pascal-voc-2007} to a size of $32 \\times 32$, so that $n$ = 1024 and then obtain the level 7 Daubechies wavelet coefficient vectors. We compute the sample covariance matrix of thus obtained wavelet coefficient data. For various values of $\\beta$, we evaluate the $\\chi^2$ distance between the histograms of the individual wavelet coefficients and their respective theoretical marginal distributions with the variances computed above. We found for $\\beta = 0.68$, the distance computed above is minimum.\n\n\t\t\\noindent\n\t\t\\par{{\\bf Computing measurement matrix:}} \n\t\tTo obtain a measurement matrix, we need to input a desired distortion vector $\\delta$ to the optimization problem in $(P2)$. The desired distortion vector is computed according to the following. We first perform principal component analysis (PCA) on the downsampled 5011 training images in the PASCAL VOC 2007 dataset \\cite{pascal-voc-2007}. We use only the top 10 PCA components as $\\phi$ to `sense' these images. We obtain the desired distortion vector by first assuming $\\phi^{d} = \\phi$ and calculating distortions, $|d^j_i|$ at each location for all training images, $j =1,..,5011$. Now, the entry in location $i$ of the desired ${\\bf \\delta}$ is given by the minimum value $\\alpha$, so that $95\\%$ of the values, $|d^j_i|, j =1,..,5011$ are less than $\\alpha$.  We use $\\epsilon =0.95$ and solve $(P2)$ to obtain ${\\bf P}^*$, and hence also ${\\bf Q}^*$. The rank of {\\bf ReFInE} $\\phi$ is simply the rank of ${\\bf Q}^*$. \n\t\t\n\t\t\n\t\n\t\t\n\t\t\n\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t\n\t\t\t\n\t\t\n\t\t\n\t\n\t\t\n\t\t\\noindent\n\t\t\\par{{\\bf Estimation of integral images:}}\n\t\tWe show that good quality estimates of integral images can be obtained using our framework. To this end, we first construct {\\bf ReFInE} measurement matrices of various ranks, $M$. We achieve this by considering the SVD of ${\\bf Q}^*$ obtained above. For a particular value of $M$, the {\\bf ReFInE} $\\phi$ is calculated according to $\\phi_{M} = {\\bf \\Sigma}_{M}^{1/2}{\\bf V}_M^{T}$, where ${\\bf \\Sigma}_M = diag\\{\\lambda_1,..,\\lambda_M\\}$ is a diagonal matrix with $M$ largest singular values arranged along the diagonal and ${\\bf V}_M^{T}$ denote the corresponding rows in ${\\bf V}^{T}$. Its dual, $\\phi^d$, is calculated similarly. For each particular measurement rate, determined by the value of $M$, the integral image estimates are recovered from $M$ {\\bf ReFInE} measurements for all the 4952 test images in the PASCAL VOC 2007 dataset \\cite{pascal-voc-2007}. Similarly integral image estimates are recovered from random Gaussian measurements by first performing non-linear iterative reconstruction using the CoSamP algorithm \\cite{needell2009cosamp} and then applying the integral operation on the reconstructed images. This pipeline is used as baseline to compare integral estimates, and henceforth is referred to as `RG-CoSamP'. We then measure the recovered signal-to-noise ratio (RSNR) via 20 $\\log_{10}\\left(\\frac{\\left\\lVert{\\hat{I}}\\right\\rVert_F}{\\left\\lVert{\\hat{I}-I}\\right\\rVert_F}\\right)$.\n\t\t\\begin{table*}\n\t\t\t\\centering\n\t\t\t{\\begin{tabular}{| l | l | l | l | l | l | l |}\n\t\t\t\t\t\\hline\n\t\t\t\t\tMethod & {\\bf ReFInE} & RG-CoSamP & {\\bf ReFInE} & RG-CoSamP &{\\bf ReFInE} & RG-CoSamP \\\\ \\hline\n\t\t\t\t\t$M$ (measurement ratio) & 20 (0.005) &  20 (0.005) & 40 (0.01) & 40 (0.01) & 60 (0.015) & 60 (0.015) \\\\ \\hline\n\t\t\t\t\tTime in s & 0.0034 & 0.38 & 0.0036 & 0.58 & 0.0031  & 0.97  \\\\ \\hline\n\t\t\t\t\tRSNR in dB & 38.95 & -16.76 & 38.96 & -11.22 & 38.96 & -10.9 \\\\ \\hline \n\t\t\t\t\\end{tabular}\n\t\t\t}\n\t\t\t\\caption{Comparison of average RSNR and time for recovered integral image estimates obtained using our method with RG-CoSamP. Our framework outperforms RG-CoSamP in terms of both recovery signal-to-noise ratio and time taken to estimate the integral image, at all measurement rates. }\n\t\t\t\\label{tb:RSNR}\n        \\end{table*}\n\t\tThe average RSNR for recovered integral image estimates as well as the time taken to obtain integral images are tabulated in the table \\ref{tb:RSNR}. Our framework outperforms RG-CoSamP in terms of both recovery signal-to-noise ratio and time taken to estimate the integral image, at all measurement rates. This shows that {\\bf ReFInE} $\\phi$, the measurement matrices designed by our framework, facilitate faster and more accurate recovery of integral image estimates than the universal matrices. The average time taken to obtain integral image estimates in our framework is about 0.003s, which amounts to a real-time speed of ~300 FPS. Further, we randomly select four images (`Two Men', `Plane', `Train' and `Room') from the test set (shown in figure \\ref{fig:twomen}, \\ref{fig:plane}, \\ref{fig:train}, \\ref{fig:room}) and present qualitative and quantitative results for individual images.   \n\t\t\\begin{figure*}\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_1.pdf}\n\t\t\t\t\\label{fig:twomen}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_2.pdf}\n\t\t\t\t\\label{fig:plane}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_3.pdf}\n\t\t\t\t\\label{fig:train}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_4.pdf}\n\t\t\t\t\\label{fig:room}\n\t\t\t}\n\t\t\t\\vspace{0.5cm}\n\t\t\t\\caption{(Four images (L-R: `Two Men', `Plane', `Train' and `Room') are randomly chosen for presenting qualitative and quantitative results.}\n\t\t\\end{figure*}\n\t\tImage-wise RSNR v/s measurement rate plots are shown in figure \\ref{fig:Integral}. It is very clear that for all the four images, our framework clearly outperforms RG-CoSamP in terms of RSNR, at all measurement rates.\n\t\t\n\t\t\\begin{figure*}\n            \\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/two_men.pdf}\n\t\t\t\t\\label{fig:subfig11}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/plane.pdf}\n\t\t\t\t\\label{fig:subfig12}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/train.pdf}\n\t\t\t\t\\label{fig:subfig13}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/room.pdf}\n\t\t\t\t\\label{fig:subfig14}\n\t\t\t}\n\t\t\t\\caption{The figure shows variation of image-wise RSNR for recovered integral image estimates for the four images. It is very clear that for all the four images, our framework outperforms `RG-CoSamP' in terms of RSNR, at all measurement rates.}\n\t\t\t\\label{fig:Integral}\n\t\t\\end{figure*}\n\t\t\n        \\noindent\n\t\t\\par{{\\bf Estimation of box-filtered outputs:}}\n\t\tIt is well known that box-filtered outputs of any size can efficiently computed using integral images \\cite{viola2004robust}. To show the capability of our framework in recovering good quality box-filtered output estimates, we conduct the following experiment. For box filters of sizes $3 \\times 3$, $5 \\times 5$ and $7 \\times 7$, we compute the estimates of filtered outputs for the four images using their respective recovered integral image estimates. RSNR v/s measurement rate plots for different filter sizes are shown in figure \\ref{fig:PSNR1}. \n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_1.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_2.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_3.pdf}\n\t\t\t\t\\label{fig:subfig3}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_4.pdf}\n\t\t\t\t\\label{fig:subfig4}\n\t\t\t}\n\t\t\t\\caption{\\small{The figure shows the variation of  RSNR for the recovered box-filtered outputs using {\\bf ReFInE} with measurement rate. It is evident that even for 1\\% measurement rate, we obtain high RSNR box-filtered outputs. For a fixed measurement rate, the RSNR increases with the size of the filter. This shows the structures global in nature are captured better. This is particularly true in the case of `Plane' image. The high RSNR for this image hints at the absence of fine structures and homogeneous background.}}\n\t\t\t\\label{fig:PSNR1}\n\t\t\t\n\t\t\\end{figure*}\n\t\tIt is evident that even for a remarkably low measurement rate of 1\\% , we obtain high RSNR box-filtered outputs. For a fixed measurement rate, expectedly the RSNR increases with the size of the filter. This shows the structures which are more global in nature are captured better. This is particularly true in the case of `Plane' image. The high RSNR for this image hints at the absence of fine structures and homogeneous background. \n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[$3 \\times 3$]{\\includegraphics[height=9em,width=40em]{figures/box_1.pdf}\n\t\t\t\t\n\t\t\t\t\\label{fig:subfig5}\n\t\t\t} \\\\\n\n\t\t\t\\subfigure[$7 \\times 7$]{\\includegraphics[height=9em,width=40em]{figures/box_2.pdf}\n\t\t\t\t\\label{fig:subfig6}\n\t\t\t}\n\t\t\t\\caption{\\small{Heat maps for box-filtered outputs for the `Two men' image. Left to right: Exact output, {\\bf ReFInE} (m/n = 0.01), and RG-CosamP (m/n = 0.01). It is clear that greater quality box-filtered output estimates can be recovered from {\\bf ReFInE} measurements and the  recovered outputs retain the information regarding medium-sized structures in the images, while in case of RG-CoSamP, the output is all noisy and does not give us any information.}}\n\n\t\t\t\\label{fig:Box3}\n\t\t\\end{figure*}\n\t\tFurther, for the `Two Men' Image, we also compare the heat maps of the exact box-filtered outputs with the estimated ones. We fix the measurement rate to 1\\%. For filter sizes $3 \\times 3$ and $7 \\times 7$, the exact box-filtered outputs are computed and compared with the box-filtered output estimates obtained using our framework, and RG-CoSamP as well. The heat map visualizations of the outputs are shown in figure \\ref{fig:Box3}. It is clear that greater quality box-filtered output estimates can be recovered using our framework and the  recovered outputs retain the information regarding medium-sized structures in the images, while in the case of RG-CoSamP, the output is all noisy and does not give us any information. \n        \n\n\t\t\\section{Tracking Application}\n\t\tIn this section, we show the utility of the framework in practical applications. In particular, we show tracking results on 50 challenging videos used in benchmark comparison of tracking algorithms \\cite{wu2013online}. We emphasize that our aim is not to obtain state-of-the-art tracking results but to show that integral image estimates can be used to obtain robust tracking results at low measurement rates. To this end, we conduct two sets of tracking experiments, one with original resolution videos and one with high definition videos. \n\t\t\\par{{\\bf Tracking with original resolution videos:}}\n\t\tWe conduct tracking experiments on original resolution videos at three different measurement rates, viz 1.28\\%, 1\\%, and 0.49\\%. In each case, we use the measurement matrix obtained for block size of $32 \\times 32$, and obtain {\\bf ReFInE} measurements for each frame using the $\\phi^{*}$ obtained as above. Once, the measurements are obtained, our framework recovers integral image estimates from these measurements in real time. The estimates are subsequently fed into the best performing Haar-feature based tracking algorithm, Struck \\cite{hare2011struck} to obtain the tracking results. Henceforth, we term this tracking pipeline as {\\bf ReFInE+Struck}. To evaluate our tracking results, we use the standard criterion of precision curve as suggested by \\cite{wu2013online}. To obtain the precision curve, we plot the precision scores against a range of thresholds. A frame contributes to the precision score for a particular threshold, $\\alpha$ if the distance between the ground truth location of the target and estimated location by the tracker is less than the threshold, $\\alpha$. Precision score for given threshold is calculated as the percentage of frames which contribute to the precision score. When precision scores are required to be compared with other trackers at one particular threshold, generally threshold is chosen to be equal to 20 pixels \\cite{wu2013online}.\n\t\t\\par{{\\bf Precision curve:}} \n\t\tThe precision curves for our framework at the three different measurement rates are plotted against a wide range of location error thresholds, and are compared with the same for other trackers, Oracle Struck \\cite{hare2011struck}, and various other trackers, TLD \\cite{kalal2010pn}, MIL \\cite{babenko2011robust}, CSK \\cite{henriques2012exploiting}, and FCT \\cite{zhang2014fast} in figure \\ref{fig:pre_all}.  It is to be noted all the trackers used for comparison utilize full-blown images for tracking and hence operate at 100\\% measurement rate.  As can be seen clearly, `ReFInE+Struck' at 1.28\\% performs better than other trackers, MIL, CSK, TLD, and FCT and only a few percentage points worse than Oracle Struck for all thresholds. In particular, the mean precision over all 50 sequences in the dataset \\cite{wu2013online} for the threshold of 20 pixels is obtained for `ReFInE+Struck' at three different measurement rates and is compared with other trackers in table \\ref{tb:Precision_or_resol}. We obtain a precision of 59.26\\% at a measurement of 1.28\\%, which is only a few percentage points less than precision of 65.5\\% using Oracle Struck and 60.8\\% using TLD. Even at an extremely low measurement rate of 0.49\\%, we obtain mean precision of 45.78\\% which is competitive when compared to other trackers, MIL, and FCT which operate at 100\\% measurement rate. This clearly suggests that the small number of well-tailored measurements obtained using our framework retain enough information regarding integral images and hence also the Haar-like features which play a critical role in achieving tracking with high precision. \n\t\t\\par{{\\bf Frame rate:}}\n\t\tEven though, our framework uses Struck tracker, the frame rates at which `ReFInE+Struck' operates are potentially less than the frame rate that can be obtained with Oracle Struck, and can even be different at different measurement rates. This is due to the fact that once the measurements are obtained for a particular frame, we first have to obtain an intermediate reconstructed frame before applying the integral operation. However, in the case of Oracle Struck, the integral operation is applied directly on the measured frame. The frame rate for `Our+Struck' at different measurement rates are compared with the frame rates for other trackers in table \\ref{tb:Precision_or_resol}. However, as can be seen, the preprocessing operation to obtain the intermediate reconstructed frame barely affects the speed of tracking since the preprocessing step, being multiplication of small-sized matrices can be efficiently at nearly 1000 frames per second.         \n\t\t   \n\t\t   \n\t\t   \\begin{figure}[ht!]\n\t\t   \t\\centering\n\t\t   \t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_All.pdf}\n\t\t   \t\t\\label{fig:subfig1}\n\t\t   \t}\n\t\t   \t\n\t\t   \t\\caption{\\small{ `ReFInE+Struck' at a measurement rate of 1.28\\% performs better than other trackers, MIL, CSK, TLD, and FCT and only a few percentage points worse than Oracle Struck for all thresholds. Even at a measurement rate of 1\\%, `ReFInE+Struck' performs nearly as well as TLD and CSK trackers which operate at 100\\% measurement rate.}}\n\t\t   \t\\label{fig:pre_all}\n\t\t   \\end{figure}\n\n\n\t\t\n\t\t\t\n\t     \\begin{table}\n\t\t\t\t\\begin{tabular}{|l|l|l|}\n\t\t\t\t\t\\hline\n\t\t\t\t\tTracker & Mean Precision & Mean FPS  \\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 1.28\\% + Struck & 59.26 & 19.61\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 1\\% + Struck & 52.47 & 19.61\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 0.49\\% + Struck & 45.78 & 19.62\\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tOracle Struck \\cite{hare2011struck} &  65.5 & 20\\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tTLD \\cite{kalal2010pn} & 60.8 & 28 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tCSK \\cite{henriques2012exploiting} &  54.11 & 362 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tMIL \\cite{babenko2011robust}  & 47.5 & 38 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tFCT \\cite{zhang2014fast} & 42.37 & 34.92\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\\end{tabular}\n\t\t\t\t\\caption{\\small{Mean precision percentage for 20 pixels error and mean frames per second for various state-of-the-art trackers are compared with our framework at different measurement rates. The precision percentages for our framework are stable even at extremely low measurement rates, and compare favorably with other trackers which operate at 100\\% measurement rate, i.e utilize all the pixels in the frames.}}\t\n\t\t\t\t\\label{tb:Precision_or_resol}\n\t\t\t\\end{table}\n\t\t\n\t\t\n\t\t\n\t\t\n\n\t\t\n\t\t\n\t\\par{{\\bf Experiments with sequence attributes:}}\n\tEach video sequence in the benchmark dataset is annotated with a set of attributes, indicating the various challenges the video sequence offers in tracking. We plot precision percentages against the location error threshold for each of these 10 different kinds of attributes. Figure \\ref{fig:pre_ill_bac_occ_sca} shows the corresponding plots for attributes, `Illumination Variation', `Background Clutter', `Occlusion', and `Scale Variation'.  In the case of `Illumination Variation' and `Occlusion' `Our+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of the `Background Clutter' and `Scale Variation' attributes, TLD performs slightly better than `Our+Struck' at measurement rate of 1.28\\%.\n\t\n\t\t\n\t\t\n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Ill.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\hspace{0.4cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Bac.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t\t\t\\\\\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Occ.pdf}\n\t\t\t\t\\label{fig:subfig3}\n\t\t\t}\n\t\t\t\\hspace{0.4cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Sca.pdf}\n\t\t\t\t\\label{fig:subfig4}\n\t\t\t}\n\t\t\t\\caption{\\small{Precision plots for four different attributes. In the case of `Illumination Variation' and `Occlusion' `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of the `Background Clutter' and `Scale Variation' attributes, TLD performs slightly better than `ReFInE+Struck' at measurement rate of 1.28\\%.}}\n\t\t\t\\label{fig:pre_ill_bac_occ_sca}\n\t\t\t\n\t\t\\end{figure*}\n\t\n\t\n\t\n\t\n\t\nFigure \\ref{fig:pre_def_fm_mb_lr} shows the corresponding plots for attributes, `Deformation', `Fast Motion', `Motion Blur', and `Low Resolution'. In the cases of  `Deformation', `Fast Motion' and `Motion Blur', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Low Resolution', TLD performs better than `ReFInE+Struck'.\n\n\\begin{figure*}[ht!]\n\t\\centering\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Def.pdf}\n\t\t\\label{fig:subfig1}\n\t}\n\t\\hspace{0.4cm}\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Fas.pdf}\n\t\t\\label{fig:subfig2}\n\t}\n\t\\\\\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Mot.pdf}\n\t\t\\label{fig:subfig3}\n\t}\n\t\\hspace{0.4cm}\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Low.pdf}\n\t\t\\label{fig:subfig4}\n\t}\n\t\\caption{\\small{Precision plots for four different attributes. In the cases of  `Deformation', `Fast Motion' and `Motion Blur', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Low Resolution', TLD performs better than `ReFInE+Struck'.}}\n\t\\label{fig:pre_def_fm_mb_lr}\n\\end{figure*}\n\nFigure \\ref{fig:pre_in_out_opr} shows the corresponding plots for attributes, `In the Plane rotation', `Out of View', and `Out of Plane rotation'.  \n\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_In-.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\hspace{0.2cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_Out.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t     \t\\hspace{0.2cm}\n\t\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_OPR.pdf}\n\t\t\t\t\t\\label{fig:subfig2}\n\t\t\t\t}\n\t\t\t\\caption{\\small{Precision plots for three different attributes. In the cases of  `In the plane rotation', and `Out of plane rotation', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Out of View', TLD performs better than `ReFInE+Struck'. }}\n\t\t\t\\label{fig:pre_in_out_opr}\n\t\\end{figure*}\n\n\t\\par{{\\bf Tracking with high resolution videos:}} Tracking using high-resolution videos can potentially lead to improvement in performance due to availability of fine-grained information regarding the scene. However, in many applications, the deployment of  high-resolution sensors is severely limited by the lack of storage capacity. In such scenarios, it will be interesting to see if the small number of ReFInE measurements of high-resolution videos can yield better tracking performance than the full-blown low-resolution videos.    To conduct tracking experiments on high resolution videos, we first employ a deep convolutional network based image super resolution (SR) algorithm, SRCNN, \\cite{dong2014learning} to obtain high resolution frames of the 50 videos considered earlier in the section. The aspect ratio for all frames is maintained, and the upscaling factor for image super resolution is calculated such that the resolution of the longer dimension in the higher resolution frame is at least 1000 pixels. We found that upscale factors varies between 2 and 8 for various videos in the dataset. Once the high resolution videos are obtained, we proceed to obtain ReFInE measurements as before. We conduct tracking experiments at four different measurement rate (1\\%, 0.49\\%, 0.29\\%, 0.2\\%). Note that these different measurement rates are with respect to (wrt) the high-resolution frames, and the measurement rate wrt original resolution, which we call effective measurement rate (EMR), is given by the ratio of the number of ReFInE measurements per frame to the number of pixels in a frame of original resolution video. Here, the tracking algorithm, Struck which we used for original resolution videos does not scale well in terms of computational complexity. For higher resolution videos, where the search space is much larger, we found that Struck is too slow for real-time application. Instead, we use a faster Haar feature based tracking algorithm, FCT \\cite{zhang2014fast} algorithm. Henceforth, we dub this tracking pipeline as {\\bf SR+ReFInE+FCT}. Once tracking results are obtained for the high resolution videos are obtained, we normalize the coordinates so as to obtain the tracking outputs with respect to original resolution videos. The precision score is calculated as before. The mean precision percentage for 20 pixels error and mean frames per second for `SR + ReFIne + FCT' at various measurement rates are given in table \\ref{tb:Precision_hi_resol} and are compared for the same for `Oracle FCT' which operates for full-blown original resolution videos. It is clear that we obtain a significant boost in tracking accuracy for high resolution videos. At measurement rate of 1\\% (EMR of 8.16\\%), we obtain a mean precision percentage of 54.83, which is 12.46 percentage points more than that for `Oracle FCT'. Even at a measurement rate of 0.2\\% ((EMR of 1.63\\%)), the precision percentage of 45.79, which is about 3.42 percentage points more than that for `Oracle FCT'. However, the more accurate precision comes at the cost of frame rate. Since the search space is much larger for high resolution videos, the speed of tracking for high resolution videos, is only about 20 FPS, while `Oracle FCT' operates at 34.92 FPS. But 20 FPS suffices for near real-time implementations.\n    \n   \\begin{table}\n   \t\\begin{tabular}{|l|l|l|}\n   \t\t\\hline\n   \t\t\\scriptsize{Tracker} & \\scriptsize{Mean Precision} & \\scriptsize{Mean FPS}  \\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 8.16\\% + FCT} & 54.83 & 19.61\\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 4\\% + FCT} & 53.03 & 19.61\\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 2.37\\% + FCT} & 50.9 & 19.62\\\\\n   \t\t\\hline \n\\scriptsize{SR + ReFInE at EMR = 1.63\\% + FCT} & 45.79 & 19.62\\\\\n        \\hline\n\\scriptsize{Oracle FCT \\cite{zhang2014fast}} & 42.37 & 34.92\\\\\n       \\hline\n  \t\\end{tabular}\n   \t\\caption{\\small{Mean precision percentage for 20 pixels error and mean frames per second for `SR + ReFIne + FCT' at various measurement rates are compared with `Oracle FCT'. Even at extremely low measurement rates, the precision percentages for `SR + ReFIne + FCT' are better that for `Oracle FCT' which operates on full-blown original resolution images.}}\t\n   \t\\label{tb:Precision_hi_resol}\n   \\end{table}  \n\n\t\t\\section{Conclusions}\n\t\tIn this paper, we qualitatively and quantitatively showed that it is possible obtain high quality estimates of integral images and box-filtered outputs directly from a small number of specially designed spatially multiplexed measurements called {\\bf ReFInE} measurements. To show the practical applicability of the integral image estimates, we presented impressive reconstruction-free tracking results on challenging videos at an extremely low measurement rate of 1\\%. We also showed that with only a small number of {\\bf ReFInE} measurements on high-resolution videos, which is only a fraction (2-8\\%) of the size of the original resolution, one can obtain significantly better object tracking results than using full blown original resolution videos. From a philosophical point of view, this points to the possibility of attaining greater performance on other computer vision inference tasks from a small number of carefully tailored spatially multiplexed measurements of high-resolution imagery rather than full-blown low resolution imagery.\n\n\\begin{appendices}\n\\section{Derivation: rank({\\bf P}) = rank({\\bf Q}) - 1}\\label{app:rank}\nBy construction we have $(\\phi^d)^T = [{\\bf 1} | (\\phi^d)_{2:m}^T] = [{\\bf 1} | ({\\bf D} {\\bf U}_{2:n}^{T})^T]$. The column of all ones in $(\\phi^d)^T$ is orthogonal to remaining $m-1$ columns. Hence, we have $rank(\\phi_{2:m}^d) = rank(\\phi^d) - 1 = rank({\\bf Q}) - 1$. Similarly, we have $rank(\\phi_{2:m}) = rank(\\phi) - 1 = rank({\\bf Q}) - 1$. Since, ${\\bf P}$ is the product of equally ranked matrices, $(\\phi^d)_{2:m}^T$ and $\\phi$, it follows that  $rank({\\bf P}) = rank(\\phi^d_{2:m}) = rank({\\bf Q}) - 1$.  \n\\section{Calculation of $\\mathcal{A}_i^*({\\bf y_i}^{k-1})$}\\label{app:adjoint}\nFor brevity, we drop the superscript, $k - 1$. Let ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T = {\\bf\\Sigma}_{U}$. Consider the following equation.\n\n", "itemtype": "equation", "pos": -1, "prevtext": "    \nOnce the measurements, $y$ are obtained, the integral image, $\\hat{I}$ is given by \n\n", "index": 39, "text": "\\begin{equation}\n\\hat{I} = {\\bf H} \\begin{bmatrix}\n(\\phi^d_{f})^T & {\\bf 0} & \\cdots & {\\bf 0} \\\\\n{\\bf 0} &  (\\phi^d_{f})^T & \\cdots & {\\bf 0} \\\\\n\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n{\\bf 0} & {\\bf 0} & \\cdots &  (\\phi^d_{f})^T\n\\end{bmatrix} \t\\begin{bmatrix}\ny_1  \\\\\ny_2  \\\\\n\\vdots  \\\\\ny_B\n\\end{bmatrix}. \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\hat{I}={\\bf H}\\begin{bmatrix}(\\phi^{d}_{f})^{T}&amp;{\\bf 0}&amp;\\cdots&amp;{\\bf 0}\\\\&#10;{\\bf 0}&amp;(\\phi^{d}_{f})^{T}&amp;\\cdots&amp;{\\bf 0}\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;{\\bf 0}&amp;{\\bf 0}&amp;\\cdots&amp;(\\phi^{d}_{f})^{T}\\end{bmatrix}\\begin{bmatrix}y_{1}\\\\&#10;y_{2}\\\\&#10;\\vdots\\\\&#10;y_{B}\\end{bmatrix}.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>I</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mi>\ud835\udc07</mi><mo>\u2062</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03d5</mi><mi>f</mi><mi>d</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mtd><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mn/></mtd></mtr><mtr><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03d5</mi><mi>f</mi><mi>d</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><mn/></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mn/></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ef</mi></mtd><mtd columnalign=\"center\"><msup><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03d5</mi><mi>f</mi><mi>d</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup></mtd></mtr></mtable><mo>]</mo></mrow><mo>\u2062</mo><mrow><mo>[</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>y</mi><mi>B</mi></msub></mtd></mtr></mtable><mo>]</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": " The left hand side can be written as \n\n", "itemtype": "equation", "pos": -1, "prevtext": " \n\t\t\n\t\t\\section{Experiments}\n\n\t\tBefore we can conduct experiments to evaluate our framework, we first need to estimate the parameters of the probability model in \\ref{MGGD}.\n\t\tEstimating parameters of the probability model and optimizing measurement matrices for any arbitrary large sized image blocks is not practical since the former task requires an enormous amount of image data and the latter requires prohibitive amount of memory and computational resources. Hence, we fix the block size to be $32 \\times 32$ images. The scatter matrix ${\\bf \\Sigma}_{w_d}$ is a scalar multiple of the covariance matrix of $w_d$. Hence it suffices to compute the covariance matrix. To this end, we first downsample all the 5011 training images in PASCAL VOC 2007 dataset \\cite{pascal-voc-2007} to a size of $32 \\times 32$, so that $n$ = 1024 and then obtain the level 7 Daubechies wavelet coefficient vectors. We compute the sample covariance matrix of thus obtained wavelet coefficient data. For various values of $\\beta$, we evaluate the $\\chi^2$ distance between the histograms of the individual wavelet coefficients and their respective theoretical marginal distributions with the variances computed above. We found for $\\beta = 0.68$, the distance computed above is minimum.\n\n\t\t\\noindent\n\t\t\\par{{\\bf Computing measurement matrix:}} \n\t\tTo obtain a measurement matrix, we need to input a desired distortion vector $\\delta$ to the optimization problem in $(P2)$. The desired distortion vector is computed according to the following. We first perform principal component analysis (PCA) on the downsampled 5011 training images in the PASCAL VOC 2007 dataset \\cite{pascal-voc-2007}. We use only the top 10 PCA components as $\\phi$ to `sense' these images. We obtain the desired distortion vector by first assuming $\\phi^{d} = \\phi$ and calculating distortions, $|d^j_i|$ at each location for all training images, $j =1,..,5011$. Now, the entry in location $i$ of the desired ${\\bf \\delta}$ is given by the minimum value $\\alpha$, so that $95\\%$ of the values, $|d^j_i|, j =1,..,5011$ are less than $\\alpha$.  We use $\\epsilon =0.95$ and solve $(P2)$ to obtain ${\\bf P}^*$, and hence also ${\\bf Q}^*$. The rank of {\\bf ReFInE} $\\phi$ is simply the rank of ${\\bf Q}^*$. \n\t\t\n\t\t\n\t\n\t\t\n\t\t\n\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t\n\t\t\t\n\t\t\n\t\t\n\t\n\t\t\n\t\t\\noindent\n\t\t\\par{{\\bf Estimation of integral images:}}\n\t\tWe show that good quality estimates of integral images can be obtained using our framework. To this end, we first construct {\\bf ReFInE} measurement matrices of various ranks, $M$. We achieve this by considering the SVD of ${\\bf Q}^*$ obtained above. For a particular value of $M$, the {\\bf ReFInE} $\\phi$ is calculated according to $\\phi_{M} = {\\bf \\Sigma}_{M}^{1/2}{\\bf V}_M^{T}$, where ${\\bf \\Sigma}_M = diag\\{\\lambda_1,..,\\lambda_M\\}$ is a diagonal matrix with $M$ largest singular values arranged along the diagonal and ${\\bf V}_M^{T}$ denote the corresponding rows in ${\\bf V}^{T}$. Its dual, $\\phi^d$, is calculated similarly. For each particular measurement rate, determined by the value of $M$, the integral image estimates are recovered from $M$ {\\bf ReFInE} measurements for all the 4952 test images in the PASCAL VOC 2007 dataset \\cite{pascal-voc-2007}. Similarly integral image estimates are recovered from random Gaussian measurements by first performing non-linear iterative reconstruction using the CoSamP algorithm \\cite{needell2009cosamp} and then applying the integral operation on the reconstructed images. This pipeline is used as baseline to compare integral estimates, and henceforth is referred to as `RG-CoSamP'. We then measure the recovered signal-to-noise ratio (RSNR) via 20 $\\log_{10}\\left(\\frac{\\left\\lVert{\\hat{I}}\\right\\rVert_F}{\\left\\lVert{\\hat{I}-I}\\right\\rVert_F}\\right)$.\n\t\t\\begin{table*}\n\t\t\t\\centering\n\t\t\t{\\begin{tabular}{| l | l | l | l | l | l | l |}\n\t\t\t\t\t\\hline\n\t\t\t\t\tMethod & {\\bf ReFInE} & RG-CoSamP & {\\bf ReFInE} & RG-CoSamP &{\\bf ReFInE} & RG-CoSamP \\\\ \\hline\n\t\t\t\t\t$M$ (measurement ratio) & 20 (0.005) &  20 (0.005) & 40 (0.01) & 40 (0.01) & 60 (0.015) & 60 (0.015) \\\\ \\hline\n\t\t\t\t\tTime in s & 0.0034 & 0.38 & 0.0036 & 0.58 & 0.0031  & 0.97  \\\\ \\hline\n\t\t\t\t\tRSNR in dB & 38.95 & -16.76 & 38.96 & -11.22 & 38.96 & -10.9 \\\\ \\hline \n\t\t\t\t\\end{tabular}\n\t\t\t}\n\t\t\t\\caption{Comparison of average RSNR and time for recovered integral image estimates obtained using our method with RG-CoSamP. Our framework outperforms RG-CoSamP in terms of both recovery signal-to-noise ratio and time taken to estimate the integral image, at all measurement rates. }\n\t\t\t\\label{tb:RSNR}\n        \\end{table*}\n\t\tThe average RSNR for recovered integral image estimates as well as the time taken to obtain integral images are tabulated in the table \\ref{tb:RSNR}. Our framework outperforms RG-CoSamP in terms of both recovery signal-to-noise ratio and time taken to estimate the integral image, at all measurement rates. This shows that {\\bf ReFInE} $\\phi$, the measurement matrices designed by our framework, facilitate faster and more accurate recovery of integral image estimates than the universal matrices. The average time taken to obtain integral image estimates in our framework is about 0.003s, which amounts to a real-time speed of ~300 FPS. Further, we randomly select four images (`Two Men', `Plane', `Train' and `Room') from the test set (shown in figure \\ref{fig:twomen}, \\ref{fig:plane}, \\ref{fig:train}, \\ref{fig:room}) and present qualitative and quantitative results for individual images.   \n\t\t\\begin{figure*}\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_1.pdf}\n\t\t\t\t\\label{fig:twomen}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_2.pdf}\n\t\t\t\t\\label{fig:plane}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_3.pdf}\n\t\t\t\t\\label{fig:train}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=6em,width=8em]{figures/image_4.pdf}\n\t\t\t\t\\label{fig:room}\n\t\t\t}\n\t\t\t\\vspace{0.5cm}\n\t\t\t\\caption{(Four images (L-R: `Two Men', `Plane', `Train' and `Room') are randomly chosen for presenting qualitative and quantitative results.}\n\t\t\\end{figure*}\n\t\tImage-wise RSNR v/s measurement rate plots are shown in figure \\ref{fig:Integral}. It is very clear that for all the four images, our framework clearly outperforms RG-CoSamP in terms of RSNR, at all measurement rates.\n\t\t\n\t\t\\begin{figure*}\n            \\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/two_men.pdf}\n\t\t\t\t\\label{fig:subfig11}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/plane.pdf}\n\t\t\t\t\\label{fig:subfig12}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/train.pdf}\n\t\t\t\t\\label{fig:subfig13}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/room.pdf}\n\t\t\t\t\\label{fig:subfig14}\n\t\t\t}\n\t\t\t\\caption{The figure shows variation of image-wise RSNR for recovered integral image estimates for the four images. It is very clear that for all the four images, our framework outperforms `RG-CoSamP' in terms of RSNR, at all measurement rates.}\n\t\t\t\\label{fig:Integral}\n\t\t\\end{figure*}\n\t\t\n        \\noindent\n\t\t\\par{{\\bf Estimation of box-filtered outputs:}}\n\t\tIt is well known that box-filtered outputs of any size can efficiently computed using integral images \\cite{viola2004robust}. To show the capability of our framework in recovering good quality box-filtered output estimates, we conduct the following experiment. For box filters of sizes $3 \\times 3$, $5 \\times 5$ and $7 \\times 7$, we compute the estimates of filtered outputs for the four images using their respective recovered integral image estimates. RSNR v/s measurement rate plots for different filter sizes are shown in figure \\ref{fig:PSNR1}. \n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_1.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_2.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_3.pdf}\n\t\t\t\t\\label{fig:subfig3}\n\t\t\t}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=20em]{figures/PSNR_4.pdf}\n\t\t\t\t\\label{fig:subfig4}\n\t\t\t}\n\t\t\t\\caption{\\small{The figure shows the variation of  RSNR for the recovered box-filtered outputs using {\\bf ReFInE} with measurement rate. It is evident that even for 1\\% measurement rate, we obtain high RSNR box-filtered outputs. For a fixed measurement rate, the RSNR increases with the size of the filter. This shows the structures global in nature are captured better. This is particularly true in the case of `Plane' image. The high RSNR for this image hints at the absence of fine structures and homogeneous background.}}\n\t\t\t\\label{fig:PSNR1}\n\t\t\t\n\t\t\\end{figure*}\n\t\tIt is evident that even for a remarkably low measurement rate of 1\\% , we obtain high RSNR box-filtered outputs. For a fixed measurement rate, expectedly the RSNR increases with the size of the filter. This shows the structures which are more global in nature are captured better. This is particularly true in the case of `Plane' image. The high RSNR for this image hints at the absence of fine structures and homogeneous background. \n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[$3 \\times 3$]{\\includegraphics[height=9em,width=40em]{figures/box_1.pdf}\n\t\t\t\t\n\t\t\t\t\\label{fig:subfig5}\n\t\t\t} \\\\\n\n\t\t\t\\subfigure[$7 \\times 7$]{\\includegraphics[height=9em,width=40em]{figures/box_2.pdf}\n\t\t\t\t\\label{fig:subfig6}\n\t\t\t}\n\t\t\t\\caption{\\small{Heat maps for box-filtered outputs for the `Two men' image. Left to right: Exact output, {\\bf ReFInE} (m/n = 0.01), and RG-CosamP (m/n = 0.01). It is clear that greater quality box-filtered output estimates can be recovered from {\\bf ReFInE} measurements and the  recovered outputs retain the information regarding medium-sized structures in the images, while in case of RG-CoSamP, the output is all noisy and does not give us any information.}}\n\n\t\t\t\\label{fig:Box3}\n\t\t\\end{figure*}\n\t\tFurther, for the `Two Men' Image, we also compare the heat maps of the exact box-filtered outputs with the estimated ones. We fix the measurement rate to 1\\%. For filter sizes $3 \\times 3$ and $7 \\times 7$, the exact box-filtered outputs are computed and compared with the box-filtered output estimates obtained using our framework, and RG-CoSamP as well. The heat map visualizations of the outputs are shown in figure \\ref{fig:Box3}. It is clear that greater quality box-filtered output estimates can be recovered using our framework and the  recovered outputs retain the information regarding medium-sized structures in the images, while in the case of RG-CoSamP, the output is all noisy and does not give us any information. \n        \n\n\t\t\\section{Tracking Application}\n\t\tIn this section, we show the utility of the framework in practical applications. In particular, we show tracking results on 50 challenging videos used in benchmark comparison of tracking algorithms \\cite{wu2013online}. We emphasize that our aim is not to obtain state-of-the-art tracking results but to show that integral image estimates can be used to obtain robust tracking results at low measurement rates. To this end, we conduct two sets of tracking experiments, one with original resolution videos and one with high definition videos. \n\t\t\\par{{\\bf Tracking with original resolution videos:}}\n\t\tWe conduct tracking experiments on original resolution videos at three different measurement rates, viz 1.28\\%, 1\\%, and 0.49\\%. In each case, we use the measurement matrix obtained for block size of $32 \\times 32$, and obtain {\\bf ReFInE} measurements for each frame using the $\\phi^{*}$ obtained as above. Once, the measurements are obtained, our framework recovers integral image estimates from these measurements in real time. The estimates are subsequently fed into the best performing Haar-feature based tracking algorithm, Struck \\cite{hare2011struck} to obtain the tracking results. Henceforth, we term this tracking pipeline as {\\bf ReFInE+Struck}. To evaluate our tracking results, we use the standard criterion of precision curve as suggested by \\cite{wu2013online}. To obtain the precision curve, we plot the precision scores against a range of thresholds. A frame contributes to the precision score for a particular threshold, $\\alpha$ if the distance between the ground truth location of the target and estimated location by the tracker is less than the threshold, $\\alpha$. Precision score for given threshold is calculated as the percentage of frames which contribute to the precision score. When precision scores are required to be compared with other trackers at one particular threshold, generally threshold is chosen to be equal to 20 pixels \\cite{wu2013online}.\n\t\t\\par{{\\bf Precision curve:}} \n\t\tThe precision curves for our framework at the three different measurement rates are plotted against a wide range of location error thresholds, and are compared with the same for other trackers, Oracle Struck \\cite{hare2011struck}, and various other trackers, TLD \\cite{kalal2010pn}, MIL \\cite{babenko2011robust}, CSK \\cite{henriques2012exploiting}, and FCT \\cite{zhang2014fast} in figure \\ref{fig:pre_all}.  It is to be noted all the trackers used for comparison utilize full-blown images for tracking and hence operate at 100\\% measurement rate.  As can be seen clearly, `ReFInE+Struck' at 1.28\\% performs better than other trackers, MIL, CSK, TLD, and FCT and only a few percentage points worse than Oracle Struck for all thresholds. In particular, the mean precision over all 50 sequences in the dataset \\cite{wu2013online} for the threshold of 20 pixels is obtained for `ReFInE+Struck' at three different measurement rates and is compared with other trackers in table \\ref{tb:Precision_or_resol}. We obtain a precision of 59.26\\% at a measurement of 1.28\\%, which is only a few percentage points less than precision of 65.5\\% using Oracle Struck and 60.8\\% using TLD. Even at an extremely low measurement rate of 0.49\\%, we obtain mean precision of 45.78\\% which is competitive when compared to other trackers, MIL, and FCT which operate at 100\\% measurement rate. This clearly suggests that the small number of well-tailored measurements obtained using our framework retain enough information regarding integral images and hence also the Haar-like features which play a critical role in achieving tracking with high precision. \n\t\t\\par{{\\bf Frame rate:}}\n\t\tEven though, our framework uses Struck tracker, the frame rates at which `ReFInE+Struck' operates are potentially less than the frame rate that can be obtained with Oracle Struck, and can even be different at different measurement rates. This is due to the fact that once the measurements are obtained for a particular frame, we first have to obtain an intermediate reconstructed frame before applying the integral operation. However, in the case of Oracle Struck, the integral operation is applied directly on the measured frame. The frame rate for `Our+Struck' at different measurement rates are compared with the frame rates for other trackers in table \\ref{tb:Precision_or_resol}. However, as can be seen, the preprocessing operation to obtain the intermediate reconstructed frame barely affects the speed of tracking since the preprocessing step, being multiplication of small-sized matrices can be efficiently at nearly 1000 frames per second.         \n\t\t   \n\t\t   \n\t\t   \\begin{figure}[ht!]\n\t\t   \t\\centering\n\t\t   \t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_All.pdf}\n\t\t   \t\t\\label{fig:subfig1}\n\t\t   \t}\n\t\t   \t\n\t\t   \t\\caption{\\small{ `ReFInE+Struck' at a measurement rate of 1.28\\% performs better than other trackers, MIL, CSK, TLD, and FCT and only a few percentage points worse than Oracle Struck for all thresholds. Even at a measurement rate of 1\\%, `ReFInE+Struck' performs nearly as well as TLD and CSK trackers which operate at 100\\% measurement rate.}}\n\t\t   \t\\label{fig:pre_all}\n\t\t   \\end{figure}\n\n\n\t\t\n\t\t\t\n\t     \\begin{table}\n\t\t\t\t\\begin{tabular}{|l|l|l|}\n\t\t\t\t\t\\hline\n\t\t\t\t\tTracker & Mean Precision & Mean FPS  \\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 1.28\\% + Struck & 59.26 & 19.61\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 1\\% + Struck & 52.47 & 19.61\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\tReFInE at MR = 0.49\\% + Struck & 45.78 & 19.62\\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tOracle Struck \\cite{hare2011struck} &  65.5 & 20\\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tTLD \\cite{kalal2010pn} & 60.8 & 28 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tCSK \\cite{henriques2012exploiting} &  54.11 & 362 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tMIL \\cite{babenko2011robust}  & 47.5 & 38 \\\\\n\t\t\t\t\t\\hline \n\t\t\t\t\tFCT \\cite{zhang2014fast} & 42.37 & 34.92\\\\\n\t\t\t\t\t\\hline\n\t\t\t\t\\end{tabular}\n\t\t\t\t\\caption{\\small{Mean precision percentage for 20 pixels error and mean frames per second for various state-of-the-art trackers are compared with our framework at different measurement rates. The precision percentages for our framework are stable even at extremely low measurement rates, and compare favorably with other trackers which operate at 100\\% measurement rate, i.e utilize all the pixels in the frames.}}\t\n\t\t\t\t\\label{tb:Precision_or_resol}\n\t\t\t\\end{table}\n\t\t\n\t\t\n\t\t\n\t\t\n\n\t\t\n\t\t\n\t\\par{{\\bf Experiments with sequence attributes:}}\n\tEach video sequence in the benchmark dataset is annotated with a set of attributes, indicating the various challenges the video sequence offers in tracking. We plot precision percentages against the location error threshold for each of these 10 different kinds of attributes. Figure \\ref{fig:pre_ill_bac_occ_sca} shows the corresponding plots for attributes, `Illumination Variation', `Background Clutter', `Occlusion', and `Scale Variation'.  In the case of `Illumination Variation' and `Occlusion' `Our+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of the `Background Clutter' and `Scale Variation' attributes, TLD performs slightly better than `Our+Struck' at measurement rate of 1.28\\%.\n\t\n\t\t\n\t\t\n\t\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Ill.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\hspace{0.4cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Bac.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t\t\t\\\\\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Occ.pdf}\n\t\t\t\t\\label{fig:subfig3}\n\t\t\t}\n\t\t\t\\hspace{0.4cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Sca.pdf}\n\t\t\t\t\\label{fig:subfig4}\n\t\t\t}\n\t\t\t\\caption{\\small{Precision plots for four different attributes. In the case of `Illumination Variation' and `Occlusion' `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of the `Background Clutter' and `Scale Variation' attributes, TLD performs slightly better than `ReFInE+Struck' at measurement rate of 1.28\\%.}}\n\t\t\t\\label{fig:pre_ill_bac_occ_sca}\n\t\t\t\n\t\t\\end{figure*}\n\t\n\t\n\t\n\t\n\t\nFigure \\ref{fig:pre_def_fm_mb_lr} shows the corresponding plots for attributes, `Deformation', `Fast Motion', `Motion Blur', and `Low Resolution'. In the cases of  `Deformation', `Fast Motion' and `Motion Blur', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Low Resolution', TLD performs better than `ReFInE+Struck'.\n\n\\begin{figure*}[ht!]\n\t\\centering\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Def.pdf}\n\t\t\\label{fig:subfig1}\n\t}\n\t\\hspace{0.4cm}\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Fas.pdf}\n\t\t\\label{fig:subfig2}\n\t}\n\t\\\\\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Mot.pdf}\n\t\t\\label{fig:subfig3}\n\t}\n\t\\hspace{0.4cm}\n\t\\subfigure[]{\\includegraphics[height=17em,width=20em]{figures/Precision_Low.pdf}\n\t\t\\label{fig:subfig4}\n\t}\n\t\\caption{\\small{Precision plots for four different attributes. In the cases of  `Deformation', `Fast Motion' and `Motion Blur', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Low Resolution', TLD performs better than `ReFInE+Struck'.}}\n\t\\label{fig:pre_def_fm_mb_lr}\n\\end{figure*}\n\nFigure \\ref{fig:pre_in_out_opr} shows the corresponding plots for attributes, `In the Plane rotation', `Out of View', and `Out of Plane rotation'.  \n\t\\begin{figure*}[ht!]\n\t\t\t\\centering\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_In-.pdf}\n\t\t\t\t\\label{fig:subfig1}\n\t\t\t}\n\t\t\t\\hspace{0.2cm}\n\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_Out.pdf}\n\t\t\t\t\\label{fig:subfig2}\n\t\t\t}\n\t     \t\\hspace{0.2cm}\n\t\t\t\t\\subfigure[]{\\includegraphics[height=14em,width=15em]{figures/Precision_OPR.pdf}\n\t\t\t\t\t\\label{fig:subfig2}\n\t\t\t\t}\n\t\t\t\\caption{\\small{Precision plots for three different attributes. In the cases of  `In the plane rotation', and `Out of plane rotation', `ReFInE+Struck' at measurement rate of 1.28\\% performs better than TLD, CSK, MIL and FCT, whereas in the case of `Out of View', TLD performs better than `ReFInE+Struck'. }}\n\t\t\t\\label{fig:pre_in_out_opr}\n\t\\end{figure*}\n\n\t\\par{{\\bf Tracking with high resolution videos:}} Tracking using high-resolution videos can potentially lead to improvement in performance due to availability of fine-grained information regarding the scene. However, in many applications, the deployment of  high-resolution sensors is severely limited by the lack of storage capacity. In such scenarios, it will be interesting to see if the small number of ReFInE measurements of high-resolution videos can yield better tracking performance than the full-blown low-resolution videos.    To conduct tracking experiments on high resolution videos, we first employ a deep convolutional network based image super resolution (SR) algorithm, SRCNN, \\cite{dong2014learning} to obtain high resolution frames of the 50 videos considered earlier in the section. The aspect ratio for all frames is maintained, and the upscaling factor for image super resolution is calculated such that the resolution of the longer dimension in the higher resolution frame is at least 1000 pixels. We found that upscale factors varies between 2 and 8 for various videos in the dataset. Once the high resolution videos are obtained, we proceed to obtain ReFInE measurements as before. We conduct tracking experiments at four different measurement rate (1\\%, 0.49\\%, 0.29\\%, 0.2\\%). Note that these different measurement rates are with respect to (wrt) the high-resolution frames, and the measurement rate wrt original resolution, which we call effective measurement rate (EMR), is given by the ratio of the number of ReFInE measurements per frame to the number of pixels in a frame of original resolution video. Here, the tracking algorithm, Struck which we used for original resolution videos does not scale well in terms of computational complexity. For higher resolution videos, where the search space is much larger, we found that Struck is too slow for real-time application. Instead, we use a faster Haar feature based tracking algorithm, FCT \\cite{zhang2014fast} algorithm. Henceforth, we dub this tracking pipeline as {\\bf SR+ReFInE+FCT}. Once tracking results are obtained for the high resolution videos are obtained, we normalize the coordinates so as to obtain the tracking outputs with respect to original resolution videos. The precision score is calculated as before. The mean precision percentage for 20 pixels error and mean frames per second for `SR + ReFIne + FCT' at various measurement rates are given in table \\ref{tb:Precision_hi_resol} and are compared for the same for `Oracle FCT' which operates for full-blown original resolution videos. It is clear that we obtain a significant boost in tracking accuracy for high resolution videos. At measurement rate of 1\\% (EMR of 8.16\\%), we obtain a mean precision percentage of 54.83, which is 12.46 percentage points more than that for `Oracle FCT'. Even at a measurement rate of 0.2\\% ((EMR of 1.63\\%)), the precision percentage of 45.79, which is about 3.42 percentage points more than that for `Oracle FCT'. However, the more accurate precision comes at the cost of frame rate. Since the search space is much larger for high resolution videos, the speed of tracking for high resolution videos, is only about 20 FPS, while `Oracle FCT' operates at 34.92 FPS. But 20 FPS suffices for near real-time implementations.\n    \n   \\begin{table}\n   \t\\begin{tabular}{|l|l|l|}\n   \t\t\\hline\n   \t\t\\scriptsize{Tracker} & \\scriptsize{Mean Precision} & \\scriptsize{Mean FPS}  \\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 8.16\\% + FCT} & 54.83 & 19.61\\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 4\\% + FCT} & 53.03 & 19.61\\\\\n   \t\t\\hline\n   \t\\scriptsize{SR + ReFInE at EMR = 2.37\\% + FCT} & 50.9 & 19.62\\\\\n   \t\t\\hline \n\\scriptsize{SR + ReFInE at EMR = 1.63\\% + FCT} & 45.79 & 19.62\\\\\n        \\hline\n\\scriptsize{Oracle FCT \\cite{zhang2014fast}} & 42.37 & 34.92\\\\\n       \\hline\n  \t\\end{tabular}\n   \t\\caption{\\small{Mean precision percentage for 20 pixels error and mean frames per second for `SR + ReFIne + FCT' at various measurement rates are compared with `Oracle FCT'. Even at extremely low measurement rates, the precision percentages for `SR + ReFIne + FCT' are better that for `Oracle FCT' which operates on full-blown original resolution images.}}\t\n   \t\\label{tb:Precision_hi_resol}\n   \\end{table}  \n\n\t\t\\section{Conclusions}\n\t\tIn this paper, we qualitatively and quantitatively showed that it is possible obtain high quality estimates of integral images and box-filtered outputs directly from a small number of specially designed spatially multiplexed measurements called {\\bf ReFInE} measurements. To show the practical applicability of the integral image estimates, we presented impressive reconstruction-free tracking results on challenging videos at an extremely low measurement rate of 1\\%. We also showed that with only a small number of {\\bf ReFInE} measurements on high-resolution videos, which is only a fraction (2-8\\%) of the size of the original resolution, one can obtain significantly better object tracking results than using full blown original resolution videos. From a philosophical point of view, this points to the possibility of attaining greater performance on other computer vision inference tasks from a small number of carefully tailored spatially multiplexed measurements of high-resolution imagery rather than full-blown low resolution imagery.\n\n\\begin{appendices}\n\\section{Derivation: rank({\\bf P}) = rank({\\bf Q}) - 1}\\label{app:rank}\nBy construction we have $(\\phi^d)^T = [{\\bf 1} | (\\phi^d)_{2:m}^T] = [{\\bf 1} | ({\\bf D} {\\bf U}_{2:n}^{T})^T]$. The column of all ones in $(\\phi^d)^T$ is orthogonal to remaining $m-1$ columns. Hence, we have $rank(\\phi_{2:m}^d) = rank(\\phi^d) - 1 = rank({\\bf Q}) - 1$. Similarly, we have $rank(\\phi_{2:m}) = rank(\\phi) - 1 = rank({\\bf Q}) - 1$. Since, ${\\bf P}$ is the product of equally ranked matrices, $(\\phi^d)_{2:m}^T$ and $\\phi$, it follows that  $rank({\\bf P}) = rank(\\phi^d_{2:m}) = rank({\\bf Q}) - 1$.  \n\\section{Calculation of $\\mathcal{A}_i^*({\\bf y_i}^{k-1})$}\\label{app:adjoint}\nFor brevity, we drop the superscript, $k - 1$. Let ${\\bf \\Sigma}^{1/2}_{w_d}{\\bf U}_{2:n}^T = {\\bf\\Sigma}_{U}$. Consider the following equation.\n\n", "index": 41, "text": "\\begin{equation}\n \\langle \\mathcal{A}({\\bf P}), {\\bf y} \\rangle = \\sum_{i=1}^{n}\\langle {\\bf P} , \\mathcal{A}_i^*({ {\\bf y_i}}) \\rangle.\n\\label{eq:calcA1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\langle\\mathcal{A}({\\bf P}),{\\bf y}\\rangle=\\sum_{i=1}^{n}\\langle{\\bf P},%&#10;\\mathcal{A}_{i}^{*}({{\\bf y_{i}}})\\rangle.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>i</mi><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07258.tex", "nexttext": "\nComparing the equations \\ref{eq:calcA1} and \\ref{eq:calcA2}, we have $\\mathcal{A}_i^*({\\bf y_i}) = {\\bf\\Sigma}_U^T {\\bf y_i} h_i^T$.    \n\n\\end{appendices}\n\t\t\n\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\\ifCLASSOPTIONcompsoc\n\t\t\n\t\t\\section*{Acknowledgments}\n\t\t\\else\n\t\t\n\t\t\\section*{Acknowledgment}\n\t\t\\fi\n\t\t\n\n\t\t\n\t\t\n\t\t\n\t\t\\ifCLASSOPTIONcaptionsoff\n\t\t\\newpage\n\t\t\\fi\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\\bibliographystyle{IEEEtran}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\\bibliography{PAMI_STSF_3}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\\begin{IEEEbiography}{Kuldeep Kulkarni}\n\t\t\t\n\t\t\\end{IEEEbiography}\n\t\t\n\t\t\\begin{IEEEbiography}{Pavan Turaga}\n\t\t\t\n\t\t\\end{IEEEbiography}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\n", "itemtype": "equation", "pos": 63274, "prevtext": " The left hand side can be written as \n\n", "index": 43, "text": "\\begin{align}\n[{\\bf y_1},...,{\\bf y_n}][(\\mathcal{A}_1({\\bf P}))^T,...,(\\mathcal{A}_n({\\bf P}))^T]^T \\\\\n= [{\\bf y_1},...,{\\bf y_n}][h_1^T {\\bf P}^T {\\bf\\Sigma}_U^T,...,h_n^T {\\bf P}^T {\\bf\\Sigma}_U^T]^T \\\\\n= \\sum_{i=1}^n {\\bf y_i} {\\bf\\Sigma}_U {\\bf P}^T h_i \\\\\n= \\sum_{i=1}^n \\langle {\\bf P}, {\\bf\\Sigma}_U^T {\\bf y_i} h_i^T \\rangle. \n\\label{eq:calcA2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle[{\\bf y_{1}},...,{\\bf y_{n}}][(\\mathcal{A}_{1}({\\bf P}))^{T},...,%&#10;(\\mathcal{A}_{n}({\\bf P}))^{T}]^{T}\" display=\"inline\"><mrow><mrow><mo stretchy=\"false\">[</mo><msub><mi>\ud835\udc32</mi><mn>\ud835\udfcf</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>\ud835\udc32</mi><mi>\ud835\udc27</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">[</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mi>n</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc0f</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo stretchy=\"false\">]</mo></mrow><mi>T</mi></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=[{\\bf y_{1}},...,{\\bf y_{n}}][h_{1}^{T}{\\bf P}^{T}{\\bf\\Sigma}_{U%&#10;}^{T},...,h_{n}^{T}{\\bf P}^{T}{\\bf\\Sigma}_{U}^{T}]^{T}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mrow><mo stretchy=\"false\">[</mo><msub><mi>\ud835\udc32</mi><mn>\ud835\udfcf</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>\ud835\udc32</mi><mi>\ud835\udc27</mi></msub><mo stretchy=\"false\">]</mo></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">[</mo><mrow><msubsup><mi>h</mi><mn>1</mn><mi>T</mi></msubsup><mo>\u2062</mo><msup><mi>\ud835\udc0f</mi><mi>T</mi></msup><mo>\u2062</mo><msubsup><mi>\ud835\udeba</mi><mi>U</mi><mi>T</mi></msubsup></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><msubsup><mi>h</mi><mi>n</mi><mi>T</mi></msubsup><mo>\u2062</mo><msup><mi>\ud835\udc0f</mi><mi>T</mi></msup><mo>\u2062</mo><msubsup><mi>\ud835\udeba</mi><mi>U</mi><mi>T</mi></msubsup></mrow><mo stretchy=\"false\">]</mo></mrow><mi>T</mi></msup></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{i=1}^{n}{\\bf y_{i}}{\\bf\\Sigma}_{U}{\\bf P}^{T}h_{i}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><msub><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi></msub><mo>\u2062</mo><msub><mi>\ud835\udeba</mi><mi>U</mi></msub><mo>\u2062</mo><msup><mi>\ud835\udc0f</mi><mi>T</mi></msup><mo>\u2062</mo><msub><mi>h</mi><mi>i</mi></msub></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\sum_{i=1}^{n}\\langle{\\bf P},{\\bf\\Sigma}_{U}^{T}{\\bf y_{i}}h_{i}%&#10;^{T}\\rangle.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mrow><mo stretchy=\"false\">\u27e8</mo><mi>\ud835\udc0f</mi><mo>,</mo><mrow><msubsup><mi>\ud835\udeba</mi><mi>U</mi><mi>T</mi></msubsup><mo>\u2062</mo><msub><mi>\ud835\udc32</mi><mi>\ud835\udc22</mi></msub><mo>\u2062</mo><msubsup><mi>h</mi><mi>i</mi><mi>T</mi></msubsup></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]