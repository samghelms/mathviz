[{"file": "1601.04359.tex", "nexttext": "\n\nwhere the symbol $\\langle\\cdot\\rangle$ denotes the ensemble average of\nthe product of characteristic functions\n$\\chi^{i}(\\vek{x}_a,\\alpha)$, which are equal to one when the point\n$\\vek{x}_a$ lies in the phase $i$ in the sample $\\alpha$ and equal\nto zero otherwise:\n\n\n", "itemtype": "equation", "pos": 9515, "prevtext": "\n\n\n\\begin{frontmatter}\n\n\\title{Compression and Reconstruction of Random Microstructures using\n  Accelerated Lineal Path Function}\n\n\\author[ctu]{Jan Havelka}\n\\ead{jan.havelka.1@fsv.cvut.cz}\n\n\\author[ctu]{Anna Ku\\v{c}erov\\'a\\corref{auth}}\n\\ead{anicka@cml.fsv.cvut.cz}\n\n\\author[ctu]{Jan S\\'{y}kora}\n\\ead{jan.sykora.1@fsv.cvut.cz}\n\n\\cortext[auth]{Corresponding author. Tel.:~+420-2-2435-5326;\nfax~+420-2-2431-0775}\n\n\\address[ctu]{Department of Mechanics, Faculty of Civil Engineering,\n  Czech Technical University in Prague, Th\\'{a}kurova 7, 166 29 Prague\n  6, Czech Republic}\n\n\n\\begin{abstract}\n\nMicrostructure reconstruction and compression techniques are designed\nto find a microstructure with desired properties. While the\nmicrostructure reconstruction searches for a microstructure with\nprescribed statistical properties, the microstructure compression\nfocuses on efficient representation of material morphology for a\npurpose of multiscale modelling. Successful application of those\ntechniques, nevertheless, requires proper understanding of underlying\nstatistical descriptors quantifying material morphology. In this paper\nwe focus on the lineal path function designed to capture namely\nshort-range effects and phase connectedness, which can be hardly\nhandled by the commonly used two-point probability function. The usage\nof the lineal path function is, however, significantly limited by huge\ncomputational requirements. So as to examine the properties of the\nlineal path function within the computationally exhaustive compression\nand reconstruction processes, we start with the acceleration of the\nlineal path evaluation, namely by porting part of its code to the\ngraphics processing unit using the CUDA (Compute Unified Device\nArchitecture) programming environment. This allows us to present a\nunique comparison of the entire lineal path function with the commonly\nused rough approximation based on the Monte Carlo and/or sampling\ntemplate. Moreover, the accelerated version of the lineal path\nfunction is then compared with the two-point probability function\nwithin the compression and reconstruction of two-phase\nmorphologies. Their significant features are thoroughly discussed and\nillustrated on a set of artificial periodic as well as real-world\nrandom microstructures.\n\\end{abstract}\n\n\\begin{keyword}\n  Lineal path function \\sep Two-point probability function \\sep\n  Statistically equivalent periodic unit cell \\sep Microstructure\n  reconstruction \\sep Microstructure compression \\sep Graphics\n  processing unit \\sep Compute Unified Device Architecture\n\\end{keyword}\n\n\\end{frontmatter}\n\n\\section{Introduction}\n\\label{sec:intro}\n\nComputational modelling of random heterogeneous materials is a\nnontrivial multi-disciplinary problem with a wide range of\nrelevant engineering applications. The FE$^{2}$-methods have been\ndeveloped as promising techniques for material modelling and used\nto derive effective models at the scale of interest. The unifying\ntheoretical framework is provided by homogenization theories\naiming at the replacement of the heterogeneous microstructure by\nan equivalent homogeneous material, see~\\cite{Torquato:2006}.\nCurrently, two main approaches are available: (i) computational\nhomogenization and (ii) effective media theories.\n\nThe latter approach aims at estimating the material response\nanalytically on the basis of limited geometrical information (e.g. the\nvolume fractions of constituents) of the analysed medium.  Structural\nimperfections are introduced in a cumulative sense using one of the\naveraging schemes, e.g. the Mori-Tanaka method~\\cite{Vorel:2009:SEM}.\nThe computational requirements are very low, however, such an\nanalytical solution is available only for a limited spectrum of\nmicrostructural geometries such as media with a specific shape of\ninclusions.\n\nMethods based on computational homogenization are more general in\napplication. They study the distribution of local fields within a\ntypical heterogeneity pattern using a numerical method. It is\ngenerally accepted that detailed discretisation techniques, and\nthe finite element method in particular, remain the most powerful\nand flexible tools available.  Despite the tedious computational\ntime, it provides us the details of local fields, see\ne.g.~\\cite{Sykora:2012:JCAM,Sykora:2013:AMC}. However, the\nprincipal requirement is to find a representative volume element\n(RVE), which can be intriguing in case of real-world random\nmicrostructures. Recent\nstudies~\\cite{Zeman:2007:MSMSE,Schroder:AAM:2011} suggest that\nstructure preserving spatial geometrical statistics such as a\nstatistically equivalent periodic unit cell (SEPUC) -- also known\nas a statistically similar representative volume element (SSRVE) --\nis computationally very efficient comparing to the classical\nconcept of the RVE.\n\n\nA relatively new concept of microstructure modelling is based on the\nproduction of a set of structures morphologically similar to the\noriginal media, so called Wang tiles,\nsee~\\cite{Novak:PR:2012,Novak:MSMSE:2013}.  It is an approach that\nallows us to obtain aperiodic local fields in heterogenous media with\na small set of statistically representative tiles. The main advantage\nof the stochastic Wang tillings is the computational efficiency and\nlong range spatial correlations, which are neglected in classical\nhomogenization techniques, see~\\cite{Novak:PR:2012}. The tiles can be\nin some cases produced by a computational efficient image quilting\nalgorithm \\cite{Doskar:2014:PRE} or generally also by optimising a\nchosen statistical descriptor.\n\nThe present paper is devoted to statistical descriptors defining\nstatistically/morphologically similar material structures (cells or\ntiles). Such structures are generally obtained by a process of\nmicrostructure reconstruction~\\cite{Yeong:1998:PRE} or \ncompression~\\cite{Povirk:AMM:2005} so as to represent the\nmicrostructure as accurately as possible in terms of the selected\nstatistical descriptor. In particular, we focus on two commonly\nused descriptors, the two-point probability function and the\nlineal path function,\nsee~\\cite{Li:2012:CMS,Singh:MSE:2008,Schroder:AAM:2011}. The goal\nof this paper is to investigate in more detail the properties and\ndifferences of these two descriptors within the compression and\nreconstruction process. So as to achieve this goal, we concentrate\non calculation of the entire lineal path function instead of its\noften used rough discretisation by a sampling template evaluated\napproximately using a Monte Carlo-based procedure,\nsee~\\cite{Zeman:2003}.  Since the evaluation of the entire lineal\npath function can be computationally extremely exhaustive, we\npresent certain acceleration steps on the algorithmic as well as\non the implementation side, where the significant speed up is\nachieved namely by porting the algorithm to the graphics\nprocessing unit (GPU) using the CUDA environment.\n\n\nThis article has been organised in the following way. The next\nsection describes a theoretical formulation of the both\ndescriptors. Section~\\ref{sec:imple} is devoted to acceleration of the\nlineal path function and presents the resulting speed-up obtained\nat GPU in comparison with the sequential CPU formulation.\nSection~\\ref{sec:optim} briefly introduce the optimisation\nalgorithm employed for microstructure compression and\nreconstruction discussed in Sections~\\ref{sec:recon}\nand~\\ref{sec:compress}, respectively. Final summary of the\nessential findings are provided in Section~\\ref{sec:concl}.\n\n\\section{Statistical description of random media}\n\\label{sec:statdes}\n\nThe morphology quantification for random heterogeneous materials\nstarts from the introduction of the concept of an ensemble\nestablished by Kr\\\"{o}ner~\\cite{Kroner:JMPS:1977} and\nBeran~\\cite{Beran:1968}. Proposed mathematical formulations are\nconsidered as one of the milestones in statistical physics and the\nbasic idea is that macroscopic observables can be calculated by\nperforming averages over the systems in the ensemble. In other\nwords, the ensemble represents the collection of geometrical\nsystems having different microstructures but being completely\nidentical from a macroscopic point of view~\\cite{Zeman:2003}.\n\nA variety of statistical descriptors were developed to describe the\nmorphology of a multi-phase random heterogenous\nmaterial~\\cite{Zeman:2003,Zeman:2007:MSMSE} based on the concept of\nan ensemble. In the present work, the two-point probability function and\nthe lineal path function are investigated as frequently used\ndescriptors. Therefore, this section provides their brief analytical\ndescription and classical numerical implementation.\n\nAs a preamble, throughout this paper we consider an ensemble of a\ntwo-phase medium consisting of a black and white phase labelled by\nsuperscripts $i,\\,j\\in\\{\\mathrm{b},\\mathrm{w}\\}$. We also model\nthe medium only as a two-dimensional system, where the position of\nan arbitrary point $\\vek{x_a}$ is defined by the Cartesian\ncoordinates $\\vek{x_a} = ( x_a, y_a)$. Nevertheless, the extension\ninto the three-dimensional systems is very straightforward.\n\n\\subsection{Two-point probability function}\n\\label{subsec:TPPF}\n\nMore formally, the two-point probability function\n$S_{2}^{ij}({\\vek{x}_1}, {\\vek{x}_2})$\\footnote{with $S_{2}^{i}$\n  abbreviating $S_{2}^{ii}$} quantifies the probability of finding\nsimultaneously the phase $i$ and the phase $j$ at two arbitrarily\nchosen points ${\\vek{x}_1}$ and ${\\vek{x}_2}$, respectively, and\ncan be written in the form,\nsee~\\cite{Zeman:2003,Lombardo:2009:IJMCE},\n\n\n", "index": 1, "text": "\\begin{equation}\nS_{2}^{ij}({\\vek{x}_1}, {\\vek{x}_2}) =\n\\langle\\chi^{i}(\\vek{x}_1,\\alpha) \\chi^{j}(\\vek{x}_2,\n\\alpha)\\rangle,\n\\label{eq:s2def}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"S_{2}^{ij}({\\vek{x}_{1}},{\\vek{x}_{2}})=\\langle\\chi^{i}(\\vek{x}_{1},\\alpha)%&#10;\\chi^{j}(\\vek{x}_{2},\\alpha)\\rangle,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mn>2</mn><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo>,</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\u03c7</mi><mi>j</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>,</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}|@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=25mm,keepaspectratio]{CCcomposite_5e2x5e2.eps} \\\\\n    (a)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=50mm,keepaspectratio]{figS2w_CCcomposite_5e2x5e2.eps}\\\\\n    (b)\\\\\n    \\includegraphics*[width=50mm,keepaspectratio]{figS2b_CCcomposite_5e2x5e2.eps}\\\\\n    (c)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=55mm,keepaspectratio]{figS2_Cut.eps} \\\\\n    (d)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\end{tabular}\n\\caption{Illustration of the two-point probability function: (a)\n  Example of a homogeneous system, size $500\\times500$ [px]; (b) $S_{2}^{\\mathrm{w}}$-function; (c) $S_{2}^{\\mathrm{b}}$-function;\n  (d) Comparison of $S_2$-functions in cut 1-1.}\n\\label{fig:s2ilustr}\n\\end{figure}\n\nIn Eq.~(\\ref{eq_charf}), $D^{i}(\\alpha)$ denotes the domain\noccupied by the $i$-th phase. In general, the evaluation of these\ncharacteristics may prove to be prohibitively difficult.\nFortunately for homogeneous systems, the $S_{2}^{i}$ depends only\non the relative position of the two points $\\vek{x} = \\vek{x}_2 -\n\\vek{x}_1$ and has following asymptotic properties,\nsee~\\cite{Yeong:1998:PRE},\n\n\\begin{eqnarray}\n  S_{2}^{i}(|\\vek{x}| = 0) & = & \\phi^{i}, \\label{eq:s2zero}\\\\\n  \\lim_{|\\vek{x}| \\rightarrow\\infty}S_{2}^{i}(\\vek{x}) & = & (\\phi^{i})^2, \\label{eq:s2lim}\n\\end{eqnarray}\n\nwhere $\\phi^{i}$ is the volume fraction of the $i$-th phase.\nEq.~\\eqref{eq:s2zero} follows from definition~\\eqref{eq:s2def} and\nmeans that the probability of a randomly thrown point (i.e. vector of\nzero length) falling into the phase~$i$ is equal to the volume\nfraction of the phase~$i$. On the other hand, Eq.~\\eqref{eq:s2lim}\nassumes that the system has no long-range correlations and thus,\nfalling of the two distant points $\\vek{x_1}$ and $\\vek{x_2}$ into the\nphase $i$ are independent events, each having the probability equal to\n$\\phi^{i}$, see Fig.~\\ref{fig:s2ilustr} as an illustrative example of such\na system.\n\nEven though we aim at characterization of generally non-periodic\nmedia by a SEPUC, whose boundaries are constructed as periodic, it\nhas been demonstrated in~\\cite{Gajdosik:2006:PEM} that assumption\nof periodic boundaries does not introduce a systematic bias in the\nvalues of statistical descriptors. On the other hand, the\nassumption of the periodicity simplifies the computation of the\ntwo-point probability function, because we do not need to consider\nall the possible orientations of the vector $\\vek{x}$.\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{ccc}\n  \\includegraphics*[width=60mm,keepaspectratio]{periodicity.eps} &\n  \\includegraphics*[width=60mm,keepaspectratio]{S2_multi.eps} \\\\\n  (a) & (b) \\\\\n\\end{tabular}\n\\caption{Vectors connecting identical points in periodical setting (a)\n  and the corresponding identical values of the periodic two-point\n  probability function (b)} \\label{fig:periodicity}\n\\end{figure}\n\nAs shown in Fig.~\\ref{fig:periodicity}a, four differently oriented\nvectors are actually connecting the identical points and obviously\nhave the same value of the two-point probability function. As a\nconsequence, the evaluation of the two-point probability function for\nvectors oriented into the first quadrant includes the information about\nall the other vector orientations, see Fig.~\\ref{fig:periodicity}b.\n\nThe last note concerns particularly the two-phase medium, where the two-point\nprobability functions of particular phases are related according to\nthe following equation\n\n\n", "itemtype": "equation", "pos": 9940, "prevtext": "\n\nwhere the symbol $\\langle\\cdot\\rangle$ denotes the ensemble average of\nthe product of characteristic functions\n$\\chi^{i}(\\vek{x}_a,\\alpha)$, which are equal to one when the point\n$\\vek{x}_a$ lies in the phase $i$ in the sample $\\alpha$ and equal\nto zero otherwise:\n\n\n", "index": 3, "text": "\\begin{equation}\n\\chi^{i}(\\vek{x}_a,\\alpha) = \\left\\{\n\\begin{array}{l}\n1, \\quad \\mbox{if } \\vek{x_a} \\in D^{i}(\\alpha) \\\\\n0, \\quad \\mbox{otherwise}\n\\end{array}.\n\\right. \\label{eq_charf}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\chi^{i}(\\vek{x}_{a},\\alpha)=\\left\\{\\begin{array}[]{l}1,\\quad\\mbox{if }\\vek{x_%&#10;{a}}\\in D^{i}(\\alpha)\\\\&#10;0,\\quad\\mbox{otherwise}\\end{array}.\\right.\" display=\"block\"><mrow><mrow><mrow><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mi>a</mi></msub></mrow><mo>,</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mn>1</mn><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mtext>if\u00a0</mtext><mtext class=\"undefined\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ERROR undefined\">\\vek</span></mtext></mrow><mo>\u2062</mo><msub><mi>x</mi><mi>a</mi></msub></mrow></mrow><mo>\u2208</mo><mrow><msup><mi>D</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mn>0</mn><mo rspace=\"12.5pt\">,</mo><mtext>otherwise</mtext></mrow></mtd></mtr></mtable><mi/></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\ni.e. they differ only by a constant as also visible in\nFig.~\\ref{fig:s2ilustr}d.  Since the constant is given by known volume\nfractions of particular phases, only one\ntwo-point probability function needs to be determined to describe the\ntwo-phase medium.  For this reason, we may drop the superscript of\n$S_{2}^{i}(\\vek{x})$ and write only the two-point\nprobability function as $S_{2}(\\vek{x})$.\n\nImplementation of the two-point probability function is based on the\nassumption of a discrete description of a studied system, mainly binary\nimages in our case. The general and simple Monte Carlo-based\nevaluation strategy throws randomly two points into the investigated\nmedium and counts successful ``hits'' of both points into the phase\n$i$.  This approach is, however, not only approximate, but also very\ncomputationally demanding. Therefore, another practical method was\nintroduced on the basis of rewriting the two-point probability\nfunction as an autocorrelation of the characteristic function $\\chi^{i}$\nfor a periodic medium as, see~\\cite{Zeman:2003},\n\n\n", "itemtype": "equation", "pos": 13830, "prevtext": "\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}|@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=25mm,keepaspectratio]{CCcomposite_5e2x5e2.eps} \\\\\n    (a)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=50mm,keepaspectratio]{figS2w_CCcomposite_5e2x5e2.eps}\\\\\n    (b)\\\\\n    \\includegraphics*[width=50mm,keepaspectratio]{figS2b_CCcomposite_5e2x5e2.eps}\\\\\n    (c)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=55mm,keepaspectratio]{figS2_Cut.eps} \\\\\n    (d)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\end{tabular}\n\\caption{Illustration of the two-point probability function: (a)\n  Example of a homogeneous system, size $500\\times500$ [px]; (b) $S_{2}^{\\mathrm{w}}$-function; (c) $S_{2}^{\\mathrm{b}}$-function;\n  (d) Comparison of $S_2$-functions in cut 1-1.}\n\\label{fig:s2ilustr}\n\\end{figure}\n\nIn Eq.~(\\ref{eq_charf}), $D^{i}(\\alpha)$ denotes the domain\noccupied by the $i$-th phase. In general, the evaluation of these\ncharacteristics may prove to be prohibitively difficult.\nFortunately for homogeneous systems, the $S_{2}^{i}$ depends only\non the relative position of the two points $\\vek{x} = \\vek{x}_2 -\n\\vek{x}_1$ and has following asymptotic properties,\nsee~\\cite{Yeong:1998:PRE},\n\n\\begin{eqnarray}\n  S_{2}^{i}(|\\vek{x}| = 0) & = & \\phi^{i}, \\label{eq:s2zero}\\\\\n  \\lim_{|\\vek{x}| \\rightarrow\\infty}S_{2}^{i}(\\vek{x}) & = & (\\phi^{i})^2, \\label{eq:s2lim}\n\\end{eqnarray}\n\nwhere $\\phi^{i}$ is the volume fraction of the $i$-th phase.\nEq.~\\eqref{eq:s2zero} follows from definition~\\eqref{eq:s2def} and\nmeans that the probability of a randomly thrown point (i.e. vector of\nzero length) falling into the phase~$i$ is equal to the volume\nfraction of the phase~$i$. On the other hand, Eq.~\\eqref{eq:s2lim}\nassumes that the system has no long-range correlations and thus,\nfalling of the two distant points $\\vek{x_1}$ and $\\vek{x_2}$ into the\nphase $i$ are independent events, each having the probability equal to\n$\\phi^{i}$, see Fig.~\\ref{fig:s2ilustr} as an illustrative example of such\na system.\n\nEven though we aim at characterization of generally non-periodic\nmedia by a SEPUC, whose boundaries are constructed as periodic, it\nhas been demonstrated in~\\cite{Gajdosik:2006:PEM} that assumption\nof periodic boundaries does not introduce a systematic bias in the\nvalues of statistical descriptors. On the other hand, the\nassumption of the periodicity simplifies the computation of the\ntwo-point probability function, because we do not need to consider\nall the possible orientations of the vector $\\vek{x}$.\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{ccc}\n  \\includegraphics*[width=60mm,keepaspectratio]{periodicity.eps} &\n  \\includegraphics*[width=60mm,keepaspectratio]{S2_multi.eps} \\\\\n  (a) & (b) \\\\\n\\end{tabular}\n\\caption{Vectors connecting identical points in periodical setting (a)\n  and the corresponding identical values of the periodic two-point\n  probability function (b)} \\label{fig:periodicity}\n\\end{figure}\n\nAs shown in Fig.~\\ref{fig:periodicity}a, four differently oriented\nvectors are actually connecting the identical points and obviously\nhave the same value of the two-point probability function. As a\nconsequence, the evaluation of the two-point probability function for\nvectors oriented into the first quadrant includes the information about\nall the other vector orientations, see Fig.~\\ref{fig:periodicity}b.\n\nThe last note concerns particularly the two-phase medium, where the two-point\nprobability functions of particular phases are related according to\nthe following equation\n\n\n", "index": 5, "text": "\\begin{equation}\n  S_{2}^{i}(\\vek{x}) = (\\phi^{i})^2 - (\\phi^{j})^2 + S_{2}^{j}(\\vek{x}),\n\\label{eq:S2add}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"S_{2}^{i}(\\vek{x})=(\\phi^{i})^{2}-(\\phi^{j})^{2}+S_{2}^{j}(\\vek{x}),\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03d5</mi><mi>i</mi></msup><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>-</mo><msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03d5</mi><mi>j</mi></msup><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><mrow><msubsup><mi>S</mi><mn>2</mn><mi>j</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nwhere the symbol $\\%$ is the modulo, $\\chi^{i}(x_1,y_1)$ denotes the value\nof $\\chi^{i}$ for the pixel located in the $y_1$-th row and the $x_1$-th\ncolumn of the digitised image with the dimensions $W \\times H$, $x$\nand $y$ are the vertical and horizontal distances between two pixels,\nsee Fig.~\\ref{fig:s2px}.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=50mm,keepaspectratio]{S2px.eps}\n\\caption{Illustration of a digitised image} \\label{fig:s2px}\n\\end{figure}\n\nAccording to~\\cite{Lombardo:2009:IJMCE}, the Eq.~(\\ref{eq:S2dis}) can\nbe computed in an efficient way using the Fast Fourier Transform.\nApplying this, the reformulation of the two-point probability function\n$S_{2}^{i}$ for a periodic medium can be written as\n\n\n", "itemtype": "equation", "pos": 15011, "prevtext": "\n\ni.e. they differ only by a constant as also visible in\nFig.~\\ref{fig:s2ilustr}d.  Since the constant is given by known volume\nfractions of particular phases, only one\ntwo-point probability function needs to be determined to describe the\ntwo-phase medium.  For this reason, we may drop the superscript of\n$S_{2}^{i}(\\vek{x})$ and write only the two-point\nprobability function as $S_{2}(\\vek{x})$.\n\nImplementation of the two-point probability function is based on the\nassumption of a discrete description of a studied system, mainly binary\nimages in our case. The general and simple Monte Carlo-based\nevaluation strategy throws randomly two points into the investigated\nmedium and counts successful ``hits'' of both points into the phase\n$i$.  This approach is, however, not only approximate, but also very\ncomputationally demanding. Therefore, another practical method was\nintroduced on the basis of rewriting the two-point probability\nfunction as an autocorrelation of the characteristic function $\\chi^{i}$\nfor a periodic medium as, see~\\cite{Zeman:2003},\n\n\n", "index": 7, "text": "\\begin{equation}\n  S_{2}^{i}(x,y) =\n  \\frac{1}{WH}\\sum_{x_1=0}^{W-1}\\sum_{y_1=0}^{H-1}\\chi^{i}(x_1,y_1)\\chi^{i}((x_1+x)\\%W,(y_1+y)\\%H),\n\\label{eq:S2dis}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"S_{2}^{i}(x,y)=\\frac{1}{WH}\\sum_{x_{1}=0}^{W-1}\\sum_{y_{1}=0}^{H-1}\\chi^{i}(x_%&#10;{1},y_{1})\\chi^{i}((x_{1}+x)\\%W,(y_{1}+y)\\%H),\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>W</mi><mo>\u2062</mo><mi>H</mi></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><mrow><mi>W</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><mrow><mi>H</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0pt\" rspace=\"3.5pt\">%</mo></mrow><mo>\u2062</mo><mi>W</mi></mrow><mo>,</mo><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mi>y</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo lspace=\"0pt\" rspace=\"3.5pt\">%</mo></mrow><mo>\u2062</mo><mi>H</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\nwhere IDFT is the inverse Discrete Fourier Transform (DFT), the symbol\n$\\bar{\\cdot}$ stands for the complex conjugate. This method is very\nefficient and its accuracy depends only on the selected resolution of the\ndigitised medium, see~\\cite{Zeman:2003,Zeman:2007:MSMSE}. The Fast\nFourier Transform, which needs only $\\mathcal{O}(WH\\log(WH)+WH)$\noperations, is used to perform the numerical computations presented\nbelow.\n\n\\subsection{Lineal path function}\n\\label{subsec:LPF}\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}|@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=25mm,keepaspectratio]{CCcomposite_5e2x5e2.eps} \\\\\n    (a)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=50mm,keepaspectratio]{figL2w_CCcomposite_5e2x5e2.eps}\\\\\n    (b)\\\\\n    \\includegraphics*[width=50mm,keepaspectratio]{figL2b_CCcomposite_5e2x5e2.eps}\\\\\n    (c)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=55mm,keepaspectratio]{figL2_Cut.eps} \\\\\n    (d)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\end{tabular}\n\\caption{Illustration of the two-point probability function: (a)\n  Example of a homogeneous system, size $500\\times500$ [px]; (b) $L_{2}^{\\mathrm{w}}$-function; (c) $L_{2}^{\\mathrm{b}}$-function;\n  (d) Comparison of $L_2$-functions in cut 1-1.}\n\\label{fig:l2ilustr}\n\\end{figure}\n\nAnother frequently used statistical descriptor for the\nmicrostructural morphology quantification is the lineal path\nfunction $L_{2}^{i}({\\vek{x}_1}, {\\vek{x}_2})$, originally\nintroduced in~\\cite{Lu:PR:1992} and further elaborated\nin~\\cite{Yeong:1998:PRE,Zeman:2003}. It is defined as a low-order\ndescriptor based on a more complex fundamental function\n$\\lambda^{i}$ able to describe certain information about the phase\nconnectedness and putting more emphasis on the short-range\ncorrelations, since its value quickly vanishes to zero with\nincreasing $|\\vek{x}|$.  The fundamental function $\\lambda^{i}$ is\ndefined as\n\n\n", "itemtype": "equation", "pos": 15914, "prevtext": "\n\nwhere the symbol $\\%$ is the modulo, $\\chi^{i}(x_1,y_1)$ denotes the value\nof $\\chi^{i}$ for the pixel located in the $y_1$-th row and the $x_1$-th\ncolumn of the digitised image with the dimensions $W \\times H$, $x$\nand $y$ are the vertical and horizontal distances between two pixels,\nsee Fig.~\\ref{fig:s2px}.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=50mm,keepaspectratio]{S2px.eps}\n\\caption{Illustration of a digitised image} \\label{fig:s2px}\n\\end{figure}\n\nAccording to~\\cite{Lombardo:2009:IJMCE}, the Eq.~(\\ref{eq:S2dis}) can\nbe computed in an efficient way using the Fast Fourier Transform.\nApplying this, the reformulation of the two-point probability function\n$S_{2}^{i}$ for a periodic medium can be written as\n\n\n", "index": 9, "text": "\\begin{equation}\nS_{2}^{i}(x,y) =\n\\frac{1}{WH}\\mbox{IDFT}\\left\\{\\mbox{DFT}\\left\\{\\chi^{i}(x,y)\\right\\}\n\\overline{ \\mbox{DFT} \\left\\{\\chi^{i}(x,y)\\right\\} } \\right\\},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"S_{2}^{i}(x,y)=\\frac{1}{WH}\\mbox{IDFT}\\left\\{\\mbox{DFT}\\left\\{\\chi^{i}(x,y)%&#10;\\right\\}\\overline{\\mbox{DFT}\\left\\{\\chi^{i}(x,y)\\right\\}}\\right\\},\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>S</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>W</mi><mo>\u2062</mo><mi>H</mi></mrow></mfrac><mo>\u2062</mo><mtext>IDFT</mtext><mo>\u2062</mo><mrow><mo>{</mo><mrow><mtext>DFT</mtext><mo>\u2062</mo><mrow><mo>{</mo><mrow><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><mover accent=\"true\"><mrow><mtext>DFT</mtext><mo>\u2062</mo><mrow><mo>{</mo><mrow><msup><mi>\u03c7</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>}</mo></mrow></mrow><mo>\u00af</mo></mover></mrow><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\ni.e., a function which equals to $1$ when the segment\n$\\vek{x}_{1}\\vek{x}_{2}$ is contained in the phase $i$ for the sample\n$\\alpha$ and $0$ otherwise. The lineal path function is defined as the\nprobability that the line segment $\\vek{x}_{1}\\vek{x}_{2}$ lies\nentirely in the phase $i$ and it can be written as the ensemble\naveraging fundamental function given as\n\n\n", "itemtype": "equation", "pos": 18165, "prevtext": "\nwhere IDFT is the inverse Discrete Fourier Transform (DFT), the symbol\n$\\bar{\\cdot}$ stands for the complex conjugate. This method is very\nefficient and its accuracy depends only on the selected resolution of the\ndigitised medium, see~\\cite{Zeman:2003,Zeman:2007:MSMSE}. The Fast\nFourier Transform, which needs only $\\mathcal{O}(WH\\log(WH)+WH)$\noperations, is used to perform the numerical computations presented\nbelow.\n\n\\subsection{Lineal path function}\n\\label{subsec:LPF}\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}|@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=25mm,keepaspectratio]{CCcomposite_5e2x5e2.eps} \\\\\n    (a)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=50mm,keepaspectratio]{figL2w_CCcomposite_5e2x5e2.eps}\\\\\n    (b)\\\\\n    \\includegraphics*[width=50mm,keepaspectratio]{figL2b_CCcomposite_5e2x5e2.eps}\\\\\n    (c)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=55mm,keepaspectratio]{figL2_Cut.eps} \\\\\n    (d)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\end{tabular}\n\\caption{Illustration of the two-point probability function: (a)\n  Example of a homogeneous system, size $500\\times500$ [px]; (b) $L_{2}^{\\mathrm{w}}$-function; (c) $L_{2}^{\\mathrm{b}}$-function;\n  (d) Comparison of $L_2$-functions in cut 1-1.}\n\\label{fig:l2ilustr}\n\\end{figure}\n\nAnother frequently used statistical descriptor for the\nmicrostructural morphology quantification is the lineal path\nfunction $L_{2}^{i}({\\vek{x}_1}, {\\vek{x}_2})$, originally\nintroduced in~\\cite{Lu:PR:1992} and further elaborated\nin~\\cite{Yeong:1998:PRE,Zeman:2003}. It is defined as a low-order\ndescriptor based on a more complex fundamental function\n$\\lambda^{i}$ able to describe certain information about the phase\nconnectedness and putting more emphasis on the short-range\ncorrelations, since its value quickly vanishes to zero with\nincreasing $|\\vek{x}|$.  The fundamental function $\\lambda^{i}$ is\ndefined as\n\n\n", "index": 11, "text": "\\begin{equation}\n\\lambda^{i}(\\vek{x}_{1},\\vek{x}_{2},\\alpha)=\\left\\{\\begin{array}{l}1,\\,\n\\mathrm{if}\\,\\vek{x}_{1}\\vek{x}_{2}\\subset\nD^{i}(\\alpha),\\\\\n0,\\, \\mathrm{otherwise},\n\\end{array}\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\lambda^{i}(\\vek{x}_{1},\\vek{x}_{2},\\alpha)=\\left\\{\\begin{array}[]{l}1,\\,%&#10;\\mathrm{if}\\,\\vek{x}_{1}\\vek{x}_{2}\\subset D^{i}(\\alpha),\\\\&#10;0,\\,\\mathrm{otherwise},\\end{array}\\right.\" display=\"block\"><mrow><mrow><msup><mi>\u03bb</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>,</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mn>1</mn><mo rspace=\"4.2pt\">,</mo><mrow><mpadded width=\"+1.7pt\"><mi>if</mi></mpadded><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></mrow><mo>\u2282</mo><mrow><msup><mi>D</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mn>0</mn><mo rspace=\"4.2pt\">,</mo><mi>otherwise</mi></mrow><mo>,</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nAs mentioned above, under the assumption of statistical\nhomogeneity~\\cite{Zeman:2003}, the function again simplifies to\n$L_{2}^{i}(\\vek{x}_{1},\\vek{x}_{2}) = L_{2}^{i}(\\vek{x})$ with\n$\\vek{x} = \\vek{x}_2 - \\vek{x}_1$ and yields\n\n\\begin{eqnarray}\n  L_{2}^{i}(|\\vek{x}| = 0) & = & \\phi^{i} \\label{eq:l2zero}\\\\\n  \\lim_{|\\vek{x}|\\rightarrow\\infty}L_{2}^{i}(\\vek{x}) & = & 0. \\label{eq:l2lim}\n\\end{eqnarray}\n\nHere again, the Eq.~\\ref{eq:l2lim} assumes no long-range correlations\nand thus the probability that the line segment\n$\\vek{x}_{1}\\vek{x}_{2}$ lies entirely in the phase $i$ vanishes to\nzero with its increasing length, see Fig.~\\ref{fig:l2ilustr} for an\nillustration of such a homogeneous system.\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}@{}c@{}@{}c@{}}\n  \\includegraphics*[width=35mm,keepaspectratio]{symmetry.eps} &\n  \\includegraphics*[width=55mm,keepaspectratio]{figL2w_CCcomposite_15e2x15e2_ipe.eps} &\n  \\includegraphics*[width=55mm,keepaspectratio]{figL2b_CCcomposite_15e2x15e2_ipe.eps}\\\\\n  (a) & (b) & (c)\\\\\n\\end{tabular}\n\\caption{Vectors corresponding to identical segments (a), point\n  symmetry of lineal path function of the black (b) and white (c)\n  phases}\n\\label{fig:symmetry}\n\\end{figure}\n\nFor the sake of consistency with the formulation and computation of\nthe two-point probability function, we introduce again the assumption of\nthe periodicity in our numerical implementation. However, there arise\nno computational benefits, since all the vectors in\nFig.~\\ref{fig:periodicity}a are connecting the same points via\na different path. Nevertheless, we need to keep in mind that the line\nsegment $\\vek{x}_{1}\\vek{x}_{2}$ is identical to the line segment\n$\\vek{x}_{2}\\vek{x}_{1}$ and thus\n\n\n", "itemtype": "equation", "pos": 18738, "prevtext": "\n\ni.e., a function which equals to $1$ when the segment\n$\\vek{x}_{1}\\vek{x}_{2}$ is contained in the phase $i$ for the sample\n$\\alpha$ and $0$ otherwise. The lineal path function is defined as the\nprobability that the line segment $\\vek{x}_{1}\\vek{x}_{2}$ lies\nentirely in the phase $i$ and it can be written as the ensemble\naveraging fundamental function given as\n\n\n", "index": 13, "text": "\\begin{equation}\nL_{2}^{i}(\\vek{x}_{1},\\vek{x}_{2})=\\langle\\lambda^{i}(\\vek{x}_{1},\\vek{x}_{2},\\alpha)\\rangle.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"L_{2}^{i}(\\vek{x}_{1},\\vek{x}_{2})=\\langle\\lambda^{i}(\\vek{x}_{1},\\vek{x}_{2},%&#10;\\alpha)\\rangle.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>L</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><msup><mi>\u03bb</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>,</mo><mi>\u03b1</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">\u27e9</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nwhich means that the lineal path posses point symmetry, see\nFig.~\\ref{fig:symmetry}. Hence, we need to compute the lineal path\nfunction only for a half of all the possible orientations of the vector\n$\\vek{x}$ and the rest is obtained by symmetry.\n\nIn contrast to the evaluation of $S_{2}^{i}$, see Eq.~(\\ref{eq:S2add}),\nthe lineal path function computed for one phase does not include the\nwhole information about the lineal path function of the other phase,\nwhich thus needs to be computed separately, see\nFig.~\\ref{fig:symmetry}. This brings additional information about the\nstructural morphology, but it also means higher computational demands.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=12cm,keepaspectratio]{L2px.eps}\n\\caption{Illustration of line segments}\n\\label{fig:l2px}\n\\end{figure}\n\nWith this in mind, the standard numerical implementation of\na sequential version of the entire $L_{2}^{i}$ starts from the\ndefinition of line segments connecting two pixels $\\vek{x}_{1}$\nand $\\vek{x}_{2}$ within the image with the dimensions $W\\times\nH$. The set of pixels representing a segment starting in\n$\\vek{x}_{1}=(0,0)$ and ending in $\\vek{x}_{2}=(x,y)$, is\nspecified by an algorithm originally proposed by\nBresenham~\\cite{Bresenham:SJ:1965} defining a unique solution for\nany positions of boundary pixels $\\vek{x}_{1},\\vek{x}_{2}$. Due to\nthe point symmetry of the lineal path function, all the\norientations of a line segment necessary for its computation are\nproduced by moving the point $\\vek{x}_2$ within the domain\n$\\mathbb{D}$ given by two rectangles specifying the left bottom corner\nof a pixel, i.e.\n\n\n", "itemtype": "equation", "pos": 20582, "prevtext": "\n\nAs mentioned above, under the assumption of statistical\nhomogeneity~\\cite{Zeman:2003}, the function again simplifies to\n$L_{2}^{i}(\\vek{x}_{1},\\vek{x}_{2}) = L_{2}^{i}(\\vek{x})$ with\n$\\vek{x} = \\vek{x}_2 - \\vek{x}_1$ and yields\n\n\\begin{eqnarray}\n  L_{2}^{i}(|\\vek{x}| = 0) & = & \\phi^{i} \\label{eq:l2zero}\\\\\n  \\lim_{|\\vek{x}|\\rightarrow\\infty}L_{2}^{i}(\\vek{x}) & = & 0. \\label{eq:l2lim}\n\\end{eqnarray}\n\nHere again, the Eq.~\\ref{eq:l2lim} assumes no long-range correlations\nand thus the probability that the line segment\n$\\vek{x}_{1}\\vek{x}_{2}$ lies entirely in the phase $i$ vanishes to\nzero with its increasing length, see Fig.~\\ref{fig:l2ilustr} for an\nillustration of such a homogeneous system.\n\n\\begin{figure} [t!]\n\\centering\n\\begin{tabular}{@{}c@{}@{}c@{}@{}c@{}}\n  \\includegraphics*[width=35mm,keepaspectratio]{symmetry.eps} &\n  \\includegraphics*[width=55mm,keepaspectratio]{figL2w_CCcomposite_15e2x15e2_ipe.eps} &\n  \\includegraphics*[width=55mm,keepaspectratio]{figL2b_CCcomposite_15e2x15e2_ipe.eps}\\\\\n  (a) & (b) & (c)\\\\\n\\end{tabular}\n\\caption{Vectors corresponding to identical segments (a), point\n  symmetry of lineal path function of the black (b) and white (c)\n  phases}\n\\label{fig:symmetry}\n\\end{figure}\n\nFor the sake of consistency with the formulation and computation of\nthe two-point probability function, we introduce again the assumption of\nthe periodicity in our numerical implementation. However, there arise\nno computational benefits, since all the vectors in\nFig.~\\ref{fig:periodicity}a are connecting the same points via\na different path. Nevertheless, we need to keep in mind that the line\nsegment $\\vek{x}_{1}\\vek{x}_{2}$ is identical to the line segment\n$\\vek{x}_{2}\\vek{x}_{1}$ and thus\n\n\n", "index": 15, "text": "\\begin{equation}\n  L_{2}^{i}(\\vek{x}) = L_{2}^{i}(-\\vek{x}),\n\\label{eq:symmetry}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"L_{2}^{i}(\\vek{x})=L_{2}^{i}(-\\vek{x}),\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>L</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msubsup><mi>L</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><mi>x</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nsee Fig.~\\ref{fig:l2px}.  The number of segments defining the\nlineal path function is thus given as a cardinality of the domain\n$\\mathbb{D}$, which is $|\\mathbb{D}| = 2HW-H-W+1$. Once having the\ndefined segments, the computation of the lineal path function involves\nsimple translations of each segment throughout the image and the\ncomparison whether all pixels of the segment at a given position\ncorrespond to image pixels with the value of the investigated\nphase.  Such an intuitive description represents, however,\na computationally exhaustive procedure leading to\n$\\mathcal{O}(H^3W^2)$ operations for periodic media with $W\\leq\nH$. For our purpose, it simplifies to $\\mathcal{O}(W^5)$ for\n$W=H$, i.e. a square shape of SEPUC/SSRVE. In order to reduce the\ncomputational cost, several algorithmic and hardware acceleration\nsteps are introduced and described in the following section.\n\n\n\n\n\n\n\n\\section{Numerical implementation of $L_{2}$}\n\\label{sec:imple}\n\nIn order to avoid huge computational requirements of the entire $L_2$\nevaluation, some authors (see e.g. \\cite{Zeman:2003}) compute\nonly its approximation using a Monte Carlo-based procedure. In such\na case, the line segments are not compared with the image at all\navailable positions equal to a number of all pixels in the image,\nbut only at a limited number of randomly selected positions. The\nerror produced by such an approximation is illustrated in Figure\n\\ref{fig:MC_LP} for three different types of microstructures as a\nfunction of the number $N$ of selected positions.\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{@{}c@{}|@{\\hspace{0.1cm}}c@{}}\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            A.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figA.eps}\\[20mm]\n            B.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figB.eps}\\[20mm]\n            C.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figC.eps}\\[10mm]\n        \\end{tabular}\n    \\end{adjustbox}\n    &\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            \\includegraphics*[width=80mm,keepaspectratio]{L2_w_CMP_e.eps}\\\\\n            (a) \\\\\n            \\includegraphics*[width=80mm,keepaspectratio]{L2_b_CMP_e.eps}\\\\\n            (b)\n        \\end{tabular}\n    \\end{adjustbox}\n\\end{tabular}\n\\end{center}\n\\caption{Convergence analysis of MC-based approximation of lineal\npath functions computed for (a) white phase and (b) black phase}\n\\label{fig:MC_LP}\n\\end{figure}\n\nThe values on the vertical axis are the least square errors between the exact\nlineal path function $L_2$ and its approximation $\\widetilde{L}_2$ given\nas\n\n\n", "itemtype": "equation", "pos": 22302, "prevtext": "\n\nwhich means that the lineal path posses point symmetry, see\nFig.~\\ref{fig:symmetry}. Hence, we need to compute the lineal path\nfunction only for a half of all the possible orientations of the vector\n$\\vek{x}$ and the rest is obtained by symmetry.\n\nIn contrast to the evaluation of $S_{2}^{i}$, see Eq.~(\\ref{eq:S2add}),\nthe lineal path function computed for one phase does not include the\nwhole information about the lineal path function of the other phase,\nwhich thus needs to be computed separately, see\nFig.~\\ref{fig:symmetry}. This brings additional information about the\nstructural morphology, but it also means higher computational demands.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=12cm,keepaspectratio]{L2px.eps}\n\\caption{Illustration of line segments}\n\\label{fig:l2px}\n\\end{figure}\n\nWith this in mind, the standard numerical implementation of\na sequential version of the entire $L_{2}^{i}$ starts from the\ndefinition of line segments connecting two pixels $\\vek{x}_{1}$\nand $\\vek{x}_{2}$ within the image with the dimensions $W\\times\nH$. The set of pixels representing a segment starting in\n$\\vek{x}_{1}=(0,0)$ and ending in $\\vek{x}_{2}=(x,y)$, is\nspecified by an algorithm originally proposed by\nBresenham~\\cite{Bresenham:SJ:1965} defining a unique solution for\nany positions of boundary pixels $\\vek{x}_{1},\\vek{x}_{2}$. Due to\nthe point symmetry of the lineal path function, all the\norientations of a line segment necessary for its computation are\nproduced by moving the point $\\vek{x}_2$ within the domain\n$\\mathbb{D}$ given by two rectangles specifying the left bottom corner\nof a pixel, i.e.\n\n\n", "index": 17, "text": "\\begin{equation}\n\\mathbb{D} := [-W+1; -1] \\times [1; H-1] + [0; W-1] \\times [0; H-1] \\,\n\\label{eq:segments}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{D}:=[-W+1;-1]\\times[1;H-1]+[0;W-1]\\times[0;H-1]\\,\" display=\"block\"><mrow><mi>\ud835\udd3b</mi><mo>:=</mo><mrow><mrow><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mo>-</mo><mi>W</mi></mrow><mo>+</mo><mn>1</mn></mrow><mo>;</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u00d7</mo><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo>;</mo><mrow><mi>H</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo>+</mo><mrow><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>;</mo><mrow><mi>W</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">]</mo></mrow><mo>\u00d7</mo><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo>;</mo><mrow><mi>H</mi><mo>-</mo><mn>1</mn></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">]</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nwhere the superscript $i$ denotes the phase and the subscript $p$ covers\nall the oriented segments defining the lineal path function given\nby \\eqref{eq:segments}. Dimensions of all three microstructural\nimages are $100 \\times 100$ pixels. Since the lineal path function\nis evaluated at $N$ positions obtained as a random $N$-combination\nof a set $|\\mathbb{D}|$ without repetition, the error converges to\nzero for $N = |\\mathbb{D}|$.\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Parallelisation on GPU using CUDA environment}\n\nThe key idea described here is a porting part of the code to GPU\ndevice. Parallel computations on GPUs have become very popular\nwithin the last decade thanks to the GPU's high performance at\na relatively low financial cost. Moreover, the programming\nenvironment called CUDA (Compute Unified Device Architecture)\nsimplifies the GPU-based software development by using the\nstandard C/C++ language, see.~\\cite{Nvidia}. In order to clearly\ndescribe the GPU parallelism, we start with the algorithmic\nstructure of the $L_{2}$ evaluation consisting of several\ncomputational steps:\n\\begin{enumerate}\n\\item generating line segments for given input dimensions,\n\n\\item allocating the inputs (e.g. the input representing a binary\nimage),\n\n\n\\item calculating the lineal path function based on translations\nof each segment and its comparison with the image.\n\\end{enumerate}\n\nRegarding computational requirements of particular steps, one\nneeds to keep in mind that the $L_2$ is supposed to be called\nrepeatedly within an optimisation process for new feasible\nsolutions (i.e. new binary images) of the same dimensions $W\n\\times H$. It means that the definition of line segments remains\nthe same during the whole optimisation process thus allowing to\nrun the step 1 only once at the beginning of the optimisation,\nwhile the steps 2 -- 3 need to be called repeatedly. It also\nfurther implies that step 1 is critical namely from the memory\nusage point of view, while steps 2 -- 3 needs to be optimised with\nrespect to the computational time.\n\nBefore starting an implementation of Bresenham's algorithm for definition of line\nsegments, one needs to decide about the line segments\ncoding. While the definition of a particular pixel by its $(x,y)$\ncoordinates is very intuitive, it is excessively memory demanding. It\nis much more efficient to index all pixels in the image by only one\ninteger value from $0$ to $WH-1$. Then the number of integer values\nrequired for definition of all line segments is given as\n\n\n", "itemtype": "equation", "pos": 25029, "prevtext": "\n\nsee Fig.~\\ref{fig:l2px}.  The number of segments defining the\nlineal path function is thus given as a cardinality of the domain\n$\\mathbb{D}$, which is $|\\mathbb{D}| = 2HW-H-W+1$. Once having the\ndefined segments, the computation of the lineal path function involves\nsimple translations of each segment throughout the image and the\ncomparison whether all pixels of the segment at a given position\ncorrespond to image pixels with the value of the investigated\nphase.  Such an intuitive description represents, however,\na computationally exhaustive procedure leading to\n$\\mathcal{O}(H^3W^2)$ operations for periodic media with $W\\leq\nH$. For our purpose, it simplifies to $\\mathcal{O}(W^5)$ for\n$W=H$, i.e. a square shape of SEPUC/SSRVE. In order to reduce the\ncomputational cost, several algorithmic and hardware acceleration\nsteps are introduced and described in the following section.\n\n\n\n\n\n\n\n\\section{Numerical implementation of $L_{2}$}\n\\label{sec:imple}\n\nIn order to avoid huge computational requirements of the entire $L_2$\nevaluation, some authors (see e.g. \\cite{Zeman:2003}) compute\nonly its approximation using a Monte Carlo-based procedure. In such\na case, the line segments are not compared with the image at all\navailable positions equal to a number of all pixels in the image,\nbut only at a limited number of randomly selected positions. The\nerror produced by such an approximation is illustrated in Figure\n\\ref{fig:MC_LP} for three different types of microstructures as a\nfunction of the number $N$ of selected positions.\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{@{}c@{}|@{\\hspace{0.1cm}}c@{}}\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            A.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figA.eps}\\[20mm]\n            B.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figB.eps}\\[20mm]\n            C.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figC.eps}\\[10mm]\n        \\end{tabular}\n    \\end{adjustbox}\n    &\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            \\includegraphics*[width=80mm,keepaspectratio]{L2_w_CMP_e.eps}\\\\\n            (a) \\\\\n            \\includegraphics*[width=80mm,keepaspectratio]{L2_b_CMP_e.eps}\\\\\n            (b)\n        \\end{tabular}\n    \\end{adjustbox}\n\\end{tabular}\n\\end{center}\n\\caption{Convergence analysis of MC-based approximation of lineal\npath functions computed for (a) white phase and (b) black phase}\n\\label{fig:MC_LP}\n\\end{figure}\n\nThe values on the vertical axis are the least square errors between the exact\nlineal path function $L_2$ and its approximation $\\widetilde{L}_2$ given\nas\n\n\n", "index": 19, "text": "\\begin{equation}\ne(L_2^i) = \\sum_{p\\in\\mathbb{D}}(L_2^i(\\vek{x}_{p})-\\widetilde{L}_2^i(\\vek{x}_{p}))^2,\n\\label{eq:LSE1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"e(L_{2}^{i})=\\sum_{p\\in\\mathbb{D}}(L_{2}^{i}(\\vek{x}_{p})-\\widetilde{L}_{2}^{i%&#10;}(\\vek{x}_{p}))^{2},\" display=\"block\"><mrow><mrow><mrow><mi>e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>L</mi><mn>2</mn><mi>i</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>p</mi><mo>\u2208</mo><mi>\ud835\udd3b</mi></mrow></munder><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>L</mi><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msubsup><mover accent=\"true\"><mi>L</mi><mo>~</mo></mover><mn>2</mn><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nwhich leads to\n\n\n", "itemtype": "equation", "pos": 27660, "prevtext": "\n\nwhere the superscript $i$ denotes the phase and the subscript $p$ covers\nall the oriented segments defining the lineal path function given\nby \\eqref{eq:segments}. Dimensions of all three microstructural\nimages are $100 \\times 100$ pixels. Since the lineal path function\nis evaluated at $N$ positions obtained as a random $N$-combination\nof a set $|\\mathbb{D}|$ without repetition, the error converges to\nzero for $N = |\\mathbb{D}|$.\n\n\n\n\n\n\n\n\n\n\n\n\\subsection{Parallelisation on GPU using CUDA environment}\n\nThe key idea described here is a porting part of the code to GPU\ndevice. Parallel computations on GPUs have become very popular\nwithin the last decade thanks to the GPU's high performance at\na relatively low financial cost. Moreover, the programming\nenvironment called CUDA (Compute Unified Device Architecture)\nsimplifies the GPU-based software development by using the\nstandard C/C++ language, see.~\\cite{Nvidia}. In order to clearly\ndescribe the GPU parallelism, we start with the algorithmic\nstructure of the $L_{2}$ evaluation consisting of several\ncomputational steps:\n\\begin{enumerate}\n\\item generating line segments for given input dimensions,\n\n\\item allocating the inputs (e.g. the input representing a binary\nimage),\n\n\n\\item calculating the lineal path function based on translations\nof each segment and its comparison with the image.\n\\end{enumerate}\n\nRegarding computational requirements of particular steps, one\nneeds to keep in mind that the $L_2$ is supposed to be called\nrepeatedly within an optimisation process for new feasible\nsolutions (i.e. new binary images) of the same dimensions $W\n\\times H$. It means that the definition of line segments remains\nthe same during the whole optimisation process thus allowing to\nrun the step 1 only once at the beginning of the optimisation,\nwhile the steps 2 -- 3 need to be called repeatedly. It also\nfurther implies that step 1 is critical namely from the memory\nusage point of view, while steps 2 -- 3 needs to be optimised with\nrespect to the computational time.\n\nBefore starting an implementation of Bresenham's algorithm for definition of line\nsegments, one needs to decide about the line segments\ncoding. While the definition of a particular pixel by its $(x,y)$\ncoordinates is very intuitive, it is excessively memory demanding. It\nis much more efficient to index all pixels in the image by only one\ninteger value from $0$ to $WH-1$. Then the number of integer values\nrequired for definition of all line segments is given as\n\n\n", "index": 21, "text": "\\begin{equation}\nM = \\sum_{i=1}^W \\sum_{j=1}^{H} \\max(i,j) + \\sum_{i=2}^W \\sum_{j=2}^{H} \\max(i,j),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"M=\\sum_{i=1}^{W}\\sum_{j=1}^{H}\\max(i,j)+\\sum_{i=2}^{W}\\sum_{j=2}^{H}\\max(i,j),\" display=\"block\"><mrow><mrow><mi>M</mi><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>2</mn></mrow><mi>W</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>2</mn></mrow><mi>H</mi></munderover><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nfor $W \\leq H$ and to\n\n\n", "itemtype": "equation", "pos": 27792, "prevtext": "\n\nwhich leads to\n\n\n", "index": 23, "text": "\\begin{equation}\nM = \\frac{W(3H^2 + 3H + W^2 -\n1)}{3}-\\frac{W(W+1)}{2}-\\frac{H(H+1)}{2}+1\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"M=\\frac{W(3H^{2}+3H+W^{2}-1)}{3}-\\frac{W(W+1)}{2}-\\frac{H(H+1)}{2}+1\" display=\"block\"><mrow><mi>M</mi><mo>=</mo><mrow><mrow><mfrac><mrow><mi>W</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mrow><mn>3</mn><mo>\u2062</mo><msup><mi>H</mi><mn>2</mn></msup></mrow><mo>+</mo><mrow><mn>3</mn><mo>\u2062</mo><mi>H</mi></mrow><mo>+</mo><msup><mi>W</mi><mn>2</mn></msup></mrow><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mn>3</mn></mfrac><mo>-</mo><mfrac><mrow><mi>W</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>W</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mn>2</mn></mfrac><mo>-</mo><mfrac><mrow><mi>H</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>H</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mn>2</mn></mfrac></mrow><mo>+</mo><mn>1</mn></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nfor $H=W$. Figure \\ref{fig:memory} shows the dimensions of square\nimages which can be handled by cards with a given memory size\nassuming that one integer takes 4 bytes.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=8cm,keepaspectratio]{GPU_memory.eps}\n\\caption{Illustration of memory requirements for line segments storage.}\n\\label{fig:memory}\n\\end{figure}\n\nAs mentioned, the consecutive steps 2 and 3 are supposed to be called\nrepeatedly within the optimisation process and thus represent the\nprincipal requirements on computational time, see\nAlg.~\\ref{alg:L2_eval} for a more detail algorithmic structure of the\nstep 3. The image enters the algorithm as the matrix $A$ twice wider and\ntwice higher than the original one, because it is periodically copied\non a grid $2 \\times 2$ to allow easily translate the segments starting\nwithin the image and ensure the segments to never end outside the\nimage. The translation is thus defined by moving the starting point of\na segment within one quadrant of the entering image. To facilitate\nthe repeatedly called computations, the indices of moves within one\nquadrant are precomputed and stored in the separate matrix $C$.\n\n\\begin{algorithm}[hbt!]\n \\KwData{ \\\\\n   $A \\dots$ a binary image  defined as an integer vector of size $2W \\cdot 2H$ \\\\\n   $B \\dots$ an irregular 2D integer matrix defining pixels of Bresenham's line segments of size $S\\times$segment size, where $S = 2WH-W-H+1$ \\\\\n   $C \\dots$ an integer vector of size $WH$ defining a translation within an image $W \\times H$ mapped onto a periodically copied image of size $2W \\times 2H$ \\\\\n   $D \\dots$ an integer vector of size $S$ defining a size of particular segments\n   $phase \\dots$ an integer defining phase, for which the $L_2$ is evaluated\n}\n \\KwResult{ $L \\dots$ an integer vector of size $S$ defining the $L_2$}\n \\For{seg=0 \\KwTo $S-1$}{\n \\For{transl=0 \\KwTo $WH-1$}{\n \\For{pix=0 \\KwTo D[seg]}{\n   \\If{A[B[seg][pix]+C[transl]] $\\neq$ phase}{\n     break;\n   }\n }\n \\If{pix = D[seg]}{$L[seg] = L[seg]+1$\\;}\n}}\n\\caption{Algorithmic structure of implementation\ndesigned for CPU device; $seg$, $transl$ and $pix$ represent\n  integer variables used to govern the corresponding\n  for loops.}\n\\label{alg:L2_eval}\n\\end{algorithm}\n\nThe structure of Alg.~\\ref{alg:L2_eval} suggests several ways of\npossible parallelisation. One way is a parallelisation over\nparticular segments (line 1), which would, however, lead to a very\nasynchronous computation due to large differences among lengths of\nthe segments. Parallelisation over translations (line 2) is not\ncompletely synchronous, because its inner cycle over pixels of the\nsegment (line 3) is stopped when proceeds to a pixel which is not\nlying in a given phase, which depends on a particular image\nmorphology. Nevertheless, the computation have at least a chance\nto be more synchronous than the surely highly asynchronous\nparallelisation over segments.\n\nFortunately, the algorithm clearly consists of a huge number of very\nsimple logic and arithmetic operations and is thus well-suited for\nparallelisation on GPU because of following reasons:\n\n\\begin{itemize}\n\\item [(i)] It allows for a nearly synchronous parallelisation scheme\n  thus respecting the basic GPU programming rule -- memory\n  coalescence;\n\\item [(ii)] It corresponds to the SIMD (single instruction, multiple\n  data) architecture: a single instruction is an index of segment to be\n  compared with the image at all possible positions, which thus\n  represents the multiple data;\n\\item [(iii)] The most of the memory transfer corresponding to copying of\n  image, translations, line segments and their sizes is done only once\n  and in large chunks thus reducing related system overhead.\n\\end{itemize}\n\n\nThe parallel algorithmic structure proposed to increase the numerical\nefficiency of the $L_2$ computation is given in Alg.~\\ref{alg:GPU}. The\ncrucial step for the implementation efficiency concerns line 9, where\nall $n_{\\mathrm{t}} = WH$ translations are distributed into available\nmultiprocessors (MP).  Since particular GPU architectures\nsignificantly differ among each other, here we concentrate on Fermi\ncompute architecture \\cite{Nvidia}, where each MP has $32$\nsingle-precision CUDA cores.  It means that each MP can simultaneously\nsolve up to $32$ tasks -- so-called threads -- defining one\nwarp. Besides currently computing threads, the MP can already load and\nprepare other threads up to maximally $1536$ threads = $48$ warps. The\ntasks are sent to the MP in blocks, where the particular translation is\nassigned to the particular thread automatically according to its position\nwithin the block.  Storing the translations in a 1D vector instead of\na 2D matrix thus allows for more even distribution of translations among\nthe MPs. Each MP can handle at the same time maximally $8$ blocks.\nParticular size of a block can be chosen by a programmer, but finding\nan optimum is not so straightforward. So as to maximise the occupancy\nof the MPs, it is convenient to define the size of block B as\n\n\\begin{eqnarray}\n\\mathrm{B} = \\left\\{\n\\begin{array}{l}\n1\\times6 \\, \\mathrm{warps} = 1\\times192  \\, \\mathrm{threads}, \\quad \\mbox{if } \\left\\lceil\\frac{n_{\\mathrm{t}}}{n_{\\mathrm{mp}}}\\right\\rceil \\geq 1536, \\\\\n1\\times\\left\\lceil\\frac{n_{\\mathrm{t}}}{8n_{\\mathrm{mp}}}\\right\\rceil \\mathrm{threads}, \\quad \\mbox{otherwise,}\n\\end{array}\n\\right.\n\\label{eq:block}\n\\end{eqnarray}\n\nwhere $\\left\\lceil \\cdot \\right\\rceil$ denotes the round-up\noperation to the nearest integer and $n_{\\mathrm{mp}}$ is a number\nof available MPs. Nevertheless, other aspects related to shared\nmemory and registers \\cite{Nvidia} may move the preferences\ntowards bigger blocks. More detailed study on the optimal block\nsize is beyond the scope of this paper. In our computations, we\nfocused on occupancy maximisation only and the block size is set\naccording to Eq.~\\eqref{eq:block}.\n\n\\begin{algorithm}[hbt!]\n \n \n CPU: \\hspace{12mm} calculating line segments: indices in $B$ and sizes in $D$\\;\n CPU$\\rightarrow$GPU: copying $B$ and $D$ into GPU\\;\n CPU: \\hspace{12mm} loading and copying binary image onto grid $2 \\times 2$ saved \\\\\n      \\hspace{25mm}into $A$, defining translations $C$ \\;\n CPU$\\rightarrow$GPU: copying $C$ and $phase$ into GPU\\;\n CPU$\\rightarrow$GPU: copying $A$ into GPU\\;\n \\For{$seg=0$ \\KwTo $S-1$}{\n    CPU$\\rightarrow$GPU: copying $seg$ into GPU\\;\n    GPU calls threads: \\For{$transl=0$ \\KwTo $WH-1$}{\n        $L[seg] = 0$\\;\n        \\For{pix=0 \\KwTo D[seg]}{\n          \\If{A[B[seg][pix]+C[transl]] $\\neq$ phase}{\n            break;\n          }\n        }\n        \\If{pix = D[seg]}{$L[seg] = L[seg]+1$\\;}\n    }\n }\n CPU$\\leftarrow$GPU: copying $L$ to CPU\\;\n\\caption{Simplified algorithmic structure of implementation designed\n  for single GPU device; All variables are defined in\n  Alg.~\\ref{alg:L2_eval}.} \\label{alg:GPU}\n\\end{algorithm}\n\n\n\\subsection{Algorithmic acceleration of $L_2$ evaluation}\n\nBesides the parallelisation, we also propose one simple\nalgorithmic acceleration of the lineal path computation. The idea\ncomes from the discrete nature of segments and a fact that some\nshorter segments are overlapped by some longer segments. See Fig.\n\\ref{fig:overlap}, where all segments start at $\\vek{x}_1 = (0,0)$\nand those ending in red pixels are overlapped by segments ending\nin black pixels.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=5.5cm,keepaspectratio]{L2path.eps}\n\\caption{Illustration of overlapping line segments}\n\\label{fig:overlap}\n\\end{figure}\n\nIf a segment never falls entirely in a given phase and its $L_2$\nvalue is zero, it is obvious that all longer overlapping segments\nwill have the zero value as well. This simple logic brings\nadditional significant time savings in the $L_2$ evaluation. It\nonly needs to precalculate a vector containing the indices of the\nlongest shorter overlapping segments (LSOS). Such a precalculation\nis computational expensive, but is done only once at the beginning\nof the algorithm. Having in mind that steps 6 to 21 in\nAlg.~\\ref{alg:GPU} are supposed to be called repeatedly within an\noptimisation process, this precalculation should take place before\nstep 3.  Then one simple if-condition is added before translating\nand comparing the segments with the image. If the LSOS\ncorresponding to the current segment has zero value of $L_2$, then\nthe $L_2$ value of the current segment is automatically assigned\nto zero value too and the translating and comparing phase is\nskipped. To be more specific, there are two possibilities where\nthis crucial if-condition can be solved. It would be an intuitive\nsolution to solve this if-condition on CPU, i.e. before line 8 of\nthe Alg.~\\ref{alg:GPU} so as to skip the whole calling of GPU.\nHowever, in such a case, the CPU needs to have knowledge about\npreviously computed segments, which means that the value of the\nlineal path function has to be sent to CPU for every segment\nseparately inside the for-loop before line 18. Our computations,\nhowever, revealed that repeated sending of one integer from GPU to\nCPU is time-consuming and it is faster to call repeatedly the GPU,\nsolve the if-condition there (i.e. before line 10) and store all\nthe computed values of the lineal path function only on GPU until\nthe last segment is computed. Then sending of the whole vector of\nthe lineal path values brings significant time savings. This\nlatter variant was implemented and is further called as {\\it\nenhanced}, while the original version of the algorithm without any\nalgorithmic acceleration is called {\\it standard}.\n\nThe performance of GPU parallelism is demonstrated on evaluation\nof the $L_2$-function on three different microstructures: (i)\nchess-type morphology with dimensions of squares $10\\times 10$\n[px], (ii) particulate suspension consisting of equal-sized\nsquares with dimensions $4\\times 4$ [px] and (iii) metal foam\ntaken from ~\\cite{Jirousek:JI:2013}. Tab.~\\ref{tab:comptime}\ncompares the amount of time necessary averaged over five\nevaluations of the lineal path function for both phases on single\nCPU or GPU devices depending on the image size and chosen variant\nof the algorithm. In particular, the computational times\ncorrespond to a part of the lineal path function computation,\nwhich is called repeatedly within the optimisation process, i.e.\nevaluation of lines 1 to 5 in Alg.~\\ref{alg:GPU} is excluded. It\nis shown that for very small images the use of CPU outperforms the\nGPU because of additional time spent by communicating with the\nGPU. Nevertheless, for images of $50\\times 50\\,\\mathrm{[px]}$ the\nGPU achieves an evident speed-up which mostly further increases\nwith the increasing dimensions of the image. The exception is the\nchess-type microstructure where a specific phase distribution\nlimits the length of the most of the line segments to $10$ [px].\nThis significantly elevates the acceleration obtained for the\nenhanced variant of the algorithm and even the CPU version is so\nfast that communication with GPU leads again to deceleration which\nincreases with the image dimensions.\n\n\\cleardoublepage\n\\begin{table}[h!]\n\\begin{center}\n\\begin{tabular}{p{2cm}|p{1.4cm}p{1.4cm}l|p{1.4cm}p{1.4cm}l|l}\n\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MC_figA.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$  & GPU\n& CPU  & $S$ & $S^{*}$\\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$\\\\\n\\hline\n$10\\times 10$   & 2.4$\\cdot 10^{-3}$  & 0.59$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$   & 2.4$\\cdot 10^{-3}$ & 0.39$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$ & \\textbf{0.2}$\\times$\\\\\n$20\\times 20$ & 11.9$\\cdot 10^{-3}$   & 11.9$\\cdot 10^{-3}$    & \\textbf{1.0}$\\times$  & 11.1$\\cdot 10^{-3}$  & 7.8$\\cdot 10^{-3}$    & \\textbf{0.7}$\\times$ & \\textbf{1.1}$\\times$\\\\\n$50\\times 50$   & 0.15  & 0.55    & \\textbf{3.7}$\\times$   & 0.10  & 0.24    & \\textbf{2.5}$\\times$ & \\textbf{5.8}$\\times$\\\\\n$100\\times 100$ & 2.1   & 7.0    & \\textbf{3.3}$\\times$  & 0.26  & 0.27    & \\textbf{1.0}$\\times$ & \\textbf{27.0}$\\times$\\\\\n$200\\times 200$ & 32.6  & 110.9   & \\textbf{3.4}$\\times$  & 2.0  & 1.0   & \\textbf{0.5}$\\times$ & \\textbf{53.9}$\\times$\\\\\n$500\\times 500$ & 318.4 & 1071.1 & \\textbf{3.4}$\\times$  & 16.3 & 6.4  & \\textbf{0.4}$\\times$ & \\textbf{65.8}$\\times$\\\\\n\\hline\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MC_figB.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$ & GPU\n& CPU  & $S$ & $S^{*}$ \\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$ \\\\\n\\hline\n$10\\times 10$   & 2.5$\\cdot 10^{-3}$  & 0.71$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$   & 2.5$\\cdot 10^{-3}$  & 0.38$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$ & \\textbf{0.3}$\\times$\\\\\n$20\\times 20$ & 12.9$\\cdot 10^{-3}$   & 16.0$\\cdot 10^{-3}$    & \\textbf{1.2}$\\times$  & 12.5$\\cdot 10^{-3}$  & 8.2$\\cdot 10^{-3}$    & \\textbf{0.7}$\\times$ & \\textbf{1.3}$\\times$\\\\\n$50\\times 50$   & 0.16  & 0.81    & \\textbf{5.0}$\\times$   & 0.13  & 0.36    & \\textbf{2.7}$\\times$ & \\textbf{6.0}$\\times$\\\\\n$100\\times 100$ & 2.5   & 16.1    & \\textbf{6.4}$\\times$  & 1.7  & 7.2    & \\textbf{4.1}$\\times$ & \\textbf{9.3}$\\times$\\\\\n$200\\times 200$ & 41.9  & 256.3   & \\textbf{6.1}$\\times$  & 20.8  & 78.0   & \\textbf{3.7}$\\times$ & \\textbf{12.3}$\\times$\\\\\n$500\\times 500$ & 411.6 & 2544.0 & \\textbf{6.2}$\\times$  & 205.1 & 789.1  & \\textbf{3.9}$\\times$ & \\textbf{12.4}$\\times$\\\\\n\\hline\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MF_500.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$  & GPU\n& CPU  & $S$ & $S^{*}$\\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$ \\\\\n\\hline\n$10\\times 10$   & 2.4$\\cdot 10^{-3}$  & 0.73$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$   & 2.4$\\cdot 10^{-3}$  & 0.65$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$ & \\textbf{0.3}$\\times$\\\\\n$20\\times 20$ & 12.0$\\cdot 10^{-3}$   & 13.8$\\cdot 10^{-3}$    & \\textbf{1.1}$\\times$  & 11.9$\\cdot 10^{-3}$  & 9.7$\\cdot 10^{-3}$    & \\textbf{0.8}$\\times$ & \\textbf{1.2}$\\times$\\\\\n$50\\times 50$   & 0.17  & 1.31    & \\textbf{7.6}$\\times$   & 0.15  & 0.67    & \\textbf{4.4}$\\times$ & \\textbf{8.7}$\\times$\\\\\n$100\\times 100$ & 2.8   & 31.9    & \\textbf{11.5}$\\times$  & 2.22  & 17.2    & \\textbf{7.7}$\\times$ & \\textbf{14.3}$\\times$\\\\\n$200\\times 200$ & 48.3  & 577.9   & \\textbf{12.0}$\\times$  & 32.9  & 241.7   & \\textbf{7.3}$\\times$ & \\textbf{17.5}$\\times$\\\\\n$500\\times 500$ & 542.1 & 7911.7 & \\textbf{14.6}$\\times$  & 445.2.1 & 3884.2  & \\textbf{8.7}$\\times$ & \\textbf{17.7}$\\times$\\\\\n\\hline\n\\end{tabular}\n\\caption{Comparison of CPU and GPU performance averaged over five\nevaluations ($S$ stands for speedup and $S^{*}$ represents overall\nspeedup obtained by hardware and software accelaration) }\n\\label{tab:comptime}\n\\end{center}\n\\end{table}\n\nThe particular computations presented in Tab.~\\ref{tab:comptime}\nwere performed on $2\\times$ INTEL Xeon E$5-2620$ @ $2.0$ GHz, $96$\nGB RAM, $2\\times$ GPU - NVIDIA QUADRO $4000$ with Micrsosoft\nWindows~$7$ $64$-bit operating system and the CUDA v. $6.5$.\nFurthermore, the algorithm is also designed for dual GPUs,\nunfortunately scalability towards the multiple GPU devices is not\nconsidered here. The logical step for the dual GPU algorithm is to\nuniformly distribute the generated segments, so that each device\nholds only a certain amount of them. This improvement thus results\nin lower memory requirements.\n\n\n\\section{Optimisation procedure} \\label{sec:optim}\nBefore proceeding to the comparative study of the lineal path and\ntwo-point probability function, we briefly describe the\noptimisation procedure employed in our computations. Here, we used\nthe framework firstly introduced by Yeong and\nTorquato~\\cite{Yeong:1998:PRE} for digitised media. The algorithm\nis based on simulated annealing method independently developed by\nKirkpatrick et al.~\\cite{Kirkpatrick:S:1983} and\n\\v{C}ern\\'{y}~\\cite{Cerny:JOTA:1985}. It starts with some randomly\ngenerated microstructure and quantification of its quality by a\nchosen statistical descriptor. The microstructure is then modified\nby a chosen operator and its new quality is evaluated. The\nacceptance of the proposed modification is governed by the\nMetropolis rule, which allows with a certain probability to accept\na worse solution and thus to escape from a local extreme. Such a\ngeneric optimisation scheme opens the possibility to define\nmodification operator suitable for a given microstructure. For\ninstance, a particulate suspension consisting of equal-sized discs\ncan be modified by moving a centre of an arbitrarily chosen disc,\nsee e.g. \\cite{Novak:PR:2012,Novak:MSMSE:2013}. Such a move\naffects the whole set of pixels and allows preserving the known\nshape of particles, thus accelerating the optimisation procedure.\nMost of the microstructures are, however, not consisting of\nparticles having a specific known shape. Then the simplest\nmodification operator is based on interchanging two randomly\nchosen pixels from different phases, which at least allows to\npreserve their volume fraction~\\cite{Yeong:1998:PRE}. Very simple\nacceleration employed in our implementation consists in a random\nselection of interfacial pixels which leads to a significant\nincrease of accepted modifications, as presented in\n\\cite{Rozman:2001:PRE}.\n\n\n\\begin{algorithm}[hbt!]\n \\KwData{binary image with dimensions $W\\times H$}\n \\KwResult{optimised SEPUC corresponding to given image} \n $create\\_random\\_image(P)$\\;\n $SDP = evaluate(P)$\\;\n $T = T_{\\max}$\\;\n $T_{\\mathrm{mult}} = (T_{\\mathrm{min}}/T_{\\mathrm{max}})^{(succ_{\\mathrm{max}}/N_{\\mathrm{step}})}$\\;\n \\While{$c<N_{\\mathrm{step}}$}{\n   $c = s = 0$\\;\n   \\While{$c<c_{\\max} \\quad \\& \\quad s<s_{\\max}$}{\n     $c = c + 1$\\;\n     $Q = modify(P)$ \\;\n     $SDQ = evaluate(Q)$\\;\n     \\If{random\\_number U[0,1] $< \\exp((SDQ-SDP)/T)$}{\n       $s = s + 1$\\;\n       $P = Q$\\;\n       $SDP = SDQ$\\;\n     }\n   }\n   $T = T \\cdot T_{\\mathrm{mult}}$\\;\n }\n\\caption{Algorithmic structure of simulated annealing} \\label{alg:annealing}\n\\end{algorithm}\n\nSince the proposed way of porting the lineal path evaluation onto\nGPU counts with copying the whole image from CPU to GPU for any\nnew proposed modification, the modification operator can be\ndesigned in any convenient way. Nevertheless, our further\ncomputations use solely the interchanging of two pixels.\nThe particular structure of the employed optimisation algorithm is given\nin Alg.~\\ref{alg:annealing}. First of all, a random digitised\nimage $P$ is created with the same volume fractions of phases as\nthe original morphology. Its statistical similarity to the original\nimage is then evaluated using the chosen statistical descriptor SD\nas the least square error:\n\n\n", "itemtype": "equation", "pos": 27921, "prevtext": "\n\nfor $W \\leq H$ and to\n\n\n", "index": 25, "text": "\\begin{equation}\nM = \\frac{4W^3 - 4W + 3}{3}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"M=\\frac{4W^{3}-4W+3}{3}\" display=\"block\"><mrow><mi>M</mi><mo>=</mo><mfrac><mrow><mrow><mrow><mn>4</mn><mo>\u2062</mo><msup><mi>W</mi><mn>3</mn></msup></mrow><mo>-</mo><mrow><mn>4</mn><mo>\u2062</mo><mi>W</mi></mrow></mrow><mo>+</mo><mn>3</mn></mrow><mn>3</mn></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.04359.tex", "nexttext": "\n\nwhere the superscript $i$ denotes the phase for which the SD is evaluated\nand the subscript $p$ corresponds to the component of a discretised\ndescriptor. If the superscript $i$ is missing in the following text,\nthe SD is evaluated for both phases. Note that the least square error\nin Eq.~\\eqref{eq:LSE} also consists of a large number of simple\narithmetic operations, which are again efficiently evaluated in\nparallel on GPU.\n\nControl parameters of the algorithm were set to following values:\n\n\\begin{table}[htb]\n\\centering\n\\begin{tabular}{ll}\n$N_{\\mathrm{step}} = 4\\cdot 10^6$ & $c_{\\max} = 0.1 N_{\\mathrm{step}}$ \\\\\n$T_{\\min} = 0.01 T_{\\max}$ & $s_{\\max} = 0.01 N_{\\mathrm{step}}$ \\\\\n\\end{tabular}\n\\caption{Control parameters of simulated annealing method}\n\\label{tab:annealing}\n\\end{table}\n\nThe value of $T_{\\max}$ was manually changed for every particular\ncomputation so as to achieve approximately the ration $s/c = 0.5$\nwithin the first few steps of the algorithm. Some other\nrecommendations for setting these parameters can be found e.g. in\n\\cite{Leps:2003:CS}.\n\n\\section{Microstructure reconstruction}\n\\label{sec:recon}\n\nReconstruction of a microstructure from its statistical\ndescription is an inverse problem addressed by several authors in\ndifferent ways, see\n\\cite{Rozman:2001:PRE,Capek:2009:TPM,Davis:2011:PRE} and the\nreferences therein. Here we follow the concept proposed in\n\\cite{Yeong:1998:PRE}, where the discretised randomly generated\nmicrostructure is optimised with respect to the prescribed\nstatistical descriptor.\n\n\\begin{figure} [b!]\n\\begin{center}\n\\begin{tabular}{c|c|ccc}\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=45mm,keepaspectratio]{Chess_100_100.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Chess_20_20_rnd.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Chess_20_20_S2.eps} \\\\\n    (c) \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Chess_20_20_L2.eps} \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{18.5mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Chess_rnd1.eps}\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{18.5mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Chess_rnd2.eps} \\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\\\\n(a) & (b) & (d) & (e) & (f) \\\\\n\\end{tabular}\n\\end{center}\n\\caption{Chess microstructure: (a) Original medium with size\n  $100\\times 100$ [px] and characteristic lengths $20 \\times 20$ [px];\n  (b) Random initial structure, size $20\\times 20$ [px]; (c)\n  $S_{2}$-based reconstructed image; (d) $L_{2}$-based reconstructed\n  image; (e) $L_{2}^{\\mathrm{b}}$-based reconstructed image; (f)\n  $L_{2}^{\\mathrm{w}}$-based reconstructed image; obtained within less\n  than $5\\cdot 10^5$ iterations.}\n\\label{fig:chess}\n\\end{figure}\n\nThe authors in \\cite{Rozman:2002:PRL} presented numerical evidence\nthat a periodic medium discretised into pixels is completely\nspecified by its two-point correlation function, up to a\ntranslation and, in some cases, inversion.\n\n\n\\begin{figure} [b!]\n\\begin{center}\n\\begin{tabular}{@{\\hspace{0.5mm}}c@{\\hspace{0.5mm}}@{\\hspace{0.5mm}}c@{\\hspace{0.5mm}}|cc}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=40mm,keepaspectratio]{8x3xp2_CLSe.eps}\\\\\n    (a) \\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{8x3xp3_CLSe.eps}\\\\\n    (g) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=20mm,keepaspectratio]{8x3xp2.eps}\\\\\n    \\vspace{30mm}\n    (b) \\\\\n    \\includegraphics*[width=20mm,keepaspectratio]{8x3xp3.eps}\\\\\n    (h) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=40mm,keepaspectratio]{S2w_1_e.eps}\\\\\n    (c)\\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{L2w_test_n.eps}\\\\\n    (e)\\\\\n    \\hline\n    \\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{S2w_2_e.eps}\\\\\n    (i)\\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{L2w_test_n.eps}\\\\\n    (k)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=40mm,keepaspectratio]{S2b_1_e.eps}\\\\\n    (d)\\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{L2b_test_n.eps}\\\\\n    (f)\\\\\n    \\hline\n    \\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{S2b_2_e.eps}\\\\\n    (j)\\\\\n    \\includegraphics*[width=40mm,keepaspectratio]{L2b_test_n.eps}\\\\\n    (l)\\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\end{tabular}\n\\end{center}\n\\caption{(a) Original medium, size $20\\times 24$ [px]; (b)\nPeriodic unit cell (PUC), size $2\\times 8$ [px];\n(c)~$S_{2}^{\\mathrm{w}}$-function of PUC;\n(d)~$S_{2}^{\\mathrm{b}}$-function of PUC;\n(e)~$L_{2}^{\\mathrm{w}}$-function of PUC;\n(f)~$L_{2}^{\\mathrm{b}}$-function of PUC; (g) Original medium,\nsize $20\\times 24$ [px]; (h) Periodic unit cell, size $2\\times 8$\n[px]; (i)~$S_{2}^{\\mathrm{w}}$-function of PUC;\n(j)~$S_{2}^{\\mathrm{b}}$-function of PUC;\n(k)~$L_{2}^{\\mathrm{w}}$-function of PUC;\n(l)~$L_{2}^{\\mathrm{b}}$-function of PUC;} \\label{fig:unicity}\n\\end{figure}\n\nThis conclusion implies that the reconstruction process based on\nthe discretised two-point probability function has a unique\nsolution. For many microstructural morphologies, the same holds\nalso for reconstruction from the lineal path function. For\ninstance, the chess-type morphology is fully defined not only by\nlineal path function computed for both phases, but only one of the\nphase is fully sufficient to completely define the morphology, see\nFigure~\\ref{fig:chess}. Nevertheless, generic evidence for a\nunique solution of the lineal path function-based reconstruction\nis missing and is suggested just by findings concerning\norientation-dependent chord length distributions in continuous\ndomains \\cite{Nagel:1993}. On the contrary, we can demonstrate\nthat employing Bresenham's algorithm for the line segments'\ndefinition, the lineal path function does not define a unique\nsolution for a reconstruction process based on a discretised\nmedium.\n\n\n\nFig.~\\ref{fig:unicity} shows an example of two different periodic\ncells of dimensions $2 \\times 8$ pixels. Due to the same volume\nfraction of both phases, the two-point probability functions\nobtained for both phases in Fig.~\\ref{fig:unicity}c-d are\nidentical, which is in agreement with the Eq.~\\ref{eq:S2add}, but\nboth functions differ from the corresponding ones obtained for the\nother cell in Fig.~\\ref{fig:unicity}i-j. The lineal path functions\nare, on the other hand, identical for both phases in\nFig.~\\ref{fig:unicity}e-f as well as for both phases obtained for\nthe second cell in Fig.~\\ref{fig:unicity}k-l. This proves a\nnon-unique solution of a reconstruction process for the chosen\nhighly rough discretisation. Of course, for a higher resolution,\nthe difference between the lineal path function obtained for both\ncells can be again revealed. As a conclusion, the reconstruction\nprocess based on the discretised medium has always a unique\nsolution in case of the two-point probability function and also\nmostly in case of the lineal path function where the differences\namong a potential set of solutions are decreasing with increasing\nresolution.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBased on this conclusion, we can proceed to the comparison of the\nentire lineal path function $L_2$ with its Monte Carlo-based\napproximation $\\tilde{L}_2$ withing the reconstruction\nprocess. Considering the microstructures depicted in\nFig.~\\ref{fig:MC_LP}, we may assume that their reconstruction based on\nthe entire lineal path function will lead to almost the same\nmicrostructures as the original ones in case of the microstructures B\nand C and to exactly same one in case of A. To decrease computational\ndemands of the comparison, we reduced the dimensions of the\nmicrostructures to $50\\times 50$ pixels. The reconstruction process is\ndriven again as the minimisation of the least square error given in\nEq.~\\ref{eq:LSE1}. The Monte Carlo-based approximation -- described in\nSec.~\\ref{sec:imple} -- is applied here to evaluate both the lineal\npath functions of the original as well as of the reconstructed image,\nrespectively. In order to investigate the influence of the\napproximation quality, we have considered three levels corresponding\nto the Monte Carlo evaluation based on $N = 10, 100$ and $1000$\nsamples. The results are compared with the reconstruction based on the\nentire lineal path function, where the number of samples is identical\nwith the number of pixels in the images, i.e. $N = 2500$.\n\nThe relative errors of the final reconstructed $L_2$-based images\nrelated to the entire lineal path function $L_2$ of original images\nare displayed in Fig.~\\ref{fig:ComMicRec}. The displayed values reveal\nthat the reconstruction procedure based on the lineal path\napproximation converges very slowly with the number of evaluated\nsamples and the reconstruction process thus leads to images with the\nlineal path function, which is highly different from the prescribed\none.\n\n\n\n\n\n\n\n\n\\begin{figure} [t!]\n\\begin{center}\n\\begin{tabular}{@{}c@{}|@{\\hspace{0.1cm}}c@{}}\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            A.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figAr.eps}\\[2mm]\n            B.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figBr.eps}\\[2mm]\n            C.~\\includegraphics*[width=15mm,keepaspectratio]{MC_figCr.eps}\\[1mm]\n        \\end{tabular}\n    \\end{adjustbox}\n    &\n    \\begin{adjustbox}{valign=b}\n        \\begin{tabular}{c}\n            \\includegraphics*[width=90mm,keepaspectratio]{reconL2_CMP.eps}\\\\\n        \\end{tabular}\n    \\end{adjustbox}\n\\end{tabular}\n\\end{center}\n\\caption{Comparison of the entire $L_2$ and its approximation\n$\\tilde{L}_2$ used in microstructure reconstruction for different\nvalues of $N$} \\label{fig:ComMicRec}\n\\end{figure}\n\n\n\\section{Microstructure compression} \\label{sec:compress}\n\nWhile the reconstruction process aims at rediscovering of\na microstructure with dimensions and spatial statistics defined by\nthe given descriptor, the compression process tries to reduce the\ninformation content of the given morphology and searches for its\ncompressed representation by a small statistically similar\nperiodic cell \\cite{Zeman:2007:MSMSE,Lee:2009:PRE} or a set of\ncompatible cells \\cite{Novak:PR:2012}. After evaluating a chosen\nstatistical descriptor over the whole available domain of the original\nmedium, one needs to decide about the cells' dimensions and\naccordingly cut the dimensions of the descriptor.  Then the\ncompression process proceeds in an exactly same manner as the\nmicrostructure reconstruction.\n\nAs our numerical implementations of the two-point probability function and\nthe lineal path function are both based on the assumption of periodicity, they\nwill not provide precise results when applied to original random and\nnon-periodic microstructure. Nevertheless, as already mentioned\npreviously, in \\cite{Gajdosik:2006:PEM} it was shown that the\nassumption of periodicity does not introduce a systematic bias in the\nvalues of the descriptors.\n\n\n\\subsection{Particulate suspension}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{c|c|@{}c@{}@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=45mm,keepaspectratio]{ctverce_100_100_200ks.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=22.5mm,keepaspectratio]{ctverce_50_50_50ks_rnd.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=22.5mm,keepaspectratio]{ctverce_50_50_50ks_S2.eps} \\\\\n    (c) \\[5mm]\n    \\includegraphics*[width=22.5mm,keepaspectratio]{ctverce_50_50_50ks_L2.eps} \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{23mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{ctverce_50_50_50ks_L2_white.eps} \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{23mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{ctverce_50_50_50ks_L2_black.eps} \\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\\\\n(a) & (b) & (d) & (e) & (f)\\\\\n\\end{tabular}\n\\end{center}\n\\caption{Particulate suspension: (a) Original medium, size $100\\times\n  100$ [px], particles $4 \\times 4$ [px]; (b) Random initial\n  structure, size $50\\times 50$ [px]; (c) Compressed $S_{2}$-based\n  image, size $50\\times 50$ [px]; (d) Compressed $L_{2}^{\\mathrm{b}}$\n  and $L_{2}^{\\mathrm{w}}$-based image, size $50\\times 50$ [px]; (e)\n  Compressed $L_{2}^{\\mathrm{w}}$-based image, size $50\\times 50$\n  [px]; (f) Compressed $L_{2}^{\\mathrm{b}}$-based image, size\n  $50\\times 50$ [px]} \\label{fig:squares}\n\\end{figure}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{c@{}@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{S2_ctverce_50_50_50ks.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{L2w_ctverce_50_50_50ks.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{L2b_ctverce_50_50_50ks.eps}\n\\end{adjustbox}\n\\\\\n(a) & (b) & (c)\n\\end{tabular}\n\\end{center}\n\\caption{Particulate suspension: (a) Original medium, size\n$100\\times 100$ [px], particles $4\\times 4$ [px]; (b)\n$S_{2}$-function; (c) $L_{2}^{\\mathrm{w}}$-function; (d)\n$L_{2}^{\\mathrm{b}}$-function} \\label{fig:sqBst}\n\\end{figure}\n\n\nThe first example comparing properties of the $S_2$- and\n$L_2$-based compression concerns an artificially created\nparticulate suspension consisting of equal-sized white squares\nrandomly distributed within a black matrix, see\nFig.~\\ref{fig:squares}. The shape of particles is a very\nsignificant property of such a microstructure, which can be easily\npreserved by modifying the optimisation algorithm so as to start\nwith randomly distributed particles and then to move their centres\nwithin the optimisation process. Nevertheless, here we aimed at\ntesting the descriptors in their ability to capture such an\nimportant property within the compression process.\n\nFig.~\\ref{fig:squares}c shows that the $S_2$-based compression\nleads to significant deterioration of the shape of particles. This\nis caused by the very small ratio of the particles over the size\nof the PUC, i.e. $4 \\times 4$ [px] vs. $50 \\times 50$ [px]. The\ninformation about their shape is thus saved on a small portion of\nthe descriptor's domain corresponding to short-range correlations\n(see Fig.~\\ref{fig:sqBst}a), while the most of the domain defines\nlong-range correlations corresponding to the mutual distances of\nthe particles. The lineal path function allows to separate the\ninformation about the shape of particles and their mutual\npositions, since the $L_{2}^{\\mathrm{w}}$ in Fig.~\\ref{fig:sqBst}b\ncontains only the first, while the $L_{2}^{\\mathrm{b}}$ in\nFig.~\\ref{fig:sqBst}c defines mostly the latter. According to\nthat, the $L_{2}^{\\mathrm{w}}$-based compression in\nFig.~\\ref{fig:squares}e leads obviously to the well compressed\nshape of particles, while the $L_{2}^{\\mathrm{b}}$-based\ncompression in Fig.~\\ref{fig:squares}f does not capture the shape\nof particles at all and the $L_2$-based compression in\nFig.~\\ref{fig:squares}d provides a compromise solution. It is hard\nto evaluate the quality of obtained structures in an objective\nmanner, but we can conclude that the $L_2$ function allows a user\nto emphasise short-range effects as needed.\n\nAnother interesting aspect concerns the mutual comparison of the\ncompressed microstructures and the corresponding errors in\ndescribing original medium according to Eq.~\\eqref{eq:LSE1}, which\nare listed in Tab.~\\ref{tab:mutual}. While the optimisation of\n$S_2$ leads to a microstructure which is relatively good also with\nrespect to $L_2$ and comparable with microstructures obtained for\nthe $L_{2}^{\\mathrm{w}}$- or $L_{2}^{\\mathrm{w}}$-based optimisation,\nthe opposite is not true. The microstructures optimised w.r.t. one\nor both phases of $L_2$ manifest very bad correlations, which are\ncomparable or even worse than those obtained for a random image.\nThe lineal path function thus cannot be applied for a\ncorrelations-based compression.\n\n\\begin{table}[htb!]\n\\centering\n\\begin{tabular}{lll}\n\\hline\nCompressed medium & $e(S_2)$  & $e(L_2)$ \\\\\n\\hline\nRandom Fig.~\\ref{fig:squares}b & $3.12 \\cdot 10^{-1}$ & $1.68 \\cdot 10^{1}$ \\\\\n$S_{2}$-based Fig.~\\ref{fig:squares}c & $9.20 \\cdot 10^{-3}$ & $2.35 \\cdot 10^{0}$ \\\\\n$L_{2}$-based Fig.~\\ref{fig:squares}d & $3.09 \\cdot 10^{-1}$ & $2.73 \\cdot 10^{-2}$ \\\\\n$L_{2}^{\\mathrm{w}}$-based Fig.~\\ref{fig:squares}e & $ 3.53 \\cdot 10^{-1}$ & $ 1.08 \\cdot 10^{0}$ \\\\\n$L_{2}^{\\mathrm{b}}$-based Fig.~\\ref{fig:squares}f & $ 6.52 \\cdot 10^{-1}$ & $ 9.60 \\cdot 10^{-1}$ \\\\\n\\hline\n\\end{tabular}\n\\caption{Mutual comparison of compressed microstructures.}\n\\label{tab:mutual}\n\\end{table}\n\n\\subsection{Epithelial cells}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{c|c|@{}c@{}@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=45mm,keepaspectratio]{Epith.eps} \\\\\n    (a) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{15mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Epith_rnd.eps} \\\\\n    (b)\n    \\\\\n    \\vspace{15mm}\\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Epith_S2_rnd.eps} \\\\\n    (c) \\[5mm]\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Epith_BW_04736.eps} \\\\\n    (d) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{23mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Epith_L2_white.eps} \\\\\n    (e) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\begin{tabular}{c}\n    \\vspace{23mm}\\\\\n    \\\\\n    \\includegraphics*[width=22.5mm,keepaspectratio]{Epith_B_04736.eps} \\\\\n    (f) \\\\\n    \\end{tabular}\n\\end{adjustbox}\n\\\\\n\\end{tabular}\n\\end{center}\n\\caption{Epithelial cells: (a) Original medium, size $510\\times\n510$ [px]; (b) Random initial structure, size $100\\times 100$\n[px]; (c) Compressed $S_{2}$-based image, size $100\\times 100$\n[px]; (d) Compressed $L_{2}^{\\mathrm{b}}$ and\n$L_{2}^{\\mathrm{w}}$-based image, size $100\\times 100$ [px]; (e)\nCompressed $L_{2}^{\\mathrm{w}}$-based image, size $100\\times 100$\n[px]; (f) Compressed $L_{2}^{\\mathrm{b}}$-based image, size\n$100\\times 100$ [px]} \\label{fig:epith}\n\\end{figure}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{c@{}@{}c@{}@{}c@{}}\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{S2_Epith.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{L2w_Epith.eps}\n\\end{adjustbox}\n&\n\\begin{adjustbox}{valign=m}\n    \\includegraphics*[width=50mm,keepaspectratio]{L2b_Epith.eps}\n\\end{adjustbox}\n\\\\\n(a) & (b) & (c)\n\\end{tabular}\n\\end{center}\n\\caption{Epithalial cells: (a) Original medium, size $100\\times 100$\n  [px]; (b) $S_{2}$-function; (c) $L_{2}^{\\mathrm{w}}$-function; (d)\n  $L_{2}^{\\mathrm{b}}$-function} \\label{fig:epithBst}\n\\end{figure}\n\n\nEpithalial cells are a typical example of morphology characterised\nby very thin and continuous walls, see Fig.~\\ref{fig:epith}a.\nTheir volume fraction is very small, only $4.97\\,\\mathrm{[\\%]}$\nand thickness is mostly equal to only $1$ pixel.  The assembling\nof continuous walls from random initial arrangement is rather\nunattainable. As can be expected, the two-point probability\nfunction fails completely in this task, see Fig.~\\ref{fig:epith}c.\nNevertheless, the assumption that the continuity of the white\nwalls can be captured by the lineal path computed for the white\nphase is wrong. As a matter of fact, the nonlinear walls are\ncomposed of a set of short line segments and the\n$L_{2}^{\\mathrm{w}}$-based compression thus leads to their random\nstars-resembling arrangement as visible in Fig.~\\ref{fig:epith}e.\nThe continuity of walls is actually closely related to cells,\nwhose limited size requires the continuity of the surrounding\nmedium. As a consequence, the information about the continuity of\nwalls is surprisingly hidden in $L_{2}^{\\mathrm{b}}$, see results\nof $L_{2}^{\\mathrm{b}}$-based compression in\nFig.~\\ref{fig:epith}f. Due the small volume fraction of the white\nphase, its influence on the $L_2$-based compression is rather\nsmall and the results are principally similar to the\n$L_{2}^{\\mathrm{b}}$-based compression, cf. Figs.~\\ref{fig:epith}d\nand \\ref{fig:epith}f. The remaining discontinuities are very\ndifficult to be improved within the proposed optimisation strategy\nbased on random interchanging of two pixels. We can only assume\nthat the full connectivity of walls can be obtained using some\nmore sophisticated modification operator.\n\n\\subsection{Trabecular bone}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{ccc}\n\\multicolumn{3}{c}{\\includegraphics*[width=100mm,keepaspectratio]{Fig_orig.eps}} \\\\\n\\multicolumn{3}{c}{(a)} \\\\\n\\includegraphics*[width=35mm,keepaspectratio]{Fig_random.eps} &\n\\includegraphics*[width=35mm,keepaspectratio]{Fig_S2.eps} &\n\\includegraphics*[width=35mm,keepaspectratio]{Fig_final.eps} \\\\\n(b) & (c) & (d) \\\\\n\\end{tabular}\n\\end{center}\n\\caption{Trabecular bone microstructure obtained by micro Computed\n  Tomography~\\cite{Jirousek:NIMPRSA:2011}: (a) $3$-D cuts of original\n  structure, $100\\times 100$ [px]; (b) Initial random morphology\n  corresponding to volume fraction $\\phi^{\\mathrm{b}}$ and\n  $\\phi^{\\mathrm{w}}$ of original medium, $100\\times 100$ [px]; (c)\n  Compressed $S_{2}$-based structure, $100\\times 100$ [px]; (d)\n  Compressed $L_{2}$-based structure, $100\\times 100$ [px]}\n\\label{fig:bone}\n\\end{figure}\n\n\\begin{figure} [h!]\n\\begin{center}\n\\begin{tabular}{@{}c@{}|@{}c@{}}\n    \\begin{adjustbox}{valign=m}\n        \\begin{tabular}{c}\n            \\includegraphics*[width=15mm,keepaspectratio]{Fig_S2.eps}\\[40mm]\n            \\includegraphics*[width=15mm,keepaspectratio]{Fig_final.eps}\\\\ [40mm]\n            \\includegraphics*[width=15mm,keepaspectratio]{Fig_final.eps}\n        \\end{tabular}\n    \\end{adjustbox}\n    &\n    \\begin{adjustbox}{valign=m}\n        \\begin{tabular}{cc}\n            \\includegraphics*[width=50mm,keepaspectratio]{S2_final_e.eps} &\n            \\includegraphics*[width=55mm,keepaspectratio]{S2_cuts_e.eps} \\\\\n            (a) & (b) \\[-0.5cm]\n            \\includegraphics*[width=50mm,keepaspectratio]{L2w_Final_e.eps}&\n            \\includegraphics*[width=55mm,keepaspectratio]{L2w_cut_e.eps} \\\\\n            (c) & (d) \\[-0.5cm]\n            \\includegraphics*[width=50mm,keepaspectratio]{L2b_Final_e.eps}&\n            \\includegraphics*[width=55mm,keepaspectratio]{L2b_cut_e.eps} \\\\\n            (e) & (f)\n        \\end{tabular}\n    \\end{adjustbox}\n\\end{tabular}\n\\end{center}\n\\caption{Results of compressed trabecular bone microstructure: (a)\n  $S_2$-function of compressed $S_{2}$-based medium; (b) Comparison of\n  $S_2$-functions in cut 1-1; (c) $L_{2}^{\\mathrm{w}}$-function of\n  compressed $L_{2}$-based system; (d) Comparison of\n  $L_{2}^{\\mathrm{w}}$-functions in cut 1-1; (e)\n  $L_{2}^{\\mathrm{b}}$-function of compressed $L_{2}$-based system;\n  (f) Comparison of $L_{2}^{\\mathrm{b}}$-functions in cut 1-1; }\n\\label{fig:boneResult}\n\\end{figure}\n\nThe last example concerns trabecular bone, which represents a medium with\napproximately equal volume fractions of both phases creating\ncontinuous irregular branches. Our original microstructural specimen\nconsists of $100 \\times 100 \\times 100$ [px] three-dimensional image\nobtained by micro Computed Tomography~\\cite{Jirousek:NIMPRSA:2011}. We\ndivide this data into ensemble of $100$ two-dimensional cuts $100\n\\times 100$ [px] and by employing the assumption of ergodicity, the\nstatistical descriptors are computed as an average over the ensemble.\n\nThe computational effort in case of the $L_{2}$-based reconstruction is\nenormous. Although the part of the $L_{2}$ calculation was ported to GPU,\nthe whole compression process for image $100\\times 100$ [px] lasted\ndays, recall Tab.~\\ref{tab:comptime} for time requirements of the single\n$L_{2}$ evaluation. According to relations in Sec.~\\ref{sec:statdes},\nthe overall number of operations for single standard\ncalculation\\footnote{The number of operations related to enhanced\n  version of $L_{2}^{i}$ evaluation cannot be determined exactly\n  because of missing knowledge about zero segments. However, it is\n  approximately $97$ percent less operations for dimensions $100\\times\n  100$ [px], i.e. approximately $2.0\\cdot 10^{8}$ operations.} of\nthe $L_{2}^{i}$-function is $6.716\\cdot 10^{9}$ comparing to\n$1.021\\cdot 10^{5}$ operations of the $S_{2}$ evaluation.\n\nThe final compressed $S_{2}$ and $L_2$-based structures are shown\nin Figs.~\\ref{fig:bone}c and d, respectively.  The $S_{2}$- and\n$L_{2}$-functions of original and new microstructures are then\nsummarised in Fig.~\\ref{fig:boneResult}. It is clearly visible\nthat the optimised functions very well coincide with the\nprescribed ones, see Fig.~\\ref{fig:boneResult}b,d,f. However, the\nsame does not hold for a microstructure optimised w.r.t. one\ndescriptor, but then evaluated w.r.t. to other. The $L_2$-based\ncompressed microstructure manifests much stronger short-range\ncorrelations, see Fig.~\\ref{fig:boneResult}b, while the\n$S_2$-based compressed microstructure underestimates the\nconnectivity and, especially in the black phase, consists of a smaller\nnumber of continuous line segments, see\nFig.~\\ref{fig:boneResult}f. Nevertheless, we can conclude that\nboth descriptors provide visually well compressed microstructures\nand even the two-point probability function allows to obtain\ncontinuous regions similar to the original medium.\n\n\\section{Conclusions}\n\\label{sec:concl}\n\nThe paper is devoted to comparison of the lineal path function and\nthe two-point probability function in reconstruction and\ncompression of two-phase microstructures. So as to investigate\nproperties of the descriptors in a sufficient detail and to avoid\nsome misleading conclusions based on rough discretisation of the\nlineal path by an approximately evaluated sampling template, the\naccelerated version of the entire lineal path function was\nproposed. The acceleration involves namely reformulation of the\nsequential C/C++ code for the repeatedly called part of the lineal\npath function into the parallel C/C++ code with CUDA extensions\nenabling the use of computational potential of the NVIDIA graphics\nprocessing unit (GPU). Even though the algorithm requires to copy\nrelatively large data structures to the GPU, it was shown that the\nprincipal limitations reside in computational time required within\nthe compression or reconstruction process, where the lineal path\nfunction needs to be often called more than million times. Despite\nthe parallel evaluation of the lineal path function on GPU, the\nevaluation of the two-point probability function remains faster\neven on a single CPU thanks to its accelerated formulation based\non the Fast Fourier Transform.\n\nThe accelerated discrete versions of both descriptors were\nsuccessfully employed for microstructure reconstruction and\ncompression processes governed by the simulated annealing algorithm\nbased on interchanging of two interfacial pixels belonging to\nopposite phases. It was demonstrated that unlike the two-point\nprobability function, the discrete version of the lineal path function\nbased on line segments defined by Bresenham's algorithm does not\ngenerally ensure a unique solution of a reconstruction process.\nNevertheless, the difference among the feasible solutions is small\nand decreases with the increasing resolution. On the other hand,\nmany different morphologies could be fully defined by the lineal path\ncomputed for only one continuous phase.\n\nThree particular microstructures were employed for illustration of\ntypical features of both descriptors. The particulate suspension\nconsisting of equal sized squares revealed incapability of the\n$S_2$ function to capture the shape of particles, which can be\nemphasised by the $L_2$ function. Example of epithelial cells\ndemonstrated that very thin walls also cannot be captured by the\n$S_2$ function and that the computation of $L_2$ corresponding to\nthe phase of walls is surprisingly not needed to achieve the\nmostly connected walls in the compressed cell. Trabecular bone, on\nthe other hand, represents an example of mutually penetrating\nphases of comparable volume fractions, where both descriptors\nprovided visually well looking microstructures.\n\nWe may conclude that despite the proposed acceleration steps, the\nlineal path function remains computationally expensive descriptor,\nwhich can be, however, essential for compression of morphologies\nconsisting of specific formations such as particles or thin\nwalls.\n\n\\section*{Acknowledgment}\nThis outcome has been achieved with the financial support of the\nCzech Science Foundation, projects No.~105/12/1146,\nNo.~105/11/P370 and No.~13-24027S. We would like to thank\nOnd\\v{r}ej Jirou\\v{s}ek of Institute of Theoretical and Applied\nMechanics, Czech Republic for providing us the measured image data\nof microstructures and Jan Zeman of Czech Technical University,\nCzech Republic, for bringing our attention to coupling the spatial\nstatistics with GPU computations.\n\n\\bibliographystyle{elsarticle-num}\n\\bibliography{liter}\n\n\n", "itemtype": "equation", "pos": 46945, "prevtext": "\n\nfor $H=W$. Figure \\ref{fig:memory} shows the dimensions of square\nimages which can be handled by cards with a given memory size\nassuming that one integer takes 4 bytes.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=8cm,keepaspectratio]{GPU_memory.eps}\n\\caption{Illustration of memory requirements for line segments storage.}\n\\label{fig:memory}\n\\end{figure}\n\nAs mentioned, the consecutive steps 2 and 3 are supposed to be called\nrepeatedly within the optimisation process and thus represent the\nprincipal requirements on computational time, see\nAlg.~\\ref{alg:L2_eval} for a more detail algorithmic structure of the\nstep 3. The image enters the algorithm as the matrix $A$ twice wider and\ntwice higher than the original one, because it is periodically copied\non a grid $2 \\times 2$ to allow easily translate the segments starting\nwithin the image and ensure the segments to never end outside the\nimage. The translation is thus defined by moving the starting point of\na segment within one quadrant of the entering image. To facilitate\nthe repeatedly called computations, the indices of moves within one\nquadrant are precomputed and stored in the separate matrix $C$.\n\n\\begin{algorithm}[hbt!]\n \\KwData{ \\\\\n   $A \\dots$ a binary image  defined as an integer vector of size $2W \\cdot 2H$ \\\\\n   $B \\dots$ an irregular 2D integer matrix defining pixels of Bresenham's line segments of size $S\\times$segment size, where $S = 2WH-W-H+1$ \\\\\n   $C \\dots$ an integer vector of size $WH$ defining a translation within an image $W \\times H$ mapped onto a periodically copied image of size $2W \\times 2H$ \\\\\n   $D \\dots$ an integer vector of size $S$ defining a size of particular segments\n   $phase \\dots$ an integer defining phase, for which the $L_2$ is evaluated\n}\n \\KwResult{ $L \\dots$ an integer vector of size $S$ defining the $L_2$}\n \\For{seg=0 \\KwTo $S-1$}{\n \\For{transl=0 \\KwTo $WH-1$}{\n \\For{pix=0 \\KwTo D[seg]}{\n   \\If{A[B[seg][pix]+C[transl]] $\\neq$ phase}{\n     break;\n   }\n }\n \\If{pix = D[seg]}{$L[seg] = L[seg]+1$\\;}\n}}\n\\caption{Algorithmic structure of implementation\ndesigned for CPU device; $seg$, $transl$ and $pix$ represent\n  integer variables used to govern the corresponding\n  for loops.}\n\\label{alg:L2_eval}\n\\end{algorithm}\n\nThe structure of Alg.~\\ref{alg:L2_eval} suggests several ways of\npossible parallelisation. One way is a parallelisation over\nparticular segments (line 1), which would, however, lead to a very\nasynchronous computation due to large differences among lengths of\nthe segments. Parallelisation over translations (line 2) is not\ncompletely synchronous, because its inner cycle over pixels of the\nsegment (line 3) is stopped when proceeds to a pixel which is not\nlying in a given phase, which depends on a particular image\nmorphology. Nevertheless, the computation have at least a chance\nto be more synchronous than the surely highly asynchronous\nparallelisation over segments.\n\nFortunately, the algorithm clearly consists of a huge number of very\nsimple logic and arithmetic operations and is thus well-suited for\nparallelisation on GPU because of following reasons:\n\n\\begin{itemize}\n\\item [(i)] It allows for a nearly synchronous parallelisation scheme\n  thus respecting the basic GPU programming rule -- memory\n  coalescence;\n\\item [(ii)] It corresponds to the SIMD (single instruction, multiple\n  data) architecture: a single instruction is an index of segment to be\n  compared with the image at all possible positions, which thus\n  represents the multiple data;\n\\item [(iii)] The most of the memory transfer corresponding to copying of\n  image, translations, line segments and their sizes is done only once\n  and in large chunks thus reducing related system overhead.\n\\end{itemize}\n\n\nThe parallel algorithmic structure proposed to increase the numerical\nefficiency of the $L_2$ computation is given in Alg.~\\ref{alg:GPU}. The\ncrucial step for the implementation efficiency concerns line 9, where\nall $n_{\\mathrm{t}} = WH$ translations are distributed into available\nmultiprocessors (MP).  Since particular GPU architectures\nsignificantly differ among each other, here we concentrate on Fermi\ncompute architecture \\cite{Nvidia}, where each MP has $32$\nsingle-precision CUDA cores.  It means that each MP can simultaneously\nsolve up to $32$ tasks -- so-called threads -- defining one\nwarp. Besides currently computing threads, the MP can already load and\nprepare other threads up to maximally $1536$ threads = $48$ warps. The\ntasks are sent to the MP in blocks, where the particular translation is\nassigned to the particular thread automatically according to its position\nwithin the block.  Storing the translations in a 1D vector instead of\na 2D matrix thus allows for more even distribution of translations among\nthe MPs. Each MP can handle at the same time maximally $8$ blocks.\nParticular size of a block can be chosen by a programmer, but finding\nan optimum is not so straightforward. So as to maximise the occupancy\nof the MPs, it is convenient to define the size of block B as\n\n\\begin{eqnarray}\n\\mathrm{B} = \\left\\{\n\\begin{array}{l}\n1\\times6 \\, \\mathrm{warps} = 1\\times192  \\, \\mathrm{threads}, \\quad \\mbox{if } \\left\\lceil\\frac{n_{\\mathrm{t}}}{n_{\\mathrm{mp}}}\\right\\rceil \\geq 1536, \\\\\n1\\times\\left\\lceil\\frac{n_{\\mathrm{t}}}{8n_{\\mathrm{mp}}}\\right\\rceil \\mathrm{threads}, \\quad \\mbox{otherwise,}\n\\end{array}\n\\right.\n\\label{eq:block}\n\\end{eqnarray}\n\nwhere $\\left\\lceil \\cdot \\right\\rceil$ denotes the round-up\noperation to the nearest integer and $n_{\\mathrm{mp}}$ is a number\nof available MPs. Nevertheless, other aspects related to shared\nmemory and registers \\cite{Nvidia} may move the preferences\ntowards bigger blocks. More detailed study on the optimal block\nsize is beyond the scope of this paper. In our computations, we\nfocused on occupancy maximisation only and the block size is set\naccording to Eq.~\\eqref{eq:block}.\n\n\\begin{algorithm}[hbt!]\n \n \n CPU: \\hspace{12mm} calculating line segments: indices in $B$ and sizes in $D$\\;\n CPU$\\rightarrow$GPU: copying $B$ and $D$ into GPU\\;\n CPU: \\hspace{12mm} loading and copying binary image onto grid $2 \\times 2$ saved \\\\\n      \\hspace{25mm}into $A$, defining translations $C$ \\;\n CPU$\\rightarrow$GPU: copying $C$ and $phase$ into GPU\\;\n CPU$\\rightarrow$GPU: copying $A$ into GPU\\;\n \\For{$seg=0$ \\KwTo $S-1$}{\n    CPU$\\rightarrow$GPU: copying $seg$ into GPU\\;\n    GPU calls threads: \\For{$transl=0$ \\KwTo $WH-1$}{\n        $L[seg] = 0$\\;\n        \\For{pix=0 \\KwTo D[seg]}{\n          \\If{A[B[seg][pix]+C[transl]] $\\neq$ phase}{\n            break;\n          }\n        }\n        \\If{pix = D[seg]}{$L[seg] = L[seg]+1$\\;}\n    }\n }\n CPU$\\leftarrow$GPU: copying $L$ to CPU\\;\n\\caption{Simplified algorithmic structure of implementation designed\n  for single GPU device; All variables are defined in\n  Alg.~\\ref{alg:L2_eval}.} \\label{alg:GPU}\n\\end{algorithm}\n\n\n\\subsection{Algorithmic acceleration of $L_2$ evaluation}\n\nBesides the parallelisation, we also propose one simple\nalgorithmic acceleration of the lineal path computation. The idea\ncomes from the discrete nature of segments and a fact that some\nshorter segments are overlapped by some longer segments. See Fig.\n\\ref{fig:overlap}, where all segments start at $\\vek{x}_1 = (0,0)$\nand those ending in red pixels are overlapped by segments ending\nin black pixels.\n\n\\begin{figure} [t!]\n\\centering\n\\includegraphics*[width=5.5cm,keepaspectratio]{L2path.eps}\n\\caption{Illustration of overlapping line segments}\n\\label{fig:overlap}\n\\end{figure}\n\nIf a segment never falls entirely in a given phase and its $L_2$\nvalue is zero, it is obvious that all longer overlapping segments\nwill have the zero value as well. This simple logic brings\nadditional significant time savings in the $L_2$ evaluation. It\nonly needs to precalculate a vector containing the indices of the\nlongest shorter overlapping segments (LSOS). Such a precalculation\nis computational expensive, but is done only once at the beginning\nof the algorithm. Having in mind that steps 6 to 21 in\nAlg.~\\ref{alg:GPU} are supposed to be called repeatedly within an\noptimisation process, this precalculation should take place before\nstep 3.  Then one simple if-condition is added before translating\nand comparing the segments with the image. If the LSOS\ncorresponding to the current segment has zero value of $L_2$, then\nthe $L_2$ value of the current segment is automatically assigned\nto zero value too and the translating and comparing phase is\nskipped. To be more specific, there are two possibilities where\nthis crucial if-condition can be solved. It would be an intuitive\nsolution to solve this if-condition on CPU, i.e. before line 8 of\nthe Alg.~\\ref{alg:GPU} so as to skip the whole calling of GPU.\nHowever, in such a case, the CPU needs to have knowledge about\npreviously computed segments, which means that the value of the\nlineal path function has to be sent to CPU for every segment\nseparately inside the for-loop before line 18. Our computations,\nhowever, revealed that repeated sending of one integer from GPU to\nCPU is time-consuming and it is faster to call repeatedly the GPU,\nsolve the if-condition there (i.e. before line 10) and store all\nthe computed values of the lineal path function only on GPU until\nthe last segment is computed. Then sending of the whole vector of\nthe lineal path values brings significant time savings. This\nlatter variant was implemented and is further called as {\\it\nenhanced}, while the original version of the algorithm without any\nalgorithmic acceleration is called {\\it standard}.\n\nThe performance of GPU parallelism is demonstrated on evaluation\nof the $L_2$-function on three different microstructures: (i)\nchess-type morphology with dimensions of squares $10\\times 10$\n[px], (ii) particulate suspension consisting of equal-sized\nsquares with dimensions $4\\times 4$ [px] and (iii) metal foam\ntaken from ~\\cite{Jirousek:JI:2013}. Tab.~\\ref{tab:comptime}\ncompares the amount of time necessary averaged over five\nevaluations of the lineal path function for both phases on single\nCPU or GPU devices depending on the image size and chosen variant\nof the algorithm. In particular, the computational times\ncorrespond to a part of the lineal path function computation,\nwhich is called repeatedly within the optimisation process, i.e.\nevaluation of lines 1 to 5 in Alg.~\\ref{alg:GPU} is excluded. It\nis shown that for very small images the use of CPU outperforms the\nGPU because of additional time spent by communicating with the\nGPU. Nevertheless, for images of $50\\times 50\\,\\mathrm{[px]}$ the\nGPU achieves an evident speed-up which mostly further increases\nwith the increasing dimensions of the image. The exception is the\nchess-type microstructure where a specific phase distribution\nlimits the length of the most of the line segments to $10$ [px].\nThis significantly elevates the acceleration obtained for the\nenhanced variant of the algorithm and even the CPU version is so\nfast that communication with GPU leads again to deceleration which\nincreases with the image dimensions.\n\n\\cleardoublepage\n\\begin{table}[h!]\n\\begin{center}\n\\begin{tabular}{p{2cm}|p{1.4cm}p{1.4cm}l|p{1.4cm}p{1.4cm}l|l}\n\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MC_figA.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$  & GPU\n& CPU  & $S$ & $S^{*}$\\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$\\\\\n\\hline\n$10\\times 10$   & 2.4$\\cdot 10^{-3}$  & 0.59$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$   & 2.4$\\cdot 10^{-3}$ & 0.39$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$ & \\textbf{0.2}$\\times$\\\\\n$20\\times 20$ & 11.9$\\cdot 10^{-3}$   & 11.9$\\cdot 10^{-3}$    & \\textbf{1.0}$\\times$  & 11.1$\\cdot 10^{-3}$  & 7.8$\\cdot 10^{-3}$    & \\textbf{0.7}$\\times$ & \\textbf{1.1}$\\times$\\\\\n$50\\times 50$   & 0.15  & 0.55    & \\textbf{3.7}$\\times$   & 0.10  & 0.24    & \\textbf{2.5}$\\times$ & \\textbf{5.8}$\\times$\\\\\n$100\\times 100$ & 2.1   & 7.0    & \\textbf{3.3}$\\times$  & 0.26  & 0.27    & \\textbf{1.0}$\\times$ & \\textbf{27.0}$\\times$\\\\\n$200\\times 200$ & 32.6  & 110.9   & \\textbf{3.4}$\\times$  & 2.0  & 1.0   & \\textbf{0.5}$\\times$ & \\textbf{53.9}$\\times$\\\\\n$500\\times 500$ & 318.4 & 1071.1 & \\textbf{3.4}$\\times$  & 16.3 & 6.4  & \\textbf{0.4}$\\times$ & \\textbf{65.8}$\\times$\\\\\n\\hline\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MC_figB.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$ & GPU\n& CPU  & $S$ & $S^{*}$ \\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$ \\\\\n\\hline\n$10\\times 10$   & 2.5$\\cdot 10^{-3}$  & 0.71$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$   & 2.5$\\cdot 10^{-3}$  & 0.38$\\cdot 10^{-3}$    & \\textbf{0.2}$\\times$ & \\textbf{0.3}$\\times$\\\\\n$20\\times 20$ & 12.9$\\cdot 10^{-3}$   & 16.0$\\cdot 10^{-3}$    & \\textbf{1.2}$\\times$  & 12.5$\\cdot 10^{-3}$  & 8.2$\\cdot 10^{-3}$    & \\textbf{0.7}$\\times$ & \\textbf{1.3}$\\times$\\\\\n$50\\times 50$   & 0.16  & 0.81    & \\textbf{5.0}$\\times$   & 0.13  & 0.36    & \\textbf{2.7}$\\times$ & \\textbf{6.0}$\\times$\\\\\n$100\\times 100$ & 2.5   & 16.1    & \\textbf{6.4}$\\times$  & 1.7  & 7.2    & \\textbf{4.1}$\\times$ & \\textbf{9.3}$\\times$\\\\\n$200\\times 200$ & 41.9  & 256.3   & \\textbf{6.1}$\\times$  & 20.8  & 78.0   & \\textbf{3.7}$\\times$ & \\textbf{12.3}$\\times$\\\\\n$500\\times 500$ & 411.6 & 2544.0 & \\textbf{6.2}$\\times$  & 205.1 & 789.1  & \\textbf{3.9}$\\times$ & \\textbf{12.4}$\\times$\\\\\n\\hline\\hline\n\\includegraphics*[width=15mm,keepaspectratio]{MF_500.eps} & \\multicolumn{3}{l}{\\textit{Standard}} &  \\multicolumn{3}{|l|}{\\textit{Enhanced}} & \\\\\n\\hline dim. & GPU & CPU & $S$  & GPU\n& CPU  & $S$ & $S^{*}$\\\\\n$\\mathrm{[px]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ &\n$\\mathrm{[-]}$ & $\\mathrm{[s]}$ & $\\mathrm{[s]}$ & $\\mathrm{[-]}$ & $\\mathrm{[-]}$ \\\\\n\\hline\n$10\\times 10$   & 2.4$\\cdot 10^{-3}$  & 0.73$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$   & 2.4$\\cdot 10^{-3}$  & 0.65$\\cdot 10^{-3}$    & \\textbf{0.3}$\\times$ & \\textbf{0.3}$\\times$\\\\\n$20\\times 20$ & 12.0$\\cdot 10^{-3}$   & 13.8$\\cdot 10^{-3}$    & \\textbf{1.1}$\\times$  & 11.9$\\cdot 10^{-3}$  & 9.7$\\cdot 10^{-3}$    & \\textbf{0.8}$\\times$ & \\textbf{1.2}$\\times$\\\\\n$50\\times 50$   & 0.17  & 1.31    & \\textbf{7.6}$\\times$   & 0.15  & 0.67    & \\textbf{4.4}$\\times$ & \\textbf{8.7}$\\times$\\\\\n$100\\times 100$ & 2.8   & 31.9    & \\textbf{11.5}$\\times$  & 2.22  & 17.2    & \\textbf{7.7}$\\times$ & \\textbf{14.3}$\\times$\\\\\n$200\\times 200$ & 48.3  & 577.9   & \\textbf{12.0}$\\times$  & 32.9  & 241.7   & \\textbf{7.3}$\\times$ & \\textbf{17.5}$\\times$\\\\\n$500\\times 500$ & 542.1 & 7911.7 & \\textbf{14.6}$\\times$  & 445.2.1 & 3884.2  & \\textbf{8.7}$\\times$ & \\textbf{17.7}$\\times$\\\\\n\\hline\n\\end{tabular}\n\\caption{Comparison of CPU and GPU performance averaged over five\nevaluations ($S$ stands for speedup and $S^{*}$ represents overall\nspeedup obtained by hardware and software accelaration) }\n\\label{tab:comptime}\n\\end{center}\n\\end{table}\n\nThe particular computations presented in Tab.~\\ref{tab:comptime}\nwere performed on $2\\times$ INTEL Xeon E$5-2620$ @ $2.0$ GHz, $96$\nGB RAM, $2\\times$ GPU - NVIDIA QUADRO $4000$ with Micrsosoft\nWindows~$7$ $64$-bit operating system and the CUDA v. $6.5$.\nFurthermore, the algorithm is also designed for dual GPUs,\nunfortunately scalability towards the multiple GPU devices is not\nconsidered here. The logical step for the dual GPU algorithm is to\nuniformly distribute the generated segments, so that each device\nholds only a certain amount of them. This improvement thus results\nin lower memory requirements.\n\n\n\\section{Optimisation procedure} \\label{sec:optim}\nBefore proceeding to the comparative study of the lineal path and\ntwo-point probability function, we briefly describe the\noptimisation procedure employed in our computations. Here, we used\nthe framework firstly introduced by Yeong and\nTorquato~\\cite{Yeong:1998:PRE} for digitised media. The algorithm\nis based on simulated annealing method independently developed by\nKirkpatrick et al.~\\cite{Kirkpatrick:S:1983} and\n\\v{C}ern\\'{y}~\\cite{Cerny:JOTA:1985}. It starts with some randomly\ngenerated microstructure and quantification of its quality by a\nchosen statistical descriptor. The microstructure is then modified\nby a chosen operator and its new quality is evaluated. The\nacceptance of the proposed modification is governed by the\nMetropolis rule, which allows with a certain probability to accept\na worse solution and thus to escape from a local extreme. Such a\ngeneric optimisation scheme opens the possibility to define\nmodification operator suitable for a given microstructure. For\ninstance, a particulate suspension consisting of equal-sized discs\ncan be modified by moving a centre of an arbitrarily chosen disc,\nsee e.g. \\cite{Novak:PR:2012,Novak:MSMSE:2013}. Such a move\naffects the whole set of pixels and allows preserving the known\nshape of particles, thus accelerating the optimisation procedure.\nMost of the microstructures are, however, not consisting of\nparticles having a specific known shape. Then the simplest\nmodification operator is based on interchanging two randomly\nchosen pixels from different phases, which at least allows to\npreserve their volume fraction~\\cite{Yeong:1998:PRE}. Very simple\nacceleration employed in our implementation consists in a random\nselection of interfacial pixels which leads to a significant\nincrease of accepted modifications, as presented in\n\\cite{Rozman:2001:PRE}.\n\n\n\\begin{algorithm}[hbt!]\n \\KwData{binary image with dimensions $W\\times H$}\n \\KwResult{optimised SEPUC corresponding to given image} \n $create\\_random\\_image(P)$\\;\n $SDP = evaluate(P)$\\;\n $T = T_{\\max}$\\;\n $T_{\\mathrm{mult}} = (T_{\\mathrm{min}}/T_{\\mathrm{max}})^{(succ_{\\mathrm{max}}/N_{\\mathrm{step}})}$\\;\n \\While{$c<N_{\\mathrm{step}}$}{\n   $c = s = 0$\\;\n   \\While{$c<c_{\\max} \\quad \\& \\quad s<s_{\\max}$}{\n     $c = c + 1$\\;\n     $Q = modify(P)$ \\;\n     $SDQ = evaluate(Q)$\\;\n     \\If{random\\_number U[0,1] $< \\exp((SDQ-SDP)/T)$}{\n       $s = s + 1$\\;\n       $P = Q$\\;\n       $SDP = SDQ$\\;\n     }\n   }\n   $T = T \\cdot T_{\\mathrm{mult}}$\\;\n }\n\\caption{Algorithmic structure of simulated annealing} \\label{alg:annealing}\n\\end{algorithm}\n\nSince the proposed way of porting the lineal path evaluation onto\nGPU counts with copying the whole image from CPU to GPU for any\nnew proposed modification, the modification operator can be\ndesigned in any convenient way. Nevertheless, our further\ncomputations use solely the interchanging of two pixels.\nThe particular structure of the employed optimisation algorithm is given\nin Alg.~\\ref{alg:annealing}. First of all, a random digitised\nimage $P$ is created with the same volume fractions of phases as\nthe original morphology. Its statistical similarity to the original\nimage is then evaluated using the chosen statistical descriptor SD\nas the least square error:\n\n\n", "index": 27, "text": "\\begin{equation}\ne(\\mathrm{SD}^i) = \\sum_{p\\in \\mathbb{D}}\n(\\mathrm{SD}_{\\mathrm{original}}^{i}(\\vek{x}_{p})-\\mathrm{SD}^{i}(\\vek{x}_{p}))^2,\n\\label{eq:LSE}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"e(\\mathrm{SD}^{i})=\\sum_{p\\in\\mathbb{D}}(\\mathrm{SD}_{\\mathrm{original}}^{i}(%&#10;\\vek{x}_{p})-\\mathrm{SD}^{i}(\\vek{x}_{p}))^{2},\" display=\"block\"><mrow><mrow><mrow><mi>e</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>SD</mi><mi>i</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>p</mi><mo>\u2208</mo><mi>\ud835\udd3b</mi></mrow></munder><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>SD</mi><mi>original</mi><mi>i</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>SD</mi><mi>i</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\vek</mtext></merror><mo>\u2062</mo><msub><mi>x</mi><mi>p</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}]