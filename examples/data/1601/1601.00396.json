[{"file": "1601.00396.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 3836, "prevtext": "\n\n\n\\setlength{\\belowcaptionskip}{0pt}\n\n\n\n\n\\title{Automatic Detection and Decoding of Photogrammetric Coded Targets}\n\n\n\n\n\n\\author{\n\\IEEEauthorblockN{Udaya Wijenayake, Sung-In Choi and Soon-Yong Park}\n\\IEEEauthorblockA{School of Computer Science Engineering\\\\\nKyungpook National University, South Korea\\\\\nudaya@vision.knu.ac.kr, ellim5th@naver.com, sypark@knu.ac.kr}\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\\begin{abstract}\n\nClose-range Photogrammetry is widely used in many industries because of the cost effectiveness and efficiency of the technique. In this research, we introduce an automated coded target detection method which can be used to enhance the efficiency of the Photogrammetry.\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\\begin{keywords}\nPhotogrammetry, Coded targets, Decoding\n\\end{keywords}\n\n\n\n\n\n\n\n\n\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\\section{Introduction}\nPhotogrammetry is a technique to determine the geometric properties of an object from a sequence of photographic images, which has a long history since 1950s. Photogram\u00c2\u00acmetry can be classified into two main categories as Aerial Photogrammetry and Close Range Photogrammetry (CRP) based on the camera location during the image acquisition process. In CRP, the camera is closed to the subject and 3D models, measurements and point clouds are the most common outputs. This technique is used in different application areas, such as modeling and measuring buildings and large engineering structures, accident scenes inspection, mine inspection, quality controlling and film industry.\n\n\\begin{figure}[!b]\n\\begin{center}\n\\subfloat[]{\\label{binary}\\includegraphics[width=2.7cm]{Fig1a}}\n\\hspace{0.1em}\n\\subfloat[]{\\label{binary}\\includegraphics[width=2.7cm]{Fig1b}}\n\\hspace{0.1em}\n\\end{center}\n\\caption{Two types of CTs. (a) Dot distributions (b) Concentric rings.}\n\\label{fig:fig1}\n\\end{figure}\n\n\\section{Coded Targets}\nIndustrial photogrammetric measurement techniques utilize retro-reflective coded targets (CTs) encoded with a unique identifier to signalize feature points. Two main categories of CTs; concentric rings [1, 2] and dot distributions [3-5] have been introduced so far and two examples are shown in Fig. \\ref{fig:fig1}.\n\nConcentric rings are relatively easy to recognize and decode, but gives a limited number of code possibilities. Therefore, it is not suitable for measuring large scale structures which need several hundreds of markers to cover the whole structure. Dot distribution targets solve this problem by allowing a large number of code possibilities, but have difficulties in recognition due to the complexity. \n\nDifferent dots distribution CTs have been introduced so far and some examples are shown in Fig. \\ref{fig:fig2}. CRP systems work with a large number of CTs within an image and 30 to 100 images for one network. Therefore, it is really important to achieve fully automatic target detection to make the system cost and time effective. In this paper, we introduce a fully automatic coded target detection and decoding method based on the CT shown in Fig. \\ref{fig:fig2}(b).\n\n\\begin{figure}[!b]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Fig2}\n\\caption{Different types of dot distribution CTs [3-5].}\n\\label{fig:fig2}\n\\end{figure} \n\n\\section{Coded Target Detection}\nThe coded target detection process starts by converting the captured image to gray-scale and removing the image noise using the Gaussian smoothing filter, explained in the Eq. \\ref{Eq1}. Then the adaptive inverse thresholding with a Gaussian kernel is employed to convert the smoothed image to a binary image. Adaptive thresholding defines different threshold values for each pixel in the image by examining the surrounding neighborhood pixels as explained in Eq. \\ref{Eq2} where $T(x,y)$ is the weighted sum of the neighborhood of $(x,y)$ and $c$ is a user defined constant.\n\n\n", "index": 1, "text": "\\begin{equation}\ng(x,y) = \\frac{1}{{2\\pi {\\sigma ^2}}}{e^{ - \\frac{{{x^2} + {y^2}}}{{2{\\sigma ^2}}}}}\n\\label{Eq1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"g(x,y)=\\frac{1}{{2\\pi{\\sigma^{2}}}}{e^{-\\frac{{{x^{2}}+{y^{2}}}}{{2{\\sigma^{2}%&#10;}}}}}\" display=\"block\"><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mfrac><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mfrac><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\u03c3</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00396.tex", "nexttext": "\n\nContour detection is applied to the binary image for finding possible circular dots belong to the CTs. After detecting contours, first we remove very large or small contours which are possibly not circular dots by examining the contour size. Then each contour is approximate to a polygon using Douglas-Peucker algorithm and analyze the shape to remove the contours which are not convex and have fewer number of sides. Algorithm introduced in [6] is used to fit each contour to an ellipse and find the center coordinates of circular dots. Finally, these detected circular dots are grouped into possible markers (CTs) using a nearest neighbor search algorithm based on a k-d tree data structure.\n\n\\begin{figure}[!b]\n\\centering\n\\includegraphics[width=0.4\\textwidth]{Fig3}\n\\caption{Flow chart of the decoding process.}\n\\label{fig:fig3}\n\\end{figure} \n\n\\section{Coded Target Decoding}\nEach CT use in this research has eight circular dots where five of them are common for all the CTs and define the axis (orientation) of the CT. Remaining three circles can be chosen from 22 possibilities and they define the code-word of the CT. The first step of the decoding process is to identify the five common circles from the detected possible CTs.\n\nWe measure the total distance from each circle to every other circles within a CT and select the circle with the lowest total as center circle $x_0$. Then we identify the two corner circles $x_1$ and $x_3$ by finding the two circles which make a straight line with $x_0$. From all the eight circles, only $x_1$, $x_0$ and $x_3$ make a straight line within a CT. $x_1$ and $x_3$ can be differentiated by finding the distance to the $x_0$. To find the $x_4$ and $x_5$, we find the two closest circles to the $x_1$ from the remaining circles. Those two circles should reside on the two sides of the line created by $x_1$ and $x_3$ and can be differentiated as $x_4$ and $x_5$ according to the side they reside. \n\nAfter finding the five common circles, the perspective transformation between the original projected CT and the detected one can be calculated. Then the remaining three circles can be projected onto the original marker and the code-word of the CT can be identified using a mask created by original positions of the code circles. Flow chart in Fig. \\ref{fig:fig3} summarizes this decoding process.\n\nWe test our proposed method with different structures (Fig. \\ref{fig:fig4}) and achieve nearly 100\\% detection rate when the CTs are nearly orthogonal to the camera view and about 85\\% for other cases. For every successful detection of a CT, decoding accuracy is almost 100\\% and most of the errors come from the target detection process.\n\n\\section{Conclusions}\nIn an effort to enhance the performance of photogrammetric measurement techniques, in this research, we proposed a fully automated coded target detection and decoding method by using various image processing and vision techniques. As a future work we are planning to integrate this target detection technique with natural feature tracking techniques to develop a more accurate and enhanced photogrammetric system.\n\n\\begin{figure}[!t]\n\\centering\n\\includegraphics[width=0.45\\textwidth]{Fig4}\n\\caption{Results of the experiments with different structures.}\n\\label{fig:fig4}\n\\end{figure} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section*{Acknowledgment}\n\nThis work was supported by the Industry Core Technology Program granted financial resource from the Ministry of Trade, Industry \\& Energy, Republic of Korea (No. 10043897) and Samsung Heavy Industries Co.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{thebibliography}{1}\n  \n\\bibitem{Ahn}\nS.J. Ahn, W. Rauh and S.I. Kim, \"Circular coded target for automation of optical 3D-measurement and camera calibration\", Int. J. Pat. Recognit. Artif. Intell., vol. 15, pp. 905-919, 2001.\n\n\\bibitem{Heuvel}\nF.V.D. Heuvel, R. Kroon and R. Le Poole, \"Digital close-range photogrammetry using artificial targets\", Int. Arch. Photogramm. Remote Sens., vol. 29, pp. 222-222, 1993.\n\n\\bibitem{Cronk}\nS. Cronk and C.S. Fraser, \"Hybrid measurement scenarios in automated close-range photogrammetry\", in ISPRS Congress, 2008, pp. 745-749.\n\n\\bibitem{Feng}\nQ. Feng, Z. Li and G. Li, \"Design and decoding of dot-distribution coded targets\", in WCICA, 2010, pp. 5381-5384.\n\n\\bibitem{Hattori}\nS. Hattori, K. Akimoto, C. Fraser and H. Imoto, \"Automated procedures with coded targets in industrial vision metrology\", Photogramm. Eng. Remote Sensing, vol. 68, pp. 441-446, 2002.\n\n\\bibitem{Fitzgibbon}\nA.W. Fitzgibbon and R.B. Fisher, \"A buyer's guide to conic fitting\",  DAI Research paper, 1996.\n\n\n\\end{thebibliography}\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 3966, "prevtext": "\n\n\n", "index": 3, "text": "\\begin{equation}\ndst(x,y) = \\left\\{ {\\begin{array}{*{20}{c}}\n0\\\\\n{255}\n\\end{array}} \\right.\\begin{array}{*{20}{c}}\n{if\\;src(x,y) > T(x,y) - c}\\\\\n{otherwise}\n\\end{array}\n\\label{Eq2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"dst(x,y)=\\left\\{{\\begin{array}[]{*{20}{c}}0\\\\&#10;{255}\\end{array}}\\right.\\begin{array}[]{*{20}{c}}{if\\;src(x,y)&gt;T(x,y)-c}\\\\&#10;{otherwise}\\end{array}\" display=\"block\"><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/></mtr><mtr><mtd columnalign=\"center\"><mn>255</mn></mtd><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/></mtr></mtable><mi/></mrow><mo>\u2062</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mrow><mi>i</mi><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi>f</mi></mpadded><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mrow><mi>T</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>c</mi></mrow></mrow></mtd><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/></mtr><mtr><mtd columnalign=\"center\"><mrow><mi>o</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>h</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>w</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>e</mi></mrow></mtd><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/><mtd/></mtr></mtable></mrow></mrow></math>", "type": "latex"}]