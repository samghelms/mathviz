[{"file": "1601.06608.tex", "nexttext": "\n\n\n\n", "itemtype": "equation", "pos": 8353, "prevtext": "\n\n\n\n\n\\title{An Unsupervised  Method for Detection and Validation of The Optic Disc and The Fovea}\n\n\n\\author{Mrinal~Haloi,  Samarendra~Dandapat, and~Rohit~Sinha\n\\thanks{M.Haloi, S. Dandapat, R. Sinha is with the Department\nof Electrical and Communication Engineering, Indian Institute of Technology, Guwahati,India\n e-mail: (h.mrinal, samaren,rsinha)@iitg.ernet.in. / mrinal.haloi11@gmail.com}\n}\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\n\n\n\n\\begin{abstract}\nIn this work, we have presented a novel method for detection of retinal image features, the optic disc and the fovea, from colour fundus photographs of dilated eyes for Computer-aided Diagnosis(CAD) system. A saliency map based method was used to detect the optic disc followed by an unsupervised probabilistic Latent Semantic Analysis for detection validation. The validation concept is based on distinct vessels structures in the optic disc. By using the clinical information of standard location of the fovea with respect to the optic disc, the macula region is estimated. Accuracy of 100\\% detection is achieved for the optic disc and the macula on MESSIDOR and DIARETDB1 and 98.8\\% detection accuracy on STARE dataset. \n\n\\end{abstract}\n\n\\begin{IEEEkeywords}\n Retinal images, PLSA, Image processing, CAD.\n\\end{IEEEkeywords}\n\n\n\\section{Introduction}\nAnalysis of retinal image for detection of its pathological \\cite{c23} and non-pathological features is very important for automatic computer aided detection and diagnosis of retinal diseases. With the emergence of medical image analysis research for faster and accurate analysis by reducing cost and time, researchers developing computer software to facilitate easier medical treatment. Use of computer aided diagnosis will help doctors in remote areas and faster analysis of retinal images, lower cost of treatment by reducing manpower. Most of the works on retinal image analysis uses retinal images obtained from fundus photography \\cite{c20, micro} by dilating pupil. The optic disc, the fovea, blood vessels and veins are main features of retinal image. Different types of retinal diseases effect those features. Age related macular degeneration causes defect of macula region also by diabetic retinopathy. Hard and soft exudates are pathological features responsible for diabetic retinopathy. Damage of optic disc is result of Glaucoma diseases [19], one major cause of vision loss. Optic disc cup and neuro retinal rim surface areas ratio, determine presence and progression of Glaucoma. Diameter changes of retinal arteries and veins are associated with different cardiovascular diseases. Thinning of the arteries and widening of the veins, result in increased risk of stroke and myocardial infraction \\cite{aao}.\n\nDetection of the optic disc, the fovea, blood vessels and veins are very important for pathological analysis of retinal image \\cite{c23}. Since severity of diseases depends on location of features of corresponding diseases with respect to those essential features. Also some pathological features occurs in specific areas. The optic disc (OD) can be observed as bright part of normal retinal image, and the fovea as the darkest region. In pathological images sometimes it\u00e2\u0080\u0099s very hard to detect the optic disc and the macula region due to abnormalities caused by different diseases. In most of the recent works on detection accuracy of the optic disc and the macula region in pathological images is very low, no proper validation of detection region is presented. Eventhough the location of the macula can be estimated from the optic disc location but due to age related macular degeneration that region may be severely effected, to find whether the region is normal or that of pathological eyes, proper validation is needed.\n For efficient detection of the OD and the fovea consideration of adverse illumination variation and damaging for these features due to eye diseases need to be addressed. Also illuminace variation linked with imaging setup. Fig. 1 shows a typical retinal image with the optic disc, the macula region, the blood vessels and pathological feature exudates.\\\\\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.5in,height=2.3in]{introret}\n\\caption{Retinal Features}\n\\end{figure}\n\nRetinal image analysis is a mature area, lots of work has been done in this area. But still a complete state of art system for performing all analysis with high accuracy is not achieved. People have used image processing and machine learning based approach for detection and classification of various features. It is not possible to give a complete analysis of these works. A few works were selected for discussing.\n\nLu et al. \\cite{lu} have used line operator to detect circular brightness structure of the optic disc. Their method failed to address large illuminance variation effect with neighbouring regions and limited to clear circular brightness structure.\nMatched filter based method was proposed by Abdel et al. \\cite{abdel}, they first preprocesses the images by illumination normalization and histogram equalization. Their algorithm performance depends on the vessel segmentation. And will be effected by adverse illuminance variation.\nUsing retinal vessel direction informtion Foracchia et al. \\cite{forc} proposed a geometrical parametric model for the optic disc detection. The algorithm need vessel segmented images and hence vessel segmentation performance effect its results. \n\nA probability map based localization of the optic disc is presented by Budai et al. \\cite{budai}, they have constructed two probability map. One is brightness based from the brightness of image and other is vessel segmentation based. And combination of these two map was used to locate the optic disc. And this method failed to address the problems of illuminance variation and difficulty involves in pathological images.\nA model based approach was used by Li et al. \\cite{li} to detect the optic disc, the macula and exudates. Principal component based method was used to locate the optic disc and active shape based method for shape detection of the optic disc and the fovea. \n\nIn this work, two new novel method for detection of retinal features is developed.  The optic disc detection is based on saliency map that can capture significant variation of local structure. Once the potential probable location of the optic disc detected, a probabilistic Latent Semantic Analysis based unsupervised method was used to validate whether the region is the optic disc or not, this is based on specific vasculature structure in that region. This method gives us 100 \\% accuracy in optic disc detection in different challenging images with pathological symptoms. This algorithm is described in section {\\uppercase\\expandafter{\\romannumeral {2}\\relax}}(A) and {\\uppercase\\expandafter{\\romannumeral {2}\\relax}}(B).  The macula region detection by using the information of the optic disc location and the main courses of blood vessels is described in section {\\uppercase\\expandafter{\\romannumeral {2}\\relax}}(C). \n\n\\section{Method}\nThis method comprises of mainly two parts. In the first stage detection and validation of the optic disc is performed, while the fovea detection is dependent on OD detection. A complete overview of the method used in this work is explained in the Fig. 2. \n\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.8in]{blockdiagramOD}\n\\caption{Method Overview}\n\\end{figure}\n\n\\subsection{Optic Disc Detection}\nThe optic disc is one of the most important anatomical structures of retina. The optic disc is also known as the blind spot, because there are no light sensitive rods or cones to respond to a light stimulus. The retinal arteries and veins emerge from the left of the optic disc.\nIts central white depression called the physiologic cup and horizontal diameter of it should not exceed 1/2 that of entire disc, otherwise it\u00e2\u0080\u0099s a sign of pathologic optic disc cupping reasons behind glaucoma.\nFor detection of optic disc a saliency region detection algorithm \\cite{smap} was used to identify salient region of the image, based on image local structure variation. For this first image will be convert to CIE Lab colour space, where luminance value from $L$ channel of image and colour value from $a$ and $b$ channel can be seperated.\nConversion process is described \\cite{lab} as follows.\n\n\n", "index": 1, "text": "\\begin{equation}\n\\left[ \\begin{array}{c} X \\\\ Y\\\\Z \\end{array} \\right] = \\begin{bmatrix} 0.4887180 & 0.3106803 & 0.2006017 \\\\  0.1762044  & 0.8129847 & 0.0108109 \\\\  0.0000000 & 0.0102048 & 0.9897952 \\end{bmatrix} \\times \\left[ \\begin{array}{c} R \\\\ G \\\\B \\end{array} \\right]\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\left[\\begin{array}[]{c}X\\\\&#10;Y\\\\&#10;Z\\end{array}\\right]=\\begin{bmatrix}0.4887180&amp;0.3106803&amp;0.2006017\\\\&#10;0.1762044&amp;0.8129847&amp;0.0108109\\\\&#10;0.0000000&amp;0.0102048&amp;0.9897952\\end{bmatrix}\\times\\left[\\begin{array}[]{c}R\\\\&#10;G\\\\&#10;B\\end{array}\\right]\" display=\"block\"><mrow><mrow><mo>[</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>X</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>Y</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>Z</mi></mtd></mtr></mtable><mo>]</mo></mrow><mo>=</mo><mrow><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>0.4887180</mn></mtd><mtd columnalign=\"center\"><mn>0.3106803</mn></mtd><mtd columnalign=\"center\"><mn>0.2006017</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0.1762044</mn></mtd><mtd columnalign=\"center\"><mn>0.8129847</mn></mtd><mtd columnalign=\"center\"><mn>0.0108109</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0.0000000</mn></mtd><mtd columnalign=\"center\"><mn>0.0102048</mn></mtd><mtd columnalign=\"center\"><mn>0.9897952</mn></mtd></mtr></mtable><mo>]</mo></mrow><mo>\u00d7</mo><mrow><mo>[</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>R</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>G</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi>B</mi></mtd></mtr></mtable><mo>]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 8646, "prevtext": "\n\n\n\n", "index": 3, "text": "\\begin{equation}\n\\begin{aligned}\nL  = 116[ h( \\frac{Y}{Y_W} )] - 16 \\\\\na = 500[h( \\frac{X}{X_W} ) - h(\\frac{Y}{Y_W})] \\\\\nb = 200[h( \\frac{Y}{Y_W} ) - h(\\frac{Z}{Z_W})] \n\\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle L=116[h(\\frac{Y}{Y_{W}})]-16\" display=\"inline\"><mrow><mi>L</mi><mo>=</mo><mrow><mrow><mn>116</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mi>Y</mi><msub><mi>Y</mi><mi>W</mi></msub></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow><mo>-</mo><mn>16</mn></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2Xa.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle a=500[h(\\frac{X}{X_{W}})-h(\\frac{Y}{Y_{W}})]\" display=\"inline\"><mrow><mi>a</mi><mo>=</mo><mrow><mn>500</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mi>X</mi><msub><mi>X</mi><mi>W</mi></msub></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mi>Y</mi><msub><mi>Y</mi><mi>W</mi></msub></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2Xb.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle b=200[h(\\frac{Y}{Y_{W}})-h(\\frac{Z}{Z_{W}})]\" display=\"inline\"><mrow><mi>b</mi><mo>=</mo><mrow><mn>200</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mi>Y</mi><msub><mi>Y</mi><mi>W</mi></msub></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mi>Z</mi><msub><mi>Z</mi><mi>W</mi></msub></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n\n\nBecause of optic disc colour and structuring variation from neighbourhood variation, saliency map (SM) can efficiently detect it. Saliency is computed on the basis of variation of local contrast of a image patch with respect to neighbourhood. Even if the colour vaiation is low but with strong structural variation SM can capture OD. This process is repeated at different scales for getting better accuracy in constructing the map and keeping finer details. The contrast based saliency of a given pixel at position $(i,j)$ is $c_{i,j}$ and computed as follows \\cite{smap}.\n\n", "itemtype": "equation", "pos": 8845, "prevtext": "\n\n\n", "index": 5, "text": "\\begin{equation}\n h(q)= \n\\begin{cases}\n    \\sqrt[3]{q} ,& \\text{if } q > 0.008856\\\\\n    7.787q + 16/116,              & \\text{otherwise}\n\\end{cases}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"h(q)=\\begin{cases}\\sqrt[3]{q},&amp;\\text{if }q&gt;0.008856\\\\&#10;7.787q+16/116,&amp;\\text{otherwise}\\end{cases}\" display=\"block\"><mrow><mrow><mi>h</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>q</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mroot><mi>q</mi><mn>3</mn></mroot><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>q</mi></mrow><mo>&gt;</mo><mn>0.008856</mn></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mn>7.787</mn><mo>\u2062</mo><mi>q</mi></mrow><mo>+</mo><mrow><mn>16</mn><mo>/</mo><mn>116</mn></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\nWhere D is Euclidean distance between the average vectors of two non-overlapping patch $P_{1}$ and $P_{2}$ and  with total number of pixels as $N1$ and $N2$. If these two vectors are correlated, Mohalanobis distance will be used. Also, $v_{p} and v_{q}$ are vector of features of two pixels corresponding to two different regions. Vector corresponding to each pixels have three features, Luminance and two colour 'a' and 'b' from CIE Lab colour space channel.\n\n", "itemtype": "equation", "pos": 9585, "prevtext": "\n\n\n\nBecause of optic disc colour and structuring variation from neighbourhood variation, saliency map (SM) can efficiently detect it. Saliency is computed on the basis of variation of local contrast of a image patch with respect to neighbourhood. Even if the colour vaiation is low but with strong structural variation SM can capture OD. This process is repeated at different scales for getting better accuracy in constructing the map and keeping finer details. The contrast based saliency of a given pixel at position $(i,j)$ is $c_{i,j}$ and computed as follows \\cite{smap}.\n\n", "index": 7, "text": "\\begin{equation}\nc_{i,j} =  D[(\\frac{1}{N1}\\displaystyle\\sum\\limits_{p=1}^{N1} v_{p}), (\\frac{1}{N2}\\displaystyle\\sum\\limits_{q=1}^{N2} v_{q})]\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"c_{i,j}=D[(\\frac{1}{N1}\\displaystyle\\sum\\limits_{p=1}^{N1}v_{p}),(\\frac{1}{N2}%&#10;\\displaystyle\\sum\\limits_{q=1}^{N2}v_{q})]\" display=\"block\"><mrow><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><mi>D</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mfrac><mn>1</mn><mrow><mi>N</mi><mo>\u2062</mo><mn>1</mn></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>\u2062</mo><mn>1</mn></mrow></munderover><msub><mi>v</mi><mi>p</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mfrac><mn>1</mn><mrow><mi>N</mi><mo>\u2062</mo><mn>2</mn></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>\u2062</mo><mn>2</mn></mrow></munderover><msub><mi>v</mi><mi>q</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\nSize of patch $P_{1}$ is taken as 9x9 and that of $P_{2}$ is calculated from the equation. Input image have c number of columns.\n\n", "itemtype": "equation", "pos": 10205, "prevtext": "\n\nWhere D is Euclidean distance between the average vectors of two non-overlapping patch $P_{1}$ and $P_{2}$ and  with total number of pixels as $N1$ and $N2$. If these two vectors are correlated, Mohalanobis distance will be used. Also, $v_{p} and v_{q}$ are vector of features of two pixels corresponding to two different regions. Vector corresponding to each pixels have three features, Luminance and two colour 'a' and 'b' from CIE Lab colour space channel.\n\n", "index": 9, "text": "\\begin{equation}\nv_{i} = [L_{i},a_{i},b_{i}]\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"v_{i}=[L_{i},a_{i},b_{i}]\" display=\"block\"><mrow><msub><mi>v</mi><mi>i</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>L</mi><mi>i</mi></msub><mo>,</mo><msub><mi>a</mi><mi>i</mi></msub><mo>,</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\nFinal saliecny map values is computed as sum of saliency map of that image at different scales,\n\n", "itemtype": "equation", "pos": 10394, "prevtext": "\nSize of patch $P_{1}$ is taken as 9x9 and that of $P_{2}$ is calculated from the equation. Input image have c number of columns.\n\n", "index": 11, "text": "\\begin{equation}\n\\frac{c}{2} \\geq (N_{P_{2}}) \\geq \\frac{c}{8} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\frac{c}{2}\\geq(N_{P_{2}})\\geq\\frac{c}{8}\" display=\"block\"><mrow><mfrac><mi>c</mi><mn>2</mn></mfrac><mo>\u2265</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>N</mi><msub><mi>P</mi><mn>2</mn></msub></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2265</mo><mfrac><mi>c</mi><mn>8</mn></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.3in]{binrect}\n\\caption{Window selection from Segmented Region}\n\\end{figure}\nFor segmentation of relevant region from saliency map, patch based segmentation techniques was used by using the relation as follows. For each patch, mean $m_{p}$ and standard deviation $\\sigma_{p}$ is computed. If $SM_{i,j}$ from equation (8) is greater than 1 then the pixels will be included in final interest map, otherwise it will be discarded.\n\n", "itemtype": "equation", "pos": 10570, "prevtext": "\n\nFinal saliecny map values is computed as sum of saliency map of that image at different scales,\n\n", "index": 13, "text": "\\begin{equation}\nsmap_{i,j} = \\displaystyle\\sum\\limits_{S} c_{i,j}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"smap_{i,j}=\\displaystyle\\sum\\limits_{S}c_{i,j}\" display=\"block\"><mrow><mrow><mi>s</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>p</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>S</mi></munder><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\nIn the final map $SM$, due to presence of different pathological symptoms in retinal images, other features along with optic disc also got detected. To get final location of optic disc a validation method will be applied.\n\n\n\\subsection{Validation of detected Optic Disc}\nFinal saliency map may have different regions, optic disc or non-optic disc. To validate whether a region is optic disc we have used a unsupervised Probabilistic latent Semantic Analysis classification algorithm. The optic disc structures consist of a complex pattern of vessels originate from it, no other part of retina has this structures, this concept have been exploited for classification and this method is independent of luminance of optic disc region. Even if due to some pathological region luminance is depreciated our method still can accurately detect the optic disc. The specific vasculature structure may be defected due to several pathological problems, to address this problem, the part based classification model was exploited. Our model comprised six classes, five classes for the optic disc and its parts and the sixth class is other retinal features for differentiation. The optic disc is divided into four parts as shown in Fig. 4. This formulation efficiently detect the optic disc even if its structure is defected.\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.6in]{templateoptic1}\n\\caption{OD part and corresponding HOG features}\n\\end{figure}\nIn the testing phase around each regions multiples window shifted to right, left, top and bottom was chosen. Variable window sizes as shown in Fig. 3 and window pixels value will be that of original image at those pixels location. Below stages involves in designing the classifier have been discussed. \n Since image is a very high dimensional data, pre-process it to reduce its dimensionality by using visual codebook formation method. Each image will be represented as a bag of visual words. By using histogram of words concept, each image will be converted to a document with previously designed vocabulary.\n\n\n\\subsubsection{Feature Extraction}\nFor extracting meaningful edges information from images HOG \\cite{hog} descriptor was used.\nFor object recognition HOG is a very popular local descriptor. This descriptor capture fine structure of images and suitable for object recognition. HOG computation based on gradient magnitude and phase.  Window with $16 \\times 16 $ is selected with 50 \\% overlap with neighbouring window, then it is further divided into $2 \\times 2$ cells having size $8 \\times 8$. For each window gradient phase is quantized into equally spaced 9 bins and gradient magnitude was used to determine values of each bin. \n \\begin{figure*}\n\n \\center\n\n  \\includegraphics[width=4.5in, height = 2.4in]{plsaalgo}\n\n  \\caption{PLSA algorithm idea}\n\n  \\label{AAA}\n\n\\end{figure*}\n\n\\subsubsection{LLC Codebook Formation}\nFor the formation of visual words locality constrained linear coding \\cite{llc} based method was used. This algorithm generate similar codes for similar descriptors by sharing bases. Locality also leads to sparsity. Idea based locality importance more than sparsity is used and given by below optimization problem. Here X is a D dimensional local descriptors ,$X = [x_{1},x_{2},...,x_{N}] \\in \\Re^{DxN}$ and $B = [b_{1},b_{2},...,b_{M}] \\in \\Re^{DXM}$ is $M$ dimensional codebook. Process is describes as follows.  \n\n", "itemtype": "equation", "pos": 11150, "prevtext": "\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.3in]{binrect}\n\\caption{Window selection from Segmented Region}\n\\end{figure}\nFor segmentation of relevant region from saliency map, patch based segmentation techniques was used by using the relation as follows. For each patch, mean $m_{p}$ and standard deviation $\\sigma_{p}$ is computed. If $SM_{i,j}$ from equation (8) is greater than 1 then the pixels will be included in final interest map, otherwise it will be discarded.\n\n", "index": 15, "text": "\\begin{equation}\nSM_{i,j} = \\frac{smap(i,j) - m_{p}}{\\sigma_{p}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"SM_{i,j}=\\frac{smap(i,j)-m_{p}}{\\sigma_{p}}\" display=\"block\"><mrow><mrow><mi>S</mi><mo>\u2062</mo><msub><mi>M</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo>=</mo><mfrac><mrow><mrow><mi>s</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msub><mi>m</mi><mi>p</mi></msub></mrow><msub><mi>\u03c3</mi><mi>p</mi></msub></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 14644, "prevtext": "\nIn the final map $SM$, due to presence of different pathological symptoms in retinal images, other features along with optic disc also got detected. To get final location of optic disc a validation method will be applied.\n\n\n\\subsection{Validation of detected Optic Disc}\nFinal saliency map may have different regions, optic disc or non-optic disc. To validate whether a region is optic disc we have used a unsupervised Probabilistic latent Semantic Analysis classification algorithm. The optic disc structures consist of a complex pattern of vessels originate from it, no other part of retina has this structures, this concept have been exploited for classification and this method is independent of luminance of optic disc region. Even if due to some pathological region luminance is depreciated our method still can accurately detect the optic disc. The specific vasculature structure may be defected due to several pathological problems, to address this problem, the part based classification model was exploited. Our model comprised six classes, five classes for the optic disc and its parts and the sixth class is other retinal features for differentiation. The optic disc is divided into four parts as shown in Fig. 4. This formulation efficiently detect the optic disc even if its structure is defected.\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.6in]{templateoptic1}\n\\caption{OD part and corresponding HOG features}\n\\end{figure}\nIn the testing phase around each regions multiples window shifted to right, left, top and bottom was chosen. Variable window sizes as shown in Fig. 3 and window pixels value will be that of original image at those pixels location. Below stages involves in designing the classifier have been discussed. \n Since image is a very high dimensional data, pre-process it to reduce its dimensionality by using visual codebook formation method. Each image will be represented as a bag of visual words. By using histogram of words concept, each image will be converted to a document with previously designed vocabulary.\n\n\n\\subsubsection{Feature Extraction}\nFor extracting meaningful edges information from images HOG \\cite{hog} descriptor was used.\nFor object recognition HOG is a very popular local descriptor. This descriptor capture fine structure of images and suitable for object recognition. HOG computation based on gradient magnitude and phase.  Window with $16 \\times 16 $ is selected with 50 \\% overlap with neighbouring window, then it is further divided into $2 \\times 2$ cells having size $8 \\times 8$. For each window gradient phase is quantized into equally spaced 9 bins and gradient magnitude was used to determine values of each bin. \n \\begin{figure*}\n\n \\center\n\n  \\includegraphics[width=4.5in, height = 2.4in]{plsaalgo}\n\n  \\caption{PLSA algorithm idea}\n\n  \\label{AAA}\n\n\\end{figure*}\n\n\\subsubsection{LLC Codebook Formation}\nFor the formation of visual words locality constrained linear coding \\cite{llc} based method was used. This algorithm generate similar codes for similar descriptors by sharing bases. Locality also leads to sparsity. Idea based locality importance more than sparsity is used and given by below optimization problem. Here X is a D dimensional local descriptors ,$X = [x_{1},x_{2},...,x_{N}] \\in \\Re^{DxN}$ and $B = [b_{1},b_{2},...,b_{M}] \\in \\Re^{DXM}$ is $M$ dimensional codebook. Process is describes as follows.  \n\n", "index": 17, "text": "\\begin{equation}\nmin_{c}\\Sigma_{i=1,N}||x_{i} - Bc_{i}||^{2} + \\lambda||d_{i} \\odot c_{i}||^{2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"min_{c}\\Sigma_{i=1,N}||x_{i}-Bc_{i}||^{2}+\\lambda||d_{i}\\odot c_{i}||^{2}\" display=\"block\"><mrow><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><msub><mi>n</mi><mi>c</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi>N</mi></mrow></mrow></msub><mo>\u2062</mo><msup><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><mrow><mi>B</mi><mo>\u2062</mo><msub><mi>c</mi><mi>i</mi></msub></mrow></mrow><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup></mrow><mo>+</mo><mrow><mi>\u03bb</mi><mo>\u2062</mo><msup><mrow><mo fence=\"true\">||</mo><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>\u2299</mo><msub><mi>c</mi><mi>i</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 14755, "prevtext": "\n\n", "index": 19, "text": "\\begin{equation}\ns.t. 1^{T}c_{i} = 1, \\forall i\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"s.t.1^{T}c_{i}=1,\\forall i\" display=\"block\"><mrow><mi>s</mi><mo>.</mo><mrow><mrow><mi>t</mi><mo>\u2062</mo><msup><mn>.1</mn><mi>T</mi></msup><mo>\u2062</mo><msub><mi>c</mi><mi>i</mi></msub></mrow><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mrow><mo>\u2200</mo><mi>i</mi></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\nWhere $\\odot $ denotes the element-wise multiplication, and $d_{i} \\in \\Re^{M}$ is the locality adaptor that gives different freedom for each basis vector proportional to its similarity to the input descriptor$ x_{i}$. Also $dist(x_{i},B)$ is the Euclidean distance between $x_{i}$  and B. Shift invariance nature is confirmed by the constraint equation (3). In our case we will have 4608 dimension HOG descriptors $x_{i}$for each image. And a codebook $B$ of size 113 words was formed. Each image was expressed as a combination of these words. Each image was represented as histogram of visual words. Fig. 6 Depicts codebook formation scenario.\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.6in]{codeword}\n\\caption{Codeword formation}\n\\end{figure}\n   \n\\subsubsection{PLSA model}\nProbabilistic latent semantic analysis \\cite{plsa} is a topic discovery model, its concept based on latent variable analysis. An image also can be considered as a collection of topics. Every image can be considered as a text document with words from a specific vocabulary. The vocabulary will be formed by using LLC algorithm on HOG features from training image. Suppose a collection of N images(document) $D ={d_{1},d_{2},...,d_{N}}$ is avilable, and corresponding vocabulary with size $N1$ is $W={w_{1},w_{2},...,w_{N1}}$. And let there be $N2$ topic $Z={z_{1},z_{2},...,z_{N2}}$ Model parameter are computed using expectation maximization method. In Fig. 5 Concept of pLSA model and its training and testing process is shown.\n\n\n\n\n\n", "itemtype": "equation", "pos": 14818, "prevtext": "\n\n", "index": 21, "text": "\\begin{equation}\nd_{i} = exp(\\frac{dist(x_{i},B)}{\\sigma})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"d_{i}=exp(\\frac{dist(x_{i},B)}{\\sigma})\" display=\"block\"><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>e</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>\u03c3</mi></mfrac><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 16431, "prevtext": "\nWhere $\\odot $ denotes the element-wise multiplication, and $d_{i} \\in \\Re^{M}$ is the locality adaptor that gives different freedom for each basis vector proportional to its similarity to the input descriptor$ x_{i}$. Also $dist(x_{i},B)$ is the Euclidean distance between $x_{i}$  and B. Shift invariance nature is confirmed by the constraint equation (3). In our case we will have 4608 dimension HOG descriptors $x_{i}$for each image. And a codebook $B$ of size 113 words was formed. Each image was expressed as a combination of these words. Each image was represented as histogram of visual words. Fig. 6 Depicts codebook formation scenario.\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.3in,height=2.6in]{codeword}\n\\caption{Codeword formation}\n\\end{figure}\n   \n\\subsubsection{PLSA model}\nProbabilistic latent semantic analysis \\cite{plsa} is a topic discovery model, its concept based on latent variable analysis. An image also can be considered as a collection of topics. Every image can be considered as a text document with words from a specific vocabulary. The vocabulary will be formed by using LLC algorithm on HOG features from training image. Suppose a collection of N images(document) $D ={d_{1},d_{2},...,d_{N}}$ is avilable, and corresponding vocabulary with size $N1$ is $W={w_{1},w_{2},...,w_{N1}}$. And let there be $N2$ topic $Z={z_{1},z_{2},...,z_{N2}}$ Model parameter are computed using expectation maximization method. In Fig. 5 Concept of pLSA model and its training and testing process is shown.\n\n\n\n\n\n", "index": 23, "text": "\\begin{equation}\nP(z|d,w) = \\frac{P(z)P(d|z)P(w|z)}{\\Sigma_{z'} P(z')P(d|z')P(w|z')}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"P(z|d,w)=\\frac{P(z)P(d|z)P(w|z)}{\\Sigma_{z^{\\prime}}P(z^{\\prime})P(d|z^{\\prime%&#10;})P(w|z^{\\prime})}\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">|</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">|</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><msup><mi>z</mi><mo>\u2032</mo></msup></msub><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">|</mo><msup><mi>z</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">|</mo><msup><mi>z</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 16531, "prevtext": "\n\n", "index": 25, "text": "\\begin{equation}\nP(w|z) = \\frac{\\Sigma_{d}n(d,w)P(z|d,w)}{\\Sigma_{d,w'}n(d,w')P(z|d,w')}\\\\\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"P(w|z)=\\frac{\\Sigma_{d}n(d,w)P(z|d,w)}{\\Sigma_{d,w^{\\prime}}n(d,w^{\\prime})P(z%&#10;|d,w^{\\prime})}\\\\&#10;\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">|</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>d</mi></msub><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi>d</mi><mo>,</mo><msup><mi>w</mi><mo>\u2032</mo></msup></mrow></msub><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo>,</mo><msup><mi>w</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><mi>d</mi><mo>,</mo><msup><mi>w</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 16637, "prevtext": "\n\n", "index": 27, "text": "\\begin{equation}\nP(d|z) = \\frac{\\Sigma_{w}n(d,w)P(z|d,w)}{\\Sigma_{d',w}n(d',w)P(z|d',w)}\\\\\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"P(d|z)=\\frac{\\Sigma_{w}n(d,w)P(z|d,w)}{\\Sigma_{d^{\\prime},w}n(d^{\\prime},w)P(z%&#10;|d^{\\prime},w)}\\\\&#10;\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo stretchy=\"false\">|</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>w</mi></msub><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mrow><msup><mi>d</mi><mo>\u2032</mo></msup><mo>,</mo><mi>w</mi></mrow></msub><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mo>\u2032</mo></msup><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><msup><mi>d</mi><mo>\u2032</mo></msup><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n", "itemtype": "equation", "pos": 16743, "prevtext": "\n\n", "index": 29, "text": "\\begin{equation}\nP(z) = \\frac{\\Sigma_{d,w}n(d,w)P(z|d,w)}{R}\\\\\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"P(z)=\\frac{\\Sigma_{d,w}n(d,w)P(z|d,w)}{R}\\\\&#10;\" display=\"block\"><mrow><mrow><mi>P</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi>d</mi><mo>,</mo><mi>w</mi></mrow></msub><mi>n</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">|</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>R</mi></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n\n\n\n\\subsubsection{Fuzzy-KNN classification}\nSince our framework based on topic modelling and discovery, fuzzy KNN classification \\cite{fuzzy} techniques was used for getting appropriate topic of a test image corresponding to training images. Fuzzy kNN perform better than traditional KNN algorithm, because it depends on weight of neighbours.\nIn the training stage we have calculated $P(w|z)$, which was used as input for testing algorithm to compute $P(z|d_{test})$.\nAfter that a K- nearest neighbour algorithm was used to classify these image by using probability distribution $P(z|d_{train})$.\n\n", "itemtype": "equation", "pos": 16821, "prevtext": "\n\n", "index": 31, "text": "\\begin{equation}\nR \\equiv\\Sigma_{d,w}n(d,w)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"R\\equiv\\Sigma_{d,w}n(d,w)\" display=\"block\"><mrow><mi>R</mi><mo>\u2261</mo><mrow><msub><mi mathvariant=\"normal\">\u03a3</mi><mrow><mi>d</mi><mo>,</mo><mi>w</mi></mrow></msub><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><mo>,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n$u_{i}$ is value for membership strength to be computed, and $u_{ij}$ is previously labelled value of i th class for j th vector.\nFinal class label of the query point x is computed as follows:\n\n", "itemtype": "equation", "pos": 17478, "prevtext": "\n\n\n\n\n\\subsubsection{Fuzzy-KNN classification}\nSince our framework based on topic modelling and discovery, fuzzy KNN classification \\cite{fuzzy} techniques was used for getting appropriate topic of a test image corresponding to training images. Fuzzy kNN perform better than traditional KNN algorithm, because it depends on weight of neighbours.\nIn the training stage we have calculated $P(w|z)$, which was used as input for testing algorithm to compute $P(z|d_{test})$.\nAfter that a K- nearest neighbour algorithm was used to classify these image by using probability distribution $P(z|d_{train})$.\n\n", "index": 33, "text": "\\begin{equation}\nu_{i}(x) = \\frac{\\displaystyle\\sum\\limits_{j=1,K}u_{ij}(\\frac{1}{||x - x_{j}||^{\\frac{2}{(m-1)}}})}{\\displaystyle\\sum\\limits_{j=1,K}(\\frac{1}{||x - x_{j}||^{\\frac{2}{(m-1)}}})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"u_{i}(x)=\\frac{\\displaystyle\\sum\\limits_{j=1,K}u_{ij}(\\frac{1}{||x-x_{j}||^{%&#10;\\frac{2}{(m-1)}}})}{\\displaystyle\\sum\\limits_{j=1,K}(\\frac{1}{||x-x_{j}||^{%&#10;\\frac{2}{(m-1)}}})}\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi>K</mi></mrow></mrow></munder></mstyle><mrow><msub><mi>u</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msup><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>j</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mfrac><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mfrac></msup></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi>K</mi></mrow></mrow></munder></mstyle><mrow><mo stretchy=\"false\">(</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msup><mrow><mo fence=\"true\">||</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>x</mi><mi>j</mi></msub></mrow><mo fence=\"true\">||</mo></mrow><mfrac><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mfrac></msup></mfrac></mstyle><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n\n\n\n\n\\subsection{Macula Localization}\nThe macula is the central region of the retina situated at the posterior pole of the eye, between the superior and inferior temporal arteries. Its centre at a distance of 2.5 D from optic disc centre. D is optic disc diameter. Fovea is located at the centre of macula and this part responsible for specialized high acuity vision. Fovea region is exclusively made up of cones, without it fine details could not be seen. Age-related macular degeneration, diabetic macular edema etc. are most common disorder of macula region. \n As per study and observation fovea the centre part of macula is located at a distance 2.5 D along the axis of symmetry of a parabola which vertex is at the centre of optic disc. Finally a parabola was fitted to the main courses of blood vessels, process is depicted in Fig. 7. \n\n\\subsubsection{Vessel Point Selection and Curve Fitting}\nFor extracting blood vessels from image, a algorithm described in this work \\cite{vesselmap} was used. In the first stage the binary map of vessels was extracted. And then connected component analysis was used to remove small unconnected parts as a pre-processing step. To get centreline of blood vessels by removing border a morphological skeletonize algorithm \\cite{skel} based algorithm was used. Also we have computed distance transform \\cite{dist} of binary vessels map. Final threshold for getting rid of small vessels and vein is computed using cumulative histogram count and real data volume. Since the real  interest was extract the main courses blood vessels, a point wise multiplication of skeleton and distance map was used to get potential candidate points.\n\n\nA parabolic model is fitted to the main course of blood vessels using least squares non linear optimization algorithm.\n\n", "itemtype": "equation", "pos": 17880, "prevtext": "\n$u_{i}$ is value for membership strength to be computed, and $u_{ij}$ is previously labelled value of i th class for j th vector.\nFinal class label of the query point x is computed as follows:\n\n", "index": 35, "text": "\\begin{equation}\nu_{0}(x) = arg max_{i}(u_{i}(x) )\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"u_{0}(x)=argmax_{i}(u_{i}(x))\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>a</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><msub><mi>x</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>u</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\nr and $\\theta$ are two constants, which are calculated using Newton non linear least squares optimization method as described follows. Suppose ( $x_{i},y_{i}$ ) are vessels coordinates, \n\n\n", "itemtype": "equation", "pos": 19738, "prevtext": "\n\n\n\n\n\n\\subsection{Macula Localization}\nThe macula is the central region of the retina situated at the posterior pole of the eye, between the superior and inferior temporal arteries. Its centre at a distance of 2.5 D from optic disc centre. D is optic disc diameter. Fovea is located at the centre of macula and this part responsible for specialized high acuity vision. Fovea region is exclusively made up of cones, without it fine details could not be seen. Age-related macular degeneration, diabetic macular edema etc. are most common disorder of macula region. \n As per study and observation fovea the centre part of macula is located at a distance 2.5 D along the axis of symmetry of a parabola which vertex is at the centre of optic disc. Finally a parabola was fitted to the main courses of blood vessels, process is depicted in Fig. 7. \n\n\\subsubsection{Vessel Point Selection and Curve Fitting}\nFor extracting blood vessels from image, a algorithm described in this work \\cite{vesselmap} was used. In the first stage the binary map of vessels was extracted. And then connected component analysis was used to remove small unconnected parts as a pre-processing step. To get centreline of blood vessels by removing border a morphological skeletonize algorithm \\cite{skel} based algorithm was used. Also we have computed distance transform \\cite{dist} of binary vessels map. Final threshold for getting rid of small vessels and vein is computed using cumulative histogram count and real data volume. Since the real  interest was extract the main courses blood vessels, a point wise multiplication of skeleton and distance map was used to get potential candidate points.\n\n\nA parabolic model is fitted to the main course of blood vessels using least squares non linear optimization algorithm.\n\n", "index": 37, "text": "\\begin{equation}\ny = \\frac{x^2}{4r sin\\theta}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"y=\\frac{x^{2}}{4rsin\\theta}\" display=\"block\"><mrow><mi>y</mi><mo>=</mo><mfrac><msup><mi>x</mi><mn>2</mn></msup><mrow><mn>4</mn><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>\u03b8</mi></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.06608.tex", "nexttext": "\n\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.4in,height=1.9in]{maculaparabola}\n\\caption{Parabolic model Fitting}\n\\end{figure}\n\nOnce the position of the fovea is estimated we need to estimate whether the macula region is infected to any diseases. For this a template matching method have been applied and healthy eyes macula region was used as standard template. A window of size $1.5D \\times 1.5D$ centred on the fovea proved to be efficient for this task and computed its distance (error) from standard template. If error is very high then the macula region is infected with age related macular degeneration.   \n\n\n\n\\begin{table}[H]\n  \\centering\n  \\begin{tabular}{*{20}{c}}\n\\hline\nDatabase & \\# Pathological Img & Resolution & Acc(\\%)\\\\\n\\hline\nMessidor  & 300 & $1000 \\times 1504$ & 100\\\\  \n\\hline\nDIARETDB1 & 89 & $1152 \\times 1500 $ & 100\\\\  \n\\hline\nSTARE & 81 & $605 \\times 700$ & 98.8\\\\\n\\hline\n\\end{tabular} \n  \\caption{Result of the optic disc and the Macula}\n\\end{table}\n\n\\begin{table}[H]\n  \\centering\n  \\begin{tabular}{*{20}{c}}\n\\hline\nMethods & \\# Images  & Acc(\\%) & \\# Failed img\\\\\n\\hline\nPrposed Method & 81& 98.8 & 1\\\\\n\\hline\nAbdel et al. \\cite{abdel} & 81 & 98.8  & 1\\\\\n\\hline\nForacchia et al. \\cite{forc} & 81 & 97.5 & 2 \\\\\n\\hline\nLu et al. \\cite{lu} & 81 & 96.3 & 3\\\\\n\\hline\n\\end{tabular} \n  \\caption{Result Comparisons of Different Optic Disc detection method on STARE dataset}\n\\end{table}\n\n\\section{RESULT and DISCUSSIONS}\nFor analysing the accuracy of this method on different set of images, publicly available MESSIDOR \\cite{messi}, STARE[ \\cite{stare}and DIARETDB1 \\cite{diaret} dataset was experimented. Images with various difficulty from these databses for was testes to evaluate this algorithm accuracy. These datasets include image with pathological features such as haemorrhages, exudates and microaneurysms. These datasets are provided by expert in Ophthalmology with proper annotation of features location in images. These three datasets includes 400 retinal images with variety of pathological symptoms and captures under different conditions. Also camera used to capture those images for all these databases are different. We have used MATLAB platform in a windows 8.1 machine with intel i7 processor to test this method.\n \nIn Fig. 3, result of saliency map is shown with possible selection windows, it is clear that due to pathological symptoms it also capture irrelevant features. To get exact location of the optic disc a validation process in the detected areas was performed with multiple windows of size [122, 112], around the detected region. \n\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.1in,height=1.3in]{odhogg}\n\\caption{Left: Optic disc Hog feature, Right: non optic disc element}\n\\end{figure}\n\n\\begin{figure*}\n        \\centering\n        \\begin{subfigure}[b]{0.33\\textwidth}\n                \\includegraphics[width=1.9in,height=1.2in]{perfvsZ}\n                \\caption{(a) Accuracy vs Z}\n                \\label{fig:cnnn}\n        \\end{subfigure}\n        \\begin{subfigure}[b]{0.33\\textwidth}\n                \\includegraphics[width=1.9in,height=1.2in]{perfvsK}\n                \\caption{(b) Accuracy vs K}\n                \\label{fig:mcnn}\n        \\end{subfigure}\n        \\begin{subfigure}[b]{0.30\\textwidth}\n                \\includegraphics[width=1.9in,height=1.2in]{perfvsV}\n                \\caption{(c) Accuracy vs V}\n                \\label{fig:plsa}\n        \\end{subfigure}\n        \\caption{Parameters variation of pLSA}\\label{imagess}\n\\end{figure*}\n\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.4in,height=1.3in]{thresholdvessel}\n\\caption{Main courses of vessel after processing}\n\\end{figure}\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.4in,height=2.4in]{macularesult}\n\\caption{Detected macula and fitted parabola}\n\\end{figure}\n\n\\begin{figure*}\n \\center\n\n  \\includegraphics[width=6.5in, height = 2.4in]{opticdiscdetect}\n\n  \\caption{Optic disc detection result on STARE dataset, Top row: Image with detected OD, Bottom row: Corresponding Saliency Map}\n\n  \\label{AAA}\n\n\\end{figure*}\n\n\n\n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.4in,height=2.6in]{opticdiscdetectd1}\n\\caption{Detected Optic Disc on DIARETDB1V2}\n\\end{figure}\n\n\n\nFor validation of the optic disc detection, the PLSA classifier is trained with 400 training images, these images are selected to include all type of possible difficulties. From each images the optic disc and its four parts is selected for training, and each image is resized to [122,112] using bilinear interpolation. From each window HOG feature as shown in Fig. 4 and Fig. 8 is extracted. Use of part based model improved the accuracy of this method and can detect OD even if it is half visible in the image. HOG feature can effectively capture structure of vessels. And non-optic disc windows are selected as negative for training the complete classifier. Classifier accuracy varies on the number of topics and words used in PLSA model, in this work classifier is trained using 15 topics, gives optimal accuracy.\n\nAlso value of number of nearest neighbours (K) in fuzzy-KNN effect accuracy. In this work optimal accuracy is obtained using 15 topics and with a visual dictionary of size 113. Optimal value of K used in this work is 9. Accuracy variation with respect to pLSA and fuzzy-KNN parameters is shown in Fig. 9. Fig . 9 (a) shows accuracy variation with respect to number of topics keeping number of words and number of nearest neighbours value fixed. Similarly Fig. 9(b) and Fig. 9 (c) shows variation with respect to K and V while keeping respective parameters fixed as shown.\n\n\n Detection of optic disc gets 100 \\% accuracy over Diaretdb1v2 and Messidor databases. Our algorithm performs well in much degraded images with low light and severe pathological symptoms. In Fig. 12, detection result of the optic disc on pathological images (STARE dataset) with extreme illuminance and structure variation is shown. Also Fig. 12 left two columns shows some result in DIARETDB1 dataset. Table. {\\uppercase\\expandafter{\\romannumeral {1}\\relax}} Gives detection accuracy of selected test images to include various difficulty from different dataset. A comparions with recent methods is shown in Table {\\uppercase\\expandafter{\\romannumeral {2}\\relax}} on STARE dataset. This method perform very well with accuracy of 98.8\\% on STARE.\n\n\nIn Fig. 10 Detected blood vessels from a image is shown and its main course of blood vessels obtained from morphological skeletonize and thresholding operation. Since main course of blood vessels have higher thickness and length than any other vessels and vein it becomes easier to extract them using as mentioned algorithm. Once the main course of blood vessels is extracted it become easy to fit parabola and locate the fovea.  \nResult of macula location detection and curve fitting in normal and pathological images is shown in Fig. 11. It can be seen from the figure, that for pathological images with age related macular degeneration, macula's position can be detected and requires validation to confirm about defect. The process of confirming pathology in the macula is very important from the perspective of possible eye vision loss. For macular detection we have also 100 \\% accuracy in normal images, this accuracy depends on the optic disc and main course of blood vessels locations. The fovea, which is centre of the macula region is located at a distance of 2.5 D of the optic disc diameter D.\n\n\n\n\\subsection{Luminance and Contrast Invariance}\nAn extensive evaluation is performed in images with varying luminosity and contrast. It has been observed that final Saliency map (SM) is robast to change of luminosity and contrast. In addition to that HOG feature values doesn't change with global contrast and luminosity variation. Fig. 14 clearly depicts the luminosity and contrast invariance, first coulmn shows the original image with color distribution and SM. First row and rest of the coloumn images were obtained by varying luminosity and contrast of original image at different lavel and second row shows their respective color disribution. It can be seen that final SM capture all features irrespective of variances. \n\\begin{figure}\n  \\centering\n      \\includegraphics[width=3.5in,height=3.0in]{invariance}\n\\caption{Top-Row: Original Image1 and its different version with modified contrast and luminosity, Middle-Row: Color Distribution of Both images, Bottom-Row: Final Saliency Map}\n\\end{figure}\n\n\n\\subsection{Processing Time}\nFor real time application, reliable method with fast computational speed is essential. The application of the proposed method takes approximately 1.1s to a typical image of the DIARETDB1V2 database of size 1152 x 1500 in conventional computer to compute SM. And validation step take maximum of 9s. Processing time can be further reduced by implementing the method on NVIDIA GPU, since most of the computation involves can be parallelised. Table {\\uppercase\\expandafter{\\romannumeral {3}\\relax}} shows comparisons of this method processing time per image with existing method. \\\\\n\\begin{table}[H]\n  \\centering\n  \\begin{tabular}{*{20}{c}}\n\\hline\nMethod & Resolution & time \\\\\n\\hline\nProposed Method & $1152 \\times 1500$ & 10.1s \\\\\n\\hline\nAbdel \\cite{abdel} & $605 \\times 700$ & 3.5 min \\\\\n\\hline\nForacchia \\cite{forc} & $605 \\times 700$ &  2min \\\\\n\\hline\nLu \\cite{lu} &  $605 \\times 700$ & 40s \\\\\n\\hline\n\n\\end{tabular} \n  \\caption{Comparions of Processing Time Per Image}\n\\end{table}\n\n\\subsection{Limitations}\nFrom experiment it has been observed that our algorithm fails in situation where optic disc deeply damaged and seems to be flat region with no difference to neighbouring regions. Lack of saliency with respect to illuminance, colour or vessels structure leads to detection failure. Figure 13 right column shows detection failure, where our algorithm end up in region having exudate and blood vessels with low detection probability. \\\\\n\nThe objective of this work is on the development of a computer aided system for detection of the optic disc and the macula for analysis of these features to diagnosis of various diseases. From processing time and accuracy points of view this method can be used to assist opthalmologist in detection of the OD and the macula. This method have several dvantages over existing systems. Seperation of detection and validation step inceases accuracy significantly. Also no seperate preprocessing is required for this system. In addition to that luminace and contrast invariance make this method suitable for practical purpose.\n\n\\section{CONCLUSIONS}\nIn this paper a novel computer aided diagnosis system is developed for retinal image analysis. For locating of the optic disc our method use the concept of saliency region and specific vasculature structure in the optic disc region. This system made use of unsupervised PLSA algorithm. We have achieved state of art accuracy for the optic disc detection in comparison to other algorithm. Detection of the macula based on clinical information of its location with respect to the optic disc and main course of the blood vessels\n\n\\addtolength{\\textheight}{-12cm}   \n                                  \n                                  \n                                  \n                                  \n                                  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\ifCLASSOPTIONcaptionsoff\n  \\newpage\n\\fi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{thebibliography}{1}\n\n\\bibitem{smap} Achanta, R., Estrada, F., Wils, P.,  S\u00c3\u00bcsstrunk, S., \"Salient region detection and segmentation\". In Computer Vision Systems (pp. 66-75). Springer Berlin Heidelberg, 2008.\n\\bibitem{plsa} Hofmann, T., \"Unsupervised learning by probabilistic latent semantic analysis\". Machine Learning 41 (2001) 177-196.\n\\bibitem{micro}Haloi, M. \"Improved Microaneurysm Detection using Deep Neural Networks.\" arXiv preprint arXiv:1505.04424 (2015).\n\\bibitem{llc}J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong, \"Locality-constrained Linear Coding for Image Classification\", CVPR 2010\n\\bibitem{sau}J. Sauvola and M. Pietikainen, \u00e2\u0080\u009cAdaptive document image binarization,\u00e2\u0080\u009d Pattern Recognition 33(2), pp. 225\u00e2\u0080\u0093236, 2000\n\\bibitem{lab} K. Leon, D. Mery, F. Pedreschic, J. Leon, \"Color measurement in L* a*  b* units from RGB digital images\", Food Research International,ELSIVIER, 2006\n\\bibitem{hog}Dalal, N., Triggs, B., \"Histograms of oriented gradients for human detection\", CVPR, San Diego, California (2005)\n\n\\bibitem{stare} A. Hoover, V. Kouznetsova and M. Goldbaum, \"Locating Blood Vessels in Retinal Images by Piece-wise Threhsold Probing of a Matched Filter Response\", IEEE Transactions on Medical Imaging , vol. 19 no. 3, pp. 203-210, March 2000.\n\\bibitem{abdel} A. Youssif, A. Z. Ghalwash, and A. Ghoneim, \u00e2\u0080\u009cOptic disc detection from normalized digital fundus images by means of a vessels\u00e2\u0080\u0099 direction matched filter,\u00e2\u0080\u009d IEEE Trans. Med. Imag., vol. 27, no. 1, pp. 11\u00e2\u0080\u009318, Jan. 2008.\n\\bibitem{forc} M. Foracchia, E. Grisan, and A. Ruggeri, \u00e2\u0080\u009cDetection of optic disc in retinal images by means of a geometrical model of vessel structure,\u00e2\u0080\u009d IEEE Trans. Med. Imag., vol. 23, no. 10, pp. 1189\u00e2\u0080\u00931195, Oct. 2004.\n\\bibitem{lu} Lu, Shijian, and Joo Hwee Lim. \"Automatic optic disc detection from retinal images by a line operator.\" Biomedical Engineering, IEEE Transactions on 58.1 (2011): 88-94.\n\n\\bibitem{fuzzy} J. M. Keller, M.M Gray and J.A. Givens , \"A Fuzzy K-Nearest Neighbor Algorithm\", IEEE Transactions on Systems, Man, and Cybernetics, 1985.\n\\bibitem{li} H. Li and O. Chutatape, \u00e2\u0080\u009cAutomated feature extraction in color retinal images by a model based approach,\u00e2\u0080\u009d IEEE Trans. Biomed. Eng., vol.51, no. 2, pp. 246\u00e2\u0080\u0093254, Feb. 2004.\n\\bibitem{diaret}Kauppi, T., Kalesnykiene, V., Kamarainen, J.-K., Lensu, L., Sorri, I., Raninen A., Voutilainen R., Uusitalo, H., K\u00c3\u00a4lvi\u00c3\u00a4inen, H., Pietil\u00c3\u00a4, J., \"DIARETDB1 diabetic retinopathy database and evaluation protocol\", In Proc of the 11th Conf. on Medical Image Understanding and Analysis (Aberystwyth, Wales, 2007)\n\\bibitem{dist} G. Borgefors, \"Distance transformations in digital images\",Computer Vision, Graphics and Image Processing,1986 \n\n\\bibitem{skel}Frank Y. Shih, Christopher C. Pu, \"A skeletonization algorithm by maxima tracking on Euclidean distance transform\", Pattern Recognition, ELSEVIER,1995\n\\bibitem{budai} Attila Budai, Lenke Laurik, Joachim Hornegger, G\u00c2\u00b4abor M. Somfai, Georg Michelson, \"PROBABILITY MAP BASED LOCALIZATION OF OPTIC DISK \",PMB, 2012\n\\bibitem{vesselmap} A. Budai, R. Bock, A. Maier, J. Hornegger, and G. Michelson, \"Robust Vessel Segmentation in Fundus Images\", RVS, 2013.\n\\bibitem{aao} http://www.aao.org/theeyeshaveit/optic-fundus\n\\bibitem{c20} Ophthalmic Photography: Retinal Photography, Angiography, and Electronic Imaging, 2nd Edition, Patrick J. Saine and Marshall E. Tyler Butterworth-Heinemann Medical; ISBN: 0750673729\n\\bibitem{messi}  http://www.adcis.net/en/DownloadThirdParty/Messidor.html\n\\bibitem{c22} https://www.nei.nih.gov/health/diabetic/retinopathy \n\\bibitem{c23} Niall Pattona et al, \"Retinal image analysis: Concepts, applications and potential\",Progress in Retinal and Eye Research, ELSEVIER, 2006\n\n\n\n\\end{thebibliography}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 19987, "prevtext": "\nr and $\\theta$ are two constants, which are calculated using Newton non linear least squares optimization method as described follows. Suppose ( $x_{i},y_{i}$ ) are vessels coordinates, \n\n\n", "index": 39, "text": "\\begin{equation}\nminimize \\displaystyle\\sum\\limits_{i=1,m} (y_{i} - f(x_{i}))^2 \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"minimize\\displaystyle\\sum\\limits_{i=1,m}(y_{i}-f(x_{i}))^{2}\" display=\"block\"><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>z</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi>m</mi></mrow></mrow></munder><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>-</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></math>", "type": "latex"}]