[{"file": "1601.01186.tex", "nexttext": "\n\nwhere $(W_s)_{s\\ge0 }$ is a Brownian motion in ${\\mathbb{R}}^q$, $(X_s)_{s\\ge0\n}$ is a diffusion in ${\\mathbb{R}}^d$ and $\\xi$ is of the form $\\Phi(X_T)$.\nIndeed, the MWDP (\\ref{eqmalscheme}) was inspired by \\cite{mazhan02}, Theorem~4.2, which states that there is a version of the\n{continuous-time} process $(Z_t)_{0\\le t<T}$ given by\n\n\n\n", "itemtype": "equation", "pos": 3783, "prevtext": "\n\n\\begin{frontmatter}\n\n\\title{Approximation of backward stochastic differential equations using Malliavin weights and least-squares regression}\n\\runtitle{Approximation of BSDEs using Malliavin weights and\nleast-squares regression}\n\n\\begin{aug}\n\n\\author[A]{\\inits{E.}\\fnms{Emmanuel}~\\snm{Gobet}\\thanksref{e1}\\ead\n[label=e1,mark]{emmanuel.gobet@polytechnique.edu}}\n\\and\n\\author[A]{\\inits{P.}\\fnms{Plamen}~\\snm{Turkedjiev}\\corref{}\\thanksref\n{e2}\\ead[label=e2,mark]{turkedjiev@cmap.polytechnique.fr}}\n\n\n\\address[A]{Centre de Math\\'ematiques Appliqu\\'ees,\nEcole Polytechnique and CNRS,\nRoute de Saclay,\n91128 Palaiseau cedex, France.\\\\\n\\printead{e1,e2}}\n\\end{aug}\n\n\n\\received{\\smonth{8} \\syear{2013}}\n\\revised{\\smonth{3} \\syear{2014}}\n\n\n\n\\begin{abstract}\nWe design a numerical scheme for solving a Dynamic Programming equation\nwith Malliavin weights arising from\nthe time-discretization of backward stochastic differential equations\nwith the integration by parts-representation\nof the $Z$-component by\n(\\textit{Ann. Appl. Probab.} \\textbf{12} (2002) 1390--1418). When the sequence of\nconditional expectations is computed using\nempirical least-squares regressions, we establish, under general\nconditions, tight error bounds as the time-average\nof local regression errors only (up to logarithmic factors).\nWe compute the algorithm complexity by a suitable optimization of the\nparameters, depending on the dimension\nand the smoothness of value functions, in the limit as the number of\ngrid times goes to infinity. The estimates\ntake into account the regularity of the terminal function.\n\\end{abstract}\n\n\n\n\n\\begin{keyword}\n\\kwd{backward stochastic differential equations}\n\\kwd{dynamic programming equation}\n\\kwd{empirical regressions}\n\\kwd{Malliavin calculus}\n\\kwd{non-asymptotic error estimates}\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\\section{Introduction}\n\n\n\\subsection{Setting}\nLet $T>0$ be a fixed terminal time and let $(\\Omega, \\mathcal\n{F},(\\mathcal{F}\n_t)_{0\\leq\nt \\leq T},{\\mathbb{P}})$ be a filtered probability space whose filtration is\naugmented with the ${\\mathbb{P}}$-null sets.\nLet $\\pi= \\{ 0 =: t_0 < t_1 < \\cdots< t_{N-1} < t_N:=T\\}$ be a given\ntime-grid on $[0,T]$ and $\\Delta_i:=t_{i+1}-t_i$.\nAdditionally, for a fixed $q\\in{\\mathbb{N}}\\setminus\\{0\\}$, we are given a set\n$\\{ {H^{(i)}_{j}}\\dvt  0\\le i < j \\le N\\}$ of $({\\mathbb{R}}^q)^\\top$-valued random\nvariables in ${\\mathbf{L}}_2(\\mathcal{F}_T,{\\mathbb{P}})$ (i.e., square integrable and\n$\\mathcal{F}\n_T$-measurable) that we call Malliavin weights. Here ${}^\\top$ stands\nfor the transpose.\n\n\nIn this paper, we introduce the Malliavin Weights Least Squares\nalgorithm, abbreviated \\textit{MWLS}, to approximate discrete time\nstochastic processes $(Y,Z)$\ndefined by\n\n\n\\begin{eqnarray}\n\\cases{\n\\displaystyle Y_i =\n\\mathbb{E}_i\\Biggl[\\xi+ \\sum_{j=i}^{N-1}\nf_j(Y_{j+1},Z_j) \\Delta_j\n\\Biggr], &\\quad $0 \\le i \\le N$,\n\\vspace*{5pt}\\cr\n\\displaystyle Z_i= \\mathbb{E}_i\\Biggl[\\xi{H^{(i)}_{N}} +\n\\sum_{j=i+1}^{N-1} f_j(Y_{j+1},Z_j)\n{H^{(i)}_{j}} \\Delta_j\\Biggr], &\\quad $0 \\le i \\le N-1$,}\\label{eqmalscheme}\n\\end{eqnarray}\n\nwhere $\\mathbb{E}_i[\\cdot]:= \\mathbb{E}[\\cdot\\mid\\mathcal{F}_{t_i}]$,\n$\\xi\n$ is a ${\\mathbb{R}}$-valued\nrandom variable in ${\\mathbf{L}}_2(\\mathcal{F}_T,{\\mathbb{P}})$, and $(\\omega,y,z)\n\\mapsto\nf_j(\\omega,y,z)$ is $\\mathcal{F}_{t_j} \\otimes\\mathcal{B}({\\mathbb{R}}\n)\\otimes\n\\mathcal{B}(({\\mathbb{R}}\n^q)^\\top\n)$-measurable. This system is solved backward in time in the order\n$Y_N, Z_{N-1}, Y_{N-1},\\dots$ and it takes the form of a dynamic\nprogramming equation with Malliavin weights. We call it the Malliavin\nWeights Dynamic Programming equation (MWDP for short).\n\n\n\nThe main application of (\\ref{eqmalscheme}) is to approximate\ncontinuous-time, {decoupled} Forward--Backward SDEs (FBSDEs) of the form\n\n\n\n", "index": 1, "text": "\\begin{equation}\nY_t = \\xi+ \\int_t^T\nf(s,X_s,Y_s,Z_s) \\,\\mathrm{d}s - \\int\n_t^T Z_s \\,\\mathrm{d}W_s,\n\\label{eqBSDEcts}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"Y_{t}=\\xi+\\int_{t}^{T}f(s,X_{s},Y_{s},Z_{s})\\,\\mathrm{d}s-\\int_{t}^{T}Z_{s}\\,%&#10;\\mathrm{d}W_{s},\" display=\"block\"><mrow><mrow><msub><mi>Y</mi><mi>t</mi></msub><mo>=</mo><mrow><mrow><mi>\u03be</mi><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>T</mi></msubsup><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><msub><mi>X</mi><mi>s</mi></msub><mo>,</mo><msub><mi>Y</mi><mi>s</mi></msub><mo>,</mo><msub><mi>Z</mi><mi>s</mi></msub><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>d</mo><mi>s</mi></mrow></mrow></mrow></mrow><mo>-</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>T</mi></msubsup><mrow><mpadded width=\"+1.7pt\"><msub><mi>Z</mi><mi>s</mi></msub></mpadded><mo>\u2062</mo><mrow><mo>d</mo><msub><mi>W</mi><mi>s</mi></msub></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nwhere the processes $({H^{(t)}_{s}})_{0\\leq t < s \\leq T} $ are Malliavin\nweights defined by\n\n\n\n", "itemtype": "equation", "pos": 4256, "prevtext": "\n\nwhere $(W_s)_{s\\ge0 }$ is a Brownian motion in ${\\mathbb{R}}^q$, $(X_s)_{s\\ge0\n}$ is a diffusion in ${\\mathbb{R}}^d$ and $\\xi$ is of the form $\\Phi(X_T)$.\nIndeed, the MWDP (\\ref{eqmalscheme}) was inspired by \\cite{mazhan02}, Theorem~4.2, which states that there is a version of the\n{continuous-time} process $(Z_t)_{0\\le t<T}$ given by\n\n\n\n", "index": 3, "text": "\\begin{equation}\nZ_t = \\mathbb{E}_t\\biggl[\\xi{H^{({t})}_{T}} + \\int\n_{t}^T f(s,X_s,Y_s,Z_s)\n{H^{({t})}_{s}} \\,\\mathrm{d}s\\biggr], \\label{eq4Z}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"Z_{t}=\\mathbb{E}_{t}\\biggl{[}\\xi{H^{({t})}_{T}}+\\int_{t}^{T}f(s,X_{s},Y_{s},Z_%&#10;{s}){H^{({t})}_{s}}\\,\\mathrm{d}s\\biggr{]},\" display=\"block\"><mrow><mrow><msub><mi>Z</mi><mi>t</mi></msub><mo>=</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msub><mi>E</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"210%\" minsize=\"210%\">[</mo><mrow><mrow><mi>\u03be</mi><mo>\u2062</mo><msubsup><mi>H</mi><mi>T</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>T</mi></msubsup><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo>,</mo><msub><mi>X</mi><mi>s</mi></msub><mo>,</mo><msub><mi>Y</mi><mi>s</mi></msub><mo>,</mo><msub><mi>Z</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msubsup><mi>H</mi><mi>s</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mpadded><mo>\u2062</mo><mrow><mo>d</mo><mi>s</mi></mrow></mrow></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">]</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor $(D_tX_r)_t$ being the Malliavin derivative of $X_r$ and $\\sigma\n(\\cdot)$ is the diffusion coefficient of $X$. The representation\n(\\ref{eq4Z}) is obtained via a Malliavin calculus integration by parts\nformula, see \\cite{nual95} for a general account on the subject.\nA discretization procedure to approximate the FBSDE \\mbox{(\\ref{eqBSDEcts})--(\\ref{eq4Z})} with (\\ref{eqmalscheme}),\nincluding explicit definitions of the random variables ${H^{(i)}_{j}}$ based\non~(\\ref{eq4malweights}),\nis given in \\cite{turk13,turk13b}, where the author also\ncomputes the discretization error in terms of $N$.\nIn honour of the connection between (\\ref{eqmalscheme}) and (\\ref\n{eqBSDEcts})--(\\ref{eq4Z}), we call the random variables ${H^{(i)}_{j}}$\nMalliavin weights, $\\xi$ the terminal condition, and $(i,\\omega,y,z)\n\\mapsto f_i(y,z)$ the driver.\nWe say that the pair $(Y,Z)$ satisfying (\\ref{eqmalscheme}) solves a\nMWDP with\n{terminal condition $\\xi$ and driver $f_i(y,z)$.}\n\n\n\n\n\\subsection{Contributions}\nIn this paper, we are not concerned with the discretization procedure,\nbut rather with the analysis of the MWDP equation (\\ref{eqmalscheme})\nitself and\nits numerical resolution via the MWLS algorithm, in which one uses\nempirical least-squares regressions (approximations on finite basis of\nfunctions using simulations) to compute conditional expectations.\n\nSince the system (\\ref{eqmalscheme}) may be relevant to problems\nbeyond the FBSDE system (\\ref{eqBSDEcts})--(\\ref{eq4Z}), we allow the\nframework and assumptions to\naccomodate as much generality as possible. However, MWLS is, to the\nbest of our knowledge, the first direct implementation of formula\n(\\ref{eq4Z}) in a fully implementable numerical scheme.\nFor other applications of Malliavin calculus in numerical simulations,\nwith different perspectives and results to ours, see, for instance, \\cite\n{fourlion99,kohapett02,bouctouz04,gobemuno05,ballcarazane05,hunualsong11,brialaba13}.\n\nWe adapt the recent theoretical analysis of the\nLeast Squares Multi-step forward Dynamical Programming algorithm (LSMDP) of \\cite\n{gobeturk14} for discrete BSDEs (without Malliavin weights) to the\nsetting of MWDP.\nAs in the aforementioned reference, we consider a locally Lipschitz\ndriver $f_i(y,z)$ that is locally bounded at $(y,z) = (0,0)$ -- see\nSection~\\ref{section4assumptions}.\nThis allows the algorithm of the current paper to be applied for the\napproximation of some quadratic BSDEs and for some proxy/variance\nreduction methods.\nFor more details on these applications, see \\cite{gobeturk14}, Section~2.2.\nMoreover, we make use of analogous stability results and conditioning\narguments in the proof of the main result, Theorem~\\ref{thmMCerr}, as\nin the proof of \\cite{gobeturk14}, Theorem 4.11.\n{However, the Malliavin weights lead to significantly differences in\nthe main theorem and stability results, both in the technical elements\nof the proofs and the results. We develop {seemingly} novel Gronwall\ntype inequalities to handle the technical differences; these results\nare outlined in Section~\\ref{sectiongronwall} and proved in\nAppendix~\\ref{appendixprooflemintegrals}.\nFurthermore, the stability results are more powerful and the complexity\nof the MWLS is better than the LSMDP, as will be discussed in what follows.\n}\n\n{We would like to mention that the class of quadratic problems we can\ntreat with these assumptions is quite different to the recent \\cite\n{chasrich13}.\nHere we are treating the {non-degenerate} setting where the terminal\ncondition may be H\\\"older continuous, whereas the other reference\nallows degeneracy at the expense of requiring locally Lipschitz\nterminal conditions.\n}\n\nWe prove stability results on the MWDP in Section~\\ref{sectionstability}.\n{Much effort is made to keep the constants explicit.}\nThese results are instrumental throughout the paper. The stability\nestimates on $Z$ are at the individual time points (coherently with the\nrepresentation theorem of \\cite{mazhan02})\nrather than the time-averaged estimates of \\cite{gobeturk14}, Proposition~3.2.\nThis allows for finer and more precise computations.\nThe time-dependency in our estimates also takes better into account the\nregularity of the terminal condition, similarly to the continuous-time\ncase \\cite{delaguat06}.\n\nSection~\\ref{section4MC} is the core of the paper: it is dedicated to\nthe MWLS algorithm in the Markovian context $Y_i=y_i(X_i)$ and\n$Z_i=z_i(X_i)$ for some Markov chain $X_i$ in ${\\mathbb{R}}^d$ and unknown\nfunctions $(y_i(\\cdot),z_i(\\cdot))$. In MWLS, the conditional\nexpectations in (\\ref{eqmalscheme})\nare replaced by Monte Carlo least-squares regressions. For each point\nof the time-grid, we use a cloud of independent paths of the {Markov\nchain} $X$ and the Malliavin weights $H$, and some approximation spaces\nfor representing the value functions $(y_i(\\cdot),z_i(\\cdot))$. The\nalgorithm is detailed in Section~\\ref{sectionMCalg}, and a full\nerror analysis\nin terms of the number of simulations and the approximation spaces\nis performed in Sections~\\ref{sectionerr} and~\\ref\n{sectionproofmainthm}. The final error estimates (Theorem~\\ref\n{thmMCerr}) are similar to \\cite{gobeturk14}, Theorem 4.11, in that\nthey are the time-averaged {local} regression errors of\nthe discrete BSDE, but the results are in a stronger norm and the\ntime-dependency is better. {The constants are completely explicit.}\n{Although the norms are stronger than in \\cite{gobeturk14}, the\nestimates do not deteriorate; instead, they are {significantly}\nimproved. This is intrinsically due to the MWDP representation, which\navoids the usual \\mbox{$1/\\Delta_i$-}factor in front of all controls on $Z$.\nThis improvement can be tracked by inspecting the a.s. bounds (compare\n(\\ref{eqasz}) and \\cite{gobeturk14}, equation~(14)) and the statistical\nerror bounds (compare the $\\frac{ K_{Z,k} }{M_k }$-terms in (\\ref\n{eqerr}) of Theorem~\\ref{thmMCerr} and the $\\frac{ K_{Z,k}\n}{\\Delta_k\nM_k }$-terms of \\cite{gobeturk14}, Theorem 4.11).\nThese error estimates {are} optimal with respect to the convergence\nrates (up to logarithmic factors)\nunder high generality regarding the distribution of the stochastic\nmodel for $X$ and $H$, even if the constants may be conservative. This\nis because the local regression errors are optimal under model-free\nestimates (Proposition~\\ref{propeqyzerrdecoM}).}\n\n{\nWith the error estimates of Theorem~\\ref{thmMCerr} in hand, we\nperform a complexity analysis in Section~\\ref{sectioncomplexity}. We\npropose a choice of basis functions and use it to calibrate the number\nof simulations in order to achieve a specified error level.\nThis then allows us to compute the complexity of the algorithm for that\nerror level.\nThe methodology for doing this is analogous to \\cite{gobeturk14}, Section~4.4, in that we use the same basis functions\n-- which also enable us to study the benefit of smoothness properties of\nthe underlying Markov functions $(y_i(\\cdot),z_i(\\cdot))$ --\nand also in that we set the ensure the global error level by\ncalibrating the local regression errors.\nHowever, the conclusion of this section is that MWLS yields better\nperformance in terms of complexity than LSMDP.\nThe main reason for this is the improved time-dependancy of the error\nestimates, which is a systemic improvement that allows one to make\ngenerate fewer simulations to obtain certain error levels.\nUnfortunately, the complexity reduction does not reduce the dependence\non the dimension compared to the LSMDP.\nThe curse of dimensionality still appears, and the rates depend on the\ndimension of the Markov chain $X$ (i.e., $d$).\nNevertheless, the reduction of complexity is substantial and, since one\nis able to make fewer simulations to obtain the same error level, will\nhelp alleviate the pressure on memory resources that is typical with\n{least-squares} Monte Carlo algorithms.}\n\nThis paper is theoretically oriented, and is aimed at paving the way\nfor new such numerical approaches {based on Malliavin calculus}. Future\nworks will be devoted to a deeper investigation about the numerical\nperformance of the MWLS algorithm compared to other known numerical schemes.\n\n\n\\subsection{Notation used throughout the paper}\\label{sectionnotation}\n\n\\begin{itemize}\n\n\\item${\\vert} x{\\vert}$ stands for the Euclidean norm of the\nvector $x$, {${ }^\\top\n$ denotes the transpose operator}.\n\n\\item${\\vert} U{\\vert}_{p}:=({\\mathbb{E}}[{\\vert} U{\\vert}\n^p])^{{1}/{p }}$ stands for the ${\\mathbf{L}}\n_p({\\mathbb{P}}\n)$-norm ($p\\geq1$) of a random variable $U$. The \\mbox{$\\mathcal{F}\n_{t_k}$-}conditional version is denoted by ${\\vert} U{\\vert}\n_{p,k}:=({\\mathbb{E}}\n_k[{\\vert} U{\\vert}^p])^{1/p}$.\nTo indicate that $U$ is additionally measurable w.r.t. the $\\sigma\n$-algebra $\\mathcal{Q}$, we may write $U\\in{\\mathbf{L}}_{ p}(\\mathcal{Q},{\\mathbb{P}})$.\n\n\\item For a multi-dimensional process $U=(U_i)_{0\\leq i\\leq N}$, its\n$l$th component is denoted by $U_l=(U_{l,i})_{0\\leq i\\leq N}$.\n\n\n\n\n\n\\item For any finite $L>0$ and $x = (x_1,\\ldots,x_n)\\in{\\mathbb{R}}^n$, define\nthe truncation function\n$\\mathcal{T}_L(x):= (-L\\vee x_1 \\wedge L,\\ldots, -L \\vee x_n \\wedge L)$.\n\n\\item For finite $x >0$, $\\log(x)$ is the natural logarithm of $x$.\n\n\n\n\n\\end{itemize}\n\n\n\\subsection{Assumptions}\\label{section4assumptions}\n\n\\subsubsection*{First set of hypotheses} The following assumptions hold\nthroughout the entirety of the paper.\nLet $R_\\pi>0$ be a fixed parameter: this constant determines which\ntime-grid can be used. The larger $R_\\pi$, the larger the class of\nadmissible time-grids. All subsequent error estimates depend on $R_\\pi$.\n\n\\begin{enumerate}[{$(\\mathbf{A_F})$}]\n\n\\item[{$(\\mathbf{A}_{\\bolds{\\xi}})$}] $\\xi$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T,{\\mathbb{P}})$.\n\n\\item[{$(\\mathbf{A_F})$}]\n\n\\begin{enumerate}[(iii)]\n\n\\item[(i)] $(\\omega,y,z)\\mapsto f_i(y,z)$ is $\\mathcal\n{F}_{t_i}\\otimes\n\\mathcal\n{B}({\\mathbb{R}}) \\otimes\\mathcal{B}(({\\mathbb{R}}^{q})^\\top)$-measurable for every\n{$i<N$}, and\nthere exist deterministic parameters ${\\theta_L}\\in(0,1]$ and $L_{f}\\in\n[0,+\\infty)$ such that\n\n\n", "itemtype": "equation", "pos": 4510, "prevtext": "\n\nwhere the processes $({H^{(t)}_{s}})_{0\\leq t < s \\leq T} $ are Malliavin\nweights defined by\n\n\n\n", "index": 5, "text": "\\begin{equation}\n{H^{(t)}_{s}}= \\frac{1}{s-t} \\biggl( \\int_t^s\n\\bigl(\\sigma^{-1}( r,X_r) D_tX_r\n\\bigr)^\\top \\,\\mathrm{d}W_r \\biggr)^\\top, \\qquad0 \\le t< s\n\\le T, \\label{eq4malweights}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"{H^{(t)}_{s}}=\\frac{1}{s-t}\\biggl{(}\\int_{t}^{s}\\bigl{(}\\sigma^{-1}(r,X_{r})D_%&#10;{t}X_{r}\\bigr{)}^{\\top}\\,\\mathrm{d}W_{r}\\biggr{)}^{\\top},\\qquad 0\\leq t&lt;s\\leq T,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>H</mi><mi>s</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>s</mi><mo>-</mo><mi>t</mi></mrow></mfrac><mo>\u2062</mo><msup><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>s</mi></msubsup><mrow><mpadded width=\"+1.7pt\"><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msup><mi>\u03c3</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo>,</mo><msub><mi>X</mi><mi>r</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>D</mi><mi>t</mi></msub><mo>\u2062</mo><msub><mi>X</mi><mi>r</mi></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u22a4</mo></msup></mpadded><mo>\u2062</mo><mrow><mo>d</mo><msub><mi>W</mi><mi>r</mi></msub></mrow></mrow></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow><mo>\u22a4</mo></msup></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mn>0</mn><mo>\u2264</mo><mi>t</mi><mo>&lt;</mo><mi>s</mi><mo>\u2264</mo><mi>T</mi></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor any $(y,y',z,z')\\in{\\mathbb{R}}\\times{\\mathbb{R}}\\times({\\mathbb{R}}^q)^\\top\\times({\\mathbb{R}}\n^q)^\\top$.\n\n\\item[(ii)] There exist deterministic parameters ${\\theta_c}\\in(0,1]$ and\n$C_{f}\\in[0,+\\infty)$ such that\n\n\n", "itemtype": "equation", "pos": 14726, "prevtext": "\n\nfor $(D_tX_r)_t$ being the Malliavin derivative of $X_r$ and $\\sigma\n(\\cdot)$ is the diffusion coefficient of $X$. The representation\n(\\ref{eq4Z}) is obtained via a Malliavin calculus integration by parts\nformula, see \\cite{nual95} for a general account on the subject.\nA discretization procedure to approximate the FBSDE \\mbox{(\\ref{eqBSDEcts})--(\\ref{eq4Z})} with (\\ref{eqmalscheme}),\nincluding explicit definitions of the random variables ${H^{(i)}_{j}}$ based\non~(\\ref{eq4malweights}),\nis given in \\cite{turk13,turk13b}, where the author also\ncomputes the discretization error in terms of $N$.\nIn honour of the connection between (\\ref{eqmalscheme}) and (\\ref\n{eqBSDEcts})--(\\ref{eq4Z}), we call the random variables ${H^{(i)}_{j}}$\nMalliavin weights, $\\xi$ the terminal condition, and $(i,\\omega,y,z)\n\\mapsto f_i(y,z)$ the driver.\nWe say that the pair $(Y,Z)$ satisfying (\\ref{eqmalscheme}) solves a\nMWDP with\n{terminal condition $\\xi$ and driver $f_i(y,z)$.}\n\n\n\n\n\\subsection{Contributions}\nIn this paper, we are not concerned with the discretization procedure,\nbut rather with the analysis of the MWDP equation (\\ref{eqmalscheme})\nitself and\nits numerical resolution via the MWLS algorithm, in which one uses\nempirical least-squares regressions (approximations on finite basis of\nfunctions using simulations) to compute conditional expectations.\n\nSince the system (\\ref{eqmalscheme}) may be relevant to problems\nbeyond the FBSDE system (\\ref{eqBSDEcts})--(\\ref{eq4Z}), we allow the\nframework and assumptions to\naccomodate as much generality as possible. However, MWLS is, to the\nbest of our knowledge, the first direct implementation of formula\n(\\ref{eq4Z}) in a fully implementable numerical scheme.\nFor other applications of Malliavin calculus in numerical simulations,\nwith different perspectives and results to ours, see, for instance, \\cite\n{fourlion99,kohapett02,bouctouz04,gobemuno05,ballcarazane05,hunualsong11,brialaba13}.\n\nWe adapt the recent theoretical analysis of the\nLeast Squares Multi-step forward Dynamical Programming algorithm (LSMDP) of \\cite\n{gobeturk14} for discrete BSDEs (without Malliavin weights) to the\nsetting of MWDP.\nAs in the aforementioned reference, we consider a locally Lipschitz\ndriver $f_i(y,z)$ that is locally bounded at $(y,z) = (0,0)$ -- see\nSection~\\ref{section4assumptions}.\nThis allows the algorithm of the current paper to be applied for the\napproximation of some quadratic BSDEs and for some proxy/variance\nreduction methods.\nFor more details on these applications, see \\cite{gobeturk14}, Section~2.2.\nMoreover, we make use of analogous stability results and conditioning\narguments in the proof of the main result, Theorem~\\ref{thmMCerr}, as\nin the proof of \\cite{gobeturk14}, Theorem 4.11.\n{However, the Malliavin weights lead to significantly differences in\nthe main theorem and stability results, both in the technical elements\nof the proofs and the results. We develop {seemingly} novel Gronwall\ntype inequalities to handle the technical differences; these results\nare outlined in Section~\\ref{sectiongronwall} and proved in\nAppendix~\\ref{appendixprooflemintegrals}.\nFurthermore, the stability results are more powerful and the complexity\nof the MWLS is better than the LSMDP, as will be discussed in what follows.\n}\n\n{We would like to mention that the class of quadratic problems we can\ntreat with these assumptions is quite different to the recent \\cite\n{chasrich13}.\nHere we are treating the {non-degenerate} setting where the terminal\ncondition may be H\\\"older continuous, whereas the other reference\nallows degeneracy at the expense of requiring locally Lipschitz\nterminal conditions.\n}\n\nWe prove stability results on the MWDP in Section~\\ref{sectionstability}.\n{Much effort is made to keep the constants explicit.}\nThese results are instrumental throughout the paper. The stability\nestimates on $Z$ are at the individual time points (coherently with the\nrepresentation theorem of \\cite{mazhan02})\nrather than the time-averaged estimates of \\cite{gobeturk14}, Proposition~3.2.\nThis allows for finer and more precise computations.\nThe time-dependency in our estimates also takes better into account the\nregularity of the terminal condition, similarly to the continuous-time\ncase \\cite{delaguat06}.\n\nSection~\\ref{section4MC} is the core of the paper: it is dedicated to\nthe MWLS algorithm in the Markovian context $Y_i=y_i(X_i)$ and\n$Z_i=z_i(X_i)$ for some Markov chain $X_i$ in ${\\mathbb{R}}^d$ and unknown\nfunctions $(y_i(\\cdot),z_i(\\cdot))$. In MWLS, the conditional\nexpectations in (\\ref{eqmalscheme})\nare replaced by Monte Carlo least-squares regressions. For each point\nof the time-grid, we use a cloud of independent paths of the {Markov\nchain} $X$ and the Malliavin weights $H$, and some approximation spaces\nfor representing the value functions $(y_i(\\cdot),z_i(\\cdot))$. The\nalgorithm is detailed in Section~\\ref{sectionMCalg}, and a full\nerror analysis\nin terms of the number of simulations and the approximation spaces\nis performed in Sections~\\ref{sectionerr} and~\\ref\n{sectionproofmainthm}. The final error estimates (Theorem~\\ref\n{thmMCerr}) are similar to \\cite{gobeturk14}, Theorem 4.11, in that\nthey are the time-averaged {local} regression errors of\nthe discrete BSDE, but the results are in a stronger norm and the\ntime-dependency is better. {The constants are completely explicit.}\n{Although the norms are stronger than in \\cite{gobeturk14}, the\nestimates do not deteriorate; instead, they are {significantly}\nimproved. This is intrinsically due to the MWDP representation, which\navoids the usual \\mbox{$1/\\Delta_i$-}factor in front of all controls on $Z$.\nThis improvement can be tracked by inspecting the a.s. bounds (compare\n(\\ref{eqasz}) and \\cite{gobeturk14}, equation~(14)) and the statistical\nerror bounds (compare the $\\frac{ K_{Z,k} }{M_k }$-terms in (\\ref\n{eqerr}) of Theorem~\\ref{thmMCerr} and the $\\frac{ K_{Z,k}\n}{\\Delta_k\nM_k }$-terms of \\cite{gobeturk14}, Theorem 4.11).\nThese error estimates {are} optimal with respect to the convergence\nrates (up to logarithmic factors)\nunder high generality regarding the distribution of the stochastic\nmodel for $X$ and $H$, even if the constants may be conservative. This\nis because the local regression errors are optimal under model-free\nestimates (Proposition~\\ref{propeqyzerrdecoM}).}\n\n{\nWith the error estimates of Theorem~\\ref{thmMCerr} in hand, we\nperform a complexity analysis in Section~\\ref{sectioncomplexity}. We\npropose a choice of basis functions and use it to calibrate the number\nof simulations in order to achieve a specified error level.\nThis then allows us to compute the complexity of the algorithm for that\nerror level.\nThe methodology for doing this is analogous to \\cite{gobeturk14}, Section~4.4, in that we use the same basis functions\n-- which also enable us to study the benefit of smoothness properties of\nthe underlying Markov functions $(y_i(\\cdot),z_i(\\cdot))$ --\nand also in that we set the ensure the global error level by\ncalibrating the local regression errors.\nHowever, the conclusion of this section is that MWLS yields better\nperformance in terms of complexity than LSMDP.\nThe main reason for this is the improved time-dependancy of the error\nestimates, which is a systemic improvement that allows one to make\ngenerate fewer simulations to obtain certain error levels.\nUnfortunately, the complexity reduction does not reduce the dependence\non the dimension compared to the LSMDP.\nThe curse of dimensionality still appears, and the rates depend on the\ndimension of the Markov chain $X$ (i.e., $d$).\nNevertheless, the reduction of complexity is substantial and, since one\nis able to make fewer simulations to obtain the same error level, will\nhelp alleviate the pressure on memory resources that is typical with\n{least-squares} Monte Carlo algorithms.}\n\nThis paper is theoretically oriented, and is aimed at paving the way\nfor new such numerical approaches {based on Malliavin calculus}. Future\nworks will be devoted to a deeper investigation about the numerical\nperformance of the MWLS algorithm compared to other known numerical schemes.\n\n\n\\subsection{Notation used throughout the paper}\\label{sectionnotation}\n\n\\begin{itemize}\n\n\\item${\\vert} x{\\vert}$ stands for the Euclidean norm of the\nvector $x$, {${ }^\\top\n$ denotes the transpose operator}.\n\n\\item${\\vert} U{\\vert}_{p}:=({\\mathbb{E}}[{\\vert} U{\\vert}\n^p])^{{1}/{p }}$ stands for the ${\\mathbf{L}}\n_p({\\mathbb{P}}\n)$-norm ($p\\geq1$) of a random variable $U$. The \\mbox{$\\mathcal{F}\n_{t_k}$-}conditional version is denoted by ${\\vert} U{\\vert}\n_{p,k}:=({\\mathbb{E}}\n_k[{\\vert} U{\\vert}^p])^{1/p}$.\nTo indicate that $U$ is additionally measurable w.r.t. the $\\sigma\n$-algebra $\\mathcal{Q}$, we may write $U\\in{\\mathbf{L}}_{ p}(\\mathcal{Q},{\\mathbb{P}})$.\n\n\\item For a multi-dimensional process $U=(U_i)_{0\\leq i\\leq N}$, its\n$l$th component is denoted by $U_l=(U_{l,i})_{0\\leq i\\leq N}$.\n\n\n\n\n\n\\item For any finite $L>0$ and $x = (x_1,\\ldots,x_n)\\in{\\mathbb{R}}^n$, define\nthe truncation function\n$\\mathcal{T}_L(x):= (-L\\vee x_1 \\wedge L,\\ldots, -L \\vee x_n \\wedge L)$.\n\n\\item For finite $x >0$, $\\log(x)$ is the natural logarithm of $x$.\n\n\n\n\n\\end{itemize}\n\n\n\\subsection{Assumptions}\\label{section4assumptions}\n\n\\subsubsection*{First set of hypotheses} The following assumptions hold\nthroughout the entirety of the paper.\nLet $R_\\pi>0$ be a fixed parameter: this constant determines which\ntime-grid can be used. The larger $R_\\pi$, the larger the class of\nadmissible time-grids. All subsequent error estimates depend on $R_\\pi$.\n\n\\begin{enumerate}[{$(\\mathbf{A_F})$}]\n\n\\item[{$(\\mathbf{A}_{\\bolds{\\xi}})$}] $\\xi$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T,{\\mathbb{P}})$.\n\n\\item[{$(\\mathbf{A_F})$}]\n\n\\begin{enumerate}[(iii)]\n\n\\item[(i)] $(\\omega,y,z)\\mapsto f_i(y,z)$ is $\\mathcal\n{F}_{t_i}\\otimes\n\\mathcal\n{B}({\\mathbb{R}}) \\otimes\\mathcal{B}(({\\mathbb{R}}^{q})^\\top)$-measurable for every\n{$i<N$}, and\nthere exist deterministic parameters ${\\theta_L}\\in(0,1]$ and $L_{f}\\in\n[0,+\\infty)$ such that\n\n\n", "index": 7, "text": "\n\\[\n\n\\bigl{\\vert} f_i(y,z)-f_i\n\\bigl(y',z'\\bigr)\\bigr{\\vert}\\leq\\frac{ L_f\n}{(T-t_i)^{(1-{\\theta_L}\n)/2}}\n\\bigl(\\bigl{\\vert} y-y'\\bigr{\\vert}+\\bigl{\\vert} z-z'\n\\bigr{\\vert}\\bigr),\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\bigl{|}f_{i}(y,z)-f_{i}\\bigl{(}y^{\\prime},z^{\\prime}\\bigr{)}\\bigr{|}\\leq%&#10;\\frac{L_{f}}{(T-t_{i})^{(1-{\\theta_{L}})/2}}\\bigl{(}\\bigl{|}y-y^{\\prime}\\bigr{%&#10;|}+\\bigl{|}z-z^{\\prime}\\bigr{|}\\bigr{)},\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>y</mi><mo>\u2032</mo></msup><mo>,</mo><msup><mi>z</mi><mo>\u2032</mo></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mo>\u2264</mo><mrow><mfrac><msub><mi>L</mi><mi>f</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b8</mi><mi>L</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mi>y</mi><mo>-</mo><msup><mi>y</mi><mo>\u2032</mo></msup></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mo>+</mo><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mi>z</mi><mo>-</mo><msup><mi>z</mi><mo>\u2032</mo></msup></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\item[(iii)] The time-grid $\\pi:= \\{0=t_0 < \\cdots< t_N = T \\}$ satisfies\n\n", "itemtype": "equation", "pos": 15129, "prevtext": "\n\nfor any $(y,y',z,z')\\in{\\mathbb{R}}\\times{\\mathbb{R}}\\times({\\mathbb{R}}^q)^\\top\\times({\\mathbb{R}}\n^q)^\\top$.\n\n\\item[(ii)] There exist deterministic parameters ${\\theta_c}\\in(0,1]$ and\n$C_{f}\\in[0,+\\infty)$ such that\n\n\n", "index": 9, "text": "\n\\[\n\n\\bigl{\\vert} f_i(0,0)\\bigr{\\vert}\\leq\n\\frac{ C_f }{(T-t_i)^{1-{\\theta_c}\n}}, \\qquad\\forall0 \\le i < N.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\bigl{|}f_{i}(0,0)\\bigr{|}\\leq\\frac{C_{f}}{(T-t_{i})^{1-{\\theta_{c}}}},%&#10;\\qquad\\forall 0\\leq i&lt;N.\" display=\"block\"><mrow><mrow><mrow><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mo>\u2264</mo><mfrac><msub><mi>C</mi><mi>f</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b8</mi><mi>c</mi></msub></mrow></msup></mfrac></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><mo>\u2200</mo><mn>0</mn></mrow><mo>\u2264</mo><mi>i</mi><mo>&lt;</mo><mi>N</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\end{enumerate}\n\n\\item[{$(\\mathbf{A_H})$}] For all $0\\le i <j \\le N$, the Malliavin weights satisfy\n\n\n\n", "itemtype": "equation", "pos": 15315, "prevtext": "\n\n\\item[(iii)] The time-grid $\\pi:= \\{0=t_0 < \\cdots< t_N = T \\}$ satisfies\n\n", "index": 11, "text": "\n\\[\n\\max_{0\\le i\\le N-2}\\frac{\\Delta_{i+1}}{\\Delta_{i}} \\le R_\\pi.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\max_{0\\leq i\\leq N-2}\\frac{\\Delta_{i+1}}{\\Delta_{i}}\\leq R_{\\pi}.\" display=\"block\"><mrow><mrow><mrow><munder><mi>max</mi><mrow><mn>0</mn><mo>\u2264</mo><mi>i</mi><mo>\u2264</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow></mrow></munder><mo>\u2061</mo><mfrac><msub><mi mathvariant=\"normal\">\u0394</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mfrac></mrow><mo>\u2264</mo><msub><mi>R</mi><mi>\u03c0</mi></msub></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor a finite constant $C_{M}\\geq0$.\n\\end{enumerate}\n\n\\textit{Comments.} We remark that assumptions {$(\\mathbf{A}_{\\bolds{\\xi}})$}~and {$(\\mathbf{A_F})$\\textup{(i)--(ii)}}~are the\nsame as their equivalents in \\cite{gobeturk14}, Section~2. The usual\ncase of ``Lipschitz'' BSDE is covered by ${\\theta_L}={\\theta_c}=1$. As\nexplained in \\cite{gobeturk14}, the case of locally Lipschitz driver\n(${\\theta_L}<1$ and/or ${\\theta_c}<1$) is interesting because it allows a\nlarge variety of applications, such as solving BSDEs using proxy\nmethods or variance reduction methods, and solving quadratic BSDEs. We\nrefer the reader to \\cite{gobeturk14}, Section~2.2, for details.\n\nAssumption {$(\\mathbf{A_F})$\\textup{(iii)}}~is much simpler compared to \\cite{gobeturk14}. If\n$R_\\pi\\geq1$, {$(\\mathbf{A_F})$\\textup{(iii)}}~is satisfied by any time grid with non-increasing\ntime-step, such as the grids of \\cite\n{gobemakh10,rich11,geisgeisgobe12}. This may be valuable for\nfuture work on time-grid optimization.\n\nAssumption {$(\\mathbf{A_H})$}~is specific to the dynamic programming equation with\nMalliavin weights. It is satisfied for the weights derived in \\cite\n{mazhan02}, and this can remain true after discretization (see \\cite\n{turk13} or \\cite{gobemuno05}).\n{\nIt is also satisfied if $X$ takes the form $X_t=g(t,W_t)$ (like\nmulti-dimensional geometric Brownian motion), by a simple change of\nvariables one can use the Malliavin weights ${H^{(t)}_{s}}= \\frac\n{(W_s-W_t)^\\top}{s-t}$ (note the process $X$ may be degenerate).}\n\n\n\\subsubsection*{Second set of hypotheses: Markovian assumptions} The\nfollowing assumptions will mostly be used in Section~\\ref{section4MC}.\n{$(\\mathbf{A_X})$}, {$(\\mathbf{A'_F})$}, and {$(\\mathbf{A'_H})$}~give us a Markov representation for solutions\nof the discrete BSDEs (see\\vspace*{1pt} equation (\\ref{eqmarkov}) later). {$(\\mathbf{A'_{\\bolds{\\xi}}})$}~is\n{used} for obtaining (model free) estimates on regression errors. We\nalso include additional optional assumptions, {$(\\mathbf{A''_{\\bolds{\\xi}}})$}, on the terminal\ncondition to obtain tighter estimates on $Z_i$ (see Corollary~\\ref\n{coras} and subsequent remarks).\n\n\\begin{enumerate}[{$(\\mathbf{A_X})$}]\n\n\\item[{$(\\mathbf{A_X})$}] $X$ is a Markov chain in ${\\mathbb{R}}^d$ $(1 \\le d < +\\infty)$\nadapted to $(\\mathcal{F}_{t_i})_i$.\nFor every $i<N$ and $j>i$, there exist $\\mathcal{G}_{i}\\otimes\n\\mathcal{B}({\\mathbb{R}}\n^d)$-measurable functions ${ V^{(i)}_{j} }\\dvtx  \\Omega\\times{\\mathbb{R}}^d\n\\rightarrow\n{\\mathbb{R}}^d$\nwhere $\\mathcal{G}_{i} \\subset\\mathcal{F}_T$ is independent of\n$\\mathcal{F}_{t_i}$, such that\n$X_{j} = { V^{({i})}_{{j}} } (X_{i})$.\n\n\\item[{$(\\mathbf{A'_{\\bolds{\\xi}}})$}]\n\n\\begin{enumerate}[(ii)]\n\n\\item[(i)] $\\xi$ is a bounded $\\mathcal{F}_T$-measurable random variable:\n$C_\\xi:={\\mathbb{P}}-\\operatorname{ess}\\sup_{\\omega}{\\vert}\\xi(\\omega){\\vert}\n<+\\infty$.\n\n\\item[(ii)] $\\xi$ is of form $\\xi:=\\Phi(X_N)$ for a {bounded},\nmeasurable function $\\Phi$.\n\\end{enumerate}\n\n\\item[{$(\\mathbf{A''_{\\bolds{\\xi}}})$}] In addition to {$(\\mathbf{A'_{\\bolds{\\xi}}})$}, for some ${\\theta_\\Phi}\\in[0,1]$\n\n\nand a finite constant $C_\\Phi\\geq0$,\nwe have ${\\vert}\\xi-{\\mathbb{E}}_i\\xi{\\vert}_{2,i}\\leq C_\\Phi\n(T-t_i)^{{\\theta_\\Phi}/2}$ for any\n$i\\in\\{0,\\ldots,N\\}$.\n\n\\item[{$(\\mathbf{A'_F})$}] For every $i<N$, the driver is of the form $f_i(\\omega\n,y,z)=f_i(X_i(\\omega),y,z)$, and\n$(x,y,z)\\mapsto f_i(x,y,z)$ is $\\mathcal{B}({\\mathbb{R}}^d)\\otimes\\mathcal\n{B}({\\mathbb{R}}) \\otimes\n\\mathcal{B}\n(({\\mathbb{R}}^{q})^\\top)$-measurable and {$(\\mathbf{A_F})$}~is satisfied.\n\n\\item[{$(\\mathbf{A'_H})$}] In addition to {$(\\mathbf{A_H})$}, for every $i<N$ and $j>i$,\nthere is a function ${ \\mathpzc{h}^{({i})}_{{j}} }\\dvtx  \\Omega\\times{\\mathbb{R}}^d \\rightarrow\n({\\mathbb{R}}^{q})^\\top$ that is $\\mathcal{G}_{i}\\otimes\\mathcal{B}({\\mathbb{R}}\n^d)$-measurable, where\n$\\mathcal{G}_{i} \\subset\\mathcal{F}_T$ is independent of $\\mathcal\n{F}_{t_i}$,\nsuch that $H^{(i)}_{j}: = { \\mathpzc{h}^{(i)}_{{j}} }(X_{i})$.\n\\end{enumerate}\n\n\\emph{Comments.} {$(\\mathbf{A_X})$}~is usually satisfied when $X$ is the solution of\nSDE or its Euler scheme built on the time-grid $\\pi$.\n\nThe statement of {$(\\mathbf{A''_{\\bolds{\\xi}}})$}~is inspired by the fractional smoothness\ncondition of \\cite{gobemakh10}, although somewhat stronger.\n\nIt is satisfied,\nfor instance, if the terminal function $\\Phi$ is ${\\theta_\\Phi}$-H\\\"older\ncontinuous and if the Markov chain satisfies $\\mathbb{E}_i[{\\vert}\nX_N -\nX_i{\\vert}^2] \\le\nC_X (T-t_i)$. This is {a reasonable} assumption on the Markov chain,\nsince it is satisfied by a diffusion process (possibly including\nbounded jumps) with bounded coefficients and also by its Euler approximation.\n\nIndeed, we have\n\n\n\n", "itemtype": "equation", "pos": 15488, "prevtext": "\n\n\\end{enumerate}\n\n\\item[{$(\\mathbf{A_H})$}] For all $0\\le i <j \\le N$, the Malliavin weights satisfy\n\n\n\n", "index": 13, "text": "\n\\[\n\\mathbb{E}\\bigl[{H^{(i)}_{j}}\\mid\\mathcal{F}_{t_i}\\bigr] = 0, \\qquad\n\n\n\n\n\\bigl(\\mathbb{E}\\bigl[\\bigl{\\vert}{H^{(i)}_{j}}\\bigr{\\vert}^2\\mid\n\\mathcal{F}_{t_i}\\bigr] \\bigr)^{1/2}\\le\\frac{C_{M}\n}{(t_j-t_i)^{1/2}}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}\\bigl{[}{H^{(i)}_{j}}\\mid\\mathcal{F}_{t_{i}}\\bigr{]}=0,\\qquad\\par&#10;%&#10;\\par&#10;\\par&#10;\\par&#10;\\bigl{(}\\mathbb{E}\\bigl{[}\\bigl{|}{H^{(i)}_{j}}\\bigr{|}^{2}\\mid%&#10;\\mathcal{F}_{t_{i}}\\bigr{]}\\bigr{)}^{1/2}\\leq\\frac{C_{M}}{(t_{j}-t_{i})^{1/2}}\" display=\"block\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mi>H</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2223</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo>=</mo><mn>0</mn><mo rspace=\"22.5pt\">,</mo><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><msubsup><mi>H</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo>\u2223</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><msub><mi>t</mi><mi>i</mi></msub></msub><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>\u2264</mo><mfrac><msub><mi>C</mi><mi>M</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>-</mo><msub><mi>t</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n{$(\\mathbf{A'_H})$}~is satisfied by the Malliavin weights (\\ref\n{eq4malweights}) under various \nconditions. It is valid for the example $X_t=g(t,W_t)$ mentioned before.\n\n\n\n\nConsider now the more complex case of the SDE with (deterministic)\ncoefficients $b(t,x)$ for the drift and $(\\sigma_1(t,x),\\ldots,\\sigma\n_d(t,x))$ for the diffusion ($q=d$) both having first space-derivatives\nthat are uniformly bounded.\nRecall the relation for the Malliavin derivative of a SDE given by\n\n\\begin{eqnarray*}\nD_tX_r= \\nabla X_r \\nabla\nX_t^{-1} \\sigma(t,X_t){\\mathbf{1}}_{t \\le r}=\n\\nabla_x X^{t,x}_r\\mid_{x=X_t}\n\\sigma(t,X_t){\\mathbf{1}}_{t \\le r},\n\\end{eqnarray*}\n\nwhere $X^{t,x}$ denotes the SDE solution starting from $x$ at time $t$,\nand $\\nabla X_t:=\\nabla_x X_t^{0,x}$ for $\\nabla_x X_t^{0,x}$ solving\nthe $(d \\times d)$-dimensional, matrix valued linear SDE\n\n", "itemtype": "equation", "pos": 20410, "prevtext": "\n\nfor a finite constant $C_{M}\\geq0$.\n\\end{enumerate}\n\n\\textit{Comments.} We remark that assumptions {$(\\mathbf{A}_{\\bolds{\\xi}})$}~and {$(\\mathbf{A_F})$\\textup{(i)--(ii)}}~are the\nsame as their equivalents in \\cite{gobeturk14}, Section~2. The usual\ncase of ``Lipschitz'' BSDE is covered by ${\\theta_L}={\\theta_c}=1$. As\nexplained in \\cite{gobeturk14}, the case of locally Lipschitz driver\n(${\\theta_L}<1$ and/or ${\\theta_c}<1$) is interesting because it allows a\nlarge variety of applications, such as solving BSDEs using proxy\nmethods or variance reduction methods, and solving quadratic BSDEs. We\nrefer the reader to \\cite{gobeturk14}, Section~2.2, for details.\n\nAssumption {$(\\mathbf{A_F})$\\textup{(iii)}}~is much simpler compared to \\cite{gobeturk14}. If\n$R_\\pi\\geq1$, {$(\\mathbf{A_F})$\\textup{(iii)}}~is satisfied by any time grid with non-increasing\ntime-step, such as the grids of \\cite\n{gobemakh10,rich11,geisgeisgobe12}. This may be valuable for\nfuture work on time-grid optimization.\n\nAssumption {$(\\mathbf{A_H})$}~is specific to the dynamic programming equation with\nMalliavin weights. It is satisfied for the weights derived in \\cite\n{mazhan02}, and this can remain true after discretization (see \\cite\n{turk13} or \\cite{gobemuno05}).\n{\nIt is also satisfied if $X$ takes the form $X_t=g(t,W_t)$ (like\nmulti-dimensional geometric Brownian motion), by a simple change of\nvariables one can use the Malliavin weights ${H^{(t)}_{s}}= \\frac\n{(W_s-W_t)^\\top}{s-t}$ (note the process $X$ may be degenerate).}\n\n\n\\subsubsection*{Second set of hypotheses: Markovian assumptions} The\nfollowing assumptions will mostly be used in Section~\\ref{section4MC}.\n{$(\\mathbf{A_X})$}, {$(\\mathbf{A'_F})$}, and {$(\\mathbf{A'_H})$}~give us a Markov representation for solutions\nof the discrete BSDEs (see\\vspace*{1pt} equation (\\ref{eqmarkov}) later). {$(\\mathbf{A'_{\\bolds{\\xi}}})$}~is\n{used} for obtaining (model free) estimates on regression errors. We\nalso include additional optional assumptions, {$(\\mathbf{A''_{\\bolds{\\xi}}})$}, on the terminal\ncondition to obtain tighter estimates on $Z_i$ (see Corollary~\\ref\n{coras} and subsequent remarks).\n\n\\begin{enumerate}[{$(\\mathbf{A_X})$}]\n\n\\item[{$(\\mathbf{A_X})$}] $X$ is a Markov chain in ${\\mathbb{R}}^d$ $(1 \\le d < +\\infty)$\nadapted to $(\\mathcal{F}_{t_i})_i$.\nFor every $i<N$ and $j>i$, there exist $\\mathcal{G}_{i}\\otimes\n\\mathcal{B}({\\mathbb{R}}\n^d)$-measurable functions ${ V^{(i)}_{j} }\\dvtx  \\Omega\\times{\\mathbb{R}}^d\n\\rightarrow\n{\\mathbb{R}}^d$\nwhere $\\mathcal{G}_{i} \\subset\\mathcal{F}_T$ is independent of\n$\\mathcal{F}_{t_i}$, such that\n$X_{j} = { V^{({i})}_{{j}} } (X_{i})$.\n\n\\item[{$(\\mathbf{A'_{\\bolds{\\xi}}})$}]\n\n\\begin{enumerate}[(ii)]\n\n\\item[(i)] $\\xi$ is a bounded $\\mathcal{F}_T$-measurable random variable:\n$C_\\xi:={\\mathbb{P}}-\\operatorname{ess}\\sup_{\\omega}{\\vert}\\xi(\\omega){\\vert}\n<+\\infty$.\n\n\\item[(ii)] $\\xi$ is of form $\\xi:=\\Phi(X_N)$ for a {bounded},\nmeasurable function $\\Phi$.\n\\end{enumerate}\n\n\\item[{$(\\mathbf{A''_{\\bolds{\\xi}}})$}] In addition to {$(\\mathbf{A'_{\\bolds{\\xi}}})$}, for some ${\\theta_\\Phi}\\in[0,1]$\n\n\nand a finite constant $C_\\Phi\\geq0$,\nwe have ${\\vert}\\xi-{\\mathbb{E}}_i\\xi{\\vert}_{2,i}\\leq C_\\Phi\n(T-t_i)^{{\\theta_\\Phi}/2}$ for any\n$i\\in\\{0,\\ldots,N\\}$.\n\n\\item[{$(\\mathbf{A'_F})$}] For every $i<N$, the driver is of the form $f_i(\\omega\n,y,z)=f_i(X_i(\\omega),y,z)$, and\n$(x,y,z)\\mapsto f_i(x,y,z)$ is $\\mathcal{B}({\\mathbb{R}}^d)\\otimes\\mathcal\n{B}({\\mathbb{R}}) \\otimes\n\\mathcal{B}\n(({\\mathbb{R}}^{q})^\\top)$-measurable and {$(\\mathbf{A_F})$}~is satisfied.\n\n\\item[{$(\\mathbf{A'_H})$}] In addition to {$(\\mathbf{A_H})$}, for every $i<N$ and $j>i$,\nthere is a function ${ \\mathpzc{h}^{({i})}_{{j}} }\\dvtx  \\Omega\\times{\\mathbb{R}}^d \\rightarrow\n({\\mathbb{R}}^{q})^\\top$ that is $\\mathcal{G}_{i}\\otimes\\mathcal{B}({\\mathbb{R}}\n^d)$-measurable, where\n$\\mathcal{G}_{i} \\subset\\mathcal{F}_T$ is independent of $\\mathcal\n{F}_{t_i}$,\nsuch that $H^{(i)}_{j}: = { \\mathpzc{h}^{(i)}_{{j}} }(X_{i})$.\n\\end{enumerate}\n\n\\emph{Comments.} {$(\\mathbf{A_X})$}~is usually satisfied when $X$ is the solution of\nSDE or its Euler scheme built on the time-grid $\\pi$.\n\nThe statement of {$(\\mathbf{A''_{\\bolds{\\xi}}})$}~is inspired by the fractional smoothness\ncondition of \\cite{gobemakh10}, although somewhat stronger.\n\nIt is satisfied,\nfor instance, if the terminal function $\\Phi$ is ${\\theta_\\Phi}$-H\\\"older\ncontinuous and if the Markov chain satisfies $\\mathbb{E}_i[{\\vert}\nX_N -\nX_i{\\vert}^2] \\le\nC_X (T-t_i)$. This is {a reasonable} assumption on the Markov chain,\nsince it is satisfied by a diffusion process (possibly including\nbounded jumps) with bounded coefficients and also by its Euler approximation.\n\nIndeed, we have\n\n\n\n", "index": 15, "text": "\\begin{equation}\n\\nonumber\n\n{\\vert}\\xi- \\mathbb{E}_i\\xi{\\vert}\n_{2,i}\\leq\\bigl{\\vert}\\Phi(X_N) - \\Phi(X_i)\n\\bigr{\\vert}_{2,i}\\leq C_\\Phi\\bigl(C_X\n(T-t_i)\\bigr)^{{ {\\theta_\\Phi}}/{2 }}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{|}\\xi-\\mathbb{E}_{i}\\xi{|}_{2,i}\\leq\\bigl{|}\\Phi(X_{N})-\\Phi(X_{i})\\bigr%&#10;{|}_{2,i}\\leq C_{\\Phi}\\bigl{(}C_{X}(T-t_{i})\\bigr{)}^{{{\\theta_{\\Phi}}}/{2}}.\" display=\"block\"><mrow><mo stretchy=\"false\">|</mo><mi>\u03be</mi><mo>-</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><msub><mi>E</mi><mi>i</mi></msub><mi>\u03be</mi><msub><mo stretchy=\"false\">|</mo><mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2264</mo><msub><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mi mathvariant=\"normal\">\u03a6</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>N</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mi mathvariant=\"normal\">\u03a6</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mrow><mn>2</mn><mo>,</mo><mi>i</mi></mrow></msub><mo>\u2264</mo><msub><mi>C</mi><mi mathvariant=\"normal\">\u03a6</mi></msub><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msub><mi>C</mi><mi>X</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><msub><mi>\u03b8</mi><mi mathvariant=\"normal\">\u03a6</mi></msub><mo>/</mo><mn>2</mn></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nThen, it is an easy exercise to prove that if $\\sigma$ and its inverse\nare uniformly bounded, then {$(\\mathbf{A'_H})$}~is fulfilled.\n\n\n\n\n\n\n\\section{Stability}\\label{sectionstability}\n\n\n\\subsection{Gronwall type inequalities}\\label{sectiongronwall}\nHere we gather deterministic inequalities frequently used throughout\nthe paper.\n{These inequalities are crucial due to novel technical problems caused\nby the Malliavin weights. }\nThey show how linear inequalities with singular coefficients propagate.\nThey take the form of unusual Gronwall type inequalities.\nTheir proofs are postponed to Appendix~\\ref{appendixprooflemintegrals}.\nWe assume that $\\pi$ is in the class of time-grids satisfying {$(\\mathbf{A_F})$\\textup{(iii)}}.\n\n\\begin{lemma}\n\\label{lemintegrals}\nLet\n\n\n{$\\alpha,\\beta>0 $ be finite. }\n\nThere exists a finite constant ${B_{{\\alpha},{\\beta}}}\\geq0$ depending\nonly on $R_{\\pi}$, $\\alpha$ and $\\beta$ (but not on the time-grid)\nsuch that,\nfor any $0\\le i < k \\le N$,\n\n\\begin{eqnarray*}\n\\sum_{j=i}^{k-1}{\\Delta_j \\over(t_{k} - t_{j})^{1 - \\alpha} }\n&\\le&{B_{{\\alpha},{1}}}(t_{k} - t_{i})^{\\alpha},\n\\\\\n\\sum_{j=i+1}^{k-1}{\\Delta_{j} \\over(t_{k} - t_{j})^{1 -\n\\alpha\n}(t_{j} - t_{i})^{1 - \\beta} }\n&\\le&{B_{{\\alpha},{\\beta}}}(t_{k} - t_{i})^{\\alpha+ \\beta-1}.\n\\end{eqnarray*}\n\n\\end{lemma}\n\n\\begin{lemma}[(Exponent improvement in recursive equations)]\n\\label{lemiterationgen1}\nLet $\\alpha\\geq0, \\beta\\in(0,\\frac{ 1 }{2 }]$ and $k\\in\\{\n0,\\ldots,N-1\\}$.\nSuppose that, for a {finite} constant $C_{u}\\geq0$, the finite\n{non-negative} real-valued sequences $\\{u_l\\}_{l \\ge k}$\nand $\\{w_l\\}_{l\\ge k}$ satisfy\n\n\n\\begin{eqnarray}\nu_j \\le w_j +C_{u}\\sum\n_{l=j+1}^{N-1} \\frac{u_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}},\n\\qquad k\\leq j \\leq\nN. \\label{eqiterationfeed}\n\\end{eqnarray}\n\nThen, for two {finite} constants {${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\geq0$ and ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\geq0$} that\ndepend only on $C_{u}, T, \\alpha, \\beta$ and $R_\\pi$,\n\n\n\\begin{eqnarray}\\label{eqiterationfeed2}\nu_j &\\le& {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} w_j + {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{} +{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum\n_{l=j+1}^{N-1} \\frac{u_l \\Delta_l}{(T-t_l)^{{{1}/2 -\n\\beta\n}}}, \\qquad k\\leq j \\leq\nN.\n\\end{eqnarray}\n\n\n\n\n\\end{lemma}\n\n\\begin{lemma}[(Intermediate a priori estimates)]\\label{lemiterationgen2}\nLet $\\alpha\\geq0, \\beta\\in(0,\\frac{ 1 }{2 }]$ and $k\\in\\{0,\\ldots,N-1\\}\n$. Assume that the finite {non-negative} real-valued sequences $\\{\nu_l\\}_{l \\ge k}$\nand $\\{w_l\\}_{l\\ge k}$ satisfy (\\ref{eqiterationfeed2}) for finite\nconstants ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\geq0$ and ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\geq0$.\nThen, for any finite $\\gamma> 0$, there is a {finite} constant ${\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}{\\geq0}$ (depending only on ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}$, ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}$, $T$, $\\alpha$,\n$\\beta$, {$R_\\pi$} and $\\gamma$)\nsuch that\n\n\n\\begin{eqnarray}\\label{eqintuw}\n&& \\sum_{l=j+1}^{N-1} \\frac{u_l \\Delta_{l}}{(T-t_{l})^{1/2 - \\beta\n}(t_l -t_j)^{1-\\gamma} }\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\quad  \\le\n{\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})} \\sum_{l=j+1}^{N-1}\n\\frac{w_l\\Delta\n_l}{(T-t_l)^{1/2\n- \\beta}(t_l -t_j)^{1-\\gamma}}, \\qquad k\\leq j \\leq N.\n\\end{eqnarray}\n\n\\end{lemma}\n\nPlugging (\\ref{eqintuw}) with $\\gamma=\\frac{1}2+\\alpha$ into\n(\\ref{eqiterationfeed}) gives a ready-to-use result.\n\n\\begin{proposition}[(Final a priori estimates)]\\label{coroiterationgen2}\nUnder the assumptions of Lemma~\\ref{lemiterationgen1}, (\\ref\n{eqiterationfeed}) implies\n\n\\begin{eqnarray*}\nu_j \\le w_j +{\\mathcal C}^{({{1}/2+ \\alpha})}_{(\\ref{eqintuw})}C_{u}\\sum_{l=j+1}^{N-1}\n\\frac{w_l\n\\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha\n}}}, \\qquad k\\leq j \\leq N.\n\\end{eqnarray*}\n\n\\end{proposition}\n\n\n\n\\subsection{Stability of discrete BSDEs with Malliavin weights}\\label{sectionstab}\n\nSuppose that $(Y_1,Z_1)$ (resp., $( Y_2, Z_2)$) solves a {MWDP}\n\nwith terminal condition/driver $(\\xi_1, f_{1,i})$ (resp., $( \\xi_2, f_{2,i})$).\nWe are interested in {obtaining estimates on} the differences $(Y_1 -\nY_2, Z_1 - Z_2)$.\n{To give a notion of how stability estimates are used, the processes\n$(Y_{1},Z_{1})$ are typically obtained by construction.\nFor example, in Section~\\ref{sectionas}, they are $(0,0)$, whereas in\nthe proof of Theorem~\\ref{thmMCerr}, they are a set of processes\ndetermined from a series of arguments based on conditioning {w.r.t.}\nthe Monte Carlo samples.\nOne then applies the stability estimates based on a priori knowledge\nthat what stands on the right-hand side is beneficial to the computations.\nIn Corollary~\\ref{coras}, for example, the right-hand side yields\nalmost sure bounds for the processes $(Y,Z)$.\n}\n{We note that the assumptions on the drivers in this section are\nsomewhat weaker than the general assumptions of Section~\\ref\n{section4assumptions}.}\n\n\nThe driver $f_{1,i}(y,z)$ {does not have} to be Lipschitz continuous, but\nwe assume that each $f_{1,i}( Y_{1,i+1},Z_{1,i})$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T)$\nso that $Y_{1,i}$ and $Z_{1,i}$ are also square integrable for any $i$\n(thanks to {$(\\mathbf{A_H})$}). The driver $ f_{2,i}(y,z)$ is locally Lipschitz\ncontinuous w.r.t. $(y,z)$ as in {$(\\mathbf{A_F})$\\textup{(i)}}, which\nis crucial for the validity of the a priori estimates.\n\n\n\nAdditionally, we do not insist that the drivers be adapted, which will\nbe needed in the setting of sample-dependant drivers.\nDefine\n\n\\begin{eqnarray*}\n\\Delta Y&:=& Y_1  - Y_2, \\qquad\\Delta Z:=\nZ_1 - Z_2, \\qquad\\Delta\\xi:= \\xi_1 -\n\\xi_2,\n\\\\\n\\Delta f_i&:=& f_{1,i}(Y_{1,{i+1}},Z_{1,i})\n- f_{2,i}({Y_{1,{i+1}},Z_{1,i}}).\n\\end{eqnarray*}\n\n{Let $k\\in\\{0,\\ldots,N-1\\}$ be fixed: throughout this subsection,\n$\\mathcal{F}\n_{t_k}$-conditional ${\\mathbf{L}}_2$-norms are considered and we recall the\nnotation ${\\vert} U{\\vert}_{2,k}:= \\sqrt{{\\mathbb{E}}_k[{\\vert}\nU{\\vert}^2]}$} for any square integrable\nrandom variable~$U$. For $j\\ge{k}$, define\n\n", "itemtype": "equation", "pos": 21463, "prevtext": "\n\n{$(\\mathbf{A'_H})$}~is satisfied by the Malliavin weights (\\ref\n{eq4malweights}) under various \nconditions. It is valid for the example $X_t=g(t,W_t)$ mentioned before.\n\n\n\n\nConsider now the more complex case of the SDE with (deterministic)\ncoefficients $b(t,x)$ for the drift and $(\\sigma_1(t,x),\\ldots,\\sigma\n_d(t,x))$ for the diffusion ($q=d$) both having first space-derivatives\nthat are uniformly bounded.\nRecall the relation for the Malliavin derivative of a SDE given by\n\n\\begin{eqnarray*}\nD_tX_r= \\nabla X_r \\nabla\nX_t^{-1} \\sigma(t,X_t){\\mathbf{1}}_{t \\le r}=\n\\nabla_x X^{t,x}_r\\mid_{x=X_t}\n\\sigma(t,X_t){\\mathbf{1}}_{t \\le r},\n\\end{eqnarray*}\n\nwhere $X^{t,x}$ denotes the SDE solution starting from $x$ at time $t$,\nand $\\nabla X_t:=\\nabla_x X_t^{0,x}$ for $\\nabla_x X_t^{0,x}$ solving\nthe $(d \\times d)$-dimensional, matrix valued linear SDE\n\n", "index": 17, "text": "\n\\[\n\\nabla_x X^{t,x}_{r} = I_d + \\int\n_{t}^r \n\\nabla_x b\\bigl(u,{X^{(t,x)}}_{u}\\bigr) \\nabla_x X^{ t,x}_u \\,\\mathrm{d}u +\n\\sum_{j=1}^d \\int_{t}^r\n\n\\nabla_x\\sigma_j\\bigl( u,{X^{(t,x)}}_{u}\\bigr) \\nabla_x X^{ t,x}_u\n\\,\\mathrm{d}W_{j,u}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\nabla_{x}X^{t,x}_{r}=I_{d}+\\int_{t}^{r}\\nabla_{x}b\\bigl{(}u,{X^{(t,x)}}_{u}%&#10;\\bigr{)}\\nabla_{x}X^{t,x}_{u}\\,\\mathrm{d}u+\\sum_{j=1}^{d}\\int_{t}^{r}\\par&#10;%&#10;\\nabla_{x}\\sigma_{j}\\bigl{(}u,{X^{(t,x)}}_{u}\\bigr{)}\\nabla_{x}X^{t,x}_{u}\\,%&#10;\\mathrm{d}W_{j,u}.\" display=\"block\"><mrow><mrow><mrow><msub><mo>\u2207</mo><mi>x</mi></msub><mo>\u2061</mo><msubsup><mi>X</mi><mi>r</mi><mrow><mi>t</mi><mo>,</mo><mi>x</mi></mrow></msubsup></mrow><mo>=</mo><mrow><msub><mi>I</mi><mi>d</mi></msub><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>r</mi></msubsup><mrow><mrow><msub><mo>\u2207</mo><mi>x</mi></msub><mo>\u2061</mo><mi>b</mi></mrow><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mi>u</mi><mo>,</mo><mmultiscripts><mi>X</mi><none/><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mi>u</mi><none/></mmultiscripts><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><mrow><msub><mo>\u2207</mo><mi>x</mi></msub><mo>\u2061</mo><mrow><mpadded width=\"+1.7pt\"><msubsup><mi>X</mi><mi>u</mi><mrow><mi>t</mi><mo>,</mo><mi>x</mi></mrow></msubsup></mpadded><mo>\u2062</mo><mi mathvariant=\"normal\">d</mi><mo>\u2062</mo><mi>u</mi></mrow></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>t</mi><mi>r</mi></msubsup><mrow><mrow><msub><mo>\u2207</mo><mi>x</mi></msub><mo>\u2061</mo><msub><mi>\u03c3</mi><mi>j</mi></msub></mrow><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mi>u</mi><mo>,</mo><mmultiscripts><mi>X</mi><none/><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mi>u</mi><none/></mmultiscripts><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><mrow><msub><mo>\u2207</mo><mi>x</mi></msub><mo>\u2061</mo><mrow><mpadded width=\"+1.7pt\"><msubsup><mi>X</mi><mi>u</mi><mrow><mi>t</mi><mo>,</mo><mi>x</mi></mrow></msubsup></mpadded><mo>\u2062</mo><mi mathvariant=\"normal\">d</mi><mo>\u2062</mo><msub><mi>W</mi><mrow><mi>j</mi><mo>,</mo><mi>u</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nUsing {$(\\mathbf{A_H})$}, we obtain $\\mathbb{E}_i[\\Delta\\xi{H^{(i)}_{N}}] = \\mathbb\n{E}_i[(\\Delta\\xi- \\mathbb{E}_i\n\\Delta\\xi){H^{(i)}_{N}}]$ {and\n\n\n\n\n\\begin{eqnarray}\\label{eqboundmalliavin}\n\\bigl{\\vert}\\mathbb{E}_i\\bigl[\\Delta\\xi{H^{(i)}_{N}}\\bigr]\\bigr\n{\\vert}^2 &\\leq& \\mathbb{E}_i\\bigl[{\\vert}\\Delta\\xi-\n\\mathbb{E}_i \\Delta\\xi{\\vert}^2\\bigr]\n\\frac{ C_{M}^2\n}{(t_N-t_i) },\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n\\bigl{\\vert}{\\mathbb{E}}_i z\\bigl[ \\Delta\nf_j {H^{(i)}_{j}} \\bigr]\\bigr{\\vert}^2 &\\le&\\frac\n{C_M^2 {\\mathbb{E}}_i[{\\vert}\\Delta\nf_j{\\vert}^2]}{t_j - t_i},\n\\qquad j \\ge i+1.\n\\end{eqnarray}\n\nCombining this kind of estimates} with {$(\\mathbf{A_F})$\\textup{(i)}}~and the triangle\ninequality, our stability equations {(for $k\\leq i$)} are\n\n\n\n\\begin{eqnarray}\n{\\vert}\\Delta Y_i{\\vert}_{2,k} & \\le&{\\vert}\\Delta\\xi\n{\\vert}_{2,k} + \\sum_{j = i}^{N-1}\n{\\vert}\\Delta f_j{\\vert}_{2,k} \\Delta_j +\n\\sum_{j=i}^{N-1} \\frac{L_{f_2}{\\vert}\\Theta\n_j{\\vert}_{2,k}}{(T-t_j)^{(1-{\\theta_L}\n)/2}}\n\\Delta_j, \\label{eqbounddelY2}\n\\\\\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&\\frac{C_{M}{\\vert}\n\\Delta\\xi- {\\mathbb{E}_i\\Delta\n\\xi\n}{\\vert}_{2,k}}{\\sqrt{T-t_i}}+ \\sum_{j = i+1}^{N-1} \\frac{C_{M}{\\vert}\\Delta f_j{\\vert}\n_{2,k}}{\\sqrt{t_j - t_i}}\n\\Delta_j\n\\nonumber\\[-8pt]\\label{eqbounddelZ2} \\[-8pt]\\nonumber\n&&{}  + \\sum_{j=i+1}^{N-1}\n\\frac{L_{f_2}C_{M}{\\vert}\\Theta\n_j{\\vert}_{2,k}}{(T-t_j)^{(1-{\\theta_L})/2}\\sqrt{t_j - t_i}} \\Delta_j.\n\\end{eqnarray}\n\n\\begin{proposition}\n\\label{propstability}\nTaking $\\alpha=0 $, $\\beta= {\\theta_L}/2 $ and\n$C_{u}=L_{f_2}(C_{M}+\\sqrt\nT)$ in Lemmas~\\ref{lemiterationgen1} and~\\ref{lemiterationgen2},\nrecall the constant ${\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}$. Assume that $\\xi_j$ is in ${\\mathbf{L}}\n_2(\\mathcal{F}_T)$.\nMoreover, for each $i \\in\\{0, \\ldots, N-1\\}$, assume that\n$f_{1,i}(Y_{1,i+1},Z_{1,i})$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T)$ and\n$ f_{2,i}(y,z)$ is\nlocally Lipschitz continuous w.r.t. $y$ and $z$ as in {$(\\mathbf{A_F})$\\textup{(i)}}, with a\nconstant $L_{ f_{2}}$.\nThen, under {$(\\mathbf{A_H})$}, we have\n\n\n\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Y_i{\\vert}_{2,k}& \\le&{C^{({1})}_{{y}} }{\\vert}\\Delta\\xi{\\vert}_{2,k} +{C^{({2})}_{{y}} }\\sum\n_{{j=i}}^{N-1} {\\vert}\\Delta f_j{\\vert}\n_{2,k} \\Delta_j,\\qquad0\\leq k \\leq i \\leq N,\n\\\\\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&{C^{({1})}_{{z}} }\\frac{ {\\vert}\\Delta\\xi- \\mathbb\n{E}_i\\Delta\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}} + {C^{({2})}_{{z}} } \\sum_{j = i+1}^{N-1}\n\\frac{{\\vert}\\Delta\nf_j{\\vert}_{2,k}}{\\sqrt{t_j - t_i}} \\Delta_j\n\\\\\n&&{}+ {C^{({3})}_{{z}} }\n{\\vert}\\Delta\n\\xi{\\vert}_{2,k} (T-t_{i})^{{ {\\theta_L}}/{2\n}},\\qquad0\\leq k\n\\leq i < N,\n\\end{eqnarray*}\n\nwhere the above constants \n\ncan be written explicitly:\n\n\n\n\\begin{eqnarray*}\n{C^{({1})}_{{y}} } &:=& 1+ L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})}\\biggl( C_{M}\n{B_{{{\\theta_L}/2},{1}}} + {B_{{{1}/2 +{\\theta_L}/2},{1}}} \\sqrt T\n\\biggr) T^{{\\theta_L}/2},\n\\\\\n\\aprioriConst2y &:=& 1 + L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})} (C_{M}+ \\sqrt T )\n{B_{{{{\\theta_L}/2}},{1}}} {T^{{\\theta_L}/2}},\n\\\\\n\\aprioriConst1z &:=& C_{M}\\biggl(1 + L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} {C_{M}} {B_{{ {{{\\theta_L}}}/2},{ {1}/2}}} {T^{{\\theta_L}/2}}\\biggr),\n\\\\\n\\aprioriConst2z &:=& C_{M}\\biggl(1 + L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} (C_{M}+ \\sqrt T) {B_{{{\\theta_L}/2},{ {1}/2}}} {T^{{\\theta_L}/2}}\\biggr),\n\\\\\n\\aprioriConst3z &:=& {C_{M}} L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} {B_{{{1}/2 + {\\theta_L}/2},{ {1}/2}}}.\n\\end{eqnarray*}\n\n\\end{proposition}\n\n\\begin{pf}\nUsing (\\ref{eqbounddelY2}) and (\\ref{eqbounddelZ2}), we obtain\n\n\n\\begin{eqnarray}\\label{eqboundtheta2}\n{\\vert}\\Theta_j{\\vert}_{2,k} & \\le&\nC_{M}\\frac{\n{\\vert}\\Delta\\xi{- \\mathbb\n{E}_j\\Delta\\xi\n} {\\vert}_{2,k}}{\\sqrt{T-t_j}} + {{\\vert}\\Delta\\xi{\\vert}_{2,k} }\n+(C_{M}+\\sqrt T) \\sum_{l = j+1}^{N-1}\n\\frac{{\\vert}\\Delta\nf_l{\\vert}_{2,k}\\Delta\n_l}{\\sqrt{t_l - t_j}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}+ (C_{M}+\\sqrt T) \\sum_{l=j+1}^{N-1}\n\\frac{L_{f_2} {\\vert}\n\\Theta\n_l{\\vert}_{2,k}\\Delta_l}{(T-t_l)^{(1-{\\theta_L})/2}\\sqrt{t_l -\nt_j}},\\qquad j\\geq k.\n\\end{eqnarray}\n\n\n\n\n\n\\textit{Upper bound for} (\\ref{eqboundtheta2}).\nWe apply\nLemmas~\\ref{lemiterationgen1} and~\\ref{lemiterationgen2}\nunder the setting $u_j={\\vert}\\Theta_j{\\vert}_{2,k}$, $w_j=\nC_{M}\\frac{ {\\vert}\\Delta\\xi- \\mathbb{E}_j\\Delta\\xi{\\vert}\n_{2,k}}{\\sqrt\n{T-t_j}} +{\\vert}\\Delta\n\\xi{\\vert}_{2,k}+\n(C_{M}+\\sqrt T) \\sum_{l = j+1}^{N-1} \\frac{{\\vert}\\Delta\nf_l{\\vert}_{2,k}\\Delta\n_l}{\\sqrt{t_l - t_j}} $, $\\alpha=0$, $\\beta=\\frac\\thetaL2$,\n$C_{u}=L_{f_2}(C_{M}+\\sqrt T)$.\nTo make results fully explicit, we first need to upper bound quantities\nof the form ($\\gamma>0$)\n\n", "itemtype": "equation", "pos": 27945, "prevtext": "\n\nThen, it is an easy exercise to prove that if $\\sigma$ and its inverse\nare uniformly bounded, then {$(\\mathbf{A'_H})$}~is fulfilled.\n\n\n\n\n\n\n\\section{Stability}\\label{sectionstability}\n\n\n\\subsection{Gronwall type inequalities}\\label{sectiongronwall}\nHere we gather deterministic inequalities frequently used throughout\nthe paper.\n{These inequalities are crucial due to novel technical problems caused\nby the Malliavin weights. }\nThey show how linear inequalities with singular coefficients propagate.\nThey take the form of unusual Gronwall type inequalities.\nTheir proofs are postponed to Appendix~\\ref{appendixprooflemintegrals}.\nWe assume that $\\pi$ is in the class of time-grids satisfying {$(\\mathbf{A_F})$\\textup{(iii)}}.\n\n\\begin{lemma}\n\\label{lemintegrals}\nLet\n\n\n{$\\alpha,\\beta>0 $ be finite. }\n\nThere exists a finite constant ${B_{{\\alpha},{\\beta}}}\\geq0$ depending\nonly on $R_{\\pi}$, $\\alpha$ and $\\beta$ (but not on the time-grid)\nsuch that,\nfor any $0\\le i < k \\le N$,\n\n\\begin{eqnarray*}\n\\sum_{j=i}^{k-1}{\\Delta_j \\over(t_{k} - t_{j})^{1 - \\alpha} }\n&\\le&{B_{{\\alpha},{1}}}(t_{k} - t_{i})^{\\alpha},\n\\\\\n\\sum_{j=i+1}^{k-1}{\\Delta_{j} \\over(t_{k} - t_{j})^{1 -\n\\alpha\n}(t_{j} - t_{i})^{1 - \\beta} }\n&\\le&{B_{{\\alpha},{\\beta}}}(t_{k} - t_{i})^{\\alpha+ \\beta-1}.\n\\end{eqnarray*}\n\n\\end{lemma}\n\n\\begin{lemma}[(Exponent improvement in recursive equations)]\n\\label{lemiterationgen1}\nLet $\\alpha\\geq0, \\beta\\in(0,\\frac{ 1 }{2 }]$ and $k\\in\\{\n0,\\ldots,N-1\\}$.\nSuppose that, for a {finite} constant $C_{u}\\geq0$, the finite\n{non-negative} real-valued sequences $\\{u_l\\}_{l \\ge k}$\nand $\\{w_l\\}_{l\\ge k}$ satisfy\n\n\n\\begin{eqnarray}\nu_j \\le w_j +C_{u}\\sum\n_{l=j+1}^{N-1} \\frac{u_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}},\n\\qquad k\\leq j \\leq\nN. \\label{eqiterationfeed}\n\\end{eqnarray}\n\nThen, for two {finite} constants {${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\geq0$ and ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\geq0$} that\ndepend only on $C_{u}, T, \\alpha, \\beta$ and $R_\\pi$,\n\n\n\\begin{eqnarray}\\label{eqiterationfeed2}\nu_j &\\le& {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} w_j + {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{} +{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum\n_{l=j+1}^{N-1} \\frac{u_l \\Delta_l}{(T-t_l)^{{{1}/2 -\n\\beta\n}}}, \\qquad k\\leq j \\leq\nN.\n\\end{eqnarray}\n\n\n\n\n\\end{lemma}\n\n\\begin{lemma}[(Intermediate a priori estimates)]\\label{lemiterationgen2}\nLet $\\alpha\\geq0, \\beta\\in(0,\\frac{ 1 }{2 }]$ and $k\\in\\{0,\\ldots,N-1\\}\n$. Assume that the finite {non-negative} real-valued sequences $\\{\nu_l\\}_{l \\ge k}$\nand $\\{w_l\\}_{l\\ge k}$ satisfy (\\ref{eqiterationfeed2}) for finite\nconstants ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}\\geq0$ and ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\geq0$.\nThen, for any finite $\\gamma> 0$, there is a {finite} constant ${\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}{\\geq0}$ (depending only on ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}$, ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}$, $T$, $\\alpha$,\n$\\beta$, {$R_\\pi$} and $\\gamma$)\nsuch that\n\n\n\\begin{eqnarray}\\label{eqintuw}\n&& \\sum_{l=j+1}^{N-1} \\frac{u_l \\Delta_{l}}{(T-t_{l})^{1/2 - \\beta\n}(t_l -t_j)^{1-\\gamma} }\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\quad  \\le\n{\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})} \\sum_{l=j+1}^{N-1}\n\\frac{w_l\\Delta\n_l}{(T-t_l)^{1/2\n- \\beta}(t_l -t_j)^{1-\\gamma}}, \\qquad k\\leq j \\leq N.\n\\end{eqnarray}\n\n\\end{lemma}\n\nPlugging (\\ref{eqintuw}) with $\\gamma=\\frac{1}2+\\alpha$ into\n(\\ref{eqiterationfeed}) gives a ready-to-use result.\n\n\\begin{proposition}[(Final a priori estimates)]\\label{coroiterationgen2}\nUnder the assumptions of Lemma~\\ref{lemiterationgen1}, (\\ref\n{eqiterationfeed}) implies\n\n\\begin{eqnarray*}\nu_j \\le w_j +{\\mathcal C}^{({{1}/2+ \\alpha})}_{(\\ref{eqintuw})}C_{u}\\sum_{l=j+1}^{N-1}\n\\frac{w_l\n\\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha\n}}}, \\qquad k\\leq j \\leq N.\n\\end{eqnarray*}\n\n\\end{proposition}\n\n\n\n\\subsection{Stability of discrete BSDEs with Malliavin weights}\\label{sectionstab}\n\nSuppose that $(Y_1,Z_1)$ (resp., $( Y_2, Z_2)$) solves a {MWDP}\n\nwith terminal condition/driver $(\\xi_1, f_{1,i})$ (resp., $( \\xi_2, f_{2,i})$).\nWe are interested in {obtaining estimates on} the differences $(Y_1 -\nY_2, Z_1 - Z_2)$.\n{To give a notion of how stability estimates are used, the processes\n$(Y_{1},Z_{1})$ are typically obtained by construction.\nFor example, in Section~\\ref{sectionas}, they are $(0,0)$, whereas in\nthe proof of Theorem~\\ref{thmMCerr}, they are a set of processes\ndetermined from a series of arguments based on conditioning {w.r.t.}\nthe Monte Carlo samples.\nOne then applies the stability estimates based on a priori knowledge\nthat what stands on the right-hand side is beneficial to the computations.\nIn Corollary~\\ref{coras}, for example, the right-hand side yields\nalmost sure bounds for the processes $(Y,Z)$.\n}\n{We note that the assumptions on the drivers in this section are\nsomewhat weaker than the general assumptions of Section~\\ref\n{section4assumptions}.}\n\n\nThe driver $f_{1,i}(y,z)$ {does not have} to be Lipschitz continuous, but\nwe assume that each $f_{1,i}( Y_{1,i+1},Z_{1,i})$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T)$\nso that $Y_{1,i}$ and $Z_{1,i}$ are also square integrable for any $i$\n(thanks to {$(\\mathbf{A_H})$}). The driver $ f_{2,i}(y,z)$ is locally Lipschitz\ncontinuous w.r.t. $(y,z)$ as in {$(\\mathbf{A_F})$\\textup{(i)}}, which\nis crucial for the validity of the a priori estimates.\n\n\n\nAdditionally, we do not insist that the drivers be adapted, which will\nbe needed in the setting of sample-dependant drivers.\nDefine\n\n\\begin{eqnarray*}\n\\Delta Y&:=& Y_1  - Y_2, \\qquad\\Delta Z:=\nZ_1 - Z_2, \\qquad\\Delta\\xi:= \\xi_1 -\n\\xi_2,\n\\\\\n\\Delta f_i&:=& f_{1,i}(Y_{1,{i+1}},Z_{1,i})\n- f_{2,i}({Y_{1,{i+1}},Z_{1,i}}).\n\\end{eqnarray*}\n\n{Let $k\\in\\{0,\\ldots,N-1\\}$ be fixed: throughout this subsection,\n$\\mathcal{F}\n_{t_k}$-conditional ${\\mathbf{L}}_2$-norms are considered and we recall the\nnotation ${\\vert} U{\\vert}_{2,k}:= \\sqrt{{\\mathbb{E}}_k[{\\vert}\nU{\\vert}^2]}$} for any square integrable\nrandom variable~$U$. For $j\\ge{k}$, define\n\n", "index": 19, "text": "\n\\[\n{\\vert}{\\Theta_j}{\\vert}_{2,k}:= {\\vert}\\Delta\nY_{{j+1}}{\\vert}_{2,k} + {\\vert}\\Delta Z_j\n{\\vert}_{2,k}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"{|}{\\Theta_{j}}{|}_{2,k}:={|}\\Delta Y_{{j+1}}{|}_{2,k}+{|}\\Delta Z_{j}{|}_{2,k}.\" display=\"block\"><mrow><mrow><msub><mrow><mo stretchy=\"false\">|</mo><msub><mi mathvariant=\"normal\">\u0398</mi><mi>j</mi></msub><mo stretchy=\"false\">|</mo></mrow><mrow><mn>2</mn><mo>,</mo><mi>k</mi></mrow></msub><mo>:=</mo><mrow><msub><mrow><mo stretchy=\"false\">|</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>Y</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><mn>2</mn><mo>,</mo><mi>k</mi></mrow></msub><mo>+</mo><msub><mrow><mo stretchy=\"false\">|</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><msub><mi>Z</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><mn>2</mn><mo>,</mo><mi>k</mi></mrow></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nUsing that\n${\\vert}\\Delta\\xi- \\mathbb{E}_l\\Delta\\xi{\\vert}_{2,k}$\nis non-increasing in\n$l$ and\nLemma~\\ref{lemintegrals}, we obtain\n\n\n\\begin{eqnarray} \\label{eqigamma}\n\\mathcal{I}^{(\\gamma)}_{j+1}&=&\\sum\n_{l=j+1}^{N-1}\n\\Biggl( C_{M}\\frac{\n{\\vert}\\Delta\\xi- \\mathbb{E}_l\\Delta\\xi{\\vert}\n_{2,k}}{\\sqrt{T-t_l}} +{\\vert}\\Delta\n\\xi{\\vert}_{2,k}+\n(C_{M}+\\sqrt T) \\sum_{r = l+1}^{N-1} \\frac{{\\vert}\\Delta\nf_r{\\vert}_{2,k}\\Delta\n_r}{\\sqrt{t_r - t_l}} \\Biggr)\\Delta_l\\nonumber\n\\\\\n&&\\hspace*{24pt}{} \\Big/\n\\bigl(\n(T-t_l)^{1/2 - {\\thetaL/2}}(t_l -t_j)^{1-\\gamma}\\bigr)\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&\\leq& C_{M}B_{{\\thetaL/2},\\gamma}\\frac{ {\\vert}\n\\Delta\\xi-\n\\mathbb{E}\n_{j+1}\\Delta\\xi{\\vert}_{2,k}}{(T-t_j)^{1-{\\thetaL/2}-\\gamma}}\n+B_{{{1}/2}+{\\thetaL/2},\\gamma}\\frac{{\\vert}\\Delta\\xi\n{\\vert}_{2,k}}{(T-t_j)^{1/2-{\\thetaL/2}-\\gamma}}\\nonumber\n\\\\\n&&{} +(C_{M}+\\sqrt T)B_{ {\\thetaL/2},\\gamma}\\sum\n_{l =\nj+2}^{N-1}\\frac{{\\vert}\\Delta f_l{\\vert}_{2,k}\\Delta\n_l}{(t_l-t_j)^{1-{{\\theta_L}/2}-\\gamma}}.\\nonumber\n\\end{eqnarray}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\textit{Upper bound for} $|\\Delta Y_i|_{2,k}$.\nStarting\n\n\n\n\nfrom (\\ref{eqbounddelY2}) and applying Lemma~\\ref\n{lemiterationgen2}, we get\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Y_i{\\vert}_{2,k} & \\le&{\\vert}\\Delta\\xi\n{\\vert}_{2,k} + \\sum_{j = i}^{N-1}\n{\\vert}\\Delta f_j{\\vert}_{2,k} \\Delta_j\n+L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})} \\mathcal{I}^{(1)}_{i};\n\n\n\n\\end{eqnarray*}\n\nthen using the estimate (\\ref{eqigamma}) and $ {\\vert}\\Delta\n\\xi-{\\mathbb{E}}_i\n\\Delta\\xi{\\vert}_{2,k}\\leq{\\vert}\\Delta\\xi{\\vert}\n_{2,k}$, we obtain the announced\ninequality.\n\n\n\n\n\\textit{Upper bound of} ${\\vert}\\Delta Z_i{\\vert}_{2,k}$.\nStarting from\n(\\ref{eqbounddelZ2}) and applying Lemma~\\ref{lemiterationgen2},\nwe have\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&\\frac{C_{M}{\\vert}\n\\Delta\\xi- \\mathbb{E}_i\\Delta\n\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}}\n+ \\sum_{j = i+1}^{N-1} \\frac{C_{M}{\\vert}\\Delta f_j{\\vert}\n_{2,k}}{\\sqrt{t_j - t_i}}\n\\Delta_j\n\\\\\n&&{}+ L_{f_2}C_{M}{\\mathcal C}^{({{{1}/2}})}_{(\\ref{eqintuw})}\n\\mathcal{I}^{({{ 1 }/{2 }})}_{i+1}; \n\n\n\n\n\n\n\n\\end{eqnarray*}\n\ntherefore using the estimate (\\ref{eqigamma}), we derive the\nadvertised upper bound on ${\\vert}\\Delta Z_i{\\vert}_{2,k}$.\n\n\\end{pf}\n\n\n\n\\subsection{Almost sure bounds}\\label{sectionas}\n{In order to obtain error estimates for the Monte Carlo scheme, we use\nthe model-free estimates of Proposition~\\ref{propeqyzerrdecoM}.\nTypically, these estimates require that the object one is trying to\napproximate is bounded.\nTherefore, the following almost sure bounds are crucial.}\n\n\\begin{corollary}\n\\label{coras}\nAssume {$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}, {$(\\mathbf{A_F})$}~and {$(\\mathbf{A_H})$}~and recall the constants ${C^{(\\cdot)}_{y} }$ and ${C^{(\\cdot)}_{z} }$ from Proposition~\\ref{propstability} where $L_{f_2}$ is\nreplaced by $L_f$. Then, we have\n\n\n\n\\begin{eqnarray}\n{\\vert} Y_i{\\vert}& \\le& C_{y,i}:= \\aprioriConst1{y}\nC_\\xi+ {C^{({2})}_{{y}} }C_f B_{{\\theta_c},1}\n(T-t_i)^{{\\theta_c}}, \\label{eqasy}\n\\\\\n{\\vert} Z_i{\\vert}& \\le& C_{z,i}:= \\aprioriConst1z\n\\frac\n{\\operatorname{ess}\\sup_{\\omega}\n{\\vert}\\xi\n- \\mathbb{E}_i\\xi{\\vert}_{2,i}}{\\sqrt{T-t_i}} + \\frac{{C^{(2)}_{{z}} }C_f B_{{\\theta_c},{{1}/2}}}{(T-t_i)^{1/2 -\n{\\theta_c}}} +\\aprioriConst3{z} C_\\xi(T-t_{i})^{{ {\\theta_L}}/{2 }}.\\qquad\n\\label{eqasz}\n\\end{eqnarray}\n\n\n\\end{corollary}\n\n\nThe above upper bounds a valid for terminal values $\\xi$ admitted by\n{$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}, which is quite general.\nWithout any further information on $\\xi$, we can derive the simple bounds\n\n\n\n", "itemtype": "equation", "pos": 32717, "prevtext": "\n\nUsing {$(\\mathbf{A_H})$}, we obtain $\\mathbb{E}_i[\\Delta\\xi{H^{(i)}_{N}}] = \\mathbb\n{E}_i[(\\Delta\\xi- \\mathbb{E}_i\n\\Delta\\xi){H^{(i)}_{N}}]$ {and\n\n\n\n\n\\begin{eqnarray}\\label{eqboundmalliavin}\n\\bigl{\\vert}\\mathbb{E}_i\\bigl[\\Delta\\xi{H^{(i)}_{N}}\\bigr]\\bigr\n{\\vert}^2 &\\leq& \\mathbb{E}_i\\bigl[{\\vert}\\Delta\\xi-\n\\mathbb{E}_i \\Delta\\xi{\\vert}^2\\bigr]\n\\frac{ C_{M}^2\n}{(t_N-t_i) },\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n\\bigl{\\vert}{\\mathbb{E}}_i z\\bigl[ \\Delta\nf_j {H^{(i)}_{j}} \\bigr]\\bigr{\\vert}^2 &\\le&\\frac\n{C_M^2 {\\mathbb{E}}_i[{\\vert}\\Delta\nf_j{\\vert}^2]}{t_j - t_i},\n\\qquad j \\ge i+1.\n\\end{eqnarray}\n\nCombining this kind of estimates} with {$(\\mathbf{A_F})$\\textup{(i)}}~and the triangle\ninequality, our stability equations {(for $k\\leq i$)} are\n\n\n\n\\begin{eqnarray}\n{\\vert}\\Delta Y_i{\\vert}_{2,k} & \\le&{\\vert}\\Delta\\xi\n{\\vert}_{2,k} + \\sum_{j = i}^{N-1}\n{\\vert}\\Delta f_j{\\vert}_{2,k} \\Delta_j +\n\\sum_{j=i}^{N-1} \\frac{L_{f_2}{\\vert}\\Theta\n_j{\\vert}_{2,k}}{(T-t_j)^{(1-{\\theta_L}\n)/2}}\n\\Delta_j, \\label{eqbounddelY2}\n\\\\\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&\\frac{C_{M}{\\vert}\n\\Delta\\xi- {\\mathbb{E}_i\\Delta\n\\xi\n}{\\vert}_{2,k}}{\\sqrt{T-t_i}}+ \\sum_{j = i+1}^{N-1} \\frac{C_{M}{\\vert}\\Delta f_j{\\vert}\n_{2,k}}{\\sqrt{t_j - t_i}}\n\\Delta_j\n\\nonumber\\[-8pt]\\label{eqbounddelZ2} \\[-8pt]\\nonumber\n&&{}  + \\sum_{j=i+1}^{N-1}\n\\frac{L_{f_2}C_{M}{\\vert}\\Theta\n_j{\\vert}_{2,k}}{(T-t_j)^{(1-{\\theta_L})/2}\\sqrt{t_j - t_i}} \\Delta_j.\n\\end{eqnarray}\n\n\\begin{proposition}\n\\label{propstability}\nTaking $\\alpha=0 $, $\\beta= {\\theta_L}/2 $ and\n$C_{u}=L_{f_2}(C_{M}+\\sqrt\nT)$ in Lemmas~\\ref{lemiterationgen1} and~\\ref{lemiterationgen2},\nrecall the constant ${\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}$. Assume that $\\xi_j$ is in ${\\mathbf{L}}\n_2(\\mathcal{F}_T)$.\nMoreover, for each $i \\in\\{0, \\ldots, N-1\\}$, assume that\n$f_{1,i}(Y_{1,i+1},Z_{1,i})$ is in ${\\mathbf{L}}_2(\\mathcal{F}_T)$ and\n$ f_{2,i}(y,z)$ is\nlocally Lipschitz continuous w.r.t. $y$ and $z$ as in {$(\\mathbf{A_F})$\\textup{(i)}}, with a\nconstant $L_{ f_{2}}$.\nThen, under {$(\\mathbf{A_H})$}, we have\n\n\n\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Y_i{\\vert}_{2,k}& \\le&{C^{({1})}_{{y}} }{\\vert}\\Delta\\xi{\\vert}_{2,k} +{C^{({2})}_{{y}} }\\sum\n_{{j=i}}^{N-1} {\\vert}\\Delta f_j{\\vert}\n_{2,k} \\Delta_j,\\qquad0\\leq k \\leq i \\leq N,\n\\\\\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&{C^{({1})}_{{z}} }\\frac{ {\\vert}\\Delta\\xi- \\mathbb\n{E}_i\\Delta\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}} + {C^{({2})}_{{z}} } \\sum_{j = i+1}^{N-1}\n\\frac{{\\vert}\\Delta\nf_j{\\vert}_{2,k}}{\\sqrt{t_j - t_i}} \\Delta_j\n\\\\\n&&{}+ {C^{({3})}_{{z}} }\n{\\vert}\\Delta\n\\xi{\\vert}_{2,k} (T-t_{i})^{{ {\\theta_L}}/{2\n}},\\qquad0\\leq k\n\\leq i < N,\n\\end{eqnarray*}\n\nwhere the above constants \n\ncan be written explicitly:\n\n\n\n\\begin{eqnarray*}\n{C^{({1})}_{{y}} } &:=& 1+ L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})}\\biggl( C_{M}\n{B_{{{\\theta_L}/2},{1}}} + {B_{{{1}/2 +{\\theta_L}/2},{1}}} \\sqrt T\n\\biggr) T^{{\\theta_L}/2},\n\\\\\n\\aprioriConst2y &:=& 1 + L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})} (C_{M}+ \\sqrt T )\n{B_{{{{\\theta_L}/2}},{1}}} {T^{{\\theta_L}/2}},\n\\\\\n\\aprioriConst1z &:=& C_{M}\\biggl(1 + L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} {C_{M}} {B_{{ {{{\\theta_L}}}/2},{ {1}/2}}} {T^{{\\theta_L}/2}}\\biggr),\n\\\\\n\\aprioriConst2z &:=& C_{M}\\biggl(1 + L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} (C_{M}+ \\sqrt T) {B_{{{\\theta_L}/2},{ {1}/2}}} {T^{{\\theta_L}/2}}\\biggr),\n\\\\\n\\aprioriConst3z &:=& {C_{M}} L_{f_2}{\\mathcal C}^{({ {1}/2})}_{(\\ref{eqintuw})} {B_{{{1}/2 + {\\theta_L}/2},{ {1}/2}}}.\n\\end{eqnarray*}\n\n\\end{proposition}\n\n\\begin{pf}\nUsing (\\ref{eqbounddelY2}) and (\\ref{eqbounddelZ2}), we obtain\n\n\n\\begin{eqnarray}\\label{eqboundtheta2}\n{\\vert}\\Theta_j{\\vert}_{2,k} & \\le&\nC_{M}\\frac{\n{\\vert}\\Delta\\xi{- \\mathbb\n{E}_j\\Delta\\xi\n} {\\vert}_{2,k}}{\\sqrt{T-t_j}} + {{\\vert}\\Delta\\xi{\\vert}_{2,k} }\n+(C_{M}+\\sqrt T) \\sum_{l = j+1}^{N-1}\n\\frac{{\\vert}\\Delta\nf_l{\\vert}_{2,k}\\Delta\n_l}{\\sqrt{t_l - t_j}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}+ (C_{M}+\\sqrt T) \\sum_{l=j+1}^{N-1}\n\\frac{L_{f_2} {\\vert}\n\\Theta\n_l{\\vert}_{2,k}\\Delta_l}{(T-t_l)^{(1-{\\theta_L})/2}\\sqrt{t_l -\nt_j}},\\qquad j\\geq k.\n\\end{eqnarray}\n\n\n\n\n\n\\textit{Upper bound for} (\\ref{eqboundtheta2}).\nWe apply\nLemmas~\\ref{lemiterationgen1} and~\\ref{lemiterationgen2}\nunder the setting $u_j={\\vert}\\Theta_j{\\vert}_{2,k}$, $w_j=\nC_{M}\\frac{ {\\vert}\\Delta\\xi- \\mathbb{E}_j\\Delta\\xi{\\vert}\n_{2,k}}{\\sqrt\n{T-t_j}} +{\\vert}\\Delta\n\\xi{\\vert}_{2,k}+\n(C_{M}+\\sqrt T) \\sum_{l = j+1}^{N-1} \\frac{{\\vert}\\Delta\nf_l{\\vert}_{2,k}\\Delta\n_l}{\\sqrt{t_l - t_j}} $, $\\alpha=0$, $\\beta=\\frac\\thetaL2$,\n$C_{u}=L_{f_2}(C_{M}+\\sqrt T)$.\nTo make results fully explicit, we first need to upper bound quantities\nof the form ($\\gamma>0$)\n\n", "index": 21, "text": "\n\\[\n\\mathcal{I}^{(\\gamma)}_{j+1}:= \\sum_{l=j+1}^{N-1}\n\\frac{w_l\\Delta_l}{(T-t_l)^{1/2 -\n{\\theta_L}/\n2}(t_l -t_j)^{1-\\gamma}}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{I}^{(\\gamma)}_{j+1}:=\\sum_{l=j+1}^{N-1}\\frac{w_{l}\\Delta_{l}}{(T-t_{l%&#10;})^{1/2-{\\theta_{L}}/2}(t_{l}-t_{j})^{1-\\gamma}}.\" display=\"block\"><mrow><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>\u03b3</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>:=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>=</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mfrac><mrow><msub><mi>w</mi><mi>l</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>l</mi></msub></mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>l</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mrow><msub><mi>\u03b8</mi><mi>L</mi></msub><mo>/</mo><mn>2</mn></mrow></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>l</mi></msub><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b3</mi></mrow></msup></mrow></mfrac></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor an explicit, time uniform constant ${C_{y,z}}$.\nIt may, however, be useful to take advantage of additional information\non $\\xi$, {to obtain finer estimates on $C_{y,i}$ and $C_{z,i}$ with\nthe aim\nof better tuning the parameters of the MWLS method (see Section~\\ref\n{sectioncomplexity}).}\nTwo situations are of particular interest.\n\n\\begin{itemize}\n\n\\item For zero terminal condition, $Y$ and $Z$ get smaller and smaller\nas $t_i$ goes to $T$ as expected:\n${\\vert} Y_i{\\vert}+\\sqrt{T-t_i}{\\vert} Z_i{\\vert}\n\\leq C(T-t_i)^{{\\theta_c}}$ for a constant $C$\ndepending only on $\\aprioriConst2y$, $\\aprioriConst2z$, $C_f$,\n${\\theta_c}$ and $R_\\pi$.\n\nThis result is useful for variance reduction methods like the proxy\nmethod of \\cite{gobeturk14}, Section~2.2, the method of Martingale basis\n\\cite{bendstei12}, and the multilevel method of \\cite{turk13}.\n\n\\item Under {$(\\mathbf{A''_{\\bolds{\\xi}}})$}, we have ${\\vert}\\xi-{\\mathbb{E}}_i\\xi{\\vert}\n_{2,i}\\leq C_\\Phi\n(T-t_i)^{{\\theta_\\Phi}/2}$, which leads to an improved estimate for $Z$:\n${\\vert} Z_i{\\vert}\\le C (T-t_i)^{-{{1}/2} + {\\theta_c}\\land\n({{{\\theta_\\Phi}}/2})} $ for\nsome constant $C$ depending only on $\\aprioriConst1z$, $\\aprioriConst2z$,\n$\\aprioriConst3z$, $C_f$, ${\\theta_c}$, $R_\\pi$, $T$, $C_\\xi$ and\n$C_\\Phi$.\n\\end{itemize}\n\nThis is why in the subsequent analysis, we keep track on the general\ndependence on $i$ of the constants $C_{y,i}$ and $C_{z,i}$.\n\n\n\\begin{pf*}{Proof of Corollary~\\ref{coras}}\n$(0,0)$ is the solution of the {MWDP} with data $(\\xi_1 \\equiv0,\nf_{1,i} \\equiv0)$.\nApplying Proposition~\\ref{propstability} with $(Y_1,Z_1) = (0,0)$ and\n$(Y_2,Z_2)=(Y,Z)$ yields\n\n\\begin{eqnarray}\n{\\vert} Y_i{\\vert}_{2,k} & \\le& C^{(1)}_{y}\n{\\vert}\\xi{\\vert}_{2,k} + C^{(2)}_{y}\\sum\n_{j=i}^{N-1}\\bigl{\\vert} f_j(0,0)\n\\bigr{\\vert}_{2,k} \\Delta_j,\n\\nonumber\n\\\\\n{\\vert} Z_i{\\vert}_{2,k} & \\le&\\frac{ C^{(1)}_{z}{\\vert}\n\\xi- \\mathbb{E}_i\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}} +\nC^{(2)}_{z} \\sum_{j=i+1}^{N-1}\n\\frac{{\\vert} f_j(0,0){\\vert}_{2,k}}{\\sqrt\n{t_j-t_i}} \\Delta_j+ C^{(3)}_{z}\n{\\vert}\\xi{\\vert}_{2,k}(T-t_{i})^{{{ {\\theta_L} }/{2 }}},\n\\nonumber\n\\end{eqnarray}\n\nfor $i=0,\\ldots,N-1$.\nTaking $k=i$, plugging in the almost sure bounds on ${\\vert}\\xi\n{\\vert}$\nfrom {$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}~and ${\\vert} f_j(0,0){\\vert}$ from {$(\\mathbf{A_F})$\\textup{(ii)}}, and\nusing Lemma~\\ref{lemintegrals}\nthen yields the result.\n\n\n\n\n\n\\end{pf*}\n\n\n\n\n\\section{Monte Carlo regression scheme}\\label{section4MC}\n\n\n\n\n\n\nThroughout this section, the Markovian assumptions {$(\\mathbf{A_X})$}, {$(\\mathbf{A'_{\\bolds{\\xi}}})$}, {$(\\mathbf{A'_F})$}~and\n{$(\\mathbf{A'_H})$}~are in force. The notation and preliminary results used in\nthis section overlap with \\cite{gobeturk14}, Section~4, and we recall\nand adapt them to the setting of MWLS in Section~\\ref\n{sectionMCprelims} for completeness.\n\n\n\\subsection{Preliminaries}\\label{sectionMCprelims}\n{An elegant property of} the Markovian assumptions is there are\nmeasurable, deterministic (but unknown) functions $y_i(\\cdot)\\dvtx  {\\mathbb{R}}^d\n\\rightarrow{\\mathbb{R}}$ and\n$z_i(\\cdot)\\dvtx  {\\mathbb{R}}^d \\rightarrow({\\mathbb{R}}^q)^\\top$ for each $i \\in\\{\n0,\\ldots,N-1\\}$\nsuch that the solution $(Y_i,Z_i)_{0\\le i \\le N-1}$ of the discrete\nBSDE (\\ref{eqmalscheme}) is given by\n\n\n\n", "itemtype": "equation", "pos": 36409, "prevtext": "\n\nUsing that\n${\\vert}\\Delta\\xi- \\mathbb{E}_l\\Delta\\xi{\\vert}_{2,k}$\nis non-increasing in\n$l$ and\nLemma~\\ref{lemintegrals}, we obtain\n\n\n\\begin{eqnarray} \\label{eqigamma}\n\\mathcal{I}^{(\\gamma)}_{j+1}&=&\\sum\n_{l=j+1}^{N-1}\n\\Biggl( C_{M}\\frac{\n{\\vert}\\Delta\\xi- \\mathbb{E}_l\\Delta\\xi{\\vert}\n_{2,k}}{\\sqrt{T-t_l}} +{\\vert}\\Delta\n\\xi{\\vert}_{2,k}+\n(C_{M}+\\sqrt T) \\sum_{r = l+1}^{N-1} \\frac{{\\vert}\\Delta\nf_r{\\vert}_{2,k}\\Delta\n_r}{\\sqrt{t_r - t_l}} \\Biggr)\\Delta_l\\nonumber\n\\\\\n&&\\hspace*{24pt}{} \\Big/\n\\bigl(\n(T-t_l)^{1/2 - {\\thetaL/2}}(t_l -t_j)^{1-\\gamma}\\bigr)\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&\\leq& C_{M}B_{{\\thetaL/2},\\gamma}\\frac{ {\\vert}\n\\Delta\\xi-\n\\mathbb{E}\n_{j+1}\\Delta\\xi{\\vert}_{2,k}}{(T-t_j)^{1-{\\thetaL/2}-\\gamma}}\n+B_{{{1}/2}+{\\thetaL/2},\\gamma}\\frac{{\\vert}\\Delta\\xi\n{\\vert}_{2,k}}{(T-t_j)^{1/2-{\\thetaL/2}-\\gamma}}\\nonumber\n\\\\\n&&{} +(C_{M}+\\sqrt T)B_{ {\\thetaL/2},\\gamma}\\sum\n_{l =\nj+2}^{N-1}\\frac{{\\vert}\\Delta f_l{\\vert}_{2,k}\\Delta\n_l}{(t_l-t_j)^{1-{{\\theta_L}/2}-\\gamma}}.\\nonumber\n\\end{eqnarray}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\textit{Upper bound for} $|\\Delta Y_i|_{2,k}$.\nStarting\n\n\n\n\nfrom (\\ref{eqbounddelY2}) and applying Lemma~\\ref\n{lemiterationgen2}, we get\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Y_i{\\vert}_{2,k} & \\le&{\\vert}\\Delta\\xi\n{\\vert}_{2,k} + \\sum_{j = i}^{N-1}\n{\\vert}\\Delta f_j{\\vert}_{2,k} \\Delta_j\n+L_{f_2} {\\mathcal C}^{({1})}_{(\\ref{eqintuw})} \\mathcal{I}^{(1)}_{i};\n\n\n\n\\end{eqnarray*}\n\nthen using the estimate (\\ref{eqigamma}) and $ {\\vert}\\Delta\n\\xi-{\\mathbb{E}}_i\n\\Delta\\xi{\\vert}_{2,k}\\leq{\\vert}\\Delta\\xi{\\vert}\n_{2,k}$, we obtain the announced\ninequality.\n\n\n\n\n\\textit{Upper bound of} ${\\vert}\\Delta Z_i{\\vert}_{2,k}$.\nStarting from\n(\\ref{eqbounddelZ2}) and applying Lemma~\\ref{lemiterationgen2},\nwe have\n\n\\begin{eqnarray*}\n{\\vert}\\Delta Z_i{\\vert}_{2,k} & \\le&\\frac{C_{M}{\\vert}\n\\Delta\\xi- \\mathbb{E}_i\\Delta\n\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}}\n+ \\sum_{j = i+1}^{N-1} \\frac{C_{M}{\\vert}\\Delta f_j{\\vert}\n_{2,k}}{\\sqrt{t_j - t_i}}\n\\Delta_j\n\\\\\n&&{}+ L_{f_2}C_{M}{\\mathcal C}^{({{{1}/2}})}_{(\\ref{eqintuw})}\n\\mathcal{I}^{({{ 1 }/{2 }})}_{i+1}; \n\n\n\n\n\n\n\n\\end{eqnarray*}\n\ntherefore using the estimate (\\ref{eqigamma}), we derive the\nadvertised upper bound on ${\\vert}\\Delta Z_i{\\vert}_{2,k}$.\n\n\\end{pf}\n\n\n\n\\subsection{Almost sure bounds}\\label{sectionas}\n{In order to obtain error estimates for the Monte Carlo scheme, we use\nthe model-free estimates of Proposition~\\ref{propeqyzerrdecoM}.\nTypically, these estimates require that the object one is trying to\napproximate is bounded.\nTherefore, the following almost sure bounds are crucial.}\n\n\\begin{corollary}\n\\label{coras}\nAssume {$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}, {$(\\mathbf{A_F})$}~and {$(\\mathbf{A_H})$}~and recall the constants ${C^{(\\cdot)}_{y} }$ and ${C^{(\\cdot)}_{z} }$ from Proposition~\\ref{propstability} where $L_{f_2}$ is\nreplaced by $L_f$. Then, we have\n\n\n\n\\begin{eqnarray}\n{\\vert} Y_i{\\vert}& \\le& C_{y,i}:= \\aprioriConst1{y}\nC_\\xi+ {C^{({2})}_{{y}} }C_f B_{{\\theta_c},1}\n(T-t_i)^{{\\theta_c}}, \\label{eqasy}\n\\\\\n{\\vert} Z_i{\\vert}& \\le& C_{z,i}:= \\aprioriConst1z\n\\frac\n{\\operatorname{ess}\\sup_{\\omega}\n{\\vert}\\xi\n- \\mathbb{E}_i\\xi{\\vert}_{2,i}}{\\sqrt{T-t_i}} + \\frac{{C^{(2)}_{{z}} }C_f B_{{\\theta_c},{{1}/2}}}{(T-t_i)^{1/2 -\n{\\theta_c}}} +\\aprioriConst3{z} C_\\xi(T-t_{i})^{{ {\\theta_L}}/{2 }}.\\qquad\n\\label{eqasz}\n\\end{eqnarray}\n\n\n\\end{corollary}\n\n\nThe above upper bounds a valid for terminal values $\\xi$ admitted by\n{$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}, which is quite general.\nWithout any further information on $\\xi$, we can derive the simple bounds\n\n\n\n", "index": 23, "text": "\\begin{equation}\n\\label{equniformbound} {\\vert} Y_i{\\vert}+\\sqrt{T-t_i}\n{\\vert} Z_i{\\vert}\\leq{C_{y,z}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"{|}Y_{i}{|}+\\sqrt{T-t_{i}}{|}Z_{i}{|}\\leq{C_{y,z}}\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><msub><mi>Y</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo></mrow><mo>+</mo><mrow><msqrt><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>i</mi></msub></mrow></msqrt><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>\u2264</mo><msub><mi>C</mi><mrow><mi>y</mi><mo>,</mo><mi>z</mi></mrow></msub></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n{In this section, we estimate these functions.} \n\n\nOne needs to apply Lemma~\\ref{lemcdnexp}\n{below} combined with\n$\\mathcal{G}= \\mathcal{G}_i$ -- defined in the assumptions {$(\\mathbf{A_X})$}~and\n{$(\\mathbf{A'_H})$}~-- $U =\nX_i$, and\n\n\\begin{eqnarray*}\nF(x) &:=& \\Phi\\bigl({ V^{(i)}_{N} }(x)\\bigr) + \\sum_{k=i}^{N-1}\nf_k \\bigl({ V^{(i)}_{k} }(x),y_{k+1}\\bigl({ V^{(i)}_{{k+1}} }\n(x)\\bigr), z_k\\bigl({ V^{(i)}_{k} } (x)\\bigr) \\bigr)\\Delta\n_k\\qquad\\mbox{for } y_i(\\cdot),\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\nF(x) &:=& \\Phi\\bigl({ V^{(i)}_{N} }(x)\\bigr) { \\mathpzc{h}^{(i)}_{N} }(x)\n\\\\\n&&{} + \\sum\n_{k=i+1}^{N-1} f_k \\bigl({ V^{(i)}_{k} }(x), y_{k+1}\\bigl({ V^{(i)}_{{k+1}} } (x)\\bigr), z_k\\bigl(\n{ V^{(i)}_{k} } (x)\\bigr) \\bigr) { \\mathpzc{h}^{(i)}_{k} }(x)\\Delta_k\\qquad\\mbox{for\n} z_i(\\cdot).\n\\end{eqnarray*}\n\n\\begin{lemma}[(\\cite{gobeturk14}, Lemma 4.1)]\n\n\\label{lemcdnexp}\nSuppose that $\\mathcal{G}$ and $\\mathcal{H}$ are independent\nsub-$\\sigma\n$-algebras of\n$\\mathcal{F}$.\n{For $l \\ge1$,} let $F\\dvtx  \\Omega\\times{\\mathbb{R}}^d \\rightarrow{{\\mathbb{R}}^l}$ be\nbounded and $\\mathcal{G}\\otimes\\mathcal{B}({\\mathbb{R}}^d) $-measurable,\nand $U\\dvtx  \\Omega\\rightarrow{\\mathbb{R}}^d$ be $\\mathcal{H}$-measurable.\nThen,\n$ {\\mathbb{E}}[F(U) \\mid\\mathcal{H}] = j({U})$ where $j(h) = {\\mathbb{E}}[F(h)]$ for\nall $h \\in\n{\\mathbb{R}}^d$.\n\\end{lemma}\n\n\nLeast-squares regression has its traditional implementation in\nnonparametric statistics and signal processing \\cite\n{gyorkohlkrzywalk02}. In the traditional setting, the random object\nis a pair of random variables {$(O,R)$ termed the ``observation'' $O$\nand the ``response'' $R$. $R$ is considered to be some function of\n$O$,} with the possible addition of noise, and one needs recover this function.\nThere are three important differences in the use of least-squares\nregression methods in our setting, and for this reason we give a\ndefinition of (ordinary) least-squares regression (OLS) that enables us\n{to }approach our problems.\nFirst, the {response} we consider is a nonlinear transformation of the\n\\emph{paths} of the Markov chain $X$ and the Malliavin weights $H$. We\nare able {to simulate observations and responses (active learning)}\n\nand we know the nonlinear function; what is unknown is the regression\nfunction\n\n\n, that is, the conditional expectation.\nTherefore, OLS is defined in a way that easily enables path-dependence\nand joint laws by defining the path of the Markov chain and Malliavin\nweights as a single random variable, ${\\mathcal{X}}$, with law $\\nu$. Secondly,\nsince we are in a dynamical setting, least-squares regressions will be\ncomputed using independent clouds of simulations on each point of the time-grid.\nThis causes a dependence on an additional source of randomness in the\nobservations, namely the cloud of simulations from the preceding computations.\nTherefore, OLS is defined to depend on \\emph{two} probability spaces:\none for the preceding clouds $(\\tilde\\Omega,\\tilde\\mathcal\n{F},\\tilde{\\mathbb{P}})$,\nand one for the current cloud {distribution} $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}\n^l),\\nu)$.\nFinally, we will make use of both general probability measures\n(associated to the joint-law of the Markov chain and Malliavin weights)\nand empirical measures.\nThe use of simulations to generate the empirical measure creates\ndependency issues that are avoided when using laws, whence we make two\ndistinct definitions depending on which measure is in use.\nWe recall the {general} notation of \\cite{gobeturk14}, Section~4.1,\nfor ordinary least-squares regression problems.\n\n\\begin{definition}[(Ordinary least-squares regression)]\\label{defls}\nFor $l,l'\\geq1$ and for probability spaces $(\\tilde\\Omega,\\tilde\n\\mathcal{F},\\tilde{\\mathbb{P}})$ and $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}^l),\\nu)$,\nlet $S$ be a $\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable\n${\\mathbb{R}}^{l'}$-valued function such that $S(\\omega,\\cdot) \\in{\\mathbf{L}}\n_2(\\mathcal{B}\n({\\mathbb{R}}\n^l),\\nu)$ for $\\tilde{\\mathbb{P}}$-a.e. $\\omega\\in\\tilde\\Omega$,\nand $\\mathcal{K}_{}$ a linear vector subspace of ${\\mathbf{L}}_2(\\mathcal\n{B}({\\mathbb{R}}\n^l),\\nu)$\nspanned by deterministic ${\\mathbb{R}}^{l'}$-valued functions $\\{p_k(\\cdot ), k\\geq\n1\\}$.\nThe least-squares approximation of $S$ in the space $\\mathcal{K}_{}$ with\nrespect to $\\nu$ is the ($\\tilde{\\mathbb{P}}\\times\\nu$-a.e.) unique,\n$\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable function\n$S^\\star$\ngiven by\n\n\n\n", "itemtype": "equation", "pos": 39810, "prevtext": "\n\nfor an explicit, time uniform constant ${C_{y,z}}$.\nIt may, however, be useful to take advantage of additional information\non $\\xi$, {to obtain finer estimates on $C_{y,i}$ and $C_{z,i}$ with\nthe aim\nof better tuning the parameters of the MWLS method (see Section~\\ref\n{sectioncomplexity}).}\nTwo situations are of particular interest.\n\n\\begin{itemize}\n\n\\item For zero terminal condition, $Y$ and $Z$ get smaller and smaller\nas $t_i$ goes to $T$ as expected:\n${\\vert} Y_i{\\vert}+\\sqrt{T-t_i}{\\vert} Z_i{\\vert}\n\\leq C(T-t_i)^{{\\theta_c}}$ for a constant $C$\ndepending only on $\\aprioriConst2y$, $\\aprioriConst2z$, $C_f$,\n${\\theta_c}$ and $R_\\pi$.\n\nThis result is useful for variance reduction methods like the proxy\nmethod of \\cite{gobeturk14}, Section~2.2, the method of Martingale basis\n\\cite{bendstei12}, and the multilevel method of \\cite{turk13}.\n\n\\item Under {$(\\mathbf{A''_{\\bolds{\\xi}}})$}, we have ${\\vert}\\xi-{\\mathbb{E}}_i\\xi{\\vert}\n_{2,i}\\leq C_\\Phi\n(T-t_i)^{{\\theta_\\Phi}/2}$, which leads to an improved estimate for $Z$:\n${\\vert} Z_i{\\vert}\\le C (T-t_i)^{-{{1}/2} + {\\theta_c}\\land\n({{{\\theta_\\Phi}}/2})} $ for\nsome constant $C$ depending only on $\\aprioriConst1z$, $\\aprioriConst2z$,\n$\\aprioriConst3z$, $C_f$, ${\\theta_c}$, $R_\\pi$, $T$, $C_\\xi$ and\n$C_\\Phi$.\n\\end{itemize}\n\nThis is why in the subsequent analysis, we keep track on the general\ndependence on $i$ of the constants $C_{y,i}$ and $C_{z,i}$.\n\n\n\\begin{pf*}{Proof of Corollary~\\ref{coras}}\n$(0,0)$ is the solution of the {MWDP} with data $(\\xi_1 \\equiv0,\nf_{1,i} \\equiv0)$.\nApplying Proposition~\\ref{propstability} with $(Y_1,Z_1) = (0,0)$ and\n$(Y_2,Z_2)=(Y,Z)$ yields\n\n\\begin{eqnarray}\n{\\vert} Y_i{\\vert}_{2,k} & \\le& C^{(1)}_{y}\n{\\vert}\\xi{\\vert}_{2,k} + C^{(2)}_{y}\\sum\n_{j=i}^{N-1}\\bigl{\\vert} f_j(0,0)\n\\bigr{\\vert}_{2,k} \\Delta_j,\n\\nonumber\n\\\\\n{\\vert} Z_i{\\vert}_{2,k} & \\le&\\frac{ C^{(1)}_{z}{\\vert}\n\\xi- \\mathbb{E}_i\\xi\n{\\vert}_{2,k}}{\\sqrt{T-t_i}} +\nC^{(2)}_{z} \\sum_{j=i+1}^{N-1}\n\\frac{{\\vert} f_j(0,0){\\vert}_{2,k}}{\\sqrt\n{t_j-t_i}} \\Delta_j+ C^{(3)}_{z}\n{\\vert}\\xi{\\vert}_{2,k}(T-t_{i})^{{{ {\\theta_L} }/{2 }}},\n\\nonumber\n\\end{eqnarray}\n\nfor $i=0,\\ldots,N-1$.\nTaking $k=i$, plugging in the almost sure bounds on ${\\vert}\\xi\n{\\vert}$\nfrom {$(\\mathbf{A'_{\\bolds{\\xi}}})$\\textup{(i)}}~and ${\\vert} f_j(0,0){\\vert}$ from {$(\\mathbf{A_F})$\\textup{(ii)}}, and\nusing Lemma~\\ref{lemintegrals}\nthen yields the result.\n\n\n\n\n\n\\end{pf*}\n\n\n\n\n\\section{Monte Carlo regression scheme}\\label{section4MC}\n\n\n\n\n\n\nThroughout this section, the Markovian assumptions {$(\\mathbf{A_X})$}, {$(\\mathbf{A'_{\\bolds{\\xi}}})$}, {$(\\mathbf{A'_F})$}~and\n{$(\\mathbf{A'_H})$}~are in force. The notation and preliminary results used in\nthis section overlap with \\cite{gobeturk14}, Section~4, and we recall\nand adapt them to the setting of MWLS in Section~\\ref\n{sectionMCprelims} for completeness.\n\n\n\\subsection{Preliminaries}\\label{sectionMCprelims}\n{An elegant property of} the Markovian assumptions is there are\nmeasurable, deterministic (but unknown) functions $y_i(\\cdot)\\dvtx  {\\mathbb{R}}^d\n\\rightarrow{\\mathbb{R}}$ and\n$z_i(\\cdot)\\dvtx  {\\mathbb{R}}^d \\rightarrow({\\mathbb{R}}^q)^\\top$ for each $i \\in\\{\n0,\\ldots,N-1\\}$\nsuch that the solution $(Y_i,Z_i)_{0\\le i \\le N-1}$ of the discrete\nBSDE (\\ref{eqmalscheme}) is given by\n\n\n\n", "index": 25, "text": "\\begin{equation}\n(Y_{i},Z_i):= \\bigl(y_i(X_{i}),z_i(X_{i})\n\\bigr). \\label{eqmarkov}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"(Y_{i},Z_{i}):=\\bigl{(}y_{i}(X_{i}),z_{i}(X_{i})\\bigr{)}.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>,</mo><msub><mi>Z</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>:=</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nWe say that $S^\\star$ solves ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu)$.\n\n{On the other hand, suppose that $\\nu_M=\\frac{1}M \\sum_{m=1}^M \\delta\n_{{\\mathcal{X}}^{(m)}}$ is a discrete probability measure\non $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}^l))$,\nwhere $\\delta_x$ is the Dirac measure on $x$ and ${\\mathcal{X}}^{(1)},\\ldots,{\\mathcal{X}}\n^{(M)}\\dvtx  \\tilde\\Omega\\rightarrow{\\mathbb{R}}^l$ are i.i.d. random variables.\nFor an $\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable ${\\mathbb{R}}\n^{l'}$-valued\nfunction $S$ such that ${\\vert} S (\\omega,{\\mathcal{X}}^{(m)}(\\omega\n)\n){\\vert}<\n\\infty$ for any $m$ and $\\tilde{\\mathbb{P}}$-a.e. $\\omega\\in\\tilde\\Omega$,\nthe least-squares approximation of $S$ in the space $\\mathcal{K}_{}$ with\nrespect to $\\nu_M$ is the ($\\tilde{\\mathbb{P}}$-a.e.) unique,\n$\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable function\n$S^\\star\n$ given by\n\n\n\n", "itemtype": "equation", "pos": 44371, "prevtext": "\n\n{In this section, we estimate these functions.} \n\n\nOne needs to apply Lemma~\\ref{lemcdnexp}\n{below} combined with\n$\\mathcal{G}= \\mathcal{G}_i$ -- defined in the assumptions {$(\\mathbf{A_X})$}~and\n{$(\\mathbf{A'_H})$}~-- $U =\nX_i$, and\n\n\\begin{eqnarray*}\nF(x) &:=& \\Phi\\bigl({ V^{(i)}_{N} }(x)\\bigr) + \\sum_{k=i}^{N-1}\nf_k \\bigl({ V^{(i)}_{k} }(x),y_{k+1}\\bigl({ V^{(i)}_{{k+1}} }\n(x)\\bigr), z_k\\bigl({ V^{(i)}_{k} } (x)\\bigr) \\bigr)\\Delta\n_k\\qquad\\mbox{for } y_i(\\cdot),\n\\end{eqnarray*}\nand\n\\begin{eqnarray*}\nF(x) &:=& \\Phi\\bigl({ V^{(i)}_{N} }(x)\\bigr) { \\mathpzc{h}^{(i)}_{N} }(x)\n\\\\\n&&{} + \\sum\n_{k=i+1}^{N-1} f_k \\bigl({ V^{(i)}_{k} }(x), y_{k+1}\\bigl({ V^{(i)}_{{k+1}} } (x)\\bigr), z_k\\bigl(\n{ V^{(i)}_{k} } (x)\\bigr) \\bigr) { \\mathpzc{h}^{(i)}_{k} }(x)\\Delta_k\\qquad\\mbox{for\n} z_i(\\cdot).\n\\end{eqnarray*}\n\n\\begin{lemma}[(\\cite{gobeturk14}, Lemma 4.1)]\n\n\\label{lemcdnexp}\nSuppose that $\\mathcal{G}$ and $\\mathcal{H}$ are independent\nsub-$\\sigma\n$-algebras of\n$\\mathcal{F}$.\n{For $l \\ge1$,} let $F\\dvtx  \\Omega\\times{\\mathbb{R}}^d \\rightarrow{{\\mathbb{R}}^l}$ be\nbounded and $\\mathcal{G}\\otimes\\mathcal{B}({\\mathbb{R}}^d) $-measurable,\nand $U\\dvtx  \\Omega\\rightarrow{\\mathbb{R}}^d$ be $\\mathcal{H}$-measurable.\nThen,\n$ {\\mathbb{E}}[F(U) \\mid\\mathcal{H}] = j({U})$ where $j(h) = {\\mathbb{E}}[F(h)]$ for\nall $h \\in\n{\\mathbb{R}}^d$.\n\\end{lemma}\n\n\nLeast-squares regression has its traditional implementation in\nnonparametric statistics and signal processing \\cite\n{gyorkohlkrzywalk02}. In the traditional setting, the random object\nis a pair of random variables {$(O,R)$ termed the ``observation'' $O$\nand the ``response'' $R$. $R$ is considered to be some function of\n$O$,} with the possible addition of noise, and one needs recover this function.\nThere are three important differences in the use of least-squares\nregression methods in our setting, and for this reason we give a\ndefinition of (ordinary) least-squares regression (OLS) that enables us\n{to }approach our problems.\nFirst, the {response} we consider is a nonlinear transformation of the\n\\emph{paths} of the Markov chain $X$ and the Malliavin weights $H$. We\nare able {to simulate observations and responses (active learning)}\n\nand we know the nonlinear function; what is unknown is the regression\nfunction\n\n\n, that is, the conditional expectation.\nTherefore, OLS is defined in a way that easily enables path-dependence\nand joint laws by defining the path of the Markov chain and Malliavin\nweights as a single random variable, ${\\mathcal{X}}$, with law $\\nu$. Secondly,\nsince we are in a dynamical setting, least-squares regressions will be\ncomputed using independent clouds of simulations on each point of the time-grid.\nThis causes a dependence on an additional source of randomness in the\nobservations, namely the cloud of simulations from the preceding computations.\nTherefore, OLS is defined to depend on \\emph{two} probability spaces:\none for the preceding clouds $(\\tilde\\Omega,\\tilde\\mathcal\n{F},\\tilde{\\mathbb{P}})$,\nand one for the current cloud {distribution} $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}\n^l),\\nu)$.\nFinally, we will make use of both general probability measures\n(associated to the joint-law of the Markov chain and Malliavin weights)\nand empirical measures.\nThe use of simulations to generate the empirical measure creates\ndependency issues that are avoided when using laws, whence we make two\ndistinct definitions depending on which measure is in use.\nWe recall the {general} notation of \\cite{gobeturk14}, Section~4.1,\nfor ordinary least-squares regression problems.\n\n\\begin{definition}[(Ordinary least-squares regression)]\\label{defls}\nFor $l,l'\\geq1$ and for probability spaces $(\\tilde\\Omega,\\tilde\n\\mathcal{F},\\tilde{\\mathbb{P}})$ and $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}^l),\\nu)$,\nlet $S$ be a $\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable\n${\\mathbb{R}}^{l'}$-valued function such that $S(\\omega,\\cdot) \\in{\\mathbf{L}}\n_2(\\mathcal{B}\n({\\mathbb{R}}\n^l),\\nu)$ for $\\tilde{\\mathbb{P}}$-a.e. $\\omega\\in\\tilde\\Omega$,\nand $\\mathcal{K}_{}$ a linear vector subspace of ${\\mathbf{L}}_2(\\mathcal\n{B}({\\mathbb{R}}\n^l),\\nu)$\nspanned by deterministic ${\\mathbb{R}}^{l'}$-valued functions $\\{p_k(\\cdot ), k\\geq\n1\\}$.\nThe least-squares approximation of $S$ in the space $\\mathcal{K}_{}$ with\nrespect to $\\nu$ is the ($\\tilde{\\mathbb{P}}\\times\\nu$-a.e.) unique,\n$\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable function\n$S^\\star$\ngiven by\n\n\n\n", "index": 27, "text": "\\begin{equation}\n\\label{eqmcmls} S^\\star(\\omega, \\cdot):=\\arg\\inf_{\\phi\\in\\mathcal{K}_{} }\n\\int\\bigl{\\vert}\\phi(x) - S(\\omega,x) \\bigr{\\vert}^2 \\nu(\\mathrm{d}x).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"S^{\\star}(\\omega,\\cdot):=\\arg\\inf_{\\phi\\in\\mathcal{K}}\\int\\bigl{|}\\phi(x)-S(%&#10;\\omega,x)\\bigr{|}^{2}\\nu(\\mathrm{d}x).\" display=\"block\"><mrow><mrow><mrow><msup><mi>S</mi><mo>\u22c6</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo>,</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mi>arg</mi><mo>\u2062</mo><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>\u03d5</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><mo>\u2061</mo><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo>,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><mi>\u03bd</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi mathvariant=\"normal\">d</mi><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nWe say that $S^\\star$ solves ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu_M)$.\n}\n\\end{definition}\n\nFrom (\\ref{eqmarkov}),\nthe {MWDP} (\\ref{eqmalscheme}) can be reformulated in terms of\nDefinition~\\ref{defls}: taking for $\\mathcal{K}_{i}^{(l')}$ any dense\nsubset {in the ${\\mathbb{R}}^{l'}$-valued functions belonging to ${\\mathbf{L}}_2(\\mathcal\n{B}({\\mathbb{R}}^d), {\\mathbb{P}}\\circ(X_i)^{-1} )$,}\nfor each $i\\in\\{0,\\ldots,N-1\\}$,\n\n\n\n\\begin{eqnarray}\\label{eqMDPlsdef}\n\\cases{ \\displaystyle y_i(\\cdot) \\mbox{ solves } {\\mathrm{OLS}}\\bigl(\n{S_{{Y,i}}\\bigl({{{\\mathbf{\\underline{{x}} } }^{(i)}}}\\bigr)}, \\mathcal{K}_{i}^{(1)}, \\nu_{i} \\bigr),\n\\cr\n\\quad\\displaystyle\\mbox{for } {S_{{Y,i}}\\bigl({ {\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:= \\Phi(x_N) + \\sum\n_{k=i}^{N-1} f_k \\bigl(x_k,y_{k+1}(x_{k+1}),\nz_k(x_k) \\bigr)\\Delta_k,\n\\cr\nz_i(\\cdot) \\mbox{ solves } {\\mathrm{OLS}}\\bigl( {S_{{Z,i}}\\bigl({ {\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}, \\mathcal{K}_{i}^{(q)}, \\nu_{i} \\bigr),\n\\cr\n\\quad\\displaystyle\\mbox{for } {S_{{Z,i}}\\bigl({ {\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:= \\Phi(x_N)h_N\n+ \\sum_{{k=i+1}}^{N-1} f_k\n\\bigl(x_k,y_{k+1}(x_{k+1}), z_k(x_k)\n\\bigr) h_k \\Delta_k,}\n\\end{eqnarray}\n\\begin{eqnarray}\n\\nu_{i}&:=& {\\mathbb{P}}\\circ\\bigl({H^{(i)}_{{i+1}}},\\ldots, {{H^{(i)}_{{N}}}},X_i,\\ldots,X_N\\bigr)^{-1},\n\\nonumber\\[-8pt]\\label{eqvecxhvecxh}\\[-8pt]\\nonumber\n{\\mathbf{\\underline{{h}} } }^{(i)}&:=&(h_{i+1},\\ldots,{h_{N}})\n\\in\\bigl(\\bigl({\\mathbb{R}}^q\\bigr)^\\top\\bigr)^{{N-i}},\n\\qquad{\\mathbf{\\underline{{x}} } }^{(i)}:= (x_i,\\ldots,x_N) \\in\n\\bigl({\\mathbb{R}}^d\\bigr)^{N-i+1}.\n\\end{eqnarray}\n\n\n\n\n\nHowever, the above least-squares regressions encounter two\ncomputational problems:\n\n\\begin{longlist}[(\\textbf{CP1})]\n\n\\item[(\\textbf{CP1})] ${\\mathbf{L}}_2(\\mathcal{B}({{\\mathbb{R}}^d}),{\\mathbb{P}}\\circ(X_i )^{-1})$\nis usually\ninfinite dimensional;\n\n\\item[(\\textbf{CP2})] the integrals of the ${\\mathrm{OLS}}$~in (\\ref{eqMDPlsdef})\nare presumably computed using the untractable law of\n\n", "itemtype": "equation", "pos": 45458, "prevtext": "\n\nWe say that $S^\\star$ solves ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu)$.\n\n{On the other hand, suppose that $\\nu_M=\\frac{1}M \\sum_{m=1}^M \\delta\n_{{\\mathcal{X}}^{(m)}}$ is a discrete probability measure\non $({\\mathbb{R}}^l,\\mathcal{B}({\\mathbb{R}}^l))$,\nwhere $\\delta_x$ is the Dirac measure on $x$ and ${\\mathcal{X}}^{(1)},\\ldots,{\\mathcal{X}}\n^{(M)}\\dvtx  \\tilde\\Omega\\rightarrow{\\mathbb{R}}^l$ are i.i.d. random variables.\nFor an $\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable ${\\mathbb{R}}\n^{l'}$-valued\nfunction $S$ such that ${\\vert} S (\\omega,{\\mathcal{X}}^{(m)}(\\omega\n)\n){\\vert}<\n\\infty$ for any $m$ and $\\tilde{\\mathbb{P}}$-a.e. $\\omega\\in\\tilde\\Omega$,\nthe least-squares approximation of $S$ in the space $\\mathcal{K}_{}$ with\nrespect to $\\nu_M$ is the ($\\tilde{\\mathbb{P}}$-a.e.) unique,\n$\\tilde\\mathcal{F}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable function\n$S^\\star\n$ given by\n\n\n\n", "index": 29, "text": "\\begin{equation}\n\\label{eqmclsempi} S^\\star(\\omega, \\cdot):= \\arg\\inf_{\\phi\\in\\mathcal\n{K}_{} }\n\\frac{1}M \\sum_{m=1}^M \\bigl\n{\\vert}\\phi\\bigl({\\mathcal{X}}^{(m)}(\\omega) \\bigr) - S \\bigl(\\omega,\n{\\mathcal{X}}^{(m)}(\\omega) \\bigr) \\bigr{\\vert}^2.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"S^{\\star}(\\omega,\\cdot):=\\arg\\inf_{\\phi\\in\\mathcal{K}}\\frac{1}{M}\\sum_{m=1}^{M%&#10;}\\bigl{|}\\phi\\bigl{(}{\\mathcal{X}}^{(m)}(\\omega)\\bigr{)}-S\\bigl{(}\\omega,{%&#10;\\mathcal{X}}^{(m)}(\\omega)\\bigr{)}\\bigr{|}^{2}.\" display=\"block\"><mrow><mrow><mrow><msup><mi>S</mi><mo>\u22c6</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo>,</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mi>arg</mi><mo>\u2062</mo><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>\u03d5</mi><mo>\u2208</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi></mrow></munder><mo>\u2061</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mi>\u03c9</mi><mo>,</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c9</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\end{longlist}\n\nTherefore, the functions $y_i(\\cdot)$ and $z_i(\\cdot)$ are to be\napproximated on\nfinite-dimensional function spaces with the sample-based empirical\nversion of the law, as described in the next subsection.\n\n\n\\subsection{Algorithm}\\label{sectionMCalg}\nThe first computational problem (\\textbf{CP1}) is handled using a pre-selected\n\\emph{finite-dimensional vector spaces}.\n\n\\begin{definition}[(Finite-dimensional approximation spaces)]\\label\n{deffindimspace}\nFor\n$i\\in\\{0,\\ldots, N-1\\}$, we are given two finite functional linear\nspaces of dimension $K_{Y,i}$ and $K_{Z,i}$\n\n", "itemtype": "equation", "pos": 47775, "prevtext": "\n\nWe say that $S^\\star$ solves ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu_M)$.\n}\n\\end{definition}\n\nFrom (\\ref{eqmarkov}),\nthe {MWDP} (\\ref{eqmalscheme}) can be reformulated in terms of\nDefinition~\\ref{defls}: taking for $\\mathcal{K}_{i}^{(l')}$ any dense\nsubset {in the ${\\mathbb{R}}^{l'}$-valued functions belonging to ${\\mathbf{L}}_2(\\mathcal\n{B}({\\mathbb{R}}^d), {\\mathbb{P}}\\circ(X_i)^{-1} )$,}\nfor each $i\\in\\{0,\\ldots,N-1\\}$,\n\n\n\n\\begin{eqnarray}\\label{eqMDPlsdef}\n\\cases{ \\displaystyle y_i(\\cdot) \\mbox{ solves } {\\mathrm{OLS}}\\bigl(\n{S_{{Y,i}}\\bigl({{{\\mathbf{\\underline{{x}} } }^{(i)}}}\\bigr)}, \\mathcal{K}_{i}^{(1)}, \\nu_{i} \\bigr),\n\\cr\n\\quad\\displaystyle\\mbox{for } {S_{{Y,i}}\\bigl({ {\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:= \\Phi(x_N) + \\sum\n_{k=i}^{N-1} f_k \\bigl(x_k,y_{k+1}(x_{k+1}),\nz_k(x_k) \\bigr)\\Delta_k,\n\\cr\nz_i(\\cdot) \\mbox{ solves } {\\mathrm{OLS}}\\bigl( {S_{{Z,i}}\\bigl({ {\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}, \\mathcal{K}_{i}^{(q)}, \\nu_{i} \\bigr),\n\\cr\n\\quad\\displaystyle\\mbox{for } {S_{{Z,i}}\\bigl({ {\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:= \\Phi(x_N)h_N\n+ \\sum_{{k=i+1}}^{N-1} f_k\n\\bigl(x_k,y_{k+1}(x_{k+1}), z_k(x_k)\n\\bigr) h_k \\Delta_k,}\n\\end{eqnarray}\n\\begin{eqnarray}\n\\nu_{i}&:=& {\\mathbb{P}}\\circ\\bigl({H^{(i)}_{{i+1}}},\\ldots, {{H^{(i)}_{{N}}}},X_i,\\ldots,X_N\\bigr)^{-1},\n\\nonumber\\[-8pt]\\label{eqvecxhvecxh}\\[-8pt]\\nonumber\n{\\mathbf{\\underline{{h}} } }^{(i)}&:=&(h_{i+1},\\ldots,{h_{N}})\n\\in\\bigl(\\bigl({\\mathbb{R}}^q\\bigr)^\\top\\bigr)^{{N-i}},\n\\qquad{\\mathbf{\\underline{{x}} } }^{(i)}:= (x_i,\\ldots,x_N) \\in\n\\bigl({\\mathbb{R}}^d\\bigr)^{N-i+1}.\n\\end{eqnarray}\n\n\n\n\n\nHowever, the above least-squares regressions encounter two\ncomputational problems:\n\n\\begin{longlist}[(\\textbf{CP1})]\n\n\\item[(\\textbf{CP1})] ${\\mathbf{L}}_2(\\mathcal{B}({{\\mathbb{R}}^d}),{\\mathbb{P}}\\circ(X_i )^{-1})$\nis usually\ninfinite dimensional;\n\n\\item[(\\textbf{CP2})] the integrals of the ${\\mathrm{OLS}}$~in (\\ref{eqMDPlsdef})\nare presumably computed using the untractable law of\n\n", "index": 31, "text": "\n\\[\n\\bigl({H^{(i)}_{{i+1}}},\\ldots, {{H^{(i)}_{{N}}}},X_i,\\ldots,X_N\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\bigl{(}{H^{(i)}_{{i+1}}},\\ldots,{{H^{(i)}_{{N}}}},X_{i},\\ldots,X_{N}\\bigr{)}.\" display=\"block\"><mrow><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msubsup><mi>H</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msubsup><mi>H</mi><mi>N</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msub><mi>X</mi><mi>i</mi></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>X</mi><mi>N</mi></msub><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nThe function $y_i(\\cdot)$ (resp., $z_{i}(\\cdot)$) will be approximated\nin the linear space $\\mathcal{K}_{Y,i}$ (resp., $\\mathcal{K}_{Z,i}$).\nThe best approximation errors are defined by\n\n\n\n", "itemtype": "equation", "pos": 48442, "prevtext": "\n\n\\end{longlist}\n\nTherefore, the functions $y_i(\\cdot)$ and $z_i(\\cdot)$ are to be\napproximated on\nfinite-dimensional function spaces with the sample-based empirical\nversion of the law, as described in the next subsection.\n\n\n\\subsection{Algorithm}\\label{sectionMCalg}\nThe first computational problem (\\textbf{CP1}) is handled using a pre-selected\n\\emph{finite-dimensional vector spaces}.\n\n\\begin{definition}[(Finite-dimensional approximation spaces)]\\label\n{deffindimspace}\nFor\n$i\\in\\{0,\\ldots, N-1\\}$, we are given two finite functional linear\nspaces of dimension $K_{Y,i}$ and $K_{Z,i}$\n\n", "index": 33, "text": "\n\\[\n\\cases{ \\mathcal{K}_{Y,i}:= \\operatorname{span}\\bigl\\{{p_{{Y,i}}^{(1)} },\\ldots, {p_{{Y,i}}^{({K_{Y,i} })} } \\bigr\\}, &\\quad for ${p_{{Y,i}}^{(k)} }\\dvtx {\\mathbb{R}}^d \\rightarrow {\\mathbb{R}}$ s.t. $\\mathbb{E}\\bigl[\\bigl{\\vert}{p^{(k)}_{{Y,i}}({X_i}) }\\bigr{\\vert}\n^2\\bigr] < +\\infty$,\n\\vspace*{5pt}\\cr\n\\mathcal{K}_{Z,i}:= \\operatorname{span}\\bigl\\{\n{p_{{Z,i}}^{(1)} },\\ldots, {p_{{Z,i}}^{({K_{Z,i} })} } \\bigr\\}, & \\quad for ${p_{{Z,i}}^{(k)} }\\dvtx\n{\\mathbb{R}}^d \\rightarrow{\\bigl({\\mathbb{R}}^q\\bigr)^\\top}$ s.t. $\\mathbb{E}\\bigl[\\bigl{\\vert}{p^{(k)}_{{Z,i}}({X_i}) }\\bigr{\\vert}\n^2\\bigr] < +\\infty$.}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\cases{\\mathcal{K}_{Y,i}:=\\operatorname{span}\\bigl{\\{}{p_{{Y,i}}^{(1)}},\\ldots%&#10;,{p_{{Y,i}}^{({K_{Y,i}})}}\\bigr{\\}},&amp;\\quad for ${p_{{Y,i}}^{(k)}}\\dvtx{\\mathbb%&#10;{R}}^{d}\\rightarrow{\\mathbb{R}}$ s.t. $\\mathbb{E}\\bigl{[}\\bigl{|}{p^{(k)}_{{Y,%&#10;i}}({X_{i}})}\\bigr{|}^{2}\\bigr{]}&lt;+\\infty$,\\cr\\mathcal{K}_{Z,i}:=\\operatorname%&#10;{span}\\bigl{\\{}{p_{{Z,i}}^{(1)}},\\ldots,{p_{{Z,i}}^{({K_{Z,i}})}}\\bigr{\\}},&amp;%&#10;\\quad for ${p_{{Z,i}}^{(k)}}\\dvtx{\\mathbb{R}}^{d}\\rightarrow{\\bigl{(}{\\mathbb{%&#10;R}}^{q}\\bigr{)}^{\\top}}$ s.t. $\\mathbb{E}\\bigl{[}\\bigl{|}{p^{(k)}_{{Z,i}}({X_{%&#10;i}})}\\bigr{|}^{2}\\bigr{]}&lt;+\\infty$.}\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>:=</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\operatorname</mtext></merror><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><msubsup><mi>p</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msubsup><mi>p</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi>K</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></msubsup><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow/><mo separator=\"true\">\u2003</mo><mrow><mtext>for\u00a0</mtext><mrow><mrow><msubsup><mi>p</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\dvtx</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><mo>\u2192</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>R</mi></mrow></mrow><mtext>\u00a0s.t.\u00a0</mtext><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msubsup><mi>p</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo>&lt;</mo><mrow><mo>+</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></mrow><mtext>,</mtext></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>:=</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\operatorname</mtext></merror><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><msubsup><mi>p</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msubsup><mi>p</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi>K</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></msubsup><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow/><mo separator=\"true\">\u2003</mo><mrow><mtext>for\u00a0</mtext><mrow><mrow><msubsup><mi>p</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\dvtx</mtext></merror><mo>\u2062</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><mo>\u2192</mo><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msup><mi>R</mi><mi>q</mi></msup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u22a4</mo></msup></mrow><mtext>\u00a0s.t.\u00a0</mtext><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msubsup><mi>p</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo>&lt;</mo><mrow><mo>+</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></mrow><mtext>.</mtext></mrow></mrow></mtd></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\end{definition}\n\nThe second computational problem (\\textbf{CP2}) is solved using the \\emph{empirical} measure built from independent simulations with distribution\n$\\nu_i$.\n{The number of simulations is large enough to avoid having\nunder-determined systems of equations to solve.}\n\n\n\n\\begin{definition}[(Simulations and empirical measures)]\\label{defsimsandempi}\nFor $i\\in\\{0,\\ldots,N-1\\}$, generate $M_i\\geq K_{Y,i} \\vee\nK_{Z,i}$ independent copies $\\mathcal{C}_i:= \\{( {H^{({i,m})}_{{ }}},{X^{({i,m})}_{{}}} )\\dvt\nm = 1,\\ldots,M_i \\}$\nof $({H^{(i)}_{{ }}},X^{(i)}):=({H^{(i)}_{{i+1}}},\\ldots, {{H^{(i)}_{{N}}}},X_i,\\ldots,X_N)$:\n$\\mathcal{C}_i$ forms a \\emph{cloud of simulations} used for the\nregression at time~$i$.\nDenote by $\\nu_{i,M}$ the empirical probability measure of the\n$\\mathcal{C}\n_i$-simulations,\nthat is,\n\n\n\n", "itemtype": "equation", "pos": 49246, "prevtext": "\n\nThe function $y_i(\\cdot)$ (resp., $z_{i}(\\cdot)$) will be approximated\nin the linear space $\\mathcal{K}_{Y,i}$ (resp., $\\mathcal{K}_{Z,i}$).\nThe best approximation errors are defined by\n\n\n\n", "index": 35, "text": "\n\\[\n\\mathcal{E}^Y_{\\mathrm{App.},i}:= \\sqrt{\\inf_{ \\phi\\in\\mathcal{K}_{Y,i}\n}\n\\mathbb{E} \\bigl[ \\bigl{\\vert}\\phi(X_i) - y_i(X_i)\n\\bigr{\\vert}^2 \\bigr]}, \\qquad\\mathcal{E}^Z_{\\mathrm{App.},i}:= \\sqrt\n{\\inf_{ \\phi\\in\\mathcal{K}_{Z,i}\n}\\mathbb{E} \\bigl[ \\bigl{\\vert}\n\\phi(X_i) - z_i(X_i)\\bigr{\\vert}\n^2 \\bigr]}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{E}^{Y}_{\\mathrm{App.},i}:=\\sqrt{\\inf_{\\phi\\in\\mathcal{K}_{Y,i}}%&#10;\\mathbb{E}\\bigl{[}\\bigl{|}\\phi(X_{i})-y_{i}(X_{i})\\bigr{|}^{2}\\bigr{]}},\\qquad%&#10;\\mathcal{E}^{Z}_{\\mathrm{App.},i}:=\\sqrt{\\inf_{\\phi\\in\\mathcal{K}_{Z,i}}%&#10;\\mathbb{E}\\bigl{[}\\bigl{|}\\phi(X_{i})-z_{i}(X_{i})\\bigr{|}^{2}\\bigr{]}}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2130</mi><mrow><mi>App</mi><mo>.</mo><mo>,</mo><mi>i</mi></mrow><mi>Y</mi></msubsup><mo>:=</mo><msqrt><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>\u03d5</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></munder><mo>\u2061</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mrow></msqrt></mrow><mo rspace=\"22.5pt\">,</mo><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2130</mi><mrow><mi>App</mi><mo>.</mo><mo>,</mo><mi>i</mi></mrow><mi>Z</mi></msubsup><mo>:=</mo><msqrt><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>\u03d5</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></munder><mo>\u2061</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><mrow><mi>\u03d5</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mrow></msqrt></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nFurthermore, we assume that the clouds of simulations $(\\mathcal\n{C}_i\\dvt 0\\leq i <\nN)$ are independently generated. All these random variables are defined\non a probability space $({\\Omega^{(M)} }, {\\mathcal{F}^{(M)}_{{}}}, {{\\mathbb{P}}^{(M)} })$.\n\\end{definition}\n\nObserve that allowing time-dependency in the number of simulations\n$M_i$ and in the vector spaces $\\mathcal{K}_{Y,i}$ and $\\mathcal{K}_{Z,i}$\nis coherent with our setting of time-dependent local Lipschitz driver.\n\nDenoting by $(\\Omega, \\mathcal{F}, {\\mathbb{P}})$ the probability space supporting\n$({H^{({0})}_{{ }}},\\ldots,{H^{({N-1})}_{{ }}}, X)$, which serves as a generic element for\nthe clouds of simulations, the full probability space used to analyze\nour algorithm is the product space $(\\bar\\Omega, \\bar\\mathcal{F},\n\\bar{\\mathbb{P}}\n)=(\\Omega, \\mathcal{F},{\\mathbb{P}}) \\otimes({\\Omega^{(M)} }, {\\mathcal{F}^{(M)}_{{}}}, {{\\mathbb{P}}^{(M)} })$.\nBy a slight abuse of notation, we write ${\\mathbb{P}}$ (resp., ${\\mathbb{E}}$) to mean\n$\\bar{\\mathbb{P}}$ (resp., $\\bar{\\mathbb{E}}$) from now on.\n\nIn what follows, extensive {use} will be made of conditioning on the\nclouds of simulations. This is much in the spirit of the proof of\n\\cite{gobeturk14}, Theorem 4.11, and the arguments are based on the\nfollowing definition of $\\sigma$-algebras.\n\n\\begin{definition}\n\\label{defsimcnd}\nDefine the $\\sigma$-algebras\n\n", "itemtype": "equation", "pos": 50383, "prevtext": "\n\n\\end{definition}\n\nThe second computational problem (\\textbf{CP2}) is solved using the \\emph{empirical} measure built from independent simulations with distribution\n$\\nu_i$.\n{The number of simulations is large enough to avoid having\nunder-determined systems of equations to solve.}\n\n\n\n\\begin{definition}[(Simulations and empirical measures)]\\label{defsimsandempi}\nFor $i\\in\\{0,\\ldots,N-1\\}$, generate $M_i\\geq K_{Y,i} \\vee\nK_{Z,i}$ independent copies $\\mathcal{C}_i:= \\{( {H^{({i,m})}_{{ }}},{X^{({i,m})}_{{}}} )\\dvt\nm = 1,\\ldots,M_i \\}$\nof $({H^{(i)}_{{ }}},X^{(i)}):=({H^{(i)}_{{i+1}}},\\ldots, {{H^{(i)}_{{N}}}},X_i,\\ldots,X_N)$:\n$\\mathcal{C}_i$ forms a \\emph{cloud of simulations} used for the\nregression at time~$i$.\nDenote by $\\nu_{i,M}$ the empirical probability measure of the\n$\\mathcal{C}\n_i$-simulations,\nthat is,\n\n\n\n", "index": 37, "text": "\\begin{equation}\n\\label{eqempimeasure} \\nu_{i,M}:= \\frac{1}{M_i} \\sum\n_{m=1}^{M_i} \\delta_{({H^{({i,m})}_{{i+1}}},\\ldots,{{H^{({i,m})}_{{N}}}}, {X^{({i,m})}_{{i}}},\\ldots,{X^{({i,m})}_{N}} )}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\nu_{i,M}:=\\frac{1}{M_{i}}\\sum{}_{m=1}^{M_{i}}\\delta_{({H^{({i,m})}_{{i+1}}},%&#10;\\ldots,{{H^{({i,m})}_{{N}}}},{X^{({i,m})}_{{i}}},\\ldots,{X^{({i,m})}_{N}})}.\" display=\"block\"><mrow><mrow><msub><mi>\u03bd</mi><mrow><mi>i</mi><mo>,</mo><mi>M</mi></mrow></msub><mo>:=</mo><mrow><mfrac><mn>1</mn><msub><mi>M</mi><mi>i</mi></msub></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mmultiscripts><mi>\u03b4</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>H</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msubsup><mi>H</mi><mi>N</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>X</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msubsup><mi>X</mi><mi>N</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><none/><mprescripts/><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>M</mi><mi>i</mi></msub></mmultiscripts></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nFor every $i\\in\\{0,\\ldots,N-1\\}$, let\n${\\mathbb{E}}^M_i[\\cdot] $ (resp., ${\\mathbb{P}}^M_i$) with respect to ${\\mathcal{F}^{(M)}_{i}}$.\n\\end{definition}\n\nWe now come to the definition of the MWLS algorithm: this is merely\nthe finite-dimensional version of (\\ref{eqMDPlsdef}) plus a soft\ntruncation of the solutions using the truncation function $\\mathcal{T}_\\cdot(\\cdot )$\n(defined in Section~\\ref{sectionnotation}).\n\n\\begin{definition}[(MWLS algorithm)]\n\n\n\\label{defmwls} Set ${y^{(M)}_{{N}}({\\cdot})}:= \\Phi(\\cdot)$. For each\n$i=N-1,N-2,\\ldots,0$, set the random functions ${y^{(M)}_{i}(\\cdot)}$ and ${z^{(M)}_{i}(\\cdot)}$ recursively as follows.\n\n\\begin{enumerate}\n\n\\item First, define ${z^{(M)}_{i}(\\cdot)}:= \\mathcal{T}_{{C_{z,i}}} ( \\psi\n^{(M)}_{Z,i}(\\cdot)\n)$ where ${C_{z,i}}$ is the almost sure bound of Corollary~\\ref{coras}\nand where\n\n\n\n", "itemtype": "equation", "pos": 51975, "prevtext": "\n\nFurthermore, we assume that the clouds of simulations $(\\mathcal\n{C}_i\\dvt 0\\leq i <\nN)$ are independently generated. All these random variables are defined\non a probability space $({\\Omega^{(M)} }, {\\mathcal{F}^{(M)}_{{}}}, {{\\mathbb{P}}^{(M)} })$.\n\\end{definition}\n\nObserve that allowing time-dependency in the number of simulations\n$M_i$ and in the vector spaces $\\mathcal{K}_{Y,i}$ and $\\mathcal{K}_{Z,i}$\nis coherent with our setting of time-dependent local Lipschitz driver.\n\nDenoting by $(\\Omega, \\mathcal{F}, {\\mathbb{P}})$ the probability space supporting\n$({H^{({0})}_{{ }}},\\ldots,{H^{({N-1})}_{{ }}}, X)$, which serves as a generic element for\nthe clouds of simulations, the full probability space used to analyze\nour algorithm is the product space $(\\bar\\Omega, \\bar\\mathcal{F},\n\\bar{\\mathbb{P}}\n)=(\\Omega, \\mathcal{F},{\\mathbb{P}}) \\otimes({\\Omega^{(M)} }, {\\mathcal{F}^{(M)}_{{}}}, {{\\mathbb{P}}^{(M)} })$.\nBy a slight abuse of notation, we write ${\\mathbb{P}}$ (resp., ${\\mathbb{E}}$) to mean\n$\\bar{\\mathbb{P}}$ (resp., $\\bar{\\mathbb{E}}$) from now on.\n\nIn what follows, extensive {use} will be made of conditioning on the\nclouds of simulations. This is much in the spirit of the proof of\n\\cite{gobeturk14}, Theorem 4.11, and the arguments are based on the\nfollowing definition of $\\sigma$-algebras.\n\n\\begin{definition}\n\\label{defsimcnd}\nDefine the $\\sigma$-algebras\n\n", "index": 39, "text": "\n\\[\n{\\mathcal{F}^{(*)}_{i}}:= {\\sigma(\\mathcal{C}_{i+1},\\ldots,\\mathcal{C}_{N-1})},\n\\qquad{\\mathcal{F}^{({M})}_{i}}:= {\\mathcal{F}^{(*)}_{i}} \\vee\\sigma\\bigl({X^{({i,m})}_{{i}}}\\dvt  1 \\le m \\le M_i\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"{\\mathcal{F}^{(*)}_{i}}:={\\sigma(\\mathcal{C}_{i+1},\\ldots,\\mathcal{C}_{N-1})},%&#10;\\qquad{\\mathcal{F}^{({M})}_{i}}:={\\mathcal{F}^{(*)}_{i}}\\vee\\sigma\\bigl{(}{X^{%&#10;({i,m})}_{{i}}}\\dvt 1\\leq m\\leq M_{i}\\bigr{)}.\" display=\"block\"><mrow><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mo>*</mo><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>:=</mo><mi>\u03c3</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"22.5pt\">,</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>:=</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mo>*</mo><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2228</mo><mi>\u03c3</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msubsup><mi>X</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\dvt</mtext></merror><mn>1</mn><mo>\u2264</mo><mi>m</mi><mo>\u2264</mo><msub><mi>M</mi><mi>i</mi></msub><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nwhere ${\\mathbf{\\underline{{h}} } }^{(i)}, {\\mathbf{\\underline{{x}} } }^{(i)}, \\nu_{i,M}$ are defined in\n(\\ref{eqvecxhvecxh}) and (\\ref{eqempimeasure}).\n\n\\item Second and similarly, define ${y^{(M)}_{i}(\\cdot)}:= \\mathcal{T}_{{C_{y,i}}\n}\n(\\psi^{(M)}\n_{Y,i}(\\cdot) )$ where\n\n\n\n", "itemtype": "equation", "pos": 53032, "prevtext": "\n\nFor every $i\\in\\{0,\\ldots,N-1\\}$, let\n${\\mathbb{E}}^M_i[\\cdot] $ (resp., ${\\mathbb{P}}^M_i$) with respect to ${\\mathcal{F}^{(M)}_{i}}$.\n\\end{definition}\n\nWe now come to the definition of the MWLS algorithm: this is merely\nthe finite-dimensional version of (\\ref{eqMDPlsdef}) plus a soft\ntruncation of the solutions using the truncation function $\\mathcal{T}_\\cdot(\\cdot )$\n(defined in Section~\\ref{sectionnotation}).\n\n\\begin{definition}[(MWLS algorithm)]\n\n\n\\label{defmwls} Set ${y^{(M)}_{{N}}({\\cdot})}:= \\Phi(\\cdot)$. For each\n$i=N-1,N-2,\\ldots,0$, set the random functions ${y^{(M)}_{i}(\\cdot)}$ and ${z^{(M)}_{i}(\\cdot)}$ recursively as follows.\n\n\\begin{enumerate}\n\n\\item First, define ${z^{(M)}_{i}(\\cdot)}:= \\mathcal{T}_{{C_{z,i}}} ( \\psi\n^{(M)}_{Z,i}(\\cdot)\n)$ where ${C_{z,i}}$ is the almost sure bound of Corollary~\\ref{coras}\nand where\n\n\n\n", "index": 41, "text": "\\begin{equation}\n\\label{eqPsiMz}\n\\hspace*{-10pt}\\cases{ \\displaystyle\\psi^{(M)}_{Z,i}(\\cdot)\n\\mbox{ solves } {\\mathrm{OLS}}\\bigl( {S^{(M)}_{{Z,i}}\\bigl({{\\mathbf{\\underline{{h}} } }^{(i)}, {\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}, \\mathcal{K}_{Z,i}, \\nu_{i,M}\\bigr)\n\\vspace*{3pt}\\cr\n\\displaystyle\\quad\\mbox{for } {S^{(M)}_{{Z,i}}\\bigl({{\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:=\n\\Phi(x_N)h_N + \\sum_{k=i+1}^{N-1}\nf_k \\bigl(x_k,{y^{(M)}_{{k+1}}({x_{k+1}})}, {z^{(M)}_{k}({x_k})} \\bigr) h_k \\Delta_k,}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\hskip-10.0pt\\cases{\\displaystyle\\psi^{(M)}_{Z,i}(\\cdot)\\mbox{ solves }{%&#10;\\mathrm{OLS}}\\bigl{(}{S^{(M)}_{{Z,i}}\\bigl{(}{{\\mathbf{\\underline{{h}}}}^{(i)}%&#10;,{\\mathbf{\\underline{{x}}}}^{(i)}}\\bigr{)}},\\mathcal{K}_{Z,i},\\nu_{i,M}\\bigr{)%&#10;}\\cr\\displaystyle\\quad\\mbox{for }{S^{(M)}_{{Z,i}}\\bigl{(}{{\\mathbf{\\underline{%&#10;{h}}}}^{(i)},{\\mathbf{\\underline{{x}}}}^{(i)}}\\bigr{)}}:=\\Phi(x_{N})h_{N}+\\sum%&#10;_{k=i+1}^{N-1}f_{k}\\bigl{(}x_{k},{y^{(M)}_{{k+1}}({x_{k+1}})},{z^{(M)}_{k}({x_%&#10;{k}})}\\bigr{)}h_{k}\\Delta_{k},}\" display=\"block\"><mpadded lspace=\"-10pt\" width=\"-10pt\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mi>\u03c8</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mtext>\u00a0solves\u00a0</mtext><mo>\u2062</mo><mi>OLS</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msubsup><mi>S</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc21</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc31</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>,</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>\u03bd</mi><mrow><mi>i</mi><mo>,</mo><mi>M</mi></mrow></msub><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded lspace=\"10pt\" width=\"+10pt\"><mtext>for\u00a0</mtext></mpadded><mo>\u2062</mo><msubsup><mi>S</mi><mrow><mi>Z</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc21</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc31</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>h</mi><mi>N</mi></msub></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><msub><mi>f</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>,</mo><mrow><msubsup><mi>y</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>z</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><msub><mi>h</mi><mi>k</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>k</mi></msub></mrow></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd/></mtr></mtable></mrow></mpadded></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\end{enumerate}\n\n\\end{definition}\n\nBefore performing the error analysis, we state the following uniform\n(resp., conditional variance) bounds on the functions ${S^{(M)}_{{Y,i}}({\\cdot})}$ (resp., the $l$th coordinate of ${S^{(M)}_{{Z,i}}({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}} })}$ for each $m$ and $l$).\n{These bounds are used repeatedly in Section~\\ref{sectionerr} in\nconjunction with Proposition~\\ref{proplsregproperties} in order to\nobtain estimates on the conditional variance of the regressions. }\nThe proof is postponed to Appendix~\\ref{appendixprooflemmalemobsbounds}.\n\n\\begin{lemma}\n\\label{lemobsbounds}\nFor all $i \\in\\{0,\\ldots,N-1\\}$,\nthere are finite constants ${\\bar C_{{y,i}} }\\geq0$ and ${\\bar C_{{z,i}} }\\geq0$\nsuch that\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{S^{(M)}_{{Y,i}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}\\bigr{\\vert}& \\le&{\\bar C_{{y,i}} },\n\\qquad\\forall{\\mathbf{\\underline{{x}} } }^{(i)},\n\\\\\n\\sum_{l=1}^q{\\mathbb{V}\\mathrm{ar}}\\bigl[{S^{(M)}_{{l,Z,i}}\\bigl({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}}}\\bigr)} \\mid{\\mathcal{F}^{({M})}_{i}} \\bigr]& \\le&{\\bar C_{{z,i}} }^2, \\qquad\\forall m \\in\n\\{1,\\ldots,M_i\\}.\n\\end{eqnarray*}\n\nWe can write a precise time-dependency\nof the constants $ {\\bar C_{{y,i}} }$ and ${\\bar C_{{z,i}} }$:\n\n\n\\begin{eqnarray}\\label{eqboundObsBd}\n{\\bar C_{{y,i}} } &:=&c_1 C_\\xi+ c_2\nC_f (T-t_i)^{\\theta_c},\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n{\\bar C_{{z,i}} }&:=&c_3 {C_\\xi(T-t_i)^{-1/2}\n} + c_4 C_f (T-t_i)^{{\\theta_c}-{ 1 }/{2 }},\n\\end{eqnarray}\n\nwhere $(c_{j})_{1\\leq j\\leq4}$ depend only on $(L_f, C_{M}, q,\n\\aprioriConst1{y},\\aprioriConst2{y},\\aprioriConst1{z},{C^{(2)}_{{z}} },\\aprioriConst3{z},T,R_\\pi,{\\theta_L},{\\theta_c})$ (computed explicitely\nin the proof).\n\\end{lemma}\n\nThe above time-dependency is to be used to derive convergence rates for\nthe complexity analysis.\n\n\n\\subsection{Main result: Error analysis}\\label{sectionerr}\n\n\nWe precise the random norms used to quantify the error of MWLS.\n\n\n\n\\begin{definition}\nLet\n$\\varphi\\dvtx  {\\Omega^{(M)} } \\times{\\mathbb{R}}^d \\rightarrow{\\mathbb{R}}$ or $({\\mathbb{R}}^q)^\\top$ be\n${\\mathcal{F}^{(M)}_{{}}}\n\\otimes\\mathcal{B}({{\\mathbb{R}}^d})$-measurable.\nFor each $i\\in\\{0,\\ldots,N-1\\}$, define the random norms\n\n\\begin{eqnarray}\n{\\Vert}\\varphi{\\Vert}_{i,\\infty} ^2:= \\int\n_{{\\mathbb{R}}^d} \\bigl{\\vert}\\varphi(x)\\bigr{\\vert}^2 {\\mathbb{P}}\n\\circ X_i^{-1} (\\mathrm{d}x), \\qquad{\\Vert}\\varphi{\\Vert}\n_{i,M} ^2:= \\frac{1}{M_i} \\sum\n_{m=1}^{M_i} \\bigl{\\vert}\\varphi\\bigl({X^{({i,m})}_{i}}\\bigr)\\bigr\n{\\vert}^2.\n\\nonumber\n\\end{eqnarray}\n\n\\end{definition}\n\nThe accuracy of the MWLS algorithm is measured as follows:\n\n\\begin{eqnarray*}\n\\bar\\mathcal{E}(Y,M,i)&: =&\\sqrt{{\\mathbb{E}}\\bigl[ \\bigl{\\Vert}{y^{(M)}_{i}(\\cdot)}-\ny_i(\\cdot) \\bigr{\\Vert}_{i,\\infty} ^2 \\bigr]},\n\\qquad\\bar\\mathcal{E}(Z,M,i):= \\sqrt{{\\mathbb{E}}\\bigl[\\bigl{\\Vert}{z^{(M)}_{i}(\\cdot)}-\nz_i(\\cdot) \\bigr{\\Vert}_{i,\\infty} ^2 \\bigr]},\n\\\\\n\\mathcal{E}(Y,M,i) &:=& \\sqrt{{\\mathbb{E}}\\bigl[\\bigl{\\Vert}{y^{(M)}_{i}(\\cdot)}-\ny_i(\\cdot)\\bigr{\\Vert}_{i,M} ^2 \\bigr]},\n\\qquad\\mathcal{E}(Z,M,i):= \\sqrt{ \\mathbb{E} \\bigl[ \\bigl{\\Vert}{z^{(M)}_{i}(\\cdot)}- z_i(\\cdot)\\bigr{\\Vert}_{i,M} ^2 \\bigr]\n}.\n\\end{eqnarray*}\n\nIn our analysis, we will have to switch from errors in true measure\n$\\bar\\mathcal{E}(\\cdots)$ to errors in empirical measure $\\mathcal\n{E}(\\cdots)$, and\nvice-versa: this is not trivial since $({y^{(M)}_{i}(\\cdot)}, {z^{(M)}_{i}(\\cdot)} )$ and the\nempirical norm ${\\Vert}\\cdot{\\Vert}_{i,M} $ depend on the same\nsample. However,\nthe switch can be performed\n\nusing concentration-of-measure estimates uniformly on a class of\nfunctions \\cite{gyorkohlkrzywalk02}, Chapter~9. We directly state\nthe ready-to-use result, which is a straightforward adaptation of \\cite{gobeturk14}, Proposition 4.10, to our context.\n\n\\begin{proposition}\\label{propeqyzerrdecoM}\nRecall Definition~\\ref{deffindimspace} and the constants ${C_{y,i}}$\n(resp., ${C_{z,i}}$) from Corollary~\\ref{coras}, and define the \\emph\n{interdependence errors}\n\n\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{Dep.},i}&:=&{C_{y,i}}\\sqrt{\\frac{2028 (K_{Y,i}+1)\n\\log(3M_i)}{M_i}},\n\\\\\n\\mathcal{E}^Z_{\\mathrm{Dep.},i}&:=&{C_{z,i}}\\sqrt{\\frac{2028\n(K_{Z,i}+1) q \\log(3M_i) }{M_i}}.\n\\end{eqnarray*}\n\nFor each $i \\in\\{0,\\ldots, N-1\\}$, we have\n\n\\begin{eqnarray*}\n\\bar\\mathcal{E}(Y,M,i) \\le\\sqrt2 \\mathcal{E}(Y,M,i) + \\mathcal\n{E}^Y_{\\mathrm{Dep.},i},\\qquad\\bar\\mathcal{E}(Z,M,i) \\le\\sqrt2\n\\mathcal{E}(Z,M,i) + \\mathcal{E}^Z_{\\mathrm{Dep.},i}.\n\\end{eqnarray*}\n\n\\end{proposition}\n\nThe aim is to determine a rate of convergence for $\\mathcal\n{E}(Y,M,k):=({\\mathbb{E}}\n[{\\Vert}\ny_k - y^M_k{\\Vert}^2_{k,M}])^{ 1 /2 }$ and $\\mathcal{E}\n(Z,M,k):=({\\mathbb{E}}[{\\Vert} z_k -\nz^M_k{\\Vert}^2_{k,M}])^{ 1 /2 }$ using the local error\nterms $(\\mathcal{E}\n(k))_k$ defined below.\n\n\\begin{theorem}[(Global error of the MWLS algorithm)]\n\\label{thmMCerr}\nFor $0\\le k\\le N-1$, define\n\n\n\\begin{eqnarray}\\label{eqerr}\n\\mathcal{E}(k)&:=& \\mathcal{E}^Y_{\\mathrm{App.},k+1} + {\\bar C_{{y,k+1}} }\n\\sqrt{\\frac{ K_{Y,k+1}}{M_{k+1} }} + \\mathcal{E}^Z_{\\mathrm{App.},k}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}  +\n{\\bar C_{{z,k}} } \\sqrt{\\frac{K_{Z,k}} { M_k} }+L_f \\bigl( \\mathcal{E}\n^Y_{\\mathrm{Dep.},k+1} + \\mathcal{E}^Z_{\\mathrm{Dep.},k}\n\\bigr).\n\\end{eqnarray}\n\nFor every $k \\in\\{0,\\ldots,N-1\\}$,\n\n\n\n\\begin{eqnarray}\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_k - y^M_k\n\\bigr{\\Vert}_{k,M} ^2\\bigr] \\bigr)^{1/2} & \\le&\n\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} } \\sqrt{\\frac{ K_{Y,k}}{M_k}}\n+ {C^{(M)}_{y} } \\sum_{j=k}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j}{(T-t_j)^{(1-{\\theta_L})/2}},\\label\n{eqMCyerr}\n\\\\\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_k - z^M_k\n\\bigr{\\Vert}_{k,M} ^2\\bigr] \\bigr)^{1/2} & \\le&\n\\mathcal{E}^Z_{\\mathrm{App.},k} +{\\bar C_{{z,k}} } \\sqrt{\\frac\n{K_{Z,k}} {\nM_k} }\n\\nonumber\\[-8pt]\\label{eqMCzerr} \\[-8pt]\\nonumber\n&&{} + {C^{(M)}_{z} } \\sum_{j=k+1}^{N-1}\n\\frac{\\mathcal{E}(j)\\Delta\n_j}{(T-t_j)^{(1-{\\theta_L})/2}\\sqrt{t_j-t_k}},\n\\end{eqnarray}\n\nwhere, recalling the constant ${\\mathcal C}^{(\\gamma)}_{(\\ref{eqintuw})}$ from Lemma~\\ref\n{lemiterationgen2} (with $\\alpha= 0$, $\\beta= \\frac\\thetaL2$,\n$\\gamma\\in\\{\\frac{1}2,1\\}$ and $C_u = L_f( \\sqrt2 C_{M}+ 4 \\sqrt T)$),\n\n\\begin{eqnarray*}\n{C^{(M)}_{y} } &:=& 2+ 4L_f{\\mathcal C}^{({1})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{{\\theta_L}/2}},{1}}} T^{{{\\theta_L}/2}}(C_{M}+ 2\\sqrt T)\\bigr),\n\\\\\n{C^{(M)}_{z} } &:=& C_{M}+ \\sqrt2C_{M}L_f\n{\\mathcal C}^{({{{1}/2}})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{\\thetaL/2}},{{1}/2}}}\nT^{{\\theta_L}/2}(C_{M}+ 2\\sqrt T)\\bigr).\n\\end{eqnarray*}\n\n\\end{theorem}\n\n\n\\emph{Discussion}.\nObserve that owing to Proposition~\\ref{propeqyzerrdecoM}, similar\nestimates (with modified constants) are valid for $\\bar\\mathcal\n{E}(Y,M,k)=({\\mathbb{E}}\n[{\\Vert} y_k - y^M_k{\\Vert}^2_{k,\\infty}])^{ 1 /2 }$ and $\\bar\\mathcal{E}\n(Z,M,k)=({\\mathbb{E}}[{\\Vert} z_k - z^M_k{\\Vert}^2_{k,\\infty\n}])^{ 1 /2 }$. The global\nerror (\\ref{eqMCyerr})--(\\ref{eqMCzerr}) is a weighted time-average\nof three different errors.\n\n\\begin{longlist}[(2)]\n\n\\item[(1)] The\\vspace*{1pt} contributions $\\mathcal{E}^\\cdot_{\\mathrm{App.},\\cdot}$ are\nthe best\napproximation errors using the vector spaces of functions: this\naccuracy is achieved asymptotically with an infinite number of\nsimulations (take $M_k \\to+\\infty$ in our estimates).\\vspace*{1pt}\n\n\\item[(2)] The contributions $\\sqrt{\\frac{K_{\\cdot,\\cdot}} { M_\\cdot}}$ are\nthe usual statistical error terms: the larger the number of simulations\nor the smaller the dimensions of the vector spaces, the better the\nestimation error.\n\n\\item[(3)] The contributions $\\mathcal{E}^{\\cdot}_{\\mathrm{Dep.},\\cdot}$ are\nrelated to\nthe interdependencies between regressions at different times. This is\nintrinsic to the dynamic programming equation with $N$ nested empirical\nregressions.\n\\end{longlist}\n\nHowever, due to Proposition~\\ref{propeqyzerrdecoM}, the latter\ncontributions are of same magnitude as the statistical error terms (up\nto logarithmic factors). Therefore roughly speaking, the global error\nis of order of the best approximation errors plus the statistical\nerrors, as if there were a single regression problem \\cite{gyorkohlkrzywalk02}, Theorem~11.1. In this sense, these error bounds are\noptimal: it is not possible to improve the above estimates with respect\nto the convergence rates (but only possibly with respect to the\nconstants). An optimal tuning of parameters is proposed in Section~\\ref\n{sectioncomplexity}.\n\nIn comparison to \\cite{gobeturk14}, where a different Monte Carlo\nregression scheme is analyzed, the upper bound for the global error has\na similar shape, but with two important differences.\n\n\\begin{itemize}\n\n\\item\\emph{Norm on $Z$.} {In \\cite{gobeturk14}, one uses the time\naveraged {squared }${\\mathbf{L}}_2$-norm $\\sum_i {\\mathbb{E}}[ {{\\Vert}\\cdot{\\Vert}_{i,M}\n^2} ]\n\\Delta_i$ to estimate the error in $Z$, whereas here the norm used is\ntime-wise. This leads to more informative error bounds. This is an\nadvantage of the discrete BSDE with Malliavin weights against the MDP\nof \\cite{gobeturk14}.}\n\n\\item\\emph{Time-dependency.} The MWDP yields better estimates on\n$y(\\cdot )$ and $z(\\cdot )$ w.r.t. time in the local error estimates, which\nallows better parameters tuning and therefore better convergence rates\n(see Section~\\ref{sectioncomplexity}).\n\\end{itemize}\n\n\n\\subsection{Proof of Theorem \\texorpdfstring{\\protect\\ref{thmMCerr}}{3.10}}\\label{sectionproofmainthm}\n\n\\subsubsection{Preliminary results}\n\nThe following proposition lists  standard tools from the theory of\nregression. They will be used repeatedly in the proof of Theorem~\\ref\n{thmMCerr}.\nThis proposition was also used in \\cite{gobeturk14}, and we refer the\nreader to that paper for the proof.\nThe two first properties are of deterministic nature, the two last are\nprobabilistic.\nItem (iv) is stated in high generality; this readily allows its\nfurther use in other regression-based Monte Carlo algorithms.\n\n\\begin{proposition}[(\\cite{gobeturk14}, Proposition~4.12)]\n\\label{proplsregproperties}\nWith the notation of Definition~\\ref{defls},\nsuppose that $\\mathcal{K}_{}$ is\nfinite-dimensional and spanned by the functions $\\{p_1(\\cdot ),\\ldots,p_K(\\cdot )\\}$.\nLet $S^\\star$ solve ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu)$ (resp., ${\\mathrm{OLS}}\n(S,\\mathcal{K}_{},\\nu_M)$), according to (\\ref{eqmcmls}) (resp.,\n(\\ref\n{eqmclsempi})).\nThe following properties are satisfied:\n\n\\begin{longlist}[(iii)]\n\n\\item[(i)] Linearity: the mapping $S\\mapsto S^\\star$ is linear.\n\n\\item[(ii)] {Stability} property: ${\\Vert} S^\\star{\\Vert}_{{\\mathbf{L}}\n_2(\\mathcal{B}({\\mathbb{R}}^l),\\mu)}\\leq{\\Vert} S{\\Vert}_{{\\mathbf{L}}_2(\\mathcal{B}({\\mathbb{R}}\n^l),\\mu)}$, where $\\mu= \\nu$ (resp., $\\mu= \\nu_M$).\n\n\\item[(iii)] Conditional expectation solution:\nin the case of the discrete probability\nmeasure $\\nu_M$,\nassume additionally that the {sub-}$\\sigma$-algebra $\\mathcal\n{Q}\\subset\n\\tilde\n\\mathcal{F}$ is such that $ (p_j({\\mathcal{X}}^{(1)}),\\ldots,p_j({\\mathcal{X}}\n^{(M)})\n)$ is\n$\\mathcal{Q}$-measurable for every $j\\in\\{1,\\ldots,K\n\\}$. Setting\n$S_\\mathcal{Q}({\\mathcal{X}}^{(m)}):=\\tilde{\\mathbb{E}}[S({\\mathcal{X}}^{(m)})\\mid\\mathcal\n{Q}]$ for each $m\n\\in\\{\n1,\\ldots,M\\}$,\nthen $\\tilde{\\mathbb{E}}[S^\\star\\mid\\mathcal{Q}]$ solves ${\\mathrm{OLS}}(\nS_\\mathcal{Q},\n\\mathcal{K}_{},\n\\nu_M )$.\n\n\\item[(iv)] Bounded conditional variance: in the case of the\ndiscrete probability measure $\\nu_M$, suppose that $S(\\omega,x)$ is\n$\\mathcal{G}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable, for $\\mathcal\n{G}\\subset\\tilde\n\\mathcal{F}$\nindependent of $\\sigma(\\Samp1,\\ldots, {{\\mathcal{X}}^{(M)} })$,\nthere exists a Borel measurable function $g\\dvtx  {\\mathbb{R}}^l \\rightarrow\n\\mathcal{E}$,\nfor some Euclidean space $\\mathcal{E}$, such that the random variables\n$\\{\np_j({{\\mathcal{X}}^{(m)} })\\dvt  m =1,\\ldots,M, j = 1,\\ldots, K\\}$ are $\\mathcal{H}:=\n\\sigma\n(g({{\\mathcal{X}}^{(m)} })\\dvt  m =1,\\ldots, M)$-measurable, and there is a finite\nconstant $\\sigma^2 \\geq0$ that uniformly bounds the conditional\nvariances $\\tilde{\\mathbb{E}}[{\\vert} S({{\\mathcal{X}}^{({m})} })-\\tilde{\\mathbb{E}}(S({{\\mathcal{X}}^{({m})} })\\mid\\mathcal{G}\n\\vee\\mathcal{H}\n){\\vert}^2 \\mid\\mathcal{G}\\vee\\mathcal{H} ]\\leq\n\\sigma^2$\n$\\tilde{\\mathbb{P}}$-a.s. and for\nall $m\n\\in\\{1,\\ldots,M\\}$. Then\n\n", "itemtype": "equation", "pos": 53862, "prevtext": "\n\nwhere ${\\mathbf{\\underline{{h}} } }^{(i)}, {\\mathbf{\\underline{{x}} } }^{(i)}, \\nu_{i,M}$ are defined in\n(\\ref{eqvecxhvecxh}) and (\\ref{eqempimeasure}).\n\n\\item Second and similarly, define ${y^{(M)}_{i}(\\cdot)}:= \\mathcal{T}_{{C_{y,i}}\n}\n(\\psi^{(M)}\n_{Y,i}(\\cdot) )$ where\n\n\n\n", "index": 43, "text": "\\begin{equation}\n\\label{eqPsiMy} \\cases{ \\displaystyle\\psi^{(M)}_{Y,i}(\\cdot)\n\\mbox{ solves }{\\mathrm{OLS}}\\bigl({S^{(M)}_{{Y,i}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)},\n\\mathcal{K}_{Y,i}, \\nu_{i,M}\\bigr)\n\\vspace*{3pt}\\cr\n\\displaystyle \\quad\\mbox{for } {S^{(M)}_{{Y,i}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}:= \\Phi(x_N) + \\sum\n_{k=i}^{N-1} f_k \\bigl(x_k,\n{y^{(M)}_{{k+1}}({x_{k+1}})}, {z^{(M)}_{{k}}({x_k})} \\bigr) \\Delta_k.}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\cases{\\displaystyle\\psi^{(M)}_{Y,i}(\\cdot)\\mbox{ solves }{\\mathrm{OLS}}\\bigl{%&#10;(}{S^{(M)}_{{Y,i}}\\bigl{(}{{\\mathbf{\\underline{{x}}}}^{(i)}}\\bigr{)}},\\mathcal%&#10;{K}_{Y,i},\\nu_{i,M}\\bigr{)}\\cr\\displaystyle\\quad\\mbox{for }{S^{(M)}_{{Y,i}}%&#10;\\bigl{(}{{\\mathbf{\\underline{{x}}}}^{(i)}}\\bigr{)}}:=\\Phi(x_{N})+\\sum{}_{k=i}^%&#10;{N-1}f_{k}\\bigl{(}x_{k},{y^{(M)}_{{k+1}}({x_{k+1}})},{z^{(M)}_{{k}}({x_{k}})}%&#10;\\bigr{)}\\Delta_{k}.}\" display=\"block\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mi>\u03c8</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mtext>\u00a0solves\u00a0</mtext><mo>\u2062</mo><mi>OLS</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msubsup><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc31</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>,</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca6</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>\u03bd</mi><mrow><mi>i</mi><mo>,</mo><mi>M</mi></mrow></msub><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded lspace=\"10pt\" width=\"+10pt\"><mtext>for\u00a0</mtext></mpadded><mo>\u2062</mo><msubsup><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><munder accentunder=\"true\"><mi>\ud835\udc31</mi><mo>\u00af</mo></munder><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>:=</mo><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mmultiscripts><mi>f</mi><mi>k</mi><none/><mprescripts/><mrow><mi>k</mi><mo>=</mo><mi>i</mi></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></mmultiscripts><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo>,</mo><mrow><msubsup><mi>y</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>z</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>k</mi></msub></mrow></mrow></mrow></mrow><mo>.</mo></mrow></mtd><mtd/></mtr></mtable></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n\\end{longlist}\n\n\\end{proposition}\n\n\\emph{Intermediate processes and local error terms.}\nAnother technique we borrow from \\cite{gobeturk14} is to introduce\nintermediate, \\emph{fictional} regressions based on the true solutions:\none replaces the full ${\\mathbf{L}}_2$ space for the approximation space and the\ntrue measure for the empirical measure in (\\ref{eqMDPlsdef}).\n\nFor each $k\\in\\{0,\\ldots,N-1\\}$, recall the functions ${S_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(i)}})}$ and ${S_{{Z,k}}({{\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}})}$ from\n(\\ref{eqMDPlsdef}),\nthe linear spaces $\\mathcal{K}_{Y,k}$ and $\\mathcal{K}_{Z,k}$ from Definition\n\\ref{deffindimspace}, and the empirical measure\n$\\nu_{k,M}$ from (\\ref{eqempimeasure}), and set\n\n\\begin{eqnarray*}\n&\\displaystyle\\psi_{Y,k}(\\cdot) \\quad\n\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( {S_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)},\n\\mathcal{K}_{Y,k}, \\nu_{k,M} \\bigr),&\n\\\\\n&\\displaystyle\\psi_{Z,k}(\\cdot) \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( {S_{{Z,k}}\\bigl({{\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}, \\mathcal{K}_{Z,k},\n\\nu_{k,M} \\bigr).&\n\\end{eqnarray*}\n\n\nNote that these regressions are not {numerically} accessible, because\nthey require knowledge of the true solution to be applied.\nAfter a series of conditioning arguments, based on Lemma~\\ref{lembary}\nbelow, the fictional regressions will eventually allow the use of\nthe stability estimates of Section~\\ref{sectionstab}, and (after a\nsomewhat complex application of the Gronwall inequalities of\nSection~\\ref{sectiongronwall}) this will yield final result.\n\nFrom Lemma~\\ref{lemcdnexp} and our Markovian assumptions, observe that\n\n", "itemtype": "equation", "pos": 66558, "prevtext": "\n\n\\end{enumerate}\n\n\\end{definition}\n\nBefore performing the error analysis, we state the following uniform\n(resp., conditional variance) bounds on the functions ${S^{(M)}_{{Y,i}}({\\cdot})}$ (resp., the $l$th coordinate of ${S^{(M)}_{{Z,i}}({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}} })}$ for each $m$ and $l$).\n{These bounds are used repeatedly in Section~\\ref{sectionerr} in\nconjunction with Proposition~\\ref{proplsregproperties} in order to\nobtain estimates on the conditional variance of the regressions. }\nThe proof is postponed to Appendix~\\ref{appendixprooflemmalemobsbounds}.\n\n\\begin{lemma}\n\\label{lemobsbounds}\nFor all $i \\in\\{0,\\ldots,N-1\\}$,\nthere are finite constants ${\\bar C_{{y,i}} }\\geq0$ and ${\\bar C_{{z,i}} }\\geq0$\nsuch that\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{S^{(M)}_{{Y,i}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}\\bigr{\\vert}& \\le&{\\bar C_{{y,i}} },\n\\qquad\\forall{\\mathbf{\\underline{{x}} } }^{(i)},\n\\\\\n\\sum_{l=1}^q{\\mathbb{V}\\mathrm{ar}}\\bigl[{S^{(M)}_{{l,Z,i}}\\bigl({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}}}\\bigr)} \\mid{\\mathcal{F}^{({M})}_{i}} \\bigr]& \\le&{\\bar C_{{z,i}} }^2, \\qquad\\forall m \\in\n\\{1,\\ldots,M_i\\}.\n\\end{eqnarray*}\n\nWe can write a precise time-dependency\nof the constants $ {\\bar C_{{y,i}} }$ and ${\\bar C_{{z,i}} }$:\n\n\n\\begin{eqnarray}\\label{eqboundObsBd}\n{\\bar C_{{y,i}} } &:=&c_1 C_\\xi+ c_2\nC_f (T-t_i)^{\\theta_c},\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n{\\bar C_{{z,i}} }&:=&c_3 {C_\\xi(T-t_i)^{-1/2}\n} + c_4 C_f (T-t_i)^{{\\theta_c}-{ 1 }/{2 }},\n\\end{eqnarray}\n\nwhere $(c_{j})_{1\\leq j\\leq4}$ depend only on $(L_f, C_{M}, q,\n\\aprioriConst1{y},\\aprioriConst2{y},\\aprioriConst1{z},{C^{(2)}_{{z}} },\\aprioriConst3{z},T,R_\\pi,{\\theta_L},{\\theta_c})$ (computed explicitely\nin the proof).\n\\end{lemma}\n\nThe above time-dependency is to be used to derive convergence rates for\nthe complexity analysis.\n\n\n\\subsection{Main result: Error analysis}\\label{sectionerr}\n\n\nWe precise the random norms used to quantify the error of MWLS.\n\n\n\n\\begin{definition}\nLet\n$\\varphi\\dvtx  {\\Omega^{(M)} } \\times{\\mathbb{R}}^d \\rightarrow{\\mathbb{R}}$ or $({\\mathbb{R}}^q)^\\top$ be\n${\\mathcal{F}^{(M)}_{{}}}\n\\otimes\\mathcal{B}({{\\mathbb{R}}^d})$-measurable.\nFor each $i\\in\\{0,\\ldots,N-1\\}$, define the random norms\n\n\\begin{eqnarray}\n{\\Vert}\\varphi{\\Vert}_{i,\\infty} ^2:= \\int\n_{{\\mathbb{R}}^d} \\bigl{\\vert}\\varphi(x)\\bigr{\\vert}^2 {\\mathbb{P}}\n\\circ X_i^{-1} (\\mathrm{d}x), \\qquad{\\Vert}\\varphi{\\Vert}\n_{i,M} ^2:= \\frac{1}{M_i} \\sum\n_{m=1}^{M_i} \\bigl{\\vert}\\varphi\\bigl({X^{({i,m})}_{i}}\\bigr)\\bigr\n{\\vert}^2.\n\\nonumber\n\\end{eqnarray}\n\n\\end{definition}\n\nThe accuracy of the MWLS algorithm is measured as follows:\n\n\\begin{eqnarray*}\n\\bar\\mathcal{E}(Y,M,i)&: =&\\sqrt{{\\mathbb{E}}\\bigl[ \\bigl{\\Vert}{y^{(M)}_{i}(\\cdot)}-\ny_i(\\cdot) \\bigr{\\Vert}_{i,\\infty} ^2 \\bigr]},\n\\qquad\\bar\\mathcal{E}(Z,M,i):= \\sqrt{{\\mathbb{E}}\\bigl[\\bigl{\\Vert}{z^{(M)}_{i}(\\cdot)}-\nz_i(\\cdot) \\bigr{\\Vert}_{i,\\infty} ^2 \\bigr]},\n\\\\\n\\mathcal{E}(Y,M,i) &:=& \\sqrt{{\\mathbb{E}}\\bigl[\\bigl{\\Vert}{y^{(M)}_{i}(\\cdot)}-\ny_i(\\cdot)\\bigr{\\Vert}_{i,M} ^2 \\bigr]},\n\\qquad\\mathcal{E}(Z,M,i):= \\sqrt{ \\mathbb{E} \\bigl[ \\bigl{\\Vert}{z^{(M)}_{i}(\\cdot)}- z_i(\\cdot)\\bigr{\\Vert}_{i,M} ^2 \\bigr]\n}.\n\\end{eqnarray*}\n\nIn our analysis, we will have to switch from errors in true measure\n$\\bar\\mathcal{E}(\\cdots)$ to errors in empirical measure $\\mathcal\n{E}(\\cdots)$, and\nvice-versa: this is not trivial since $({y^{(M)}_{i}(\\cdot)}, {z^{(M)}_{i}(\\cdot)} )$ and the\nempirical norm ${\\Vert}\\cdot{\\Vert}_{i,M} $ depend on the same\nsample. However,\nthe switch can be performed\n\nusing concentration-of-measure estimates uniformly on a class of\nfunctions \\cite{gyorkohlkrzywalk02}, Chapter~9. We directly state\nthe ready-to-use result, which is a straightforward adaptation of \\cite{gobeturk14}, Proposition 4.10, to our context.\n\n\\begin{proposition}\\label{propeqyzerrdecoM}\nRecall Definition~\\ref{deffindimspace} and the constants ${C_{y,i}}$\n(resp., ${C_{z,i}}$) from Corollary~\\ref{coras}, and define the \\emph\n{interdependence errors}\n\n\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{Dep.},i}&:=&{C_{y,i}}\\sqrt{\\frac{2028 (K_{Y,i}+1)\n\\log(3M_i)}{M_i}},\n\\\\\n\\mathcal{E}^Z_{\\mathrm{Dep.},i}&:=&{C_{z,i}}\\sqrt{\\frac{2028\n(K_{Z,i}+1) q \\log(3M_i) }{M_i}}.\n\\end{eqnarray*}\n\nFor each $i \\in\\{0,\\ldots, N-1\\}$, we have\n\n\\begin{eqnarray*}\n\\bar\\mathcal{E}(Y,M,i) \\le\\sqrt2 \\mathcal{E}(Y,M,i) + \\mathcal\n{E}^Y_{\\mathrm{Dep.},i},\\qquad\\bar\\mathcal{E}(Z,M,i) \\le\\sqrt2\n\\mathcal{E}(Z,M,i) + \\mathcal{E}^Z_{\\mathrm{Dep.},i}.\n\\end{eqnarray*}\n\n\\end{proposition}\n\nThe aim is to determine a rate of convergence for $\\mathcal\n{E}(Y,M,k):=({\\mathbb{E}}\n[{\\Vert}\ny_k - y^M_k{\\Vert}^2_{k,M}])^{ 1 /2 }$ and $\\mathcal{E}\n(Z,M,k):=({\\mathbb{E}}[{\\Vert} z_k -\nz^M_k{\\Vert}^2_{k,M}])^{ 1 /2 }$ using the local error\nterms $(\\mathcal{E}\n(k))_k$ defined below.\n\n\\begin{theorem}[(Global error of the MWLS algorithm)]\n\\label{thmMCerr}\nFor $0\\le k\\le N-1$, define\n\n\n\\begin{eqnarray}\\label{eqerr}\n\\mathcal{E}(k)&:=& \\mathcal{E}^Y_{\\mathrm{App.},k+1} + {\\bar C_{{y,k+1}} }\n\\sqrt{\\frac{ K_{Y,k+1}}{M_{k+1} }} + \\mathcal{E}^Z_{\\mathrm{App.},k}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}  +\n{\\bar C_{{z,k}} } \\sqrt{\\frac{K_{Z,k}} { M_k} }+L_f \\bigl( \\mathcal{E}\n^Y_{\\mathrm{Dep.},k+1} + \\mathcal{E}^Z_{\\mathrm{Dep.},k}\n\\bigr).\n\\end{eqnarray}\n\nFor every $k \\in\\{0,\\ldots,N-1\\}$,\n\n\n\n\\begin{eqnarray}\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_k - y^M_k\n\\bigr{\\Vert}_{k,M} ^2\\bigr] \\bigr)^{1/2} & \\le&\n\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} } \\sqrt{\\frac{ K_{Y,k}}{M_k}}\n+ {C^{(M)}_{y} } \\sum_{j=k}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j}{(T-t_j)^{(1-{\\theta_L})/2}},\\label\n{eqMCyerr}\n\\\\\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_k - z^M_k\n\\bigr{\\Vert}_{k,M} ^2\\bigr] \\bigr)^{1/2} & \\le&\n\\mathcal{E}^Z_{\\mathrm{App.},k} +{\\bar C_{{z,k}} } \\sqrt{\\frac\n{K_{Z,k}} {\nM_k} }\n\\nonumber\\[-8pt]\\label{eqMCzerr} \\[-8pt]\\nonumber\n&&{} + {C^{(M)}_{z} } \\sum_{j=k+1}^{N-1}\n\\frac{\\mathcal{E}(j)\\Delta\n_j}{(T-t_j)^{(1-{\\theta_L})/2}\\sqrt{t_j-t_k}},\n\\end{eqnarray}\n\nwhere, recalling the constant ${\\mathcal C}^{(\\gamma)}_{(\\ref{eqintuw})}$ from Lemma~\\ref\n{lemiterationgen2} (with $\\alpha= 0$, $\\beta= \\frac\\thetaL2$,\n$\\gamma\\in\\{\\frac{1}2,1\\}$ and $C_u = L_f( \\sqrt2 C_{M}+ 4 \\sqrt T)$),\n\n\\begin{eqnarray*}\n{C^{(M)}_{y} } &:=& 2+ 4L_f{\\mathcal C}^{({1})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{{\\theta_L}/2}},{1}}} T^{{{\\theta_L}/2}}(C_{M}+ 2\\sqrt T)\\bigr),\n\\\\\n{C^{(M)}_{z} } &:=& C_{M}+ \\sqrt2C_{M}L_f\n{\\mathcal C}^{({{{1}/2}})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{\\thetaL/2}},{{1}/2}}}\nT^{{\\theta_L}/2}(C_{M}+ 2\\sqrt T)\\bigr).\n\\end{eqnarray*}\n\n\\end{theorem}\n\n\n\\emph{Discussion}.\nObserve that owing to Proposition~\\ref{propeqyzerrdecoM}, similar\nestimates (with modified constants) are valid for $\\bar\\mathcal\n{E}(Y,M,k)=({\\mathbb{E}}\n[{\\Vert} y_k - y^M_k{\\Vert}^2_{k,\\infty}])^{ 1 /2 }$ and $\\bar\\mathcal{E}\n(Z,M,k)=({\\mathbb{E}}[{\\Vert} z_k - z^M_k{\\Vert}^2_{k,\\infty\n}])^{ 1 /2 }$. The global\nerror (\\ref{eqMCyerr})--(\\ref{eqMCzerr}) is a weighted time-average\nof three different errors.\n\n\\begin{longlist}[(2)]\n\n\\item[(1)] The\\vspace*{1pt} contributions $\\mathcal{E}^\\cdot_{\\mathrm{App.},\\cdot}$ are\nthe best\napproximation errors using the vector spaces of functions: this\naccuracy is achieved asymptotically with an infinite number of\nsimulations (take $M_k \\to+\\infty$ in our estimates).\\vspace*{1pt}\n\n\\item[(2)] The contributions $\\sqrt{\\frac{K_{\\cdot,\\cdot}} { M_\\cdot}}$ are\nthe usual statistical error terms: the larger the number of simulations\nor the smaller the dimensions of the vector spaces, the better the\nestimation error.\n\n\\item[(3)] The contributions $\\mathcal{E}^{\\cdot}_{\\mathrm{Dep.},\\cdot}$ are\nrelated to\nthe interdependencies between regressions at different times. This is\nintrinsic to the dynamic programming equation with $N$ nested empirical\nregressions.\n\\end{longlist}\n\nHowever, due to Proposition~\\ref{propeqyzerrdecoM}, the latter\ncontributions are of same magnitude as the statistical error terms (up\nto logarithmic factors). Therefore roughly speaking, the global error\nis of order of the best approximation errors plus the statistical\nerrors, as if there were a single regression problem \\cite{gyorkohlkrzywalk02}, Theorem~11.1. In this sense, these error bounds are\noptimal: it is not possible to improve the above estimates with respect\nto the convergence rates (but only possibly with respect to the\nconstants). An optimal tuning of parameters is proposed in Section~\\ref\n{sectioncomplexity}.\n\nIn comparison to \\cite{gobeturk14}, where a different Monte Carlo\nregression scheme is analyzed, the upper bound for the global error has\na similar shape, but with two important differences.\n\n\\begin{itemize}\n\n\\item\\emph{Norm on $Z$.} {In \\cite{gobeturk14}, one uses the time\naveraged {squared }${\\mathbf{L}}_2$-norm $\\sum_i {\\mathbb{E}}[ {{\\Vert}\\cdot{\\Vert}_{i,M}\n^2} ]\n\\Delta_i$ to estimate the error in $Z$, whereas here the norm used is\ntime-wise. This leads to more informative error bounds. This is an\nadvantage of the discrete BSDE with Malliavin weights against the MDP\nof \\cite{gobeturk14}.}\n\n\\item\\emph{Time-dependency.} The MWDP yields better estimates on\n$y(\\cdot )$ and $z(\\cdot )$ w.r.t. time in the local error estimates, which\nallows better parameters tuning and therefore better convergence rates\n(see Section~\\ref{sectioncomplexity}).\n\\end{itemize}\n\n\n\\subsection{Proof of Theorem \\texorpdfstring{\\protect\\ref{thmMCerr}}{3.10}}\\label{sectionproofmainthm}\n\n\\subsubsection{Preliminary results}\n\nThe following proposition lists  standard tools from the theory of\nregression. They will be used repeatedly in the proof of Theorem~\\ref\n{thmMCerr}.\nThis proposition was also used in \\cite{gobeturk14}, and we refer the\nreader to that paper for the proof.\nThe two first properties are of deterministic nature, the two last are\nprobabilistic.\nItem (iv) is stated in high generality; this readily allows its\nfurther use in other regression-based Monte Carlo algorithms.\n\n\\begin{proposition}[(\\cite{gobeturk14}, Proposition~4.12)]\n\\label{proplsregproperties}\nWith the notation of Definition~\\ref{defls},\nsuppose that $\\mathcal{K}_{}$ is\nfinite-dimensional and spanned by the functions $\\{p_1(\\cdot ),\\ldots,p_K(\\cdot )\\}$.\nLet $S^\\star$ solve ${\\mathrm{OLS}}(S,\\mathcal{K}_{},\\nu)$ (resp., ${\\mathrm{OLS}}\n(S,\\mathcal{K}_{},\\nu_M)$), according to (\\ref{eqmcmls}) (resp.,\n(\\ref\n{eqmclsempi})).\nThe following properties are satisfied:\n\n\\begin{longlist}[(iii)]\n\n\\item[(i)] Linearity: the mapping $S\\mapsto S^\\star$ is linear.\n\n\\item[(ii)] {Stability} property: ${\\Vert} S^\\star{\\Vert}_{{\\mathbf{L}}\n_2(\\mathcal{B}({\\mathbb{R}}^l),\\mu)}\\leq{\\Vert} S{\\Vert}_{{\\mathbf{L}}_2(\\mathcal{B}({\\mathbb{R}}\n^l),\\mu)}$, where $\\mu= \\nu$ (resp., $\\mu= \\nu_M$).\n\n\\item[(iii)] Conditional expectation solution:\nin the case of the discrete probability\nmeasure $\\nu_M$,\nassume additionally that the {sub-}$\\sigma$-algebra $\\mathcal\n{Q}\\subset\n\\tilde\n\\mathcal{F}$ is such that $ (p_j({\\mathcal{X}}^{(1)}),\\ldots,p_j({\\mathcal{X}}\n^{(M)})\n)$ is\n$\\mathcal{Q}$-measurable for every $j\\in\\{1,\\ldots,K\n\\}$. Setting\n$S_\\mathcal{Q}({\\mathcal{X}}^{(m)}):=\\tilde{\\mathbb{E}}[S({\\mathcal{X}}^{(m)})\\mid\\mathcal\n{Q}]$ for each $m\n\\in\\{\n1,\\ldots,M\\}$,\nthen $\\tilde{\\mathbb{E}}[S^\\star\\mid\\mathcal{Q}]$ solves ${\\mathrm{OLS}}(\nS_\\mathcal{Q},\n\\mathcal{K}_{},\n\\nu_M )$.\n\n\\item[(iv)] Bounded conditional variance: in the case of the\ndiscrete probability measure $\\nu_M$, suppose that $S(\\omega,x)$ is\n$\\mathcal{G}\\otimes\\mathcal{B}({\\mathbb{R}}^l)$-measurable, for $\\mathcal\n{G}\\subset\\tilde\n\\mathcal{F}$\nindependent of $\\sigma(\\Samp1,\\ldots, {{\\mathcal{X}}^{(M)} })$,\nthere exists a Borel measurable function $g\\dvtx  {\\mathbb{R}}^l \\rightarrow\n\\mathcal{E}$,\nfor some Euclidean space $\\mathcal{E}$, such that the random variables\n$\\{\np_j({{\\mathcal{X}}^{(m)} })\\dvt  m =1,\\ldots,M, j = 1,\\ldots, K\\}$ are $\\mathcal{H}:=\n\\sigma\n(g({{\\mathcal{X}}^{(m)} })\\dvt  m =1,\\ldots, M)$-measurable, and there is a finite\nconstant $\\sigma^2 \\geq0$ that uniformly bounds the conditional\nvariances $\\tilde{\\mathbb{E}}[{\\vert} S({{\\mathcal{X}}^{({m})} })-\\tilde{\\mathbb{E}}(S({{\\mathcal{X}}^{({m})} })\\mid\\mathcal{G}\n\\vee\\mathcal{H}\n){\\vert}^2 \\mid\\mathcal{G}\\vee\\mathcal{H} ]\\leq\n\\sigma^2$\n$\\tilde{\\mathbb{P}}$-a.s. and for\nall $m\n\\in\\{1,\\ldots,M\\}$. Then\n\n", "index": 45, "text": "\n\\[\n\\tilde{\\mathbb{E}}\\bigl[ \\bigl{\\Vert} S^\\star(\\cdot) - \\tilde{\\mathbb{E}}\n\\bigl[S^\\star(\\cdot) \\mid \\mathcal{G}\\vee\\mathcal{H}\\bigr]\n\\bigr{\\Vert}_{{\\mathbf{L}}_2(\\mathcal{B}({\\mathbb{R}}^l),\\nu_M)}^2 \\mid \\mathcal\n{G} \\vee\n\\mathcal{H} \\bigr] \\le\\sigma^2 \\frac{ K }{M }.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\tilde{\\mathbb{E}}\\bigl{[}\\bigl{\\|}S^{\\star}(\\cdot)-\\tilde{\\mathbb{E}}\\bigl{[}%&#10;S^{\\star}(\\cdot)\\mid\\mathcal{G}\\vee\\mathcal{H}\\bigr{]}\\bigr{\\|}_{{\\mathbf{L}}_%&#10;{2}(\\mathcal{B}({\\mathbb{R}}^{l}),\\nu_{M})}^{2}\\mid\\mathcal{G}\\vee\\mathcal{H}%&#10;\\bigr{]}\\leq\\sigma^{2}\\frac{K}{M}.\" display=\"block\"><mrow><mover accent=\"true\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi></mrow><mo stretchy=\"false\">~</mo></mover><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo><msup><mi>S</mi><mo>\u22c6</mo></msup><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mover accent=\"true\"><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi></mrow><mo stretchy=\"false\">~</mo></mover><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mi>S</mi><mo>\u22c6</mo></msup><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mo>\u2228</mo><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo></mrow><mrow><msub><mi>\ud835\udc0b</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msup><mi>R</mi><mi>l</mi></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msub><mi>\u03bd</mi><mi>M</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mn>2</mn></msubsup><mo>\u2223</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca2</mi><mo>\u2228</mo><mi class=\"ltx_font_mathcaligraphic\">\u210b</mi><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo>\u2264</mo><msup><mi>\u03c3</mi><mn>2</mn></msup><mfrac><mi>K</mi><mi>M</mi></mfrac><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor each $m\\in\\{1,\\ldots,M_k \\}$ where $ (y_k(\\cdot),z_k (\\cdot)\n)$ are the unknown functions defined in (\\ref{eqmarkov}). Proposition\n\\ref{proplsregproperties}(iii) implies the first statement of the\nfollowing lemma. The second statement results from a direct interchange\nof $\\inf$ and ${\\mathbb{E}}$, and from the identical distribution of\n$(X^{(k,m)}_k)$ for all~$m$.\n\n\\begin{lemma}\n\\label{lembary}\nFor each $k\\in\\{0,\\ldots,N-1\\}$,\n\n\\begin{eqnarray*}\n& \\displaystyle{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Y,k}(\\cdot)\\bigr] \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl(\ny_k(\\cdot ), \\mathcal{K}_{Y,k}, \\nu_{k,M} \\bigr),&\n\\\\\n& \\displaystyle {\\mathbb{E}}^M_k\\bigl[\\psi_{Z,k}(\\cdot)\\bigr] \\quad\n\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( z_k(\\cdot ), \\mathcal{K}_{Z,k},\n\\nu_{k,M} \\bigr).&\n\\end{eqnarray*}\n\nIn addition, recalling the local error terms $\\mathcal{E}^Y_{\\mathrm\n{App.},k}$ and $\\mathcal{E}^Z_{\\mathrm{App.},k}$\nfrom Definition~\\ref{deffindimspace},\n\n\\begin{eqnarray*}\n \\mathbb{E} \\bigl[ \\bigl{\\Vert}{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Y,k}(\\cdot) \\bigr]-y_k(\\cdot) \\bigr{\\Vert}\n_{k,M} ^2 \\bigr]&=&\\mathbb{E} \\Bigl[ \\inf\n_{ \\phi\\in\\mathcal{K}_{Y,k} } \\bigl{\\Vert}\\phi(\\cdot) - y_k(\\cdot)\\bigr\n{\\Vert}_{k,M} ^2 \\Bigr]\\leq\\bigl(\\mathcal{E}\n^Y_{\\mathrm{App.},k}\\bigr)^2,\n\\\\\n \\mathbb{E} \\bigl[ \\bigl{\\Vert}{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Z,k}(\\cdot) \\bigr] -z_k(\\cdot)\\bigr{\\Vert}\n_{k,M} ^2 \\bigr]&=&\\mathbb{E} \\Bigl[ \\inf\n_{ \\phi\\in\\mathcal{K}_{Z,k} } \\bigl{\\Vert}\\phi(\\cdot) - z_k(\\cdot)\\bigr\n{\\Vert}_{k,M} ^2 \\Bigr]\\leq\\bigl(\\mathcal{E}\n^Z_{\\mathrm{App.},k}\\bigr)^2.\n\\end{eqnarray*}\n\n\\end{lemma}\n\n\n\\subsubsection{Proof of Theorem \\texorpdfstring{\\protect\\ref{thmMCerr}}{3.10}}\n\n\\begin{longlist}\n\\item[\\textit{Step} 1: \\textit{decomposition of the error on $Y$.}]\nRecall the soft truncation function $\\mathcal{T}_L(x):= (-L\\vee x_1\n\\wedge L,\\ldots, -L \\vee x_n \\wedge L)$ {for $x\\in{\\mathbb{R}}^n$}.\nFrom the almost sure bounds of Corollary~\\ref{coras}, $\\mathcal\n{T}_{{C_{y,k}}}\n(y_k) = y_k$. Then, the Lipschitz continuity of $\\mathcal{T}_{{C_{y,k}}}$ yields\n$ {\\Vert} y_k(\\cdot) - {y^{(M)}_{{k}}({\\cdot})} {\\Vert}_{k,M} $ is\nless than or\nequal to\n${\\Vert} y_k(\\cdot) - \\psi^{(M)}_{Y,k}(\\cdot) {\\Vert}\n_{k,M} $.\nUsing the triangle inequality for the ${\\Vert}\\cdot{\\Vert}_{k,M}\n$-norm, it\nfollows that\n\n\n\\begin{eqnarray}\\label{eqMCy1}\n&& \\bigl{\\Vert} y_k(\\cdot)- {y^{(M)}_{k}(\\cdot)}\\bigr{\\Vert}_{k,M}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\quad  \\le\\bigl{\\Vert} y_k(\\cdot) - {\\mathbb{E}}^M_k\n\\bigl[ \\psi_{Y,k}(\\cdot) \\bigr] \\bigr{\\Vert}_{k,M} + \\bigl\n{\\Vert}\\mathbb{E} ^{M}_k\\bigl[ \\psi_{Y,k}(\n\\cdot)\\bigr] - \\psi^{(M)}_{Y,k}(\\cdot) \\bigr{\\Vert}\n_{k,M}.\n\\end{eqnarray}\n\nBecause ${S^{(M)}_{{Y,k}}({\\cdot})}$ depends on ${z^{(M)}_{{k}}({\\cdot})}$ computed with\nthe same cloud of simulations $\\mathcal{C}_k$ as that used to define\nthe OLS\nsolution $\\psi^{(M)}_{Y,k}(\\cdot)$, it raises some interdependency issues\nthat we solve by {making} a small perturbation {to the intermediate\nprocesses} as follows {(compare with (\\ref{eqMDPlsdef}) and~(\\ref{eqPsiMy}))}:\nfor ${\\mathbf{\\underline{{x}} } }^{(k)} = (x_k,\\ldots, x_N)$, define\n\n\\begin{eqnarray*}\n&\\displaystyle {\\tilde S^{(M)}_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(k)}}\\bigr)} := \\Phi(x_N)\n+f_k \\bigl(x_k, {y^{(M)}_{{k+1}}({x_{k+1}})},\nz_{k}(x_k) \\bigr) \\Delta_k+ \\sum\n_{i=k+1}^{N-1} f_i \\bigl(x_i,\n{y^{(M)}_{{i+1}}({x_{i+1}})}, {z^{(M)}_{{i}}({x_i})} \\bigr) \\Delta_i,&\n\\\\\n&\\displaystyle\\tilde\\psi^{(M)}_{Y,k}(\\cdot) \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\n\\bigl({\\tilde S^{(M)}_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(k)}}\\bigr)}, \\mathcal{K}_{Y,k},\n\\nu_{k,M}\\bigr).&\n\\end{eqnarray*}\n\nThis perturbation is not needed for the $Z$-component, because ${S^{(M)}_{{Z,k}}({{\\mathbf{\\underline{{h}} } }^{(k)},{\\mathbf{\\underline{{x}} } }^{(k)}})}$ depends {only} on the subsequent\nclouds of simulations $\\{\\mathcal{C}_{j},j\\ge k+1\\}$.\nApplying the ${\\mathbf{L}}_2$-norm ${\\vert}\\cdot{\\vert}_2$, the\ntriangle inequality in\n(\\ref{eqMCy1}), and the first part of Lemma~\\ref{lembary} yields\n\n\n\\begin{eqnarray} \\label{eqMCy2}\n\\mathcal{E}(Y,M,k) & \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} + \\bigl\n{\\vert}\\bigl{\\Vert}\\mathbb{E}^{M}_k\\bigl[ \\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot)\\bigr]\\bigr\n{\\Vert}_{k,M} \\bigr{\\vert}_2\\nonumber\n\\\\\n&&{}  + \\bigl{\\vert}\\bigl{\\Vert}\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)- \\mathbb{E}^{M}_k\n\\bigl[ \\tilde\\psi^{(M)} _{Y,k}(\\cdot)\\bigr]\\bigr{\\Vert}\n_{k,M} \\bigr{\\vert}_2\n\\\\\n&&{}+ \\bigl{\\vert}\\bigl{\\Vert}\\tilde\\psi^{(M)}_{Y,k}(\n\\cdot)-\\psi^{(M)}_{Y,k}(\\cdot) \\bigr{\\Vert}_{k,M}\n\\bigr{\\vert}_2.\\nonumber\n\\end{eqnarray}\n\nLet us handle each term in the above inequality separately.\n\n\\begin{longlist}[$\\rhd$]\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\mathbb{E}^{M}_k[\n\\tilde\\psi^{(M)} _{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot)]{\\Vert}\n_{k,M} {\\vert}_2$.\nSet\n\n", "itemtype": "equation", "pos": 68556, "prevtext": "\n\n\\end{longlist}\n\n\\end{proposition}\n\n\\emph{Intermediate processes and local error terms.}\nAnother technique we borrow from \\cite{gobeturk14} is to introduce\nintermediate, \\emph{fictional} regressions based on the true solutions:\none replaces the full ${\\mathbf{L}}_2$ space for the approximation space and the\ntrue measure for the empirical measure in (\\ref{eqMDPlsdef}).\n\nFor each $k\\in\\{0,\\ldots,N-1\\}$, recall the functions ${S_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(i)}})}$ and ${S_{{Z,k}}({{\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}})}$ from\n(\\ref{eqMDPlsdef}),\nthe linear spaces $\\mathcal{K}_{Y,k}$ and $\\mathcal{K}_{Z,k}$ from Definition\n\\ref{deffindimspace}, and the empirical measure\n$\\nu_{k,M}$ from (\\ref{eqempimeasure}), and set\n\n\\begin{eqnarray*}\n&\\displaystyle\\psi_{Y,k}(\\cdot) \\quad\n\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( {S_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)},\n\\mathcal{K}_{Y,k}, \\nu_{k,M} \\bigr),&\n\\\\\n&\\displaystyle\\psi_{Z,k}(\\cdot) \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( {S_{{Z,k}}\\bigl({{\\mathbf{\\underline{{h}} } }^{(i)},{\\mathbf{\\underline{{x}} } }^{(i)}}\\bigr)}, \\mathcal{K}_{Z,k},\n\\nu_{k,M} \\bigr).&\n\\end{eqnarray*}\n\n\nNote that these regressions are not {numerically} accessible, because\nthey require knowledge of the true solution to be applied.\nAfter a series of conditioning arguments, based on Lemma~\\ref{lembary}\nbelow, the fictional regressions will eventually allow the use of\nthe stability estimates of Section~\\ref{sectionstab}, and (after a\nsomewhat complex application of the Gronwall inequalities of\nSection~\\ref{sectiongronwall}) this will yield final result.\n\nFrom Lemma~\\ref{lemcdnexp} and our Markovian assumptions, observe that\n\n", "index": 47, "text": "\n\\[\n\\bigl({\\mathbb{E}}^M_k\\bigl[{S_{{Y,k}}\\bigl({{X^{({k,m})}_{{}}} }\\bigr)}\\bigr],\n{\\mathbb{E}}^M_k\\bigl[ {S_{{Z,k}}\\bigl({{H^{({k,m})}_{{}}},{X^{({k,m})}_{{}}} }\\bigr)}\\bigr] \\bigr)\n= \\bigl( y_k\\bigl({X^{({k,m})}_{{k}}}\\bigr), z_k\\bigl({X^{({k,m})}_{{k}}}\\bigr) \\bigr)\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\bigl{(}{\\mathbb{E}}^{M}_{k}\\bigl{[}{S_{{Y,k}}\\bigl{(}{{X^{({k,m})}}}\\bigr{)}}%&#10;\\bigr{]},{\\mathbb{E}}^{M}_{k}\\bigl{[}{S_{{Z,k}}\\bigl{(}{{H^{({k,m})}},{X^{({k,%&#10;m})}}}\\bigr{)}}\\bigr{]}\\bigr{)}=\\bigl{(}y_{k}\\bigl{(}{X^{({k,m})}_{{k}}}\\bigr{%&#10;)},z_{k}\\bigl{(}{X^{({k,m})}_{{k}}}\\bigr{)}\\bigr{)}\" display=\"block\"><mrow><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msubsup><mi>E</mi><mi>k</mi><mi>M</mi></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><msub><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo>,</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msubsup><mi>E</mi><mi>k</mi><mi>M</mi></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><msub><mi>S</mi><mrow><mi>Z</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>=</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msubsup><mi>X</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>z</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msubsup><mi>X</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo>,</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nRecalling that ${\\tilde S^{(M)}_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(k)}})}-{S_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(k)}})}$\nis built only using the clouds $\\{\\mathcal{C}_{j},j\\geq k+1\\}$,\nit follows from {Lemma~\\ref{lemcdnexp}} that $\\mathbb\n{E}^{M}_k[{\\tilde S^{(M)}_{{Y,k}}({{X^{({k,m})}_{{ }}} })}-{S_{{Y,k}}({{X^{({k,m})}_{{ }}} })}]$ is equal to\n${\\tilde\\xi^*_{{Y,k}}({{X^{({k,m})}_{{k}}}})}$ for every $m \\in\\{1,\\ldots, M_k\\}$.\nThen, using Proposition~\\ref{proplsregproperties}(i)~and~(iii),\n$\\mathbb{E}^{M}_k[ \\tilde\\psi^{(M)}_{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot\n)]$ solves\n${\\mathrm{OLS}}({\\tilde\\xi^*_{{Y,k}}(\\cdot)}, \\mathcal{K}_{Y,k}, \\nu_{k,M})$.\nBy Proposition~\\ref{proplsregproperties}(ii),\n\n", "itemtype": "equation", "pos": 73622, "prevtext": "\n\nfor each $m\\in\\{1,\\ldots,M_k \\}$ where $ (y_k(\\cdot),z_k (\\cdot)\n)$ are the unknown functions defined in (\\ref{eqmarkov}). Proposition\n\\ref{proplsregproperties}(iii) implies the first statement of the\nfollowing lemma. The second statement results from a direct interchange\nof $\\inf$ and ${\\mathbb{E}}$, and from the identical distribution of\n$(X^{(k,m)}_k)$ for all~$m$.\n\n\\begin{lemma}\n\\label{lembary}\nFor each $k\\in\\{0,\\ldots,N-1\\}$,\n\n\\begin{eqnarray*}\n& \\displaystyle{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Y,k}(\\cdot)\\bigr] \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl(\ny_k(\\cdot ), \\mathcal{K}_{Y,k}, \\nu_{k,M} \\bigr),&\n\\\\\n& \\displaystyle {\\mathbb{E}}^M_k\\bigl[\\psi_{Z,k}(\\cdot)\\bigr] \\quad\n\\mbox{solves}\\quad{\\mathrm{OLS}}\\bigl( z_k(\\cdot ), \\mathcal{K}_{Z,k},\n\\nu_{k,M} \\bigr).&\n\\end{eqnarray*}\n\nIn addition, recalling the local error terms $\\mathcal{E}^Y_{\\mathrm\n{App.},k}$ and $\\mathcal{E}^Z_{\\mathrm{App.},k}$\nfrom Definition~\\ref{deffindimspace},\n\n\\begin{eqnarray*}\n \\mathbb{E} \\bigl[ \\bigl{\\Vert}{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Y,k}(\\cdot) \\bigr]-y_k(\\cdot) \\bigr{\\Vert}\n_{k,M} ^2 \\bigr]&=&\\mathbb{E} \\Bigl[ \\inf\n_{ \\phi\\in\\mathcal{K}_{Y,k} } \\bigl{\\Vert}\\phi(\\cdot) - y_k(\\cdot)\\bigr\n{\\Vert}_{k,M} ^2 \\Bigr]\\leq\\bigl(\\mathcal{E}\n^Y_{\\mathrm{App.},k}\\bigr)^2,\n\\\\\n \\mathbb{E} \\bigl[ \\bigl{\\Vert}{\\mathbb{E}}^M_k\\bigl[\n\\psi_{Z,k}(\\cdot) \\bigr] -z_k(\\cdot)\\bigr{\\Vert}\n_{k,M} ^2 \\bigr]&=&\\mathbb{E} \\Bigl[ \\inf\n_{ \\phi\\in\\mathcal{K}_{Z,k} } \\bigl{\\Vert}\\phi(\\cdot) - z_k(\\cdot)\\bigr\n{\\Vert}_{k,M} ^2 \\Bigr]\\leq\\bigl(\\mathcal{E}\n^Z_{\\mathrm{App.},k}\\bigr)^2.\n\\end{eqnarray*}\n\n\\end{lemma}\n\n\n\\subsubsection{Proof of Theorem \\texorpdfstring{\\protect\\ref{thmMCerr}}{3.10}}\n\n\\begin{longlist}\n\\item[\\textit{Step} 1: \\textit{decomposition of the error on $Y$.}]\nRecall the soft truncation function $\\mathcal{T}_L(x):= (-L\\vee x_1\n\\wedge L,\\ldots, -L \\vee x_n \\wedge L)$ {for $x\\in{\\mathbb{R}}^n$}.\nFrom the almost sure bounds of Corollary~\\ref{coras}, $\\mathcal\n{T}_{{C_{y,k}}}\n(y_k) = y_k$. Then, the Lipschitz continuity of $\\mathcal{T}_{{C_{y,k}}}$ yields\n$ {\\Vert} y_k(\\cdot) - {y^{(M)}_{{k}}({\\cdot})} {\\Vert}_{k,M} $ is\nless than or\nequal to\n${\\Vert} y_k(\\cdot) - \\psi^{(M)}_{Y,k}(\\cdot) {\\Vert}\n_{k,M} $.\nUsing the triangle inequality for the ${\\Vert}\\cdot{\\Vert}_{k,M}\n$-norm, it\nfollows that\n\n\n\\begin{eqnarray}\\label{eqMCy1}\n&& \\bigl{\\Vert} y_k(\\cdot)- {y^{(M)}_{k}(\\cdot)}\\bigr{\\Vert}_{k,M}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\quad  \\le\\bigl{\\Vert} y_k(\\cdot) - {\\mathbb{E}}^M_k\n\\bigl[ \\psi_{Y,k}(\\cdot) \\bigr] \\bigr{\\Vert}_{k,M} + \\bigl\n{\\Vert}\\mathbb{E} ^{M}_k\\bigl[ \\psi_{Y,k}(\n\\cdot)\\bigr] - \\psi^{(M)}_{Y,k}(\\cdot) \\bigr{\\Vert}\n_{k,M}.\n\\end{eqnarray}\n\nBecause ${S^{(M)}_{{Y,k}}({\\cdot})}$ depends on ${z^{(M)}_{{k}}({\\cdot})}$ computed with\nthe same cloud of simulations $\\mathcal{C}_k$ as that used to define\nthe OLS\nsolution $\\psi^{(M)}_{Y,k}(\\cdot)$, it raises some interdependency issues\nthat we solve by {making} a small perturbation {to the intermediate\nprocesses} as follows {(compare with (\\ref{eqMDPlsdef}) and~(\\ref{eqPsiMy}))}:\nfor ${\\mathbf{\\underline{{x}} } }^{(k)} = (x_k,\\ldots, x_N)$, define\n\n\\begin{eqnarray*}\n&\\displaystyle {\\tilde S^{(M)}_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(k)}}\\bigr)} := \\Phi(x_N)\n+f_k \\bigl(x_k, {y^{(M)}_{{k+1}}({x_{k+1}})},\nz_{k}(x_k) \\bigr) \\Delta_k+ \\sum\n_{i=k+1}^{N-1} f_i \\bigl(x_i,\n{y^{(M)}_{{i+1}}({x_{i+1}})}, {z^{(M)}_{{i}}({x_i})} \\bigr) \\Delta_i,&\n\\\\\n&\\displaystyle\\tilde\\psi^{(M)}_{Y,k}(\\cdot) \\quad\\mbox{solves}\\quad{\\mathrm{OLS}}\n\\bigl({\\tilde S^{(M)}_{{Y,k}}\\bigl({{\\mathbf{\\underline{{x}} } }^{(k)}}\\bigr)}, \\mathcal{K}_{Y,k},\n\\nu_{k,M}\\bigr).&\n\\end{eqnarray*}\n\nThis perturbation is not needed for the $Z$-component, because ${S^{(M)}_{{Z,k}}({{\\mathbf{\\underline{{h}} } }^{(k)},{\\mathbf{\\underline{{x}} } }^{(k)}})}$ depends {only} on the subsequent\nclouds of simulations $\\{\\mathcal{C}_{j},j\\ge k+1\\}$.\nApplying the ${\\mathbf{L}}_2$-norm ${\\vert}\\cdot{\\vert}_2$, the\ntriangle inequality in\n(\\ref{eqMCy1}), and the first part of Lemma~\\ref{lembary} yields\n\n\n\\begin{eqnarray} \\label{eqMCy2}\n\\mathcal{E}(Y,M,k) & \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} + \\bigl\n{\\vert}\\bigl{\\Vert}\\mathbb{E}^{M}_k\\bigl[ \\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot)\\bigr]\\bigr\n{\\Vert}_{k,M} \\bigr{\\vert}_2\\nonumber\n\\\\\n&&{}  + \\bigl{\\vert}\\bigl{\\Vert}\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)- \\mathbb{E}^{M}_k\n\\bigl[ \\tilde\\psi^{(M)} _{Y,k}(\\cdot)\\bigr]\\bigr{\\Vert}\n_{k,M} \\bigr{\\vert}_2\n\\\\\n&&{}+ \\bigl{\\vert}\\bigl{\\Vert}\\tilde\\psi^{(M)}_{Y,k}(\n\\cdot)-\\psi^{(M)}_{Y,k}(\\cdot) \\bigr{\\Vert}_{k,M}\n\\bigr{\\vert}_2.\\nonumber\n\\end{eqnarray}\n\nLet us handle each term in the above inequality separately.\n\n\\begin{longlist}[$\\rhd$]\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\mathbb{E}^{M}_k[\n\\tilde\\psi^{(M)} _{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot)]{\\Vert}\n_{k,M} {\\vert}_2$.\nSet\n\n", "index": 49, "text": "\n\\[\n{\\tilde\\xi^*_{{Y, k}}(x)}:={\\mathbb{E}}\\bigl({\\tilde S^{(M)}_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)}-{S_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)}\\mid X^{(k)}_k=x,{\\mathcal{F}^{(M)}_{{}}}\\bigr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"{\\tilde{\\xi}^{*}_{{Y,k}}(x)}:={\\mathbb{E}}\\bigl{(}{\\tilde{S}^{(M)}_{{Y,k}}%&#10;\\bigl{(}{{X}^{(k)}}\\bigr{)}}-{S_{{Y,k}}\\bigl{(}{{X}^{(k)}}\\bigr{)}}\\mid X^{(k)%&#10;}_{k}=x,{\\mathcal{F}^{(M)}}\\bigr{)}.\" display=\"block\"><mrow><msubsup><mover accent=\"true\"><mi>\u03be</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mo>*</mo></msubsup><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>:=</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msubsup><mover accent=\"true\"><mi>S</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>-</mo><msub><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow></msub><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2223</mo><msubsup><mi>X</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>x</mi><mo>,</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nwhere the final equality follows from the fact that ${\\tilde\\xi^*_{{Y,k}}({\\cdot})}$\nis generated only using the simulations in the clouds $\\{\\mathcal{C}_j\\dvt  j\n>k\\}$ and $\\{X_k,{X^{({k,1})}_{{k}}},\\ldots,{X^{({k,M_k})}_{{k}}}\\}$ are identically\ndistributed.\nDefining\n\n\n\n", "itemtype": "equation", "pos": 74511, "prevtext": "\n\nRecalling that ${\\tilde S^{(M)}_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(k)}})}-{S_{{Y,k}}({{\\mathbf{\\underline{{x}} } }^{(k)}})}$\nis built only using the clouds $\\{\\mathcal{C}_{j},j\\geq k+1\\}$,\nit follows from {Lemma~\\ref{lemcdnexp}} that $\\mathbb\n{E}^{M}_k[{\\tilde S^{(M)}_{{Y,k}}({{X^{({k,m})}_{{ }}} })}-{S_{{Y,k}}({{X^{({k,m})}_{{ }}} })}]$ is equal to\n${\\tilde\\xi^*_{{Y,k}}({{X^{({k,m})}_{{k}}}})}$ for every $m \\in\\{1,\\ldots, M_k\\}$.\nThen, using Proposition~\\ref{proplsregproperties}(i)~and~(iii),\n$\\mathbb{E}^{M}_k[ \\tilde\\psi^{(M)}_{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot\n)]$ solves\n${\\mathrm{OLS}}({\\tilde\\xi^*_{{Y,k}}(\\cdot)}, \\mathcal{K}_{Y,k}, \\nu_{k,M})$.\nBy Proposition~\\ref{proplsregproperties}(ii),\n\n", "index": 51, "text": "\n\\[\n{\\mathbb{E}}\\bigl[\\bigl{\\Vert}\\mathbb{E}^{M}_k\\bigl[ \\tilde\n\\psi^{(M)}_{Y,k}(\\cdot)-\\psi_{Y,k}(\\cdot)\\bigr]\\bigr\n{\\Vert}_{k,M} ^2 \\bigr] \\leq{\\mathbb{E}}\\bigl[ \\bigl{\\Vert}{\\tilde\\xi^*_{{Y,k}}(\\cdot)}\\bigr{\\Vert}_{k,M} ^2 \\bigr] = {\\mathbb{E}}\\bigl[\\bigl({\\tilde\\xi^*_{{Y,k}}({X_k})}\\bigr)^2 \\bigr], \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"{\\mathbb{E}}\\bigl{[}\\bigl{\\|}\\mathbb{E}^{M}_{k}\\bigl{[}\\tilde{\\psi}^{(M)}_{Y,k%&#10;}(\\cdot)-\\psi_{Y,k}(\\cdot)\\bigr{]}\\bigr{\\|}_{k,M}^{2}\\bigr{]}\\leq{\\mathbb{E}}%&#10;\\bigl{[}\\bigl{\\|}{\\tilde{\\xi}^{*}_{{Y,k}}(\\cdot)}\\bigr{\\|}_{k,M}^{2}\\bigr{]}={%&#10;\\mathbb{E}}\\bigl{[}\\bigl{(}{\\tilde{\\xi}^{*}_{{Y,k}}({X_{k}})}\\bigr{)}^{2}\\bigr%&#10;{]},\" display=\"block\"><mrow><mrow><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><msubsup><mi>E</mi><mi>k</mi><mi>M</mi></msubsup><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><mrow><mrow><msubsup><mover accent=\"true\"><mi>\u03c8</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>\u03c8</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo></mrow><mrow><mi>k</mi><mo>,</mo><mi>M</mi></mrow><mn>2</mn></msubsup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo>\u2264</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo><mrow><msubsup><mover accent=\"true\"><mi>\u03be</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mo>\u22c5</mo><mo stretchy=\"false\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">\u2225</mo></mrow><mrow><mi>k</mi><mo>,</mo><mi>M</mi></mrow><mn>2</mn></msubsup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow><mo>=</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msubsup><mover accent=\"true\"><mi>\u03be</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mo>*</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mn>2</mn></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nthe triangle inequality yields\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\tilde\\xi^*_{{Y,k}}({X_k })} \\bigr{\\vert}_2 & \\le&\\bigl{\\vert}\n{\\tilde S^{(M)}_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)} - {S^{(M)}_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)} \\bigr{\\vert}\n_2 + \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2\n\\\\\n& \\le&\\bigl{\\vert} f_k\\bigl(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, {z^{(M)}_{k}({X_{k} })} \\bigr) - f_k\n\\bigl(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, z_k(X_{k})\n\\bigr) \\bigr{\\vert}_2 \\Delta_k\n\\\\\n&&{}+ \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2\n\\\\\n& \\le&\\frac{L_f\\Delta_k}{(T-t_k)^{1/2-{\\thetaL/2}}} \\bar\\mathcal\n{E}(Z,M,k) + \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})}\\bigr{\\vert}_2.\n\\end{eqnarray*}\n\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)- \\mathbb{E}^{M}_k[ \\tilde\\psi^{(M)}_{Y,k}(\\cdot\n)]{\\Vert}_{k,M} {\\vert}_2$.\nSince $ {\\tilde S^{(M)}_{{Y,k}}({\\cdot})}{ }$ depends only on the clouds $\\{\\mathcal{C}\n_{j},j\\geq\nk+1\\}$ and is bounded from above by ${\\bar C_{{y,k}} } $ (like ${S^{(M)}_{{Y,k}}({\\cdot})}{ }$, see Lemma~\\ref{lemobsbounds}), it follows from\nProposition~\\ref{proplsregproperties}(iv) that ${\\vert}\n{\\Vert}\\tilde\\psi^{(M)} _{Y,k}(\\cdot)- \\mathbb{E}^{M}_k[\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)]{\\Vert}_{k,M} {\\vert}_2$ is\nbounded from\nabove by ${\\bar C_{{y,k}} } \\sqrt{K_{Y,k} /M_k}$. This is similar to the\nstatistical error term in usual regression theory.\n\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)-\\psi^{(M)} _{Y,k}(\\cdot) {\\Vert}_{k,M}\n{\\vert}_2$.\nOwing to Proposition~\\ref{proplsregproperties}(i)~and~(ii), ${\\Vert}\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)-\\psi^{(M)}_{Y,k}(\\cdot) {\\Vert}\n_{k,M} ^2$ is\nbounded from\nabove by\n${\\Vert}{\\tilde S^{(M)}_{{Y,k}}(\\cdot)}-{S^{(M)}_{{Y,k}}(\\cdot)}{\\Vert}_{k,M}\n^2$, which equals\n\n\\begin{eqnarray*}\n&& \\frac{\\Delta_k^2}{M_k} \\sum_{m=1}^{M_k} \\bigl\n{\\vert} f_k\\bigl({X^{({k,m})}_{k}},{y^{(M)}_{{k+1}}\\bigl({{X^{({k,m})}_{{k+1}}}}\\bigr)}, {z^{(M)}_{k}\\bigl({{X^{({k,m})}_{{k}}}}\\bigr)}\n\\bigr) - f_k\\bigl({X^{({k,m})}_{k}},{y^{(M)}_{{k+1}}\\bigl({{X^{({k,m})}_{{k+1}}}}\\bigr)}, z_k\\bigl(\n{X^{({k,m})}_{{k}}}\\bigr) \\bigr) \\bigr{\\vert}^2\n\\\\\n&&\\quad \\le\\frac{ L_f^2 \\Delta_k^2 {\\Vert} z_k(\\cdot) - {z^{(M)}_{k}(\\cdot)}\n{\\Vert}_{k,M} ^2\n}{ (T-t_k)^{1-{\\theta_L}} }.\n\\end{eqnarray*}\n\nCollecting the bounds on the three terms, substituting them into (\\ref\n{eqMCy2})\n{and applying Proposition~\\ref{propeqyzerrdecoM} }\nyields\n\n\n\\begin{eqnarray}\\label{eqMCy3}\n\\mathcal{E}(Y,M,k) & \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} + \\bigl{\\vert}\n\\xi^*_{Y,k}(X_k) \\bigr{\\vert}_2 +\n{\\bar C_{{y,k}} } \\sqrt{\\frac{ K_{Y,k}}{M_k}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}  + \\frac{L_f \\Delta_k}{\n(T-t_k)^{1/2-{\\thetaL/2}}} \\bigl\\{ (1 + \\sqrt2) {\n\\mathcal{E}(Z,M,k)} + \\mathcal{E}^Z_{\\mathrm\n{Dep.},k} \\bigr\\}.\n\\end{eqnarray}\n\\end{longlist}\n\\end{longlist}\n\n\\begin{longlist}\n\\item[\\textit{Step} 2: \\textit{decomposition of the error on $Z$.}]\nAnalogously to (\\ref{eqMCy2}), one obtains the upper bound\n\n\\begin{eqnarray}\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} + \\bigl\n{\\vert}\\bigl{\\Vert}\\mathbb{E}^{M}_k\\bigl[\n\\psi^{(M)}_{Z,k}(\\cdot)-\\psi_{Z,k}(\\cdot)\\bigr]\\bigr\n{\\Vert}_{k,M} \\bigr{\\vert}_2 + \\bigl{\\vert}\\bigl{\\Vert}\n\\psi^{(M)}_{Z,k}(\\cdot)- \\mathbb{E}^{M}_k\n\\bigl[ \\psi^{(M)}_{Z,k}(\\cdot)\\bigr]\\bigr{\\Vert}\n_{k,M} \\bigr{\\vert}_2.\n\\nonumber\n\\end{eqnarray}\n\nSince ${S^{(M)}_{{Z,k}}({\\cdot})} $ depends only on the clouds $\\{\\mathcal\n{C}_{j},j\\geq\nk+1\\}\n$ and the ${\\mathcal{F}^{(M)}_{k}}$-conditional variance of ${S^{(M)}_{{Z,k}}({{H^{({k,m})}_{{}}},{X^{({k,m})}_{{}}} })}$ is bounded from above by $ {\\bar C_{{z,k}} }^2 $ for all $m$ (see\nLemma~\\ref{lemobsbounds}), it follows from Proposition~\\ref\n{proplsregproperties}(iv) that ${\\vert}{\\Vert}\\psi\n^{(M)}_{Z,k}(\\cdot)- \\mathbb{E} ^{M}_k[ \\psi^{(M)}_{Z,k}(\\cdot\n)]{\\Vert}_{k,M} {\\vert}_2$ is bounded from\nabove by\n${\\bar C_{{z,k}} } \\sqrt{K_{Z,k} / M_k}$.\nDefining\n\n\n\n", "itemtype": "equation", "pos": 75092, "prevtext": "\n\nwhere the final equality follows from the fact that ${\\tilde\\xi^*_{{Y,k}}({\\cdot})}$\nis generated only using the simulations in the clouds $\\{\\mathcal{C}_j\\dvt  j\n>k\\}$ and $\\{X_k,{X^{({k,1})}_{{k}}},\\ldots,{X^{({k,M_k})}_{{k}}}\\}$ are identically\ndistributed.\nDefining\n\n\n\n", "index": 53, "text": "\\begin{equation}\n\\label{eqximy} {\\xi^*_{{Y,k}}(x)}:= {\\mathbb{E}}\\bigl[{S^{(M)}_{{Y,k}}\\bigl({X^{(k)}}\\bigr)}-{S_{{Y,k}}\\bigl({X^{(k)}}\\bigr)}\\mid X^{(k)}_k=x,{\\mathcal{F}^{(M)}_{{}}}\\bigr],\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"{\\xi^{*}_{{Y,k}}(x)}:={\\mathbb{E}}\\bigl{[}{S^{(M)}_{{Y,k}}\\bigl{(}{X^{(k)}}%&#10;\\bigr{)}}-{S_{{Y,k}}\\bigl{(}{X^{(k)}}\\bigr{)}}\\mid X^{(k)}_{k}=x,{\\mathcal{F}^%&#10;{(M)}}\\bigr{]},\" display=\"block\"><mrow><msubsup><mi>\u03be</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mo>*</mo></msubsup><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>:=</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>-</mo><msub><mi>S</mi><mrow><mi>Y</mi><mo>,</mo><mi>k</mi></mrow></msub><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2223</mo><msubsup><mi>X</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>x</mi><mo>,</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nit follows that\n$\\mathbb{E}^{M}_k[ \\psi^{(M)}_{Z,k}(\\cdot)-\\psi_{Z,k}(\\cdot)]$\nsolves ${\\mathrm{OLS}}(\\xi\n^*_{Z,k}(\\cdot), \\mathcal{K}_{Z,k}, \\nu_{k,M})$. Therefore,\n\n\n\\begin{eqnarray}\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} + \\bigl{\\vert}\n{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 +{\\bar C_{{z,k}} } \\sqrt{\n\\frac{K_{Z,k}} { M_k} }. \\label{eqMCz1}\n\\end{eqnarray}\n\n\\end{longlist}\n\n\n\\begin{longlist}\n\\item[\\textit{Step} 3: \\textit{error propagation and a priori estimates.}]\nObserve that $({\\xi^*_{{Y,k}}({X_k})}, {\\xi^*_{{Z,k}}({X_k})})$ defined in (\\ref\n{eqximy}),~(\\ref{eqximz}) solves a {MWDP} with terminal condition $0$\nand driver\n$f_{\\xi^*,k } (y,z):= f_k(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, {z^{(M)}_{k}({X_k})}\n)-f_k(X_k,y_{k+1}(X_{k+1}), z_k(X_k) )$.\nApplying\\break \nProposition~\\ref{propstability} with {$(Y_2,Z_2)\\equiv0$ (so that\n$L_{f_2} = 0$)} and using the Lipschitz continuity of $f_j(\\cdot )$ yields\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\nL_f \\sum_{j =\nk}^{N-1}\n\\frac{\\bar\\mathcal{E}\n(Y,M,j+1) + \\bar\\mathcal{E}(Z,M,j) }{(T-t_j)^{1/2 - {\\thetaL/2}} } \\Delta_j,\n\\\\\n\\bigl{\\vert}{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\nC_{M}L_f \\sum_{j =\nk+1}^{N-1}\n\\frac{\\bar\n\\mathcal{E}\n(Y,M,j+1) + \\bar\\mathcal{E}(Z,M,j) }{(T-t_j)^{1/2 - {\\thetaL/2}}\n\\sqrt\n{t_j - t_k} } \\Delta_j.\n\\end{eqnarray*}\n\nNext, introducing the notation $\\Theta_j:= \\mathcal{E}(Y,M,j+1) +\n\\mathcal{E}(Z,M,j)$\nand applying Proposition~\\ref{propeqyzerrdecoM}, it follows that\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\\sqrt2\nL_f \\sum_{j = k}^{N-1}\n\\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} } + L_f \\sum_{j\n= k}^{N-1}\n\\frac{ ( \\mathcal{E}^Y_{\\mathrm{Dep.},j+1}\n+ \\mathcal{E}\n^Z_{\\mathrm{Dep.},j} ) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} },\n\\\\\n\\bigl{\\vert}{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\\sqrt2\nC_{M}L_f \\sum_{j = k +1}^{N-1}\n\\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j -\nt_k}}\n\\\\\n&&{} + C_{M}L_f \\sum\n_{j = k+1}^{N-1} \\frac{ ( \\mathcal{E}^Y_{\\mathrm\n{Dep.},j+1}\n +\n\\mathcal{E}^Z_{\\mathrm{Dep.},j} )\n\\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k} }.\n\\end{eqnarray*}\n\nSubstituting the above into (\\ref{eqMCy3}) and (\\ref{eqMCz1}),\nand merging together the terms in $Z$, it follows that\n\n\n\n\\begin{eqnarray}\n\\mathcal{E}(Y,M,k)& \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} }\n\\sqrt{\\frac{\nK_{Y,k}}{M_k}} + 2L_f \\sum_{j = k}^{N-1}\n\\frac{ ( \\mathcal{E}^Y_{\\mathrm\n{Dep.},j+1} + \\mathcal{E}\n^Z_{\\mathrm{Dep.},j} ) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\\nonumber\n\\\\\n&&{} + 4 L_f \\sum_{j = k}^{N-1}\n\\frac{ \\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\n\\nonumber\\[-8pt]\\label{eqMCy4} \\[-8pt]\\nonumber\n& \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} } \\sqrt{\n\\frac{\nK_{Y,k}}{M_k}} + 2 \\sum_{j = k}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\n\\\\\n&&{} + 4 L_f \\sum_{j = k}^{N-1}\n\\frac{ \\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }, \\nonumber\n\\\\\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} +{\\bar C_{{z,k}} }\n\\sqrt{\\frac\n{K_{Z,k}} {\nM_k} } + C_{M}\\sum_{j = k+1}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k} }\n\\nonumber\\[-8pt]\\label{eqMCz2}\\[-8pt]\\nonumber\n&&{}+ \\sqrt2 C_{M}L_f \\sum\n_{j = k +1}^{N-1} \\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j -\nt_k}}.\n\\end{eqnarray}\n\\end{longlist}\n\n\\begin{longlist}\n\\item[\\textit{Step} 4: \\textit{final estimates.}]\nNow, summing (\\ref{eqMCz2}) and (\\ref{eqMCy4}), one obtains an\nestimate for $\\Theta_k$:\n\n\\begin{eqnarray*}\n\\Theta_k & \\le&\\mathcal{E}(k) + (C_{M}+ 2\\sqrt T) \\sum\n_{j =\nk+1}^{N-1} \\frac{\n\\mathcal{E}(j) \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt\n{t_j - t_k}\n}\n\\nonumber\n\\\\\n&&{}+ L_f( \\sqrt2 C_{M}+ 4 \\sqrt T) \\sum\n_{j = k +1}^{N-1} \\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k}}.\n\\end{eqnarray*}\n\nThus, using Lemmas~\\ref{lemiterationgen1} and~\\ref\n{lemiterationgen2} with $\\alpha= 0$, $\\beta= \\frac\\thetaL2$, $C_u\n= L_f( \\sqrt2 C_{M}+ 4 \\sqrt T)$, $w_k:=\\mathcal{E}(k) + (C_{M}+\n2\\sqrt\nT) \\sum_{j = k+1}^{N-1} \\frac{\n\\mathcal{E}(j) \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt\n{t_j - t_k}\n}$, we can control weighted sums involving $(\\Theta_k)_k$ using\nweighted sums of $(w_k)_k$, which is exactly what we need to complete\nthe upper bounds (\\ref{eqMCy4})--(\\ref{eqMCz2}) for $\\mathcal\n{E}(Y,M,k)$ and\n$\\mathcal{E}(Z,M,k)$. Namely, let $\\gamma>0$:\n\n\\begin{eqnarray*}\n&& \\sum_{j = k+1}^{N-1} \\frac{ w_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n\n\n\n\n\n\n&&\\quad  \\le\\sum\n_{j = k+1}^{N-1} \\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\qquad{}+(C_{M}+\n2\\sqrt T)\\sum_{l=k+2}^{N-1} \\frac{ \\mathcal{E}(l) \\Delta_l\n}{(T-t_l)^{1/2 - {\\thetaL/2}} }\n\\sum_{j = k+1}^{l-1} \\frac{ \\Delta_j\n}{(t_l-t_j)^{ 1 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\quad  \\le\\bigl(1+{B_{{{{\\theta_L}/2}},{\\gamma}}} T^{{\\theta_L}/2}(C_{M}+ 2\n\\sqrt T)\\bigr) \\sum_{l=k+1}^{N-1}\n\\frac{ \\mathcal{E}(l) \\Delta_l}{\n(T-t_l)^{1/2 - {\\thetaL/2}} (t_l - t_k)^{1 - \\gamma} },\n\\end{eqnarray*}\n\nwhere we have applied Lemma~\\ref{lemintegrals}. Thus,\n\n\\begin{eqnarray*}\n&& \\sum_{j = k+1}^{N-1} \\frac{\n\\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\quad  \\le\n{\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{{\\theta_L}/2}},{\\gamma}}} T^{{{\\theta_L}/2}}(C_{M}+\n2\\sqrt T)\\bigr) \\sum_{l=k+1}^{N-1}\n\\frac{ \\mathcal{E}(l) \\Delta_l}{\n(T-t_l)^{1/2 - {\\thetaL/2}} (t_l - t_k)^{1 - \\gamma} }\n\\end{eqnarray*}\n\nand plugging the above inequality into (\\ref{eqMCy4}) and (\\ref\n{eqMCz2}) yields (\\ref{eqMCyerr}) and (\\ref{eqMCzerr}).\n\n\\end{longlist}\n\n\n\\subsection{Complexity analysis}\\label{sectioncomplexity}\n\nAs usual in empirical regression theory, appropriately tuning numerical\nparamaters is crucial for finding the right trade-off between\nstatistical errors and estimation errors. This analysis allows to\nexpress the error magnitude as a function of computational work\n(complexity analysis).\nWe discuss { the complexity }in different cases according to the\nregularity of the value functions $(y_i(\\cdot), z_i(\\cdot))$ and the\nchoice of the grid $\\pi$. In order to have a fair comparison with other\nnumerical schemes, we revisit the setting of \\cite{gobeturk14}, Section~4.4, which we partly recall for completeness,\nand extend the analysis\n{to include more general settings.}\n\n\\begin{itemize}\n\n\\item We perform an asymptotic complexity analysis as the number $N$ of\ngrid times goes to $+\\infty$. We are concerned with time-dependent\nbounds: thus in the following, the order convention, $\\mathrm{O}(\\cdot )$ or $\\mathrm{o}(\\cdot )$,\nis uniform in $t_i$.\n\n\\item The grids under consideration are of the form ${\\pi^{(\\theta_\\pi)}}:=\\{t_i\n= T- T(1-\\frac{i}{N})^{{{1}/{{\\theta_\\pi}}}} \\}$ for $\\theta_\\pi\\in(0,1]$\n(inspired by \\cite{gobemakh10,geisgeisgobe12}). Observe that their\ntime-step $\\Delta_i$ is not-increasing in $i$, hence they all satisfy\n{$(\\mathbf{A_F})$\\textup{(iii)}}~with the same parameter $R_\\pi=1$.\n\n\\item The magnitude of the final accuracy is denoted by $N^{-{\\theta_{\\mathrm{conv}}}\n}$ for some parameter ${\\theta_{\\mathrm{conv}}}>0$. This is usually related to\ntime-discretization errors between the continuous-time BSDE and the\ndiscrete-time one, ${\\theta_{\\mathrm{conv}}}$ may range from $0^+$ (for non-smooth\ndata \\cite{gobemakh10}, Theorem 1.1) to~1 (in the case of smooth data\n\\cite{gobelaba07}, Theorems 7 and 8).\n\n\\item The approximation\\vspace*{1pt} spaces are given by local polynomials of degree\n$n$ $(n\\geq0)$ defined on hypercubes with edge length $\\delta>0$,\ncovering the set $[-R,R]^d$ ($R>0$): we denote it by ${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta ,R}}$. The functions in ${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}}$ take values in ${\\mathbb{R}}$ for\nthe $y$-component and in $({\\mathbb{R}}^q)^\\top$ for~$z$ {(using local\npolynomials component-wise)}, but we omit this in the notation. The\nbest-approximation errors are easily controlled (using the Taylor formula):\n\n\n\n", "itemtype": "equation", "pos": 79169, "prevtext": "\n\nthe triangle inequality yields\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\tilde\\xi^*_{{Y,k}}({X_k })} \\bigr{\\vert}_2 & \\le&\\bigl{\\vert}\n{\\tilde S^{(M)}_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)} - {S^{(M)}_{{Y,k}}\\bigl({{X}^{(k)}}\\bigr)} \\bigr{\\vert}\n_2 + \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2\n\\\\\n& \\le&\\bigl{\\vert} f_k\\bigl(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, {z^{(M)}_{k}({X_{k} })} \\bigr) - f_k\n\\bigl(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, z_k(X_{k})\n\\bigr) \\bigr{\\vert}_2 \\Delta_k\n\\\\\n&&{}+ \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2\n\\\\\n& \\le&\\frac{L_f\\Delta_k}{(T-t_k)^{1/2-{\\thetaL/2}}} \\bar\\mathcal\n{E}(Z,M,k) + \\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})}\\bigr{\\vert}_2.\n\\end{eqnarray*}\n\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)- \\mathbb{E}^{M}_k[ \\tilde\\psi^{(M)}_{Y,k}(\\cdot\n)]{\\Vert}_{k,M} {\\vert}_2$.\nSince $ {\\tilde S^{(M)}_{{Y,k}}({\\cdot})}{ }$ depends only on the clouds $\\{\\mathcal{C}\n_{j},j\\geq\nk+1\\}$ and is bounded from above by ${\\bar C_{{y,k}} } $ (like ${S^{(M)}_{{Y,k}}({\\cdot})}{ }$, see Lemma~\\ref{lemobsbounds}), it follows from\nProposition~\\ref{proplsregproperties}(iv) that ${\\vert}\n{\\Vert}\\tilde\\psi^{(M)} _{Y,k}(\\cdot)- \\mathbb{E}^{M}_k[\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)]{\\Vert}_{k,M} {\\vert}_2$ is\nbounded from\nabove by ${\\bar C_{{y,k}} } \\sqrt{K_{Y,k} /M_k}$. This is similar to the\nstatistical error term in usual regression theory.\n\n\\item[$\\rhd$] Term ${\\vert}{\\Vert}\\tilde\\psi\n^{(M)}_{Y,k}(\\cdot)-\\psi^{(M)} _{Y,k}(\\cdot) {\\Vert}_{k,M}\n{\\vert}_2$.\nOwing to Proposition~\\ref{proplsregproperties}(i)~and~(ii), ${\\Vert}\n\\tilde\\psi^{(M)}_{Y,k}(\\cdot)-\\psi^{(M)}_{Y,k}(\\cdot) {\\Vert}\n_{k,M} ^2$ is\nbounded from\nabove by\n${\\Vert}{\\tilde S^{(M)}_{{Y,k}}(\\cdot)}-{S^{(M)}_{{Y,k}}(\\cdot)}{\\Vert}_{k,M}\n^2$, which equals\n\n\\begin{eqnarray*}\n&& \\frac{\\Delta_k^2}{M_k} \\sum_{m=1}^{M_k} \\bigl\n{\\vert} f_k\\bigl({X^{({k,m})}_{k}},{y^{(M)}_{{k+1}}\\bigl({{X^{({k,m})}_{{k+1}}}}\\bigr)}, {z^{(M)}_{k}\\bigl({{X^{({k,m})}_{{k}}}}\\bigr)}\n\\bigr) - f_k\\bigl({X^{({k,m})}_{k}},{y^{(M)}_{{k+1}}\\bigl({{X^{({k,m})}_{{k+1}}}}\\bigr)}, z_k\\bigl(\n{X^{({k,m})}_{{k}}}\\bigr) \\bigr) \\bigr{\\vert}^2\n\\\\\n&&\\quad \\le\\frac{ L_f^2 \\Delta_k^2 {\\Vert} z_k(\\cdot) - {z^{(M)}_{k}(\\cdot)}\n{\\Vert}_{k,M} ^2\n}{ (T-t_k)^{1-{\\theta_L}} }.\n\\end{eqnarray*}\n\nCollecting the bounds on the three terms, substituting them into (\\ref\n{eqMCy2})\n{and applying Proposition~\\ref{propeqyzerrdecoM} }\nyields\n\n\n\\begin{eqnarray}\\label{eqMCy3}\n\\mathcal{E}(Y,M,k) & \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} + \\bigl{\\vert}\n\\xi^*_{Y,k}(X_k) \\bigr{\\vert}_2 +\n{\\bar C_{{y,k}} } \\sqrt{\\frac{ K_{Y,k}}{M_k}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{}  + \\frac{L_f \\Delta_k}{\n(T-t_k)^{1/2-{\\thetaL/2}}} \\bigl\\{ (1 + \\sqrt2) {\n\\mathcal{E}(Z,M,k)} + \\mathcal{E}^Z_{\\mathrm\n{Dep.},k} \\bigr\\}.\n\\end{eqnarray}\n\\end{longlist}\n\\end{longlist}\n\n\\begin{longlist}\n\\item[\\textit{Step} 2: \\textit{decomposition of the error on $Z$.}]\nAnalogously to (\\ref{eqMCy2}), one obtains the upper bound\n\n\\begin{eqnarray}\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} + \\bigl\n{\\vert}\\bigl{\\Vert}\\mathbb{E}^{M}_k\\bigl[\n\\psi^{(M)}_{Z,k}(\\cdot)-\\psi_{Z,k}(\\cdot)\\bigr]\\bigr\n{\\Vert}_{k,M} \\bigr{\\vert}_2 + \\bigl{\\vert}\\bigl{\\Vert}\n\\psi^{(M)}_{Z,k}(\\cdot)- \\mathbb{E}^{M}_k\n\\bigl[ \\psi^{(M)}_{Z,k}(\\cdot)\\bigr]\\bigr{\\Vert}\n_{k,M} \\bigr{\\vert}_2.\n\\nonumber\n\\end{eqnarray}\n\nSince ${S^{(M)}_{{Z,k}}({\\cdot})} $ depends only on the clouds $\\{\\mathcal\n{C}_{j},j\\geq\nk+1\\}\n$ and the ${\\mathcal{F}^{(M)}_{k}}$-conditional variance of ${S^{(M)}_{{Z,k}}({{H^{({k,m})}_{{}}},{X^{({k,m})}_{{}}} })}$ is bounded from above by $ {\\bar C_{{z,k}} }^2 $ for all $m$ (see\nLemma~\\ref{lemobsbounds}), it follows from Proposition~\\ref\n{proplsregproperties}(iv) that ${\\vert}{\\Vert}\\psi\n^{(M)}_{Z,k}(\\cdot)- \\mathbb{E} ^{M}_k[ \\psi^{(M)}_{Z,k}(\\cdot\n)]{\\Vert}_{k,M} {\\vert}_2$ is bounded from\nabove by\n${\\bar C_{{z,k}} } \\sqrt{K_{Z,k} / M_k}$.\nDefining\n\n\n\n", "index": 55, "text": "\\begin{equation}\n\\label{eqximz} \\xi^*_{Z, k}(x):={\\mathbb{E}}\\bigl[{S^{(M)}_{{Z,k}}\\bigl({{H^{({k})}_{{}}},{X}^{(k)}}\\bigr)}-{S_{{Z,k}}\\bigl({{H^{({k})}_{{}}},{X}^{(k)}}\\bigr)}\\mid\nX^{(k)}_k=x,{\\mathcal{F}^{(M)}_{{}}}\\bigr],\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\xi^{*}_{Z,k}(x):={\\mathbb{E}}\\bigl{[}{S^{(M)}_{{Z,k}}\\bigl{(}{{H^{({k})}},{X}%&#10;^{(k)}}\\bigr{)}}-{S_{{Z,k}}\\bigl{(}{{H^{({k})}},{X}^{(k)}}\\bigr{)}}\\mid X^{(k)%&#10;}_{k}=x,{\\mathcal{F}^{(M)}}\\bigr{]},\" display=\"block\"><mrow><msubsup><mi>\u03be</mi><mrow><mi>Z</mi><mo>,</mo><mi>k</mi></mrow><mo>*</mo></msubsup><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>:=</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>E</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">[</mo><msubsup><mi>S</mi><mrow><mi>Z</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>-</mo><msub><mi>S</mi><mrow><mi>Z</mi><mo>,</mo><mi>k</mi></mrow></msub><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msup><mi>H</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2223</mo><msubsup><mi>X</mi><mi>k</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>x</mi><mo>,</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\u2131</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo maxsize=\"120%\" minsize=\"120%\">]</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nfor any function $u$ that is bounded, $n+1$-times continuously\ndifferentiable with bounded derivatives, and where the constant $c_n$\ndoes not depend on $(R,u,\\delta)$. The dimension of the vector space\n${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}}$ is bounded by $\\tilde c_n (2R/\\delta)^{d}$ where\n$\\tilde c_n$ {is the number of polynomials on each hypercube (it\ndepends on $d$ and $n$)}.\n\nA significant computational advantage of local polynomial basis is that\nthe cost of computing the regression coefficients associated to a\nsample of size $M\\geq\\operatorname{dim}({\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}})$ is $\\mathrm{O}(M)$ flops.\n{The cost of the regression in the $l$th hypercube is of order\n$M^{(l)} \\times{\\tilde c_n^2}$ using SVD least squares minimization\n\\cite{goluvanl96}, Chapter~5, where $M^{(l)}$ is the number of\nsimulations that land in the hypercube.\nTherefore, the total cost of the regressions at any time-point is of\norder ${\\tilde c_n^2} \\sum_l M^{(l)} = {\\tilde c_n^2} M = \\mathrm{O}(M)$.\n}\n\n\n\n\nOn the other hand, the cost of generating the clouds of simulations and\ncomputing the simulated functionals $({S^{(M)}_{{Y,i}}({X^{(i,m)}})},{S^{(M)}_{{Z,i}}({{H}^{(i,m)},{X}^{(i,m)}})})_{i,m}$ is $\\mathrm{O}(\\sum_{i=0}^{N-1}NM_i)$,\nwhich is clearly dominant in the computational cost $\\mathcal{C}$ of\nthe MWLS\nalgorithm. To summarize, the computational cost is\n\n", "itemtype": "equation", "pos": 87474, "prevtext": "\n\nit follows that\n$\\mathbb{E}^{M}_k[ \\psi^{(M)}_{Z,k}(\\cdot)-\\psi_{Z,k}(\\cdot)]$\nsolves ${\\mathrm{OLS}}(\\xi\n^*_{Z,k}(\\cdot), \\mathcal{K}_{Z,k}, \\nu_{k,M})$. Therefore,\n\n\n\\begin{eqnarray}\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} + \\bigl{\\vert}\n{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 +{\\bar C_{{z,k}} } \\sqrt{\n\\frac{K_{Z,k}} { M_k} }. \\label{eqMCz1}\n\\end{eqnarray}\n\n\\end{longlist}\n\n\n\\begin{longlist}\n\\item[\\textit{Step} 3: \\textit{error propagation and a priori estimates.}]\nObserve that $({\\xi^*_{{Y,k}}({X_k})}, {\\xi^*_{{Z,k}}({X_k})})$ defined in (\\ref\n{eqximy}),~(\\ref{eqximz}) solves a {MWDP} with terminal condition $0$\nand driver\n$f_{\\xi^*,k } (y,z):= f_k(X_k,{y^{(M)}_{{k+1}}({X_{k+1}})}, {z^{(M)}_{k}({X_k})}\n)-f_k(X_k,y_{k+1}(X_{k+1}), z_k(X_k) )$.\nApplying\\break \nProposition~\\ref{propstability} with {$(Y_2,Z_2)\\equiv0$ (so that\n$L_{f_2} = 0$)} and using the Lipschitz continuity of $f_j(\\cdot )$ yields\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\nL_f \\sum_{j =\nk}^{N-1}\n\\frac{\\bar\\mathcal{E}\n(Y,M,j+1) + \\bar\\mathcal{E}(Z,M,j) }{(T-t_j)^{1/2 - {\\thetaL/2}} } \\Delta_j,\n\\\\\n\\bigl{\\vert}{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\nC_{M}L_f \\sum_{j =\nk+1}^{N-1}\n\\frac{\\bar\n\\mathcal{E}\n(Y,M,j+1) + \\bar\\mathcal{E}(Z,M,j) }{(T-t_j)^{1/2 - {\\thetaL/2}}\n\\sqrt\n{t_j - t_k} } \\Delta_j.\n\\end{eqnarray*}\n\nNext, introducing the notation $\\Theta_j:= \\mathcal{E}(Y,M,j+1) +\n\\mathcal{E}(Z,M,j)$\nand applying Proposition~\\ref{propeqyzerrdecoM}, it follows that\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{\\xi^*_{{Y,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\\sqrt2\nL_f \\sum_{j = k}^{N-1}\n\\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} } + L_f \\sum_{j\n= k}^{N-1}\n\\frac{ ( \\mathcal{E}^Y_{\\mathrm{Dep.},j+1}\n+ \\mathcal{E}\n^Z_{\\mathrm{Dep.},j} ) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} },\n\\\\\n\\bigl{\\vert}{\\xi^*_{{Z,k}}({X_k})} \\bigr{\\vert}_2 & \\le&\\sqrt2\nC_{M}L_f \\sum_{j = k +1}^{N-1}\n\\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j -\nt_k}}\n\\\\\n&&{} + C_{M}L_f \\sum\n_{j = k+1}^{N-1} \\frac{ ( \\mathcal{E}^Y_{\\mathrm\n{Dep.},j+1}\n +\n\\mathcal{E}^Z_{\\mathrm{Dep.},j} )\n\\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k} }.\n\\end{eqnarray*}\n\nSubstituting the above into (\\ref{eqMCy3}) and (\\ref{eqMCz1}),\nand merging together the terms in $Z$, it follows that\n\n\n\n\\begin{eqnarray}\n\\mathcal{E}(Y,M,k)& \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} }\n\\sqrt{\\frac{\nK_{Y,k}}{M_k}} + 2L_f \\sum_{j = k}^{N-1}\n\\frac{ ( \\mathcal{E}^Y_{\\mathrm\n{Dep.},j+1} + \\mathcal{E}\n^Z_{\\mathrm{Dep.},j} ) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\\nonumber\n\\\\\n&&{} + 4 L_f \\sum_{j = k}^{N-1}\n\\frac{ \\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\n\\nonumber\\[-8pt]\\label{eqMCy4} \\[-8pt]\\nonumber\n& \\le&\\mathcal{E}^Y_{\\mathrm{App.},k} +{\\bar C_{{y,k}} } \\sqrt{\n\\frac{\nK_{Y,k}}{M_k}} + 2 \\sum_{j = k}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }\n\\\\\n&&{} + 4 L_f \\sum_{j = k}^{N-1}\n\\frac{ \\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} }, \\nonumber\n\\\\\n\\mathcal{E}(Z,M,k) & \\le&\\mathcal{E}^Z_{\\mathrm{App.},k} +{\\bar C_{{z,k}} }\n\\sqrt{\\frac\n{K_{Z,k}} {\nM_k} } + C_{M}\\sum_{j = k+1}^{N-1}\n\\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k} }\n\\nonumber\\[-8pt]\\label{eqMCz2}\\[-8pt]\\nonumber\n&&{}+ \\sqrt2 C_{M}L_f \\sum\n_{j = k +1}^{N-1} \\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j -\nt_k}}.\n\\end{eqnarray}\n\\end{longlist}\n\n\\begin{longlist}\n\\item[\\textit{Step} 4: \\textit{final estimates.}]\nNow, summing (\\ref{eqMCz2}) and (\\ref{eqMCy4}), one obtains an\nestimate for $\\Theta_k$:\n\n\\begin{eqnarray*}\n\\Theta_k & \\le&\\mathcal{E}(k) + (C_{M}+ 2\\sqrt T) \\sum\n_{j =\nk+1}^{N-1} \\frac{\n\\mathcal{E}(j) \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt\n{t_j - t_k}\n}\n\\nonumber\n\\\\\n&&{}+ L_f( \\sqrt2 C_{M}+ 4 \\sqrt T) \\sum\n_{j = k +1}^{N-1} \\frac{\n\\Theta_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt{t_j - t_k}}.\n\\end{eqnarray*}\n\nThus, using Lemmas~\\ref{lemiterationgen1} and~\\ref\n{lemiterationgen2} with $\\alpha= 0$, $\\beta= \\frac\\thetaL2$, $C_u\n= L_f( \\sqrt2 C_{M}+ 4 \\sqrt T)$, $w_k:=\\mathcal{E}(k) + (C_{M}+\n2\\sqrt\nT) \\sum_{j = k+1}^{N-1} \\frac{\n\\mathcal{E}(j) \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} \\sqrt\n{t_j - t_k}\n}$, we can control weighted sums involving $(\\Theta_k)_k$ using\nweighted sums of $(w_k)_k$, which is exactly what we need to complete\nthe upper bounds (\\ref{eqMCy4})--(\\ref{eqMCz2}) for $\\mathcal\n{E}(Y,M,k)$ and\n$\\mathcal{E}(Z,M,k)$. Namely, let $\\gamma>0$:\n\n\\begin{eqnarray*}\n&& \\sum_{j = k+1}^{N-1} \\frac{ w_j \\Delta_j }{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n\n\n\n\n\n\n&&\\quad  \\le\\sum\n_{j = k+1}^{N-1} \\frac{ \\mathcal{E}(j) \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\qquad{}+(C_{M}+\n2\\sqrt T)\\sum_{l=k+2}^{N-1} \\frac{ \\mathcal{E}(l) \\Delta_l\n}{(T-t_l)^{1/2 - {\\thetaL/2}} }\n\\sum_{j = k+1}^{l-1} \\frac{ \\Delta_j\n}{(t_l-t_j)^{ 1 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\quad  \\le\\bigl(1+{B_{{{{\\theta_L}/2}},{\\gamma}}} T^{{\\theta_L}/2}(C_{M}+ 2\n\\sqrt T)\\bigr) \\sum_{l=k+1}^{N-1}\n\\frac{ \\mathcal{E}(l) \\Delta_l}{\n(T-t_l)^{1/2 - {\\thetaL/2}} (t_l - t_k)^{1 - \\gamma} },\n\\end{eqnarray*}\n\nwhere we have applied Lemma~\\ref{lemintegrals}. Thus,\n\n\\begin{eqnarray*}\n&& \\sum_{j = k+1}^{N-1} \\frac{\n\\Theta_j \\Delta_j\n}{(T-t_j)^{1/2 - {\\thetaL/2}} (t_j - t_k)^{1-\\gamma} }\n\\\\\n&&\\quad  \\le\n{\\mathcal C}^{({\\gamma})}_{(\\ref{eqintuw})}\\bigl(1+{B_{{{{\\theta_L}/2}},{\\gamma}}} T^{{{\\theta_L}/2}}(C_{M}+\n2\\sqrt T)\\bigr) \\sum_{l=k+1}^{N-1}\n\\frac{ \\mathcal{E}(l) \\Delta_l}{\n(T-t_l)^{1/2 - {\\thetaL/2}} (t_l - t_k)^{1 - \\gamma} }\n\\end{eqnarray*}\n\nand plugging the above inequality into (\\ref{eqMCy4}) and (\\ref\n{eqMCz2}) yields (\\ref{eqMCyerr}) and (\\ref{eqMCzerr}).\n\n\\end{longlist}\n\n\n\\subsection{Complexity analysis}\\label{sectioncomplexity}\n\nAs usual in empirical regression theory, appropriately tuning numerical\nparamaters is crucial for finding the right trade-off between\nstatistical errors and estimation errors. This analysis allows to\nexpress the error magnitude as a function of computational work\n(complexity analysis).\nWe discuss { the complexity }in different cases according to the\nregularity of the value functions $(y_i(\\cdot), z_i(\\cdot))$ and the\nchoice of the grid $\\pi$. In order to have a fair comparison with other\nnumerical schemes, we revisit the setting of \\cite{gobeturk14}, Section~4.4, which we partly recall for completeness,\nand extend the analysis\n{to include more general settings.}\n\n\\begin{itemize}\n\n\\item We perform an asymptotic complexity analysis as the number $N$ of\ngrid times goes to $+\\infty$. We are concerned with time-dependent\nbounds: thus in the following, the order convention, $\\mathrm{O}(\\cdot )$ or $\\mathrm{o}(\\cdot )$,\nis uniform in $t_i$.\n\n\\item The grids under consideration are of the form ${\\pi^{(\\theta_\\pi)}}:=\\{t_i\n= T- T(1-\\frac{i}{N})^{{{1}/{{\\theta_\\pi}}}} \\}$ for $\\theta_\\pi\\in(0,1]$\n(inspired by \\cite{gobemakh10,geisgeisgobe12}). Observe that their\ntime-step $\\Delta_i$ is not-increasing in $i$, hence they all satisfy\n{$(\\mathbf{A_F})$\\textup{(iii)}}~with the same parameter $R_\\pi=1$.\n\n\\item The magnitude of the final accuracy is denoted by $N^{-{\\theta_{\\mathrm{conv}}}\n}$ for some parameter ${\\theta_{\\mathrm{conv}}}>0$. This is usually related to\ntime-discretization errors between the continuous-time BSDE and the\ndiscrete-time one, ${\\theta_{\\mathrm{conv}}}$ may range from $0^+$ (for non-smooth\ndata \\cite{gobemakh10}, Theorem 1.1) to~1 (in the case of smooth data\n\\cite{gobelaba07}, Theorems 7 and 8).\n\n\\item The approximation\\vspace*{1pt} spaces are given by local polynomials of degree\n$n$ $(n\\geq0)$ defined on hypercubes with edge length $\\delta>0$,\ncovering the set $[-R,R]^d$ ($R>0$): we denote it by ${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta ,R}}$. The functions in ${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}}$ take values in ${\\mathbb{R}}$ for\nthe $y$-component and in $({\\mathbb{R}}^q)^\\top$ for~$z$ {(using local\npolynomials component-wise)}, but we omit this in the notation. The\nbest-approximation errors are easily controlled (using the Taylor formula):\n\n\n\n", "index": 57, "text": "\\begin{equation}\n\\label{eqpolloc} \\inf_{\\varphi\\in{\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}}}\\bigl{\\vert}\n\\varphi\n(X_i)-u(X_i)\\bigr{\\vert}_2\\leq{\\vert} u\n{\\vert}_\\infty\\bigl({\\mathbb{P}}\\bigl({\\vert} X_i{\\vert}\n_\\infty>R\\bigr)\\bigr)^{1/2}+ c_n \\bigl{\\vert}\nD^{n+1} u\\bigr{\\vert}_\\infty\\delta^{n+1}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\inf_{\\varphi\\in{\\mathcal{P}}_{\\mathrm{loc.}}^{{n,\\delta,R}}}\\bigl{|}\\varphi(X%&#10;_{i})-u(X_{i})\\bigr{|}_{2}\\leq{|}u{|}_{\\infty}\\bigl{(}{\\mathbb{P}}\\bigl{(}{|}X%&#10;_{i}{|}_{\\infty}&gt;R\\bigr{)}\\bigr{)}^{1/2}+c_{n}\\bigl{|}D^{n+1}u\\bigr{|}_{\\infty%&#10;}\\delta^{n+1}\" display=\"block\"><mrow><munder><mo movablelimits=\"false\">inf</mo><mrow><mi>\u03c6</mi><mo>\u2208</mo><msubsup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mrow><mi>loc</mi><mo>.</mo></mrow><mrow><mi>n</mi><mo>,</mo><mi>\u03b4</mi><mo>,</mo><mi>R</mi></mrow></msubsup></mrow></munder><msub><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mi>\u03c6</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mi>u</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mn>2</mn></msub><mo>\u2264</mo><mo stretchy=\"false\">|</mo><mi>u</mi><msub><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u221e</mi></msub><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\mathbb</mtext></merror><mi>P</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mo stretchy=\"false\">|</mo><msub><mi>X</mi><mi>i</mi></msub><msub><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u221e</mi></msub><mo>&gt;</mo><mi>R</mi><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>+</mo><msub><mi>c</mi><mi>n</mi></msub><msub><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><msup><mi>D</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup><mi>u</mi><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mi mathvariant=\"normal\">\u221e</mi></msub><msup><mi>\u03b4</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n{Another advantage of the local polynomial basis is that there is\nsubstantial potential for parallel computing.}\n\n\\item To make the tail contributions (outside $[-R,R]^d$) small enough,\nwe assume that $X_i$ has exponential moments (uniformly in $i$), that\nis, $\\sup_{N\\geq1}\\sup_{0\\leq i \\leq N}{\\mathbb{E}}(\\mathrm{e}^{\\lambda{\\vert}\nX_i{\\vert}_\\infty\n})<+\\infty$ for some $\\lambda>0$, so that the choice\n$ R:= 2{\\theta_{\\mathrm{conv}}}\\lambda^{-1} \\log(N+1)$ is sufficient to ensure\n$({\\mathbb{P}}\n({\\vert} X_i{\\vert}_\\infty> R))^{1/2}= \\mathrm{O}(N^{-{\\theta_{\\mathrm{conv}}}})$.\n\\end{itemize}\n\nTo simplify the discussion, we assume ${\\theta_L}={\\theta_c}=1$.\n\n\n\\subsubsection*{Smooth functions} Assume that $y_i(\\cdot), z_i(\\cdot)$ are,\nrespectively, of class $\\mathcal{C}^{l+1}_b({\\mathbb{R}}^d,{\\mathbb{R}})$ and $\\mathcal\n{C}^{l}_b({\\mathbb{R}}\n^d,({\\mathbb{R}}\n^q)^\\top)$ (bounded with bounded derivatives) for some $l \\in{\\mathbb{N}}\n\\setminus\\{0\\}$: this is similar to the discussion of \\cite{gobeturk14}, Section~4.4. In fact, this is usually valid for the\ncontinuous-time limit (a priori estimates on the semi-linear PDE, see\n\\cite{delaguat06,crisdela12}) provided that the data are smooth\nenough. In particular, we may assume {$(\\mathbf{A''_{\\bolds{\\xi}}})$}~with $\\theta_\\Phi=1$. This\nleads to time-uniform bounds on the quantities $C_{y,i}, C_{z,i},\n{\\bar C_{{y,i}} }, \\sqrt{T-t_i}{\\bar C_{{z,i}} }$.\n\nSet\n\n", "itemtype": "equation", "pos": 89173, "prevtext": "\n\nfor any function $u$ that is bounded, $n+1$-times continuously\ndifferentiable with bounded derivatives, and where the constant $c_n$\ndoes not depend on $(R,u,\\delta)$. The dimension of the vector space\n${\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}}$ is bounded by $\\tilde c_n (2R/\\delta)^{d}$ where\n$\\tilde c_n$ {is the number of polynomials on each hypercube (it\ndepends on $d$ and $n$)}.\n\nA significant computational advantage of local polynomial basis is that\nthe cost of computing the regression coefficients associated to a\nsample of size $M\\geq\\operatorname{dim}({\\mathcal P}_{\\mathrm{loc.}}^{{n,\\delta,R}})$ is $\\mathrm{O}(M)$ flops.\n{The cost of the regression in the $l$th hypercube is of order\n$M^{(l)} \\times{\\tilde c_n^2}$ using SVD least squares minimization\n\\cite{goluvanl96}, Chapter~5, where $M^{(l)}$ is the number of\nsimulations that land in the hypercube.\nTherefore, the total cost of the regressions at any time-point is of\norder ${\\tilde c_n^2} \\sum_l M^{(l)} = {\\tilde c_n^2} M = \\mathrm{O}(M)$.\n}\n\n\n\n\nOn the other hand, the cost of generating the clouds of simulations and\ncomputing the simulated functionals $({S^{(M)}_{{Y,i}}({X^{(i,m)}})},{S^{(M)}_{{Z,i}}({{H}^{(i,m)},{X}^{(i,m)}})})_{i,m}$ is $\\mathrm{O}(\\sum_{i=0}^{N-1}NM_i)$,\nwhich is clearly dominant in the computational cost $\\mathcal{C}$ of\nthe MWLS\nalgorithm. To summarize, the computational cost is\n\n", "index": 59, "text": "\n\\[\n\\mathcal{C}=\\mathrm{O}\\Biggl(\\sum_{i=0}^{N-1}N\nM_i\\Biggr).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}=\\mathrm{O}\\Biggl{(}\\sum_{i=0}^{N-1}NM_{i}\\Biggr{)}.\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">O</mi><mo>\u2062</mo><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>N</mi><mo>\u2062</mo><msub><mi>M</mi><mi>i</mi></msub></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\ntake $\\mathcal{K}_{Y,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l,\\delta_{y,i},R}}$ and $\\mathcal\n{K}_{Z,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l-1,\\delta_{z,i},R}}$.\nFrom Proposition~\\ref{propeqyzerrdecoM}, Theorem~\\ref{thmMCerr}\nand the inequality (\\ref{eqpolloc}), it is easy to check that\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{App.},i} &=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Y_{\\mathrm\n{Dep.},i}=\\mathrm{o}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n{\\bar C_{{y,i}} }\\sqrt{\\frac{ K_{Y,i}}{M_{i} }}&=&\\mathrm{o} \\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}/\\sqrt{\n\\log(N+1)} \\bigr),\n\\\\\n\\mathcal{E}^Z_{\\mathrm{App.},i}&=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Z_{\\mathrm{Dep.},i}=\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\\\\n{\\bar C_{{z,i}} }\\sqrt{\\frac{ K_{Z,i}}{M_{i} }}&=&(T-t_i)^{-{{ 1 }/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}/\\sqrt{\\log(N+1)} \\bigr).\n\\end{eqnarray*}\n\nConsequently, using Lemma~\\ref{lemintegrals}, we finally obtain\n\n\\begin{eqnarray*}\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_i - y^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_i -\nz^M_i\\bigr{\\Vert}_{i,M} ^2\n\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr) \\biggl(1+\n\\frac{(T-t_i)^{-{{ 1 }/{2 }}}}{\\sqrt{\\log(N+1)}} \\biggr).\n\\end{eqnarray*}\n\nFor\\vspace*{1pt} any time-grid $\\pi={\\pi^{(\\theta_\\pi)}}$, we get $\\sup_{0\\leq i\\leq N}{\\mathbb{E}}\n[{\\Vert} y_i - y^M_i {\\Vert}_{i,M} ^2]+ \\sum_{i=0}^{N-1}\\Delta_i {\\mathbb{E}}\n[{\\Vert} z_i - z^M_i{\\Vert}_{i,M} ^2]= \\mathrm{O}(N^{-2{\\theta_{\\mathrm{conv}}}})$.\nThe computational cost is\n$\\mathcal{C}=\\mathrm{O} (\\log(N+1)^{d+1} N^{{\\theta_{\\mathrm{conv}}}(2+{{ d }/{l }})+2})$.\nIgnoring the logarithmic factors, we obtain a final accuracy in terms\nof the computational cost:\n\n", "itemtype": "equation", "pos": 90661, "prevtext": "\n\n{Another advantage of the local polynomial basis is that there is\nsubstantial potential for parallel computing.}\n\n\\item To make the tail contributions (outside $[-R,R]^d$) small enough,\nwe assume that $X_i$ has exponential moments (uniformly in $i$), that\nis, $\\sup_{N\\geq1}\\sup_{0\\leq i \\leq N}{\\mathbb{E}}(\\mathrm{e}^{\\lambda{\\vert}\nX_i{\\vert}_\\infty\n})<+\\infty$ for some $\\lambda>0$, so that the choice\n$ R:= 2{\\theta_{\\mathrm{conv}}}\\lambda^{-1} \\log(N+1)$ is sufficient to ensure\n$({\\mathbb{P}}\n({\\vert} X_i{\\vert}_\\infty> R))^{1/2}= \\mathrm{O}(N^{-{\\theta_{\\mathrm{conv}}}})$.\n\\end{itemize}\n\nTo simplify the discussion, we assume ${\\theta_L}={\\theta_c}=1$.\n\n\n\\subsubsection*{Smooth functions} Assume that $y_i(\\cdot), z_i(\\cdot)$ are,\nrespectively, of class $\\mathcal{C}^{l+1}_b({\\mathbb{R}}^d,{\\mathbb{R}})$ and $\\mathcal\n{C}^{l}_b({\\mathbb{R}}\n^d,({\\mathbb{R}}\n^q)^\\top)$ (bounded with bounded derivatives) for some $l \\in{\\mathbb{N}}\n\\setminus\\{0\\}$: this is similar to the discussion of \\cite{gobeturk14}, Section~4.4. In fact, this is usually valid for the\ncontinuous-time limit (a priori estimates on the semi-linear PDE, see\n\\cite{delaguat06,crisdela12}) provided that the data are smooth\nenough. In particular, we may assume {$(\\mathbf{A''_{\\bolds{\\xi}}})$}~with $\\theta_\\Phi=1$. This\nleads to time-uniform bounds on the quantities $C_{y,i}, C_{z,i},\n{\\bar C_{{y,i}} }, \\sqrt{T-t_i}{\\bar C_{{z,i}} }$.\n\nSet\n\n", "index": 61, "text": "\n\\[\n\\delta_{y,i}:=N^{-{{{\\theta_{\\mathrm{conv}}}}/({l+1})}},\\qquad\\delta_{z,i}:=N^{-{{{\\theta_{\\mathrm{conv}}}}/{l }}},\n\\qquad M_i:=\\bigl(\\log(N+1)\\bigr)^{d+1}\nN^{{\\theta_{\\mathrm{conv}}}\n(2+{{ d }/{l }})},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\delta_{y,i}:=N^{-{{{\\theta_{\\mathrm{conv}}}}/({l+1})}},\\qquad\\delta_{z,i}:=N^%&#10;{-{{{\\theta_{\\mathrm{conv}}}}/{l}}},\\qquad M_{i}:=\\bigl{(}\\log(N+1)\\bigr{)}^{d%&#10;+1}N^{{\\theta_{\\mathrm{conv}}}(2+{{d}/{l}})},\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03b4</mi><mrow><mi>y</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>:=</mo><msup><mi>N</mi><mrow><mo>-</mo><mrow><msub><mi>\u03b8</mi><mi>conv</mi></msub><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><msub><mi>\u03b4</mi><mrow><mi>z</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>:=</mo><msup><mi>N</mi><mrow><mo>-</mo><mrow><msub><mi>\u03b8</mi><mi>conv</mi></msub><mo>/</mo><mi>l</mi></mrow></mrow></msup></mrow><mo rspace=\"22.5pt\">,</mo><mrow><msub><mi>M</mi><mi>i</mi></msub><mo>:=</mo><mrow><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><mi>d</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mi>N</mi><mrow><msub><mi>\u03b8</mi><mi>conv</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>+</mo><mrow><mi>d</mi><mo>/</mo><mi>l</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nIt should be compared with the rate $\\mathcal{C}^{-{{1}/({(2+{{d }/{l }})+ {{3 }/{{\\theta_{\\mathrm{conv}}}}}})}}$ which is valid for the Least Squares\nMulti-step forward Dynamical Programming algorithm (LSMDP) \\cite{gobeturk14}.\nThis shows an improvement on the rate, {although there is no change in\nthe dependence on dimension.}\nThe ratio $d/l$ is the usual balance between dimension and smoothness,\narising when approximating a multi-dimensional function.\n{The controls of MWLS are stated in stronger norms than the controls of\nLSMDP, and despite that, the estimates improve. The convergence\nimprovement is due to better MWDP-intrinsic estimates on $Z$, which\navoid the $1/\\Delta_i$-factor of the LSMDP. This results in better\nlocal error bounds, whence better global estimates. The reader can\neasily check that this happens already in the simple case with null driver.}\n\n\n\\subsubsection*{H\\\"older terminal condition} We investigate the case of\nnon-smooth terminal condition, where nevertheless there is a smoothing\neffect of the conditional expectation yielding smooth value functions\n$(y_i(\\cdot),z_i(\\cdot))$. Namely, assume that $\\Phi$ is bounded and\n${\\theta_\\Phi}$-H\\\"older continuous (in particular with {$(\\mathbf{A''_{\\bolds{\\xi}}})$}), and that,\\vspace*{2pt} for\nall~$i$, the function $y_i(\\cdot)$ (resp., $z_i(\\cdot)$) is\n$(l+1)$-times (resp., $l$-times) continuously differentiable with\nhighest derivatives bounded by\n\n\n\\begin{eqnarray}\n\\bigl{\\vert} D^{l+1}_x y_i\\bigr{\\vert}\n_\\infty\\le C(T-t_i)^{({\\theta_\\Phi}-\nl)/2},\\qquad\\bigl{\\vert}\nD^l_x z_i\\bigr{\\vert}_\\infty\\le\nC(T-t_i)^{({\\theta_\\Phi}- (l+1))/2}. \\label\n{eqderivyz}\n\\end{eqnarray}\n\nThese qualitative assumptions are related to the works of \\cite\n{delaguat06,crisdela12}, who have determined similar estimates for\nthe gradients of quasi-linear PDEs under quite general conditions on\nthe driver, terminal condition and differential operator.\nTheir estimates cover the case $l=0$\n(\\cite{delaguat06}, Theorem~2.1) or ${\\theta_\\Phi}=0$ {and $l \\ge1$} (\\cite{crisdela12}, Theorem 1.4), but the H\\\"older continuous setting {with\nhigh order derivatives} is not investigated. We therefore extrapolate\nthese results in the assumptions (\\ref{eqderivyz}) for the purposes\nof this discussion.\n\nIn this setting, we have time-uniform bounds on the quantities $C_{y,i}$,\n$(T-t_i)^{({ 1-{\\theta_\\Phi}})/{2 }}C_{z,i}$, ${\\bar C_{{y,i}} }$, $\\sqrt\n{T-t_i}{\\bar C_{{z,i}} }$.\nSet\n\n\\begin{eqnarray*}\n\\delta_{y,i}&:=&\\sqrt{T-t_i}N^{-{{{\\theta_{\\mathrm{conv}}}}/({l+1})}},\\qquad\\delta\n_{z,i}:=\\sqrt{T-t_i}N^{-{{{\\theta_{\\mathrm{conv}}}}/{l }}},\n\\\\\nM_i&:=&\\bigl(\\log(N+1)\\bigr)^{d+1} N^{{\\theta_{\\mathrm{conv}}}(2+{{ d }/{l }})}(T-t_i)^{-d/2},\n\\end{eqnarray*}\n\ntake $\\mathcal{K}_{Y,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l,\\delta_{y,i},R}}$ and $\\mathcal\n{K}_{Z,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l-1,\\delta_{z,i},R}}$.\nSimilarly to before, using in particular (\\ref{eqpolloc}), we\neventually obtain\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{App.},i} &=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Y_{\\mathrm\n{Dep.},i}=\\mathrm{o}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n{\\bar C_{{y,i}} }\\sqrt{\\frac{ K_{Y,i}}{M_{i} }}&=&\\mathrm{o} \\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}/\\sqrt{\n\\log(N+1)} \\bigr),\n\\\\\n\\mathcal{E}^Z_{\\mathrm{App.},i}&=&(T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr), \\qquad\\mathcal{E}^Z_{\\mathrm\n{Dep.},i}=(T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\\\\n {\\bar C_{{z,i}} }\\sqrt{\\frac{ K_{Z,i}}{M_{i} }}&=&(T-t_i)^{-{{ 1 }/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}/\\sqrt{\\log(N+1)} \\bigr).\n\\end{eqnarray*}\n\nConsequently, using Lemma~\\ref{lemintegrals}, we finally obtain\n\n\\begin{eqnarray*}\n \\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_i - y^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n \\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_i - z^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr) \\biggl((T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}+\n\\frac{(T-t_i)^{-{{ 1 }/{2 }}}}{\\sqrt\n{\\log(N+1)}} \\biggr).\n\\end{eqnarray*}\n\nThe computation cost is given by (under the assumption $\\pi={\\pi^{(\\theta_\\pi)}}$)\n\n", "itemtype": "equation", "pos": 92765, "prevtext": "\n\ntake $\\mathcal{K}_{Y,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l,\\delta_{y,i},R}}$ and $\\mathcal\n{K}_{Z,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l-1,\\delta_{z,i},R}}$.\nFrom Proposition~\\ref{propeqyzerrdecoM}, Theorem~\\ref{thmMCerr}\nand the inequality (\\ref{eqpolloc}), it is easy to check that\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{App.},i} &=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Y_{\\mathrm\n{Dep.},i}=\\mathrm{o}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n{\\bar C_{{y,i}} }\\sqrt{\\frac{ K_{Y,i}}{M_{i} }}&=&\\mathrm{o} \\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}/\\sqrt{\n\\log(N+1)} \\bigr),\n\\\\\n\\mathcal{E}^Z_{\\mathrm{App.},i}&=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Z_{\\mathrm{Dep.},i}=\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\\\\n{\\bar C_{{z,i}} }\\sqrt{\\frac{ K_{Z,i}}{M_{i} }}&=&(T-t_i)^{-{{ 1 }/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}/\\sqrt{\\log(N+1)} \\bigr).\n\\end{eqnarray*}\n\nConsequently, using Lemma~\\ref{lemintegrals}, we finally obtain\n\n\\begin{eqnarray*}\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_i - y^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n\\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_i -\nz^M_i\\bigr{\\Vert}_{i,M} ^2\n\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr) \\biggl(1+\n\\frac{(T-t_i)^{-{{ 1 }/{2 }}}}{\\sqrt{\\log(N+1)}} \\biggr).\n\\end{eqnarray*}\n\nFor\\vspace*{1pt} any time-grid $\\pi={\\pi^{(\\theta_\\pi)}}$, we get $\\sup_{0\\leq i\\leq N}{\\mathbb{E}}\n[{\\Vert} y_i - y^M_i {\\Vert}_{i,M} ^2]+ \\sum_{i=0}^{N-1}\\Delta_i {\\mathbb{E}}\n[{\\Vert} z_i - z^M_i{\\Vert}_{i,M} ^2]= \\mathrm{O}(N^{-2{\\theta_{\\mathrm{conv}}}})$.\nThe computational cost is\n$\\mathcal{C}=\\mathrm{O} (\\log(N+1)^{d+1} N^{{\\theta_{\\mathrm{conv}}}(2+{{ d }/{l }})+2})$.\nIgnoring the logarithmic factors, we obtain a final accuracy in terms\nof the computational cost:\n\n", "index": 63, "text": "\n\\[\n\\mathcal{C}^{-{{ 1 }/({(2+{{d }/{l }})+ {{2 }/{{\\theta_{\\mathrm{conv}}}}} })}}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}^{-{{1}/({(2+{{d}/{l}})+{{2}/{{\\theta_{\\mathrm{conv}}}}}})}}.\" display=\"block\"><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>+</mo><mrow><mi>d</mi><mo>/</mo><mi>l</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mrow><mn>2</mn><mo>/</mo><msub><mi>\u03b8</mi><mi>conv</mi></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nUp to possibly a $\\log(N)$-factor, the last sum is $\\mathrm{O}(N^{{{ d }/({2 {\\theta_\\pi}})}\\lor1})$. Ignoring the logarithmic factors, we obtain\n$\\mathcal{C}=\\mathrm{O}(N^{1+{{ d }/({2 {\\theta_\\pi}})}\\lor1+{\\theta_{\\mathrm{conv}}}(2+{{d }/{l }})})$.\nEquivalently, as a function of the computational cost, the convergence\nrate of the final accuracy equals\n\n", "itemtype": "equation", "pos": 97139, "prevtext": "\n\nIt should be compared with the rate $\\mathcal{C}^{-{{1}/({(2+{{d }/{l }})+ {{3 }/{{\\theta_{\\mathrm{conv}}}}}})}}$ which is valid for the Least Squares\nMulti-step forward Dynamical Programming algorithm (LSMDP) \\cite{gobeturk14}.\nThis shows an improvement on the rate, {although there is no change in\nthe dependence on dimension.}\nThe ratio $d/l$ is the usual balance between dimension and smoothness,\narising when approximating a multi-dimensional function.\n{The controls of MWLS are stated in stronger norms than the controls of\nLSMDP, and despite that, the estimates improve. The convergence\nimprovement is due to better MWDP-intrinsic estimates on $Z$, which\navoid the $1/\\Delta_i$-factor of the LSMDP. This results in better\nlocal error bounds, whence better global estimates. The reader can\neasily check that this happens already in the simple case with null driver.}\n\n\n\\subsubsection*{H\\\"older terminal condition} We investigate the case of\nnon-smooth terminal condition, where nevertheless there is a smoothing\neffect of the conditional expectation yielding smooth value functions\n$(y_i(\\cdot),z_i(\\cdot))$. Namely, assume that $\\Phi$ is bounded and\n${\\theta_\\Phi}$-H\\\"older continuous (in particular with {$(\\mathbf{A''_{\\bolds{\\xi}}})$}), and that,\\vspace*{2pt} for\nall~$i$, the function $y_i(\\cdot)$ (resp., $z_i(\\cdot)$) is\n$(l+1)$-times (resp., $l$-times) continuously differentiable with\nhighest derivatives bounded by\n\n\n\\begin{eqnarray}\n\\bigl{\\vert} D^{l+1}_x y_i\\bigr{\\vert}\n_\\infty\\le C(T-t_i)^{({\\theta_\\Phi}-\nl)/2},\\qquad\\bigl{\\vert}\nD^l_x z_i\\bigr{\\vert}_\\infty\\le\nC(T-t_i)^{({\\theta_\\Phi}- (l+1))/2}. \\label\n{eqderivyz}\n\\end{eqnarray}\n\nThese qualitative assumptions are related to the works of \\cite\n{delaguat06,crisdela12}, who have determined similar estimates for\nthe gradients of quasi-linear PDEs under quite general conditions on\nthe driver, terminal condition and differential operator.\nTheir estimates cover the case $l=0$\n(\\cite{delaguat06}, Theorem~2.1) or ${\\theta_\\Phi}=0$ {and $l \\ge1$} (\\cite{crisdela12}, Theorem 1.4), but the H\\\"older continuous setting {with\nhigh order derivatives} is not investigated. We therefore extrapolate\nthese results in the assumptions (\\ref{eqderivyz}) for the purposes\nof this discussion.\n\nIn this setting, we have time-uniform bounds on the quantities $C_{y,i}$,\n$(T-t_i)^{({ 1-{\\theta_\\Phi}})/{2 }}C_{z,i}$, ${\\bar C_{{y,i}} }$, $\\sqrt\n{T-t_i}{\\bar C_{{z,i}} }$.\nSet\n\n\\begin{eqnarray*}\n\\delta_{y,i}&:=&\\sqrt{T-t_i}N^{-{{{\\theta_{\\mathrm{conv}}}}/({l+1})}},\\qquad\\delta\n_{z,i}:=\\sqrt{T-t_i}N^{-{{{\\theta_{\\mathrm{conv}}}}/{l }}},\n\\\\\nM_i&:=&\\bigl(\\log(N+1)\\bigr)^{d+1} N^{{\\theta_{\\mathrm{conv}}}(2+{{ d }/{l }})}(T-t_i)^{-d/2},\n\\end{eqnarray*}\n\ntake $\\mathcal{K}_{Y,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l,\\delta_{y,i},R}}$ and $\\mathcal\n{K}_{Z,i}:={\\mathcal P}_{\\mathrm{loc.}}^{{l-1,\\delta_{z,i},R}}$.\nSimilarly to before, using in particular (\\ref{eqpolloc}), we\neventually obtain\n\n\\begin{eqnarray*}\n\\mathcal{E}^Y_{\\mathrm{App.},i} &=&\\mathrm{O}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\qquad\\mathcal{E}^Y_{\\mathrm\n{Dep.},i}=\\mathrm{o}\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n{\\bar C_{{y,i}} }\\sqrt{\\frac{ K_{Y,i}}{M_{i} }}&=&\\mathrm{o} \\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}/\\sqrt{\n\\log(N+1)} \\bigr),\n\\\\\n\\mathcal{E}^Z_{\\mathrm{App.},i}&=&(T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr), \\qquad\\mathcal{E}^Z_{\\mathrm\n{Dep.},i}=(T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}\\bigr),\n\\\\\n {\\bar C_{{z,i}} }\\sqrt{\\frac{ K_{Z,i}}{M_{i} }}&=&(T-t_i)^{-{{ 1 }/{2 }}}\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}}/\\sqrt{\\log(N+1)} \\bigr).\n\\end{eqnarray*}\n\nConsequently, using Lemma~\\ref{lemintegrals}, we finally obtain\n\n\\begin{eqnarray*}\n \\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} y_i - y^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr),\n\\\\\n \\bigl({\\mathbb{E}}\\bigl[\\bigl{\\Vert} z_i - z^M_i\n\\bigr{\\Vert}_{i,M} ^2\\bigr] \\bigr)^{1/2}&=&\\mathrm{O}\n\\bigl(N^{-{\\theta_{\\mathrm{conv}}}\n}\\bigr) \\biggl((T-t_i)^{{({{\\theta_\\Phi}- 1 })/{2 }}}+\n\\frac{(T-t_i)^{-{{ 1 }/{2 }}}}{\\sqrt\n{\\log(N+1)}} \\biggr).\n\\end{eqnarray*}\n\nThe computation cost is given by (under the assumption $\\pi={\\pi^{(\\theta_\\pi)}}$)\n\n", "index": 65, "text": "\n\\[\n\\mathcal{C}=\\mathrm{O} \\Biggl(\\sum_{i=0}^{N-1}N\nM_i \\Biggr)=\\mathrm{O} \\bigl(\\bigl(\\log(N+1)\\bigr)^{d+1}\nN^{1+{\\theta_{\\mathrm{conv}}}(2+{{ d }/{l }})} \\bigr) \\sum_{i=0}^{N-1}\n\\biggl(1-\\frac{ i }{ N}\\biggr)^{-{{ d }/({2 {\\theta_\\pi}})}}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}=\\mathrm{O}\\Biggl{(}\\sum_{i=0}^{N-1}NM_{i}\\Biggr{)}=\\mathrm{O}\\bigl%&#10;{(}\\bigl{(}\\log(N+1)\\bigr{)}^{d+1}N^{1+{\\theta_{\\mathrm{conv}}}(2+{{d}/{l}})}%&#10;\\bigr{)}\\sum_{i=0}^{N-1}\\biggl{(}1-\\frac{i}{N}\\biggr{)}^{-{{d}/({2{\\theta_{\\pi%&#10;}}})}}.\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">O</mi><mo>\u2062</mo><mrow><mo maxsize=\"260%\" minsize=\"260%\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>N</mi><mo>\u2062</mo><msub><mi>M</mi><mi>i</mi></msub></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">)</mo></mrow></mrow><mo>=</mo><mrow><mi mathvariant=\"normal\">O</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><mi>d</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mi>N</mi><mrow><mn>1</mn><mo>+</mo><mrow><msub><mi>\u03b8</mi><mi>conv</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>+</mo><mrow><mi>d</mi><mo>/</mo><mi>l</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><msup><mrow><mo maxsize=\"210%\" minsize=\"210%\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mi>i</mi><mi>N</mi></mfrac></mrow><mo maxsize=\"210%\" minsize=\"210%\">)</mo></mrow><mrow><mo>-</mo><mrow><mi>d</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>\u03b8</mi><mi>\u03c0</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nFollowing \\cite{gobemakh10} (under suitable assumptions), two\ntime-grid choices are possible for solving the same BSDE.\n\n\\begin{itemize}\n\n\\item The uniform grid $\\pi={\\pi^{({1})}}$ gives ${\\theta_{\\mathrm{conv}}}={\\theta_\\Phi}/2$ (at\nleast). The convergence order becomes\n{$( 2+\\frac{ d }{l }+\\frac{ 2 }{{\\theta_\\Phi}}(1+ \\frac{d }{2 } \\lor1 ) )^{-1}$.}\n\n\\item The grid $\\pi={\\pi^{({\\theta})}}$ (for $\\theta<{\\theta_\\Phi}$) gives\n${\\theta_{\\mathrm{conv}}}=1/2$. Taking $\\theta\\uparrow{\\theta_\\Phi}$, the convergence\norder is\n{$(2+\\frac{ d }{l }+\\frac{2}{{\\theta_\\Phi}}({\\theta_\\Phi}+ \\frac{d }{2 } \\lor\n{\\theta_\\Phi}\n))^{-1}$.}\n\\end{itemize}\n\nThe grid ${\\pi^{({\\theta})}}$ exhibits a better convergence rate compared to\nthe uniform grid. This corroborates the interest in time grids that are\nwell adapted to the regularity of the data.\nThese features will be investigated in subsequent more experimental works.\n\n\\begin{appendix}\n\\section*{Appendix}\\label{appendix}\n\n\\setcounter{subsection}{0}\n\\setcounter{equation}{0}\n\n\n\\subsection{Proof of Lemmas \\texorpdfstring{\\protect\\ref{lemintegrals}}{2.1}, \\texorpdfstring{\\protect\\ref{lemiterationgen1}}{2.2}\nand \\texorpdfstring{\\protect\\ref{lemiterationgen2}}{2.3}}\\label{appendixprooflemintegrals}\n\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemintegrals}}{2.1}}\nThe first inequality, for $\\alpha\\leq1$, follows by bounding the sum\nby $\\int_{t_i}^{t_k} (t_k-t)^{\\alpha-1} \\,\\mathrm{d}t$, whence ${B_{{\\alpha},{1}}}\n=1/\\alpha$. The case $\\alpha>1$ is obvious with ${B_{{\\alpha},{1}}}=1$.\nFor the second inequality, there are two main cases:\n\n\\begin{longlist}\n\\item[$\\rhd$] If $\\alpha\\geq1$ and $\\beta\\geq1$, the advertised inequality\nis obvious with $B_{ \\alpha,\\beta}=1$.\n\n\\item[$\\rhd$] Now, assume the complementary case, that is, $\\alpha< 1$\nand/or $\\beta< 1$, and first\nconsider the case $t_{i} = 0$ and $t_{k} = 1$.\nWe set $\\varphi(s) = (1-s)^{\\alpha- 1}s^{\\beta-1}$ and we\nuse the integral $\\int_{0}^1\\varphi(s) \\,\\mathrm{d}s$\n(equivalent to the usual beta function with parameters $(\\alpha,\\beta)$)\nto bound the sum. {A simple but useful property {(due to $\\alpha< 1$\nand/or $\\beta< 1$)} is that $\\varphi$ is either monotone or {has a\nunique minimum on $(0,1)$}, whence\n\n\n\\begin{eqnarray*}\n(1 - t_{j})^{\\alpha-1}t_{j}^{\\beta-1}\n\\Delta_{j} \\le R_\\pi\\int_{t_{j-1}}^{t_{j}}\n\\varphi(s) \\,\\mathrm{d}s+\\int_{t_j}^{t_{j+1}}\\varphi(s) \\,\\mathrm{d}s.\n\\end{eqnarray*}\n\nSumming up over $j$ and defining $B_{\\alpha,\\beta} = (1+R_{\\pi})\n\\int_{0}^1 \\varphi(s) \\,\\mathrm{d}s$ concludes the proof for the simple case.}\nFor general $t_{i}$ and $t_{k}$ one can use the bounds on the simple\ncase by rearranging the $j$-sum which is equal to\n\n\\begin{eqnarray*}\n(t_{k} - t_{i})^{\\alpha+ \\beta-1} \\sum\n_{j=i+1}^{k-1}\\biggl( 1 - \\frac{t_{j}-t_{i}}{t_{k} - t_{i}}\n\\biggr)^{\\alpha-1} \\biggl(\\frac{t_{j} - t_{i}}{t_{k} - t_{i}}\\biggr\n)^{\\beta-1}\n\\frac{\\Delta_{j}}{t_k - t_i} \\le B_{\\alpha,\\beta} (t_{k} -\nt_{i})^{\\alpha+ \\beta-1}.\n\\end{eqnarray*}\n\\end{longlist}\n\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemiterationgen1}}{2.2}}\nIf $\\alpha\\geq\\frac{1 }{2 }$, the result trivially holds with ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}=1$\nand ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}=C_{u}{T^{\\alpha-{{ 1}/{2 }}}}$.\n\nNow, assume $\\alpha<\\frac{1 }2 $: if (\\ref\n{eqiterationfeed}) holds, of course we also have\n\n\n\n", "itemtype": "equation", "pos": 97741, "prevtext": "\n\nUp to possibly a $\\log(N)$-factor, the last sum is $\\mathrm{O}(N^{{{ d }/({2 {\\theta_\\pi}})}\\lor1})$. Ignoring the logarithmic factors, we obtain\n$\\mathcal{C}=\\mathrm{O}(N^{1+{{ d }/({2 {\\theta_\\pi}})}\\lor1+{\\theta_{\\mathrm{conv}}}(2+{{d }/{l }})})$.\nEquivalently, as a function of the computational cost, the convergence\nrate of the final accuracy equals\n\n", "index": 67, "text": "\n\\[\n\\mathcal{C}^{-{{ 1 }/{ ((2+{{d }/{l }})+{{1 }/{{\\theta_{\\mathrm{conv}}} }}(1+{{ d}/{(2 {\\theta_\\pi})}}\\lor1)}})}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}^{-{{1}/{((2+{{d}/{l}})+{{1}/{{\\theta_{\\mathrm{conv}}}}}(1+{{d}/{(2%&#10;{\\theta_{\\pi}})}}\\lor 1)}})}.\" display=\"block\"><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo>-</mo><mrow><mn>1</mn><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>+</mo><mrow><mi>d</mi><mo>/</mo><mi>l</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><mrow><mrow><mn>1</mn><mo>/</mo><msub><mi>\u03b8</mi><mi>conv</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mn>1</mn><mo>+</mo><mrow><mi>d</mi><mo>/</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>\u03b8</mi><mi>\u03c0</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>\u2228</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nBy substituting (\\ref{eqiterationgenbis}) into the last sum, and\nusing Lemma~\\ref{lemintegrals} we observe\n\n\\begin{eqnarray*}\n&&\\sum_{l=j+1}^{N-1} \\frac{u_l \\Delta_l }{(T-t_l)^{{{1}/2}- \\beta}(t_l\n- t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\quad \\le\\sum_{l=j+1}^{N-1} \\frac{w_l\\Delta_l}{(T-t_l)^{{{1 }/{2 }}-\n\\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{} +\n\\sum_{l = j+1}^{N-1} \\frac{\\sum_{r = l+1}^{N-1} {w_r\\Delta\n_r}\\Delta_l\n/({(T-t_r)^{1/2-\\beta}(t_r-t_l)^{1/2 -\\alpha}}) }{\n(T-t_l)^{{{1}/2}- \\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{}+ C_{u}\\sum_{l = j+1}^{N-1}\n\\frac{\\sum_{r = l+1}^{N-1}\n{u_r\\Delta_r}\n\\Delta_l/\n({(T-t_r)^{{{1}/2}- \\beta}(t_r - t_l)^{{{1}/2}-\n\\alpha\n}}) }{\n(T-t_l)^{{{1}/2}- \\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\quad \\le\\sum_{l=j+1}^{N-1} \\frac{w_l\\Delta_l}{(T-t_l)^{{{1 }/{2 }}-\n\\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{}+\nB_{\\alpha+\\beta,{{1}/2}+\\alpha} \\sum_{r = j+2}^{N-1}\n\\frac\n{w_r\\Delta\n_r}{(T-t_r)^{1/2-\\beta}(t_r-t_j)^{1/2 -2\\alpha-\\beta}}\n\\\\\n&&\\qquad{}+ C_{u}B_{\\alpha+\\beta,{{1}/2}+\\alpha} \\sum_{r =\nj+2}^{N-1}\n\\frac{u_r\\Delta_r}{(T-t_r)^{1/2-\\beta\n}(t_r-t_j)^{1/2 -2\\alpha-\\beta}}.\n\\end{eqnarray*}\n\nSubstituting into (\\ref{eqiterationgenbis}), we observe that we have\nan equation of similar form to (\\ref{eqiterationgenbis}),\nexcept that, in the sum involving $u$, $\\alpha\\mapsto2\\alpha+ \\beta$\nand $C_u \\mapsto C_u^2 B_{\\alpha+\\beta,{{ 1 }/{2 }}+\\alpha}$,\nand, in the sum involving $w$, $w \\mapsto{(1+C_u (1+ T^{\\alpha+\\beta\n}B_{\\alpha+\\beta,{{ 1 }/{2 }}+\\alpha} ))}w$.\n\n\nAfter $\\kappa$ iterations of the previous step, we obtain $\\alpha\n\\mapsto2^{\\kappa}(\\alpha+\\beta) - \\beta=: \\alpha_\\kappa$.\nHence, for $\\kappa$ sufficiently large so that $\\alpha_\\kappa\\ge\n\\frac{1}{2}$,\nthat is, $\\kappa\\ge\\log_2 (\\frac{{{1}/2} + \\beta}{\\alpha+\n\\beta }) $,\nwe obtain the bound advertised in the lemma statement.\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemiterationgen2}}{2.3}}\n{W.l.o.g. we can assume that ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}=1$ in (\\ref{eqiterationfeed2});\nif it is not, one can redefine $w$ as ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} w$.}\nWe first prove the case $\\gamma=1$.\nDefine\n\n\n\n", "itemtype": "equation", "pos": 101254, "prevtext": "\n\nFollowing \\cite{gobemakh10} (under suitable assumptions), two\ntime-grid choices are possible for solving the same BSDE.\n\n\\begin{itemize}\n\n\\item The uniform grid $\\pi={\\pi^{({1})}}$ gives ${\\theta_{\\mathrm{conv}}}={\\theta_\\Phi}/2$ (at\nleast). The convergence order becomes\n{$( 2+\\frac{ d }{l }+\\frac{ 2 }{{\\theta_\\Phi}}(1+ \\frac{d }{2 } \\lor1 ) )^{-1}$.}\n\n\\item The grid $\\pi={\\pi^{({\\theta})}}$ (for $\\theta<{\\theta_\\Phi}$) gives\n${\\theta_{\\mathrm{conv}}}=1/2$. Taking $\\theta\\uparrow{\\theta_\\Phi}$, the convergence\norder is\n{$(2+\\frac{ d }{l }+\\frac{2}{{\\theta_\\Phi}}({\\theta_\\Phi}+ \\frac{d }{2 } \\lor\n{\\theta_\\Phi}\n))^{-1}$.}\n\\end{itemize}\n\nThe grid ${\\pi^{({\\theta})}}$ exhibits a better convergence rate compared to\nthe uniform grid. This corroborates the interest in time grids that are\nwell adapted to the regularity of the data.\nThese features will be investigated in subsequent more experimental works.\n\n\\begin{appendix}\n\\section*{Appendix}\\label{appendix}\n\n\\setcounter{subsection}{0}\n\\setcounter{equation}{0}\n\n\n\\subsection{Proof of Lemmas \\texorpdfstring{\\protect\\ref{lemintegrals}}{2.1}, \\texorpdfstring{\\protect\\ref{lemiterationgen1}}{2.2}\nand \\texorpdfstring{\\protect\\ref{lemiterationgen2}}{2.3}}\\label{appendixprooflemintegrals}\n\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemintegrals}}{2.1}}\nThe first inequality, for $\\alpha\\leq1$, follows by bounding the sum\nby $\\int_{t_i}^{t_k} (t_k-t)^{\\alpha-1} \\,\\mathrm{d}t$, whence ${B_{{\\alpha},{1}}}\n=1/\\alpha$. The case $\\alpha>1$ is obvious with ${B_{{\\alpha},{1}}}=1$.\nFor the second inequality, there are two main cases:\n\n\\begin{longlist}\n\\item[$\\rhd$] If $\\alpha\\geq1$ and $\\beta\\geq1$, the advertised inequality\nis obvious with $B_{ \\alpha,\\beta}=1$.\n\n\\item[$\\rhd$] Now, assume the complementary case, that is, $\\alpha< 1$\nand/or $\\beta< 1$, and first\nconsider the case $t_{i} = 0$ and $t_{k} = 1$.\nWe set $\\varphi(s) = (1-s)^{\\alpha- 1}s^{\\beta-1}$ and we\nuse the integral $\\int_{0}^1\\varphi(s) \\,\\mathrm{d}s$\n(equivalent to the usual beta function with parameters $(\\alpha,\\beta)$)\nto bound the sum. {A simple but useful property {(due to $\\alpha< 1$\nand/or $\\beta< 1$)} is that $\\varphi$ is either monotone or {has a\nunique minimum on $(0,1)$}, whence\n\n\n\\begin{eqnarray*}\n(1 - t_{j})^{\\alpha-1}t_{j}^{\\beta-1}\n\\Delta_{j} \\le R_\\pi\\int_{t_{j-1}}^{t_{j}}\n\\varphi(s) \\,\\mathrm{d}s+\\int_{t_j}^{t_{j+1}}\\varphi(s) \\,\\mathrm{d}s.\n\\end{eqnarray*}\n\nSumming up over $j$ and defining $B_{\\alpha,\\beta} = (1+R_{\\pi})\n\\int_{0}^1 \\varphi(s) \\,\\mathrm{d}s$ concludes the proof for the simple case.}\nFor general $t_{i}$ and $t_{k}$ one can use the bounds on the simple\ncase by rearranging the $j$-sum which is equal to\n\n\\begin{eqnarray*}\n(t_{k} - t_{i})^{\\alpha+ \\beta-1} \\sum\n_{j=i+1}^{k-1}\\biggl( 1 - \\frac{t_{j}-t_{i}}{t_{k} - t_{i}}\n\\biggr)^{\\alpha-1} \\biggl(\\frac{t_{j} - t_{i}}{t_{k} - t_{i}}\\biggr\n)^{\\beta-1}\n\\frac{\\Delta_{j}}{t_k - t_i} \\le B_{\\alpha,\\beta} (t_{k} -\nt_{i})^{\\alpha+ \\beta-1}.\n\\end{eqnarray*}\n\\end{longlist}\n\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemiterationgen1}}{2.2}}\nIf $\\alpha\\geq\\frac{1 }{2 }$, the result trivially holds with ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}=1$\nand ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}=C_{u}{T^{\\alpha-{{ 1}/{2 }}}}$.\n\nNow, assume $\\alpha<\\frac{1 }2 $: if (\\ref\n{eqiterationfeed}) holds, of course we also have\n\n\n\n", "index": 69, "text": "\\begin{equation}\\label{eqiterationgenbis}\n\\hspace*{-10pt}u_j \\le w_j + \\sum_{l=j+1}^{N-1}\n\\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}\n+C_{u}\\sum_{l=j+1}^{N-1}\n\\frac{u_l \\Delta_l}{(T-t_l)^{{{1}/2 -\n\\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\hskip-10.0ptu_{j}\\leq w_{j}+\\sum_{l=j+1}^{N-1}\\frac{w_{l}\\Delta_{l}}{(T-t_{l}%&#10;)^{{{1}/2-\\beta}}(t_{l}-t_{j})^{{{1}/2-\\alpha}}}+C_{u}\\sum_{l=j+1}^{N-1}\\frac{%&#10;u_{l}\\Delta_{l}}{(T-t_{l})^{{{1}/2-\\beta}}(t_{l}-t_{j})^{{{1}/2-\\alpha}}}.\" display=\"block\"><mrow><mrow><msub><mpadded lspace=\"-10pt\" width=\"-10pt\"><mi>u</mi></mpadded><mi>j</mi></msub><mo>\u2264</mo><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>=</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mfrac><mrow><msub><mi>w</mi><mi>l</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>l</mi></msub></mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>l</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b2</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>l</mi></msub><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b1</mi></mrow></msup></mrow></mfrac></mrow><mo>+</mo><mrow><msub><mi>C</mi><mi>u</mi></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>l</mi><mo>=</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mfrac><mrow><msub><mi>u</mi><mi>l</mi></msub><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>l</mi></msub></mrow><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>l</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b2</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>l</mi></msub><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b1</mi></mrow></msup></mrow></mfrac></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nand write $\\zeta_{j } = \\zeta_{t_{j}}$ for brevity.\n{We first multiply (\\ref{eqiterationfeed2}) by ${\\mathrm{e}^\\zeta_j \\Delta_j\n\\over(T-t_j)^{1/2 - \\beta} }$, then sum the outcome equation over\n$j \\in\\{i+1, \\ldots, N-1\\}$, and finally switch the order of\nsummation on the right-hand side as follows:}\n\n\\begin{eqnarray*}\n&& \\sum_{j=i+1}^{N-1} \\frac{u_j \\mathrm{e}^{\\zeta_{j}}\\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\quad  \\le\n\\sum_{j=i+1}^{N-1} \\frac{w_j \\mathrm{e}^{\\zeta_{j}}\\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\qquad{} +\\sum\n_{j=i+1}^{N-1} \\frac{\\sum_{l=j+1}^{N-1} {w_l \\Delta\n_l}\\mathrm{e}^{\\zeta_{j}}\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}})\n}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\qquad{} +{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum_{j=i+1}^{N-1} \\frac{\\sum_{l=j+1}^{N-1}\n{u_l \\Delta\n_l}\n\\mathrm{e}^{\\zeta_{j}}\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}})\n}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\quad  \\le \\mathrm{e}^{\\zeta_T}\\sum_{j=i+1}^{N-1}\n\\frac{w_j \\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }+\\mathrm{e}^{\\zeta_T}{B_{{\\alpha+\\beta},{1}}}\\sum\n_{l=i+2}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l -\nt_i)^{-\\alpha\n-\\beta}}\n\\\\\n&&\\qquad{}+{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum_{l=i+2}^{N-1} \\frac{u_l\\Delta_l}{(T-t_l)^{{{1}/2} -\n\\beta\n}}\n\\sum_{j=i+1}^{l-1} \\frac{ \\mathrm{e}^{\\zeta_{j}}\\Delta_{j}}{(T-t_{j})^{1/2\n- \\beta} }\n\\\\\n&&\\quad  \\le \\mathrm{e}^{\\zeta_T}\\bigl(1+{B_{{\\alpha+\\beta},{1}}}T^{\\alpha+\\beta}\\bigr)\n\\sum_{l=i+1}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}} +\n\\frac{1}2 \\sum_{l=i+1}^{N-1}\n\\frac{u_l \\mathrm{e}^{\\zeta_{l}}\\Delta\n_{l}}{(T-t_{l})^{1/2 - \\beta} },\n\\end{eqnarray*}\n\nwhere we have used (because $\\zeta$ is {non-decreasing} and $\\beta\n\\leq\n\\frac{1}2$)\n\n", "itemtype": "equation", "pos": 103725, "prevtext": "\n\nBy substituting (\\ref{eqiterationgenbis}) into the last sum, and\nusing Lemma~\\ref{lemintegrals} we observe\n\n\\begin{eqnarray*}\n&&\\sum_{l=j+1}^{N-1} \\frac{u_l \\Delta_l }{(T-t_l)^{{{1}/2}- \\beta}(t_l\n- t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\quad \\le\\sum_{l=j+1}^{N-1} \\frac{w_l\\Delta_l}{(T-t_l)^{{{1 }/{2 }}-\n\\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{} +\n\\sum_{l = j+1}^{N-1} \\frac{\\sum_{r = l+1}^{N-1} {w_r\\Delta\n_r}\\Delta_l\n/({(T-t_r)^{1/2-\\beta}(t_r-t_l)^{1/2 -\\alpha}}) }{\n(T-t_l)^{{{1}/2}- \\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{}+ C_{u}\\sum_{l = j+1}^{N-1}\n\\frac{\\sum_{r = l+1}^{N-1}\n{u_r\\Delta_r}\n\\Delta_l/\n({(T-t_r)^{{{1}/2}- \\beta}(t_r - t_l)^{{{1}/2}-\n\\alpha\n}}) }{\n(T-t_l)^{{{1}/2}- \\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\quad \\le\\sum_{l=j+1}^{N-1} \\frac{w_l\\Delta_l}{(T-t_l)^{{{1 }/{2 }}-\n\\beta}(t_l - t_j)^{{{1}/2}- \\alpha}}\n\\\\\n&&\\qquad{}+\nB_{\\alpha+\\beta,{{1}/2}+\\alpha} \\sum_{r = j+2}^{N-1}\n\\frac\n{w_r\\Delta\n_r}{(T-t_r)^{1/2-\\beta}(t_r-t_j)^{1/2 -2\\alpha-\\beta}}\n\\\\\n&&\\qquad{}+ C_{u}B_{\\alpha+\\beta,{{1}/2}+\\alpha} \\sum_{r =\nj+2}^{N-1}\n\\frac{u_r\\Delta_r}{(T-t_r)^{1/2-\\beta\n}(t_r-t_j)^{1/2 -2\\alpha-\\beta}}.\n\\end{eqnarray*}\n\nSubstituting into (\\ref{eqiterationgenbis}), we observe that we have\nan equation of similar form to (\\ref{eqiterationgenbis}),\nexcept that, in the sum involving $u$, $\\alpha\\mapsto2\\alpha+ \\beta$\nand $C_u \\mapsto C_u^2 B_{\\alpha+\\beta,{{ 1 }/{2 }}+\\alpha}$,\nand, in the sum involving $w$, $w \\mapsto{(1+C_u (1+ T^{\\alpha+\\beta\n}B_{\\alpha+\\beta,{{ 1 }/{2 }}+\\alpha} ))}w$.\n\n\nAfter $\\kappa$ iterations of the previous step, we obtain $\\alpha\n\\mapsto2^{\\kappa}(\\alpha+\\beta) - \\beta=: \\alpha_\\kappa$.\nHence, for $\\kappa$ sufficiently large so that $\\alpha_\\kappa\\ge\n\\frac{1}{2}$,\nthat is, $\\kappa\\ge\\log_2 (\\frac{{{1}/2} + \\beta}{\\alpha+\n\\beta }) $,\nwe obtain the bound advertised in the lemma statement.\n\n\n\n\\subsubsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemiterationgen2}}{2.3}}\n{W.l.o.g. we can assume that ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}=1$ in (\\ref{eqiterationfeed2});\nif it is not, one can redefine $w$ as ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} w$.}\nWe first prove the case $\\gamma=1$.\nDefine\n\n\n\n", "index": 71, "text": "\\begin{equation}\n\\zeta_{s}:= 2{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\int_{0}^{s}\n\\frac{\\mathrm{d}r}{(T - r)^{1/2 -\\beta}} \\le\\frac{ 2 }{1+2\\beta} 2{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\n{T^{(1+2\\beta)/2}},\n\\label{eqbeta}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\zeta_{s}:=2{\\mathcal{C}}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\int_{0}^{s}%&#10;\\frac{\\mathrm{d}r}{(T-r)^{1/2-\\beta}}\\leq\\frac{2}{1+2\\beta}2{\\mathcal{C}}_{(%&#10;\\ref{eqiterationfeed2}\\mathrm{b})}{T^{(1+2\\beta)/2}},\" display=\"block\"><mrow><mrow><msub><mi>\u03b6</mi><mi>s</mi></msub><mo>:=</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\" style=\"font-size:70%;\">LABEL:eqiterationfeed2</span></mtext><mo>\u2062</mo><mi mathvariant=\"normal\">b</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msub><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>s</mi></msubsup><mfrac><mrow><mi mathvariant=\"normal\">d</mi><mo>\u2062</mo><mi>r</mi></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><mi>r</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b2</mi></mrow></msup></mfrac></mrow></mrow><mo>\u2264</mo><mrow><mfrac><mn>2</mn><mrow><mn>1</mn><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></mrow></mfrac><mo>\u2062</mo><mn>2</mn><mo>\u2062</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\" style=\"font-size:70%;\">LABEL:eqiterationfeed2</span></mtext><mo>\u2062</mo><mi mathvariant=\"normal\">b</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msub><mo>\u2062</mo><msup><mi>T</mi><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03b2</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mn>2</mn></mrow></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\n{By subtracting} the term with factor $\\frac{1}2$, the result for\n$\\gamma\n=1$ follows.\nMoreover, plugging the result into (\\ref{eqiterationfeed2}), and\nreturning to general ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}$, gives\n\n\n\\begin{eqnarray}\\label{equpperboundu}\nu_j &\\le&{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} w_j + {\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 -\n\\beta\n}}}\n\\end{eqnarray}\n\nfor a constant ${\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}:= 2 {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} \\mathrm{e}^{\\zeta_T} (1 + {B_{{\\alpha+ \\beta},1}}\nT^{\\alpha+\\beta})$. Now for the general case $\\gamma>0$, observe that,\nfor any $\\delta\\geq0$,\none obtains by change of the order of summation that\n\n\n\\begin{eqnarray}\\label{eqineqappendix}\n&& \\sum_{j=i+1}^{N-1}\n\\frac{\\sum_{l=j+1}^{N-1}\n{w_l \\Delta_l}\n\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\delta}}}) }{(T-t_{j})^{1/2 - \\beta\n}(t_j-t_i)^{1-\\gamma} }\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\qquad \\leq B_{\\beta+\\delta,\\gamma} \\sum_{l=i+2}^{N-1}\n\\frac{w_l\\Delta\n_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1-\\beta-\\delta-\\gamma} }.\n\\end{eqnarray}\n\nThus, (\\ref{equpperboundu}) yields\n\n\\begin{eqnarray*}\n&& \\sum_{j=i+1}^{N-1} \\frac{u_j \\Delta_{j}}{(T-t_{j})^{1/2 - \\beta\n}(t_j -t_i)^{1-\\gamma} }\n\\\\\n&&\\quad \\leq\n{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum_{j=i+1}^{N-1} \\frac{w_j \\Delta_j}{(T-t_j)^{{{1}/2 -\n\\beta}}(t_j - t_i)^{{1-\\gamma}}}\n\\\\\n&&\\qquad{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} B_{\\beta+\\alpha,\\gamma}\\sum_{l=i+2}^{N-1}\n\\frac\n{w_l\\Delta_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1-\\beta-\\alpha\n-\\gamma} }\n\\\\\n&&\\qquad{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} B_{\\beta+{{1}/2},\\gamma}\\sum_{l=i+2}^{N-1}\n\\frac\n{w_l\\Delta_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1/2-\\beta\n-\\gamma} }\n\\\\\n&&\\quad \\leq{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\bigl(1+B_{\\beta+\\alpha,\\gamma}T^{\\alpha+\\beta}+\nB_{\\beta+{{1}/2},\\gamma}T^{1/2+\\beta}\\bigr)\\sum_{j=i+1}^{N-1}\n\\frac\n{w_j \\Delta_j}{(T-t_j)^{{{1}/2 - \\beta}}(t_j - t_i)^{{1-\\gamma}}}.\n\\end{eqnarray*}\n\n\n\n\n\\subsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemobsbounds}}{3.7}}\\label{appendixprooflemmalemobsbounds}\nUsing the bounds ${C_{y,i}}$ and ${C_{z,i}}$ on ${y^{(M)}_{i}(\\cdot)}$ and ${z^{(M)}_{i}(\\cdot)}$,\nrespectively, one applies the local Lipschitz continuity and\nboundedness properties of $f_j$ given in {$(\\mathbf{A_F})$}~to obtain the bound\n\n\n\n", "itemtype": "equation", "pos": 105734, "prevtext": "\n\nand write $\\zeta_{j } = \\zeta_{t_{j}}$ for brevity.\n{We first multiply (\\ref{eqiterationfeed2}) by ${\\mathrm{e}^\\zeta_j \\Delta_j\n\\over(T-t_j)^{1/2 - \\beta} }$, then sum the outcome equation over\n$j \\in\\{i+1, \\ldots, N-1\\}$, and finally switch the order of\nsummation on the right-hand side as follows:}\n\n\\begin{eqnarray*}\n&& \\sum_{j=i+1}^{N-1} \\frac{u_j \\mathrm{e}^{\\zeta_{j}}\\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\quad  \\le\n\\sum_{j=i+1}^{N-1} \\frac{w_j \\mathrm{e}^{\\zeta_{j}}\\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\qquad{} +\\sum\n_{j=i+1}^{N-1} \\frac{\\sum_{l=j+1}^{N-1} {w_l \\Delta\n_l}\\mathrm{e}^{\\zeta_{j}}\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}})\n}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\qquad{} +{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum_{j=i+1}^{N-1} \\frac{\\sum_{l=j+1}^{N-1}\n{u_l \\Delta\n_l}\n\\mathrm{e}^{\\zeta_{j}}\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}})\n}{(T-t_{j})^{1/2 - \\beta} }\n\\\\\n&&\\quad  \\le \\mathrm{e}^{\\zeta_T}\\sum_{j=i+1}^{N-1}\n\\frac{w_j \\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }+\\mathrm{e}^{\\zeta_T}{B_{{\\alpha+\\beta},{1}}}\\sum\n_{l=i+2}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l -\nt_i)^{-\\alpha\n-\\beta}}\n\\\\\n&&\\qquad{}+{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}\\sum_{l=i+2}^{N-1} \\frac{u_l\\Delta_l}{(T-t_l)^{{{1}/2} -\n\\beta\n}}\n\\sum_{j=i+1}^{l-1} \\frac{ \\mathrm{e}^{\\zeta_{j}}\\Delta_{j}}{(T-t_{j})^{1/2\n- \\beta} }\n\\\\\n&&\\quad  \\le \\mathrm{e}^{\\zeta_T}\\bigl(1+{B_{{\\alpha+\\beta},{1}}}T^{\\alpha+\\beta}\\bigr)\n\\sum_{l=i+1}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 - \\beta}}} +\n\\frac{1}2 \\sum_{l=i+1}^{N-1}\n\\frac{u_l \\mathrm{e}^{\\zeta_{l}}\\Delta\n_{l}}{(T-t_{l})^{1/2 - \\beta} },\n\\end{eqnarray*}\n\nwhere we have used (because $\\zeta$ is {non-decreasing} and $\\beta\n\\leq\n\\frac{1}2$)\n\n", "index": 73, "text": "\n\\[\n{{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}}\\sum_{j=i+1}^{l-1}\\frac{ \\mathrm{e}^{\\zeta_{j}}\\Delta\n_{j}}{(T-t_{j})^{1/2 - \\beta} }\n\\le\\int_{{{t_{i+1}}}}^{t_l}\\frac{{{\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{b})}}\\mathrm{e}^{\\zeta_s }}{(T-s)^{1/2 -\n\\beta\n}}\\,\\mathrm{d}s\\leq{\n\\frac{\\mathrm{e}^{\\zeta_l}}{2}}. \n\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"{{\\mathcal{C}}_{(\\ref{eqiterationfeed2}\\mathrm{b})}}\\sum_{j=i+1}^{l-1}\\frac{%&#10;\\mathrm{e}^{\\zeta_{j}}\\Delta{}_{j}}{(T-t_{j})^{1/2-\\beta}}\\leq\\int_{{{t_{i+1}}%&#10;}}^{t_{l}}\\frac{{{\\mathcal{C}}_{(\\ref{eqiterationfeed2}\\mathrm{b})}}\\mathrm{e}%&#10;^{\\zeta_{s}}}{(T-s)^{1/2-\\beta}}\\,\\mathrm{d}s\\leq{\\frac{\\mathrm{e}^{\\zeta_{l}}%&#10;}{2}}.\\par&#10;\" display=\"block\"><mrow><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\" style=\"font-size:70%;\">LABEL:eqiterationfeed2</span></mtext><mo>\u2062</mo><mi mathvariant=\"normal\">b</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow></munderover><mfrac><mrow><msup><mi mathvariant=\"normal\">e</mi><msub><mi>\u03b6</mi><mi>j</mi></msub></msup><mi mathvariant=\"normal\">\u0394</mi><msub><mi/><mi>j</mi></msub></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b2</mi></mrow></msup></mfrac></mrow></mrow><mo>\u2264</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>t</mi><mi>l</mi></msub></msubsup><mrow><mpadded width=\"+1.7pt\"><mfrac><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mtext class=\"ltx_missing_label\" mathvariant=\"italic\"><span xmlns=\"http://www.w3.org/1999/xhtml\" class=\"ltx_ref ltx_missing_label ltx_font_italic ltx_ref_self\" style=\"font-size:70%;\">LABEL:eqiterationfeed2</span></mtext><mo>\u2062</mo><mi mathvariant=\"normal\">b</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msub><mo>\u2062</mo><msup><mi mathvariant=\"normal\">e</mi><msub><mi>\u03b6</mi><mi>s</mi></msub></msup></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><mi>s</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mi>\u03b2</mi></mrow></msup></mfrac></mpadded><mo>\u2062</mo><mrow><mo>d</mo><mi>s</mi></mrow></mrow></mrow><mo>\u2264</mo><mfrac><msup><mi mathvariant=\"normal\">e</mi><msub><mi>\u03b6</mi><mi>l</mi></msub></msup><mn>2</mn></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.01186.tex", "nexttext": "\n\nSubstituting this into the definition ${S^{(M)}_{{Y,i}}({{\\mathbf{\\underline{{x}} } }^{(i)}})} $\n{(see (\\ref{eqPsiMy}))}, it follows from {$(\\mathbf{A_F})$}~that\n\n\\begin{eqnarray*}\n\\bigl{\\vert}{S^{(M)}_{{Y,i}}\\bigl({{\\mathbf{\\underline{x} } }^{(i)}}\\bigr)}\\bigr{\\vert}\\le\nC_\\xi+ \\sum_{j = i}^{N-1} \\biggl(\n\\frac{L_f ({C_{y,j+1}}+ {C_{z,j}}) }{(T-t_j)^{1/2 - {\\thetaL/2}} } + \\frac\n{C_f}{(T-t_j)^{1-{\\theta_c}}} \\biggr)\\Delta_j.\n\\end{eqnarray*}\n\nSubstituting the value of ${C_{y,j}}$ and ${C_{z,j}}$ given in equations (\\ref{eqasy}) and (\\ref{eqasz}), respectively, using the crude bound\n${\\vert}\\xi-{\\mathbb{E}}_i\\xi{\\vert}_{2,i}\\leq C_\\xi$ and Lemma\n\\ref{lemintegrals}, we\nobtain the bound ${\\bar C_{{y,i}} }$, with the form~(\\ref{eqboundObsBd}).\\vspace*{1pt}\n\nTo obtain the bound ${\\bar C_{{z,i}} }$, apply first the triangle inequality\non the conditional standard deviation of ${S^{(M)}_{{l,Z,i}}({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}}})}$; second use the bound (\\ref{eqMCbdf}) on the driver,\nand the bound {$(\\mathbf{A_H})$}~to obtain\n\n\\begin{eqnarray*}\n&& \\sqrt{{\\mathbb{V}\\mathrm{ar}}\\bigl[{S^{(M)}_{{l,Z,i}}\\bigl({{H^{({i,m})}_{{}}}, {X^{({i,m})}_{{}}}}\\bigr)} \\mid{\\mathcal{F}^{({M})}_{i}} \\bigr]}\n\\\\\n&&\\quad \\leq\\frac{{C_\\xi} C_{M}}{\\sqrt{T - t_i}} + \\sum_{j = i+1}^{N-1}\n\\biggl(\\frac{L_f ({C_{y,j+1}}+ {C_{z,j}})\n}{(T-t_j)^{1/2 {- {\\thetaL/2}}} } + \\frac\n{C_f}{(T-t_j)^{1-{\\theta_c}\n}} \\biggr) \\frac{ C_{M}}{\\sqrt{t_j - t_i}}\n\\Delta_j.\n\\end{eqnarray*}\n\nThen, the computation of ${\\bar C_{{z,i}} }$ follows again from equations\n(\\ref{eqasy}) and (\\ref{eqasz}), and Lemma~\\ref{lemintegrals}.\nThe form (\\ref{eqboundObsBd}) is also derived. We skip details.\n\n\\end{appendix}\n\n\n\\section*{Acknowledgements}\nThis research benefited from the support of the Chair Finance and\nSustainable Development,\nunder the aegis of Louis Bachelier Finance and Sustainable Growth\nlaboratory, a joint initiative with Ecole polytechnique.\nEmmanuel Gobet's\nresearch is part of the Chair Financial Risks of the Risk Foundation\nand of the FiME Laboratory.\nPlamen Turkedjiev\nacknowledges support form German Science Fondation DFG via Berlin\nMathematical School and Matheon.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{thebibliography}{22}\n\n\n\n\\bibitem{ballcarazane05}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Bally},~\\bfnm{Vlad}\\binits{V.}},\n\\bauthor{\\bsnm{Caramellino},~\\bfnm{Lucia}\\binits{L.}} \\AND\n\\bauthor{\\bsnm{Zanette},~\\bfnm{Antonino}\\binits{A.}}\n(\\byear{2005}).\n\\btitle{Pricing and hedging {A}merican options by {M}onte {C}arlo\nmethods using a {M}alliavin calculus approach}.\n\\bjournal{Monte Carlo Methods Appl.}\n\\bvolume{11}\n\\bpages{97--133}.\n\\bid{doi={10.1163/156939605777585944}, issn={0929-9629}, mr={2152631}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{bendstei12}\n\n\\begin{bincollection}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Bender},~\\bfnm{C.}\\binits{C.}} \\AND\n\\bauthor{\\bsnm{Steiner},~\\bfnm{J.}\\binits{J.}}\n(\\byear{2012}).\n\\btitle{Least-squares {Monte-Carlo} for {BSDE}s}.\nIn \\bbooktitle{Numerical Methods in Finance}\n(\\beditor{\\bfnm{R.}\\binits{R.}~\\bsnm{Carmona}},\n\\beditor{\\bfnm{P.}\\binits{P.}~\\bsnm{Del Moral}},\n\\beditor{\\bfnm{P.}\\binits{P.}~\\bsnm{Hu}} \\AND\n\\beditor{\\bfnm{N.}\\binits{N.}~\\bsnm{Oudjane}}, eds.).\n\\bseries{Springer Proceedings in Mathematics}\n\\bvolume{12}\n\\bpages{257--289}.\n\\blocation{Berlin--Heidelberg}:\n\\bpublisher{Springer}.\n\\end{bincollection}\n\n\n\\bptok{imsref}\n\\endbibitem\n\n\n\\bibitem{bouctouz04}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Bouchard},~\\bfnm{Bruno}\\binits{B.}} \\AND\n\\bauthor{\\bsnm{Touzi},~\\bfnm{Nizar}\\binits{N.}}\n(\\byear{2004}).\n\\btitle{Discrete-time approximation and {M}onte-{C}arlo simulation of\nbackward stochastic differential equations}.\n\\bjournal{Stochastic Process. Appl.}\n\\bvolume{111}\n\\bpages{175--206}.\n\\bid{doi={10.1016/j.spa.2004.01.001}, issn={0304-4149}, mr={2056536}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{brialaba13}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Briand},~\\bfnm{Philippe}\\binits{P.}} \\AND\n\\bauthor{\\bsnm{Labart},~\\bfnm{C{\\'e}line}\\binits{C.}}\n(\\byear{2014}).\n\\btitle{Simulation of {BSDE}s by {W}iener chaos expansion}.\n\\bjournal{Ann. Appl. Probab.}\n\\bvolume{24}\n\\bpages{1129--1171}.\n\\bid{doi={10.1214/13-AAP943}, issn={1050-5164}, mr={3199982}}\n\\bptnote{check year}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{chasrich13}\n\n\\begin{bmisc}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Chassagneux},~\\bfnm{J.-F.}\\binits{J.-F.}} \\AND\n\\bauthor{\\bsnm{Richou},~\\bfnm{A.}\\binits{A.}}\n(\\byear{2013}).\n\\bhowpublished{Numerical simulation of quadratic {BSDE}s.\nPreprint. Available at \\arxivurl{arXiv:1307.5741}.}\n\\end{bmisc}\n\n\n\\bptok{imsref}\n\n\n\\endbibitem\n\n\n\\bibitem{crisdela12}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Crisan},~\\bfnm{Dan}\\binits{D.}} \\AND\n\\bauthor{\\bsnm{Delarue},~\\bfnm{Fran{\\c{c}}ois}\\binits{F.}}\n(\\byear{2012}).\n\\btitle{Sharp derivative bounds for solutions of degenerate semi-linear\npartial differential equations}.\n\\bjournal{J. Funct. Anal.}\n\\bvolume{263}\n\\bpages{3024--3101}.\n\\bid{doi={10.1016/j.jfa.2012.07.015}, issn={0022-1236}, mr={2973334}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{delaguat06}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Delarue},~\\bfnm{F.}\\binits{F.}} \\AND\n\\bauthor{\\bsnm{Guatteri},~\\bfnm{G.}\\binits{G.}}\n(\\byear{2006}).\n\\btitle{Weak existence and uniqueness for forward--backward {SDE}s}.\n\\bjournal{Stochastic Process. Appl.}\n\\bvolume{116}\n\\bpages{1712--1742}.\n\\bid{doi={10.1016/j.spa.2006.05.002}, issn={0304-4149}, mr={2307056}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{fourlion99}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Fourni{\\'e}},~\\bfnm{Eric}\\binits{E.}},\n\\bauthor{\\bsnm{Lasry},~\\bfnm{Jean-Michel}\\binits{J.-M.}},\n\\bauthor{\\bsnm{Lebuchoux},~\\bfnm{J{\\'e}r{\\^o}me}\\binits{J.}},\n\\bauthor{\\bsnm{Lions},~\\bfnm{Pierre-Louis}\\binits{P.-L.}} \\AND\n\\bauthor{\\bsnm{Touzi},~\\bfnm{Nizar}\\binits{N.}}\n(\\byear{1999}).\n\\btitle{Applications of {M}alliavin calculus to {M}onte {C}arlo methods\nin finance}.\n\\bjournal{Finance Stoch.}\n\\bvolume{3}\n\\bpages{391--412}.\n\\bid{doi={10.1007/s007800050068}, issn={0949-2984}, mr={1842285}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{geisgeisgobe12}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Geiss},~\\bfnm{Christel}\\binits{C.}},\n\\bauthor{\\bsnm{Geiss},~\\bfnm{Stefan}\\binits{S.}} \\AND\n\\bauthor{\\bsnm{Gobet},~\\bfnm{Emmanuel}\\binits{E.}}\n(\\byear{2012}).\n\\btitle{Generalized fractional smoothness and {$L\\sb p$}-variation of\n{BSDE}s with non-{L}ipschitz terminal condition}.\n\\bjournal{Stochastic Process. Appl.}\n\\bvolume{122}\n\\bpages{2078--2116}.\n\\bid{doi={10.1016/j.spa.2012.02.006}, issn={0304-4149}, mr={2921973}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{gobelaba07}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Gobet},~\\bfnm{Emmanuel}\\binits{E.}} \\AND\n\\bauthor{\\bsnm{Labart},~\\bfnm{C{\\'e}line}\\binits{C.}}\n(\\byear{2007}).\n\\btitle{Error expansion for the discretization of backward stochastic\ndifferential equations}.\n\\bjournal{Stochastic Process. Appl.}\n\\bvolume{117}\n\\bpages{803--829}.\n\\bid{doi={10.1016/j.spa.2006.10.007}, issn={0304-4149}, mr={2330720}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{gobemakh10}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Gobet},~\\bfnm{Emmanuel}\\binits{E.}} \\AND\n\\bauthor{\\bsnm{Makhlouf},~\\bfnm{Azmi}\\binits{A.}}\n(\\byear{2010}).\n\\btitle{{$\\mathbf{L}\\sb2$}-time regularity of {BSDE}s with irregular\nterminal functions}.\n\\bjournal{Stochastic Process. Appl.}\n\\bvolume{120}\n\\bpages{1105--1132}.\n\\bid{doi={10.1016/j.spa.2010.03.003}, issn={0304-4149}, mr={2639740}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{gobemuno05}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Gobet},~\\bfnm{Emmanuel}\\binits{E.}} \\AND\n\\bauthor{\\bsnm{Munos},~\\bfnm{R{\\'e}mi}\\binits{R.}}\n(\\byear{2005}).\n\\btitle{Sensitivity analysis using {I}t\\^o--{M}alliavin calculus and\nmartingales, and application to stochastic optimal control}.\n\\bjournal{SIAM J. Control Optim.}\n\\bvolume{43}\n\\bpages{1676--1713 (electronic)}.\n\\bid{doi={10.1137/S0363012902419059}, issn={0363-0129}, mr={2137498}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{gobeturk14}\n\n\\begin{barticle}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Gobet},~\\bfnm{E.}\\binits{E.}} \\AND\n\\bauthor{\\bsnm{Turkedjiev},~\\bfnm{P.}\\binits{P.}}\n(\\byear{2014}).\n\\btitle{Linear regression MDP scheme for discrete backward stochastic\ndifferential equations under general conditions}.\n\\bjournal{Math. Comp.}\n\\bnote{To appear. Available at \\url{http://hal.archives-ouvertes.fr/hal-00855760}}.\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\\endbibitem\n\n\n\\bibitem{goluvanl96}\n\n\\begin{bbook}[mr]\n\\bauthor{\\bsnm{Golub},~\\bfnm{Gene~H.}\\binits{G.H.}} \\AND\n\\bauthor{\\bsnm{Van Loan},~\\bfnm{Charles~F.}\\binits{C.F.}}\n(\\byear{1996}).\n\\btitle{Matrix Computations},\n\\bedition{3rd} ed.\n\\bseries{Johns Hopkins Studies in the Mathematical Sciences}.\n\\blocation{Baltimore, MD}:\n\\bpublisher{Johns Hopkins Univ. Press}.\n\\bid{mr={1417720}}\n\\end{bbook}\n\n\n\\bptok{imsref}\n\n\n\n\\endbibitem\n\n\n\\bibitem{gyorkohlkrzywalk02}\n\n\\begin{bbook}[mr]\n\\bauthor{\\bsnm{Gy{\\\"o}rfi},~\\bfnm{L{\\'a}szl{\\'o}}\\binits{L.}},\n\\bauthor{\\bsnm{Kohler},~\\bfnm{Michael}\\binits{M.}},\n\\bauthor{\\bsnm{Krzy{\\.z}ak},~\\bfnm{Adam}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Walk},~\\bfnm{Harro}\\binits{H.}}\n(\\byear{2002}).\n\\btitle{A Distribution-Free Theory of Nonparametric Regression}.\n\\bseries{Springer Series in Statistics}.\n\\blocation{New York}:\n\\bpublisher{Springer}.\n\\bid{doi={10.1007/b97848}, mr={1920390}}\n\\end{bbook}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{hunualsong11}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Hu},~\\bfnm{Yaozhong}\\binits{Y.}},\n\\bauthor{\\bsnm{Nualart},~\\bfnm{David}\\binits{D.}} \\AND\n\\bauthor{\\bsnm{Song},~\\bfnm{Xiaoming}\\binits{X.}}\n(\\byear{2011}).\n\\btitle{Malliavin calculus for backward stochastic differential\nequations and application to numerical solutions}.\n\\bjournal{Ann. Appl. Probab.}\n\\bvolume{21}\n\\bpages{2379--2423}.\n\\bid{doi={10.1214/11-AAP762}, issn={1050-5164}, mr={2895419}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{kohapett02}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Kohatsu-Higa},~\\bfnm{Arturo}\\binits{A.}} \\AND\n\\bauthor{\\bsnm{Pettersson},~\\bfnm{Roger}\\binits{R.}}\n(\\byear{2002}).\n\\btitle{Variance reduction methods for simulation of densities on\n{W}iener space}.\n\\bjournal{SIAM J. Numer. Anal.}\n\\bvolume{40}\n\\bpages{431--450 (electronic)}.\n\\bid{doi={10.1137/S0036142901385507}, issn={0036-1429}, mr={1921664}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{mazhan02}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Ma},~\\bfnm{Jin}\\binits{J.}} \\AND\n\\bauthor{\\bsnm{Zhang},~\\bfnm{Jianfeng}\\binits{J.}}\n(\\byear{2002}).\n\\btitle{Representation theorems for backward stochastic differential\nequations}.\n\\bjournal{Ann. Appl. Probab.}\n\\bvolume{12}\n\\bpages{1390--1418}.\n\\bid{doi={10.1214/aoap/1037125868}, issn={1050-5164}, mr={1936598}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{nual95}\n\n\\begin{bbook}[mr]\n\\bauthor{\\bsnm{Nualart},~\\bfnm{David}\\binits{D.}}\n(\\byear{2006}).\n\\btitle{The {M}alliavin Calculus and Related Topics},\n\\bedition{2nd} ed.\n\\bseries{Probability and Its Applications (New York)}.\n\\blocation{Berlin}:\n\\bpublisher{Springer}.\n\\bid{mr={2200233}}\n\\end{bbook}\n\n\n\\bptok{imsref}\n\n\n\n\\endbibitem\n\n\n\\bibitem{rich11}\n\n\\begin{barticle}[mr]\n\\bauthor{\\bsnm{Richou},~\\bfnm{Adrien}\\binits{A.}}\n(\\byear{2011}).\n\\btitle{Numerical simulation of {BSDE}s with drivers of quadratic growth}.\n\\bjournal{Ann. Appl. Probab.}\n\\bvolume{21}\n\\bpages{1933--1964}.\n\\bid{doi={10.1214/10-AAP744}, issn={1050-5164}, mr={2884055}}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\n\n\\endbibitem\n\n\n\\bibitem{turk13}\n\n\\begin{bmisc}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Turkedjiev},~\\bfnm{P.}\\binits{P.}}\n(\\byear{2013}).\n\\bhowpublished{Numerical methods for backward stochastic differential\nequations of quadratic and locally lipschitz type.\nPh.D. thesis, Mathematisch-Naturwissenschaftlichen Fakult\\\"at II der\nHumboldt-Universit\\\"at zu Berlin}.\n\\end{bmisc}\n\n\n\\bptok{imsref}\n\\endbibitem\n\n\n\\bibitem{turk13b}\n\n\\begin{barticle}[auto:parserefs-M02]\n\\bauthor{\\bsnm{Turkedjiev},~\\bfnm{P.}\\binits{P.}}\n(\\byear{2014}).\n\\btitle{Two algorithms for the discrete time approximation of\n{M}arkovian backward stochastic differential equations under local conditions}.\n\\bjournal{Electron. J. Probab.}\n\\bnote{In revision. Available at \\url\n{http://hal.archives-ouvertes.fr/hal-00862848}.}\n\\end{barticle}\n\n\n\\bptok{imsref}\n\n\n\\endbibitem\n\\end{thebibliography}\n\n\\printhistory\n\n", "itemtype": "equation", "pos": 108714, "prevtext": "\n\n{By subtracting} the term with factor $\\frac{1}2$, the result for\n$\\gamma\n=1$ follows.\nMoreover, plugging the result into (\\ref{eqiterationfeed2}), and\nreturning to general ${\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})}$, gives\n\n\n\\begin{eqnarray}\\label{equpperboundu}\nu_j &\\le&{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} w_j + {\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta\n_l}{(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\alpha}}}\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum\n_{l=j+1}^{N-1} \\frac{w_l \\Delta_l}{(T-t_l)^{{{1}/2 -\n\\beta\n}}}\n\\end{eqnarray}\n\nfor a constant ${\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}:= 2 {\\mathcal C}_{(\\ref{eqiterationfeed2}\\mathrm{a})} \\mathrm{e}^{\\zeta_T} (1 + {B_{{\\alpha+ \\beta},1}}\nT^{\\alpha+\\beta})$. Now for the general case $\\gamma>0$, observe that,\nfor any $\\delta\\geq0$,\none obtains by change of the order of summation that\n\n\n\\begin{eqnarray}\\label{eqineqappendix}\n&& \\sum_{j=i+1}^{N-1}\n\\frac{\\sum_{l=j+1}^{N-1}\n{w_l \\Delta_l}\n\\Delta_{j}/\n({(T-t_l)^{{{1}/2 - \\beta}}(t_l - t_j)^{{{1}/2-\\delta}}}) }{(T-t_{j})^{1/2 - \\beta\n}(t_j-t_i)^{1-\\gamma} }\n\\nonumber\\[-8pt]\\[-8pt]\\nonumber\n&&\\qquad \\leq B_{\\beta+\\delta,\\gamma} \\sum_{l=i+2}^{N-1}\n\\frac{w_l\\Delta\n_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1-\\beta-\\delta-\\gamma} }.\n\\end{eqnarray}\n\nThus, (\\ref{equpperboundu}) yields\n\n\\begin{eqnarray*}\n&& \\sum_{j=i+1}^{N-1} \\frac{u_j \\Delta_{j}}{(T-t_{j})^{1/2 - \\beta\n}(t_j -t_i)^{1-\\gamma} }\n\\\\\n&&\\quad \\leq\n{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\sum_{j=i+1}^{N-1} \\frac{w_j \\Delta_j}{(T-t_j)^{{{1}/2 -\n\\beta}}(t_j - t_i)^{{1-\\gamma}}}\n\\\\\n&&\\qquad{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} B_{\\beta+\\alpha,\\gamma}\\sum_{l=i+2}^{N-1}\n\\frac\n{w_l\\Delta_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1-\\beta-\\alpha\n-\\gamma} }\n\\\\\n&&\\qquad{} +{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}} B_{\\beta+{{1}/2},\\gamma}\\sum_{l=i+2}^{N-1}\n\\frac\n{w_l\\Delta_l}{(T-t_l)^{{{1}/2} - \\beta}(t_l-t_i)^{1/2-\\beta\n-\\gamma} }\n\\\\\n&&\\quad \\leq{\\mathcal C}_{\\mathrm{(\\ref{equpperboundu})}}\\bigl(1+B_{\\beta+\\alpha,\\gamma}T^{\\alpha+\\beta}+\nB_{\\beta+{{1}/2},\\gamma}T^{1/2+\\beta}\\bigr)\\sum_{j=i+1}^{N-1}\n\\frac\n{w_j \\Delta_j}{(T-t_j)^{{{1}/2 - \\beta}}(t_j - t_i)^{{1-\\gamma}}}.\n\\end{eqnarray*}\n\n\n\n\n\\subsection{Proof of Lemma \\texorpdfstring{\\protect\\ref{lemobsbounds}}{3.7}}\\label{appendixprooflemmalemobsbounds}\nUsing the bounds ${C_{y,i}}$ and ${C_{z,i}}$ on ${y^{(M)}_{i}(\\cdot)}$ and ${z^{(M)}_{i}(\\cdot)}$,\nrespectively, one applies the local Lipschitz continuity and\nboundedness properties of $f_j$ given in {$(\\mathbf{A_F})$}~to obtain the bound\n\n\n\n", "index": 75, "text": "\\begin{equation}\n\\bigl{\\vert} f_j \\bigl(x_j, {y^{(M)}_{{j+1}}({x_{j+1}})}, {z^{(M)}_{j}({x_j})} \\bigr) \\bigr{\\vert}\\le\n\\frac{L_f ({C_{y,j+1}}\n+ {C_{z,j}}) }{(T-t_j)^{1/2 {- {\\thetaL/2}}} } +\n\\frac\n{C_f}{(T-t_j)^{1-{\\theta_c}}}. \\label{eqMCbdf}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\bigl{|}f_{j}\\bigl{(}x_{j},{y^{(M)}_{{j+1}}({x_{j+1}})},{z^{(M)}_{j}({x_{j}})}%&#10;\\bigr{)}\\bigr{|}\\leq\\frac{L_{f}({C_{y,j+1}}+{C_{z,j}})}{(T-t_{j})^{1/2{-{%&#10;\\thetaL/2}}}}+\\frac{C_{f}}{(T-t_{j})^{1-{\\theta_{c}}}}.\" display=\"block\"><mrow><mrow><mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo><mrow><msub><mi>f</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>,</mo><mrow><msubsup><mi>y</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msubsup><mi>z</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>M</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow><mo fence=\"true\" maxsize=\"120%\" minsize=\"120%\">|</mo></mrow><mo>\u2264</mo><mrow><mfrac><mrow><msub><mi>L</mi><mi>f</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>C</mi><mrow><mi>y</mi><mo>,</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></mrow></msub><mo>+</mo><msub><mi>C</mi><mrow><mi>z</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow><mo>-</mo><mrow><merror class=\"ltx_ERROR undefined undefined\"><mtext>\\thetaL</mtext></merror><mo>/</mo><mn>2</mn></mrow></mrow></msup></mfrac><mo>+</mo><mfrac><msub><mi>C</mi><mi>f</mi></msub><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>T</mi><mo>-</mo><msub><mi>t</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03b8</mi><mi>c</mi></msub></mrow></msup></mfrac></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]