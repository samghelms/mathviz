[{"file": "1601.06038.tex", "nexttext": "\nyields additional insight in the optimization dynamic and helps determining proper mutation probabilities.\nHere, $F{\\ensuremath{^{}_{{i}}}}$ is the fitness on the basis of a set of $N \\in \\mathbb{N}$ measurements $X = \\left\\lbrace v{\\ensuremath{^{}_{{i}}}} | i= 1,..,N\\right\\rbrace$ with the mean denoted by $\\braket{\\cdot} $.\n\nSpecifically, the probability to mutate a parameter should be chosen according to the correlation, since for small changes it is a measure for linear response.\nAn absolute value $|c| = 1$ indicates a complete linear relation.\nThe correct choice of the mutation range is rather difficult. Ideally, the EA explores the whole parameter space. However, if in a single step the mutation range spreads over the whole parameter space, the mutation process effectively realizes a random parameter generator which does not necessarily converge on the optimization of the fitness. We privilege a small mutation range and hence we expect a linear dependence on the fitness, resulting in a vanishing correlation around local maxima. In this case, the mutation range should be extended by setting the range anti-proportional to the correlation thus allowing to leave the local maximum and spread for global optima.\n\nAfter the mutation step, the fitness of the population, which comprises the newly created individuals ${\\ensuremath{\\mathcal{{B}}}}$ and their ancestors ${\\ensuremath{\\mathcal{{A}}}}$, is determined.\nExperimentally, this implies a realization of the experimental cycle for every parameter set of any individual and measuring all quantities that compose the fitness, such as the atomic loading rate of a magneto-optical trap (MOT), the atom number in the dipole trap, or the phase-space density of a BEC.\nFinally the EA selects those individuals with the highest fitness as ancestors for the next generation (step 4), or it stops if a termination condition such as maximum fitness is reached or total duration is exceeded (step 5).\nWhile the bare EA randomly explores the parameter space, being rather a stochastical process, there exist many implementations that combine the power of EAs to scale with increasing dimension and approach global optima with other optimization techniques that converge faster to local maxima.\n\n{\\textit{{Differential evolution (DE)}:}}\nA common way of manual optimization is to keep track of important parameters and separately tune them to an optimum. \nThe DE employed in our system (see figure \\ref{fig:steepest_descent}) is an adaption of a steepest descent linear optimization technique~\\cite{Price2005}, capable of accelerating the convergence to a local optimum~\\cite{Das2005}.\nThis step is added to the EA between determining the fitness of a generation and  selecting the fittest individuals.\nIt compares the fitness of an individual $\\vec{v}{\\ensuremath{^{}_{{i}}}}$ to the fitness of the population in the previous generation. If the individual shows an improvement \\mbox{$\\Delta F{\\ensuremath{^{}_{{i,j}}}} = F(v{\\ensuremath{^{}_{{i}}}}) - F(v{\\ensuremath{^{}_{{j}}}}) > 0$} compared to the one of its ancestors $\\vec{a}{\\ensuremath{^{}_{{j}}}}$ the total optimization vector \n\\mbox{$\\delta \\vec{k} = \\sum{\\ensuremath{^{}_{{j}}}} \\Delta F{\\ensuremath{^{}_{{i, j}}}} (\\vec{v}{\\ensuremath{^{}_{{i}}}} - \\vec{a}{\\ensuremath{^{}_{{j}}}}) / \\sum{\\ensuremath{^{}_{{j}}}} |\\Delta F{\\ensuremath{^{}_{{i,j}}}}|$} is calculated.\nTherefore, we sum over all vectors from ancestor to individual weighted with the improvement $\\Delta F{\\ensuremath{^{}_{{i,j}}}}$.\nOnce such an optimization vector has been found, new individuals ${\\ensuremath{\\mathcal{{O}}}} = \\lbrace \\vec{o}{\\ensuremath{^{}_{{k}}}} = \\vec{v}{\\ensuremath{^{}_{{\\text{{i}}}}}} + k \\cdot \\delta \\vec{k} \\rbrace$ following the vector are successively injected into the EA and their fitness is evaluated. In order to determine the quality of the DE vector $\\delta \\vec{k}$, the correlation between the DE step $k$ on the one hand and the fitness increase on the other hand is chosen. For small steps $\\delta \\vec{k}$ the correlation can be understood as a measure of a linear gradient, which is expected to vanish when approaching a local optimum. This allows to define a pre-selected threshold, that determines whether the EA further follows this vector or it is rejected.\nThe adaption of this threshold depending on the signal to noise ratio decreases the sensitivity to measurement noise, thus increasing the capability to find local optima when optimizing a noisy fitness.\n\n\n\\begin{figure}[h]\n\t\\includegraphics[width=0.48\\textwidth]{experiment.pdf}\n\t\\caption{\n\t\tExemplary sketches of different measurement signals that serve as fitness in the steps of the BEC creation to which we apply the EA.\n\t\t(i) Fluorescence signal from loading of a MOT. (ii) Absorption image of the atoms loaded to a crossed FORT. (iii) Absorption Image of a BEC which is optimized to a maximized phase-space density.\n\t}\n\t\\label{fig:experiment}\n\\end{figure}\n\n\n\\section{Application of the EA to BEC Production}\n\\label{sec:application}\n\nWe apply our EA to the individual steps of our BEC creation sequence (see figure \\ref{fig:experiment}) comprised of (i) laser cooling of an atomic beam in a two-dimensional (2D) MOT and subsequent trapping in a three-dimensional (3D) MOT \\cite{Steane1991,Metcalf1999}, (ii) transfer of atoms to a crossed far off resonance trap (FORT) \\cite{Grimm2000}, and (iii) evaporation of the sample in this optical trap~\\cite{Ketterle1999}. In each step the EA has been granted full access to important parameters such as laser detuning, laser intensities, coil currents and it is able to control the timing of, e.g., laser pulses or intensity ramps. In all cases, we define a proper fitness for each individual step and extract the correlation between a parameter and the respective fitness.\n\\begin{figure}[b]\n\t\\centering\n\t\\includegraphics[scale=0.75]{optimization_2d_pca.pdf}\n\t\\caption{\n\t\tOptimization of 2D MOT performance.\n\t\t{({a})} MOT loading rates being the fitness of optimization for vertically opposing coil currents. The fitness is encoded in color and size of the dots. Point $I{\\ensuremath{^{}_{{\\text{{S}}}}}}$ marks the center-of-mass of all data points. It is the center of the new coordinate system of the PCA, shown in {({b})}. Tagged with {({G})} are the main and the minor axes, which differ most in correlation. The orthogonality is due to our geometry rather than a general property of PCA's main axes. By choosing this set of axes and keeping the minor axis fixed almost no information is lost. The set of axes tagged with {({W})} exemplifies a case where the correlation to the fitness does not differ and therefore no reduction in dimension is possible without loosing information.\n\t}\n\t\\label{fig:optimization_2d_pca}\n\\end{figure}\n\n\n\\begin{figure*}[t]\n\t\\includegraphics[width=\\textwidth]{optimization_3d_from_scratch.jpg}\n\t\\caption{\n\t\tTypical time evolution of the fitness defined as MOT loading rate $\\gamma$ evolving in the EA, starting from randomly chosen individuals. The reference measurements {({R, red triangles})}, obtained from manual optimization, are not participating in EA. Generations are separated by vertical lines.\n\t\tIn the first generation of the EA a single random choice reaches a significant loading rate, yet still smaller than the reference set. This individual survives the first generation and is remeasured in the following iteration, marked as survivor (blue dot).\n\t\tAfter $\\SI{60}{\\second}$ the DE is applied for the first time (green diamonds). At {({C})} in the fourth generation the recombination resulted in individuals with a fitness exceeding the initial, manual optimization {({R})}.\n\t\tDE further increases the loading rate from $\\SI{4.0 \\pm .1 e8}{\\atoms \\per \\second}$ to $\\SI{6.6 \\pm .1 e8}{\\atoms \\per \\second}$ at {({G})}. The genealogy of the differential optimization {({G})}, which is plotted below, increases the power of the cooling laser and correlates up to $c = 0.92 $ with the fitness. Details of this optimization vector are given in table \\ref{tb:optimizsation_3d_from_scratch}.\n\t}\n\t\\label{fig:optimization_3d_from_scratch}\n\\end{figure*}\n{\\textit{{(i) MOT optimization}:}}\nIn a first step of the BEC creation sequence a large number of atoms are laser cooled and captured in a 3D MOT. The 3D MOT is loaded from a pre-cooled atomic beam originating from a 2D MOT, described in \\cite{Hohmann2015}.\nTo optimize the 3D MOT loading, where the atom number of trapped atoms $N$ can be described by an exponential $N(t) = N_\\mathrm{max} \\cdot (1- \\exp\\{- \\gamma t \\})$, we obtain the loading rate $\\gamma$ from a fit.\nThe parameters to be optimized thus include the laser detunings and intensities for the 2D and 3D cooling and repumper lasers, the intensity and detuning of a push beam which guides the atoms from the 2D to the 3D MOT region, and the currents of the magnetic quadrupole fields of the MOT. In total the dimension of this optimization problem sums up to 12 parameters.\nSpecifically, the quadrupole fields for the 2D MOT are produced by four coils, the currents of which can be independently adjusted. Here, the ratio of opposing coil currents determines the position of the 2D MOT, while the absolute current determines the size of the cooling area. The atomic beam emitted from the 2D MOT has to pass a differential pumping tube with a diameter of $\\SI{1.8}{\\milli\\meter}$. Thus, the ratio of opposing currents is rather fixed by this constraint, effectively allowing the parameter space to be reduced.\nWe use a mathematical tool called principal component analysis (PCA) \\cite{Handl2010} in order to identify a rotated coordinate system in parameter space which is more suited for optimization. Specifically, we aim for finding major axes of the rotated coordinate system that contain important information of the problem, while minor axes can be neglected with minimal loss of information. The amount of information of an axis is described by the correlation of the fitness to variations along the axis.\nWe apply a PCA to the fitness values obtained from the optimization of our 2D MOT coil currents.\nThe result is depicted in figure \\ref{fig:optimization_2d_pca} for opposing coils and clearly shows a high correlation on a line close to a current ratio of unity, with a starting point $I{\\ensuremath{^{}_{{\\text{{S}}}}}}$ for further applications of the EA. The perpendicular axis, in contrast, only shows a weak correlation. This is an optimal coordinate system for our problem with a major axis along the high correlation, and we neglect the weakly correlated minor axis in the following. This coordinate system especially improves the reproduction process since we use a discrete inheritance which does not necessarily conserve the ratio of parameters, e.g., opposing coil currents.\n\nNow we add the parameters of the 3D MOT to the EAs optimization task and  improve the loading rate further.\nAn increase in fitness value will show the progress of the EA, however, the fitness can also be affected by drifts of the experimental apparatus.\nIn order to quantify the progress of the EA independently from these drifts, we apply reference measurements with a predefined parameter set, representing the best manual optimization. This parameter set is evaluated at the beginning of each new generation but it is not taking part in any population of the EA. Figure \\ref{fig:optimization_3d_from_scratch} compares the evolution of the fitness for the 3D MOT with such reference measurements. The EA starts from random initial parameters with initially vanishing fitness. The graph demonstrates the typical observation, where the EA exceeds the fitness of the manually obtained optimum by a factor of three after $\\SI{400}{\\second}$. Importantly, both components of our algorithm, evolutionary strategy as well as differential optimization, contribute to the total improvement.\n\nThe parameter values of the differential optimization depicted in figure \\ref{fig:optimization_3d_from_scratch} are given in table \\ref{tb:optimizsation_3d_from_scratch}. \nHere, we observe an increase in loading rate that is highly correlated ($c = 0.93$) to the increase of the cooling laser power. \nHowever the expected parameter, {\\textit{i.e.}\\,\\,} the cooling laser intensity control value, surprisingly remains unchanged.\nThis indicates that the EA has found a hidden correlation. Pathologically, a frequency change of our laser lock setup also affects the intensity of the diffracted laser beam in the acousto-optical modulators (AOM) that are used for fast switching of intensities and detuning the laser frequencies. This is caused by modifying the working point of the AOM on the non-linear curve of diffraction efficiency versus frequency. Thus, the AOM output power depends on the frequency chosen. \n\n{\\textit{{(ii) Atom transfer to the FORT}:}}\nFrom the MOT, the atoms are transfered to a crossed FORT at $\\SI{1064}{\\nano\\meter}$ for evaporative cooling to degeneracy.\nTo optimize the initial conditions for the evaporation, the transfer rate is improved with our EA, choosing the total amount of transferred atoms as fitness.\nHere, we add an initial phase of self evaporation where the laser intensities are kept constant and an additional compressed-MOT (CMOT) phase \\cite{Ketterle1993,Lewandowski2003}, where the cooling laser is far red detuned leading to a decreased heating from re-emission of photons.\nThis results in a anti-correlation of $c = -0.09$ between the cooling laser power and the fitness, which means that an increase in cooling laser power results in a lower loading rate.\nIn contrast to the MOT, the repumping laser intensity here is highly anti-correlated with $c \\approx -0.74$, since less repumping power allows more atoms to leave the cooling cycle, which minimizes heating.\nThis optimization increases the total atom number loaded to the FORT from $\\SI{2.6e5}{\\atoms}$ to $\\SI{1.05 e6}{\\atoms}$ by a factor of four and is used as starting point for the following evaporation process.\n\n{\\textit{{(iii) Optimization of the evaporation}:}}\nAs a last step we focus on the experimental details and analyze the consequences when applying the EA to optimize the BEC production, namely evaporation \\cite{Lewandowski2003,Clement2009}, and improve the phase space density.\nThe optimization parameters for the evaporation process include initial and final intensities as well as the decay times of the exponentially ramped trapping potentials for both arms of the crossed FORT. Furthermore we introduce a delay between the start of both evaporation ramps. \nIn order to estimate the phase space density we image the atomic sample with a time-of-flight (TOF) of \\mbox{${\\ensuremath{t{\\ensuremath{^{}_{{\\text{{TOF}}}}}}}} = \\SI{16}{\\milli\\second}$}. We extract the widths $\\sigma_{x,y}$ and the total atom number\n$N = A \\left[\\pi (\\sigma_x^2+\\sigma_y^2)\\right]^{1/2}$, where $A$ is the optical peak density integrated over the $z$-direction. For the fit of the measured distribution we use a Gaussian distribution rather than a bimodal fit, which is numerically unstable when spanning a large parameter space across the critical point of Bose-Einstein condensation.\nThereby we estimate the temperature $T \\propto (\\sigma_x^2 + \\sigma_y^2) / {\\ensuremath{t{\\ensuremath{^{}_{{\\text{{TOF}}}}}}}}$, neglecting the clouds in trap size, justified by the large TOF.\nThe fitness for the algorithm is defined as the peak density $\\sfrac{A}{(\\sigma_x^2 + \\sigma_y^2)}$, which is a coarse approximation of the phase space density $\\rho = n \\lambda^{3}_\\text{dB}$, where $\\lambda{\\ensuremath{^{}_{{\\text{{dB}}}}}} \\propto T^{\\sfrac{-1}{2}}$ is the thermal De-Broglie wavelength and $n = \\sfrac{N}{V{\\ensuremath{^{}_{{\\text{{Trap}}}}}}}$ the atomic density.\n\nThe evolution of the evaporation is depicted in figure \\ref{fig:optimization_bec}, where additionally to the fitness the absolute atom number and the temperature are shown.\nIn the region {\\ensuremath{({A-B})}} of figure \\ref{fig:optimization_bec}, the algorithm increases the atom number $N$ while in {\\ensuremath{({B-C})}} it reduces the temperature $T$, both leading to an increased phase space density $\\rho$. \n\n\\begin{figure}[b]\n\t\\includegraphics[width=.48\\textwidth]{optimization_bec.jpg}\n\t\\caption{\n\t\tOptimization of evaporative cooling to a maximum phase space density $\\rho$. The color code visualizes the obtained fitness which is directly proportional to the phase space density. The mean values of the reference measurements are marked by a black line with its confidence interval (shaded area). Since the reference parameter set has been readjusted to new optimum values after each break (dashed vertical line) it is not continuous. The different regions separated by vertical solid grey lines indicate, where the EA follows different optimization strategies {\\ensuremath{({A-D})}}.\n\t\tThe dotted vertical lines indicate a break in optimization, the red horizontal line is the critical temperature.\n\t\tThe insets show cold clouds at the beginning (left inset) and at the end (right inset) of the optimization process, where color coding is the same.\n\t}\n\t\\label{fig:optimization_bec}\n\\end{figure}\n\nBy correlating applied changes to measured observables, we determine the parameters with the strongest impact.\nIn the region ${\\ensuremath{({A-B})}}$ the increase of atom number has a maximum correlation of $c = 0.46$ to the CMOT duration.\nExtending the CMOT duration and consequently decreasing the duration of the self evaporation in the FORT increases the number of atoms loaded results in an augmentation of remaining atoms after the evaporation.\nOn the one hand, the phase space density is directly proportional to the atom number, hence increasing the CMOT duration is a good optimization vector. On the other hand, we have limited the time for the CMOT duration to avoid violation of timing constraints.  At {({B})} in figure \\ref{fig:optimization_bec} the optimization vector violates timing constraints and therefore cannot increase the atom number any further. This results in a positive correlation indicating that further improvement by extending the CMOT duration is possible.\n\nIn region ${\\ensuremath{({B-C})}}$ we observe that the atomic temperature is decreased from {({B})} $T=\\SI{0.29 \\pm 0.05}{\\micro\\kelvin}$ to {({C})} $T=\\SI{0.10 \\pm 0.05}{\\micro\\kelvin}$.\nWe find that the evaporation ramp decay time has the highest absolute correlation $c \\approx -0.48$ which is therefore the main reason for the temperature drop.\nDecreasing the decay time results in less time for the atoms to thermalize and  increased loss of atoms during the evaporation process, causing the average atom number to drop from {({B})} $N = 101(28)\\cdot10^3$ atoms to {({C})} $N = 46(12)\\cdot 10^3 $ atoms.\n\nBesides yielding information about important parameters for the evaporation and FORT loading processes, the application of the EA resulted in an increased phase space density which enabled us to reduce the time for the creation of our BEC from $\\SI{8}{\\second}$ to $\\SI{4}{\\second}$.\n\n\n\\section{Conclusion}\n\\label{sec:outlook}\n\nWe have discussed the implementation of an EA enhanced with a differential evolution method to optimize the different steps of BEC production. Particularly, we introduced the various fitness definitions we applied to improve these individual trapping steps. We showed that the parameter space can be reduced by applying a principal component analysis and furthermore illustrated the genealogy of the EA, that reveals non trivial correlations of the experimental setup.\nBasically the EA can be applied to any optimization problem and in our application resulted in several improvements such as the increase of magneto-optical trap loading rate by a factor of $\\approx 3$, an increase in total atom number loaded into the dipole trap by a factor of $\\approx 4$, when starting with already optimized parameters from the MOT and an increase of the BEC phase space density by an order of magnitude allowing for a BEC creation in $\\SI{4}{\\second}$.\nWe have shown that, by applying the EA, we do not only gain long term statistics that yield information about drifts of devices and optimal parameter sets, but we also learn about further optimization options by analyzing correlations between parameters and fitness and by evaluating the DE optimization vectors.\n\n\n{\\textit{{Acknowledgement}:}}\n\tThe project was financially supported partially by the European Union via the ERC Starting Grant 278208 and partially by the DFG via SFB/TR49.\n\tD.M. is a recipient of a DFG-fellowship through the Excellence Initiative by the Graduate School Materials Science in Mainz (GSC 266),\n\tF.S. acknowledges funding by Studienstiftung des deutschen Volkes, and\n\tT.L. acknowledges funding from Carl-Zeiss Stiftung.\n\n\t\n\n\n\t\\bibliography{manuscript.bib}\n\t\n\t\n\t\n\\section{Supplementary}\n\n\\begin{table}[H]\n\t\\caption[Optimization vector {({G})} depicted in figure \\ref{fig:optimization_3d_from_scratch}]{Data of the optimization vector {({G})} depicted in figure \\ref{fig:optimization_3d_from_scratch} with relevant changes (degree of mutation $\\nu > 1\\%$) and correlations of observables ( $c > 0.7$).\n\t\tWe observe highest correlation to the 3D cooling laser power (${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$), which is the main reason for the increase of the loading rate.\n\t\tPathologically the intensity control voltage ${\\ensuremath{C{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$ is not changed, thus the reason of the increase in ${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$ is a consequence of a non trivial hidden correlation of our setup.\n\t\tThe spectroscopy ${\\ensuremath{\\omega{\\ensuremath{^{}_{{\\text{{Spec}}}}}}}}$ is the first of two AOMs, that control cooling lasers detuning.\n\t\tIn order to keep the 3D MOT detuning ${\\ensuremath{\\det{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$ constant the subsequent AOM compensates the change per linear optimization step of $\\delta\\vec{k}({\\ensuremath{\\omega{\\ensuremath{^{}_{{\\text{{Spec}}}}}}}}) = -{\\ensuremath{{\\ensuremath{2\\pi\\cdot\\SI{{{3.0}}}{{\\mega}\\hertz}}}}}$ and thereby optimizes the working point resulting in an increased ${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$.\n\t}\n\t\\label{tb:optimizsation_3d_from_scratch}\n\t\\centering\n\t\\begin{tabular}{ l|c c c }\n\t\t\\toprule\n\t\tparameter\t\t \t& start \t\t&  $\\delta\\vec{k}$\t\t& \\\\\n\t\t\\midrule\n\t\t{\\ensuremath{\\omega{\\ensuremath{^{}_{{\\text{{Spec}}}}}}}} \t\t& ${\\ensuremath{{\\ensuremath{2\\pi\\cdot\\SI{{{435.7}}}{{\\mega}\\hertz}}}}}$ \t& $-{\\ensuremath{{\\ensuremath{2\\pi\\cdot\\SI{{{3.0}}}{{\\mega}\\hertz}}}}} $\t& \\\\ \n\t\t{\\ensuremath{\\det{\\ensuremath{^{}_{{\\text{{2D}}}}}}}} \t& $-{\\ensuremath{{\\ensuremath{2\\pi\\cdot\\SI{{{13.5}}}{{\\mega}\\hertz}}}}}$ \t& $+{\\ensuremath{{\\ensuremath{2\\pi\\cdot\\SI{{{0.3}}}{{\\mega}\\hertz}}}}} $\t& \\\\\n\t\t\\toprule\n\t\tobservable \t\t\t& start \t\t& change                 & corr. \\\\\n\t\t\\midrule\n\t\t${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{3D}}}}}}}}$ & $\\SI{118}{\\milli\\watt}$ & $+\\SI{23}{\\milli\\watt}$ & $\\num{0.93} $ \\\\\n\t\t${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{2D}}}}}}}}$ &$\\SI{79}{\\milli\\watt}$ & $+\\SI{3.39}{\\milli\\watt}$ & $\\num{0.83} $ \\\\\n\t\t${\\ensuremath{P{\\ensuremath{^{}_{{\\text{{Rep}}}}}}}}$ & $\\SI{2.58}{\\milli\\watt}$ & $+\\SI{48}{\\micro\\watt}$ & $\\num{0.72} $ \\\\\n\t\\end{tabular}\n\\end{table}\n\n\n", "itemtype": "equation", "pos": 10744, "prevtext": "\n\t\\title{Optimizing Quantum Gas Production by an Evolutionary Algorithm}\n\n\t\\author{Tobias Lausch}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\n\t\\author{Michael Hohmann}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\n\t\\author{Farina Kindermann}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\n\t\\author{Daniel Mayer}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\\affiliation{Graduate School Materials Science in Mainz, Gottlieb-Daimler-Strasse 47, 67663 Kaiserslautern, Germany}\n\t\n\t\\author{Felix Schmidt}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\\affiliation{Graduate School Materials Science in Mainz, Gottlieb-Daimler-Strasse 47, 67663 Kaiserslautern, Germany}\n\t\n\t\\author{Artur Widera}\n\t\\affiliation{Department of Physics and Research Center OPTIMAS, University of Kaiserslautern, Germany}\n\t\\affiliation{Graduate School Materials Science in Mainz, Gottlieb-Daimler-Strasse 47, 67663 Kaiserslautern, Germany}\n\t\n\\begin{abstract}\n\tWe report on the application of an evolutionary algorithm (EA) to enhance performance of an ultra-cold quantum gas experiment.\n\tThe production of a $^{87}$Rubidium Bose-Einstein condensate (BEC) can be divided into fundamental cooling steps, specifically magneto optical trapping of cold atoms, loading of atoms to a far detuned crossed dipole trap and finally the process of evaporative cooling. The EA is applied separately for each of these steps with a particular definition for the feedback the so-called fitness. We discuss the principles of an EA and implement an enhancement called differential evolution.\n\tAnalyzing the reasons for the EA to improve {\\textit{e.g.}\\,\\,}, the atomic loading rates and increase the BEC phase-space density, yields an optimal parameter set for the BEC production and enables us to reduce the BEC production time significantly. Furthermore, we focus on how additional information about the experiment and optimization possibilities can be extracted and how the correlations revealed allow for further improvement.\t\n\tOur results illustrate that EAs are powerful optimization tools for complex experiments and exemplify that the application yields useful information on the dependence of these experiments on the optimized parameters.\n\\end{abstract}\n\n\\keywords{Ultracold Quantum Gases -- Bose-Einstein Condensate -- Optimization -- Evolutionary Algorithm -- Differential Evolution}\n\n\n\\maketitle\n\n\n\n\\section{Introduction}\n\\label{sec:introduction}\n\nQuantum gases have proven to be versatile model systems to investigate intriguing phenomena of quantum physics, including, for example, superfluidity in ultracold bosonic \\cite{Desbuquois2012} or fermionic quantum gases \\cite{Zwierlein2005}.\n\nIn an experimental realization, quantum gas production requires several distinct cooling steps, typically including different laser cooling stages, a transfer to a conservative trap, and evaporative cooling to the quantum degenerate regime \\cite{Ketterle1999}. \nWhile these individual steps and the underlying physics are well understood, the experimental apparatus usually requires controlling dozens of parameters. \nThese are normally constrained depending on the specific experimental scenario, such as maximum currents or laser powers. \nBeyond the large number of parameters, an additional complication arises from the emergence of correlations between experimental parameters which are sometimes unknown and originate from the particular experimental setup. \nA simple and well-known example for such a correlation is the change of atomic transition frequencies in deep optical traps due to the AC Stark shift \\cite{Barber2008,Rosenbusch2009}, which correlates the detuning of external resonant lasers to the intensity that defines the trap depth.\nIn normal operation, therefore, it is unclear, if an apparatus is operating at the optimum of its capabilities. \nOperating at the optimum, however, is advantageous for statistics of the measurements, stable operation over long times and achieving the fastest possible experimental cycle duration.\nWe show that, in all cases considered, a manually optimized set of parameters can be improved by application of an evolutionary algorithm.\n\nEvolution is the most natural way of optimization in a given scenario, which in terms of biology may be associated with the evolution of genetic material \\cite{Stern2013}.\nThe corresponding digitized version in information technology is called  \\emph{evolutionary algorithm} (EA).\nIn fact, EAs are commonly applied in various fields \\cite{Baumert1997,Pearson2001,Tsubouchi2008,Roslund2009} and moreover have created their own field of research in information technology that is closely linked to swarm optimization algorithms, artificial intelligence and self-teaching technologies \\cite{Picard2008,Kennedy1995,Fogel1966}.\nThe application of such an algorithm has proven to result in interesting improvements, {\\textit{e.g.}\\,\\,} the design of antennas \\cite{Hornby2011}.\nIn general, it is an iterative modification and selection process that optimizes a so-called fitness value on a given set of parameters, {\\textit{e.g.}\\,\\,} selecting the combination of parameters in our quantum gas experiment that leads to the fastest sequence to produce a BEC.\n\nWe report on the implementation of an evolutionary algorithm which has  been shown to operate in systems with large dimension that exhibit unknown correlations \\cite{Price2005}. The application of such algorithms elucidates these correlations and improves, {\\textit{e.g.}\\,\\,}  the performance of quantum gas production.\nThis technology is applied to the creation of an all optical BEC of $^{87}$Rubidium (Rb), which in our project is combined with individual $^{133}$Caesium (Cs) atoms.\nIn order to obtain small statistical errors for measurements on a single atom we require many repetitions and therefore the fastest possible creation cycle for the BEC.\nIn our setup, approximately 70 parameters need to be controlled during a single realization of the experiment. Controlling and optimizing this number of parameters manually is a challenging and demanding task. Since manual adjustment mostly optimizes each parameter separately, it falls short behind the system's technical potential. We find that using the EA on computer-controlled parameters leads to a general improvement of a pre-defined figure of merit and allows reducing the time for quantum gas production from eight to four seconds.\nPrevious work has applied an EA to the creation of ultra cold quantum gases and increased the mean atom number of an optical molasses \\cite{Rohringer2008} with a three-dimensional set of parameters or increased the phase-space density of a four-dimensional problem by improving the radio-frequencies (RF) and timing of RF-cooling ramps \\cite{Rohringer2011}. In a related work the scaling with dimensionality of an EA was analyzed and the introduction of a limited lifetime effectively shown to increase robustness against signal noise \\cite{Geisel2013}.\nThere are also other techniques such as machine-learning algorithms applied to the shaping of the evaporation scheme to increase phase-space density of a BEC \\cite{Wigley2015}.\nHere, we do not only describe our implementation of such an EA but also give examples how to further enhance the bare EA. We keep focus on the information that can be obtained from applying such an algorithm revealing important correlations and knowledge about the experiment.\n\n\n\n\\section{The Evolutionary Algorithm}\n\\label{sec:evolution}\nThe steps of the EA implemented  are depicted in Figure  \\ref{fig:evolution_cycle}.\nIn order to quantify the performance of a specific set of parameter values, referred to as an individual $\\vec{\\nu}{\\ensuremath{^{}_{{\\text{{i}}}}}} \\in {\\ensuremath{\\mathcal{{M}}}} $ out of parameter space ${\\ensuremath{\\mathcal{{M}}}}$,  it is assigned a single real value as fitness $F: {\\ensuremath{\\mathcal{{M}}}} \\rightarrow \\mathbb{R}$ during the iteration. All individuals of a given time step form a population ${\\ensuremath{\\mathcal{{A}}}}$ (step 1).\nFrom the selected individuals of the previous generation, a new population ${\\ensuremath{\\mathcal{{B}}}}$ is created in a reproduction step (step 2).\nFor this second step, we have implemented discrete inheritance $\\vec{\\nu}{\\ensuremath{^{}_{{\\text{{i}}}}}} \\oplus \\vec{\\nu}{\\ensuremath{^{}_{{\\text{{j}}}}}}$, where the partners $\\vec{\\nu}{\\ensuremath{^{}_{{\\text{{i,j}}}}}}$ are selected by descending fitness.\n\n\\begin{figure}[t]\n\t\\subfigure[]{\n\t\t\\includegraphics[width=.45\\textwidth]{evolution_cycle.pdf}\n\t\t\\label{fig:evolution_cycle}\t\n\t}\n\t\\subfigure[]{\n\t\t\\includegraphics[width=.45\\textwidth]{steepest_descent.pdf}\n\t\t\\label{fig:steepest_descent}\n\t}\n\t\\caption{\n\t\tEA Scheme: {({a})} The different processes of an EA (1.-5.) and the integration of differential evolution.\n\t\tThe algorithm includes reproduction of a population by combining individuals of highest fitness (2.), mutation (3.) of individuals with a certain rate and determination of the fitness. Based on the results of the preceding generation a subsequent steepest descent process adds linearly optimized individuals into the current population.\n\t\tFinally the individuals with highest fitness are selected (4.) to become ancestors in the following time step or the evolution is terminated due to having fulfilled a termination condition (5.).\n\t\t{({b})} Example of a steepest descent optimization based on an artificial fitness landscape for different fitness values $F$.\n\t\tThe improvement of $\\Delta F = +1$ from the individual $v$ to its ancestor $a{\\ensuremath{^{}_{{2}}}}$ creates a weighted optimization vector $\\delta \\vec{k}$ and multiple optimization candidates $o{\\ensuremath{^{}_{{1-3}}}}$.\n\t}\n\\end{figure}\n\nThus the parameters of new individuals match the parameter values of their parents and cannot leave a discontiguous parameter space.\nFor all applications here the number of parents was chosen to be two, but in general can be adjusted freely. The newly created individuals are subsequently mutated $\\vec{c}{\\ensuremath{^{}_{{\\text{{j}}}}}} = M(\\vec{\\nu}{\\ensuremath{^{}_{{\\text{{j}}}}}})$ (step 3), thus their parameter values are randomly changed with a certain probability and within a predefined range.\nThe probability for a parameter mutation as well as the degree of mutation are external properties, which have a strong influence on the convergence of the algorithm. Therefore their values are adapted to the optimization task.\n\nThe correlation \n\n", "index": 1, "text": "\\begin{equation}\n\tc(X,F) = \\sum_{i=0}^{N}\\frac{(v{\\ensuremath{^{}_{{i}}}} - \\braket{v})(F{\\ensuremath{^{}_{{i}}}}-\\braket{F})}{\\sqrt{(v{\\ensuremath{^{}_{{i}}}} - \\braket{v})^2(F{\\ensuremath{^{}_{{i}}}}-\\braket{F})^2}} \n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"c(X,F)=\\sum_{i=0}^{N}\\frac{(v{{}_{{i}}}-\\lx@braket@{v})(F{{}_{{i}}}-%&#10;\\lx@braket@{F})}{\\sqrt{(v{{}_{{i}}}-\\lx@braket@{v})^{2}(F{{}_{{i}}}-%&#10;\\lx@braket@{F})^{2}}}\" display=\"block\"><mrow><mrow><mi>c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>X</mi><mo>,</mo><mi>F</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>N</mi></munderover><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mmultiscripts><mo>-</mo><mprescripts/><mi>i</mi><none/></mmultiscripts><mrow><mo stretchy=\"false\">\u27e8</mo><mi>v</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo stretchy=\"false\">(</mo><mi>F</mi><mmultiscripts><mo>-</mo><mprescripts/><mi>i</mi><none/></mmultiscripts><mrow><mo stretchy=\"false\">\u27e8</mo><mi>F</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><msqrt><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mi>v</mi><mmultiscripts><mo>-</mo><mprescripts/><mi>i</mi><none/></mmultiscripts><mrow><mo stretchy=\"false\">\u27e8</mo><mi>v</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><msup><mrow><mo stretchy=\"false\">(</mo><mi>F</mi><mmultiscripts><mo>-</mo><mprescripts/><mi>i</mi><none/></mmultiscripts><mrow><mo stretchy=\"false\">\u27e8</mo><mi>F</mi><mo stretchy=\"false\">\u27e9</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mfrac></mrow></mrow></math>", "type": "latex"}]