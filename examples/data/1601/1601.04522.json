[{"file": "1601.04522.tex", "nexttext": "\nwhere the function round(.) denotes rounding a value to the nearest integer.\n\\par\nIn the embedding procedure, according to the message bit $m$, $Q^0$ or $Q^1$ is chosen to quantize the sample $x$ to the nearest quantization point $y$. For example, $Q^0$ and $Q^1$ may be chosen in such way that $Q^0$ quantizes x to even integers and $Q^1$ quantizes x to odd integers. If we wish to embed a \u00a1\u00b00\u00a1\u00b1 bit, then $Q^0$ is chosen, else $Q^1$.\n\\par\nIn the detecting procedure, it is reasonable to assume the marked signal $y$ is corrupted by the attacker, resulting in a noisy signal $\\tilde{y}$. The QIM detector is a minimum-distance decoder, which finds the quantization point closest to $\\tilde{y}$ and outputs the estimated message bit $\\tilde{m}$ \\cite{Data-HidingCodes}.\n\n", "itemtype": "equation", "pos": 8730, "prevtext": "\n\n\n\n\\title{Multiple Watermarking Algorithm Based on Spread Transform Dither Modulation}\n\n\n\n\n\n\n\n\n\n\n\n\\author{Xinchao~Li, Ju~Liu\\IEEEauthorrefmark{1},~\\IEEEmembership{Senior Member,~IEEE,}\n        Jiande~Sun,~\\IEEEmembership{Member,~IEEE,} Xiaohui~Yang, and Wei~Liu\n\n\\thanks{Xinchao~Li, Ju~Liu, Jiande~Sun, and Xiaohui~Yang are with the School of Information Science and Engineering, Shandong University, Jinan,\n250100, China (e-mail: juliu@sdu.edu.cn).}\n\n\\thanks{Ju~Liu and Wei Liu are with the Hisense State Key Laboratory of Digital Multi-Media Technology Co., Ltd, Qingdao, China.\n}\n\n\\thanks{This work was supported partially by the National Basic Research Program of China (973 Program, No.2009CB320905), the National Natural Science Foundation of China (60872024), the Cultivation Fund of the Key Scientific and Technical Innovation Project (708059), Education Ministry of China for funding, Nature Science Foundation of Shandong Province (Q2008G03), Doctoral Program Foundation of Institutions of Higher Education of China (200804221023).\n}\n\n\n\n\n\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\\begin{abstract}\n\nMultiple watermarking technique, embedding several watermarks in one carrier, has enabled many interesting applications. In this study, a novel multiple watermarking algorithm is proposed based on the spirit of spread transform dither modulation (STDM). It can embed multiple watermarks into the same region and the same transform domain of one image; meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference. Furthermore, to improve the fidelity of the watermarked image, the properties of the dither modulation quantizer and the proposed multiple watermarks embedding strategy are investigated, and two practical optimization methods are proposed. Finally, to enhance the application flexibility, an extension of the proposed algorithm is proposed which can sequentially embeds different watermarks into one image during each stage of its circulation. Compared with the pioneering multiple watermarking algorithms, the proposed one owns more flexibility in practical application and is more robust against distortion due to basic operations such as random noise, JPEG compression and valumetric scaling.\n\n\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\n\\begin{IEEEkeywords}\nMultiple Watermarking, STDM, Constrained Quadratic Minimization, Sequential Multiple Watermarking\n\\end{IEEEkeywords}\n\n\n\n\n\n\n\n\n\n\n\\IEEEpeerreviewmaketitle\n\n\n\n\\section{Introduction}\n\\IEEEPARstart\nIn recent years, as the rapid development in the field of digital watermarking, multiple watermarking algorithms which give the possibility of embedding different watermarks in the same image, have received widespread attention since the pioneering contribution \\cite{Cox97}, where the idea of embedding multiple watermarks in the same image is initially presented.\n\\par\nSince then, multiple watermarking has enabled many interesting applications. In \\cite{MW_ICASSP1999}, Mintzer and Braudaway suggest that the insertion of multiple watermarks can be exploited to convey multiple sets of information. Sencar and Memon \\cite{MW_ambiguity} apply the selective detection of multiple embedded watermarks, which can yield lower false-positive rates compared with embedding a single watermark, to resist ambiguity attacks. Boato et al. \\cite{MW_Tracing} introduce a new approach that allows the tracing and property sharing of image documents by sequentially embedding multiple watermarks into the data. Giakoumaki et al. \\cite{MW_health} apply multiple watermarking algorithm to simultaneously addresses medical data protection, archiving, and retrieval, as well as source and data authentication.\n\\par\nMeanwhile, different watermarking techniques and strategies have been proposed to achieve multiple watermarking. In \\cite{On_multiple_watermarking}, Sheppard et al. discuss three methods to achieve multiple watermarking: rewatermarking, composite watermarking and segmented watermarking. Rewatermarking embeds watermarks one after another and the watermark signal could only be detected in the corresponding watermarked image using the former watermarked signal as the original image. The watermark embedded previously may be destroyed by the one embedded later. Composite watermarking discusses the extension of single watermarking algorithms to the case of multiple watermarking by introducing orthogonal watermarks \\cite{MW_extention1,MW_extention2}. Being similar to these, CDMA based schemes \\cite{MW_CDMA1,MW_CDMA2} use the orthogonal codes to modulate the watermarks from different users to derive the orthogonal watermarks. Unfortunately, they cannot guarantee the robustness in the case of blind extraction. Segmented watermarking embeds multiple watermarks into different segments of one image. Clearly, the number of segments limits the number and size of watermarks to be embedded \\cite{Segment_WM}. The embedding pattern chosen for mapping watermarks to segments can greatly affect the robustness of each watermark against cropping attack \\cite{Embedding_Patterns}.\n\\par\nOther schemes embed different watermarks into different channels of the host data, e.g., different levels of wavelet transform coefficients\\cite{MW_health}, or RGB of the color image \\cite{MW_Phase-Modulation,MW_RGB}. In fact, the limited quantity of watermarks embedded would somehow constrain their application area.\n\\par\nIn this study, we focus on the techniques that can embed multiple watermarks into the same area and the same transform domain of one image, meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference.\n\\par\nTo this end, a novel multiple watermarking algorithm is proposed. It initially extends the spread transform dither modulation (STDM), a single watermarking algorithm, to the field of multiple watermarking. Moreover, through investigating the properties of the dither modulation (DM) quantizer and the proposed multiple watermarks embedding strategy, two optimization methods are presented which can improve the fidelity of the watermarked image significantly. Compared with the pioneering multiple watermarking algorithm \\cite{MW_wang2003}, it has considerable advantages, especially in robustness against Gauss Noise, Salt\\&Pepper Noise, JPEG Compression and Valumetric Scaling. Finally, some potential interesting applications are discussed and an application extension of our algorithm is proposed to realize image history management by sequentially embedded watermarks.\n\\par\nThe reminder of this paper is organized as follows. In section II, we briefly describe the main algorithm of spread transform dither modulation. In section III, the proposed multiple watermarking algorithm is introduced. In section IV, to improve the fidelity of the watermarked image, the properties of the dither modulation quantizer and the embedding strategy of the proposed algorithm are analyzed. In section V, two practical optimization methods are presented. In section VI, the efficiency of the two optimization methods is tested, meanwhile, the robustness of the proposed methods is assessed. Finally, some potential interesting applications of the proposed algorithm and the concluding remarks are summarized in section VII and VIII, respectively.\n\n\\section{Spread Transform Dither Modulation}\nAs the proposed multiple watermarking algorithm is based on Spread Transform Dither Modulation, a blind single watermarking algorithm belonging to the QIM family, introduction beginning with the basic QIM is appropriate.\n\n\\subsection{Quantization Index Modulation}\n\\begin{figure}[htb!]\\label{fg1}\n  \\centering\n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{QIM_traditional.eps}}\n  \\caption{Embedding one message bit, $m$, into one sample $x$ using original QIM, where sets of circles and crosses represent $\\Omega^0$ and $\\Omega^1$, respectively.}\\label{QIM_traditional}\n\\end{figure}\n\\par\nIn the original QIM watermarking, a set of features extracted from the host signal are quantized by means of a quantizer chosen from a pool of predefined quantizers on the basis of the to-be-hidden message \\cite{SW_QIM}. In the simplest case, a set of uniform quantizers are used leading to lattice-based QIM watermarking. As illustrated in Fig.\\ref{QIM_traditional}, the basic QIM uses two quantizers $Q^0$ and $Q^1$ to implement the function, and each of them maps a value to the nearest point belonging to a class of predefined discontinuous points, one class ($\\Omega^0$) represents bit \u00a1\u00b00\u00a1\u00b1 while the other ($\\Omega^1$) represents bit \u00a1\u00b01\u00a1\u00b1 \\cite{SW_QIM_Q.li_07Trans}. The standard quantization operation with step-size $\\Delta$ is defined as\n\n", "index": 1, "text": "\\begin{equation}\\label{eq1}\n\n\\operatorname{Q}(x,\\Delta)=\\Delta \\cdot \\operatorname{round}(\\frac{x}{\\Delta})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\operatorname{Q}(x,\\Delta)=\\Delta\\cdot\\operatorname{round}(\\frac{x}{%&#10;\\Delta})\" display=\"block\"><mrow><mrow><mo>Q</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u22c5</mo><mrow><mo>round</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mfrac><mi>x</mi><mi mathvariant=\"normal\">\u0394</mi></mfrac><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\mathop{\\rm dist}\\nolimits} (\\tilde{y},\\Omega^m ) \\buildrel \\Delta \\over = \\mathop {\\min }\\limits_{s \\in \\Omega^m } \\left| {\\tilde{y} - s} \\right|$.\n\n\n\\subsection{QIM-Dither Modulation}\nDither modulation, proposed by Chen and Wornell \\cite{SW_QIM}, is an extension of the original QIM. Compared with the original QIM, it uses the pseudo-random dither signal, which can reduce quantization artifacts, to produce a perceptually superior quantized signal. Meanwhile, through the dither procedure, the quantization noise is independent from the host signal. The DM quantizer QDM is as following\n\n", "itemtype": "equation", "pos": 9623, "prevtext": "\nwhere the function round(.) denotes rounding a value to the nearest integer.\n\\par\nIn the embedding procedure, according to the message bit $m$, $Q^0$ or $Q^1$ is chosen to quantize the sample $x$ to the nearest quantization point $y$. For example, $Q^0$ and $Q^1$ may be chosen in such way that $Q^0$ quantizes x to even integers and $Q^1$ quantizes x to odd integers. If we wish to embed a \u00a1\u00b00\u00a1\u00b1 bit, then $Q^0$ is chosen, else $Q^1$.\n\\par\nIn the detecting procedure, it is reasonable to assume the marked signal $y$ is corrupted by the attacker, resulting in a noisy signal $\\tilde{y}$. The QIM detector is a minimum-distance decoder, which finds the quantization point closest to $\\tilde{y}$ and outputs the estimated message bit $\\tilde{m}$ \\cite{Data-HidingCodes}.\n\n", "index": 3, "text": "\\begin{equation}\\label{eq2}\n\n\\tilde{m}=\\operatorname*{argmin}\\limits_{m \\in \\mathbf{0,1}}\\operatorname{dist}(\\tilde{y},\\Omega^m)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\tilde{m}=\\operatorname*{argmin}\\limits_{m\\in\\mathbf{0,1}}\\operatorname{%&#10;dist}(\\tilde{y},\\Omega^{m})\" display=\"block\"><mrow><mover accent=\"true\"><mi>m</mi><mo stretchy=\"false\">~</mo></mover><mo>=</mo><mrow><mrow><munder><mo movablelimits=\"false\">argmin</mo><mrow><mi>m</mi><mo>\u2208</mo><mrow><mn/><mo>,</mo><mn>\ud835\udfcf</mn></mrow></mrow></munder><mo>\u2061</mo><mo>dist</mo></mrow><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><msup><mi mathvariant=\"normal\">\u03a9</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $y$ is the marked signal of $x$ by DM quantizer, $d^m$ is the dither signal corresponding to the message bit $m$.\n\n", "itemtype": "equation", "pos": 10366, "prevtext": "\nwhere ${\\mathop{\\rm dist}\\nolimits} (\\tilde{y},\\Omega^m ) \\buildrel \\Delta \\over = \\mathop {\\min }\\limits_{s \\in \\Omega^m } \\left| {\\tilde{y} - s} \\right|$.\n\n\n\\subsection{QIM-Dither Modulation}\nDither modulation, proposed by Chen and Wornell \\cite{SW_QIM}, is an extension of the original QIM. Compared with the original QIM, it uses the pseudo-random dither signal, which can reduce quantization artifacts, to produce a perceptually superior quantized signal. Meanwhile, through the dither procedure, the quantization noise is independent from the host signal. The DM quantizer QDM is as following\n\n", "index": 5, "text": "\\begin{equation}\\label{eq3}\n\ny=\\operatorname{QDM(x,\\Delta,d^m)}=\\operatorname{Q}(x+d^m,\\Delta)-d^m , m=0,1\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; y=\\operatorname{QDM(x,\\Delta,d^{m})}=\\operatorname{Q}(x+d^{m},\\Delta)-d^%&#10;{m},m=0,1\" display=\"block\"><mrow><mrow><mi>y</mi><mo>=</mo><mrow><mi>QDM</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">x</mi><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi mathvariant=\"normal\">d</mi><mi mathvariant=\"normal\">m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>Q</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>+</mo><msup><mi>d</mi><mi>m</mi></msup></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msup><mi>d</mi><mi>m</mi></msup></mrow></mrow><mo>,</mo><mrow><mi>m</mi><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $d^0$ is a pseudo-random signal and is usually chosen with a uniform distribution over $[-\\Delta/2,\\Delta/2]$.\n\\par\nIn the detecting procedure, the detector firstly applies the QDM quantizer \\eqref{eq3} to produce two signals $S^0$ and $S^1$, by embedding ``0\" and ``1\" into the received signal $\\tilde{y}$ respectively.\n\n", "itemtype": "equation", "pos": 10608, "prevtext": "\nwhere $y$ is the marked signal of $x$ by DM quantizer, $d^m$ is the dither signal corresponding to the message bit $m$.\n\n", "index": 7, "text": "\\begin{equation}\\label{eq4}\n\nd^1=d^0-\\operatorname{sign}(d^0)\\frac{\\Delta}{2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; d^{1}=d^{0}-\\operatorname{sign}(d^{0})\\frac{\\Delta}{2}\" display=\"block\"><mrow><msup><mi>d</mi><mn>1</mn></msup><mo>=</mo><mrow><msup><mi>d</mi><mn>0</mn></msup><mo>-</mo><mrow><mrow><mo>sign</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mn>0</mn></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2061</mo><mfrac><mi mathvariant=\"normal\">\u0394</mi><mn>2</mn></mfrac></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $d^m$ must be exactly the same as which in the embedding procedure. Note that the pseudo-random signal $d^0$ can be considered as a key to improve the security of the system, and in what follows, this secret signal is referenced as the dither factor, $df$.\n\\par\nThe detected message bit is then estimated by judging which of these two signals has the minimum Euclidean distance to the received signal $\\tilde{y}$, in the same manner as \\eqref{eq2}.\n\n", "itemtype": "equation", "pos": 11028, "prevtext": "\nwhere $d^0$ is a pseudo-random signal and is usually chosen with a uniform distribution over $[-\\Delta/2,\\Delta/2]$.\n\\par\nIn the detecting procedure, the detector firstly applies the QDM quantizer \\eqref{eq3} to produce two signals $S^0$ and $S^1$, by embedding ``0\" and ``1\" into the received signal $\\tilde{y}$ respectively.\n\n", "index": 9, "text": "\\begin{equation}\\label{eq5}\n\nS^m=\\operatorname{QDM}(\\tilde{y},\\Delta,d^m)=\\operatorname{Q}(\\tilde{y}+d^m,\\Delta)-d^m , m=0,1\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; S^{m}=\\operatorname{QDM}(\\tilde{y},\\Delta,d^{m})=\\operatorname{Q}(\\tilde%&#10;{y}+d^{m},\\Delta)-d^{m},m=0,1\" display=\"block\"><mrow><mrow><msup><mi>S</mi><mi>m</mi></msup><mo>=</mo><mrow><mo>QDM</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi>d</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo>Q</mo><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">~</mo></mover><mo>+</mo><msup><mi>d</mi><mi>m</mi></msup></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msup><mi>d</mi><mi>m</mi></msup></mrow></mrow><mo>,</mo><mrow><mi>m</mi><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\n\\subsection{QIM-Spread Transform Dither Modulation}\n\n\nAs an important extension of the original QIM, STDM applies the idea of projection modulation. It utilizes the DM quantizer to modulate the projection of the host vector along a given direction. This scheme combines the effectiveness of QIM and robustness of spread-spectrum system, and provides significant improvements compared with DM.\n\n\\begin{figure}[htb!]\n  \\centering\n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{QIM_STDM.eps}}\n  \\caption{Block diagram of spread transform dither modulation}\\label{QIM_STDM}\n\\end{figure}\nTo embed one message bit $m$, a host vector \\textbf{x}, consisting of samples to be embedded, is projected onto a random vector \\textbf{u} to get the projection $x_p$. Then, the projection $x_p$ is modulated according to the message bit $m$ using the DM quantizer \\eqref{eq3}. This procedure can be illustrated in Fig.\\ref{QIM_STDM}, and the watermarked vector \\textbf{g} is as follows,\n\n", "itemtype": "equation", "pos": 11623, "prevtext": "\nwhere $d^m$ must be exactly the same as which in the embedding procedure. Note that the pseudo-random signal $d^0$ can be considered as a key to improve the security of the system, and in what follows, this secret signal is referenced as the dither factor, $df$.\n\\par\nThe detected message bit is then estimated by judging which of these two signals has the minimum Euclidean distance to the received signal $\\tilde{y}$, in the same manner as \\eqref{eq2}.\n\n", "index": 11, "text": "\\begin{equation}\\label{eq6}\n\n\\tilde{m}=\\operatorname*{argmin}\\limits_{m \\in \\mathbf{0,1}}\\operatorname{dist}(\\tilde{y},S^m)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\tilde{m}=\\operatorname*{argmin}\\limits_{m\\in\\mathbf{0,1}}\\operatorname{%&#10;dist}(\\tilde{y},S^{m})\" display=\"block\"><mrow><mover accent=\"true\"><mi>m</mi><mo stretchy=\"false\">~</mo></mover><mo>=</mo><mrow><mrow><munder><mo movablelimits=\"false\">argmin</mo><mrow><mi>m</mi><mo>\u2208</mo><mrow><mn/><mo>,</mo><mn>\ud835\udfcf</mn></mrow></mrow></munder><mo>\u2061</mo><mo>dist</mo></mrow><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><msup><mi>S</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}) \\buildrel \\Delta \\over = \\frac{{\\left\\langle {{\\bf{x}},{\\bf{u}}} \\right\\rangle }}{{\\left\\| {\\bf{u}} \\right\\|_2 }}$, $\\left\\langle {{\\bf{x}},{\\bf{u}}} \\right\\rangle$ is the inner product of \\textbf{x} and \\textbf{u},\n$\\left\\| {\\; \\cdot \\;} \\right\\|_2$ denotes the $L^2$-norm operation. $\\Delta$ is the quantization step generated from a pseudo-random generator.\n\\par\nIn the detecting procedure, the detector projects the received vector ${\\bf{\\tilde g}}$ onto the random vector \\textbf{u}. And then, it utilizes the DM detector to estimate the message bit $\\tilde{m}$ from the projection, in the same manner as \\eqref{eq5} and \\eqref{eq6}. This can be expressed as follows,\n\n", "itemtype": "equation", "pos": 12740, "prevtext": "\n\n\n\\subsection{QIM-Spread Transform Dither Modulation}\n\n\nAs an important extension of the original QIM, STDM applies the idea of projection modulation. It utilizes the DM quantizer to modulate the projection of the host vector along a given direction. This scheme combines the effectiveness of QIM and robustness of spread-spectrum system, and provides significant improvements compared with DM.\n\n\\begin{figure}[htb!]\n  \\centering\n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{QIM_STDM.eps}}\n  \\caption{Block diagram of spread transform dither modulation}\\label{QIM_STDM}\n\\end{figure}\nTo embed one message bit $m$, a host vector \\textbf{x}, consisting of samples to be embedded, is projected onto a random vector \\textbf{u} to get the projection $x_p$. Then, the projection $x_p$ is modulated according to the message bit $m$ using the DM quantizer \\eqref{eq3}. This procedure can be illustrated in Fig.\\ref{QIM_STDM}, and the watermarked vector \\textbf{g} is as follows,\n\n", "index": 13, "text": "\\begin{equation}\\label{eq7}\n\n{\\bf{g}} = {\\bf{x}} + (\\frac{{{\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}),\\Delta ,d^m ) - {\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}})}}{{\\left\\| {\\bf{u}} \\right\\|_2 }}){\\bf{u}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}={\\bf{x}}+(\\frac{{{\\mathop{\\rm QDM}\\nolimits}({\\mathop{\\rm proj}%&#10;\\nolimits}({\\bf{x}},{\\bf{u}}),\\Delta,d^{m})-{\\mathop{\\rm proj}\\nolimits}({\\bf{%&#10;x}},{\\bf{u}})}}{{\\left\\|{\\bf{u}}\\right\\|_{2}}}){\\bf{u}}\" display=\"block\"><mrow><mi>\ud835\udc20</mi><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mfrac><mrow><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi>d</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><msub><mrow><mo>\u2225</mo><mi>\ud835\udc2e</mi><mo>\u2225</mo></mrow><mn>2</mn></msub></mfrac><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\ud835\udc2e</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nNote that, the random vector \\textbf{u} and the random positive real number $\\Delta$ used in the STDM detector must be exactly the same as they are in the embedder, and can be considered as two keys which are only known to the embedder and detector, thereby improving the security of the system.\n\n\\section{Multiple Watermarking Algorithm}\nBased on the algorithms mentioned above, we extend the spread transform dither modulation (STDM), a single watermarking algorithm, to the field of multiple watermarking application. The proposed multiple watermarking algorithm, namely STDM-Multiple Watermarking (STDM-MW), can embed multiple watermarks into the same area and the same transform domain of one image, meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference.\n\n\\subsection{Fundamental Idea }\nAs mentioned in section II, to embed a single message bit, $m$, STDM modulates the projection of the host vector $\\bf{x}$ along a given direction $\\bf{u}$. The modulated host vector $\\bf{g}$ can be expressed as follows,\n\n", "itemtype": "equation", "pos": 13729, "prevtext": "\nwhere ${\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}) \\buildrel \\Delta \\over = \\frac{{\\left\\langle {{\\bf{x}},{\\bf{u}}} \\right\\rangle }}{{\\left\\| {\\bf{u}} \\right\\|_2 }}$, $\\left\\langle {{\\bf{x}},{\\bf{u}}} \\right\\rangle$ is the inner product of \\textbf{x} and \\textbf{u},\n$\\left\\| {\\; \\cdot \\;} \\right\\|_2$ denotes the $L^2$-norm operation. $\\Delta$ is the quantization step generated from a pseudo-random generator.\n\\par\nIn the detecting procedure, the detector projects the received vector ${\\bf{\\tilde g}}$ onto the random vector \\textbf{u}. And then, it utilizes the DM detector to estimate the message bit $\\tilde{m}$ from the projection, in the same manner as \\eqref{eq5} and \\eqref{eq6}. This can be expressed as follows,\n\n", "index": 15, "text": "\\begin{equation}\\label{eq8}\n\n\\tilde m = \\mathop {\\arg \\min }\\limits_{m \\in \\{ 0,1\\} } {\\mathop{\\rm dist}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{\\tilde g}},{\\bf{u}}),{\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{\\tilde g}},{\\bf{u}}),\\Delta ,d^m )\\;)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\tilde{m}=\\mathop{\\arg\\min}\\limits_{m\\in\\{0,1\\}}{\\mathop{\\rm dist}%&#10;\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{\\tilde{g}}},{\\bf{u}}),{\\mathop{%&#10;\\rm QDM}\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{\\tilde{g}}},{\\bf{u}}),%&#10;\\Delta,d^{m})\\;)\" display=\"block\"><mrow><mover accent=\"true\"><mi>m</mi><mo stretchy=\"false\">~</mo></mover><mo>=</mo><mrow><munder><mrow><mi>arg</mi><mo movablelimits=\"false\">\u2061</mo><mi>min</mi></mrow><mrow><mi>m</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mrow><mo>dist</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>\ud835\udc20</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>\ud835\udc20</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi>d</mi><mi>m</mi></msup><mo rspace=\"5.3pt\" stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nTo detect the message bit, the detector projects the modulated vector $\\bf{g}$ onto the given direction $\\bf{u}$. And then, it utilizes the DM detector to estimate the message bit from the projection. This detection mechanism induces the vector $\\bf{g}$ must be subject to\n\n", "itemtype": "equation", "pos": 15095, "prevtext": "\nNote that, the random vector \\textbf{u} and the random positive real number $\\Delta$ used in the STDM detector must be exactly the same as they are in the embedder, and can be considered as two keys which are only known to the embedder and detector, thereby improving the security of the system.\n\n\\section{Multiple Watermarking Algorithm}\nBased on the algorithms mentioned above, we extend the spread transform dither modulation (STDM), a single watermarking algorithm, to the field of multiple watermarking application. The proposed multiple watermarking algorithm, namely STDM-Multiple Watermarking (STDM-MW), can embed multiple watermarks into the same area and the same transform domain of one image, meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference.\n\n\\subsection{Fundamental Idea }\nAs mentioned in section II, to embed a single message bit, $m$, STDM modulates the projection of the host vector $\\bf{x}$ along a given direction $\\bf{u}$. The modulated host vector $\\bf{g}$ can be expressed as follows,\n\n", "index": 17, "text": "\\begin{equation}\\label{eq11}\n\n{\\bf{g}} = {\\bf{x}} + k{\\bf{u}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}={\\bf{x}}+k{\\bf{u}}\" display=\"block\"><mrow><mi>\ud835\udc20</mi><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><mi>k</mi><mo>\u2062</mo><mi>\ud835\udc2e</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nThus, the embedding procedure is actually to derive the scaling factor $k$ used in \\eqref{eq11} to make the modulated vector $\\bf{g}$ in the form of \\eqref{eq12}. Substituting \\eqref{eq11} into \\eqref{eq12}, the scaling factor $k$ can be given by\n\n", "itemtype": "equation", "pos": 15450, "prevtext": "\n\\par\nTo detect the message bit, the detector projects the modulated vector $\\bf{g}$ onto the given direction $\\bf{u}$. And then, it utilizes the DM detector to estimate the message bit from the projection. This detection mechanism induces the vector $\\bf{g}$ must be subject to\n\n", "index": 19, "text": "\\begin{equation}\\label{eq12}\n\n{\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}) = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}),\\Delta ,d^m )\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}})={\\mathop{\\rm QDM}%&#10;\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{x}},{\\bf{u}}),\\Delta,d^{m})\" display=\"block\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi>d</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nInspired by this, to embed multiple message bits, $m_1$, $m_2$,..., $m_n$, into the same host vector $\\bf{x}$, we can modulate the projection of the host vector $\\bf{x}$ along different given directions, $\\bf{u}_1$, $\\bf{u}_2$,..., $\\bf{u}_n$. The modulated host vector $\\bf{g}$ can be expressed as follows\n\n", "itemtype": "equation", "pos": 15890, "prevtext": "\n\\par\nThus, the embedding procedure is actually to derive the scaling factor $k$ used in \\eqref{eq11} to make the modulated vector $\\bf{g}$ in the form of \\eqref{eq12}. Substituting \\eqref{eq11} into \\eqref{eq12}, the scaling factor $k$ can be given by\n\n", "index": 21, "text": "\\begin{equation}\\label{eq13}\n\nk  = \\frac{{{\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}),\\Delta ,d^m ) - {\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}})}}{{\\left\\| {\\bf{u}} \\right\\|_2 }}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; k=\\frac{{{\\mathop{\\rm QDM}\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{x%&#10;}},{\\bf{u}}),\\Delta,d^{m})-{\\mathop{\\rm proj}\\nolimits}({\\bf{x}},{\\bf{u}})}}{{%&#10;\\left\\|{\\bf{u}}\\right\\|_{2}}}\" display=\"block\"><mrow><mi>k</mi><mo>=</mo><mfrac><mrow><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msup><mi>d</mi><mi>m</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><mi>\ud835\udc2e</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><msub><mrow><mo>\u2225</mo><mi>\ud835\udc2e</mi><mo>\u2225</mo></mrow><mn>2</mn></msub></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\bf{U}} = [{\\bf{u}}_1 ,{\\bf{u}}_2 ,...,{\\bf{u}}_n ]$, ${\\bf{K}} = [k_1 ,k_2 ,...,k_n ]^T$.\n\n\n\n\n\\par\nTo detect the message bits, the modulated vector $\\bf{g}$ is projected onto the given directions, $\\bf{u}_1$, $\\bf{u}_2$,..., $\\bf{u}_n$, respectively. And then, the DM detector is used to estimate each message bit from the corresponding projection. Thus, in the same manner as \\eqref{eq12}, the modulated vector $\\bf{g}$ must be subject to the following equation,\n\n\n", "itemtype": "equation", "pos": 16436, "prevtext": "\n\\par\nInspired by this, to embed multiple message bits, $m_1$, $m_2$,..., $m_n$, into the same host vector $\\bf{x}$, we can modulate the projection of the host vector $\\bf{x}$ along different given directions, $\\bf{u}_1$, $\\bf{u}_2$,..., $\\bf{u}_n$. The modulated host vector $\\bf{g}$ can be expressed as follows\n\n", "index": 23, "text": "\\begin{equation}\\label{eq14}\n\n\n\\;{\\bf{g}} = {\\bf{x}} + {\\bf{U}}{\\bf{K}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\par&#10;\\;{\\bf{g}}={\\bf{x}}+{\\bf{U}}{\\bf{K}}\" display=\"block\"><mrow><mpadded lspace=\"2.8pt\" width=\"+2.8pt\"><mi>\ud835\udc20</mi></mpadded><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mi>\ud835\udc14\ud835\udc0a</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $d_{j}^{m_j}$ is the dither signal in the direction ${\\bf{u}_j}$ corresponding to the message bit $m_j$.\n\\par\nBy substituting \\eqref{eq14} into \\eqref{eq15}, n equations can be obtained. These are expressed as follows in the matrix form,\n\n", "itemtype": "equation", "pos": 16997, "prevtext": "\nwhere ${\\bf{U}} = [{\\bf{u}}_1 ,{\\bf{u}}_2 ,...,{\\bf{u}}_n ]$, ${\\bf{K}} = [k_1 ,k_2 ,...,k_n ]^T$.\n\n\n\n\n\\par\nTo detect the message bits, the modulated vector $\\bf{g}$ is projected onto the given directions, $\\bf{u}_1$, $\\bf{u}_2$,..., $\\bf{u}_n$, respectively. And then, the DM detector is used to estimate each message bit from the corresponding projection. Thus, in the same manner as \\eqref{eq12}, the modulated vector $\\bf{g}$ must be subject to the following equation,\n\n\n", "index": 25, "text": "\\begin{equation}\\label{eq15}\n\n\\begin{array}{l}\n \\left\\{ \\begin{array}{l}\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_1 ) = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_1 ),\\Delta_1 ,d_{1}^{m_1} ) \\\\\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_2 ) = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_2 ),\\Delta_2 ,d_{2}^{m_2} ) \\\\\n .........\\;......... \\\\\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_n ) = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_n ),\\Delta_n ,d_{n}^{m_n} ) \\\\\n \\end{array} \\right. \\\\\n  \\\\\n \\end{array}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\begin{array}[]{l}\\left\\{\\begin{array}[]{l}{\\mathop{\\rm proj}\\nolimits}({%&#10;\\bf{g}},{\\bf{u}}_{1})={\\mathop{\\rm QDM}\\nolimits}({\\mathop{\\rm proj}\\nolimits}%&#10;({\\bf{x}},{\\bf{u}}_{1}),\\Delta_{1},d_{1}^{m_{1}})\\\\&#10;{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}}_{2})={\\mathop{\\rm QDM}\\nolimits%&#10;}({\\mathop{\\rm proj}\\nolimits}({\\bf{x}},{\\bf{u}}_{2}),\\Delta_{2},d_{2}^{m_{2}}%&#10;)\\\\&#10;.........\\;.........\\\\&#10;{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}}_{n})={\\mathop{\\rm QDM}\\nolimits%&#10;}({\\mathop{\\rm proj}\\nolimits}({\\bf{x}},{\\bf{u}}_{n}),\\Delta_{n},d_{n}^{m_{n}}%&#10;)\\\\&#10;\\end{array}\\right.\\\\&#10;\\\\&#10;\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mn>1</mn></msub><mo>,</mo><msubsup><mi>d</mi><mn>1</mn><msub><mi>m</mi><mn>1</mn></msub></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mn>2</mn></msub><mo>,</mo><msubsup><mi>d</mi><mn>2</mn><msub><mi>m</mi><mn>2</mn></msub></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mpadded width=\"+2.8pt\"><mi mathvariant=\"normal\">\u2026</mi></mpadded><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u2026</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>n</mi></msub><mo>,</mo><msubsup><mi>d</mi><mi>n</mi><msub><mi>m</mi><mi>n</mi></msub></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr></mtable><mi/></mrow></mtd></mtr><mtr><mtd/></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere\n\\par\n$\\begin{array}{l}\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{U}}_{\\bf{I}}  = \\Lambda _U {\\bf{U}^T}{\\bf{U}} ,\\;\\Lambda _U  = [\\frac{1}{{\\left\\| {{\\bf{u}}_1 } \\right\\|}},\\frac{1}{{\\left\\| {{\\bf{u}}_2 } \\right\\|}},...,\\frac{1}{{\\left\\| {{\\bf{u}}_n } \\right\\|}}] \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{P}} = [{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_1 ),{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_2 ),...,{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_n )]^T  \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{QDMV}} = [QDMV_1 ,QDMV_2 ,...,QDMV_n ]^T  \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;QDMV_j  = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_j ),\\Delta_j ,d_{j}^{m_j} )\\\\\n \\end{array}$\n \\par\n $\\;$\n \\par\n From \\eqref{eq16}, the scaling factor sequence $\\bf{K}$ can be calculated by\n\n", "itemtype": "equation", "pos": 17885, "prevtext": "\nwhere $d_{j}^{m_j}$ is the dither signal in the direction ${\\bf{u}_j}$ corresponding to the message bit $m_j$.\n\\par\nBy substituting \\eqref{eq14} into \\eqref{eq15}, n equations can be obtained. These are expressed as follows in the matrix form,\n\n", "index": 27, "text": "\\begin{equation}\\label{eq16}\n\n{\\bf{U}}_{\\bf{I}} {\\bf{K}} = {\\bf{QDMV}}-{\\bf{P}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{U}}_{\\bf{I}}{\\bf{K}}={\\bf{QDMV}}-{\\bf{P}}\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc14</mi><mi>\ud835\udc08</mi></msub><mo>\u2062</mo><mi>\ud835\udc0a</mi></mrow><mo>=</mo><mrow><mi>\ud835\udc10\ud835\udc03\ud835\udc0c\ud835\udc15</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nFinally, according to \\eqref{eq14}, the watermarked host vector $\\bf{g}$ which carries $n$ message bits can be generated. Note that, to make \\eqref{eq17} tenable, the length of the host vector $\\bf{x}$, namely $L$, must be no less than the number of embedded message bits, $n$, i.e., $L \\ge n$, (see Appendix A).\n\\par\nIn the detecting procedure, we can apply the STDM detector \\eqref{eq8} to estimate every single bit $\\widetilde m_j$ from the projection of the received vector ${\\bf{\\tilde g}}$ along the corresponding direction ${\\bf{u}}_j$, independently. This can be expressed as follows,\n\n\n", "itemtype": "equation", "pos": 18763, "prevtext": "\nwhere\n\\par\n$\\begin{array}{l}\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{U}}_{\\bf{I}}  = \\Lambda _U {\\bf{U}^T}{\\bf{U}} ,\\;\\Lambda _U  = [\\frac{1}{{\\left\\| {{\\bf{u}}_1 } \\right\\|}},\\frac{1}{{\\left\\| {{\\bf{u}}_2 } \\right\\|}},...,\\frac{1}{{\\left\\| {{\\bf{u}}_n } \\right\\|}}] \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{P}} = [{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_1 ),{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_2 ),...,{\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_n )]^T  \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{QDMV}} = [QDMV_1 ,QDMV_2 ,...,QDMV_n ]^T  \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;QDMV_j  = {\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{x}},{\\bf{u}}_j ),\\Delta_j ,d_{j}^{m_j} )\\\\\n \\end{array}$\n \\par\n $\\;$\n \\par\n From \\eqref{eq16}, the scaling factor sequence $\\bf{K}$ can be calculated by\n\n", "index": 29, "text": "\\begin{equation}\\label{eq17}\n\n{\\bf{K}} = {\\bf{U}}_{_{\\bf{I}} }^{^{ - 1} } ({\\bf{QDMV}} - {\\bf{P}})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{K}}={\\bf{U}}_{{}_{\\bf{I}}}^{{}^{-1}}({\\bf{QDMV}}-{\\bf{P}})\" display=\"block\"><mrow><mi>\ud835\udc0a</mi><mo>=</mo><mrow><msubsup><mi>\ud835\udc14</mi><msub><mi/><mi>\ud835\udc08</mi></msub><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc10\ud835\udc03\ud835\udc0c\ud835\udc15</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\n\\subsection{Detailed Implementation }\nAs illustrated in Fig.\\ref{STDM_mutiple} and Fig.\\ref{STDM_mutiple_detector}, the proposed scheme, STDM-MW, consists of two parts, the embedder (Fig.\\ref{STDM_mutiple}) and the detector (Fig.\\ref{STDM_mutiple_detector}). In this scheme, each user is given three secret keys, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, to implement watermark embedding and detecting. It is assumed that there are $n$ users and the watermark sequence of the $j^{th}$ user is $\\bf{w}_j$, ${\\bf{w}_j} = [w_{j1} ,w_{j2} ,...,w_{jN} ]$, with length $N$.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.9}{\\includegraphics[width=\\textwidth]{STDM_mutiple_embedder.eps}}\n  \\caption{Block diagram of STDM-Multiple Watermarking embedder}\\label{STDM_mutiple}\n\\end{center}\n\\end{figure*}\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.7}{\\includegraphics[width=\\textwidth]{STDM_mutiple_detector.eps}}\n  \\caption{Block diagram of STDM-Multiple Watermarking detector for the $j^{th}$ user}\\label{STDM_mutiple_detector}\n\\end{center}\n\\end{figure*}\n\n\\par\nThe embedding procedure is as follows,\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(a) Divide the image into disjoint $8 \\times 8$ blocks of pixels, and perform DCT transform to each block to gain its DCT coefficients. A part of these coefficients will be selected to form a single vector, denoted as the host vector ${\\bf{x}}_i(i=1,2,...,N)$, ${\\bf{x}}_i = [x_1 ,x_2 ,...,x_L ]$, with length L. As illustrated in Fig.\\ref{parameter_arrangement}, each host vector ${\\bf{x}}_i$ is used to embed one bit sequence $[w_{1i},w_{2i},...,w_{ni}]$, the $j^{th}$ element of which is corresponding to the $j^{th}$ user's $i^{th}$ bit.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(b) Use the secret keys, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, of each user to generate the step sizes $\\Delta_{ji}$, the random projective vectors ${\\bf{u}}_{ji}$ and the dither factors $df_{ji}$ for each host vector ${\\bf{x}}_i$, respectively. According to the message bit $w_{ji}$, the final dither signal $d_{ji}^{w_{ji}}$ can be generated using $df_{ji}$.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(c) Embed each bit sequence $[w_{1i},w_{2i},...,w_{ni}]$ by modulating each host vector ${\\bf{x}}_i$ into ${\\bf{g}}_i$ using the method mentioned in III-A , based on the parameters, $[{\\bf{u}}_{1i},{\\bf{u}}_{2i},...,{\\bf{u}}_{ni}]$, $[d_{1i}^{w_{1i}},d_{2i}^{w_{2i}},...,d_{ni}^{w_{ni}}]$, $[\\Delta _{1i},\\Delta _{2i},...,\\Delta _{ni}]$, calculated in step (b). Finally, transform the modified coefficients back to form the watermarked image.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.4}{\\includegraphics[width=\\textwidth]{parameter_arrangement.eps}}\n  \\caption{Parameters arrangement, the arrangement for projective vector ${\\bf{u}}$, dither factor $df$ and step size $\\Delta$ is the same as it is for watermark $w$.}\\label{parameter_arrangement}\n\\end{center}\n\\end{figure}\n\n\\par\nDuring the transmission, the watermarked image may sustain certain attacks, intentional or unintentional, and become a distorted image at the receiver. Each user can use his own secret keys to detect his own watermark independently.\n\\par\nThe detecting procedure of the $j^{th}$ user is as follows\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(a) Form each host vector ${\\bf{\\tilde g}}_i$ of the received image in the same manner as step (a) in the embedding procedure.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(b) use the secret keys, $STEP\\_KEY_j$, $U\\_KEY_j$ and $Dither\\_KEY_j$, of the $j^{th}$ user to generate the step sizes $[\\Delta_{j1},\\Delta_{j2},...,\\Delta_{jN}]$, the random projective vectors $[{\\bf{u}}_{j1},{\\bf{u}}_{j2},...,{\\bf{u}}_{jN}]$ and the dither factors $[df_{j1},df_{j2},...,df_{jN}]$, respectively.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(c) Use the STDM detector to detect every bit $\\tilde{w}_{ji}$ from each host vector ${\\bf{\\tilde x}}_i$, based on the parameters, ${\\bf{u}}_{ji}$, $df_{ji}$ and $\\Delta _{ji}$.\n\nNote that, with an eye to the robustness of STDM-MW against valumetric scaling, the step-size $\\Delta$ should be multiplied by the mean intensity of the whole image.\n\n\n\\section{Analysis of STDM-Multiple Watermarking}\nThrough experiment, it is found that along with the increase of the number of watermarks embedded, the quality of the images declines in vary degrees. To address this issue, further analysis of the embedding strategy of STDM-Multiple Watermarking is demanded.\n\\par\nAs is widely known, in the case of Imperceptible $\\&$ Robust watermarking, owning the same robustness, the more imperceptible, the more effective the algorithm is. In most cases, the imperceptibility of the watermark, in other words the fidelity of the watermarked image, is measured in PSNR, which varies inversely with the mean squared error, MSE. Referencing Appendix B, we have\n\n", "itemtype": "equation", "pos": 19476, "prevtext": "\n\\par\nFinally, according to \\eqref{eq14}, the watermarked host vector $\\bf{g}$ which carries $n$ message bits can be generated. Note that, to make \\eqref{eq17} tenable, the length of the host vector $\\bf{x}$, namely $L$, must be no less than the number of embedded message bits, $n$, i.e., $L \\ge n$, (see Appendix A).\n\\par\nIn the detecting procedure, we can apply the STDM detector \\eqref{eq8} to estimate every single bit $\\widetilde m_j$ from the projection of the received vector ${\\bf{\\tilde g}}$ along the corresponding direction ${\\bf{u}}_j$, independently. This can be expressed as follows,\n\n\n", "index": 31, "text": "\\begin{equation}\\label{eq18}\n\n\\begin{array}{l}\n\\widetilde m_j  = \\mathop {\\arg \\min }\\limits_{m_j \\in \\{ 0,1\\} } {\\mathop{\\rm dist}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{\\tilde g}},{\\bf{u}}_j ),{\\mathop{\\rm QDM}\\nolimits} ({\\mathop{\\rm proj}\\nolimits} ({\\bf{\\tilde g}},{\\bf{u}}_j ),\\Delta _j ,d_{j}^{m_j} ),\\\\\n\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;j=1,2,...,n\n\\end{array}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\begin{array}[]{l}\\widetilde{m}_{j}=\\mathop{\\arg\\min}\\limits_{m_{j}\\in\\{0%&#10;,1\\}}{\\mathop{\\rm dist}\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{\\tilde{g}}%&#10;},{\\bf{u}}_{j}),{\\mathop{\\rm QDM}\\nolimits}({\\mathop{\\rm proj}\\nolimits}({\\bf{%&#10;\\tilde{g}}},{\\bf{u}}_{j}),\\Delta_{j},d_{j}^{m_{j}}),\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;%&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;j=1,2,...,n\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mover accent=\"true\"><mi>m</mi><mo>~</mo></mover><mi>j</mi></msub><mo>=</mo><munder><mrow><mi>arg</mi><mo movablelimits=\"false\">\u2061</mo><mi>min</mi></mrow><mrow><msub><mi>m</mi><mi>j</mi></msub><mo>\u2208</mo><mrow><mo stretchy=\"false\">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mo>dist</mo><mrow><mo stretchy=\"false\">(</mo><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>\ud835\udc20</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><msub><mi>\ud835\udc2e</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mo>QDM</mo><mrow><mo stretchy=\"false\">(</mo><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>\ud835\udc20</mi><mo stretchy=\"false\">~</mo></mover><mo>,</mo><msub><mi>\ud835\udc2e</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>j</mi></msub><mo>,</mo><msubsup><mi>d</mi><mi>j</mi><msub><mi>m</mi><mi>j</mi></msub></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mpadded lspace=\"173.6pt\" width=\"+173.6pt\"><mi>j</mi></mpadded><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>n</mi></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $\\bf{C}$ and $\\bf{C}'$ are the DCT coefficient vectors of the original image and the watermarked one.\n\\par\nThus, under the PSNR measurement, the smaller the Euclidian distance between the watermarked coefficient and the original one is, the higher the fidelity of the watermarked image will be. According to this idea, to improve the fidelity of the watermarked image, we need to produce the watermarked vector that is closest to the host vector.\n\\par\nAt the very beginning, as the embedding procedure of STDM-Multiple Watermarking is based on Dither Modulation, it is appropriate to investigate the DM quantizer in a deeper way.\n\n\\par\n\n\\subsection{Dither Modulation Based Single Watermarking }\nFrom section II-B, to embed one message bit $m$, the original DM quantizer, QDM, quantizes the point $x$ to ($\\Delta round(\\frac{{x + d^m }}{\\Delta }) - d^m$). However, ignoring the imperceptible constraint (minimum Euclidian distance), we can quantize the point $x$ to any point $b_i$, $b_i \\in {\\bf{B}}$.\n\n", "itemtype": "equation", "pos": 24812, "prevtext": "\n\n\n\\subsection{Detailed Implementation }\nAs illustrated in Fig.\\ref{STDM_mutiple} and Fig.\\ref{STDM_mutiple_detector}, the proposed scheme, STDM-MW, consists of two parts, the embedder (Fig.\\ref{STDM_mutiple}) and the detector (Fig.\\ref{STDM_mutiple_detector}). In this scheme, each user is given three secret keys, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, to implement watermark embedding and detecting. It is assumed that there are $n$ users and the watermark sequence of the $j^{th}$ user is $\\bf{w}_j$, ${\\bf{w}_j} = [w_{j1} ,w_{j2} ,...,w_{jN} ]$, with length $N$.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.9}{\\includegraphics[width=\\textwidth]{STDM_mutiple_embedder.eps}}\n  \\caption{Block diagram of STDM-Multiple Watermarking embedder}\\label{STDM_mutiple}\n\\end{center}\n\\end{figure*}\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.7}{\\includegraphics[width=\\textwidth]{STDM_mutiple_detector.eps}}\n  \\caption{Block diagram of STDM-Multiple Watermarking detector for the $j^{th}$ user}\\label{STDM_mutiple_detector}\n\\end{center}\n\\end{figure*}\n\n\\par\nThe embedding procedure is as follows,\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(a) Divide the image into disjoint $8 \\times 8$ blocks of pixels, and perform DCT transform to each block to gain its DCT coefficients. A part of these coefficients will be selected to form a single vector, denoted as the host vector ${\\bf{x}}_i(i=1,2,...,N)$, ${\\bf{x}}_i = [x_1 ,x_2 ,...,x_L ]$, with length L. As illustrated in Fig.\\ref{parameter_arrangement}, each host vector ${\\bf{x}}_i$ is used to embed one bit sequence $[w_{1i},w_{2i},...,w_{ni}]$, the $j^{th}$ element of which is corresponding to the $j^{th}$ user's $i^{th}$ bit.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(b) Use the secret keys, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, of each user to generate the step sizes $\\Delta_{ji}$, the random projective vectors ${\\bf{u}}_{ji}$ and the dither factors $df_{ji}$ for each host vector ${\\bf{x}}_i$, respectively. According to the message bit $w_{ji}$, the final dither signal $d_{ji}^{w_{ji}}$ can be generated using $df_{ji}$.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(c) Embed each bit sequence $[w_{1i},w_{2i},...,w_{ni}]$ by modulating each host vector ${\\bf{x}}_i$ into ${\\bf{g}}_i$ using the method mentioned in III-A , based on the parameters, $[{\\bf{u}}_{1i},{\\bf{u}}_{2i},...,{\\bf{u}}_{ni}]$, $[d_{1i}^{w_{1i}},d_{2i}^{w_{2i}},...,d_{ni}^{w_{ni}}]$, $[\\Delta _{1i},\\Delta _{2i},...,\\Delta _{ni}]$, calculated in step (b). Finally, transform the modified coefficients back to form the watermarked image.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.4}{\\includegraphics[width=\\textwidth]{parameter_arrangement.eps}}\n  \\caption{Parameters arrangement, the arrangement for projective vector ${\\bf{u}}$, dither factor $df$ and step size $\\Delta$ is the same as it is for watermark $w$.}\\label{parameter_arrangement}\n\\end{center}\n\\end{figure}\n\n\\par\nDuring the transmission, the watermarked image may sustain certain attacks, intentional or unintentional, and become a distorted image at the receiver. Each user can use his own secret keys to detect his own watermark independently.\n\\par\nThe detecting procedure of the $j^{th}$ user is as follows\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(a) Form each host vector ${\\bf{\\tilde g}}_i$ of the received image in the same manner as step (a) in the embedding procedure.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(b) use the secret keys, $STEP\\_KEY_j$, $U\\_KEY_j$ and $Dither\\_KEY_j$, of the $j^{th}$ user to generate the step sizes $[\\Delta_{j1},\\Delta_{j2},...,\\Delta_{jN}]$, the random projective vectors $[{\\bf{u}}_{j1},{\\bf{u}}_{j2},...,{\\bf{u}}_{jN}]$ and the dither factors $[df_{j1},df_{j2},...,df_{jN}]$, respectively.\n\\par\n\\hangafter=1\\hangindent=1.5em\\noindent\n(c) Use the STDM detector to detect every bit $\\tilde{w}_{ji}$ from each host vector ${\\bf{\\tilde x}}_i$, based on the parameters, ${\\bf{u}}_{ji}$, $df_{ji}$ and $\\Delta _{ji}$.\n\nNote that, with an eye to the robustness of STDM-MW against valumetric scaling, the step-size $\\Delta$ should be multiplied by the mean intensity of the whole image.\n\n\n\\section{Analysis of STDM-Multiple Watermarking}\nThrough experiment, it is found that along with the increase of the number of watermarks embedded, the quality of the images declines in vary degrees. To address this issue, further analysis of the embedding strategy of STDM-Multiple Watermarking is demanded.\n\\par\nAs is widely known, in the case of Imperceptible $\\&$ Robust watermarking, owning the same robustness, the more imperceptible, the more effective the algorithm is. In most cases, the imperceptibility of the watermark, in other words the fidelity of the watermarked image, is measured in PSNR, which varies inversely with the mean squared error, MSE. Referencing Appendix B, we have\n\n", "index": 33, "text": "\\begin{equation}\\label{eq19}\n\nMSE \\propto \\left\\| {\\bf{C'} - \\bf{C}} \\right\\|_2\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; MSE\\propto\\left\\|{\\bf{C^{\\prime}}-\\bf{C}}\\right\\|_{2}\" display=\"block\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>\u221d</mo><msub><mrow><mo>\u2225</mo><mrow><msup><mi>\ud835\udc02</mi><mo>\u2032</mo></msup><mo>-</mo><mi>\ud835\udc02</mi></mrow><mo>\u2225</mo></mrow><mn>2</mn></msub></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nDefinitely, any points in ${\\bf{B}}$ have the same detection robustness according to the DM detection mechanism, \\eqref{eq5} and \\eqref{eq6}. In what follows, this kind of points are defined as the DM quantization points of point $x$.\n\\par\n\nAs illustrated in Fig.\\ref{DM_embedder}, in the case of DM single watermarking, it is optimal to use \\eqref{eq3}, which is equivalent to $\\beta=round(\\frac{{x + d^m }}{\\Delta })$ in \\eqref{eq20}, to choose the final quantization point, because the selected one is the closest point to $x$ among all the DM quantization points of $x$,(i.e., points in $B$).\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{DM_embedder.eps}}\n  \\caption{Utilizing DM to embed one message bit $m$ into point $x$, where the set of circles represents quantization points in $B$, (assuming $d^m>0$). Dotted-lines, $L=\\{l|l=((2\\alpha  + 1)\\frac{\\Delta }{2} - d^m,\\;\\alpha \\in Z\\}$, denote the median point between two adjacent quantization points.}\\label{DM_embedder}\n\\end{center}\n\\end{figure}\n\n\n\\par\nInspired by this idea, in the original STDM, as illustrated in Fig.\\ref{STDM_embedder_explain}, we can modulate the host vector $\\bf{x}$ to any vector (${\\bf{g}}''$,${\\bf{g}}'$,${\\bf{g}}$), whose projection point is the DM quantization point of the host vector's projection point $p$.\n\\par\nHowever, the imperceptible constraint must be considered. Referencing \\eqref{eq11}, the Euclidian distance $dis\\_v$ between the watermarked vector $\\bf{g}$ and the host vector $\\bf{x}$, is proportional to $k$, which is actually the distance $dis\\_p$ between the host vector's projection point $p$ and $p$'s DM quantization point. This can be formulated as follows,\n\n", "itemtype": "equation", "pos": 25915, "prevtext": "\nwhere $\\bf{C}$ and $\\bf{C}'$ are the DCT coefficient vectors of the original image and the watermarked one.\n\\par\nThus, under the PSNR measurement, the smaller the Euclidian distance between the watermarked coefficient and the original one is, the higher the fidelity of the watermarked image will be. According to this idea, to improve the fidelity of the watermarked image, we need to produce the watermarked vector that is closest to the host vector.\n\\par\nAt the very beginning, as the embedding procedure of STDM-Multiple Watermarking is based on Dither Modulation, it is appropriate to investigate the DM quantizer in a deeper way.\n\n\\par\n\n\\subsection{Dither Modulation Based Single Watermarking }\nFrom section II-B, to embed one message bit $m$, the original DM quantizer, QDM, quantizes the point $x$ to ($\\Delta round(\\frac{{x + d^m }}{\\Delta }) - d^m$). However, ignoring the imperceptible constraint (minimum Euclidian distance), we can quantize the point $x$ to any point $b_i$, $b_i \\in {\\bf{B}}$.\n\n", "index": 35, "text": "\\begin{equation}\\label{eq20}\n\n{\\bf{B}} = \\{ b|b = \\beta \\Delta  - d^m ,\\;\\beta  \\in Z\\}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{B}}=\\{b|b=\\beta\\Delta-d^{m},\\;\\beta\\in Z\\}\" display=\"block\"><mrow><mi>\ud835\udc01</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mi>b</mi><mo stretchy=\"false\">|</mo><mrow><mrow><mi>b</mi><mo>=</mo><mrow><mrow><mi>\u03b2</mi><mo>\u2062</mo><mi mathvariant=\"normal\">\u0394</mi></mrow><mo>-</mo><msup><mi>d</mi><mi>m</mi></msup></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mi>\u03b2</mi><mo>\u2208</mo><mi>Z</mi></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\\par\nAs DM quantizer \\eqref{eq3} can generate the quantization point that is closest to the original point, it can find the closest DM quantization point to the host vector's projection point, i.e., the DM quantizer can make $dis\\_p$ minimum. Thus, it is optimal to use DM quantizer to modulate the host vector $\\bf{x}$ to vector $\\bf{g}$ by \\eqref{eq7}. In this way, the minimum $dis\\_v$ can be guaranteed.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_embedder_explain.eps}}\n  \\caption{Utilizing STDM to embed one message bit $m$ into one host vector $\\bf{x}$, where $\\bf{u}$ is the projective vector and $\\bf{g}$ is the watermarked vector. The set of circles represents the DM quantization points of the projection point $p$ of the host vector $\\bf{x}$ along the direction $\\bf{u}$.}\\label{STDM_embedder_explain}\n\\end{center}\n\\end{figure}\n\n\\subsection{Embedding Strategy of STDM-Multiple Watermarking}\nAs mentioned above, DM quantizer is optimal for STDM in the case of single watermarking. Unfortunately, it seems that this strategy is not optimal in the case of multiple watermarking.\n\\par\nAs mentioned in III-A, in the case of multiple watermarking, if $n$ message bits are embedded, the host vector $\\bf{x}$ must be modulated along $n$ given directions to form the watermarked vector $\\bf{g}$. For each direction, the projection of the watermarked vector $\\bf{g}$ must be the closet DM quantization point to the host vector $\\bf{x}$'s projection point.\n\n\\par\nAs illustrated in Fig.\\ref{un_optimal}, it is a simple example for two users, that is embedding two bits into the host vector $\\bf{x}$. To do this, host vector $\\bf{x}$ must be projected along the projective vectors $\\bf{u}_1$ and $\\bf{u}_2$ to gain the projection points $p_1$ and $p_2$, respectively. And then, points $p_1$ and $p_2$ are quantized into their closet DM quantization points, $Q_1$ and $Q_2$, respectively. Finally, host vector $\\bf{x}$ is modulated into vector $\\bf{G}_1$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{un_optimal.eps}}\n  \\caption{Utilizing the original embedding strategy STDM-MW to embed two message bits into one host vector $\\bf{x}$, where $\\bf{u}_1$ and $\\bf{u}_2$ are the two projective vectors denoting the quantization directions. $p_1$ and $p_2$ are the projection points of $\\bf{x}$ along $\\bf{u}_1$ and $\\bf{u}_2$, respectively. The circles along $\\bf{u}_1$ and $\\bf{u}_2$ denote the DM quantization points, belonging to the point set ${\\bf{B}}_1$ and ${\\bf{B}}_2$,respectively. ${\\bf{B}}_j=\\{ b|b =\\beta_j \\Delta_j  - d_j^{m_j} ,\\;\\beta_j  \\in Z \\}$. }\\label{un_optimal}\n\\end{center}\n\\end{figure}\n\n\\par\nHowever, this original embedding strategy, using the closest DM quantization point as the final quantization point of the projection point, can not product the closet watermarked vector to the host vector. Actually, vectors $\\bf{G}_1$, $\\bf{G}_2$, $\\bf{G}_3$ and $\\bf{G}_4$ can all be selected as the watermarked vector of the host vector $\\bf{x}$ while owning the same detection robustness. And, as shown in Fig.\\ref{un_optimal}, vector $\\bf{G}_1$, the original selected one, dose not have the minimum Euclidian distance to the host vector $\\bf{x}$ among the four alternative ones. In practice, vector $\\bf{G}_2$ is the closest one.\n\\par\nThus, it is not optimal to use vector $\\bf{G}_1$ to play as the watermarked vector. More specifically, once the host vector $\\bf{x}$ belongs to the shadowed area in the parallelogram in Fig.\\ref{un_optimal}, it is not optimal to use the original embedding strategy to select the quantization point along each direction and generate the watermarked vector.\n\\par\nThe original multiple watermarks embedding strategy \\eqref{eq15} and \\eqref{eq17} must be rewritten as\n\n", "itemtype": "equation", "pos": 27739, "prevtext": "\n\\par\nDefinitely, any points in ${\\bf{B}}$ have the same detection robustness according to the DM detection mechanism, \\eqref{eq5} and \\eqref{eq6}. In what follows, this kind of points are defined as the DM quantization points of point $x$.\n\\par\n\nAs illustrated in Fig.\\ref{DM_embedder}, in the case of DM single watermarking, it is optimal to use \\eqref{eq3}, which is equivalent to $\\beta=round(\\frac{{x + d^m }}{\\Delta })$ in \\eqref{eq20}, to choose the final quantization point, because the selected one is the closest point to $x$ among all the DM quantization points of $x$,(i.e., points in $B$).\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{DM_embedder.eps}}\n  \\caption{Utilizing DM to embed one message bit $m$ into point $x$, where the set of circles represents quantization points in $B$, (assuming $d^m>0$). Dotted-lines, $L=\\{l|l=((2\\alpha  + 1)\\frac{\\Delta }{2} - d^m,\\;\\alpha \\in Z\\}$, denote the median point between two adjacent quantization points.}\\label{DM_embedder}\n\\end{center}\n\\end{figure}\n\n\n\\par\nInspired by this idea, in the original STDM, as illustrated in Fig.\\ref{STDM_embedder_explain}, we can modulate the host vector $\\bf{x}$ to any vector (${\\bf{g}}''$,${\\bf{g}}'$,${\\bf{g}}$), whose projection point is the DM quantization point of the host vector's projection point $p$.\n\\par\nHowever, the imperceptible constraint must be considered. Referencing \\eqref{eq11}, the Euclidian distance $dis\\_v$ between the watermarked vector $\\bf{g}$ and the host vector $\\bf{x}$, is proportional to $k$, which is actually the distance $dis\\_p$ between the host vector's projection point $p$ and $p$'s DM quantization point. This can be formulated as follows,\n\n", "index": 37, "text": "\\begin{equation}\\label{eq21}\n\ndis\\_v=\\left\\| {{\\bf{g}} - {\\bf{x}}} \\right\\|_2  = \\left\\| {{\\bf{x}} + k{\\bf{u}} - {\\bf{x}}} \\right\\|_2  = k\\left\\| {\\bf{u}} \\right\\|_2=dis\\_p\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; dis\\_v=\\left\\|{{\\bf{g}}-{\\bf{x}}}\\right\\|_{2}=\\left\\|{{\\bf{x}}+k{\\bf{u}}%&#10;-{\\bf{x}}}\\right\\|_{2}=k\\left\\|{\\bf{u}}\\right\\|_{2}=dis\\_p\" display=\"block\"><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>v</mi></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mi>\ud835\udc20</mi><mo>-</mo><mi>\ud835\udc31</mi></mrow><mo>\u2225</mo></mrow><mn>2</mn></msub><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><mi>k</mi><mo>\u2062</mo><mi>\ud835\udc2e</mi></mrow></mrow><mo>-</mo><mi>\ud835\udc31</mi></mrow><mo>\u2225</mo></mrow><mn>2</mn></msub><mo>=</mo><mrow><mi>k</mi><mo>\u2062</mo><msub><mrow><mo>\u2225</mo><mi>\ud835\udc2e</mi><mo>\u2225</mo></mrow><mn>2</mn></msub></mrow><mo>=</mo><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>p</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n \n", "itemtype": "equation", "pos": 31744, "prevtext": "\n\n\\par\nAs DM quantizer \\eqref{eq3} can generate the quantization point that is closest to the original point, it can find the closest DM quantization point to the host vector's projection point, i.e., the DM quantizer can make $dis\\_p$ minimum. Thus, it is optimal to use DM quantizer to modulate the host vector $\\bf{x}$ to vector $\\bf{g}$ by \\eqref{eq7}. In this way, the minimum $dis\\_v$ can be guaranteed.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_embedder_explain.eps}}\n  \\caption{Utilizing STDM to embed one message bit $m$ into one host vector $\\bf{x}$, where $\\bf{u}$ is the projective vector and $\\bf{g}$ is the watermarked vector. The set of circles represents the DM quantization points of the projection point $p$ of the host vector $\\bf{x}$ along the direction $\\bf{u}$.}\\label{STDM_embedder_explain}\n\\end{center}\n\\end{figure}\n\n\\subsection{Embedding Strategy of STDM-Multiple Watermarking}\nAs mentioned above, DM quantizer is optimal for STDM in the case of single watermarking. Unfortunately, it seems that this strategy is not optimal in the case of multiple watermarking.\n\\par\nAs mentioned in III-A, in the case of multiple watermarking, if $n$ message bits are embedded, the host vector $\\bf{x}$ must be modulated along $n$ given directions to form the watermarked vector $\\bf{g}$. For each direction, the projection of the watermarked vector $\\bf{g}$ must be the closet DM quantization point to the host vector $\\bf{x}$'s projection point.\n\n\\par\nAs illustrated in Fig.\\ref{un_optimal}, it is a simple example for two users, that is embedding two bits into the host vector $\\bf{x}$. To do this, host vector $\\bf{x}$ must be projected along the projective vectors $\\bf{u}_1$ and $\\bf{u}_2$ to gain the projection points $p_1$ and $p_2$, respectively. And then, points $p_1$ and $p_2$ are quantized into their closet DM quantization points, $Q_1$ and $Q_2$, respectively. Finally, host vector $\\bf{x}$ is modulated into vector $\\bf{G}_1$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{un_optimal.eps}}\n  \\caption{Utilizing the original embedding strategy STDM-MW to embed two message bits into one host vector $\\bf{x}$, where $\\bf{u}_1$ and $\\bf{u}_2$ are the two projective vectors denoting the quantization directions. $p_1$ and $p_2$ are the projection points of $\\bf{x}$ along $\\bf{u}_1$ and $\\bf{u}_2$, respectively. The circles along $\\bf{u}_1$ and $\\bf{u}_2$ denote the DM quantization points, belonging to the point set ${\\bf{B}}_1$ and ${\\bf{B}}_2$,respectively. ${\\bf{B}}_j=\\{ b|b =\\beta_j \\Delta_j  - d_j^{m_j} ,\\;\\beta_j  \\in Z \\}$. }\\label{un_optimal}\n\\end{center}\n\\end{figure}\n\n\\par\nHowever, this original embedding strategy, using the closest DM quantization point as the final quantization point of the projection point, can not product the closet watermarked vector to the host vector. Actually, vectors $\\bf{G}_1$, $\\bf{G}_2$, $\\bf{G}_3$ and $\\bf{G}_4$ can all be selected as the watermarked vector of the host vector $\\bf{x}$ while owning the same detection robustness. And, as shown in Fig.\\ref{un_optimal}, vector $\\bf{G}_1$, the original selected one, dose not have the minimum Euclidian distance to the host vector $\\bf{x}$ among the four alternative ones. In practice, vector $\\bf{G}_2$ is the closest one.\n\\par\nThus, it is not optimal to use vector $\\bf{G}_1$ to play as the watermarked vector. More specifically, once the host vector $\\bf{x}$ belongs to the shadowed area in the parallelogram in Fig.\\ref{un_optimal}, it is not optimal to use the original embedding strategy to select the quantization point along each direction and generate the watermarked vector.\n\\par\nThe original multiple watermarks embedding strategy \\eqref{eq15} and \\eqref{eq17} must be rewritten as\n\n", "index": 39, "text": "\\begin{equation}\\label{eq22}\n\n\\left\\{ \\begin{array}{l}\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_1 ) = Qp_1  \\\\\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_2 ) = Qp_2  \\\\\n ...........\\;.......... \\\\\n {\\mathop{\\rm proj}\\nolimits} ({\\bf{g}},{\\bf{u}}_n ) = Qp_n  \\\\\n \\end{array} \\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\left\\{\\begin{array}[]{l}{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}}_{%&#10;1})=Qp_{1}\\\\&#10;{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}}_{2})=Qp_{2}\\\\&#10;...........\\;..........\\\\&#10;{\\mathop{\\rm proj}\\nolimits}({\\bf{g}},{\\bf{u}}_{n})=Qp_{n}\\\\&#10;\\end{array}\\right.\" display=\"block\"><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>Q</mi><mo>\u2062</mo><msub><mi>p</mi><mn>1</mn></msub></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>Q</mi><mo>\u2062</mo><msub><mi>p</mi><mn>2</mn></msub></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi mathvariant=\"normal\">\u2026</mi><mi mathvariant=\"normal\">\u2026</mi><mi mathvariant=\"normal\">\u2026</mi><mo>.</mo><mo rspace=\"5.3pt\">.</mo><mi mathvariant=\"normal\">\u2026</mi><mi mathvariant=\"normal\">\u2026</mi><mi mathvariant=\"normal\">\u2026</mi><mo>.</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mo>proj</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc20</mi><mo>,</mo><msub><mi>\ud835\udc2e</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>Q</mi><mo>\u2062</mo><msub><mi>p</mi><mi>n</mi></msub></mrow></mrow></mtd></mtr></mtable><mi/></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $Qp_j$ denotes one DM quantization point in the j-th direction,\n\n\n\n\n$\n\\begin{array}{l}\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{Qp}} = [Qp_1 ,Qp_2 ,...,Qp_n ]^T ,\\; \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;Qp_j  \\in {\\bf{B}}_j, {\\bf{B}}_j=\\{ b|b = \\beta _j \\Delta _j  - d_j^{m_j} ,\\beta _j  \\in {\\rm Z}\\}  \\\\\n \\end{array}\n$\n\n\\par\n$\\;$\n\\par\n\nSubstituting \\eqref{eq23} into \\eqref{eq14}, the watermarked vector can be given by\n\n\n", "itemtype": "equation", "pos": 32057, "prevtext": "\n\n \n", "index": 41, "text": "\\begin{equation}\\label{eq23}\n \n{\\bf{K}} = {\\bf{U}}_{_{\\bf{I}} }^{^{ - 1} } ({\\bf{Qp}} - {\\bf{P}})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{K}}={\\bf{U}}_{{}_{\\bf{I}}}^{{}^{-1}}({\\bf{Qp}}-{\\bf{P}})\" display=\"block\"><mrow><mi>\ud835\udc0a</mi><mo>=</mo><mrow><msubsup><mi>\ud835\udc14</mi><msub><mi/><mi>\ud835\udc08</mi></msub><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\nAs there are many DM quantization points in each direction, there are several combinations to make $\\bf{Qp}$. This will form a vector pool for $\\bf{Qp}$, namely $\\bf{Qp\\_S}$. Vectors in $\\bf{Qp\\_S}$ can all be chosen as $\\bf{Qp}$ in \\eqref{eq105}, and correspondingly, a vector pool for the watermarked vector ${\\bf{g}}$ is generated, namely {\\bf{g\\_S}}. The goal of our optimization procedure is to find the closest one to the host vector ${\\bf{x}}$ from this vector pool $\\bf{g\\_S}$, and finally use this vector to play as the optimized watermarked vector.\n\n\n\\section{Optimization for STDM-Multiple Watermarking}\n\nAs mentioned above, obviously, if all the candidate vectors in the pool $\\bf{g\\_S}$ are traversed, the one which is closest to the host vector will be found ultimately. However, as the infinite size of $\\bf{g\\_S}$, this procedure is not practical. To address this issue, the optimization procedure is divided into two cases, the special case and the general case.\n\n\\subsection{Special Case: Multiple Watermarking using Orthogonal Projective Vectors}\nIt has been observed that the goal of our optimization procedure is to find the closet watermarked vector to the host vector, i.e., the Euclidian distance between them is minimum. According to \\eqref{eq105}, the Euclidian distance, $dis\\_v$, can be expressed as follows,\n\n", "itemtype": "equation", "pos": 32574, "prevtext": "\nwhere $Qp_j$ denotes one DM quantization point in the j-th direction,\n\n\n\n\n$\n\\begin{array}{l}\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;{\\bf{Qp}} = [Qp_1 ,Qp_2 ,...,Qp_n ]^T ,\\; \\\\\n \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;Qp_j  \\in {\\bf{B}}_j, {\\bf{B}}_j=\\{ b|b = \\beta _j \\Delta _j  - d_j^{m_j} ,\\beta _j  \\in {\\rm Z}\\}  \\\\\n \\end{array}\n$\n\n\\par\n$\\;$\n\\par\n\nSubstituting \\eqref{eq23} into \\eqref{eq14}, the watermarked vector can be given by\n\n\n", "index": 43, "text": "\\begin{equation}\\label{eq105}\n\n\n\\;{\\bf{g}} = {\\bf{x}} + {\\bf{U}}{\\bf{U}}_{_{\\bf{I}} }^{^{ - 1} } ({\\bf{Qp}} - {\\bf{P}})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\par&#10;\\;{\\bf{g}}={\\bf{x}}+{\\bf{U}}{\\bf{U}}_{{}_{\\bf{I}}}^{{}^{-1}}({\\bf{Qp%&#10;}}-{\\bf{P}})\" display=\"block\"><mrow><mpadded lspace=\"2.8pt\" width=\"+2.8pt\"><mi>\ud835\udc20</mi></mpadded><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><msubsup><mi>\ud835\udc14\ud835\udc14</mi><msub><mi/><mi>\ud835\udc08</mi></msub><msup><mi/><mrow><mo>-</mo><mn>1</mn></mrow></msup></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\bf{U}}_e  = \\Lambda _U ^{ - 1} ({\\bf{U}}^T {\\bf{U}})^{ - 1} \\Lambda _U ^{ - 1}$.\n\\par\nIf the projective vectors $\\bf{u_1}$,$\\bf{u_2}$,...,$\\bf{u_n}$ are preprocessed by Gram-Schmidt orthogonalization, the matrix ${\\bf{U}}_e$ will be Identity matrix ${\\bf{I}}_n$, and $dis\\_v$ is actually the Euclidian distance between the vector of DM quantization points, $\\bf{Qp}$, and the vector of projection points, $\\bf{P}$.\n\n", "itemtype": "equation", "pos": 34048, "prevtext": "\n\n\nAs there are many DM quantization points in each direction, there are several combinations to make $\\bf{Qp}$. This will form a vector pool for $\\bf{Qp}$, namely $\\bf{Qp\\_S}$. Vectors in $\\bf{Qp\\_S}$ can all be chosen as $\\bf{Qp}$ in \\eqref{eq105}, and correspondingly, a vector pool for the watermarked vector ${\\bf{g}}$ is generated, namely {\\bf{g\\_S}}. The goal of our optimization procedure is to find the closest one to the host vector ${\\bf{x}}$ from this vector pool $\\bf{g\\_S}$, and finally use this vector to play as the optimized watermarked vector.\n\n\n\\section{Optimization for STDM-Multiple Watermarking}\n\nAs mentioned above, obviously, if all the candidate vectors in the pool $\\bf{g\\_S}$ are traversed, the one which is closest to the host vector will be found ultimately. However, as the infinite size of $\\bf{g\\_S}$, this procedure is not practical. To address this issue, the optimization procedure is divided into two cases, the special case and the general case.\n\n\\subsection{Special Case: Multiple Watermarking using Orthogonal Projective Vectors}\nIt has been observed that the goal of our optimization procedure is to find the closet watermarked vector to the host vector, i.e., the Euclidian distance between them is minimum. According to \\eqref{eq105}, the Euclidian distance, $dis\\_v$, can be expressed as follows,\n\n", "index": 45, "text": "\\begin{equation}\\label{eq27}\n\n\\begin{array}{l}\n dis\\_v = \\left\\| {{\\bf{g}} - {\\bf{x}}} \\right\\|_2  = \\sqrt {({\\bf{Qp}}- {\\bf{P}})^T {\\bf{U}}_e ({\\bf{Qp}} - {\\bf{P}})}\n \\end{array}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\begin{array}[]{l}dis\\_v=\\left\\|{{\\bf{g}}-{\\bf{x}}}\\right\\|_{2}=\\sqrt{({%&#10;\\bf{Qp}}-{\\bf{P}})^{T}{\\bf{U}}_{e}({\\bf{Qp}}-{\\bf{P}})}\\end{array}\" display=\"block\"><mtable displaystyle=\"true\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>v</mi></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mi>\ud835\udc20</mi><mo>-</mo><mi>\ud835\udc31</mi></mrow><mo>\u2225</mo></mrow><mn>2</mn></msub><mo>=</mo><msqrt><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><msub><mi>\ud835\udc14</mi><mi>e</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msqrt></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\nAs QDM quantizer \\eqref{eq3} can minimize each item in \\eqref{eq36}, the original embedding strategy, using the closest DM quantization point as the final quantization point of the projection point, is optimal in the case of multiple watermarking using orthogonal projective vectors. Note that, in the following description, this special case will be referred as STDM-MW-Uorth.\n\\par\nThe simple example for this case is illustrated in Fig.\\ref{STDM_MW_Uorth}, if the host vector $\\bf{x}$ belongs to the rectangle area centered by ${\\bf{G}}_i$ with width $\\Delta_1$ and height $\\Delta_2$, it will be modulated to the vector ${\\bf{G}}_i$. Obviously, ${\\bf{G}}_i$ is the optimal watermarked vector for ${\\bf{x}}$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_Uorth.eps}}\n  \\caption{Embedding two message bits into one host vector $\\bf{x}$ in the case of $\\bf{u_1}$ and $\\bf{u_2}$ are orthogonal projective vectors, and ${\\bf{G}}_5$ is the optimal watermarked vector for ${\\bf{x}}$.}\\label{STDM_MW_Uorth}\n\\end{center}\n\\end{figure}\n\n\n\\subsection{General Case: Multiple Watermarking using Unorthogonal Projective Vectors}\nIn general, it is not realistic to expect the projective vectors $\\bf{u_1}$,$\\bf{u_2}$,...,$\\bf{u_n}$ are orthogonal with each other. Thus, taking a tradeoff between PSNR and time efficiency, we propose two methods for the general case to find the optimized watermarked vector which is much closer to the host vector, namely STDM-MW-Poptim and STDM-MW-Qoptim.\n\n\\subsubsection{STDM-MW-Poptim}\nIn STDM-MW-Poptim, along each direction, $t$ quantization points, which are near the projection point of the host vector, are selected to form the point-set for this direction. This can be expressed as follows\n\n", "itemtype": "equation", "pos": 34667, "prevtext": "\nwhere ${\\bf{U}}_e  = \\Lambda _U ^{ - 1} ({\\bf{U}}^T {\\bf{U}})^{ - 1} \\Lambda _U ^{ - 1}$.\n\\par\nIf the projective vectors $\\bf{u_1}$,$\\bf{u_2}$,...,$\\bf{u_n}$ are preprocessed by Gram-Schmidt orthogonalization, the matrix ${\\bf{U}}_e$ will be Identity matrix ${\\bf{I}}_n$, and $dis\\_v$ is actually the Euclidian distance between the vector of DM quantization points, $\\bf{Qp}$, and the vector of projection points, $\\bf{P}$.\n\n", "index": 47, "text": "\\begin{equation}\\label{eq36}\n\ndis\\_v=\\left\\| {{\\bf{Qp}} - {\\bf{P}}} \\right\\|_2=\\sqrt {\\sum\\limits_j {({\\bf{Qp}}(j) - {\\bf{P}}(j))^2 } }\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; dis\\_v=\\left\\|{{\\bf{Qp}}-{\\bf{P}}}\\right\\|_{2}=\\sqrt{\\sum\\limits_{j}{({%&#10;\\bf{Qp}}(j)-{\\bf{P}}(j))^{2}}}\" display=\"block\"><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>v</mi></mrow><mo>=</mo><msub><mrow><mo>\u2225</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo>\u2225</mo></mrow><mn>2</mn></msub><mo>=</mo><msqrt><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>\ud835\udc0f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\bf{H}}_j$ denotes the point-set of the j-th direction.\n\\par\nAnd then, one point of each point-set is selected to form a vector $\\bf{PoQp}$. It can be used to substitute the vector $\\bf{Qp}$ in \\eqref{eq105}, and the watermarked vector can be calculated by\n\n", "itemtype": "equation", "pos": 36592, "prevtext": "\n\nAs QDM quantizer \\eqref{eq3} can minimize each item in \\eqref{eq36}, the original embedding strategy, using the closest DM quantization point as the final quantization point of the projection point, is optimal in the case of multiple watermarking using orthogonal projective vectors. Note that, in the following description, this special case will be referred as STDM-MW-Uorth.\n\\par\nThe simple example for this case is illustrated in Fig.\\ref{STDM_MW_Uorth}, if the host vector $\\bf{x}$ belongs to the rectangle area centered by ${\\bf{G}}_i$ with width $\\Delta_1$ and height $\\Delta_2$, it will be modulated to the vector ${\\bf{G}}_i$. Obviously, ${\\bf{G}}_i$ is the optimal watermarked vector for ${\\bf{x}}$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_Uorth.eps}}\n  \\caption{Embedding two message bits into one host vector $\\bf{x}$ in the case of $\\bf{u_1}$ and $\\bf{u_2}$ are orthogonal projective vectors, and ${\\bf{G}}_5$ is the optimal watermarked vector for ${\\bf{x}}$.}\\label{STDM_MW_Uorth}\n\\end{center}\n\\end{figure}\n\n\n\\subsection{General Case: Multiple Watermarking using Unorthogonal Projective Vectors}\nIn general, it is not realistic to expect the projective vectors $\\bf{u_1}$,$\\bf{u_2}$,...,$\\bf{u_n}$ are orthogonal with each other. Thus, taking a tradeoff between PSNR and time efficiency, we propose two methods for the general case to find the optimized watermarked vector which is much closer to the host vector, namely STDM-MW-Poptim and STDM-MW-Qoptim.\n\n\\subsubsection{STDM-MW-Poptim}\nIn STDM-MW-Poptim, along each direction, $t$ quantization points, which are near the projection point of the host vector, are selected to form the point-set for this direction. This can be expressed as follows\n\n", "index": 49, "text": "\\begin{equation}\\label{eq24}\n\n{\\bf{H}}_j  = \\{ h|h = \\Delta _j (floor(\\frac{x}{{\\Delta _j }}) + k) - d_j^{m_j} ,\\;\\;k \\in {\\rm Z}\\}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{H}}_{j}=\\{h|h=\\Delta_{j}(floor(\\frac{x}{{\\Delta_{j}}})+k)-d_{j}^{m_{%&#10;j}},\\;\\;k\\in{\\rm Z}\\}\" display=\"block\"><mrow><msub><mi>\ud835\udc07</mi><mi>j</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mi>h</mi><mo stretchy=\"false\">|</mo><mrow><mrow><mi>h</mi><mo>=</mo><mrow><mrow><msub><mi mathvariant=\"normal\">\u0394</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mi>l</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mfrac><mi>x</mi><msub><mi mathvariant=\"normal\">\u0394</mi><mi>j</mi></msub></mfrac><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>k</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><msubsup><mi>d</mi><mi>j</mi><msub><mi>m</mi><mi>j</mi></msub></msubsup></mrow></mrow><mo rspace=\"8.1pt\">,</mo><mrow><mi>k</mi><mo>\u2208</mo><mi mathvariant=\"normal\">Z</mi></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere, assuming there are $n$ bits to be embedded in one host vector, in other words $n$ quantization directions are given for one host vector, thus there are $F=t^n$ ways to choose one element from $n$ point-sets (of length $t$) to form the vector $\\bf{PoQp}$. And correspondingly, $F$ watermarked vectors $\\bf{g}$ are produced.\n\\par\nThe final optimized watermarked vector ${\\bf{g}}_{optim}$ is then given by judging which of these watermarked vectors produced in \\eqref{eq25} has the minimum Euclidean distance to the host vector $\\bf{x}$.\n\n", "itemtype": "equation", "pos": 37004, "prevtext": "\nwhere ${\\bf{H}}_j$ denotes the point-set of the j-th direction.\n\\par\nAnd then, one point of each point-set is selected to form a vector $\\bf{PoQp}$. It can be used to substitute the vector $\\bf{Qp}$ in \\eqref{eq105}, and the watermarked vector can be calculated by\n\n", "index": 51, "text": "\\begin{equation}\\label{eq25}\n\n{\\bf{g}}_i  = {\\bf{x}} + {\\bf{UU}}_{\\bf{I}} ^{ - 1} ({\\bf{PoQp}}_i  - {\\bf{P}}),\\;\\;i=1,2,...,F\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}_{i}={\\bf{x}}+{\\bf{UU}}_{\\bf{I}}^{-1}({\\bf{PoQp}}_{i}-{\\bf{P}}),%&#10;\\;\\;i=1,2,...,F\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><msubsup><mi>\ud835\udc14\ud835\udc14</mi><mi>\ud835\udc08</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc0f\ud835\udc28\ud835\udc10\ud835\udc29</mi><mi>i</mi></msub><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"8.1pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>F</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\\par\nMore specifically, Fig.\\ref{STDM_MW_OptimR} gives an optimization example for STDM-MW-Poptim, which is the simple case of embedding two bits into one host vector. Three quantization points are selected in each directions, thus $3^2$ watermarked vectors ($G_1$,$G_2$,...,$G_9$) can be generated. The final optimized watermarked vector is $G_2$, the one that is closest to the host vector $\\bf{x}$ among the nine candidate vectors.\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_OptimR.eps}}\n  \\caption{Utilizing STDM-MW-Poptim to embed two message bits into one host vector $\\bf{x}$, where $\\bf{u}_1$ and $\\bf{u}_2$ are the two projective vectors denoting the quantization directions. $Q_1$, $Q_2$ and $Q_3$ are the selected quantization points, corresponding to the search area $k=-1,0,1$ in \\eqref{eq24}. These points form ${\\bf{H}}_1$, the point-set of direction $\\bf{u}_1$. $Q_4$, $Q_5$, $Q_6$ are the same ones.}\\label{STDM_MW_OptimR}\n\\end{center}\n\\end{figure}\n\n\n\\subsubsection{STDM-MW-Qoptim}\nIt has been observed that the goal of our optimization procedure is to find the optimal DM quantization point along each direction which makes the Euclidian distance between the optimized watermarked vector and the host vector is minimum. According to \\eqref{eq27}, the Euclidian distance, $dis\\_v$, can be expressed as follows,\n\n", "itemtype": "equation", "pos": 37687, "prevtext": "\nwhere, assuming there are $n$ bits to be embedded in one host vector, in other words $n$ quantization directions are given for one host vector, thus there are $F=t^n$ ways to choose one element from $n$ point-sets (of length $t$) to form the vector $\\bf{PoQp}$. And correspondingly, $F$ watermarked vectors $\\bf{g}$ are produced.\n\\par\nThe final optimized watermarked vector ${\\bf{g}}_{optim}$ is then given by judging which of these watermarked vectors produced in \\eqref{eq25} has the minimum Euclidean distance to the host vector $\\bf{x}$.\n\n", "index": 53, "text": "\\begin{equation}\\label{eq26}\n\n{\\bf{g}}_{optim}  = \\mathop {\\arg \\min }\\limits_{{\\bf{g}}_i ,i \\in \\{ 1,2,...,F\\} }dist({\\bf{x}},{\\bf{g}}_i )\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}_{optim}=\\mathop{\\arg\\min}\\limits_{{\\bf{g}}_{i},i\\in\\{1,2,...,F\\}%&#10;}dist({\\bf{x}},{\\bf{g}}_{i})\" display=\"block\"><mrow><msub><mi>\ud835\udc20</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>m</mi></mrow></msub><mo>=</mo><mrow><munder><mrow><mi>arg</mi><mo movablelimits=\"false\">\u2061</mo><mi>min</mi></mrow><mrow><mrow><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo>,</mo><mi>i</mi></mrow><mo>\u2208</mo><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>F</mi><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere ${\\bf{A}} = ({\\bf{Qp}}- {\\bf{P}})$.\n\\par\nThus, the optimization procedure can be formulated as a constrained quadratic minimization problem that minimizes\n\n", "itemtype": "equation", "pos": 39228, "prevtext": "\n\n\\par\nMore specifically, Fig.\\ref{STDM_MW_OptimR} gives an optimization example for STDM-MW-Poptim, which is the simple case of embedding two bits into one host vector. Three quantization points are selected in each directions, thus $3^2$ watermarked vectors ($G_1$,$G_2$,...,$G_9$) can be generated. The final optimized watermarked vector is $G_2$, the one that is closest to the host vector $\\bf{x}$ among the nine candidate vectors.\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_OptimR.eps}}\n  \\caption{Utilizing STDM-MW-Poptim to embed two message bits into one host vector $\\bf{x}$, where $\\bf{u}_1$ and $\\bf{u}_2$ are the two projective vectors denoting the quantization directions. $Q_1$, $Q_2$ and $Q_3$ are the selected quantization points, corresponding to the search area $k=-1,0,1$ in \\eqref{eq24}. These points form ${\\bf{H}}_1$, the point-set of direction $\\bf{u}_1$. $Q_4$, $Q_5$, $Q_6$ are the same ones.}\\label{STDM_MW_OptimR}\n\\end{center}\n\\end{figure}\n\n\n\\subsubsection{STDM-MW-Qoptim}\nIt has been observed that the goal of our optimization procedure is to find the optimal DM quantization point along each direction which makes the Euclidian distance between the optimized watermarked vector and the host vector is minimum. According to \\eqref{eq27}, the Euclidian distance, $dis\\_v$, can be expressed as follows,\n\n", "index": 55, "text": "\\begin{equation}\\label{eq47}\ndis\\_v =  \\sqrt {{\\bf{A}}^T {\\bf{U}}_e {\\bf{A}}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"dis\\_v=\\sqrt{{\\bf{A}}^{T}{\\bf{U}}_{e}{\\bf{A}}}\" display=\"block\"><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>v</mi></mrow><mo>=</mo><msqrt><mrow><msup><mi>\ud835\udc00</mi><mi>T</mi></msup><mo>\u2062</mo><msub><mi>\ud835\udc14</mi><mi>e</mi></msub><mo>\u2062</mo><mi>\ud835\udc00</mi></mrow></msqrt></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nsubject to the constraint in the form of\n\n", "itemtype": "equation", "pos": 39482, "prevtext": "\nwhere ${\\bf{A}} = ({\\bf{Qp}}- {\\bf{P}})$.\n\\par\nThus, the optimization procedure can be formulated as a constrained quadratic minimization problem that minimizes\n\n", "index": 57, "text": "\\begin{equation}\\label{eq28}\nY = {\\bf{A}}^T {\\bf{U}}_e {\\bf{A}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"Y={\\bf{A}}^{T}{\\bf{U}}_{e}{\\bf{A}}\" display=\"block\"><mrow><mi>Y</mi><mo>=</mo><mrow><msup><mi>\ud835\udc00</mi><mi>T</mi></msup><mo>\u2062</mo><msub><mi>\ud835\udc14</mi><mi>e</mi></msub><mo>\u2062</mo><mi>\ud835\udc00</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nTo do the optimization, a part of elements in $\\bf{Qp}$ are selected as the fixed elements, each of which is generated from quantizing the projection point using \\eqref{eq3}, that is, the closest DM quantization point to the projection point. The other elements in $\\bf{Qp}$ will be optimized to minimize $Y$ in \\eqref{eq28}.\n\\par\nAssuming the elements to be optimized in $\\bf{Qp}$ are $Qp(o_1)$,$Qp(o_2)$,...,$Qp(o_t)$ and the elements to be fixed are $Qp(f_1)$,$Qp(f_2)$,...,$Qp(f_r)$, thus, in \\eqref{eq28}, the corresponding elements to be optimized and fixed in $\\bf{A}$, ${\\bf{A}}={\\bf{Qp}}- {\\bf{P}}$, will be $A(o_1)$,$A(o_2)$,...,$A(o_t)$ and $A(f_1)$,$A(f_2)$,...,$A(f_r)$. By differentiating $Y$ with respect to each element to be optimized, and setting the derivatives to be zero, $t$ equations will be generated\n\n", "itemtype": "equation", "pos": 39602, "prevtext": "\nsubject to the constraint in the form of\n\n", "index": 59, "text": "\\begin{equation}\\label{eq29}\n\n{\\bf{A}} + {\\bf{P}} \\in {\\bf{Qp\\_S}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{A}}+{\\bf{P}}\\in{\\bf{Qp\\_S}}\" display=\"block\"><mrow><mrow><mi>\ud835\udc00</mi><mo>+</mo><mi>\ud835\udc0f</mi></mrow><mo>\u2208</mo><mrow><mi>\ud835\udc10\ud835\udc29</mi><mo>\u2062</mo><mi mathvariant=\"normal\">_</mi><mo>\u2062</mo><mi>\ud835\udc12</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\n", "itemtype": "equation", "pos": 40514, "prevtext": "\n\\par\nTo do the optimization, a part of elements in $\\bf{Qp}$ are selected as the fixed elements, each of which is generated from quantizing the projection point using \\eqref{eq3}, that is, the closest DM quantization point to the projection point. The other elements in $\\bf{Qp}$ will be optimized to minimize $Y$ in \\eqref{eq28}.\n\\par\nAssuming the elements to be optimized in $\\bf{Qp}$ are $Qp(o_1)$,$Qp(o_2)$,...,$Qp(o_t)$ and the elements to be fixed are $Qp(f_1)$,$Qp(f_2)$,...,$Qp(f_r)$, thus, in \\eqref{eq28}, the corresponding elements to be optimized and fixed in $\\bf{A}$, ${\\bf{A}}={\\bf{Qp}}- {\\bf{P}}$, will be $A(o_1)$,$A(o_2)$,...,$A(o_t)$ and $A(f_1)$,$A(f_2)$,...,$A(f_r)$. By differentiating $Y$ with respect to each element to be optimized, and setting the derivatives to be zero, $t$ equations will be generated\n\n", "index": 61, "text": "\\begin{equation}\\label{eq30}\n\n\\frac{{\\partial Y}}{{\\partial A(o_i) }} = 0,\\;i = 1,2,...,t\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\frac{{\\partial Y}}{{\\partial A(o_{i})}}=0,\\;i=1,2,...,t\" display=\"block\"><mrow><mrow><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>Y</mi></mrow><mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><mi>A</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mn>0</mn></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>t</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nSolving \\eqref{eq31}, $t$ optimized elements in $A$ are produced, consequently, the optimized elements in $\\bf{Qp}$ can be generated, $Qp(o_i)=A(o_i)+P(o_i)$. Unfortunately, each $Qp(o_i)$ may not subject to the constraint \\eqref{eq29}, in other words, $Qp(o_i)$ dose not belong to the set of quantization points of the $o_i$-th direction, set ${\\bf{B}}_{o_i}$, $\\{b|b=\\beta_{o_i} \\Delta_{o_i}  - d_{o_i}^{m_{0_i}},\\;\\beta_{o_i}  \\in Z\\}$. To satisfy this constraint, the final optimized $Qp(o_i)$ can be given by\n\n", "itemtype": "equation", "pos": 40620, "prevtext": "\n\n\n", "index": 63, "text": "\\begin{equation}\\label{eq31}\n\n \\Rightarrow\\;\\sum\\limits_{j = 1}^t {{\\bf{U}}_{eo_io_j } A(o_j) }=\\sum\\limits_{k = 1}^r {{\\bf{U}}_{eo_if_k } A(f_k)},\\;i=1,2,...t\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\Rightarrow\\;\\sum\\limits_{j=1}^{t}{{\\bf{U}}_{eo_{i}o_{j}}A(o_{j})}=\\sum%&#10;\\limits_{k=1}^{r}{{\\bf{U}}_{eo_{i}f_{k}}A(f_{k})},\\;i=1,2,...t\" display=\"block\"><mrow><mrow><mi/><mo rspace=\"5.3pt\">\u21d2</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><msub><mi>\ud835\udc14</mi><mrow><mi>e</mi><mo>\u2062</mo><msub><mi>o</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>o</mi><mi>j</mi></msub></mrow></msub><mo>\u2062</mo><mi>A</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>o</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mrow><msub><mi>\ud835\udc14</mi><mrow><mi>e</mi><mo>\u2062</mo><msub><mi>o</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>f</mi><mi>k</mi></msub></mrow></msub><mo>\u2062</mo><mi>A</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>f</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"5.3pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mrow><mi mathvariant=\"normal\">\u2026</mi><mo>\u2062</mo><mi>t</mi></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\\par\nFinally, vector $\\bf{QoQp}$ is generated by assembling $Qp(o_i)$ and $Qp(o_f)$, and it can be used to substitute the vector $\\bf{Qp}$ in \\eqref{eq105}. The watermarked vector can be calculated by\n\n", "itemtype": "equation", "pos": 41314, "prevtext": "\n\\par\nSolving \\eqref{eq31}, $t$ optimized elements in $A$ are produced, consequently, the optimized elements in $\\bf{Qp}$ can be generated, $Qp(o_i)=A(o_i)+P(o_i)$. Unfortunately, each $Qp(o_i)$ may not subject to the constraint \\eqref{eq29}, in other words, $Qp(o_i)$ dose not belong to the set of quantization points of the $o_i$-th direction, set ${\\bf{B}}_{o_i}$, $\\{b|b=\\beta_{o_i} \\Delta_{o_i}  - d_{o_i}^{m_{0_i}},\\;\\beta_{o_i}  \\in Z\\}$. To satisfy this constraint, the final optimized $Qp(o_i)$ can be given by\n\n", "index": 65, "text": "\\begin{equation}\\label{eq32}\n\nQp(o_i)  = \\mathop {\\arg \\min }\\limits_{b_j ,b_j \\in {\\bf{B}}_{o_i} }dist(Qp(o_i),b_j)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; Qp(o_{i})=\\mathop{\\arg\\min}\\limits_{b_{j},b_{j}\\in{\\bf{B}}_{o_{i}}}dist(%&#10;Qp(o_{i}),b_{j})\" display=\"block\"><mrow><mrow><mi>Q</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mrow><mi>arg</mi><mo movablelimits=\"false\">\u2061</mo><mi>min</mi></mrow><mrow><mrow><msub><mi>b</mi><mi>j</mi></msub><mo>,</mo><msub><mi>b</mi><mi>j</mi></msub></mrow><mo>\u2208</mo><msub><mi>\ud835\udc01</mi><msub><mi>o</mi><mi>i</mi></msub></msub></mrow></munder><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Q</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>o</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><msub><mi>b</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere, assuming there are $n$ bits to be embedded in one host vector, in other words, there are $n$ given quantization directions for one host vector. Thus, there are $\nF=\\left( \\begin{array}{l}\n r \\\\\n n \\\\\n \\end{array} \\right)\n$ ways to choose $r$ elements from $\\bf{Qp}$ (of length $n$) to play as the fixed elements. $F$ vectors $\\bf{QoQp}$ are generated, and correspondingly, $F$ watermarked vectors $\\bf{g}$ are produced.\n\\par\nThe final optimized watermarked vector ${\\bf{g}}_{optim}$ is then given by judging which of these watermarked vectors produced in \\eqref{eq33} has the minimum Euclidean distance to the host vector $\\bf{x}$.\n\n", "itemtype": "equation", "pos": 41647, "prevtext": "\n\\par\nFinally, vector $\\bf{QoQp}$ is generated by assembling $Qp(o_i)$ and $Qp(o_f)$, and it can be used to substitute the vector $\\bf{Qp}$ in \\eqref{eq105}. The watermarked vector can be calculated by\n\n", "index": 67, "text": "\\begin{equation}\\label{eq33}\n\n{\\bf{g}}_i  = {\\bf{x}} + {\\bf{UU}}_{\\bf{I}} ^{ - 1} ({\\bf{QoQp}}_i  - {\\bf{P}}),\\;\\;i=1,2,...,F\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}_{i}={\\bf{x}}+{\\bf{UU}}_{\\bf{I}}^{-1}({\\bf{QoQp}}_{i}-{\\bf{P}}),%&#10;\\;\\;i=1,2,...,F\" display=\"block\"><mrow><mrow><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>\ud835\udc31</mi><mo>+</mo><mrow><msubsup><mi>\ud835\udc14\ud835\udc14</mi><mi>\ud835\udc08</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc10\ud835\udc28\ud835\udc10\ud835\udc29</mi><mi>i</mi></msub><mo>-</mo><mi>\ud835\udc0f</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"8.1pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>F</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\n\\par\nMore specifically, Fig.\\ref{STDM_MW_Optim} gives an optimization example for STDM-MW-Qoptim, which is the simple case of embedding two bits into one host vector. Thus, there are two elements in $\\bf{Qp}$, $Qp(1)$ and $Qp(2)$, corresponding to the projection directions $\\bf{u_1}$ and $\\bf{u_2}$. If $Qp(1)$ is fixed, then $Qp(1)$ is equal to $Q_2$. Through \\eqref{eq30}, actually Path 1 in Fig.\\ref{STDM_MW_Optim}, the optimized point of $Qp(2)$ is $O_2$. Finally, according to \\eqref{eq32}, $O_2$ is quantized to $Q_4$, and the corresponding watermarked vector is $G_1$. Correspondingly, if $Qp(2)$ is fixed, Path 2 is used to optimize $Qp(1)$, and $G_2$ is the corresponding watermarked vector. Comparing $G_1$ with $G_2$, the final optimal watermarked vector is $G_2$, the one that is closer to the host vector $\\bf{x}$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_Optim.eps}}\n  \\caption{Utilizing STDM-MW-Qoptim to embed two message bits into one host vector $\\bf{x}$.}\\label{STDM_MW_Optim}\n\\end{center}\n\\end{figure}\n\n\n\\section{Experimental Results and Analysis}\n\nTo evaluate the performance of our proposed method, experiments are performed on standard images with size $256 \\times 256$ as shown in Fig.\\ref{16image}. And all the experiment data illustrated in the following section are the averaged ones.\n\\par\n\n\\begin{figure}[htb!]\n  \\centering\n  \\scalebox{0.35}{\\includegraphics[width=\\textwidth]{16image.eps}}\n  \\caption{Test images}\\label{16image}\n\\end{figure}\n\nMore specifically, for all the proposed algorithms, to be analyzed in the experiments, the $2^{nd}  - 8^{th}$ DCT coefficients, in zig-zag-scaned order, of each $8 \\times 8$ block are used to form each host vector which is used to embed several message bits in it. The projective vectors and quantization steps are generated from the Gaussian distribution $\\mathcal {N}(0,16)$ and $\\mathcal {N}(f_g,4)$, respectively. $f_g$ is adjusted to ensure a given image fidelity.\n\n\n\\subsection{Experimental Test for the Efficiency of the Optimization Methods}\nAs mentioned above, to optimize the proposed multiple watermarking algorithm, two optimization methods, STDM-MW-Poptim and STDM-MW-Qoptim, are proposed to realize image fidelity improvement. To test their performance, 5 watermarks, with size $32\\times32$, are embedded into the standard image. Meanwhile, the same quantization steps, dither signals and projective vectors are used for the two methods to compare their performance in PSNR\\&CPU-time.\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.5}{\\includegraphics[width=\\textwidth]{psnr_cputime.eps}}\n  \\caption{PSNR Vs. CPU-time with different optimization parameters. The first point denotes embedding without optimization, the rest points are corresponding to the different search areas, $k=(0,1),(0,1,2),(-1,0,1),(-1,0,1,2)$ in \\eqref{eq24}, for STDM-MW-Poptim and the fixed numbers, $r=4,3,2,1$ in \\eqref{eq31}, for STDM-MW-Qoptim.}\\label{psnr_cputime}\n\\end{center}\n\\end{figure}\n\nAs illustrated in Fig.\\ref{psnr_cputime}, both of them have great performance in the improvement of the fidelity of the watermarked image. The image fidelity is promoted from 41dB to 44dB in PSNR, compared with the original embedding strategy.\n\\par\nIn STDM-MW-Poptim, along with the growth of the search area, it takes more time to realize the optimization, whereas, gives less contribution to the increase in PSNR. Taking a tradeoff between CPU-time and PSNR, $2^{nd}$ point, search area $k=0,1$, is the optimal one for five users in STDM-MW-Poptim.\n\\par\nIn STDM-MW-Qoptim, the CPU-time of $2^{nd}$\\&$5^{th}$ point and $3^{rd}$\\&$4^{th}$ point are almost the same. This is mainly due to the fact that the number of the watermarked vectors generated for one host vector, $F$ in \\eqref{eq33}, are the same, because $\nF=\\left( \\begin{array}{l}\n 4 \\\\\n 5 \\\\\n \\end{array} \\right)\n =\\left( \\begin{array}{l}\n 1 \\\\\n 5 \\\\\n \\end{array} \\right)\n$ for $2^{nd}$\\&$5^{th}$ point, and $\nF=\\left( \\begin{array}{l}\n 3 \\\\\n 5 \\\\\n \\end{array} \\right)\n =\\left( \\begin{array}{l}\n 2 \\\\\n 5 \\\\\n \\end{array} \\right)\n$ for $3^{rd}$\\&$4^{th}$ point. Taking a tradeoff between CPU-time and PSNR, $4^{th}$ point, fix number $r=2$, is the optimal one for five users in STDM-MW-Qoptim.\n\\par\nComparing the two optimal points in the two methods, STDM-MW-Poptim has better performance due to less CPU-time and higher PSNR.\n\\par\nThrough experiments, for different numbers of users, it is found that $k=0,1$ and $r=floor(user\\_number/2)$ are the appropriate optimization parameters for STDM-MW-Poptim and STDM-MW-Qoptim. And in what follows, these two parameters are used to implement the optimization.\n\n\n\n\\subsection{Experimental Test for the Proposed Methods in Robustness\\&PSNR}\nTo test the impact of multiple watermarks embedding to the fidelity of the image, different numbers of watermarks are embedded into the image using the four proposed methods separately.\n\\par\n\n\nAs illustrated in Fig.\\ref{PSNR}, along with the increase of the number of watermarks embedded, the quality of the images declines in vary degrees. STDM-MW-Uorth, which uses Gram-Schmidt orthogonalization to preprocess the projective vectors, has the superior image quality among these methods. This is mainly due to STDM-MW-Uorth is optimal in the case of orthogonal projective vectors. Unfortunately, in the general case that the projective vectors are not orthogonal, STDM-MW-no-optim, the quality of the watermarked image declines rapidly using the original embedding strategy without optimization. In contrast, if optimization is applied, e.g., STDM-MW-Poptim, the situation will be improved by a large scale, which is promoted by 1.03dB for 3 watermarks, 2.09dB for 4 watermarks, and 3.59dB for 5 watermarks.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{PSNR.eps}}\n  \\caption{PSNR Vs. Number of watermarks}\\label{PSNR}\n\\end{center}\n\\end{figure}\n\n\\par\nFrom another point of view, to evaluate the robustness of our proposed multiple watermarking methods, the test images are embedded into 3 watermarks, with size $32\\times32$, under the uniform fidelity, a fixed PSNR of 42 dB. Meanwhile, four kinds of attacks, Gauss Noise, JPEG Compression, Salt\\&Pepper Noise and Amplitude Scaling, are used to verify the performance of the schemes.\n\n\\par\nAs illustrated in Fig.\\ref{inner_compare}, we test four versions, STDM-MW-no-optim, STDM-MW-Poptim, STDM-MW-Qoptim and STDM-MW-Uorth. And we use the average detection score, measured in bit error rate (BER), to analyze the performance, and each curve is the average BER of the three detected watermarks.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Gauss.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Jpeg.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Salt.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Sca.eps}}}\n\n  \\caption{BER vs. (a) Gaussian Noise, (b) JPEG, (c) Salt\\&Pepper Noise and (d) Amplitude Scaling}\\label{inner_compare}\n\\end{center}\n\\end{figure*}\n\n\\par\nAs we expected, according to Fig.\\ref{inner_compare}.(d), all the proposed schemes do have good performance in amplitude scaling. The rise of BER in scale $\\beta  \\ge 1.2$ is mainly due to the ``cutoff distortion\", that is, some pixels of the image are already quite huge and will be cut off to the maximum allowed value when there is an scaling. In this case, the pixels will not scale linearly with the scaling factor while the quantization step-sizes still scale linearly as usual. Thus, experimental performance on bright images will have a worse robustness in this scale.\n\\par\nWith regard to other attacks, both STDM-MW-Poptim and STDM-MW-Qoptim have better robustness against Gauss noise (Fig.\\ref{inner_compare}.(a)) and JPEG compression (Fig.\\ref{inner_compare}.(b)) compared with STDM-MW-no-optim. This mainly due to the fact that the optimization procedures can improve the fidelity of the watermarked image, as shown in Fig.\\ref{PSNR}, in other words, the embedding strength used in them could be relatively increased while ensuring the given fidelity.\n\\par\nAlthough the STDM-MW-Uorth is the best performed one, it is not suitable for the applications where independent detection is required, because all the projective vectors of each users must be gained in the detector to perform Gram-Schmidt orthogonalization before the detecting procedure. Thus, referencing to section VI-A, STDM-MW-Poptim is the optimal one to play as the multiple watermarks embedding strategy in the sense of higher robustness, less CPU-time and for general applications.\n\n\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Gauss.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Jpeg.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Salt.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Sca.eps}}}\n\n  \\caption{BER vs. (a) Gaussian Noise, (b) JPEG, (c) Salt\\&Pepper Noise and (d) Amplitude Scaling}\\label{inter_compare}\n\\end{center}\n\\end{figure*}\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.95}{\\includegraphics[width=\\textwidth]{watermark_show.eps}}\n  \\caption{Watermark show}\\label{watermark_show}\n\\end{center}\n\\end{figure*}\n\n\n\\subsection{Comparison with the Pioneering Multiple Watermarking Algorithms}\nTo give an objective analysis of the performance of the proposed method, the optimal one of our proposed schemes, STDM-MW-Poptim, is picked up to be compared with the pioneering multiple watermarking algorithms, DA and IA-R in \\cite{MW_wang2003}. Both of them can embed multiple watermarks into the same image area, and each watermark can be detected independently, like ours. To correspond with the original paper, the parameters used for them are  identical, the keys K is generated from Gaussian distribution $\\mathcal {N}(0,16)$ and the first 10\\% of the DCT AC coefficients are used to form the host vector, meanwhile, 3 watermarks are embedded into the standard images, the same as ours. Note that, the mean of the keys D is modified to meet the uniform image fidelity, 42dB in PSNR. The BER curves are illustrated in Fig.\\ref{inter_compare}, meanwhile, to show the subjective visual effect, the detected watermarks corresponding to different conditions are given in Fig.\\ref{watermark_show}.\n\\par\nAs illustrated in Fig.\\ref{inter_compare}.(d), because DA and IA-R do not take the amplitude scaling attack into account, they cannot resist the image process which scales the amplitude of the pixels. In contrast, STDM-MW-Poptim has great advantage in this field,\n\\par\nIn robustness to random noise and JPEG Compression, Fig.\\ref{inter_compare}.(a)(b)(c), our proposed scheme outperforms others significantly, especially in Salt\\&Pepper Noise attack, the performance is almost improved by 70\\%. Such superior performance is attributed to the exploitation of the great robustness of the original STDM in single watermarking. In addition, the optimization strategy can provide a significant improvement in image fidelity, in other words, the embedding strength used in our scheme could be relatively increased while ensuring the given fidelity.\n\n\n\\section{Application Discussion and Extension}\nAs mentioned above, the proposed multiple watermarking algorithm has the feature that it can embed multiple watermarks into the same area and the same transform domain of one image, meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference. To this end, it may own some potential interesting applications.\n\n\\subsection{Coauthor Copyright Certification}\nIn the field of copyright management, one common scenario is that a number of authors who have co-designed an image need separate certification for each of them. This can be fulfilled by the proposed algorithm, STDM-MW-Poptim, in which the embedded watermarks (certifications for each author) can be extracted independently and blindly in the detector. Every author can use his/her own key set, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, to extract his/her own watermark, by which the copyright of each author can be certificated independently.\n\n\\subsection{Secret Related Area}\nA more interesting feature of STDM-MW-Poptim is that the detecting procedure of each watermark is independent with each other. More importantly, the receiver even dose not know how many watermarks are exactly embedded, i.e., one receiver cannot perceive the exist of other hidden information without the notification from the embedder. This is due to the fact that in terms of each receiver, the detecting procedure is exactly the same as STDM, which is deemed as a single watermarking algorithm. This interesting feature would cause the gloss to the receiver that the watermark he/she has extracted is the only information hidden in the image, and this gloss may provide a key cover for the protection of the true secret information.\n\n\\subsection{Image History Management}\nIn some applications such as medical image management, it is desirable to acquire the history of a medical image from the patient through the various laboratories and physicians, e.g., directly detecting from the image who is the creator, who has access to the data after its creation. This can be realized by sequentially embedding each user's digital signature into the image during each stage of its circulation.\n\\par\nInspired by \\cite{MW_wang_sequential}, we can utilize the special case of our proposed algorithm, multiple watermarking using orthogonal projective vectors, STDM-MW-Uorth, combined with STDM-MW-Poptim to fulfill this application.\n\\par\nAs illustrated in Fig.\\ref{MW_Sequential}, if Q additional watermarks are desired to be embedded into the watermarked image with P watermarks embedded, we must guarantee that these additional watermarks must not interfere with the former embedded watermarks. To realize this, we apply the idea of STDM-MW-Uorth, using projective vectors that are orthogonal to the ones of the former embedded watermarks.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.94}{\\includegraphics[width=\\textwidth]{sec_paper_sequential.eps}}\n  \\caption{Sequential Multiple Watermarks Embedding}\\label{MW_Sequential}\n\\end{center}\n\\end{figure*}\n\n\\par\nTo embed Q additional watermarks simultaneously for the coming Q users, the watermarked image with P watermarks embedded as well as a public key set (the former users' $U\\_KEY$) are needed. Then, the projective vector ${\\bf{u}}_i$ produced by each new user will be preprocessed by Gram-Schmidt orthogonalization.\n\n", "itemtype": "equation", "pos": 42427, "prevtext": "\nwhere, assuming there are $n$ bits to be embedded in one host vector, in other words, there are $n$ given quantization directions for one host vector. Thus, there are $\nF=\\left( \\begin{array}{l}\n r \\\\\n n \\\\\n \\end{array} \\right)\n$ ways to choose $r$ elements from $\\bf{Qp}$ (of length $n$) to play as the fixed elements. $F$ vectors $\\bf{QoQp}$ are generated, and correspondingly, $F$ watermarked vectors $\\bf{g}$ are produced.\n\\par\nThe final optimized watermarked vector ${\\bf{g}}_{optim}$ is then given by judging which of these watermarked vectors produced in \\eqref{eq33} has the minimum Euclidean distance to the host vector $\\bf{x}$.\n\n", "index": 69, "text": "\\begin{equation}\\label{eq34}\n\n{\\bf{g}}_{optim}  = \\mathop {\\arg \\min }\\limits_{{\\bf{g}}_i ,i \\in \\{ 1,2,...,F\\} }dist({\\bf{x}},{\\bf{g}}_i )\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{g}}_{optim}=\\mathop{\\arg\\min}\\limits_{{\\bf{g}}_{i},i\\in\\{1,2,...,F\\}%&#10;}dist({\\bf{x}},{\\bf{g}}_{i})\" display=\"block\"><mrow><msub><mi>\ud835\udc20</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>m</mi></mrow></msub><mo>=</mo><mrow><munder><mrow><mi>arg</mi><mo movablelimits=\"false\">\u2061</mo><mi>min</mi></mrow><mrow><mrow><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo>,</mo><mi>i</mi></mrow><mo>\u2208</mo><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>F</mi><mo stretchy=\"false\">}</mo></mrow></mrow></munder><mrow><mi>d</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>s</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo>,</mo><msub><mi>\ud835\udc20</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\n\nFinally, based on these preprocessed projective vectors, ${\\bf{u}}^{orth} _1$,${\\bf{u}}^{orth} _2$,...,${\\bf{u}}^{orth} _Q$,  Q additional watermarks can be simultaneously embedded into the watermarked image using STDM-MW-Poptim without any interference.\n\\par\nOne step further, if all the watermarks are desired to be embedded into the image one by one, this case is equivalent to STDM-MW-Uorth.\n\\par\nIn this way, we can embed multiple watermarks into the image sequentially to realize image history management. Compared with \\cite{MW_Tracing}, which is based on \\cite{SW_07MW_Tracing_base1,SW_07MW_Tracing_base2}, an additional management for the public key set is needed in our scheme. Nevertheless, to detect the watermark, \\cite{MW_Tracing} must acquire the knowledge of the content of the original embedded watermark to implement correlation detection and can only judge whether there exists the given watermark. This feature may somehow constrain its application area.\n\n\\section{Conclusions}\nIn this paper, a novel multiple watermarking algorithm is presented which initially extend the STDM, a single watermarking algorithm, to the field of multiple watermarking application. It can embed multiple watermarks into the same area and the same transform domain of one image; meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference. Moreover, through investigating the properties of the DM quantizer and the proposed multiple watermarks embedding strategy, two optimization methods are presented to improve the fidelity of the watermarked image. Experimental results indicate that the optimization procedure can significantly improve the quality of the watermarked image, meanwhile, the more watermarks embedded the more quality improvements can be gained. Finally, to enhance the application flexibility, an application extension of our algorithm is proposed, which can sequentially embed multiple watermarks into the image during each stage of its circulation, thereby realizing image history management. In general, compared with the pioneering multiple watermarking algorithms, the proposed scheme owns more flexibility in practical application and is more robust against distortion due to basic operations such as random noise, JPEG compression and valumetric scaling.\n\n\n\\appendices\n\\section{}\nReferencing \\eqref{eq17}, to make it tenable, the matrix ${\\bf{U}}_{_{\\bf{I}} }$ must be reversible. As ${\\bf{U}}_{_{\\bf{I}} }$ is an n-by-n matrix, thus\n", "itemtype": "equation", "pos": 57403, "prevtext": "\n\n\\par\nMore specifically, Fig.\\ref{STDM_MW_Optim} gives an optimization example for STDM-MW-Qoptim, which is the simple case of embedding two bits into one host vector. Thus, there are two elements in $\\bf{Qp}$, $Qp(1)$ and $Qp(2)$, corresponding to the projection directions $\\bf{u_1}$ and $\\bf{u_2}$. If $Qp(1)$ is fixed, then $Qp(1)$ is equal to $Q_2$. Through \\eqref{eq30}, actually Path 1 in Fig.\\ref{STDM_MW_Optim}, the optimized point of $Qp(2)$ is $O_2$. Finally, according to \\eqref{eq32}, $O_2$ is quantized to $Q_4$, and the corresponding watermarked vector is $G_1$. Correspondingly, if $Qp(2)$ is fixed, Path 2 is used to optimize $Qp(1)$, and $G_2$ is the corresponding watermarked vector. Comparing $G_1$ with $G_2$, the final optimal watermarked vector is $G_2$, the one that is closer to the host vector $\\bf{x}$.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{STDM_MW_Optim.eps}}\n  \\caption{Utilizing STDM-MW-Qoptim to embed two message bits into one host vector $\\bf{x}$.}\\label{STDM_MW_Optim}\n\\end{center}\n\\end{figure}\n\n\n\\section{Experimental Results and Analysis}\n\nTo evaluate the performance of our proposed method, experiments are performed on standard images with size $256 \\times 256$ as shown in Fig.\\ref{16image}. And all the experiment data illustrated in the following section are the averaged ones.\n\\par\n\n\\begin{figure}[htb!]\n  \\centering\n  \\scalebox{0.35}{\\includegraphics[width=\\textwidth]{16image.eps}}\n  \\caption{Test images}\\label{16image}\n\\end{figure}\n\nMore specifically, for all the proposed algorithms, to be analyzed in the experiments, the $2^{nd}  - 8^{th}$ DCT coefficients, in zig-zag-scaned order, of each $8 \\times 8$ block are used to form each host vector which is used to embed several message bits in it. The projective vectors and quantization steps are generated from the Gaussian distribution $\\mathcal {N}(0,16)$ and $\\mathcal {N}(f_g,4)$, respectively. $f_g$ is adjusted to ensure a given image fidelity.\n\n\n\\subsection{Experimental Test for the Efficiency of the Optimization Methods}\nAs mentioned above, to optimize the proposed multiple watermarking algorithm, two optimization methods, STDM-MW-Poptim and STDM-MW-Qoptim, are proposed to realize image fidelity improvement. To test their performance, 5 watermarks, with size $32\\times32$, are embedded into the standard image. Meanwhile, the same quantization steps, dither signals and projective vectors are used for the two methods to compare their performance in PSNR\\&CPU-time.\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.5}{\\includegraphics[width=\\textwidth]{psnr_cputime.eps}}\n  \\caption{PSNR Vs. CPU-time with different optimization parameters. The first point denotes embedding without optimization, the rest points are corresponding to the different search areas, $k=(0,1),(0,1,2),(-1,0,1),(-1,0,1,2)$ in \\eqref{eq24}, for STDM-MW-Poptim and the fixed numbers, $r=4,3,2,1$ in \\eqref{eq31}, for STDM-MW-Qoptim.}\\label{psnr_cputime}\n\\end{center}\n\\end{figure}\n\nAs illustrated in Fig.\\ref{psnr_cputime}, both of them have great performance in the improvement of the fidelity of the watermarked image. The image fidelity is promoted from 41dB to 44dB in PSNR, compared with the original embedding strategy.\n\\par\nIn STDM-MW-Poptim, along with the growth of the search area, it takes more time to realize the optimization, whereas, gives less contribution to the increase in PSNR. Taking a tradeoff between CPU-time and PSNR, $2^{nd}$ point, search area $k=0,1$, is the optimal one for five users in STDM-MW-Poptim.\n\\par\nIn STDM-MW-Qoptim, the CPU-time of $2^{nd}$\\&$5^{th}$ point and $3^{rd}$\\&$4^{th}$ point are almost the same. This is mainly due to the fact that the number of the watermarked vectors generated for one host vector, $F$ in \\eqref{eq33}, are the same, because $\nF=\\left( \\begin{array}{l}\n 4 \\\\\n 5 \\\\\n \\end{array} \\right)\n =\\left( \\begin{array}{l}\n 1 \\\\\n 5 \\\\\n \\end{array} \\right)\n$ for $2^{nd}$\\&$5^{th}$ point, and $\nF=\\left( \\begin{array}{l}\n 3 \\\\\n 5 \\\\\n \\end{array} \\right)\n =\\left( \\begin{array}{l}\n 2 \\\\\n 5 \\\\\n \\end{array} \\right)\n$ for $3^{rd}$\\&$4^{th}$ point. Taking a tradeoff between CPU-time and PSNR, $4^{th}$ point, fix number $r=2$, is the optimal one for five users in STDM-MW-Qoptim.\n\\par\nComparing the two optimal points in the two methods, STDM-MW-Poptim has better performance due to less CPU-time and higher PSNR.\n\\par\nThrough experiments, for different numbers of users, it is found that $k=0,1$ and $r=floor(user\\_number/2)$ are the appropriate optimization parameters for STDM-MW-Poptim and STDM-MW-Qoptim. And in what follows, these two parameters are used to implement the optimization.\n\n\n\n\\subsection{Experimental Test for the Proposed Methods in Robustness\\&PSNR}\nTo test the impact of multiple watermarks embedding to the fidelity of the image, different numbers of watermarks are embedded into the image using the four proposed methods separately.\n\\par\n\n\nAs illustrated in Fig.\\ref{PSNR}, along with the increase of the number of watermarks embedded, the quality of the images declines in vary degrees. STDM-MW-Uorth, which uses Gram-Schmidt orthogonalization to preprocess the projective vectors, has the superior image quality among these methods. This is mainly due to STDM-MW-Uorth is optimal in the case of orthogonal projective vectors. Unfortunately, in the general case that the projective vectors are not orthogonal, STDM-MW-no-optim, the quality of the watermarked image declines rapidly using the original embedding strategy without optimization. In contrast, if optimization is applied, e.g., STDM-MW-Poptim, the situation will be improved by a large scale, which is promoted by 1.03dB for 3 watermarks, 2.09dB for 4 watermarks, and 3.59dB for 5 watermarks.\n\n\\begin{figure}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.45}{\\includegraphics[width=\\textwidth]{PSNR.eps}}\n  \\caption{PSNR Vs. Number of watermarks}\\label{PSNR}\n\\end{center}\n\\end{figure}\n\n\\par\nFrom another point of view, to evaluate the robustness of our proposed multiple watermarking methods, the test images are embedded into 3 watermarks, with size $32\\times32$, under the uniform fidelity, a fixed PSNR of 42 dB. Meanwhile, four kinds of attacks, Gauss Noise, JPEG Compression, Salt\\&Pepper Noise and Amplitude Scaling, are used to verify the performance of the schemes.\n\n\\par\nAs illustrated in Fig.\\ref{inner_compare}, we test four versions, STDM-MW-no-optim, STDM-MW-Poptim, STDM-MW-Qoptim and STDM-MW-Uorth. And we use the average detection score, measured in bit error rate (BER), to analyze the performance, and each curve is the average BER of the three detected watermarks.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Gauss.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Jpeg.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Salt.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inner_Sca.eps}}}\n\n  \\caption{BER vs. (a) Gaussian Noise, (b) JPEG, (c) Salt\\&Pepper Noise and (d) Amplitude Scaling}\\label{inner_compare}\n\\end{center}\n\\end{figure*}\n\n\\par\nAs we expected, according to Fig.\\ref{inner_compare}.(d), all the proposed schemes do have good performance in amplitude scaling. The rise of BER in scale $\\beta  \\ge 1.2$ is mainly due to the ``cutoff distortion\", that is, some pixels of the image are already quite huge and will be cut off to the maximum allowed value when there is an scaling. In this case, the pixels will not scale linearly with the scaling factor while the quantization step-sizes still scale linearly as usual. Thus, experimental performance on bright images will have a worse robustness in this scale.\n\\par\nWith regard to other attacks, both STDM-MW-Poptim and STDM-MW-Qoptim have better robustness against Gauss noise (Fig.\\ref{inner_compare}.(a)) and JPEG compression (Fig.\\ref{inner_compare}.(b)) compared with STDM-MW-no-optim. This mainly due to the fact that the optimization procedures can improve the fidelity of the watermarked image, as shown in Fig.\\ref{PSNR}, in other words, the embedding strength used in them could be relatively increased while ensuring the given fidelity.\n\\par\nAlthough the STDM-MW-Uorth is the best performed one, it is not suitable for the applications where independent detection is required, because all the projective vectors of each users must be gained in the detector to perform Gram-Schmidt orthogonalization before the detecting procedure. Thus, referencing to section VI-A, STDM-MW-Poptim is the optimal one to play as the multiple watermarks embedding strategy in the sense of higher robustness, less CPU-time and for general applications.\n\n\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Gauss.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Jpeg.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Salt.eps}}}\n  \\subfigure[] {\\scalebox{0.46}{\\includegraphics[width=\\textwidth]{inter_Sca.eps}}}\n\n  \\caption{BER vs. (a) Gaussian Noise, (b) JPEG, (c) Salt\\&Pepper Noise and (d) Amplitude Scaling}\\label{inter_compare}\n\\end{center}\n\\end{figure*}\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.95}{\\includegraphics[width=\\textwidth]{watermark_show.eps}}\n  \\caption{Watermark show}\\label{watermark_show}\n\\end{center}\n\\end{figure*}\n\n\n\\subsection{Comparison with the Pioneering Multiple Watermarking Algorithms}\nTo give an objective analysis of the performance of the proposed method, the optimal one of our proposed schemes, STDM-MW-Poptim, is picked up to be compared with the pioneering multiple watermarking algorithms, DA and IA-R in \\cite{MW_wang2003}. Both of them can embed multiple watermarks into the same image area, and each watermark can be detected independently, like ours. To correspond with the original paper, the parameters used for them are  identical, the keys K is generated from Gaussian distribution $\\mathcal {N}(0,16)$ and the first 10\\% of the DCT AC coefficients are used to form the host vector, meanwhile, 3 watermarks are embedded into the standard images, the same as ours. Note that, the mean of the keys D is modified to meet the uniform image fidelity, 42dB in PSNR. The BER curves are illustrated in Fig.\\ref{inter_compare}, meanwhile, to show the subjective visual effect, the detected watermarks corresponding to different conditions are given in Fig.\\ref{watermark_show}.\n\\par\nAs illustrated in Fig.\\ref{inter_compare}.(d), because DA and IA-R do not take the amplitude scaling attack into account, they cannot resist the image process which scales the amplitude of the pixels. In contrast, STDM-MW-Poptim has great advantage in this field,\n\\par\nIn robustness to random noise and JPEG Compression, Fig.\\ref{inter_compare}.(a)(b)(c), our proposed scheme outperforms others significantly, especially in Salt\\&Pepper Noise attack, the performance is almost improved by 70\\%. Such superior performance is attributed to the exploitation of the great robustness of the original STDM in single watermarking. In addition, the optimization strategy can provide a significant improvement in image fidelity, in other words, the embedding strength used in our scheme could be relatively increased while ensuring the given fidelity.\n\n\n\\section{Application Discussion and Extension}\nAs mentioned above, the proposed multiple watermarking algorithm has the feature that it can embed multiple watermarks into the same area and the same transform domain of one image, meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference. To this end, it may own some potential interesting applications.\n\n\\subsection{Coauthor Copyright Certification}\nIn the field of copyright management, one common scenario is that a number of authors who have co-designed an image need separate certification for each of them. This can be fulfilled by the proposed algorithm, STDM-MW-Poptim, in which the embedded watermarks (certifications for each author) can be extracted independently and blindly in the detector. Every author can use his/her own key set, $STEP\\_KEY$, $U\\_KEY$ and $Dither\\_KEY$, to extract his/her own watermark, by which the copyright of each author can be certificated independently.\n\n\\subsection{Secret Related Area}\nA more interesting feature of STDM-MW-Poptim is that the detecting procedure of each watermark is independent with each other. More importantly, the receiver even dose not know how many watermarks are exactly embedded, i.e., one receiver cannot perceive the exist of other hidden information without the notification from the embedder. This is due to the fact that in terms of each receiver, the detecting procedure is exactly the same as STDM, which is deemed as a single watermarking algorithm. This interesting feature would cause the gloss to the receiver that the watermark he/she has extracted is the only information hidden in the image, and this gloss may provide a key cover for the protection of the true secret information.\n\n\\subsection{Image History Management}\nIn some applications such as medical image management, it is desirable to acquire the history of a medical image from the patient through the various laboratories and physicians, e.g., directly detecting from the image who is the creator, who has access to the data after its creation. This can be realized by sequentially embedding each user's digital signature into the image during each stage of its circulation.\n\\par\nInspired by \\cite{MW_wang_sequential}, we can utilize the special case of our proposed algorithm, multiple watermarking using orthogonal projective vectors, STDM-MW-Uorth, combined with STDM-MW-Poptim to fulfill this application.\n\\par\nAs illustrated in Fig.\\ref{MW_Sequential}, if Q additional watermarks are desired to be embedded into the watermarked image with P watermarks embedded, we must guarantee that these additional watermarks must not interfere with the former embedded watermarks. To realize this, we apply the idea of STDM-MW-Uorth, using projective vectors that are orthogonal to the ones of the former embedded watermarks.\n\n\\begin{figure*}[htb!]\n\\begin{center}\n  \n  \\scalebox{0.94}{\\includegraphics[width=\\textwidth]{sec_paper_sequential.eps}}\n  \\caption{Sequential Multiple Watermarks Embedding}\\label{MW_Sequential}\n\\end{center}\n\\end{figure*}\n\n\\par\nTo embed Q additional watermarks simultaneously for the coming Q users, the watermarked image with P watermarks embedded as well as a public key set (the former users' $U\\_KEY$) are needed. Then, the projective vector ${\\bf{u}}_i$ produced by each new user will be preprocessed by Gram-Schmidt orthogonalization.\n\n", "index": 71, "text": "\\begin{equation}\\label{eq37}\n\n{\\bf{u}}^{orth} _i  = {\\bf{u}}_i  - \\sum\\limits_{j = 1}^P {proj({\\bf{u}}_i ,{\\bf{k}}_j ) \\cdot \\frac{{{\\bf{k}}_j }}{{\\left\\| {{\\bf{k}}_j } \\right\\|_2 }}\\;\\;,i = 1,2,...,Q}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\bf{u}}^{orth}_{i}={\\bf{u}}_{i}-\\sum\\limits_{j=1}^{P}{proj({\\bf{u}}_{i},%&#10;{\\bf{k}}_{j})\\cdot\\frac{{{\\bf{k}}_{j}}}{{\\left\\|{{\\bf{k}}_{j}}\\right\\|_{2}}}\\;%&#10;\\;,i=1,2,...,Q}\" display=\"block\"><mrow><mrow><msubsup><mi>\ud835\udc2e</mi><mi>i</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>h</mi></mrow></msubsup><mo>=</mo><mrow><msub><mi>\ud835\udc2e</mi><mi>i</mi></msub><mo>-</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>P</mi></munderover><mrow><mrow><mi>p</mi><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><mi>j</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc2e</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\ud835\udc24</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u22c5</mo><mpadded width=\"+5.6pt\"><mfrac><msub><mi>\ud835\udc24</mi><mi>j</mi></msub><msub><mrow><mo>\u2225</mo><msub><mi>\ud835\udc24</mi><mi>j</mi></msub><mo>\u2225</mo></mrow><mn>2</mn></msub></mfrac></mpadded></mrow></mrow></mrow></mrow><mo>,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>Q</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nReferencing \\eqref{eq16}, ${\\bf{U}}_{\\bf{I}}  = \\Lambda _U {\\bf{U}^T}{\\bf{U}}$, thus\n", "itemtype": "equation", "pos": 60139, "prevtext": "\n\nFinally, based on these preprocessed projective vectors, ${\\bf{u}}^{orth} _1$,${\\bf{u}}^{orth} _2$,...,${\\bf{u}}^{orth} _Q$,  Q additional watermarks can be simultaneously embedded into the watermarked image using STDM-MW-Poptim without any interference.\n\\par\nOne step further, if all the watermarks are desired to be embedded into the image one by one, this case is equivalent to STDM-MW-Uorth.\n\\par\nIn this way, we can embed multiple watermarks into the image sequentially to realize image history management. Compared with \\cite{MW_Tracing}, which is based on \\cite{SW_07MW_Tracing_base1,SW_07MW_Tracing_base2}, an additional management for the public key set is needed in our scheme. Nevertheless, to detect the watermark, \\cite{MW_Tracing} must acquire the knowledge of the content of the original embedded watermark to implement correlation detection and can only judge whether there exists the given watermark. This feature may somehow constrain its application area.\n\n\\section{Conclusions}\nIn this paper, a novel multiple watermarking algorithm is presented which initially extend the STDM, a single watermarking algorithm, to the field of multiple watermarking application. It can embed multiple watermarks into the same area and the same transform domain of one image; meanwhile, the embedded watermarks can be extracted independently and blindly in the detector without any interference. Moreover, through investigating the properties of the DM quantizer and the proposed multiple watermarks embedding strategy, two optimization methods are presented to improve the fidelity of the watermarked image. Experimental results indicate that the optimization procedure can significantly improve the quality of the watermarked image, meanwhile, the more watermarks embedded the more quality improvements can be gained. Finally, to enhance the application flexibility, an application extension of our algorithm is proposed, which can sequentially embed multiple watermarks into the image during each stage of its circulation, thereby realizing image history management. In general, compared with the pioneering multiple watermarking algorithms, the proposed scheme owns more flexibility in practical application and is more robust against distortion due to basic operations such as random noise, JPEG compression and valumetric scaling.\n\n\n\\appendices\n\\section{}\nReferencing \\eqref{eq17}, to make it tenable, the matrix ${\\bf{U}}_{_{\\bf{I}} }$ must be reversible. As ${\\bf{U}}_{_{\\bf{I}} }$ is an n-by-n matrix, thus\n", "index": 73, "text": "\n\\[\nrank({\\bf{U}}_{_{\\bf{I}} })=n\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"rank({\\bf{U}}_{{}_{\\bf{I}}})=n\" display=\"block\"><mrow><mrow><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc14</mi><msub><mi/><mi>\ud835\udc08</mi></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi>n</mi></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nConsequently, we have $rank({\\bf{U}}) \\ge n$, and reference \\eqref{eq14}, ${\\bf{U}}$ is an L-by-n matrix, thus\n", "itemtype": "equation", "pos": 60260, "prevtext": "\nReferencing \\eqref{eq16}, ${\\bf{U}}_{\\bf{I}}  = \\Lambda _U {\\bf{U}^T}{\\bf{U}}$, thus\n", "index": 75, "text": "\n\\[\nrank({\\bf{U}}_{\\bf{I}} ) \\le \\min \\{ rank({\\bf{U}}),rank\\{ {\\bf{U'}}\\} \\}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"rank({\\bf{U}}_{\\bf{I}})\\leq\\min\\{rank({\\bf{U}}),rank\\{{\\bf{U^{\\prime}}}\\}\\}\" display=\"block\"><mrow><mrow><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc14</mi><mi>\ud835\udc08</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc14</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msup><mi>\ud835\udc14</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere L denotes the length of the host vector ${\\bf{x}}$.\n\n\n\\section{}\nConsider $X$ and $X'$ represent the original image and the watermarked one in the space domain. And referencing the DCT transformation, we have\n", "itemtype": "equation", "pos": 60451, "prevtext": "\nConsequently, we have $rank({\\bf{U}}) \\ge n$, and reference \\eqref{eq14}, ${\\bf{U}}$ is an L-by-n matrix, thus\n", "index": 77, "text": "\n\\[\n\\left\\{ \\begin{array}{l}\n rank({\\bf{U}}) = n \\\\\n L \\ge n \\\\\n \\end{array} \\right.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\left\\{\\begin{array}[]{l}rank({\\bf{U}})=n\\\\&#10;L\\geq n\\\\&#10;\\end{array}\\right.\" display=\"block\"><mrow><mo>{</mo><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>r</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc14</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi>n</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi>L</mi><mo>\u2265</mo><mi>n</mi></mrow></mtd></mtr></mtable><mi/></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $Y$ and $Y'$ are the coefficients in DCT domain.\n\\par\nThen, the MSE between the original image and the watermarked image can be written by\n", "itemtype": "equation", "pos": 60753, "prevtext": "\nwhere L denotes the length of the host vector ${\\bf{x}}$.\n\n\n\\section{}\nConsider $X$ and $X'$ represent the original image and the watermarked one in the space domain. And referencing the DCT transformation, we have\n", "index": 79, "text": "\n\\[\n\nY = AXA^{\\rm T},\\;\\;Y' = AX'A^{\\rm T}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; Y=AXA^{\\rm T},\\;\\;Y^{\\prime}=AX^{\\prime}A^{\\rm T}\" display=\"block\"><mrow><mrow><mi>Y</mi><mo>=</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>X</mi><mo>\u2062</mo><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup></mrow></mrow><mo rspace=\"8.1pt\">,</mo><mrow><msup><mi>Y</mi><mo>\u2032</mo></msup><mo>=</mo><mrow><mi>A</mi><mo>\u2062</mo><msup><mi>X</mi><mo>\u2032</mo></msup><mo>\u2062</mo><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $\\left\\| Q \\right\\|_F$ denotes the Frobenius norm of the matrix $Q$, in view of $\\left\\| Q \\right\\|_F  \\buildrel \\Delta \\over = (\\sum\\limits_{i = 1}^m {\\sum\\limits_{j = 1}^n {(Q(i,j))^2 )^{1/2} } }  = (tr(Q^T Q))^{1/2}$,\n", "itemtype": "equation", "pos": 60943, "prevtext": "\nwhere $Y$ and $Y'$ are the coefficients in DCT domain.\n\\par\nThen, the MSE between the original image and the watermarked image can be written by\n", "index": 81, "text": "\n\\[\n\n\\begin{array}{l}\n MSE = \\frac{1}{{mn}}\\sum\\limits_{i = 1}^{m } {\\sum\\limits_{j = 1}^{n } {[X(i,j) - X'(i,j)]^2 } }  \\\\\n  \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\| {X - X'} \\right\\|_F^2  \\\\\n  \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\| {A^{\\rm T} YA - A^{\\rm T} Y'A} \\right\\|_F^2  \\\\\n  \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\| {A^{\\rm T} (Y-Y')A} \\right\\|_F^2  \\\\\n \\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\begin{array}[]{l}MSE=\\frac{1}{{mn}}\\sum\\limits_{i=1}^{m}{\\sum\\limits_{j=%&#10;1}^{n}{[X(i,j)-X^{\\prime}(i,j)]^{2}}}\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\|{X-X^{\\prime}}\\right\\|_{F}^{2}\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\|{A^{\\rm T}YA-A^{\\rm T}Y^{\\prime}A}%&#10;\\right\\|_{F}^{2}\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\|{A^{\\rm T}(Y-Y^{\\prime})A}\\right\\|_{%&#10;F}^{2}\\\\&#10;\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>X</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">]</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi/><mo lspace=\"30.5pt\">=</mo><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi>X</mi><mo>-</mo><msup><mi>X</mi><mo>\u2032</mo></msup></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi/><mo lspace=\"30.5pt\">=</mo><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><mi>Y</mi><mo>\u2062</mo><mi>A</mi></mrow><mo>-</mo><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><msup><mi>Y</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mi>A</mi></mrow></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi/><mo lspace=\"30.5pt\">=</mo><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>A</mi></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nConsidering $A^T=A^{-1}$ in the DCT transformation, thus\n", "itemtype": "equation", "pos": 61555, "prevtext": "\nwhere $\\left\\| Q \\right\\|_F$ denotes the Frobenius norm of the matrix $Q$, in view of $\\left\\| Q \\right\\|_F  \\buildrel \\Delta \\over = (\\sum\\limits_{i = 1}^m {\\sum\\limits_{j = 1}^n {(Q(i,j))^2 )^{1/2} } }  = (tr(Q^T Q))^{1/2}$,\n", "index": 83, "text": "\n\\[\n\n MSE =\\frac{1}{{mn}}\\times tr((A^{\\rm T} (Y-Y')A)^T(A^{\\rm T} (Y-Y')A)) \\\\\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; MSE=\\frac{1}{{mn}}\\times tr((A^{\\rm T}(Y-Y^{\\prime})A)^{T}(A^{\\rm T}(Y-Y%&#10;^{\\prime})A))\\\\&#10;\" display=\"block\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>=</mo><mrow><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u00d7</mo><mi>t</mi></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>A</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>A</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nWhen $Y$ and $Y'$ are grouped into 1-dimension vectors, we have\n", "itemtype": "equation", "pos": 61694, "prevtext": "\nConsidering $A^T=A^{-1}$ in the DCT transformation, thus\n", "index": 85, "text": "\n\\[\n\n\\begin{array}{l}\n MSE =\\frac{1}{{mn}}\\times  tr(A^{\\rm T} (Y-Y')^T(Y-Y')A) \\\\\n  \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\times  tr((Y-Y')^T(Y-Y')) \\\\\n  \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\| {Y - Y'} \\right\\|_F^2\n \\end{array}\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\begin{array}[]{l}MSE=\\frac{1}{{mn}}\\times tr(A^{\\rm T}(Y-Y^{\\prime})^{T}%&#10;(Y-Y^{\\prime})A)\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\times tr((Y-Y^{\\prime})^{T}(Y-Y^{\\prime}))%&#10;\\\\&#10;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=\\frac{1}{{mn}}\\left\\|{Y-Y^{\\prime}}\\right\\|_{F}^{2}\\end{array}\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>=</mo><mrow><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u00d7</mo><mi>t</mi></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>A</mi><mi mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>A</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi/><mo lspace=\"30.5pt\">=</mo><mrow><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u00d7</mo><mi>t</mi></mrow><mo>\u2062</mo><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi/><mo lspace=\"30.5pt\">=</mo><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>\u2062</mo><mi>n</mi></mrow></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi>Y</mi><mo>-</mo><msup><mi>Y</mi><mo>\u2032</mo></msup></mrow><mo>\u2225</mo></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.04522.tex", "nexttext": "\nwhere $N=mn$, denotes the total number of the elements in the vector.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\bibliographystyle{IEEEtran}\n\n\\bibliography{xinba}\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 61990, "prevtext": "\nWhen $Y$ and $Y'$ are grouped into 1-dimension vectors, we have\n", "index": 87, "text": "\n\\[\n\n MSE =\\frac{1}{{N}}\\left\\| {C - C'} \\right\\|_2^2\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; MSE=\\frac{1}{{N}}\\left\\|{C-C^{\\prime}}\\right\\|_{2}^{2}\" display=\"block\"><mrow><mrow><mi>M</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>E</mi></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>\u2062</mo><msubsup><mrow><mo>\u2225</mo><mrow><mi>C</mi><mo>-</mo><msup><mi>C</mi><mo>\u2032</mo></msup></mrow><mo>\u2225</mo></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></mrow></math>", "type": "latex"}]