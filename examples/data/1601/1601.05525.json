[{"file": "1601.05525.tex", "nexttext": " \n where $\\sigma_j(\\cdot)$, $\\lambda_j(\\cdot)$, are the $j$-th largest singular value, eigenvalue, respectively. The question was recently solved by Drury in the affirmative.  This article revisits Drury's solution. In particular, we simplify the proof for a key auxiliary result  in his solution.  \n \n\\end{abstract}\n\n\\begin{keyword} AM-GM inequality, singular value, eigenvalue.\n  \\MSC[2010] 15A45, 15A60\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\n\\section{Introduction}\n Bhatia has made many fundamental contributions to Matrix Analysis  \\cite{Bha97}. One of his favorite topics is matrix inequalities.  Roughly speaking, matrix inequalities are noncommutative versions of the corresponding scalar inequalities. To get a glimpse of this topic, let us start with a simple example. The simplest AM-GM inequality says that \n \n \n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\\begin{frontmatter}\n\n\\title{On Drury's solution of Bhatia \\& Kittaneh's question\\tnoteref{mytitlenote}}\n\\tnotetext[mytitlenote]{Dedicated to Rajendra Bhatia on the occassion of his 65th birthday.}\n\n\n\\author{Minghua Lin\\fnref{myfootnote}}\n\\address{Department of Mathematics, Shanghai University, Shanghai, 200444, China}\n\\fntext[myfootnote]{Email: mlin87@ymail.com}\n\n \n\n \n\n\\begin{abstract} Let $A, B$ be $n\\times n$ positive semidefinite matrices. Bhatia and Kittaneh  asked whether it is true \n", "index": 1, "text": "$$ \\sqrt{\\sigma_j(AB)}\\le \\frac{1}{2} \\lambda_j(A+B),   \\qquad  j=1, \\ldots, n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\sqrt{\\sigma_{j}(AB)}\\leq\\frac{1}{2}\\lambda_{j}(A+B),\\qquad j=1,\\ldots,n\" display=\"block\"><mrow><mrow><msqrt><mrow><msub><mi>\u03c3</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><mi>B</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msqrt><mo>\u2264</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>\u2062</mo><msub><mi>\u03bb</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>+</mo><mi>B</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>n</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": " \n \nNow it is known that \\cite[p. 107]{Bha07} its most ``direct\" noncommutative version is \n\\begin{eqnarray}\\label{am-gm}\n A, B ~ \\hbox{are $n\\times n$ positive definite matrices} \\implies \\frac{A+B}{2}\\ge A\\sharp B,\n\\end{eqnarray} \nwhere $A\\sharp B:=A^{\\frac{1}{2}}(A^{-\\frac{1}{2}}BA^{-\\frac{1}{2}})^{\\frac{1}{2}}A^{\\frac{1}{2}}$ is called the geometric mean of $A$ and $B$. For two Hermitian matrices $A$ and $B$ of the same size, in this article, we write $A\\ge B$ (or $B\\le A$) to mean that $A-B$ is positive semidefinite. \n\nIf we denote $S:=A\\sharp B$, then $B=SA^{-1}S$. Thus a variant of (\\ref{am-gm}) is the following\n\\begin{eqnarray}\\label{am-gm1}\nA, S ~ \\hbox{are $n\\times n$ positive definite matrices} \\implies  A+SA^{-1}S\\ge 2S.\n\\end{eqnarray}\n\nThere is a long tradition in matrix analysis of comparing eigenvalues or singular values. To proceed, let us fix some notation. The $j$-th largest singular value of  a complex matrix  $A$ is denoted by $\\sigma_j(A)$. If all the eigenvalues of $A$ are real, then we denote its $j$-th largest one by $\\lambda_j(A)$. By  Weyl's Monotonicity Theorem  \\cite[p. 63]{Bha97},  (\\ref{am-gm}) readily implies \n\\begin{eqnarray*}   \\lambda_j(A+B)\\ge  2 \\lambda_j(A\\sharp B), \\qquad  j=1, \\ldots, n. \n\\end{eqnarray*}\n\n\nAs far as the eigenvalues or singular values are considered, there are other versions of ``geometric mean\".  Bhatia and Kittaneh studied this kind of inequalities over a twenty year period \\cite{BK90, BK00, BK08}. Their elegant results include the following: If $A, B$ are $n\\times n$ positive semidefinite matrices, then \n\\begin{eqnarray}\\label{bk1} && \\lambda_j(A+B)\\ge  2\\sqrt{\\lambda_j(AB)}=2\\sigma_j(A^{\\frac{1}{2}}B^{\\frac{1}{2}}); \\\\&&\n\t\\label{bk2}  \\lambda_j(A+B)\\ge   2\\lambda_j(A^{\\frac{1}{2}}B^{\\frac{1}{2}}) \n\\end{eqnarray} for  $j=1, \\ldots, n$.\n\nTo complete the picture in (\\ref{bk1})-(\\ref{bk2}), they asked whether it is true \n\\begin{eqnarray*}\\lambda_j(A+B)\\ge  2\\sqrt{\\sigma_j(AB)}, \\qquad  j=1, \\ldots, n?\n\\end{eqnarray*}  \n\nThis question was recently answered in the affirmative by Drury in his very brilliant work \\cite{Dru12}. The purpose of this expository article is to revisit Drury's solution.   Hopefully, some of our arguments would shed new insights into the beautiful result, which is now a theorm. \n\n\\begin{thm}\\cite{Dru12}  If $A, B$ are $n\\times n$ positive definite semidefinite matrices, then \n\\begin{eqnarray}\n \\label{bkd}   \t\\lambda_j(A+B)\\ge  2\\sqrt{\\sigma_j(AB)}, \\qquad  j=1, \\ldots, n.\n\\end{eqnarray} \n  \\end{thm}\n\n\n \\section{Drury's reduction in proving (\\ref{bkd})}\n Our presentation here is just slightly different from that in \\cite{Dru12}.  \n \n Assume without loss of generality that $A, B$ are positive definite (the general case is by a standard purturbation argument). Fix $r$ in the range $1\\le r\\le n$ and normalize so that \n $\\sigma_r(AB)=1$. Our goal is to  show that  $\\lambda_r(A+B)\\ge 2$. \n \n Note that $\\sigma_r(AB)=1$ is the same as $\\lambda_r(AB^2A)=1$. Consider the spectral decomposition \n", "itemtype": "equation", "pos": -1, "prevtext": " \n where $\\sigma_j(\\cdot)$, $\\lambda_j(\\cdot)$, are the $j$-th largest singular value, eigenvalue, respectively. The question was recently solved by Drury in the affirmative.  This article revisits Drury's solution. In particular, we simplify the proof for a key auxiliary result  in his solution.  \n \n\\end{abstract}\n\n\\begin{keyword} AM-GM inequality, singular value, eigenvalue.\n  \\MSC[2010] 15A45, 15A60\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\n\\section{Introduction}\n Bhatia has made many fundamental contributions to Matrix Analysis  \\cite{Bha97}. One of his favorite topics is matrix inequalities.  Roughly speaking, matrix inequalities are noncommutative versions of the corresponding scalar inequalities. To get a glimpse of this topic, let us start with a simple example. The simplest AM-GM inequality says that \n \n \n", "index": 3, "text": "$$a, b>0 \\implies \\frac{a+b}{2}\\ge \\sqrt{ab}.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"a,b&gt;0\\implies\\frac{a+b}{2}\\geq\\sqrt{ab}.\" display=\"block\"><mrow><mrow><mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow><mo>&gt;</mo><mn>0</mn><mo>\u27f9</mo><mfrac><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow><mn>2</mn></mfrac><mo>\u2265</mo><msqrt><mrow><mi>a</mi><mo>\u2062</mo><mi>b</mi></mrow></msqrt></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": " where $P_1, P_2, \\ldots, P_n$, are orthogonal projections. Then\n $\\lambda_k(AB^2A)\\ge 1$ for $k=1, \\ldots, r$. Define a positive semidefinite \n", "itemtype": "equation", "pos": -1, "prevtext": " \n \nNow it is known that \\cite[p. 107]{Bha07} its most ``direct\" noncommutative version is \n\\begin{eqnarray}\\label{am-gm}\n A, B ~ \\hbox{are $n\\times n$ positive definite matrices} \\implies \\frac{A+B}{2}\\ge A\\sharp B,\n\\end{eqnarray} \nwhere $A\\sharp B:=A^{\\frac{1}{2}}(A^{-\\frac{1}{2}}BA^{-\\frac{1}{2}})^{\\frac{1}{2}}A^{\\frac{1}{2}}$ is called the geometric mean of $A$ and $B$. For two Hermitian matrices $A$ and $B$ of the same size, in this article, we write $A\\ge B$ (or $B\\le A$) to mean that $A-B$ is positive semidefinite. \n\nIf we denote $S:=A\\sharp B$, then $B=SA^{-1}S$. Thus a variant of (\\ref{am-gm}) is the following\n\\begin{eqnarray}\\label{am-gm1}\nA, S ~ \\hbox{are $n\\times n$ positive definite matrices} \\implies  A+SA^{-1}S\\ge 2S.\n\\end{eqnarray}\n\nThere is a long tradition in matrix analysis of comparing eigenvalues or singular values. To proceed, let us fix some notation. The $j$-th largest singular value of  a complex matrix  $A$ is denoted by $\\sigma_j(A)$. If all the eigenvalues of $A$ are real, then we denote its $j$-th largest one by $\\lambda_j(A)$. By  Weyl's Monotonicity Theorem  \\cite[p. 63]{Bha97},  (\\ref{am-gm}) readily implies \n\\begin{eqnarray*}   \\lambda_j(A+B)\\ge  2 \\lambda_j(A\\sharp B), \\qquad  j=1, \\ldots, n. \n\\end{eqnarray*}\n\n\nAs far as the eigenvalues or singular values are considered, there are other versions of ``geometric mean\".  Bhatia and Kittaneh studied this kind of inequalities over a twenty year period \\cite{BK90, BK00, BK08}. Their elegant results include the following: If $A, B$ are $n\\times n$ positive semidefinite matrices, then \n\\begin{eqnarray}\\label{bk1} && \\lambda_j(A+B)\\ge  2\\sqrt{\\lambda_j(AB)}=2\\sigma_j(A^{\\frac{1}{2}}B^{\\frac{1}{2}}); \\\\&&\n\t\\label{bk2}  \\lambda_j(A+B)\\ge   2\\lambda_j(A^{\\frac{1}{2}}B^{\\frac{1}{2}}) \n\\end{eqnarray} for  $j=1, \\ldots, n$.\n\nTo complete the picture in (\\ref{bk1})-(\\ref{bk2}), they asked whether it is true \n\\begin{eqnarray*}\\lambda_j(A+B)\\ge  2\\sqrt{\\sigma_j(AB)}, \\qquad  j=1, \\ldots, n?\n\\end{eqnarray*}  \n\nThis question was recently answered in the affirmative by Drury in his very brilliant work \\cite{Dru12}. The purpose of this expository article is to revisit Drury's solution.   Hopefully, some of our arguments would shed new insights into the beautiful result, which is now a theorm. \n\n\\begin{thm}\\cite{Dru12}  If $A, B$ are $n\\times n$ positive definite semidefinite matrices, then \n\\begin{eqnarray}\n \\label{bkd}   \t\\lambda_j(A+B)\\ge  2\\sqrt{\\sigma_j(AB)}, \\qquad  j=1, \\ldots, n.\n\\end{eqnarray} \n  \\end{thm}\n\n\n \\section{Drury's reduction in proving (\\ref{bkd})}\n Our presentation here is just slightly different from that in \\cite{Dru12}.  \n \n Assume without loss of generality that $A, B$ are positive definite (the general case is by a standard purturbation argument). Fix $r$ in the range $1\\le r\\le n$ and normalize so that \n $\\sigma_r(AB)=1$. Our goal is to  show that  $\\lambda_r(A+B)\\ge 2$. \n \n Note that $\\sigma_r(AB)=1$ is the same as $\\lambda_r(AB^2A)=1$. Consider the spectral decomposition \n", "index": 5, "text": "$$AB^2A=\\sum_{k=1}^n\\lambda_k(AB^2A)P_k,$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"AB^{2}A=\\sum_{k=1}^{n}\\lambda_{k}(AB^{2}A)P_{k},\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mo>\u2062</mo><msup><mi>B</mi><mn>2</mn></msup><mo>\u2062</mo><mi>A</mi></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>\u03bb</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><msup><mi>B</mi><mn>2</mn></msup><mo>\u2062</mo><mi>A</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>P</mi><mi>k</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": " It is easy to see (indeed, from $B^2\\ge B_1^2$) that \n \n", "itemtype": "equation", "pos": -1, "prevtext": " where $P_1, P_2, \\ldots, P_n$, are orthogonal projections. Then\n $\\lambda_k(AB^2A)\\ge 1$ for $k=1, \\ldots, r$. Define a positive semidefinite \n", "index": 7, "text": "$$B_1:=\\left(A^{-1}\\left(\\sum_{k=1}^r P_k\\right)A^{-1}\\right)^{1/2}.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"B_{1}:=\\left(A^{-1}\\left(\\sum_{k=1}^{r}P_{k}\\right)A^{-1}\\right)^{1/2}.\" display=\"block\"><mrow><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>:=</mo><msup><mrow><mo>(</mo><mrow><msup><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><msub><mi>P</mi><mi>k</mi></msub></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": " So we are done if we can show  \\begin{eqnarray}\\label{reduction1}\n  \\lambda_r(A+B_1)\\ge 2. \n \\end{eqnarray}\n \n As $B_1$ has rank $r$, split the underlying space as the direct sum of image and kernel of $B_1$, we may partition comformally $B_1$ and $A$ in the following form\n \n", "itemtype": "equation", "pos": -1, "prevtext": " It is easy to see (indeed, from $B^2\\ge B_1^2$) that \n \n", "index": 9, "text": "$$B=\\left(A^{-1}\\left(\\sum_{k=1}^r\\lambda_k(AB^2A) P_k\\right)A^{-1}\\right)^{1/2}\\ge B_1.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"B=\\left(A^{-1}\\left(\\sum_{k=1}^{r}\\lambda_{k}(AB^{2}A)P_{k}\\right)A^{-1}\\right%&#10;)^{1/2}\\geq B_{1}.\" display=\"block\"><mrow><mrow><mi>B</mi><mo>=</mo><msup><mrow><mo>(</mo><mrow><msup><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mrow><msub><mi>\u03bb</mi><mi>k</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>A</mi><mo>\u2062</mo><msup><mi>B</mi><mn>2</mn></msup><mo>\u2062</mo><mi>A</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mi>P</mi><mi>k</mi></msub></mrow></mrow><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>\u2265</mo><msub><mi>B</mi><mn>1</mn></msub></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": "\n \n Note $AB_1^2A$ is an orthogonal projection of rank $r$, the same is true for $B_1A^2B_1$. Therefore, \n", "itemtype": "equation", "pos": 5132, "prevtext": " So we are done if we can show  \\begin{eqnarray}\\label{reduction1}\n  \\lambda_r(A+B_1)\\ge 2. \n \\end{eqnarray}\n \n As $B_1$ has rank $r$, split the underlying space as the direct sum of image and kernel of $B_1$, we may partition comformally $B_1$ and $A$ in the following form\n \n", "index": 11, "text": "$$B_1=\\begin{pmatrix}\n X & 0 \\\\0& 0\n \\end{pmatrix}, \\  A=\\begin{pmatrix}\n A_{11} & A_{12}\\\\ A_{12}^*&  A_{22}\n \\end{pmatrix}.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"B_{1}=\\begin{pmatrix}X&amp;0\\\\&#10;0&amp;0\\end{pmatrix},\\ A=\\begin{pmatrix}A_{11}&amp;A_{12}\\\\&#10;A_{12}^{*}&amp;A_{22}\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi>X</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo rspace=\"7.5pt\">,</mo><mrow><mi>A</mi><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>A</mi><mn>11</mn></msub></mtd><mtd columnalign=\"center\"><msub><mi>A</mi><mn>12</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup></mtd><mtd columnalign=\"center\"><msub><mi>A</mi><mn>22</mn></msub></mtd></mtr></mtable><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": "\n where $I_r$ is the $r\\times r$ identity matrix. \n \n Finally, observe that \n", "itemtype": "equation", "pos": 5364, "prevtext": "\n \n Note $AB_1^2A$ is an orthogonal projection of rank $r$, the same is true for $B_1A^2B_1$. Therefore, \n", "index": 13, "text": "$$B_1A^2B_1=\\begin{pmatrix}\n X(A_{11}^2+A_{12}A_{12}^*)X & 0\\\\ 0& 0\n \\end{pmatrix}\\implies X(A_{11}^2+A_{12}A_{12}^*)X=I_r$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"B_{1}A^{2}B_{1}=\\begin{pmatrix}X(A_{11}^{2}+A_{12}A_{12}^{*})X&amp;0\\\\&#10;0&amp;0\\end{pmatrix}\\implies X(A_{11}^{2}+A_{12}A_{12}^{*})X=I_{r}\" display=\"block\"><mrow><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>\u2062</mo><msup><mi>A</mi><mn>2</mn></msup><mo>\u2062</mo><msub><mi>B</mi><mn>1</mn></msub></mrow><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mn>11</mn><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi>A</mi><mn>12</mn></msub><mo>\u2062</mo><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>X</mi></mrow></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u27f9</mo><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>A</mi><mn>11</mn><mn>2</mn></msubsup><mo>+</mo><mrow><msub><mi>A</mi><mn>12</mn></msub><mo>\u2062</mo><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>X</mi></mrow><mo>=</mo><msub><mi>I</mi><mi>r</mi></msub></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": "\nTherefore,  (\\ref{reduction1}) would follow from \n  \\begin{eqnarray}\\label{reduction2}\n  \\lambda_r(A_1+B_1)\\ge 2. \n  \\end{eqnarray}\n  \nThus, the remaining effort is made to show   (\\ref{reduction2}), which we formulate as a proposition. \n\\begin{proposition}\\label{p1}\nLet $A_{11}$ and $X$ be $r\\times r$ positive definite matrices and $A_{12}$ is an $(n-r)\\times (n-r)$ matrix such that $X(A_{11}^2+A_{12}A_{12}^*)X=I_r$. Then \\begin{eqnarray}\\label{reduction3}\n \\lambda_r\\begin{pmatrix}\n A_{11}+X & A_{12}\\\\ A_{12}^*&  A_{12}^*A_{11}^{-1}A_{12}  \n \\end{pmatrix}\\ge 2.\n\\end{eqnarray} \n\\end{proposition}\n\n \n \\section{The mystified part}\n In order to prove (\\ref{reduction3}), Drury made the following key observations. \n \\begin{proposition}\\label{p2}\\cite[Proposition 2]{Dru12} Let $M$ and $N$ be $r\\times r$ positive definite matrices. Then \n \\begin{eqnarray*}\n \\lambda_r\\begin{pmatrix}\nM &(M\\sharp N)^{-1}\\\\ (M\\sharp N)^{-1}& N \n \\end{pmatrix}\\ge 2.\n \\end{eqnarray*} \t \\end{proposition}\n \t\\begin{proposition}\\label{p3}\\cite[Theorem 7]{Dru12} Let $L$ and $M$ be $r\\times r$ positive definite matrices, and let $Z$ be an $r\\times r$ matrix such that $ML(I+ZZ^*)LM=I_r$. Then \n \t\t\\begin{eqnarray} \\label{reduction4} \\lambda_r\\begin{pmatrix}\n \t\t\t\tL+M & LZ\\\\ Z^*L&  Z^*LZ \n \t\t\t\\end{pmatrix}\\ge 2.\n \t\t\\end{eqnarray} \t \\end{proposition}\n \t\n \t \n The way that Drury proved (\\ref{reduction4}) is by showing that $T:=\\begin{pmatrix}\n L+M & LZ\\\\ Z^*L&  Z^*LZ \n \\end{pmatrix}$ and $R:=\\begin{pmatrix}\n M &(M\\sharp N)^{-1}\\\\ (M\\sharp N)^{-1}& N \n \\end{pmatrix}$ have the same characteristic polynomial, and so the eigenvalues of $R$ and $T$ coincide.  As explained in \\cite{Dru12a}, this connection (between $R$ and $T$) is mystified. Formally, the  mystified part also comes from $R$ and $T$ themselves, indeed, $T$ is always positive semidefinite while  $R$ is not!\n \n In order to apply Proposition \\ref{p3} to Proposition \\ref{p1}, Drury discussed three possible relations between the size $n$ and $r$. Our proof of Proposition \\ref{p1} in the next section allows us to skip this discussion on the size. \n \n   \\section{Proof of Proposition \\ref{p1}}\n   The following lemma slightly generalizes Proposition \\ref{p2} in form. \n   \\begin{lemma} \\label{lem1} Let $X$ be a $r\\times r$ positive definite matrix and let $S$ be a  $r\\times r$ nonsingular matrix. Then \n   \t\\begin{eqnarray*}\n   \t\t\\lambda_r\\begin{pmatrix}\n   \t\t\tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t\t\\end{pmatrix}\\ge 2.\n   \t\\end{eqnarray*}    \t \n   \\end{lemma}\n   \\begin{proof}\n   \t Consider the polar decomposition of $S$, $S=U|S|$, where $U$ is unitary and $|S|=(S^*S)^{\\frac{1}{2}}$. The matrix $\\begin{pmatrix}\n   \t \tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t \\end{pmatrix}$ is unitarily similar to \n   \t \n", "itemtype": "equation", "pos": 5564, "prevtext": "\n where $I_r$ is the $r\\times r$ identity matrix. \n \n Finally, observe that \n", "index": 15, "text": "$$A\\ge A_1:=\\begin{pmatrix}\n \tA_{11} & A_{12}\\\\ A_{12}^*&   \tA_{12}^*A_{11}^{-1}A_{12}\n \\end{pmatrix}.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"A\\geq A_{1}:=\\begin{pmatrix}A_{11}&amp;A_{12}\\\\&#10;A_{12}^{*}&amp;A_{12}^{*}A_{11}^{-1}A_{12}\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mi>A</mi><mo>\u2265</mo><msub><mi>A</mi><mn>1</mn></msub><mo>:=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msub><mi>A</mi><mn>11</mn></msub></mtd><mtd columnalign=\"center\"><msub><mi>A</mi><mn>12</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup></mtd><mtd columnalign=\"center\"><mrow><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup><mo>\u2062</mo><msubsup><mi>A</mi><mn>11</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi>A</mi><mn>12</mn></msub></mrow></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": "\n   \t As $P:=\\frac{1}{2}\\begin{pmatrix}\n   \t I_r\\\\ I_r\n   \t \\end{pmatrix}$ is a partial isometry, \n   \t \n   \t  \t\\begin{eqnarray*}\n   \t  \t\t\\lambda_r\\begin{pmatrix}\n   \t  \t\t\tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t  \t\t\\end{pmatrix}&=&\\lambda_r\\begin{pmatrix}\n   \t  \t\t|S|X^{-1}|S|& |S|^{-1}\\\\|S|^{-1}& X\n   \t  \t\\end{pmatrix}\\\\&\\ge& \\lambda_r \\left(P^*\\begin{pmatrix}\n   \t  \t|S|X^{-1}|S|& |S|^{-1}\\\\|S|^{-1}& X\n   \t  \\end{pmatrix}P\\right)\\\\&=&\\lambda_r\\left(\\frac{X+|S|X^{-1}|S|}{2}+|S|^{-1}\\right)\\\\&\\ge& \\lambda_r(|S|+|S|^{-1})  \\ge 2.  \\qquad \\hbox{by (\\ref{am-gm1})}\n   \t  \t\\end{eqnarray*}  \n   \t  \tThe required result follows. \n   \\end{proof}\n   \n   Now we are ready to give a simpler proof of  Proposition \\ref{p1}. \n   \n   ~\n   \n   \\noindent\n   {\\it Proof. } Consider the factorization  \n", "itemtype": "equation", "pos": 8422, "prevtext": "\nTherefore,  (\\ref{reduction1}) would follow from \n  \\begin{eqnarray}\\label{reduction2}\n  \\lambda_r(A_1+B_1)\\ge 2. \n  \\end{eqnarray}\n  \nThus, the remaining effort is made to show   (\\ref{reduction2}), which we formulate as a proposition. \n\\begin{proposition}\\label{p1}\nLet $A_{11}$ and $X$ be $r\\times r$ positive definite matrices and $A_{12}$ is an $(n-r)\\times (n-r)$ matrix such that $X(A_{11}^2+A_{12}A_{12}^*)X=I_r$. Then \\begin{eqnarray}\\label{reduction3}\n \\lambda_r\\begin{pmatrix}\n A_{11}+X & A_{12}\\\\ A_{12}^*&  A_{12}^*A_{11}^{-1}A_{12}  \n \\end{pmatrix}\\ge 2.\n\\end{eqnarray} \n\\end{proposition}\n\n \n \\section{The mystified part}\n In order to prove (\\ref{reduction3}), Drury made the following key observations. \n \\begin{proposition}\\label{p2}\\cite[Proposition 2]{Dru12} Let $M$ and $N$ be $r\\times r$ positive definite matrices. Then \n \\begin{eqnarray*}\n \\lambda_r\\begin{pmatrix}\nM &(M\\sharp N)^{-1}\\\\ (M\\sharp N)^{-1}& N \n \\end{pmatrix}\\ge 2.\n \\end{eqnarray*} \t \\end{proposition}\n \t\\begin{proposition}\\label{p3}\\cite[Theorem 7]{Dru12} Let $L$ and $M$ be $r\\times r$ positive definite matrices, and let $Z$ be an $r\\times r$ matrix such that $ML(I+ZZ^*)LM=I_r$. Then \n \t\t\\begin{eqnarray} \\label{reduction4} \\lambda_r\\begin{pmatrix}\n \t\t\t\tL+M & LZ\\\\ Z^*L&  Z^*LZ \n \t\t\t\\end{pmatrix}\\ge 2.\n \t\t\\end{eqnarray} \t \\end{proposition}\n \t\n \t \n The way that Drury proved (\\ref{reduction4}) is by showing that $T:=\\begin{pmatrix}\n L+M & LZ\\\\ Z^*L&  Z^*LZ \n \\end{pmatrix}$ and $R:=\\begin{pmatrix}\n M &(M\\sharp N)^{-1}\\\\ (M\\sharp N)^{-1}& N \n \\end{pmatrix}$ have the same characteristic polynomial, and so the eigenvalues of $R$ and $T$ coincide.  As explained in \\cite{Dru12a}, this connection (between $R$ and $T$) is mystified. Formally, the  mystified part also comes from $R$ and $T$ themselves, indeed, $T$ is always positive semidefinite while  $R$ is not!\n \n In order to apply Proposition \\ref{p3} to Proposition \\ref{p1}, Drury discussed three possible relations between the size $n$ and $r$. Our proof of Proposition \\ref{p1} in the next section allows us to skip this discussion on the size. \n \n   \\section{Proof of Proposition \\ref{p1}}\n   The following lemma slightly generalizes Proposition \\ref{p2} in form. \n   \\begin{lemma} \\label{lem1} Let $X$ be a $r\\times r$ positive definite matrix and let $S$ be a  $r\\times r$ nonsingular matrix. Then \n   \t\\begin{eqnarray*}\n   \t\t\\lambda_r\\begin{pmatrix}\n   \t\t\tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t\t\\end{pmatrix}\\ge 2.\n   \t\\end{eqnarray*}    \t \n   \\end{lemma}\n   \\begin{proof}\n   \t Consider the polar decomposition of $S$, $S=U|S|$, where $U$ is unitary and $|S|=(S^*S)^{\\frac{1}{2}}$. The matrix $\\begin{pmatrix}\n   \t \tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t \\end{pmatrix}$ is unitarily similar to \n   \t \n", "index": 17, "text": "$$\\begin{pmatrix}U^*\n   \t SX^{-1}S^*U& U^*(S^{-1})^*\\\\S^{-1}U& X\n   \t \\end{pmatrix}=\\begin{pmatrix}\n   \t |S|X^{-1}|S|& |S|^{-1}\\\\|S|^{-1}& X\n   \t \\end{pmatrix}.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\begin{pmatrix}U^{*}SX^{-1}S^{*}U&amp;U^{*}(S^{-1})^{*}\\\\&#10;S^{-1}U&amp;X\\end{pmatrix}=\\begin{pmatrix}|S|X^{-1}|S|&amp;|S|^{-1}\\\\&#10;|S|^{-1}&amp;X\\end{pmatrix}.\" display=\"block\"><mrow><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><msup><mi>U</mi><mo>*</mo></msup><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><msup><mi>X</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msup><mi>S</mi><mo>*</mo></msup><mo>\u2062</mo><mi>U</mi></mrow></mtd><mtd columnalign=\"center\"><mrow><msup><mi>U</mi><mo>*</mo></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>S</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>*</mo></msup></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msup><mi>S</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>U</mi></mrow></mtd><mtd columnalign=\"center\"><mi>X</mi></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mrow><mo stretchy=\"false\">|</mo><mi>S</mi><mo stretchy=\"false\">|</mo></mrow><mo>\u2062</mo><msup><mi>X</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mi>S</mi><mo stretchy=\"false\">|</mo></mrow></mrow></mtd><mtd columnalign=\"center\"><msup><mrow><mo stretchy=\"false\">|</mo><mi>S</mi><mo stretchy=\"false\">|</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><msup><mrow><mo stretchy=\"false\">|</mo><mi>S</mi><mo stretchy=\"false\">|</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd><mtd columnalign=\"center\"><mi>X</mi></mtd></mtr></mtable><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05525.tex", "nexttext": "\n   Clearly, $\\begin{pmatrix}\n   \tA_{11}+X & A_{12}\\\\ A_{12}^*&  A_{12}^*A_{11}^{-1}A_{12}  \n   \\end{pmatrix}$ is unitarily similar to  \\begin{eqnarray*}\n   \\begin{pmatrix}\n   \tA_{11}^{\\frac{1}{2}}&X^{\\frac{1}{2}}\\\\ A_{12}^*A_{11}^{-\\frac{1}{2}}&  0\n   \\end{pmatrix}^*\\begin{pmatrix}\n   A_{11}^{\\frac{1}{2}}&X^{\\frac{1}{2}}\\\\ A_{12}^*A_{11}^{-\\frac{1}{2}}&  0\n\\end{pmatrix}&=&\\begin{pmatrix}\nA_{11}+A_{11}^{-\\frac{1}{2}}A_{12}A_{12}^*A_{11}^{-\\frac{1}{2}}& A_{11}^{\\frac{1}{2}}X^{\\frac{1}{2}}\\\\ X_{11}^{\\frac{1}{2}}A^{\\frac{1}{2}}&  X\n\\end{pmatrix}\\\\&=&\\begin{pmatrix}\n A_{11}^{-\\frac{1}{2}}X^{-2}A_{11}^{-\\frac{1}{2}}& A_{11}^{\\frac{1}{2}}X^{\\frac{1}{2}}\\\\ X_{11}^{\\frac{1}{2}}A^{\\frac{1}{2}}&  X\n\t\\end{pmatrix}.\n   \\end{eqnarray*} \n   Now setting $S=A_{11}^{-\\frac{1}{2}}X^{-\\frac{1}{2}}$ in Lemma \\ref{lem1}  yields the desired result. \\qed\n   \n   \\section{A conjecture}\n A weighted version of  (\\ref{bk1}) is known. That is, if $A, B$ are $n\\times n$ positive  semidefinite matrices, then   for any $t\\in [0, 1]$ and   $j=1, \\ldots, n$ \n \\begin{eqnarray}\\label{ando} && \\lambda_j((1-t)A+tB)\\ge  \\sqrt{\\lambda_j(A^{2(1-t)}B^{2t})}=\\sigma_j(A^{1-t}B^{t}).\n \\end{eqnarray}   Inequality  (\\ref{ando}) is due to Ando \\cite{Ando95}. With \\ref{ando}), it is not hard to present a weighted version of (\\ref{bk2}).\n \n   \\begin{proposition}\\label{p4}  If $A, B$ are $n\\times n$ positive  semidefinite matrices, then   for any $t\\in [0, 1]$ and   $j=1, \\ldots, n$ \n   \\begin{eqnarray}\\label{lin} \\lambda_j((1-t)A+tB)\\ge    \\lambda_j(A^{1-t}B^{t}). \n   \t\t\\end{eqnarray}\n     \\end{proposition}\n  \\begin{proof} By (\\ref{ando}) and the matrix convexity of the square function,\n  \t    \\begin{eqnarray*} \\lambda_j(A^{1-t}B^{t})&=&\\sigma_j^2(A^{(1-t)/2}B^{t/2})\\\\&\\le&\\lambda_j((1-t)A^{1/2}+tB^{1/2})^2 \\\\ &\\le& \\lambda_j((1-t)A+tB). \n  \t    \\end{eqnarray*}\n  \\end{proof}\nWe conclude the paper with the following conjecture \\begin{conj}\n\t  If $A, B$ are $n\\times n$ positive definite semidefinite matrices, then for any $t\\in [0, 1]$\n \t\\begin{eqnarray*}\n    \t\\lambda_j((1-t)A+tB)\\ge   \\sqrt{\\sigma_j(A^{2(1-t)}B^{2t})}, \\qquad  j=1, \\ldots, n.\n \t\\end{eqnarray*} \n \\end{conj}\n    The present method of proof does not seem to lead to a solution of this conjecture.  \n    \n \\section*{Acknowledgement} The author thanks some helpful conversations with T. Ando and P. van den Driessche. \n \n\n\\begin{thebibliography}{11}\n \\bibitem {Ando95}\tT. Ando, Matrix Young inequalities, Oper. Theory Adv. Appl. 75 (1995) 33-38.\n\t \n\t \\bibitem {Bha97} R. Bhatia, Matrix Analysis, GTM 169, Springer-Verlag, New York,\t 1997.\n\t \n\t \\bibitem {Bha07} R. Bhatia, Positive Definite Matrices, Princeton University Press, Princeton, 2007.\n\t \\bibitem {BK90} R. Bhatia, F. Kittaneh, On the singular values of a product of operators, SIAM J. Matrix Anal. Appl. 11 (1990) 272-277.\n\t \\bibitem {BK00}   R. Bhatia, F. Kittaneh, Notes on matrix arithmetic\u00e2\u0080\u0093geometric mean inequalities, Linear Algebra Appl. 308 (2000) 203-211.\n  \\bibitem {BK08}  R. Bhatia, F. Kittaneh, The matrix arithmetic\u00e2\u0080\u0093geometric mean inequality revisited, Linear Algebra Appl. 428 (2008) 2177-2191.\n  \\bibitem {Dru12}  S. W. Drury, On a question of Bhatia and Kittaneh, Linear Algebra Appl. 437 (2012) 1955-1960.\n  \\bibitem {Dru12a}   S. W. Drury, An operator Arithmetic-Geometric mean inequality, available at \\href{http://www.math.mcgill.ca/drury/research/bhatiakittaneh/BKBlurb.html}{\\url{http://www.math.mcgill.ca/drury/research/bhatiakittaneh/BKBlurb.html}} \n\\end{thebibliography}\n\n\n", "itemtype": "equation", "pos": 9372, "prevtext": "\n   \t As $P:=\\frac{1}{2}\\begin{pmatrix}\n   \t I_r\\\\ I_r\n   \t \\end{pmatrix}$ is a partial isometry, \n   \t \n   \t  \t\\begin{eqnarray*}\n   \t  \t\t\\lambda_r\\begin{pmatrix}\n   \t  \t\t\tSX^{-1}S^*& (S^{-1})^*\\\\S^{-1}& X\n   \t  \t\t\\end{pmatrix}&=&\\lambda_r\\begin{pmatrix}\n   \t  \t\t|S|X^{-1}|S|& |S|^{-1}\\\\|S|^{-1}& X\n   \t  \t\\end{pmatrix}\\\\&\\ge& \\lambda_r \\left(P^*\\begin{pmatrix}\n   \t  \t|S|X^{-1}|S|& |S|^{-1}\\\\|S|^{-1}& X\n   \t  \\end{pmatrix}P\\right)\\\\&=&\\lambda_r\\left(\\frac{X+|S|X^{-1}|S|}{2}+|S|^{-1}\\right)\\\\&\\ge& \\lambda_r(|S|+|S|^{-1})  \\ge 2.  \\qquad \\hbox{by (\\ref{am-gm1})}\n   \t  \t\\end{eqnarray*}  \n   \t  \tThe required result follows. \n   \\end{proof}\n   \n   Now we are ready to give a simpler proof of  Proposition \\ref{p1}. \n   \n   ~\n   \n   \\noindent\n   {\\it Proof. } Consider the factorization  \n", "index": 19, "text": "$$\\begin{pmatrix}\n   A_{11}+X & A_{12}\\\\ A_{12}^*&  A_{12}^*A_{11}^{-1}A_{12}  \n   \\end{pmatrix}=\\begin{pmatrix}\n   A_{11}^{\\frac{1}{2}}&X^{\\frac{1}{2}}\\\\ A_{12}^*A_{11}^{-\\frac{1}{2}}&  0\n   \\end{pmatrix}\\begin{pmatrix}\n   A_{11}^{\\frac{1}{2}}&X^{\\frac{1}{2}}\\\\ A_{12}^*A_{11}^{-\\frac{1}{2}}&  0\n   \\end{pmatrix}^*.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\begin{pmatrix}A_{11}+X&amp;A_{12}\\\\&#10;A_{12}^{*}&amp;A_{12}^{*}A_{11}^{-1}A_{12}\\end{pmatrix}=\\begin{pmatrix}A_{11}^{%&#10;\\frac{1}{2}}&amp;X^{\\frac{1}{2}}\\\\&#10;A_{12}^{*}A_{11}^{-\\frac{1}{2}}&amp;0\\end{pmatrix}\\begin{pmatrix}A_{11}^{\\frac{1}{%&#10;2}}&amp;X^{\\frac{1}{2}}\\\\&#10;A_{12}^{*}A_{11}^{-\\frac{1}{2}}&amp;0\\end{pmatrix}^{*}.\" display=\"block\"><mrow><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><msub><mi>A</mi><mn>11</mn></msub><mo>+</mo><mi>X</mi></mrow></mtd><mtd columnalign=\"center\"><msub><mi>A</mi><mn>12</mn></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup></mtd><mtd columnalign=\"center\"><mrow><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup><mo>\u2062</mo><msubsup><mi>A</mi><mn>11</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi>A</mi><mn>12</mn></msub></mrow></mtd></mtr></mtable><mo>)</mo></mrow><mo>=</mo><mrow><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msubsup><mi>A</mi><mn>11</mn><mfrac><mn>1</mn><mn>2</mn></mfrac></msubsup></mtd><mtd columnalign=\"center\"><msup><mi>X</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup><mo>\u2062</mo><msubsup><mi>A</mi><mn>11</mn><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup></mrow></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><msubsup><mi>A</mi><mn>11</mn><mfrac><mn>1</mn><mn>2</mn></mfrac></msubsup></mtd><mtd columnalign=\"center\"><msup><mi>X</mi><mfrac><mn>1</mn><mn>2</mn></mfrac></msup></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><msubsup><mi>A</mi><mn>12</mn><mo>*</mo></msubsup><mo>\u2062</mo><msubsup><mi>A</mi><mn>11</mn><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msubsup></mrow></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>)</mo></mrow><mo>*</mo></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]