[{"file": "1601.01396.tex", "nexttext": "\n\nMore formally, the result to an OSCP query is the single best location \n$\\mu^* \\in V$ where all travelers should meet so as to minimize the cost \nfunction $\\sigma_u$, i.e., $\\mu^* = \\textrm{argmin}_{u \\in V} \\sigma_u$. \nIf the goal is to minimize the \\emph{maximal travel distance} we define $\\sigma_u$ as:\n\\begin{eqnarray}\n  \\sigma_{u}^{max}= \\max_i \\{\\lambda_{ii} d_{s_i u}\n\t\t+ d_{u\\omega} \\prod_{j \\neq i} \\lambda_{ij}\\}\n\t\t\\label{eq:mincostmaxfunction} \n\\end{eqnarray}\nOtherwise, if our target is to minimize the \\emph{average travel distance} we define $\\sigma_u$ as:\n\\begin{eqnarray}\n  \\sigma_{u}^{avg} = \\frac{1}{n} \\sum_i \\{\\lambda_{ii} d_{s_i u}  \n\t\t+ d_{u\\omega} \\prod_{j \\neq i} \\lambda_{ij}\\}\n\t\t\\label{eq:mincostsumfunction} \n\\end{eqnarray}\n\n\n\n\n\n\n\nThe OMCP, however, allows for {\\em multiple} connecting points.  In order to understand how the cost of \na solution to the OMCP is obtained, let us discuss the solution shown in Figure~\\ref{fig:problem}(c) in detail.\n\nFirst, traveler $t_1$ meets traveler $t_2$ at connecting point $x_1$ and they proceed together until $x_0$ \n(where traveler $t_3$ joins the group) at summed cost \n$d_{s_1 x_1} \\lambda_{1 1} + d_{s_2 x_1} \\lambda_{2 2} + (\\lambda_{1 2} + \\lambda_{2 1}) d_{x_1 x_0} $. \n\n\n\n\n\n\n\n\n\n\nIn order to meet $t_1$ and $t_2$ at connecting point $x_0$ traveler $t_3$ needs to travel from $s_3$ \nto $x_0$ by him/herself at a cost equal to \n$\nd_{s_3 x_0} \\lambda_{3 3}\n$.\nThen, all three travelers proceed together from $x_0$ to the destination $\\omega$ at a cost equal to \n$\n(\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_0 \\omega}\n$.\n\nIt is noteworthy that $x_0$ is essentially the solution of another OSCP query, where the destination is \n$\\omega$,\ntraveler $t_3$ leaves from $s_3$ and a ``super-traveler'' representing travelers $t_1$ and $t_2$ \n{\\em together}  leaving from $x_0$ (where they were connected).\nHow to derive the affinity factor for such a ``super-traveler'' though? For \\emph{min-avg} ranking criteria \n$\\lambda_{1 2}$ + $\\lambda_{2 1}$ quantifies how much the ``super-traveler'' likes to travel alone \nas if a single traveler.\nThis is intuitive as it combines how $t_1$ likes to travel with $t_2$ and vice-versa.\n\n\n\n\nTherefore, the average travel cost of the OMCP solution\nshown in Figure~\\ref{fig:problem}(c) is equal to \n$\n\\frac{1}{3} (d_{s_1 x_1} \\lambda_{1 1} + d_{s_2 x_1} \\lambda_{2 2} + d_{s_3 x_0} \\lambda_{3 3} \n+ (\\lambda_{1 2} + \\lambda_{2 1}) d_{x_1 x_0} +   \n(\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_0 \\omega})\n$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{table}[!htbp]\n\\centering\n\\begin{tabular}{c c c}\n\\hline\n\\textbf{\\small{Notation}} & \\textbf{\\small{Description}} \\\\\n\\hline\n$t_1, t_2, \\cdots, t_n$         & \\small{$t_i$ stands for the $i$-th traveler.} \\\\\n$s_1, s_2, \\cdots, s_n$         & \\small{$s_i$ stands for the starting location of traveler $t_i$.} \\\\\n$\\omega$                        & \\small{common destination shared by all travelers.} \\\\\n$d_{uv}$                        & \\small{minimum cost for traveling from node $u$ to $v$.} \\\\\n$\\lambda_{ij}$                  & \\small{captures how much traveler $t_i$ enjoys $t_j$'s company.} \\\\\n$p$                             & \\small{a partitioning of travelers into groups and subgroups.} \\\\\n$\\mu_p$                         & \\small{connecting point where the elements of group $p$ meet.} \\\\\n$\\sigma_u$                      & \\small{aggregated score for point $u$ of the road network.} \\\\\n$\\sigma_p$                      & \\small{aggregated score that grouping $p$ achieves.} \\\\\n\n\n\\hline\n\\end{tabular}\n\\caption{Notation and terminology.}\n\\label{table:terminology}\n\\end{table}\n\n\n\n\nWe can generalize the reasoning above as follows.  \nLet $S_{i k}$ the $k$-th connecting group where traveler $t_i$ appears; and let us assume that there are $G$ such  groups.  \nFurther, we denote as $\\mu_{S_{i k}}$ the location (node) in the network, where this connection takes place.\nNote that $\\mu_{S_{i 0}} = s_i, \\forall t_i$, i.e., $t_i$'s starting position.\nBy construction, we have that \n$S_{i_0} \\subset S_{i 1} \\subset S_{i 2} \\subset \\cdots \\subset S_{i m_i}, \\forall t_i$.  \nOnce a traveler joins a group it never leaves it, and at each connection point at least one new traveler or possibly a subgroup of travelers, joins a group.\nWith this in mind the cost of the OMCP query can be broken down into the following components.\n\nWe know that all travelers will travel by themselves from their starting location to their first connecting point, thus \ncontributing each with cost $d_{s_i \\mu_{S_{i 1}}} \\lambda_{i i}$.\n\nAfter traveler $t_i$ joins its $k$-th connecting group, it moves to the next connecting point, i.e., \n$S_{i (k+1)}$.  \nHowever, we need to take into account that all travelers in that group will be traveling together, \ntherefore, such group movement will yield for each traveler $t_i \\in S_{i (k+1)}$ a cost equal to \n$\nd_{\\mu_{S_{i k}} \\mu_{S_{i (k+1)}}} \\prod_{\\substack{t_j \\in S_{ik}\\\\ t_i \\neq t_j}} \\lambda_{i j}\n$.\n\nIt leads that a route plan costs on average for each traveler:\n\n", "itemtype": "equation", "pos": 8716, "prevtext": "\n\\maketitle\n\n\n\\begin{abstract}\nIn this paper we consider a set of travelers, starting from likely different locations \ntowards a common destination within a road network, and propose solutions to find the \noptimal connecting points for them.  A connecting point is a vertex of the network where \na subset of the travelers meet and continue traveling together towards the next connecting \npoint or the destination.  The notion of optimality is with regard to a given aggregated \ntravel cost, e.g., travel distance or shared fuel cost.  This problem by itself is new \nand we make it even more interesting (and complex) by considering affinity factors among \nthe users, i.e., how much a user likes to travel together with another one. This plays a \nfundamental role in determining where the connecting points are and how subsets of travelers \nare formed.  We propose three methods for addressing this problem, one that relies on a fast \nand greedy approach that finds a sub-optimal solution, and two others that yield globally \noptimal solution.  We evaluate all proposed approaches through experiments, where collections \nof real datasets are used to assess the trade-offs, behavior and characteristics of each method.\n\\end{abstract}\n\n\n\\section{Introduction}\n\nConsider a group of travelers starting \nfrom, likely different, points in a (city) road network (e.g., their workplaces) towards a common destination \n(e.g., a restaurant)  where\ntraversing an edge of the network incurs a cost (e.g., distance, travel time or fuel cost).  \nWhile they can each travel on their own following their respective most cost effective \nroutes, it may be the case that they might prefer to travel alongside other travelers, e.g., ``time flies \nwhen in good company.''  Then it is possible that travelers may accept to travel using less \nefficient paths in exchange for having company. \nThis leads us to what we call the {\\em Optimal Multiple Connecting Points} (OMCP) query.\nThis query returns the optimal {\\em connecting points}\nwhere subsets of travelers can connect and form groups of increasing sizes until \nthey all reach the destination.  \nThe underlying goal in this query is to find routes that\nminimize an aggregate cost, e.g.,  the maximum or the average cost \ntravelers have to incur in terms of the recommended route from their \nstarting locations to the common destination.\n\n\n\n\nThis type of query, which one can classify as belonging to the class of Trip Planning Queries, \nbecomes more relevant and applicable with the proliferation of \ngeo-spatial applications, location- and mobility-aware handheld devices \ndictating a trend towards the development of efficient solutions for problems \nstated on actual road networks. Apart from portable devices, countless \napplications have been launched on the web, developed over the Google Maps \nand OpenStreetMap platforms. The provided APIs operate on official data for \nthe former, or data gathered through crowdsourcing for the latter; so as to \nallow the implementation of web mapping services with cutting edge development \ntools, such as Javascript, Ajax and XML at the front-end. Our own flavor \naddressing the problem studied here relies on the Google Maps API and also employs \nJava Server Pages (JSPs). It is available at \\url{http://connect.cs.ualberta.ca/omcp/} \nwith an elegant and intuitive interface for interacting with the users.\n\nFigure~\\ref{fig:problem} illustrates three different scenarios for  three \ntravelers. First, let the starting locations $s_1, s_2$ and $s_3$ be where \nthe travelers are initially located. Figure~\\ref{fig:problem}(a) depicts the \ncase where all travelers follow their respective shortest path to the common \ndestination independently of each other. \nIn Figure~\\ref{fig:problem}(b), we depict the case \nwhere all travelers meet at an intermediate location (node $x_1$) before \ncontinuing their journey to the final destination $\\omega$.  Depending on the \naffinity parameters the second route plan can be more preferable in terms of \nthe total aggregated cost arising from the suitable cost function that provides \na direct way to quantify this.  Finally, in Figure \n\\ref{fig:problem}(c), travelers $t_1$ and $t_2$ meet in $x_1$ before encountering \ntraveler $t_3$ in $x_0$, and then all proceed to their common destination, \nnode $\\omega$.\n\n\n\\input{initiation.tex}\n\n\nWe propose three different schemes to solve OMCP queries.\n\nThe first one relies on a fast, greedy approach that finds a sub-optimal \nsolution.  The two other ones finds globally optimal solutions, the first one\nprunes candidate solutions based on cost bounds over the refinements of \nan examined route, whereas the second is more aggressive, it employs a \nbest-first search approach so as to process the most promising \nroutes first, thus aiming at enforcing stricter bounds.\n\n\n\n\n\n\n\n\n\n\n\nIn summary, the main contributions we offer in this paper are the following:\n\n\\begin{packed_item}\n\\item We define, for the first time, OMCP queries in road networks.\n\\item We take the affinity between users into account in the computation of the aggregate travel cost.\n\\item We explore several interesting properties of the problem in order to reduce the search space.\n\\item We propose and evaluate three novel approaches for processing OMCP queries.\n\\item We implement a framework leveraging the methods presented here, and make it available on-line \nat \\url{http://connect.cs.ualberta.ca/omcp/}.\n\\end{packed_item}\n\nThis paper is structured as follows: in Section \\ref{sec:problem}, we formally \npose the problem tackled in this paper; in Section \\ref{sec:processing}, we \npropose a paradigm for processing the addressed query type; in Section \n\\ref{sec:evaluation}, we evaluate our methods; in Section \\ref{sec:related} \nwe discuss the relevant literature, and finally, in Section \\ref{sec:conclusion}, \nwe summarize our contributions.\n\n\n\\section{Problem Statement}\n\\label{sec:problem}\n\n\n\n\n\n\n\n  \n\n\nLet us assume: \n({\\it i}) a road network, modeled as a graph $G(V,E)$, where $d_{xy}$ denotes the\ncost to traverse the shortest path in $G$ connecting the nodes $x$ and $y$ in $V$,\n({\\it ii}) a set $T= \\{t_1, t_2, \\cdots, t_n\\}$ of $n$ travelers and their respective \nstarting locations (i.e., nodes in $V$) $S = \\{s_1, s_2, \\cdots, s_n\\}$,\n({\\it iii}) a set of affinity factors $\\lambda_{ij}$ reflecting how much traveler \n$i$ enjoys the company of traveler $j$, \nand ({\\it iv}) a common destination $\\omega$.\nWe also assume that \n$\\lambda_{ij}$, with $0 \\leq \\lambda_{ij} \\leq 1$ and $\\sum_{j=1}^n \\lambda_{ij} = 1, \\forall i$.\nIn particular, the lower the $\\lambda_{ij}$ value \nthe more the enjoyment $i$ \nhas by traveling together with $j$. \nThat is, we make the reasonable assumption that \n$\\lambda_{ij}$ serves as a relaxing factor for traveler $i$ when \naccompanied by $j$, that is, when traveling together over a path $uv \\in G$ the \ncost $d_{uv}$ is \\emph{perceived} as $\\lambda_{ij} d_{uv} \\leq d_{uv}$. \n\nBefore we define the OMCP query, let us define a restricted version thereof, namely the \nOptimal {\\em Single} Connecting Point (OSCP) query \\cite{oscp}.  \nIn fact, we will build upon a solution to the latter to solve the former.\nWe illustrate a possible solution to an OSCP query in Figure \\ref{fig:problem}(b), where the \ntravelers from starting locations $s_1$, $s_2$ and $s_3$ meet at $x_1$ before proceeding \nto $\\omega$.  The cost of that solution can be build as follows.\n\nFirst $t_1$, $t_2$ and $t_3$ travel by themselves from their\nstarting locations to $x_1$, the connecting point \nwhere the group is formed before they continue together to their common destination $\\omega$. \nAs such, the travel cost from the starting locations to the \nconnection location are multiplied by a factor representing how much each traveler enjoys \ntraveling by him/herself, i.e., $\\lambda_{1 1}$, $\\lambda_{2 2}$ and $\\lambda_{3 3}$, \nfor each of the travelers $t_1$, $t_2$ and $t_3$, respectively, yielding\n$\n\\lambda_{1 1} d_{s_1 x_1} + \\lambda_{2 2} d_{s_2 x_1} + \\lambda_{3 3} d_{s_3 x_1} \n$.\nNext, we need to account for the average travel cost for all travelers from the connecting point $x_1$ towards\n$\\omega$, \n$\n\\frac{1}{3} (\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_1 \\omega}\n$.\nNote that the multiplied affinity factors reflect how $d_{x_1 \\omega}$ is {\\em perceived} by each \ntraveler when travelling with the\nothers.  For instance, when traveler $t_1$ travels with\n$t_2$ and $t_3$, $d_{x_1 \\omega}$ ``feels like'' $\\lambda_{1 2} \\lambda_{1 3} d_{x_1 \\omega} < d_{x_1 \\omega}$ for that particular traveler.\nIt follows that the average cost of the route plan shown in Figure \\ref{fig:problem}(b) is equal to:\n\n", "index": 1, "text": "\\begin{equation}\n\\begin{split}\n\\sigma_{x_1}  = \\frac{1}{3} & (\\lambda_{1 1} d_{s_1 x_1} + \\lambda_{2 2} d_{s_2 x_1} + \\lambda_{3 3} d_{s_3 x_1}   + \\\\\n           & (\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_1 \\omega})\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle\\sigma_{x_{1}}=\\frac{1}{3}&amp;\\displaystyle(\\lambda_{11%&#10;}d_{s_{1}x_{1}}+\\lambda_{22}d_{s_{2}x_{1}}+\\lambda_{33}d_{s_{3}x_{1}}+\\\\&#10;&amp;\\displaystyle(\\lambda_{12}\\lambda_{13}+\\lambda_{21}\\lambda_{23}+\\lambda_{31}%&#10;\\lambda_{32})d_{x_{1}\\omega})\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><msub><mi>\u03c3</mi><msub><mi>x</mi><mn>1</mn></msub></msub><mo>=</mo><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></mtd><mtd columnalign=\"left\"><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>11</mn></msub><msub><mi>d</mi><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>\u03bb</mi><mn>22</mn></msub><msub><mi>d</mi><mrow><msub><mi>s</mi><mn>2</mn></msub><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>\u03bb</mi><mn>33</mn></msub><msub><mi>d</mi><mrow><msub><mi>s</mi><mn>3</mn></msub><mo>\u2062</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><mo>+</mo></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bb</mi><mn>12</mn></msub><msub><mi>\u03bb</mi><mn>13</mn></msub><mo>+</mo><msub><mi>\u03bb</mi><mn>21</mn></msub><msub><mi>\u03bb</mi><mn>23</mn></msub><mo>+</mo><msub><mi>\u03bb</mi><mn>31</mn></msub><msub><mi>\u03bb</mi><mn>32</mn></msub><mo stretchy=\"false\">)</mo></mrow><msub><mi>d</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>\u2062</mo><mi>\u03c9</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.01396.tex", "nexttext": "\n\nWe can now generalize Equation \\ref{eq:mincostmaxfunction} \nas well so as to account for the \nincreased number of meeting locations. The respective cost \nfunction now takes the following form: \n\n", "itemtype": "equation", "pos": 14140, "prevtext": "\n\nMore formally, the result to an OSCP query is the single best location \n$\\mu^* \\in V$ where all travelers should meet so as to minimize the cost \nfunction $\\sigma_u$, i.e., $\\mu^* = \\textrm{argmin}_{u \\in V} \\sigma_u$. \nIf the goal is to minimize the \\emph{maximal travel distance} we define $\\sigma_u$ as:\n\\begin{eqnarray}\n  \\sigma_{u}^{max}= \\max_i \\{\\lambda_{ii} d_{s_i u}\n\t\t+ d_{u\\omega} \\prod_{j \\neq i} \\lambda_{ij}\\}\n\t\t\\label{eq:mincostmaxfunction} \n\\end{eqnarray}\nOtherwise, if our target is to minimize the \\emph{average travel distance} we define $\\sigma_u$ as:\n\\begin{eqnarray}\n  \\sigma_{u}^{avg} = \\frac{1}{n} \\sum_i \\{\\lambda_{ii} d_{s_i u}  \n\t\t+ d_{u\\omega} \\prod_{j \\neq i} \\lambda_{ij}\\}\n\t\t\\label{eq:mincostsumfunction} \n\\end{eqnarray}\n\n\n\n\n\n\n\nThe OMCP, however, allows for {\\em multiple} connecting points.  In order to understand how the cost of \na solution to the OMCP is obtained, let us discuss the solution shown in Figure~\\ref{fig:problem}(c) in detail.\n\nFirst, traveler $t_1$ meets traveler $t_2$ at connecting point $x_1$ and they proceed together until $x_0$ \n(where traveler $t_3$ joins the group) at summed cost \n$d_{s_1 x_1} \\lambda_{1 1} + d_{s_2 x_1} \\lambda_{2 2} + (\\lambda_{1 2} + \\lambda_{2 1}) d_{x_1 x_0} $. \n\n\n\n\n\n\n\n\n\n\nIn order to meet $t_1$ and $t_2$ at connecting point $x_0$ traveler $t_3$ needs to travel from $s_3$ \nto $x_0$ by him/herself at a cost equal to \n$\nd_{s_3 x_0} \\lambda_{3 3}\n$.\nThen, all three travelers proceed together from $x_0$ to the destination $\\omega$ at a cost equal to \n$\n(\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_0 \\omega}\n$.\n\nIt is noteworthy that $x_0$ is essentially the solution of another OSCP query, where the destination is \n$\\omega$,\ntraveler $t_3$ leaves from $s_3$ and a ``super-traveler'' representing travelers $t_1$ and $t_2$ \n{\\em together}  leaving from $x_0$ (where they were connected).\nHow to derive the affinity factor for such a ``super-traveler'' though? For \\emph{min-avg} ranking criteria \n$\\lambda_{1 2}$ + $\\lambda_{2 1}$ quantifies how much the ``super-traveler'' likes to travel alone \nas if a single traveler.\nThis is intuitive as it combines how $t_1$ likes to travel with $t_2$ and vice-versa.\n\n\n\n\nTherefore, the average travel cost of the OMCP solution\nshown in Figure~\\ref{fig:problem}(c) is equal to \n$\n\\frac{1}{3} (d_{s_1 x_1} \\lambda_{1 1} + d_{s_2 x_1} \\lambda_{2 2} + d_{s_3 x_0} \\lambda_{3 3} \n+ (\\lambda_{1 2} + \\lambda_{2 1}) d_{x_1 x_0} +   \n(\\lambda_{1 2} \\lambda_{1 3} + \\lambda_{2 1} \\lambda_{2 3} + \\lambda_{3 1} \\lambda_{3 2}) d_{x_0 \\omega})\n$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\begin{table}[!htbp]\n\\centering\n\\begin{tabular}{c c c}\n\\hline\n\\textbf{\\small{Notation}} & \\textbf{\\small{Description}} \\\\\n\\hline\n$t_1, t_2, \\cdots, t_n$         & \\small{$t_i$ stands for the $i$-th traveler.} \\\\\n$s_1, s_2, \\cdots, s_n$         & \\small{$s_i$ stands for the starting location of traveler $t_i$.} \\\\\n$\\omega$                        & \\small{common destination shared by all travelers.} \\\\\n$d_{uv}$                        & \\small{minimum cost for traveling from node $u$ to $v$.} \\\\\n$\\lambda_{ij}$                  & \\small{captures how much traveler $t_i$ enjoys $t_j$'s company.} \\\\\n$p$                             & \\small{a partitioning of travelers into groups and subgroups.} \\\\\n$\\mu_p$                         & \\small{connecting point where the elements of group $p$ meet.} \\\\\n$\\sigma_u$                      & \\small{aggregated score for point $u$ of the road network.} \\\\\n$\\sigma_p$                      & \\small{aggregated score that grouping $p$ achieves.} \\\\\n\n\n\\hline\n\\end{tabular}\n\\caption{Notation and terminology.}\n\\label{table:terminology}\n\\end{table}\n\n\n\n\nWe can generalize the reasoning above as follows.  \nLet $S_{i k}$ the $k$-th connecting group where traveler $t_i$ appears; and let us assume that there are $G$ such  groups.  \nFurther, we denote as $\\mu_{S_{i k}}$ the location (node) in the network, where this connection takes place.\nNote that $\\mu_{S_{i 0}} = s_i, \\forall t_i$, i.e., $t_i$'s starting position.\nBy construction, we have that \n$S_{i_0} \\subset S_{i 1} \\subset S_{i 2} \\subset \\cdots \\subset S_{i m_i}, \\forall t_i$.  \nOnce a traveler joins a group it never leaves it, and at each connection point at least one new traveler or possibly a subgroup of travelers, joins a group.\nWith this in mind the cost of the OMCP query can be broken down into the following components.\n\nWe know that all travelers will travel by themselves from their starting location to their first connecting point, thus \ncontributing each with cost $d_{s_i \\mu_{S_{i 1}}} \\lambda_{i i}$.\n\nAfter traveler $t_i$ joins its $k$-th connecting group, it moves to the next connecting point, i.e., \n$S_{i (k+1)}$.  \nHowever, we need to take into account that all travelers in that group will be traveling together, \ntherefore, such group movement will yield for each traveler $t_i \\in S_{i (k+1)}$ a cost equal to \n$\nd_{\\mu_{S_{i k}} \\mu_{S_{i (k+1)}}} \\prod_{\\substack{t_j \\in S_{ik}\\\\ t_i \\neq t_j}} \\lambda_{i j}\n$.\n\nIt leads that a route plan costs on average for each traveler:\n\n", "index": 3, "text": "\\begin{equation}\n\\sigma^{(avg)} = \\frac{1}{n} \n\n\\sum_{t_i \\in T} \n( \\sum_{k=0}^{m_i-1} d_{\\mu_{S_{i k}} \\mu_{S_{i (k+1)}}} \\prod_{\\substack{t_j \\in S_{ik}\\\\ t_i \\neq t_j}} \\lambda_{i j})\n\\label{eq:multigroupmincostsumfunction}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\sigma^{(avg)}=\\frac{1}{n}\\par&#10;\\sum_{t_{i}\\in T}(\\sum_{k=0}^{m_{i}-1}d_{\\mu_{S%&#10;_{ik}}\\mu_{S_{i(k+1)}}}\\prod_{\\begin{subarray}{c}t_{j}\\in S_{ik}\\\\&#10;t_{i}\\neq t_{j}\\end{subarray}}\\lambda_{ij})\" display=\"block\"><mrow><msup><mi>\u03c3</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>a</mi><mo>\u2062</mo><mi>v</mi><mo>\u2062</mo><mi>g</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>\u2208</mo><mi>T</mi></mrow></munder><mrow><mo stretchy=\"false\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><msub><mi>d</mi><mrow><msub><mi>\u03bc</mi><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msub></msub></mrow></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mtable class=\"ltx_align_c\" rowspacing=\"0.0pt\"><mtr><mtd><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>\u2208</mo><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>\u2260</mo><msub><mi>t</mi><mi>j</mi></msub></mrow></mtd></mtr></mtable></munder><msub><mi>\u03bb</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.01396.tex", "nexttext": "\n\nThe challenge we shall address for the remaining of this paper is to find the best such partitioning \nof the travelers' set into subgroups and their respective meeting locations $\\mu_{S_{i k}}$ where each \ntraveler joins a group so as to minimize the aggregated travel cost. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Processing Route Combinations}\n\\label{sec:processing}\n\nIn this section, we propose a paradigm consisting of three \nconcrete algorithms for combining paths rooted at $n$ sources \nand led to a single destination. The proposed scheme involves \ncomputing the best sequence of locations where each time two \nor more groups of travelers following different paths are \njoined together in such a way that any other combination of \njoined routes would yield a suboptimal score overall. However, \nwe first need an effective algorithm for solving the simplest \nform of the problem, where we seek the optimal connecting point \nfor a single group. We will use consistently for this purpose \nthe method from \\cite{oscp} for smaller subgroups by the methods \nfor computing the best combination of multiple connecting points.\n\n\n\\subsection{Structuring Routes Plans}\n\nThe most fundamental concept of our paradigm that we need to delineate \nfirst is that of the \\emph{grouping}. We define a \\emph{grouping} to \nbe any \\emph{disjoint partitioning} of the travelers. Therewith, a \ngrouping is essentially nothing more than a collection of groups of \ntravelers having a recursive structure of arbitrary depth with the \nfollowing properties: (i) a number of contained subgroups with possible \nnested deeper group structure, (ii) a meeting location where all \ncontained subgroups meet, and of course, (iii) is associated with a \nspecific destination node of the road network shared by all travelers.\n\nGiven a number of groups, we provide three different options on how to \ncombine a collection of groups from all available choices, so as to \nform a valid grouping, and therewith, select the most beneficial \ncombination each time. Namely: (i) leave them intact as each group \narrives at the destination point (or next connecting point) independently, \nas in Fig.~\\ref{fig:problem}(a)  where three travelers follow completely \ndifferent paths and each one constitutes a group of its own, as in the \npartitioning $\\{t_1\\},\\{t_2\\},\\{t_3\\}$ , (ii) \\emph{join} them by \nestablishing a meeting location where those groups meet and from then \non form a single solid group, as in Fig.~\\ref{fig:problem}(c) where at \n$x_0$ a group of two travelers is joined with a third traveler from $s_3$, \na route plan that corresponds to partitioning $\\{\\{t_1, t_2\\}, \\{t_3\\}\\}$, \n(iii) \\emph{merge} them altogether by rejecting and \ndissolving their previous structure, for example the route plan of \nFig.~\\ref{fig:problem}(c) becomes the one in Fig.~\\ref{fig:problem}(b) \nas we split the group of two travelers into its element and compute the \nmeeting location for all three, corresponding to partitioning $\\{t_1,t_2,t_3\\}$. \nLikewise, the route plan produced by our framework in Fig.~\\ref{fig:newyork} \nwas produced by joining the user D with a larger group consisting of users \nA, B and C. Each of those two subgroups has its own meeting location where \nits members are met, that also serves as a ``starting location'' for \ncomputing where those two groups should be joined. Conversely, we could merge \nthose two groups into a single one where all four users would meet at a single \nlocation before proceeding to their common destination. Thereby, we would \ndiscard the previous formation of the two separate groups. Which one of the \ntwo choices is more preferable depends on the aggregated cost of the two route plans.\n\n\\begin{figure}[hbt]\n  \\centering\n  \\includegraphics[width=.75\\textwidth]{annotatedmergejoin.png}\n  \\caption{Route plan derived by merging users A, B, C into a single \n                         group, joined with user D later on.}\n  \\label{fig:newyork}\n\\end{figure}\n\nThese are the three fundamental operations we consider \nwhen computing incrementally more complex combinations of larger groups, \nstarting from trivial groups initially, each consisting of just one traveler. \nMoreover, any route plan can be represented with a tree hierarchy that \ncorresponds to a multi-level recursive group, where the $n$ travelers \nconstitute the bottom layer (level 0), and each intermediate level corresponds \nto a separate grouping. Thereby, the route plan of Fig.~\\ref{fig:newyork} \nhas four travelers as its leaves, three of them (A, B, C) merged together to \nan internal node, which is then joined with leaf node D to form an another internal \nnode that is directly connected to the root corresponding to the destination.\n\n\nEach internal node is associated with a meeting location, or a single connecting \npoint that is computed by taking into consideration the locations of the \nmembers of that group only. More importantly, changing the location associated \nwith an internal node does not affect the meeting locations of the lower layers \nof the hierarchy. In other words, by choosing a different location where the \ntwo groups (one group for users A, B, C, and another containing user D only) \nare joined in Fig.~\\ref{fig:newyork}, has no effect on where users A, B, C meet, \nas the same location would serve as the optimal connecting point for this specific \nsubgroup in spite of any change in the rest of the route plan. We could generalize \nthis with the statement that the best location where any subgroup meets does \nnot change with what happens in another subgroup, e.g. if we change its meeting \nlocation, or merge it with another subgroup. This very simple concept allows \nfor the incremental bottom-up computation of the most preferable route plans.\n\n\n\n\n\nNow, what it remains is to find the best way to combine these travelers until \nonly one group remains in the end, encompassing all travelers' routes that are \njoined in combinations arranged in such a way that the aggregated travel cost \nis minimized. Towards this end, we propose three different algorithms, namely \nHeuristic Processing (HP), Extensive Processing (EP), and Clustered Processing \n(CP), that leverage similar processing principles. The aforementioned algorithms \nare incremental and with each iteration we obtain another more complex grouping \nin terms of its nested structure that might replace the previous candidate solution, \nonly if better. \n\nIn principle, all methods start with an initial tentative solution, which we \ntry to refine successively. Thereby, a naive grouping solution would involve \nall individual travelers, which we represent with groups having no deeper \nstructure. The sequential scheme we propose tries to put together only the \ngroups whose either joining, or merging yields a better score overall, while \nthe rest remain intact for the same iteration. \n\n\nMoreover, users' preferences expressed with their respective $\\lambda$-values play \na prominent role and affect two major aspects: (i) which groups belong together, and \n(ii) how much a route should be expanded (starting from the shortest path between two \nnodes), so as to allow for a more preferable journey when combined with others. In \npractice, we start from an initial solution of completely independent travelers that \nare grouped together in more complex structures in a bottom-up approach that leverages \nagglomerative clustering in an effort to construct more efficient route plans.\n\n\n\n\\subsection{OMCP Query Complexity}\n\nWe can show that the problem we study is NP-hard with a reduction to the \nwell-known weighted set cover problem. We assume a set of elements called \nthe universe, and a set $S$ of $n$ sets whose union equals the universe. \nThe set cover problem is to identify the min weight subset of $S$ whose \nunion equals the universe. We have for our reduction that $S$ corresponds \nto a set which is larger than the power-set of the set of travelers. The \nmain reason behind this claim is that a group of 3 travelers, like the one \nin the example of Fig.~\\ref{fig:problem} may consist of other smaller groups. \nFor instance, in Fig.~\\ref{fig:problem}(c), the group that is formed at \n$x_0$ congregates two smaller groups. The first consists of two travelers \nthat met at $x_1$, while the remaining traveler constitutes a group of his \nown. This peculiarity increases the complexity and the perplexity of the \nproblem we study here by a great deal. Therefore, since we can have groups \nthat are nested within other groups recursively at arbitrary depth (we can \nhave no smaller granularity than one traveler each), we will form $S$ as \nthe power-set of the travelers' set and for each element of that set we will \ncompute its own power-set and congregate its elements appropriately to produce \nnew more complex subsets to add to $S$. This is also repeated for each newly \ncreated subset until no sets can be further produced. For instance, let travelers \n$t_1, t_2$ and $t_3$. Then, as discussed earlier, we have the following set \n$S = \\{\\{t_1\\}, \\{t_2\\}, \\{t_3\\}$, $\\{t_1, t_2\\}, \\{t_1, t_3\\}, \\{t_2, t_3\\}$, \n$\\{\\{t_2\\}, \\{t_1, t_3\\}\\}$, $\\{\\{t_1, t_2\\}, \\{t_3\\}\\}$, $\\{\\{t_1\\}, \\{t_2, t_3\\}\\}$, \n$\\{t_1, t_2, t_3\\}\\}$, a set which is clearly superset of the power-set of the \ntravelers' set. Therefore, it is at least as difficult to find the optimal route plan \nthan it is to solve the set cover problem with up to $2^n$ sets to select from, \nso as to find the minimum weight sets required to form a valid partitioning \nthat comprises all travelers, whereas the search space of the problem we tackle \nhere comprises $\\Theta(n^n)$ possible route plans\\footnote{Due to lack of space \nthe computation of the number of possible route plans has been omitted}.\nWe also note that each element of $S$ corresponds to a grouping associated \nwith a meeting location. Likewise, each nested subgroup corresponds to a group \nof travelers which is associated with a meeting location where those travelers \nmet in advance. Also, we should add another rule to this variation of the \nset-cover problem, according to which we do not allow to select elements \nwith common elements. In terms of the weights of each element of $S$, we \nwant the arising cost for $S$ to be minimized, and hence, we set this by \nconvention according the cost functions we discussed earlier.\n\nAfter showing the intractability of the problem we tackle in this paper, \nwe will shortly discuss the courses of actions we undertake. First, we \npropose a method that computes an approximate solution by incrementally \nrefining a naive solution where each traveler sets his journey separately \ntowards $\\omega$, by putting together the travelers that yield the greatest \ngain at the time. Second, two approaches are presented for finding the \noptimal solution. Even though they are of exponential complexity with regard \nto the number of travelers by a worst case analysis, the pruning policy we \ndiscuss in later sections reduces the search space so as to empower the \ncomputation of the solution in an effective way.\n\n\n\\subsection{Bounding and Pruning}\n\nGiven a grouping, say $p$, we can make some safe assumptions with regard to \nthe minimum and maximum score any other more complex grouping that uses $p$ as \na basis can achieve. These bounds can be used to safely discard the derived \ngroupings, according to some sequence of the three aforementioned operations,\nthat are dominated in terms of their possibility to produce the best \nsolution. In effect, we can disregard a route plan and stop processing it any \nfurther when the lower bound of the score of the dominated route plan is greater \nthan the upper bound of the better one. Otherwise, unless an effective pruning \npolicy is adopted, the total number of processed groupings would rise dramatically \nand the computation cost would be immense to constitute such methods unable to \nrespond in real-time. Towards this end, we start initially from a naive route \nplan where each individual traveler follows independently the shortest path to \nthe destination. We are in search next for a lower bound for the optimal score \n$\\sigma^*$ of any route plan that can be derived from this naive route plan where \nthe travelers meet nowhere else but at the destination. Since there is no way of \nknowing this beforehand, we would like to have a lower bound, so that we can \napproximate and quantify how promising a route plan is and whether processing \nit any further could yield better and improved route plans subsequently. One \ncould expect that a reasonable lower bound would be the minimum individual traveler \ncost. However, this is not the case, as a route plan of lower cost could still \nbe feasible when other travelers join him early on from his starting post, for a \ngiven setting of the affinity parameters of course. More specifically, we have \nthen that, $\\text{aggr}_i d_{i\\omega} \\prod_j \\lambda_{ij} \\leq \\sigma^* \\leq \n\\text{aggr}_i d_{i\\omega} \\lambda_{ii}$, where aggr$_i$ is replaced with either \n$\\sum_i$ or $\\max_i$, accordingly. In other words, we have on the right side \nthe aggregated scores from the individual travelers serving as an upper bound \nfor the score any subsequent route combination could achieve, whereas on the \nleft we relax each individual cost at the maximum possible degree, as if all \ntravelers could join right from the starting post, without considering the \nscore of the other travelers moving to that post from their own, though. \nClearly, any possible route plan that can be derived would yield a higher cost \nbecause of the overhead arising from the other travelers' costs to get there.\n\n\\input{bounds.tex}\n\nIn Figure \\ref{fig:bounds}, we illustrate the case where a number of groups \nhas already been formed. Each of these groups is naturally associated with \na location where its comprised members meet. From then on, each group follows \nthe shortest path to the common destination $\\omega$. In Fig.~\\ref{fig:bounds}(a), \nwe show the shortest paths from the point where each group meets before \nproceeding to $\\omega$. However, a more preferable route plan might be found \nwhen two or more of these groups meet before they reach their final destination. \nThis is due to the affinity parameters that affect the aggregated cost according \nto the combinations of travelers that are formed. This case is shown in \nFig.~\\ref{fig:bounds}(b), where thicker lines depict paths followed by more \ntravelers. Let's see now how the formula that we use as a lower bound here \nrelates to this particular route plan. The cost value of the route plan (does \nnot correspond to a realistic route plan) in Fig.~\\ref{fig:bounds}(b) would \ndiminish if the travelers that participate in each of the groups where accompanied \nby all their fellow travelers, something that is infeasible of course. In other words, \nif we could see only thick lines in Fig.~\\ref{fig:bounds}(b), as an insight. \nBut still, we can find an even lower bound that \n\ncorresponds to the unrealistic route plan that we illustrate in Fig.~\\ref{fig:bounds}(c), \nwhere each group follows the shortest path to the destination at the cost of being \naccompanied by all travelers in the same time. Still an unrealistic query plan \nbut devoid of the additional costs arising from the groups meeting at intermediate \nlocations that detour from the shortest paths. To sum up with, the lower bound for \nthe cost of the route plan that corresponds to Fig.~\\ref{fig:bounds}(a) is calculated \nby multiplying the respective cost of each group to the destination by the affinity \nparameters that correspond to all travelers, an unrealistic route plan but extremely \nuseful as a lower bound for pruning.\n\nThe previous example was about establishing lower and upper bounds for the score \nany subsequent route plan could achieve after processing further the naive solution \nwhere each traveler follows an independent route to the destination. Let's generalize \nand examine a grouping $p$ that consists of a finite number of groups, say $c_1, c_2, \n\\cdots, c_m$. Now, even if this is not the overall perfect grouping assigning travelers \nto groups, and consequently to subgroups, and the structure within each $c_i$ group of \nthe route plan expressed within $p$ is not optimal, it is however definitely known, and \nhence, the respective score can be calculated. We denote the score of grouping $p$ as \n$\\sigma_{p}$ from either Eq.~\\ref{eq:multigroupmincostmaxfunction} or \\ref{eq:multigroupmincostsumfunction}. \nAccordingly, we define $\\tau_{p}$ the upper bound that can be achieved, where $\\tau_{p} \n= \\sum_{c \\in p} \\tau_{c} + d_{\\mu_c \\mu_p} \\sum_{x \\in c} \\prod_{y \\in c, y \\neq x} \\lambda_{xy}$ \nfor \\emph{min-avg} ranking, or $\\tau_{p} = \\max_{c \\in p} \\tau_{c} + d_{\\mu_c \\mu_p} \n\\prod_{y \\in c, y \\neq x} \\lambda_{xy}$, with $x = \\textrm{argmax}_z \\tau_z + d_{z\\mu_c} \\prod_{y \\in c, y \\neq x} \n\\lambda_{zy}$. Then, for the globally optimum score that involves all groupings that can \nbe built over $p$, in other words the different ways that the groups of $p$ can be combined \ntogether to form more complex and preferable route plans, it follows that $\\sigma_{p^*} \n\\leq \\tau_p$, where we note with $\\tau_p$ the maximum score any grouping built over the \n$p$ can achieve, and with $p^*$ the best (not known at the time) grouping that can be \nbuilt over the structure of $p$ and $\\sigma_{p^*}$ its optimal respective score. Analogously, \nwe can establish a lower bound $\\ell_p$, which is extremely useful for processing all \nthese collections of groups effectively and prune from early on the ones that cannot \ncontribute to the result for being dominated by other more successful route plans. In \nparticular, we have $\\ell_{p} = \\sum_{c \\in p} \\ell_c + d_{\\mu_c \\mu_p} \\sum_{x \\in c} \n\\prod_{y \\in p, y \\neq x} \\lambda_{xy}$ for \\emph{min-avg} ranking, while for \\emph{min-max} \nranking it follows, $\\ell_{p} = \\max_{c \\in p} \\ell_c + d_{\\mu_c \\mu_p} \\prod_{y \\in p, y \\neq x} \n\\lambda_{xy}$, where $x = \\textrm{argmax}_z \\ell_z + d_{z\\mu_c} \\prod_{y \\in p, y \\neq z} \\lambda_{zy}$.\nTherefore, it follows that $\\sigma_p^* \\geq \\ell_p$.\n\nIn effect, both bounds will be used to prevent from expanding the groupings \nthat cannot lead to good route plans, and also prioritize the most promising \nones. Besides, processing those first sets stricter constraints for all others, \nand allows for even more effective pruning, and thus, faster response-times \nfor our schemes. We reckon that even though the derived bounds from early \nprocessing stages would be quite far from the optimal route plan, since they \nconsist of individual travelers or rudimentary groups, as we proceed with \nbuilding more complex but more cost-efficient groupings and filtering-out the \nones that are guaranteed to be outranked eventually, both bounds are getting \ncloser and closer to the optimal value $\\sigma_p^*$, the best possible score \nthat a route plan that is built over $p$ can achieve.\n\n\\begin{algorithm}[htbp]\n  $\\Theta \\gets +\\infty$\\;\n  $\\hat{p} \\gets$ \\textbf{new} Group ($\\omega$)\\;\n  \\ForEach{$s$ \\textbf{in} $\\{s_1,s_2,\\cdots,s_n\\}$}{\n    $g \\gets$ \\textbf{new} Group($s$)\\;\n    $g$.addSubbgroup (\\textbf{new} Group($t$))\\;\n    $\\hat{p}$.addSubgroup ($g$)\\;\n  }\n\n  hasImprovedGroup $\\gets$ true\\;\n  \\While{hasImprovedGroup}{\n    hasImprovedGroup $\\gets$ false\\;\n    \\For{outer in $\\hat{p}$.subgroups()}{\n      \\For{inner in $\\hat{p}$.subgroups(}{\n        joined $\\gets \\hat{p}$.join(outer,inner)\\;\n        merged $\\gets \\hat{p}$.merge(outer,inner)\\;\n        \\If{$\\sigma_{\\text{joined}}<\\sigma_{\\text{merged}}$}{\n          \\If{$\\sigma_{\\text{joined}}<\\Theta$}{\n            hasImprovedGroup $\\gets$ true\\;\n            $\\hat{p} \\gets$ joined\\;\n            $\\Theta \\gets \\sigma_{\\text{joined}}$\\;\n          }\n        }\\Else{\n          \\If{$\\sigma_{\\text{merged}}<\\Theta$}{\n            hasImprovedGroup $\\gets$ true\\;\n            $\\hat{p} \\gets$ merged\\;\n            $\\Theta \\gets \\sigma_{\\text{merged}}$\\;\n          }\n        }\n      }\n    }\n  }\n  \\Return $\\hat{p}$\\;\n  \\caption{Heuristic Processing (HP) algorithm.}\n  \\label{algo:HP}\n\\end{algorithm}\n\n\n\\subsection{Heuristic Processing}\n\nThe first method we propose in this paper relies on greedy heuristics. Towards \nthis end, we start from a certain grouping and we iteratively refine it until \nno other change can occur. The best improvement each time builds up incrementally \nto the previous candidate solution that we have constructed so far. More specifically, \nAlgorithm \\ref{algo:HP} starts from the input group, and dissolves it to its \nconstituents in lines 10 and 11 before it combines them in lines 12 and 13 by \ntrying to either join them, where the two subgroups will meet at an intermediate \nlocation, or merge them, and by that we mean that all the elements of the two \ngroups will meet at a new single meeting location to form a new bigger \ngroup. This last operation resembles merging the containment of the two into \none that meets at a new intermediate location. Another way to put it, we \nrevoked the structure of the previous groups and formed a new one that congregates \ntheir constituents. On the other hand, we formed a new more complex group for the \nformer case by joining appropriately the examined parts at an intermediate \nlocation while preserving their previous structure at the same time. The \nderived groups are then compared with each other in line 14, and then in lines \n15 and 20, whether the best derived group outranks the previous form of the \ningredient elements that produced this more preferable group combination. \nIf so, then it is replaced. This process is repeated until the candidate \nsolution cannot be improved any further, when no other possible change \nwould yield a more preferable solution.\n\n\\begin{algorithm}[htbp]\n  $\\Theta \\gets +\\infty$\\;\n  $\\hat{p} \\gets$ \\textbf{new} Group ($\\omega$)\\;\n  \\ForEach{$s$ \\textbf{in} $\\{s_1,s_2,\\cdots,s_n\\}$}{\n    $g \\gets$ \\textbf{new} Group($\\omega$)\\;\n    $g$.addSubbgroup (\\textbf{new} Group($s$))\\;\n    $\\hat{p}$.addSubgroup ($g$)\\;\n  }\n\n  processed $\\gets$ \\textbf{new} Set()\\;\n  pool $\\gets$ \\textbf{new} Queue()\\;\n\n  processed.add ($\\hat{p}$)\\;\n  pool.add ($\\hat{p}$)\\;\n\n  \\While{not pool.isEmpty()}{\n    $p \\gets$ pool.remove()\\;\n    \\If{$\\ell_{p}>\\Theta$}{\n      continue\\;\n    }\n    \\ElseIf{$\\sigma_{p}<\\Theta$}{\n        $\\hat{p} \\gets p$;\n    }\n\n    \\For{outer in $p$.subgroups()}{\n      \\For{inner in $p$.subgroups()}{\n        \\If{outer = inner}{\n          break\\;\n        }\\Else{\n            merged $\\gets p$.merge(outer,inner)\\;\n            \\If{$\\ell_{\\text{merged}} < \\Theta$ \\textbf{and not} processed.contains(merged)}{\n              processed.add(merged)\\;\n              pool.add(merged)\\;\n            }\n\n            joined $\\gets p$.join(outer,inner)\\;\n            \\If{$\\ell_{\\text{joined}} < \\Theta$ \\textbf{and not} processed.contains(merged)}{\n              processed.add(joined)\\;\n              pool.add(joined)\\;\n            }\n        }\n      }\n    }\n  }\n  \\Return $\\hat{p}$\\;\n  \\caption{The Extensive Processing (EP) algorithm.}\n  \\label{algo:EP}\n\\end{algorithm}\n\n\n\\subsection{Extensive Processing}\n\nThe second method we present resembles a brute-force algorithm (with a twist) \nthat examines a route plan and produces all possible combinations that can \npossibly outrank the best solution found so far with a further refinement \nover the route plan that we examine. Those refinements are performed using \nthe aforementioned operations over the congregated groups of the grouping, \nnamely merging and joining. In addition, whenever we construct a subsequent \nroute plan two comparisons take place that decide whether it will be qualified \nfor further processing, or even whether should replace the candidate solution \nwe have found at the time. \n\nFirst, an eligible \nsubsequent grouping that comprises a group that corresponds to a \nconstruct of two groups of the route plan, should constitute \na more preferable option than the aggregation of its ingredient groups \nfrom which it was formed. If this is not the case, then we can safely \ndiscard the derived element and rely on the previous combination of \nthe two separate elements instead. In other words, drop the derived \ngrouping for the sake of the previous route plan. Second, another \ncheck in terms of the lower bound of the score the newly derived \ngroup can achieve is performed. More specifically, the resulting route \nplan containing the newly derived group should have a lower bound that \noutranks the upper bound of the best solution we have found so far. Then, the \ngroups that pass the test are appended at the end of a queue for further \nprocessing later on. To elaborate, while there are remaining groupings to \nbe processed and further refined (Alg.~\\ref{algo:EP}, line 11), we probe \nthe next one in line 12, and test whether it can produce more preferable \nroute combinations in line 13. If this is the case, then we check in line \n15 if the examined group outranks the candidate solution and replace it \naccordingly in line 16. From then on, we produce groups and compute the next \npossible meeting locations for the travelers to meet up by combining in \npairs the elements of the examined group in lines 17--29. Initially, in line 22, \nwe try to merge the two elements by rejecting their previous structure and \ncombine their encapsulated subgroups in such a way that a new group is \nformed. Then, in line 26, we construct an additional combination when the \ntwo subgroups have to be joined at an intermediate location while maintaining \ntheir initial structure before reaching their target location. In lines 23 and \n27, we perform checks to ascertain whether the derived combinations can be \nfurther refined into better route plans. If this is possible, then they are \nappended to the appropriate queues in lines 24, 25, 28 and 29, accordingly.\n\n\n\\subsection{Clustered Processing}\n\nFor the remainder of this section, we shall discuss the intricate details \nof our last  method. More specifically, in Algorithm \\ref{algo:toplevel}, \nwe maintain all promising groupings in a heap, and process them according \nto their rank. More importantly, only groupings of the next processing stage \nwhose lower bound is less or equal than the smaller upper bound found so far \nare processed any further, with $\\Theta$ serving as a threshold to filter-out \nall groupings with higher lower bounds. In addition, the algorithm \nterminates when the heap is either empty, or the next popped element is \noutranked in terms of its bound by the current candidate solution $\\hat{p}$, \nwhich is then returned to the user.\n\n\\begin{algorithm}[htbp]\n\t$\\Theta \\gets +\\infty$\\;\n\t$\\hat{p} \\gets$ \\textbf{new} Group ($\\omega$)\\;\n\t\\ForEach{$s$ \\textbf{in} $\\{s_1,s_2,\\cdots,s_n\\}$}{\n\t\t$g \\gets$ \\textbf{new} Group($\\omega$)\\;\n\t\t$g$.addSubbgroup (\\textbf{new} Group($s$))\\;\n\t\t$\\hat{p}$.addSubgroup ($g$)\\;\n\t}\n\n\tgroupings $\\gets$ \\textbf{new} MinHeap ()\\;\n\tgroupings.push (\\textbf{new} HeapEntry($\\hat{p},\\sigma_{\\hat{p}}$))\\;\n\n\t\\While{\\textbf{not} groupings.isEmpty()}{\n\t\ttop $\\gets$ groupings.pop()\\;\n\t\t\\If{$\\sigma_{\\hat{p}} \\geq \\ell_{top}$}{\n\t\t\t\\textbf{break}\\;\n\t\t}\n\t\t$\\mathcal{P} \\gets$ generateNextPhaseGroupings (top)\\;\n\t\t$\\theta \\gets \\min_{p \\in \\mathcal{P}} \\sigma_p$\\;\n\t\t\\If{$\\theta < \\sigma_{\\hat{p}}$}{\n\t\t\t$\\hat{p} \\gets \\text{argmin}_{p \\in \\mathcal{P}} \\sigma_p$\\;\n\t\t}\n\t\t\\If{$\\theta < \\Theta$}{\n\t\t\t$\\Theta \\gets \\theta$\\;\n\t\t}\n\t\t\\ForEach{$p$ \\textbf{in} $\\mathcal{P}$}{\n\t\t\t\\If{$\\ell_p \\leq \\Theta$}{\n\t\t\t\tgroupings.push (\\textbf{new} HeapEntry($p,\\sigma_p$))\\;\n\n\t\t\t}\n\t\t}\n\t}\n\t\\Return  $\\hat{p}$\\;\n\t\\caption{ClusteredProcessing ($\\omega,\\{s_1,s_2,\\cdots,s_n\\}$)}\n\t\\label{algo:toplevel}\n\\end{algorithm}\n\nFurthermore, with each iteration of Alg.~\\ref{algo:toplevel}, we invoke \nAlg.~\\ref{algo:nextphase} in order to compute the groupings of the next \nphase. In essence, Alg.~\\ref{algo:nextphase} takes as input a sequence \nof groups constituting a valid grouping, and detects which of them can \nbe merged together for they yield a better score. In Alg.~\\ref{algo:nextphase}, \nlines \\ref{algo:nextphase:joingroups} and \\ref{algo:nextphase:mergegroups}, \nthe elements of two distinct groups are put together to form a more preferable \noption when qualified in lines 11, 12, 17 and 18. All constituents of the \nnewly formed group (either smaller subgroups, or individual travelers) will \nbe met at the location that is returned by the method proposed in \\cite{oscp}.\n\n\n\n\n\n\n\\begin{algorithm}[htbp]\n\tpool $\\gets$ \\textbf{new} Set ()\\;\n\tlist $\\gets$ \\textbf{new} ArrayList ()\\;\n\n\t\\ForEach{group \\textbf{in} grouping} {\n\t\tlist.add (group)\\;\n\t\tpool.insert (group)\\;\n\t}\n\n\t\\ForEach {over \\textbf{in} list} {\n\t\n\t\t\n\t\t\\ForEach {under \\textbf{in} list} {\n\t\t\t\\If{over $\\neq$ under}{\n\t\t\t\t$\\zeta \\gets$ join (over,under)\\; \\label{algo:nextphase:joingroups}\n\t\t\t\t\\If {useMinMaxRank \\textbf{and} $\\sigma_{\\zeta} < \\sigma_{group}$ \\textbf{and} $\\sigma_{\\zeta} < \\sigma_{top}$\\\\\n\t\t\t\t\\textbf{or} useMinAvgRank \\textbf{and} $\\sigma_{\\zeta} \\leq \\frac{|\\text{over}|\\sigma_\\text{over} \n\t\t\t\t+ |\\text{under}| \\sigma_\\text{under}}{|\\text{over}|+|\\text{under}|}$}{\n\t\t\t\t\t\\If {\\textbf{not} pool.contains ($\\zeta$)} {\n\t\t\t\t\t\tlist.add ($\\zeta$)\\;\n\t\t\t\t\t\tpool.insert ($\\zeta$)\\;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t$\\xi \\gets$ merge (over,under)\\; \\label{algo:nextphase:mergegroups}\n\t\t\t\t\\If {useMinMaxRank \\textbf{and} $\\sigma_{\\xi} < \\sigma_{group}$ \\textbf{and} $\\sigma_{\\xi} < \\sigma_{top}$\\\\\n\t\t\t\t\\textbf{or} useMinAvgRank \\textbf{and} $\\sigma_{\\xi} \\leq \\frac{|\\text{over}|\\sigma_\\text{over} \n\t\t\t\t+ |\\text{under}| \\sigma_\\text{under}}{|\\text{over}|+|\\text{under}|}$}{\n\t\t\t\t\t\\If {\\textbf{not} pool.contains ($\\xi$)} {\n\t\t\t\t\t\tlist.add ($\\xi$)\\;\n\t\t\t\t\t\tpool.insert ($\\xi$)\\;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tgroupingtree $\\gets$ \\textbf{new} GroupingTree ()\\;\n\t\\ForEach {$c$ \\textbf{in} pool.reverse()} {\n\t\tgroupingtree.addGroup ($c$, \\textbf{not} grouping.contains($c$))\\;\n\t}\n\n\tnewgroupings $\\gets$ groupingtree.getGroupings()\\;\n\t$\\theta \\gets \\min_{p \\in \\text{newgroupings}} \\sigma_p$\\;\n\n\tqualified $\\gets$ \\textbf{new} List()\\;\n\t\\ForEach{p \\textbf{in} newgroupings}{\n\t\t\\If{$\\ell_{p} \\leq \\theta$}{\n\t\t\tqualified.insert (p)\\;\n\t\t}\n\t}\n\t\\Return qualified;\n\t\\caption{nextPhaseGroupings (grouping)}\n\t\\label{algo:nextphase}\n\\end{algorithm}\n\nAs a result, this incremental operation improves the traveling \nexperience for all the involved parties. What is more, this is repeated \nsuccessively until we are left with a collection of groups that \ncannot be improved so as to give another more influential group. \nThis is accomplished within the while-loop of Alg.~\\ref{algo:nextphase}, \nwhere with each iteration we check whether the rudimentary groups of the \nprevious levels can either be merged or joined with any of the \nother groups so as to yield a better grouping. Since the final \nnumber of groups is not known in advance in the general case, we \nwill have to design an auxiliary structure that concentrates all \nrequired information and allow us to process effectively the numerous \nderived groups, but also prioritize them according to the bounds \nthereof. As a result, we would be in position of filtering-out any \ngroupings that lead to suboptimal route combinations. More importantly, \nas the more complex qualified groups achieve a better score usually, \nwe shall often place them at the top of the hierarchy, since it is \nvery likely that they will participate in the most successful route \nplans, and thus, probably in the final solution, as well.\n\n\\begin{algorithm}[htbp]\n\tstack $\\gets$ \\textbf{new} Stack()\\;\n\t\n\n\tstack.push (root)\\;\n\t\n\n\t\\While{\\textbf{not} stack.isEmpty()}{\n\t\ttop $\\gets$ stack.pop()\\;\n\t\t\\If{top.isLeaf()}{\n\t\t\ttop.addChild (newgroup)\\;\n\t\t}\\Else{\n\t\t\thasDisjointChild $\\gets$ \\textbf{false}\\;\n\t\t\t\\ForEach{child \\textbf{in} top.getChildren()}{\n\t\t\t\t\\If{child.isDisjoint(newgroup)}{\n\t\t\t\t\thasDisjointChild $\\gets$ \\textbf{true}\\;\n\t\t\t\t\tstack.push (child)\\;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\\If{isDerived \\textbf{and not} hasDisjointChild}{\n\t\t\t\ttop.addChild (newgroup)\\;\n\t\t\t}\n\t\t}\n\t}\n\n\t\\caption{GroupingTree.addGroup (newgroup, isDerived) : adds a new group in the appropriate places \n\t\tof the hierarchy built for retrieving the best groupings of a specific level.}\n\t\\label{algo:groupingtree}\n\\end{algorithm}\n\nTo elaborate, the root of this purpose-specific hierarchy that we call \n\\emph{grouping-tree} corresponds to an empty group containing no subgroups, \nand is therefore, disjoint with any other group. By disjoint we mean that \nthe travelers each group contains do not overlap, in a sense that they \ncongregate no common travelers, and thus, correspond to disjoint travelers' \nsets and partitions thereof. Next, since larger groups were constructed \nlast on the basis of the ones formed previously, we will examine them in \nreverse order to insert them at the top levels of the tree. For \neach group we will execute Alg.~\\ref{algo:groupingtree}, which in essence, \nperforms a DFS-like traversal of the hierarchy we have constructed so far, \nby expanding the encountered tree-nodes, and inserting their children to a \nstack, if and only if, they correspond to groups that are disjoint with the \ncurrently examined group. Otherwise, we proceed with the next tree-node we \npop from the stack. Leaves are expanded naturally by appending a new \nleaf-node associated with the examined group. Alternatively, if no branch \nof the encountered node accepts the examined group, then we will insert a \nnew child-node for this node. As a final note, we generalize and claim that \neach path of the grouping-tree is a more complex expression of a list of \ntrivial groups, where two or more groups have been funneled together through \na sequence of merging or joining operations so as to form each node of the \ntracked path. \n\n\\begin{figure}[hbt]\n  \\centering\n  \\includegraphics[width=.75\\textwidth]{annotatedrunexample.png}\n  \\caption{A route plan for six travelers split into two separate smaller \n                                groups that are joined at the destination.}\n  \\label{fig:runexample}\n\\end{figure}\n\n\n\\subsection{Running Example}\n\nWe will now present a simple problem instance for six travelers starting from \nlocations $\\alpha, \\beta, \\gamma,x, y$ and $z$, respectively, and discuss how \nour Clustered Processing (CP) algorithm runs. First, Alg.~\\ref{algo:toplevel} \nis executed and will produce the initial grouping with just one group associated \nwith each traveler right before entering the while-loop and expanding the best \ngrouping retrieved at the time in each iteration with a call to Alg.~\\ref{algo:nextphase}. \nMore specifically, each element of the group-list is combined with the rest of \nthe elements, and we check whether their combination (by either joining or merging) \nproduces a more complex group that benefits all its members, and therefore, it \nis more preferable than their previous separate form. For the purposes of this \nexample, we assume that traveler $t_\\alpha$ from starting location $\\alpha$ can \nbe combined only with travelers $t_\\beta$ and $t_\\gamma$ from locations $\\beta$ \nand $\\gamma$, respectively, while a combination with travelers $t_x, t_y$ or $t_z$ \nwould not meet the necessary constraints. Likewise, the rest of the travelers \nstarting from locations denoted with greek letters, namely $t_\\beta$ and $t_\\gamma$, \nshould not be combined with travelers from locations denoted with latin, namely \n$t_x, t_y$ and $t_z$, and vice versa. This could be either because those subsets \nof travelers like each other much more than the travelers from the opposite group, \nor due to their distances in the underlying network, or both. We illustrate such \na scenario for six travelers in Fig.~\\ref{fig:runexample}. We have two groups of \nfriends, users A, B, C on one side belong to one group, while users D, E, F on \nthe other side belong to the other. Each of those subgroups was formed by merging \none traveler with another, say user A with B, and then merging user C with the \ngroup of two travelers that was formed earlier. Hence, two merging operations were \nrequired to form each of the smaller groups, and with a join operation we found \nwhere those two groups should be met so as to form a single solid group to reach \nTimes Square. Conversely, a merge operation over the two subgroups would break them \napart and their containment, six travelers in total, would constitute a new solid \ngroup that meets before or right at the destination. Hence, we would have just one \nmeeting location for all six travelers instead. \n\n\\input{clustering.tex}\n\nMore precisely, we demand from the new groups to outrank the aggregation of the \nscores of the groups they were produced from, namely, we want, $\\sigma_{\\alpha x} \n\\leq \\frac{|\\alpha| \\sigma_\\alpha + |x| \\sigma_x}{|\\alpha|+|x|}$, $\\sigma_{\\alpha y} \n\\leq \\frac{|\\alpha|\\sigma_\\alpha + |y|\\sigma_y}{|\\alpha+y|}$, and $\\sigma_{\\alpha z} \n\\leq \\frac{|\\alpha|\\sigma_\\alpha + |z|\\sigma_z}{|\\alpha|+|z|}$ for \\emph{min-avg \nranking}, or analogously, $\\sigma_{\\alpha x} \\leq \\sigma_\\alpha, \\sigma_{\\alpha x} \n\\leq \\sigma_x$, $\\sigma_{\\alpha y} \\leq \\sigma_\\alpha, \\sigma_{\\alpha y} \\leq \\sigma_y$, \nand $\\sigma_{\\alpha z} \\leq \\sigma_\\alpha, \\sigma_{\\alpha z} \\leq \\sigma_z$ for \n\\emph{min-max ranking}. Otherwise, the overall ranking function that considers all \ntravelers would deteriorate instead of ameliorate. This is actually how our first \nphase of pruning is applied so as to prevent from processing further the route plans \nthat mix travelers from the one group with travelers from the other. Then, as shown \nin Fig.~\\ref{fig:grouplist}, the newly derived groups are appended at the end of the \ngroup-list, and will be then combined with the elements we will examine next. Now, \nsimple group $\\beta$ manages to produce new larger groups $\\beta\\gamma$ and \n$\\alpha\\beta\\gamma$, when combined with groups $\\gamma$ and $\\alpha\\gamma$, \nrespectively. On the other hand, the group containing $\\gamma$ fails to produce new \ngroups that meet the requirements when combined with the succeeding elements. Following \nexactly the same procedure, we generate groups $xy$ and $xz$ when examining group $x$, \nand groups $yz$ and $xyz$ from processing group $y$. Moreover, each derived group is \nassociated with a unique location where \\emph{all} its members meet, regardless of \ntheir own recursive structure since only the part of the route to the next meeting \nlocation and beyond remains to be decided. Therewith, location $\\mu_{\\alpha\\beta}$ \nserves as the meeting place for groups $\\alpha$ and $\\beta$, so that from then on \ngroup $\\alpha\\beta$ is formed to represent the respective travelers' journey towards \ntheir common destination $\\omega$. Likewise, at $\\mu_{\\alpha\\gamma}$ is where groups \n$\\alpha$ and $\\gamma$ meet to form group $\\alpha\\gamma$. Similarly, $\\beta$ unites \nwith $\\gamma$ at $\\mu_{\\beta\\gamma}$. At $\\mu_{\\alpha\\beta\\gamma}$, three parts are \nmet into a larger group. Additionally, locations $\\mu_{xy}$, $\\mu_{xz}$, $\\mu_{yz}$ \nand $\\mu_{xyz}$ serve as meeting places for the elements of groups $xy$, $xz$, $yz$ \nand $xyz$, respectively.\n\n\\begin{figure*}[htbp]\n  \\centering\n  \\includegraphics[width=\\textwidth]{grouptree}\n  \\vspace{-10pt}\n  \\caption{Grouping-tree instance for six travelers starting \n  from locations $x,y,z,\\alpha,\\beta,\\gamma$, respectively.}\n  \\label{fig:groupingtree}\n\\end{figure*}\n\nFor the remainder of this section, we will study how \nAlg.~\\ref{algo:groupingtree} builds the grouping-tree \ngiven a collection of groups from the group-list produced \nin Alg.~\\ref{algo:nextphase}. At the end of the execution \nof Alg.~\\ref{algo:nextphase}, we start examining the \nelements of the list in reverse order, and each time we \ninvoke Alg.~\\ref{algo:groupingtree}. Hence, the first group \nwe encounter, namely $xyz$, becomes the first child-node of \nthe root of the grouping-tree, as depicted in Fig.~\\ref{fig:groupingtree}. \nNext, group $yz$, will also be placed right under the root, \nsince both its elements exist in the previously inserted group \nand it cannot be subsumed by it. Likewise, we insert groups $xz$ \nand $xy$ for they have at least one common element with each \nof the aforementioned groups. Now, upon the insertion \nof group $\\alpha\\beta\\gamma$, we ascertain whether it is \ndisjoint with any of the groups under the root. Since this \nis the case, it will become the child of each of these \nnodes, and therefore, will not be placed under the root. \nSimilarly, we insert at depth 2 groups $\\beta\\gamma, \n\\alpha\\gamma, \\alpha\\beta$ under all nodes. Consequently, \nall nodes at depth 1 have exactly the same children. \nHowever, this in not the case at depth 3. When examining \nsimple group $z$, we place it under $xy$ only, and \nsince all its child-nodes, $\\alpha\\beta\\gamma, \\beta\\gamma, \n\\alpha\\gamma, \\alpha\\beta$, are disjoint with $z$, \nthey will all become responsible for a copy of it. Likewise, \ngroup $y$ is inserted under all children of group $xz$, \nwhereas trivial group $x$ finds its place under the \nchildren nodes of group $yz$. We find at depth 4 the \nlast groups we shall examine, namely trivial groups $\\alpha, \n\\beta$ and $\\gamma$, which are placed under \ntrivial groups $x,y$ and $z$. \n\nFurthermore, it is hard to \nmiss that the path from any leaf to the root corresponds \nto a valid grouping that congregates groups that were \ncreated at this processing phase mostly. More importantly, \nonly when necessary, at the bottom levels of the tree, \nwe will find groups of the previous processing phases \nthat were needed so as to complement any valid grouping. \nIn effect, whatever groups of the input failed to find \na suitable spot in the grouping-tree, they are naturally \npruned and prevented from being processed during the next phases. \nIn plain words, these groups are safely discarded because \nthey are better represented within larger groups that \nnow improve the experience for a greater number of travelers.\nThe reader may find in the appendix a series of lemmas on \nthe soundness of the methods operating over the grouping-tree.\n\nArguably, the most influential groupings are the ones that \ncomprise a small number of large groups. This is the case \nwith grouping $\\langle xyz, \\alpha\\beta\\gamma\\rangle$, the \nfirst grouping returned by an in-order traversal of the \nhierarchy. This is exactly the route plan that is shown in \nFig.~\\ref{fig:runexample}, where we have two groups of users \nthat are joined at the destination. Each of those groups \nis produced through merging, the way we described earlier.\nNotably, which will be the groupings that \nwill eventually prevail and be passed on to the next phase \nfor further processing depends exclusively on their scores \nand the bounds thereof. All qualified groupings must have \na lower bound that is less than the upper bounds of all \ngroupings that were generated from. Now, let $\\tau_{xyz,\\alpha\\beta\\gamma}$ \nthe lowest upper bound of all generated groupings. Hence, \nall groupings with a lower bound that surpasses \n$\\tau_{xyz, \\alpha\\beta\\gamma}$ will be rejected due to \nthe fact that they cannot lead to a better solution than \nany of the eligible groupings can. \n\nFor simplicity and ease of presentation, we assume that only \nthe groupings that congregate less than three groups are qualified, \nand the travelers starting from locations $\\alpha,\\beta$ and \n$\\gamma$ cannot be combined with the travelers starting from \nlocations $x,y$ and $z$, by convention.\nConsequently, Alg.~\\ref{algo:nextphase} will eventually \nreturn a list containing the following groupings: \n$\\langle xyz, \\alpha\\beta\\gamma\\rangle$, $\\langle xyz, \n\\beta\\gamma, \\alpha\\rangle$, $\\langle xyz, \\alpha\\gamma, \n\\beta\\rangle$, $\\langle xyz, \\alpha\\beta, \\gamma \\rangle$, \n$\\langle yz, \\alpha\\beta\\gamma, x\\rangle$, $\\langle xz, \n\\alpha\\beta\\gamma, y\\rangle$ and $\\langle xy, \\alpha\\beta\\gamma, \nz\\rangle$, which in turn will be inserted into the heap \nof Alg.~\\ref{algo:toplevel}, where they will be processed \naccording to their rank. For example, when examining the \nnext grouping $\\langle xy, \\alpha\\beta\\gamma, z\\rangle$, \na series of additional candidate groupings with more \ncomplex structure will be derived, namely groupings $\\langle \n\\langle xy, \\alpha\\beta\\gamma \\rangle, z\\rangle$, $\\langle \nxy, \\langle \\alpha\\beta\\gamma, z \\rangle \\rangle$ and \n$\\langle \\langle xy, z \\rangle, \\alpha\\beta\\gamma \\rangle$, \nassociated with locations $\\mu_{\\langle xy, \\alpha\\beta\\gamma \n\\rangle, z}$, $\\mu_{xy, \\langle \\alpha\\beta\\gamma, z \\rangle}$ \nand $\\mu_{\\langle xy, z \\rangle, \\alpha\\beta\\gamma}$, \nrespectively. Same as before, a new \ninstance of a grouping-tree will be constructed, and then, \nonly the best of the new groupings will be returned for \nfurther processing, until we are left with only one grouping \nthat outranks all the rest, either by comparison for those \ngroupings that were eventually fully processed, or in terms \nof their bounds (for those groupings that were effectively \npruned).\n\n\n\n\n\n\\section{Experimental Evaluation}\n\\label{sec:evaluation}\n\nIn this section we assess the performance of all methods \nwe propose in this paper. We adopt two important metrics: \n(i) the total \\emph{execution time} required until each \nmethod returns its result, \n\n\n\n(ii) the \\emph{quality} of the result returned \nby each method. The scores of the respective cost functions \nare used for this purpose.\n\n\\begin{table}[hbt]\n\\centering\n\\begin{tabular}{c c c}\n\\hline\n\\textbf{Parameter}       & \\textbf{Range}      & \\textbf{Default} \\\\\n\\hline\nnumber of travelers      & $4,5,7$             & $4$ \\\\\ncoverage area            & $40\\%, 50\\%, 70\\%$  & $40\\%$\\\\\ndistance to destination  & $40\\%, 50\\%, 70\\%$  & $40\\%$\\\\\nself-affinity parameter  & $40\\%, 50\\%, 70\\%$  & $40\\%$\\\\\n\\hline \n\\end{tabular}\n\\caption{System parameters.}\n\\label{table:parameters}\n\\end{table}\n\nA variety of different parameters has been \nemployed so as to expose the strengths and the weaknesses \nof each method: (1) The number of travelers $n$. \n\n(2) The size of coverage area from which the starting posts are selected\nIt is defined as a percentage over the nodes \nof the road network that are closer to a node selected at random. \n(3) The distance to the final destination that the \ntravelers need to cover. This is expressed as a percentage \nover the remaining nodes of the road network that are immediately\nbeyond the coverage area. Last but not \nleast, (4) the affinity factor $\\lambda_{ii}$ has an indirect \nimpact on performance by affecting the cardinality of the \nsearch space.   Note that for simplicity we only \nvary the self-affinity factors, the remaining amount \n($1-\\lambda_{ii}$) is equally distributed among \nall fellow travelers.\n\n\n\n\n\nIn Table \\ref{table:parameters}, we present all parameters \nalong with the range of values that they take and their \ndefault values.\n\n\n\n\n\\begin{figure*}[!bt]\n    \\centering\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxtime2travelers}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxtime2coverage}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxtime2target}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxtime2lambda}\n    }\n    \\vspace{-10pt}\n    \\caption{Processing time for different configurations for \\emph{min-max} ranking.}\n    \\label{fig:results:max:time}\n\n    \\centering\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumtime2travelers}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumtime2coverage}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumtime2target}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumtime2lambda}\n    }\n    \\vspace{-10pt}\n    \\caption{Processing time for different configurations for \\emph{min-avg} ranking.}\n    \\label{fig:results:sum:time}\n\n\n\n    \\centering\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxscore2travelers}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxscore2coverage}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxscore2target}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/maxscore2lambda}\n    }\n    \\vspace{-10pt}\n    \\caption{Aggregated costs for different configurations for \\emph{min-max} ranking.}\n    \\label{fig:results:max:score}\n\n    \\centering\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumscore2travelers}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumscore2coverage}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumscore2target}\n    }\n    \\hspace{-5pt}\n    \\subfigure[]{\n    \\includegraphics[width=.23\\textwidth]{exp/sumscore2lambda}\n    }\n    \\vspace{-10pt}\n    \\caption{Aggregated costs for different configurations for \\emph{min-avg} ranking.}\n    \\label{fig:results:sum:score}\n\\end{figure*}\n\nFurthermore, we use real datasets that were obtained from \n\\cite{lifeifei} that correspond to the cities of Oldenburg \n(OL), San Joaquin County (TG) and to the road network of \nCalifornia (CA). Their sizes vary from over 7,000 edges to \napproximately 24,000, and are associated with a number of \nnodes that ranges between 6,000 and a little over 21,000 \nnodes. Upon each of these datasets we created query sets by \nvarying the aforementioned parameters, one at a time, while \nthe rest take their default values. All queries were run in \nan AMD Opteron 6134 processor running at 2.3GHz.\n\nA general observation throughout our evaluation, whose results are depicted \nin Figures \\ref{fig:results:max:time},  \\ref{fig:results:sum:time}, \n\\ref{fig:results:max:score} and \\ref{fig:results:sum:score}, is that albeit \nthe fastest method, HP always returns a suboptimal solution due to the greedy \nheuristics employed. CP is faster than EP because of the better way it \nderives new groupings and adopts more effective pruning techniques at the \ncost of being a more complex method that has to manage and coordinate \na number of heaps. Notably, we observe similar performance patterns for \nboth types of ranking, namely \\emph{min-max} and \\emph{min-avg}. For each \nconfiguration we depict one bar per evaluated road network, starting from \nleft to right (with regard to their sizes), we have \nOL for Oldenburg, CA for California, and TG for San Joaquin County. The road \nnetwork of California has approximately the same size as TG but is qualitatively \ndifferent in a sense that it describes a road network consisted of interstates \nand highways, unlike the rest that model urban areas.\n\nFigures \\ref{fig:results:max:time} and \\ref{fig:results:sum:time} \nillustrate the total processing time over all studied parameters. \nThe combination XX/YY in the legend means that method XX was used \nwith dataset YY, e.g., the bar for CP/CA depicts the results obtained \nby using the CP (clustered processing) method for the CA (California) \nroad network, and so on.\n\nClearly, time grows exponentially in terms of the number of travelers in \nFigures \\ref{fig:results:max:time}(a) and \\ref{fig:results:sum:time}(a) \nshown in log-scale. This manifests the importance of this parameter and \nthe significant computation cost imposed when a large number of travelers \nis involved. This result manifests the exponential complexity of the problem \narising from the increased number of route plans that can be derived with the \ndifferent combinations of travelers.\nIn Figures \\ref{fig:results:max:time}(b) and \\ref{fig:results:sum:time}(b), \nwe observe that the cover area, which corresponds to the percentage over \nthe overall area from which the starting posts are selected, has a slightly \nirregular effect on execution time. On the other hand, the distance of the \ndestination from the starting posts has also a negative effect on performance, \nas shown in Figures \\ref{fig:results:max:time}(c) and \\ref{fig:results:sum:time}(c).\nThose two parameters affect only the time spent for graph search and do not \nincrease the number of possible route plans to be examined. Consequently, their \nimpact is not as strong as the number of travelers. Therefore, we see that \nrelatively slight change in performance.\nQuite remarkably, we can easily observe in Figures \\ref{fig:results:max:time}(d) \nand \\ref{fig:results:sum:time}(d) that by increasing the self-affinity parameter \n(or equivalently by increasing how much each traveler enjoys traveling with others \nother than alone), makes it easier and faster to retrieve the globally optimal route \nplan. The reason lies with the fact that when the relaxation factors maximize their \neffect (high $\\lambda_{ii}$-values and low $\\lambda_{ij}$-values with $i \\neq j$), \nthe cost function over the search space takes a steeper form. Hence, the \nprioritization policy we enforce with the usage of the heaps is more effective, \nand along with our pruning approach, processing becomes much more efficient.\n\nIn Figures \\ref{fig:results:max:score} and \\ref{fig:results:sum:score}, we \nillustrate the aggregated scores that the returned results achieve with regard \nto the studied parameters. Obviously, EP and CP return results of better quality \nwhen compared with HP. This is due to the fact that HP, as its name implies, \nrelies on greedy heuristics, and hence, cannot consider all possible grouping \noutcomes. CP and EP return the same (optimal) result corresponding to equi-height \nbars. In Figures \\ref{fig:results:max:score}(a) and \\ref{fig:results:sum:score}(a) \nwe study the impact that the number of travelers has on the result quality. In \nparticular, for \\emph{min-max} ranking criteria, there is an insignificant change \nin the normalized aggregated cost for the optimal methods as the number of travelers \ngrows, and it slightly increases for the heuristic method. For \\emph{min-avg}, the \naggregated cost apparently diminishes, especially for the optimal methods, because \nof the additional affinity parameters, the product of which in the ranking function \ncauses the decrease. Moreover, the gap of HP from the optimal solution is further \ndeepened, even though a diminishing trend is still evident. In other words, the \nheuristic solution impairs as the number of travelers increases. Arguably, this \nobservation provides a clear evidence of the trade-off and when the time overhead \nis justified the usage of CP is the appropriate choice.  \nOn the other hand, the effect of the growing coverage area becomes evident \nin Figures \\ref{fig:results:max:score}(b) and \\ref{fig:results:sum:score}(b), \nwhere the costs increase mainly due to the longer distances the travelers \nhave to cover until they meet. In Figures \\ref{fig:results:max:score}(c) and \n\\ref{fig:results:sum:score}(c), the distance of the destination has an insignificant \nimpact on the scores because of the aggregated relaxation factor that diminishes \nthe part of the cost associated with the final step of the route plan after all \ntravelers meet. Last but not least, the aggregated costs surprisingly increase in Figures \n\\ref{fig:results:max:score}(d) and \\ref{fig:results:sum:score}(d) due to the \nfirst parts of the route plans where the travelers travel alone, as the relaxation \nfactors increase. We would expect those scores to drop as larger groups would be \nformed early on in an effort to minimize the overall travel cost. However, when \nthe travelers are that spread apart (default value for the cover area is 40\\%), \nthis is still a difficult task, and the overhead from those early steps makes \nits presence known here.\n\n\n\n\\section{Related Work}\n\\label{sec:related}\n\n\n\n\n\n\n\n\n\n\n\nTo the best of our knowledge, this is the first time that the OMCP \nquery is proposed. Additionally, no other similar method has been \never proposed to consider multiple meeting locations, mainly due to \nthe complexity of the problem, which can be proved to be NP-hard.\nOn the other hand, the simpler form of the query that searches for \njust one such point that optimizes the objective, is related to \nqueries focusing on finding the \\emph{Optimal Meeting Point} (OMP). \nThis line of work does not consider any notion of common destination \nshared by the travelers to succeed the meet up. Previous works on \nthe OMP problems focus on finding a location (on a road network or \nin the Euclidean space) that minimize the aggregate distance (e.g., maximum \nor average) from a set of query locations, e.g., the starting points \nof users who want to meet.\n\n\nThe OMP problem has been well studied in the Euclidean space in \n\\cite{PapadiasTMH05}, where bounds on the MBRs of R-trees are used \nto guide search. \n\n\\eat{\nContemporary technology and \nthe proliferation of geo-spatial applications and hand-held devices \nrequire the development of efficient schemes over much more restricted road \nnetworks. In this context, \\cite{papadias} constitutes a seminal work \n\n\n\nwhere the authors proposed a common framework for processing several types \nof queries for \n\nobjects in road networks. \n\n\n\n}\n\nThe first work to study and solve the OMP problem in road networks was \n\\cite{ann}. The authors propose three methods: (i) the Incremental Euclidean \nRestriction (IER), that exploits spatial data structures by utilizing Euclidean \nlower bounds in combination with A* search and an incremental Euclidean Aggregate \nNearest Neighbor method, (ii) the Threshold Algorithm (TA), which is motivated by \naggregate top-k query processing techniques and (iii) the Concurrent Expansion (CE) algorithm, which \nconcurrently expands the searched area in an effort to avoid the shortest \npath computations, since they can be expensive because they traverse the \nnetwork nodes in a less systematic way. CE is a more general method \nwhich does not rely on bounds and can be applied for any cost function\non the network's edges.\\eat{More on this method can be found \nin our experimental evaluation where we compare it against our own paradigm.}\nMore recently, the authors of \\cite{splitpoints} address the OMP problem \nrelying on finding all the split-points of the road network that satisfy the \nquery requirements to minimize the specified distance parameters.\nFor any point of the road network its split-points are the points that halve \nthe distance from that point over any cyclic path it participates over the graph. \nAmong these points they select the point with the smallest sum of network distances \nfrom all starting posts. However, this paradigm imposes a significant computational cost. \n\n\n\nThe authors in \\cite{convex} \naim at retrieving the OMP, by associating the nodes of the road networks \nwith their spatial locations. However, this \n\nis somewhat limiting as the road network could have much different \ncharacteristics than the Euclidean space where the nodes lie (e.g., the\nweights in a road network can represent the traveling time \nbetween any two nodes, or the max speed of a vehicle along that path, etc.) \nNonetheless, two distinct approaches are proposed in \\cite{convex}. The first, \nlimits the search among the nodes that are located within the convex hull formed \nby the query points. We note that, this is only a filtering step and there is no \nsense of prioritization during search. On the other hand, the second approach \ncalculates the centroid of the query points and then enacts a nearest neighbor \nsearch. We note that the centroid is a fictitious point and its nearest \nnode in the road networks does not always capture the desired properties \nas it does not necessarily minimize the aggregated cost. Moreover \nthe solutions obtained cannot be claimed to be optimal.\\eat{\nIn the OSCP problem, we do not constrain \nthe cost function on edges to be related to a spatial distance. In \nother words, we aim at solving the general problem with arbitrary edge weights.\nSpecifically, we assume that the road network could have much different \ncharacteristics than the Euclidean space where the nodes lie, e.g., the \nweights in a road network can represent the traveling time \nbetween any two nodes, or the speed of a vehicle along that path, etc.\n\n\n\n\n} The continuous monitoring of the OMP in the Euclidean space was more \nrecently studied in \\cite{saferegions}, \n\nwhere the query input points (i.e., user locations) are assumed to be \nconstantly moving and the objective is to minimize the computation and \ncommunication cost \nfor continuously updating their OMP.\n\n\n\n\\eat{\nThe authors exploit the notion of a \\emph{safe region}; a \nwidely used concept for continuous queries in the context of moving objects.\nThey key idea is that, for as long as the objects remain within their \nrespective safe regions, the OMP remains unchanged.\n\n\n\n\n\n\n\n\n\nOur OSCP query is novel and goes beyond the definition of OMP in two main \nways. First, the users \\emph{meet and continue} towards a common destination. \nSecond, accounting for the users' mutual affinity makes OSCP special, meaning \nthat existing approaches for solving OMP are not appropriate for OSCP queries \nor their brute-force adaptations are inefficient, as we will show in Section \n\\ref{sec:evaluation}.\n}\n\n\n\n\\section{Conclusions}\n\\label{sec:conclusion}\n\nTo recapitulate, in this paper we proposed a novel query type that \nretrieves the \\emph{Optimal Multiple Connecting Points (OMCPs)}, or \nthe best locations where groups of travelers having a common destination \nshould meet so that the aggregated (either maximum, or average) traveler \ncost is minimized. In this context, we proposed three distinct approaches \nfor retrieving the OMCPs. Namely, (i) \\emph{Heuristic Processing (HP)} \nrelies on a fast and greedy approach that finds a sub-optimal solution, \n(ii) \\emph{Extensive Processing (EP)} adopts a pruning approach based \non score bounds that a refined route can achieve, so as to reduce the \nnumber of processed routes, and (iii) \\emph{Clustered Processing (CP)}, \nwhich employs a best-first search approach to process the most promising \nroutes first, so as to enforce stricter bounds, and hence, impose even \nmore effective pruning, in an effort to ameliorate overall response-times. \nNotably, EP and CP retrieve the globally optimal solution. Albeit the \nfastest method, HP returns a suboptimal solution due to the greedy \nheuristics employed. CP is faster than EP because of the smarter way \nit derives new candidate solutions and adopts more effective pruning \ntechniques at the cost of being a more complicated method that has to \nmanage and coordinate a number of heaps. Most importantly, as shown \nin our evaluation, our methods are efficient overall, in spite of \naddressing an intractable problem. Finally, we developed a framework \nin Java leveraging the methods proposed in this paper, and made it \navailable at \\url{http://connect.cs.ualberta.ca/omcp/}.\n\n\\eat{\nFinally, this work lays the seed for prominent future extensions. More \nspecifically, we plan to extend the problem we study in this paper and \ninvestigate the case when the top-$k$ such solutions are queried, instead \nof just the best one.\n}\n\n\\section*{Appendix}\n\n\n\\begin{lemma}\n  The union of the groups associated with the nodes on any path of the \n  grouping-tree produced at any processing phase congregates all travelers.\n  \\label{lemma:inclusive}\n\\end{lemma}\n\n\\begin{proof}\n  By induction, we show that it holds after processing phase \n  0, we accept it is true for processing phase $i$, and last, \n  we prove that it also holds after processing phase $i+1$. \n\n  \\noindent\\textbf{\\textit{Phase 1:}} \n  We start from the fact that the initial grouping used as \n  input comprises all travelers. This is the input for the \n  first processing phase where each traveler naturally \n  corresponds to a disjoint group to each of his fellow \n  travelers' groups. In effect, the grouping-tree of that \n  rudimentary grouping takes the form of a plain list for \n  that matter. Then, at the end of the first processing \n  step, the output group-list consists of two parts, the \n  first containing a number of the input elements, and the \n  second, the qualified groups derived from mergings and \n  joins that can occur.\n\n  Now, the produced grouping-tree, given this basic input, \n  will have at its first level the groups that are pairwise \n  non-disjoint, meaning that each group from the first level \n  intersects somehow with every other group of the same level. \n  \n  \n  \n  \n  \n  \n  The second layer of the hierarchy congregates again groups that \n  are pairwise non-disjoint, but also they have the property of being \n  disjoint to the group that is associated with their parent node.\n  Therefore, it is impossible to find groups from the first layer at \n  any subsequent layer. Now, even if none derived group fulfils that \n  specification to find a spot at the second layer, we can be certain \n  that the remaining elements of the input can complement the top groups, \n  arranged in the form of a linear list, one (complementary) group per \n  node. However, we have given priority to the larger newly derived \n  groups that congregate those simpler elements in more preferable \n  combinations. \n  \n  \n  \n  \n  \n  \n\n  Similarly, the $k$-th layer of each subtree is built, and whenever \n  we run out of derived groups, we know that the remaining elements \n  from the input will fill the tree-branch, one group per node. \n  \n  \n  \n  \n  \n  Therefore, all paths \n  from the root comprise a mixture of new and old groups, arranged in such \n  a way that a valid grouping is formed. And thus, only valid groupings \n  are passed on for further processing.\n\n  \\noindent\\textbf{\\textit{Phase i:}} \n  We accept that the hypothesis is true and the $i$-th processing phase \n  constitutes a grouping-tree with paths that correspond to valid groupings. \n  This also holds for its output, which is produced based on the paths of \n  the grouping tree. \n\n  \\noindent\\textbf{\\textit{Phase i+1:}} \n  We start from the fact that the input of this processing phase is \n  necessarily a valid grouping, as the output of the $i$-th phase. \n  In addition, its elements are the atomic parts that will constitute \n  any derived group. Of course, if some are not used in a more complex \n  combination, they can definitely be used to complement some groupings \n  when needed. In essence, there is no chance to be needing just some \n  part of these atomic elements so as to form a valid grouping, and \n  therefore, all the necessary pieces of the puzzle are already in the \n  group-list, and arranged appropriately inside the grouping-tree.\n\n  As far as the tree construction is concerned, we examine the input \n  in reverse and we put at the top levels of the hierarchy the groups \n  that were derived in this phase, and each time we encounter a disjoint \n  node, we add a child node. Otherwise, if none such node is encountered, \n  we place it as a sibling node under the same disjoint parent node. The \n  elements of the group-list that were not derived during this phase \n  can be placed in tandem as leaf-nodes. When no other disjoint group \n  can be found within the group-list, it means that all travelers are \n  already involved in that particular route plan.\n  {\\ensuremath{\\blacksquare}}\n\\end{proof}\n\n\\begin{corollary}\n All paths from the root of the grouping-tree from any processing phase \n correspond to valid groupings.\n\\end{corollary}\n\n\\begin{proof}\n By contradiction. Let a path of the grouping tree, that it does not \n correspond to a valid grouping for either of the two following reasons:\n \\begin{description}\n  \\item [\\textit{there is at least one pair of non-disjoint groups}] does \n  not hold by construction: a node is not subsumed by another at any level \n  unless they are associated with fully disjoint groups.\n  \\item [\\textit{does not involve all travelers}] contradicts Lemma \\ref{lemma:inclusive}.\n \\end{description}\n Thus, the statement holds for the opposite cannot be true.\n {\\ensuremath{\\blacksquare}}\n\\end{proof}\n\n\n\\begin{lemma}\n The grouping-tree produced at any phase includes all possible groupings \n that involve the newly generated groups.\n\\end{lemma}\n\n\\begin{proof}\n By contradiction. Let grouping $\\langle c_1, c_2, \\cdots, c_k \\rangle$, \n that was not represented in the grouping-tree. Since, it constitutes a \n valid grouping, all its elements are mutually disjoint and the union of \n all their elements corresponds to the set of all travelers. For this \n grouping to have been missed, it means that at least one of its elements \n was not encountered when building the grouping-tree.\n\n Now, we assume that the elements of the missed grouping appear inside \n the group-list in the following order $\\{ c'_1, c'_2, \\cdots, c'_k \\}$, \n with other groups intervening between them in the original group-list. \n Hence, since we examine the elements in reverse order, the first element \n of the missed grouping we encounter is $c'_k$. The elements of $c'_k$ \n are naturally represented in all other groupings by definition (otherwise \n they would not constitute valid groupings). All groups of the group-list \n preceding $c'_k$ are non-disjoint, and therefore, $c'_k$ will not be \n subsumed by any of them, but instead will be placed as their sibling. \n If $c'_k$ was disjoint with any preceding group, then it would appear in \n another position subsumed by any of them, and therefore, no valid grouping \n with these exact elements would exist. From then on, when we will encounter \n each remaining element of the missed grouping, it will be put (among other \n places) exactly below the previously seen group of the sequence, since it \n is disjoint with all groups of the sequence that we have encountered.\n\n And thus, there is no missing grouping in the grouping-tree since the initial \n hypothesis is false. Therefore, all groupings are well represented within \n the hierarchy.\n {\\ensuremath{\\blacksquare}}\n\\end{proof}\n\n\\bibliography{omcp}\n\\bibliographystyle{plain}\n\n\n", "itemtype": "equation", "pos": 14577, "prevtext": "\n\nWe can now generalize Equation \\ref{eq:mincostmaxfunction} \nas well so as to account for the \nincreased number of meeting locations. The respective cost \nfunction now takes the following form: \n\n", "index": 5, "text": "\\begin{equation}\n\\sigma^{(max)} = \\max_{t_i} (\n\n\\sum_{k=0}^{m_i-1} d_{\\mu_{S_{i k}} \\mu_{S_{i (k+1)}}} \\prod_{\\substack{t_j \\in S_{ik}\\\\ t_i \\neq t_j}} \\lambda_{i j})\n\\label{eq:multigroupmincostmaxfunction}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\sigma^{(max)}=\\max_{t_{i}}(\\par&#10;\\sum_{k=0}^{m_{i}-1}d_{\\mu_{S_{ik}}\\mu_{S_{i(%&#10;k+1)}}}\\prod_{\\begin{subarray}{c}t_{j}\\in S_{ik}\\\\&#10;t_{i}\\neq t_{j}\\end{subarray}}\\lambda_{ij})\" display=\"block\"><mrow><msup><mi>\u03c3</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mrow><munder><mi>max</mi><msub><mi>t</mi><mi>i</mi></msub></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><mrow><msub><mi>d</mi><mrow><msub><mi>\u03bc</mi><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></msub><mo>\u2062</mo><msub><mi>\u03bc</mi><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msub></msub></mrow></msub><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mtable class=\"ltx_align_c\" rowspacing=\"0.0pt\"><mtr><mtd><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>\u2208</mo><msub><mi>S</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>t</mi><mi>i</mi></msub><mo>\u2260</mo><msub><mi>t</mi><mi>j</mi></msub></mrow></mtd></mtr></mtable></munder><msub><mi>\u03bb</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}]