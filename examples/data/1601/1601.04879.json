[{"file": "1601.04879.tex", "nexttext": " with $h=1,\\ldots,k^*$. Notice that these weights are constructed so that $\\sum_{h=1}^{k^*}\\pi^*_h=1$, and the definition comes naturally from the representation of clusters as sets in a sample space.\n\n The Multiple Allocation Mixture model (MAM) can be defined as a  reparameterization of (\\ref{mod1}) in the new formulation\n   \\begin{eqnarray}\\label{mod2}\nf(\\boldsymbol{y}_j|\\Theta)=\\sum_{h=1}^{k^*} \\pi_h^* f(\\boldsymbol{y}_j|\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta), \\phi_h)\n\\end{eqnarray}\n  where $\\boldsymbol{u}_h$ is the $h$-th row of $U$ and $\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta)$ is a function that transforms the primary parameters $\\boldsymbol\\theta_i$ into the parameters of the multiple allocation components according to several possible schemes:\n \\begin{itemize}\n \\item in an additive framework, the parameters of the mixed groups could be the sum of the original parameters, that is \n", "itemtype": "equation", "pos": -1, "prevtext": "\n\n\n\\title{Mixture model with multiple allocations for clustering spatially correlated observations in the analysis of ChIP-Seq data}\n\\date{}\n\n\\author{Ranciati, S.$^{(*)(1)(2)}$, Viroli, C.$^{(1)}$, Wit, E.$^{(2)}$\n\\[4pt]\n\\footnotesize (1) Department of Statistical Sciences \\[2pt]\n\\footnotesize University of Bologna, 40126 Bologna, Italy,\\[4pt]\n\\footnotesize email: saverio.ranciati2@unibo.it\n\\[16pt]\n\\footnotesize (2) Johann Bernoulli Institute for Mathematics and Computer Sciences\\[2pt]\n\\footnotesize University of Groningen, 9747 AG Groningen, The Netherlands\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\n\n\n\n\n\\begin{abstract}\nModel-based clustering is a technique widely used to group a collection of units into mutually exclusive groups. There are, however, situations in which an observation could in principle belong to more than one cluster. In the context of Next-Generation Sequencing (NGS) experiments, for example, the signal observed in the data might be produced by two (or more) different biological processes operating together and a gene could participate in both (or all) of them. We propose a novel approach to cluster NGS discrete data, coming from a ChIP-Seq experiment, with a mixture model, allowing each unit to belong potentially to more than one group: these multiple allocation clusters can be flexibly defined via a function combining the features of the original groups without introducing new parameters. The formulation naturally gives rise to a `zero-inflation group' in which values close to zero can be allocated, acting as a correction for the abundance of zeros that manifest in this type of data. We take into account the spatial dependency between observations, which is described through a latent Conditional Auto-Regressive process that can reflect different dependency patterns. We assess the performance of our model within a simulation environment and then we apply it to ChIP-seq real data.\\\\\n\n\\emph{KEYWORDS:} Heterogeneity; Model-based clustering; Spatial dependency; Multiple allocations.\n\\end{abstract}\n\n\n\\section{Introduction}\n\\label{sec1}\nIn the last 15 years, the development of parallel massively sequencing platforms for mapping the genome has completely revolutionized the way of studying gene expression patterns. These recent technologies called Next Generation Sequencing (NGS) allow to simultaneously investigate thousands of features within a single reliable and cost-effective experiment, thus representing a valid alternative to microarray experiments in enhancing our understanding of how genetic differences affect health and disease \\citep{nag}. Indeed, these innovative platforms have been quickly applied to many genomic contexts giving rise to a large amount of available data in complex form. The output data are peculiar and their analysis has raised an imperative need for specific methodologies: technical or biological replicates can be observed in several experimental conditions \\citep{Bao}, and the single observational units, such as genes or exons, are very likely characterized by spatial dependencies and relationships \\citep{Mo}. Moreover, the abundance of a particular transcript is measured as a count and so the single data point is a discrete measurement.\n\nConsider as an example the Chromatin ImmunoPrecipitation and sequencing (ChIP-Seq) data on proteins p300 and CBP analysed by \\cite{Ramos2010}. In this experiment, two technical replicates are observed after 30 minutes from the initial interaction of the proteins with the human genome, with the aim of discovering the binding profile of these transcription factors. Figure \\ref{plot_full} displays summarized counts for 1000 base pairs contiguous windows along chromosome 21. The plot shows segments with high read counts and segments where there is a uniformly low level of signal, thus suggesting a potential spatial effect.\n\nOne additional interesting feature of gene expression data is that a single gene may be an actor participating in a plethora of cellular functions and that many cellular processes are somewhat overlapped \\citep{Battle}. From the statistical point of view, the problem of the detection of such biological processes and of the genes involved therein can be addressed by  clustering with the aim of identifying groups of genes that exhibit similar expression patterns. Tipically, conventional clustering methods perform classification of units into mutually exclusive partitions. Multiple partitions can be obtained in (at least) two ways: (a) by fuzzy or `soft' clustering that is the assignment of a unit to the group with some posterior probabilities \\citep[see, for instance, ][]{Bezdek, Heller2} or (b) by accounting for multiple allocations directly as a generative model. Our proposal moves in this second perspective that explicitly assumes that genes are fully co-actors of multiple processes in a model based framework. The idea stemmed from some interesting contributions devoted to discover multiple clusters. \\cite{Battle} introduced a probabilistic-based method to discover overlapping cellular processes and the associated gene regulation scheme. Given the complexity of a cellular system, they propose a decomposition of the observed continuous data matrix into layers representing biological processes and groups of co-regulated genes, allowing every unit to express itself in more than one activity layer and belong to multiple clusters. In \\cite{Banerjee} and \\cite{Fu}, the problem of multiple allocation is solved within a model based clustering strategy, where the distribution of the groups is extended generalizing the Gaussian probability distribution used in \\cite{Battle} to the case of exponential family distributions. The main idea of such approach known as `Model-Based Overlapping Clustering' is to re-parameterize the density of the overlapped clusters as the product of some primary densities that, being members of the exponential family, still result in the same parametric family.\n\\cite{Heller1} extended these models by employing a nonparametric Bayesian technique to inference the number of groups in their overlapping clusters model, while maintaining the characterization of the mixture densities as members of the exponential family. More recently, \\cite{Zhang} proposed the `epistatic model based clustering' for the analysis of microarray data. In this approach, a more explicit description of the mixed component densities in terms of Gaussians is given; different interactions between the parameters of the primary groups are investigated but the order of the interactions between these original clusters and the overlapped counterparts is practically limited to the second order.\n\nThe aim of this work is to define a general Multiple Allocation Mixture (MAM) model for analyzing the ChIP-Seq data. The peculiar features of these experimental data demand for specific treatment. First, their discrete nature and a marked overdispersion require a flexible count distribution such as the Negative Binomial, that however, despite the Poisson, does not generally belong to the exponential family, unless its dispersion parameter is known and fixed. To this aim we generalize the model-based overlapping clustering to arbitrary parametric probabilistic functions thus enlarging the exponential family boundary. In addition, as shown in Figure \\ref{plot_full}, data are characterized by the inflation of non-structural zero's. These aspects are naturally taken into account by the proposed model, where each component of the multiple mixture corresponds to a primary or to an overlapped cluster distributed as Negative Binomials with parameters that are function of the primary parameters only.\nA further interesting aspect that emerges from Figure \\ref{plot_full} is that the gene expressions are spatially correlated. We will show that the model can be easily extended in order to account for the spatial linkage among the genes, via a Conditional Auto-Regressive (CAR) process.\n\nIn what follows, we will present our proposal in three gradual steps in order to sequentially address these issues. First, in Section 2, the general MAM model will be presented and then we will adapt the model to the NGS data. Then we will illustrate how to extend this approach in order to model spatial dependent observations. In Section 3, a simulation study aimed to investigate the flexibility and effectiveness of the proposal is presented and we fit our model on the real dataset; in Section 4, conclusions are discussed.\n\n\n\n\\section{Methods}\n\\label{sec2}\n\n\\subsection{Model-based clustering with mixture model}\n\nFinite mixture models have been receiving a wide interest in the statistical literature as a tool for performing model based clustering and density estimation \\citep[see][]{Banfield1993,McLachlan2000,Fraley2002}.\n\nLet $\\boldsymbol{y}_j$ ($j=1,\\dots,p$) be an observed vector of values that we want to classify in some unknown groups.  The conventional model based clustering model assumes\n\\begin{eqnarray}\\label{mod1}\nf(\\boldsymbol{y}_j|\\Theta)=\\sum_{i=1}^k\\pi_i f(\\boldsymbol{y}_j|\\boldsymbol\\theta_i),\n\\end{eqnarray}\nwhere $f(\\boldsymbol{y}_j|\\boldsymbol\\theta_i)$ are the component densities and $\\pi_i$ are the prior probabilities to belong to each component, satisfying $\\pi_i>0$ and $\\sum_{i=1}^k\\pi_i =1$. According to this model, a sample of $p$ observations arises from some underlying populations of unknown proportions and the purpose is to decompose the sample into its mixture components, where each component corresponds to a cluster. In doing so, the data are partitioned into mutually exclusive $k$ groups. This is achieved by introducing a latent variable, say $z_{ji}$, which allocate each observation $j$ to the component $i$. More precisely, $\\boldsymbol{z}_{j}$ is a vector of length $k$ that takes the value 1 in correspondence of the cluster assignment, and 0 elsewhere, so that $\\sum_{i=1}^k z_{ji}=1$. According to the maximum a posteriori probability (MAP) rule, the partition is then obtained by assigning subjects to their most likely class according to the posterior probabilities of $z$ given the data:\n\\begin{eqnarray*}\nf(z_{ji}|\\boldsymbol{y};\\Theta)=\\frac{\\pi_if(\\boldsymbol{y}_j|z_{ji};\\boldsymbol\\theta_i)}\n{\\sum_{i'=1}^k\\pi_{i'}f(\\boldsymbol{y}_j|z_{ji'};\\boldsymbol\\theta_{i'})}.\n\\end{eqnarray*}\nIn this sense the classification produced by a mixture model is `hard' (because a unit is allocated to the mixture component with the maximum posterior probability of belonging to) but in principles it could be `soft' by assigning each cluster a weight that equals its posterior probability as in the partial membership model \\citep{Heller2}. However, a soft assignment perspective does not mitigate the limitation of the model based classification, that results when data points may simultaneously belong to multiple clusters. In such situations, a change in the generative model should be done, by explicitly assuming that the vector $\\boldsymbol{z}_{j}$ may contain several - and not just a single - ones, thus defining a general boolean matrix.\n\n \\subsection{Multiple Allocation Mixture model}\n\nIn order to construct a new generative model for multiple components, we define $k$ in equation (\\ref{mod1}) as the number of primary groups which are not mutually exclusive. For such a reason, we assume the prior probabilities of each primary group satisfying the constraint $\\pi_i>0$ but not necessarily summing up to one,  $\\sum_{i=1}^k\\pi_i\\neq 1$.\n\nThe total number of possible single and multiple allocation clusters is $k^*=2^{k}$ and $\\sum_{i=1}^kz_{ji}=n_j$ is the multiplicity of the cluster membership for the unit $j$th.  When $n_j=1$ we have a single group allocation, otherwise we have multiple group allocations. More precisely, if $n_j=2$ the unit $j$th belongs to two groups simultaneously. These two groups altogether may be thought of as a new \\emph{secondary} group. If $n_j=3$ the unit belongs to three groups that jointly define a \\emph{tertiary} group and so forth. When $n_j=0$, the unit is assigned to what we call a `outward cluster': this group collects observations that ideally do not belong to any clusters, and for this reason their distribution might be described by peculiar parameters depending on the empirical context. For instance, in many applications it could represent a group of outliers or noisy observations, characterized by high variance. The definition and existence of the `outward cluster' is particularly relevant for the analysis of ChIP-Seq data, where the clusters are interpretable as biological processes. A gene that does not take part to any biological processes will have extremely low values (close to zero or zero). Thus, the  outward cluster has the purpose to describe the group of `inactive genes' and, in so doing, it acts as a zero-inflation adjustment for the model.\n\nFor $k$ fixed, let $U$ be a connection matrix of dimension $2^{k} \\times k$, with elements $u_{hi} \\in \\{0,1\\}$, containing all the possible assignment configurations. For instance, for $k=3$:\n \\begin{eqnarray}\\label{con.mat}\nU= \\left(\n   \\begin{array}{ccc}\n     0 & 0 & 0 \\\\\n     1 & 0 & 0 \\\\\n     0 & 1 & 0 \\\\\n     0 & 0 & 1 \\\\\n     1 & 1 & 0 \\\\\n     0 & 1 & 1 \\\\\n     1 & 0 & 1 \\\\\n     1 & 1 & 1 \\\\\n   \\end{array}\n \\right)\n.  \\end{eqnarray}\nIn this case we define the prior probability to belong to a general (single or multiple allocation) group \n", "index": 1, "text": "$$\\pi^*_h=\\prod_{i=1}^k \\pi_i^{u_{hi}} (1-\\pi_i)^{1-u_{hi}}$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\pi^{*}_{h}=\\prod_{i=1}^{k}\\pi_{i}^{u_{hi}}(1-\\pi_{i})^{1-u_{hi}}\" display=\"block\"><mrow><msubsup><mi>\u03c0</mi><mi>h</mi><mo>*</mo></msubsup><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msubsup><mi>\u03c0</mi><mi>i</mi><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></msubsup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msub><mi>\u03c0</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": " where in the second term the indicator function is introduced to account for the parameters of the outward mixture component;\n\\item alternatively, we could assume a model of co-dominance of the primary parameters with some order, such as the order 1: \n", "itemtype": "equation", "pos": -1, "prevtext": " with $h=1,\\ldots,k^*$. Notice that these weights are constructed so that $\\sum_{h=1}^{k^*}\\pi^*_h=1$, and the definition comes naturally from the representation of clusters as sets in a sample space.\n\n The Multiple Allocation Mixture model (MAM) can be defined as a  reparameterization of (\\ref{mod1}) in the new formulation\n   \\begin{eqnarray}\\label{mod2}\nf(\\boldsymbol{y}_j|\\Theta)=\\sum_{h=1}^{k^*} \\pi_h^* f(\\boldsymbol{y}_j|\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta), \\phi_h)\n\\end{eqnarray}\n  where $\\boldsymbol{u}_h$ is the $h$-th row of $U$ and $\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta)$ is a function that transforms the primary parameters $\\boldsymbol\\theta_i$ into the parameters of the multiple allocation components according to several possible schemes:\n \\begin{itemize}\n \\item in an additive framework, the parameters of the mixed groups could be the sum of the original parameters, that is \n", "index": 3, "text": "$$\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta)=\\sum_{i=1}^k u_{hi}\\boldsymbol\\theta_i + \\boldsymbol\\theta_b\\mathds{1}_{\\left[ {{\\sum_{i=1}^{k^*}u_{hi}=0}} \\right] },$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\theta})=\\sum_{i=1}^{k}u_{hi}\\boldsymbol{%&#10;\\theta}_{i}+\\boldsymbol{\\theta}_{b}\\mathds{1}_{\\left[{{\\sum_{i=1}^{k^{*}}u_{hi%&#10;}=0}}\\right]},\" display=\"block\"><mrow><mrow><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msub><mi>\ud835\udf3d</mi><mi>i</mi></msub></mrow></mrow><mo>+</mo><mrow><msub><mi>\ud835\udf3d</mi><mi>b</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>[</mo><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></msubsup></mstyle><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>0</mn><mo>]</mo></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\\item or order 0:\n \n", "itemtype": "equation", "pos": 14795, "prevtext": " where in the second term the indicator function is introduced to account for the parameters of the outward mixture component;\n\\item alternatively, we could assume a model of co-dominance of the primary parameters with some order, such as the order 1: \n", "index": 5, "text": "$$\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta)=\\frac{\\sum_{i=1}^k u_{hi}\\boldsymbol\\theta_i}{\\sum_{i=1}^k u_{hi}}+ \\boldsymbol\\theta_b\\mathds{1}_{\\left[ {{\\sum_{i=1}^{k^*}u_{hi}=0}} \\right] };$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\theta})=\\frac{\\sum_{i=1}^{k}u_{hi}%&#10;\\boldsymbol{\\theta}_{i}}{\\sum_{i=1}^{k}u_{hi}}+\\boldsymbol{\\theta}_{b}\\mathds{%&#10;1}_{\\left[{{\\sum_{i=1}^{k^{*}}u_{hi}=0}}\\right]};\" display=\"block\"><mrow><mrow><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><mrow><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>\u2062</mo><msub><mi>\ud835\udf3d</mi><mi>i</mi></msub></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></mfrac><mo>+</mo><mrow><msub><mi>\ud835\udf3d</mi><mi>b</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>[</mo><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></msubsup></mstyle><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>0</mn><mo>]</mo></mrow></msub></mrow></mrow></mrow><mo>;</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\\end{itemize}\nFinally, $\\phi_h$ are some specific parameters that may be introduced to add flexibility to the mixture model.\n\n\n\n\\subsection{Multiple Allocation Mixture model for ChIP-Seq Data}\n\nSuppose we observe the read counts of $p$ genes in $D$ biological conditions or replicates. We denote $Y_{jd}$ the random variable that expresses the read counts, say $y_{jd}$, mapped to gene $j$ ($j$=$1,...,p$), in sample $d$ with $d=1,\\ldots,D$. Let $\\boldsymbol{Y}_j$ be the random vector of length $D$ denoting the expression profile of a gene. Let $\\boldsymbol{y}_j$ be the observed value. We assume that $Y_{jd}$ is distributed according to the Negative Binomial ($\\mathcal{NB}$) distribution, given both the discrete nature of the observations and the flexibility of having a specific parameter used to model the overdispersion, that makes this distribution preferable to the Poisson. We further assume that, conditionally on the group, the replicates are independent draws so that the mixture model in (\\ref{mod2}) becomes:\n   \\begin{eqnarray}\\label{mod3}\nf(\\boldsymbol{y}_j|\\Theta)=\\sum_{h=1}^{k^*} \\pi_h^*\n\\prod_{d=1}^D \\mathcal{NB}\\left(y_{jd}|\\psi(\\boldsymbol{u}_h,\\boldsymbol\\mu_d),\\phi_{dh}\\right)\n,\\end{eqnarray}\nwhere $\\phi_{dh}$ are specific dispersion parameters of the negative binomials and $\\mu_{dh}^*=\\psi(\\boldsymbol{u}_h,\\boldsymbol\\mu_d)$ are the means defined in the extended space of multiple components. \n\nWe allow dispersion parameters $\\phi_{hd}$ to vary for each of the $k^*$ possible assignment and replicates because it is not directly clear what is the most reasonable variance structure to define through a function for the multiple allocation clusters. This allows, nevertheless, for a certain degree of flexibility in describing the context-specific variability in the data.\n\nWith reference to the means $\\mu_{dh}^*$ they are modelled as function of  primary $k$ means through the combining function $\\psi$. More specifically, with reference to the connection matrix $U$ in formula (\\ref{con.mat}), $\\mu_{d1}^*$ is the mean parameter in condition $d$ of the outward distribution; $\\mu_{d2}^*$ is the mean parameter of the units that belong to the first primary group only and not to mixed groups, and so on, till $\\mu_{d8}^*$ that is the mean of the units that belong simultaneously to the three components under condition $d$. Given the nature of the data we consider the `outward' group as the component devoted to describe the inactive genes and for this reason we fix its mean to a very low value, such as $\\mu_{d1}^*=0.01$. The other mean parameters are obtained as combined function through $\\psi$ of $k$ primary values that represent the means of the units that belong to the primary groups or related multiple groups. In order to construct an hierarchical form of the model, we define with $\\boldsymbol{z}^*$ the allocation matrix in the augmented space given by $k^*$ as a $p \\times k^*$ `multinomial' matrix. While each row of $\\boldsymbol{z}$ can have multiple ones according to the assignment of the unit to multiple clusters, the rows of $\\boldsymbol{z}^*$ only have a single one and the matrix $U$ allows for a connection between original parametrization allocation and the re-parametrized version. Given the whole set of parameters, say $\\Theta$, the joint complete likelihood of our model is the following:\n\n", "itemtype": "equation", "pos": 15005, "prevtext": "\n\\item or order 0:\n \n", "index": 7, "text": "$$\\psi(\\boldsymbol{u}_h,\\boldsymbol\\theta)=\\left(\\prod_{i=1}^k \\boldsymbol\\theta_i^{u_{hi}}\\right)^{1/\\sum_{i=1}^k u_{hi}}+ \\boldsymbol\\theta_b\\mathds{1}_{\\left[ {{\\sum_{i=1}^{k^*}u_{hi}=0}} \\right] }.$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\theta})=\\left(\\prod_{i=1}^{k}\\boldsymbol{%&#10;\\theta}_{i}^{u_{hi}}\\right)^{1/\\sum_{i=1}^{k}u_{hi}}+\\boldsymbol{\\theta}_{b}%&#10;\\mathds{1}_{\\left[{{\\sum_{i=1}^{k^{*}}u_{hi}=0}}\\right]}.\" display=\"block\"><mrow><mrow><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msubsup><mi>\ud835\udf3d</mi><mi>i</mi><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></msubsup></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mrow><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup></mstyle><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></mrow></msup><mo>+</mo><mrow><msub><mi>\ud835\udf3d</mi><mi>b</mi></msub><mo>\u2062</mo><msub><mn>\ud835\udfd9</mn><mrow><mo>[</mo><mstyle displaystyle=\"false\"><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></msubsup></mstyle><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub><mo>=</mo><mn>0</mn><mo>]</mo></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nInference is carried out within a bayesian framework. The posterior distribution of the parameters and the latent variables is:\n\n", "itemtype": "equation", "pos": 18563, "prevtext": "\n\\end{itemize}\nFinally, $\\phi_h$ are some specific parameters that may be introduced to add flexibility to the mixture model.\n\n\n\n\\subsection{Multiple Allocation Mixture model for ChIP-Seq Data}\n\nSuppose we observe the read counts of $p$ genes in $D$ biological conditions or replicates. We denote $Y_{jd}$ the random variable that expresses the read counts, say $y_{jd}$, mapped to gene $j$ ($j$=$1,...,p$), in sample $d$ with $d=1,\\ldots,D$. Let $\\boldsymbol{Y}_j$ be the random vector of length $D$ denoting the expression profile of a gene. Let $\\boldsymbol{y}_j$ be the observed value. We assume that $Y_{jd}$ is distributed according to the Negative Binomial ($\\mathcal{NB}$) distribution, given both the discrete nature of the observations and the flexibility of having a specific parameter used to model the overdispersion, that makes this distribution preferable to the Poisson. We further assume that, conditionally on the group, the replicates are independent draws so that the mixture model in (\\ref{mod2}) becomes:\n   \\begin{eqnarray}\\label{mod3}\nf(\\boldsymbol{y}_j|\\Theta)=\\sum_{h=1}^{k^*} \\pi_h^*\n\\prod_{d=1}^D \\mathcal{NB}\\left(y_{jd}|\\psi(\\boldsymbol{u}_h,\\boldsymbol\\mu_d),\\phi_{dh}\\right)\n,\\end{eqnarray}\nwhere $\\phi_{dh}$ are specific dispersion parameters of the negative binomials and $\\mu_{dh}^*=\\psi(\\boldsymbol{u}_h,\\boldsymbol\\mu_d)$ are the means defined in the extended space of multiple components. \n\nWe allow dispersion parameters $\\phi_{hd}$ to vary for each of the $k^*$ possible assignment and replicates because it is not directly clear what is the most reasonable variance structure to define through a function for the multiple allocation clusters. This allows, nevertheless, for a certain degree of flexibility in describing the context-specific variability in the data.\n\nWith reference to the means $\\mu_{dh}^*$ they are modelled as function of  primary $k$ means through the combining function $\\psi$. More specifically, with reference to the connection matrix $U$ in formula (\\ref{con.mat}), $\\mu_{d1}^*$ is the mean parameter in condition $d$ of the outward distribution; $\\mu_{d2}^*$ is the mean parameter of the units that belong to the first primary group only and not to mixed groups, and so on, till $\\mu_{d8}^*$ that is the mean of the units that belong simultaneously to the three components under condition $d$. Given the nature of the data we consider the `outward' group as the component devoted to describe the inactive genes and for this reason we fix its mean to a very low value, such as $\\mu_{d1}^*=0.01$. The other mean parameters are obtained as combined function through $\\psi$ of $k$ primary values that represent the means of the units that belong to the primary groups or related multiple groups. In order to construct an hierarchical form of the model, we define with $\\boldsymbol{z}^*$ the allocation matrix in the augmented space given by $k^*$ as a $p \\times k^*$ `multinomial' matrix. While each row of $\\boldsymbol{z}$ can have multiple ones according to the assignment of the unit to multiple clusters, the rows of $\\boldsymbol{z}^*$ only have a single one and the matrix $U$ allows for a connection between original parametrization allocation and the re-parametrized version. Given the whole set of parameters, say $\\Theta$, the joint complete likelihood of our model is the following:\n\n", "index": 9, "text": "\\begin{align}\\label{jcl}\nf(\\boldsymbol{y},\\boldsymbol{z}^* | \\Theta) = f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\Theta)\\cdot f(\\boldsymbol{z}^*|\\Theta).\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle f(\\boldsymbol{y},\\boldsymbol{z}^{*}|\\Theta)=f(\\boldsymbol{y}|%&#10;\\boldsymbol{z}^{*},\\Theta)\\cdot f(\\boldsymbol{z}^{*}|\\Theta).\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo>,</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwith $f(\\Theta | \\boldsymbol{\\xi})$ defining suitable priors for the mixture parameters and $\\boldsymbol{\\xi}$ as the vector containing the hyper-parameters. \nThe posterior in Eq. (\\ref{postdens}) can then be rewritten as:\n\n", "itemtype": "equation", "pos": 18851, "prevtext": "\nInference is carried out within a bayesian framework. The posterior distribution of the parameters and the latent variables is:\n\n", "index": 11, "text": "\\begin{equation}\\label{postdens}\nf(\\boldsymbol{z}^*, \\Theta, \\boldsymbol{\\xi} | \\boldsymbol{y}) \\propto f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\Theta)\\cdot f(\\boldsymbol{z}^*|\\Theta) \\cdot f(\\Theta | \\boldsymbol{\\xi})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"f(\\boldsymbol{z}^{*},\\Theta,\\boldsymbol{\\xi}|\\boldsymbol{y})\\propto f(%&#10;\\boldsymbol{y}|\\boldsymbol{z}^{*},\\Theta)\\cdot f(\\boldsymbol{z}^{*}|\\Theta)%&#10;\\cdot f(\\Theta|\\boldsymbol{\\xi})\" display=\"block\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi mathvariant=\"normal\">\u0398</mi><mo>,</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u0398</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwhere $ f(\\boldsymbol{\\pi} | \\boldsymbol{\\xi}), f(\\boldsymbol{\\mu} | \\boldsymbol{\\xi})$ and $ f(\\boldsymbol{\\phi} | \\boldsymbol{\\xi})$ are prior distributions for these quantities.\nAs prior distribution for the weights we assume a Beta distribution so that we get the following hierarchical structure:\n\n", "itemtype": "equation", "pos": 19304, "prevtext": "\nwith $f(\\Theta | \\boldsymbol{\\xi})$ defining suitable priors for the mixture parameters and $\\boldsymbol{\\xi}$ as the vector containing the hyper-parameters. \nThe posterior in Eq. (\\ref{postdens}) can then be rewritten as:\n\n", "index": 13, "text": "\\begin{align}\\label{postNegBin}\n\\nonumber &f(\\boldsymbol{z}^*,\\boldsymbol{\\pi}, \\boldsymbol{\\mu}, \\boldsymbol{\\phi}, \\boldsymbol{\\xi} | \\boldsymbol{y}) \\propto f(\\boldsymbol{y} | \\boldsymbol{z}^*,  \\boldsymbol{\\mu}, \\boldsymbol{\\phi}) f(\\boldsymbol{z}^*| \\boldsymbol{\\pi}) f(\\boldsymbol{\\pi} | \\boldsymbol{\\xi}) f(\\boldsymbol{\\mu} | \\boldsymbol{\\xi}) f(\\boldsymbol{\\phi} | \\boldsymbol{\\xi}) = \\\\\n& \\nonumber  = \\prod_{j=1}^{p} \\prod_{d=1}^{D} \\prod_{h=1}^{k^*} \\left\\{ \\frac{\\Gamma(\\phi_{hd}+y_{jd})}{\\Gamma(\\phi_{hd})\\Gamma(y_{jd}+1)} \\left[ \\frac{\\phi_{hd}}{\\phi_{hd}+\\psi(\\boldsymbol{u}_h, \\boldsymbol{\\mu}_d)} \\right]^{\\phi_{hd}} \\left[ \\frac{\\psi(\\boldsymbol{u}_h, \\boldsymbol{\\mu}_d)}{\\phi_{hd}+\\psi(\\boldsymbol{u}_h, \\boldsymbol{\\mu}_d)} \\right]^{y_{jd}} \\right\\}^{z^*_{jh}} \\times \\\\\n& \\times \\prod_{j=1}^{p} \\prod_{h=1}^{k^*} \\left( \\prod_{i=1}^k\\pi_i^{u_{hi}} (1-\\pi_i)^{1-u_{hi}} \\right)^{z^*_{jh}}   f(\\boldsymbol{\\pi} | \\boldsymbol{\\xi}) f(\\boldsymbol{\\mu} | \\boldsymbol{\\xi}) f(\\boldsymbol{\\phi} | \\boldsymbol{\\xi})\n, \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle f(\\boldsymbol{z}^{*},\\boldsymbol{\\pi},\\boldsymbol{\\mu},%&#10;\\boldsymbol{\\phi},\\boldsymbol{\\xi}|\\boldsymbol{y})\\propto f(\\boldsymbol{y}|%&#10;\\boldsymbol{z}^{*},\\boldsymbol{\\mu},\\boldsymbol{\\phi})f(\\boldsymbol{z}^{*}|%&#10;\\boldsymbol{\\pi})f(\\boldsymbol{\\pi}|\\boldsymbol{\\xi})f(\\boldsymbol{\\mu}|%&#10;\\boldsymbol{\\xi})f(\\boldsymbol{\\phi}|\\boldsymbol{\\xi})=\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udf45</mi><mo>,</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo>,</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi>\ud835\udf45</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf45</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\prod_{j=1}^{p}\\prod_{d=1}^{D}\\prod_{h=1}^{k^{*}}\\left\\{\\frac{%&#10;\\Gamma(\\phi_{hd}+y_{jd})}{\\Gamma(\\phi_{hd})\\Gamma(y_{jd}+1)}\\left[\\frac{\\phi_{%&#10;hd}}{\\phi_{hd}+\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\mu}_{d})}\\right]^{\\phi_{hd%&#10;}}\\left[\\frac{\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\mu}_{d})}{\\phi_{hd}+\\psi(%&#10;\\boldsymbol{u}_{h},\\boldsymbol{\\mu}_{d})}\\right]^{y_{jd}}\\right\\}^{z^{*}_{jh}}\\times\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></munderover></mstyle><msup><mrow><mo>{</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo>+</mo><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u0393</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mrow><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo>+</mo><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><msub><mi>\ud835\udf41</mi><mi>d</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>]</mo></mrow><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub></msup><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><msub><mi>\ud835\udf41</mi><mi>d</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo>+</mo><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><msub><mi>\ud835\udf41</mi><mi>d</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>]</mo></mrow><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub></msup><mo>}</mo></mrow><msubsup><mi>z</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>h</mi></mrow><mo>*</mo></msubsup></msup><mo>\u00d7</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\times\\prod_{j=1}^{p}\\prod_{h=1}^{k^{*}}\\left(\\prod_{i=1}^{k}\\pi_%&#10;{i}^{u_{hi}}(1-\\pi_{i})^{1-u_{hi}}\\right)^{z^{*}_{jh}}f(\\boldsymbol{\\pi}|%&#10;\\boldsymbol{\\xi})f(\\boldsymbol{\\mu}|\\boldsymbol{\\xi})f(\\boldsymbol{\\phi}|%&#10;\\boldsymbol{\\xi}),\" display=\"inline\"><mrow><mo>\u00d7</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></munderover></mstyle><msup><mrow><mo>(</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover></mstyle><msubsup><mi>\u03c0</mi><mi>i</mi><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></msubsup><msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><msub><mi>\u03c0</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></msup><mo>)</mo></mrow><msubsup><mi>z</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>h</mi></mrow><mo>*</mo></msubsup></msup><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf45</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nFor the other two parameters we select conjugate and flat priors. More precisely,\n\n", "itemtype": "equation", "pos": 20650, "prevtext": "\nwhere $ f(\\boldsymbol{\\pi} | \\boldsymbol{\\xi}), f(\\boldsymbol{\\mu} | \\boldsymbol{\\xi})$ and $ f(\\boldsymbol{\\phi} | \\boldsymbol{\\xi})$ are prior distributions for these quantities.\nAs prior distribution for the weights we assume a Beta distribution so that we get the following hierarchical structure:\n\n", "index": 15, "text": "\\begin{align}\n\\label{hier}\n\\boldsymbol{\\pi} &\\sim Beta\\left(\\frac{1}{2},\\frac{1}{2} \\right) \\nonumber  \\\\\nP(\\boldsymbol{z}_{jh}^* = 1 | \\boldsymbol{\\pi}^*) &= \\pi^*_{h} \\\\\n\\boldsymbol{y}_{jd} | \\boldsymbol{z}^*_{jh} ; \\boldsymbol{\\Theta} & \\sim \\mathcal{NB}(\\psi(\\boldsymbol{u}_h,\\boldsymbol{\\mu_d}); \\boldsymbol{\\phi}) \\nonumber.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\boldsymbol{\\pi}\" display=\"inline\"><mi>\ud835\udf45</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim Beta\\left(\\frac{1}{2},\\frac{1}{2}\\right)\" display=\"inline\"><mrow><mi/><mo>\u223c</mo><mrow><mi>B</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>t</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>,</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle P(\\boldsymbol{z}_{jh}^{*}=1|\\boldsymbol{\\pi}^{*})\" display=\"inline\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\ud835\udc9b</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>h</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mn>1</mn><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udf45</mi><mo>*</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\pi^{*}_{h}\" display=\"inline\"><mrow><mi/><mo>=</mo><msubsup><mi>\u03c0</mi><mi>h</mi><mo>*</mo></msubsup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\boldsymbol{y}_{jd}|\\boldsymbol{z}^{*}_{jh};\\boldsymbol{\\Theta}\" display=\"inline\"><mrow><msub><mi>\ud835\udc9a</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">|</mo><msubsup><mi>\ud835\udc9b</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>h</mi></mrow><mo>*</mo></msubsup><mo>;</mo><mi>\ud835\udeaf</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\mathcal{NB}(\\psi(\\boldsymbol{u}_{h},\\boldsymbol{\\mu_{d}});%&#10;\\boldsymbol{\\phi}).\" display=\"inline\"><mrow><mrow><mi/><mo>\u223c</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><msub><mi>\ud835\udf41</mi><mi>\ud835\udc85</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>;</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\nGiven these chosen priors, full conditionals can be derived and a Gibbs sampling MCMC algorithm applied to estimate the parameters. At the implementation step of the algorithm we exploit the Gamma-Poisson mixture representation of a Negative Binomial distribution. We introduce a further latent variabile $s$, specific to each unit $j$ in each replicate/condition $d$, that has a Gamma density with shape and rate parameters equal to $\\phi_{hd}$. It follows that:\n\n", "itemtype": "equation", "pos": 21075, "prevtext": "\nFor the other two parameters we select conjugate and flat priors. More precisely,\n\n", "index": 17, "text": "\\begin{align}\n\\nonumber \\mu &\\sim Gam(1,0.001) \\\\\n\\phi &\\sim Unif(100,2000).\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mu\" display=\"inline\"><mi>\u03bc</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim Gam(1,0.001)\" display=\"inline\"><mrow><mi/><mo>\u223c</mo><mrow><mi>G</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>,</mo><mn>0.001</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\phi\" display=\"inline\"><mi>\u03d5</mi></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim Unif(100,2000).\" display=\"inline\"><mrow><mrow><mi/><mo>\u223c</mo><mrow><mi>U</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mn>100</mn><mo>,</mo><mn>2000</mn><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwhich allows us to use a Gibbs sampler for the mean parameters $\\mu_i$.\n\n\n\n\\subsection{Modelling spatial correlation with a CAR structure}\n\nThe units/observations (in our case, genes or genomic locations) are not independent but spatially correlated. We introduce the spatial correlation by allowing the primary weights $\\pi_i $ to be $j$-varying and we denote them as $\\pi_{ij}$. The spatial relationship is taken into account by allowing the weights of the mixture in (\\ref{mod2}) to vary from one gene to another. The way we formulate it is inspired by the work proposed by \\cite{Fern}. They first introduced $k$ independent $p$-dimensional latent variables with a Markov random-field distribution. The weights are then a non-linear function of these latent variables and spatial relationships are expressed in terms of neighborhood relationships. In other terms, two genes may be considered neighbour or not, despite their factual distance. This could be restrictive because the correlation between two genes should decrease as their distance increases. We extended the approach by considering a Gaussian conditional auto-regressive model \\citep{Pettitt}, where the distances are directly used to model correlations instead of dummies denoting the neighborhood condition. In a Bayesian framework, this is accomplished by introducing additional layers to the hierarchy formulation show in Eq. \\ref{hier}, with their own set of hyper-parameters. With reference to $\\boldsymbol\\pi$, we introduce the spatial latent vectors, denoted by $\\boldsymbol{x}_1,\\ldots, \\boldsymbol{x}_i, \\ldots, \\boldsymbol{x}_k$, with $i=1,\\ldots,k$: each $\\boldsymbol{x}_i$ is a Gaussian conditional autoregressive model given by\n\\begin{eqnarray}\\label{eqn:car}\nf(\\boldsymbol{x}_i)=\\mathcal{N}(\\boldsymbol{0},Q^{-1})\n\\end{eqnarray}\nwhere $Q$ is a matrix of order $p$ with\n\\begin{itemize}\n\\item $Q=I_p + \\Delta - \\Gamma $\n\\item $\\gamma_{jj'}$ is a non-linear function of $\\delta_{jj'}$, which are the distances between all the units\n\\end{itemize}\n\n\n", "itemtype": "equation", "pos": 21629, "prevtext": "\n\nGiven these chosen priors, full conditionals can be derived and a Gibbs sampling MCMC algorithm applied to estimate the parameters. At the implementation step of the algorithm we exploit the Gamma-Poisson mixture representation of a Negative Binomial distribution. We introduce a further latent variabile $s$, specific to each unit $j$ in each replicate/condition $d$, that has a Gamma density with shape and rate parameters equal to $\\phi_{hd}$. It follows that:\n\n", "index": 19, "text": "\\begin{align}\n\\nonumber &f(s_{jd}) = \\textit{Gam}( \\phi_{hd}, \\phi_{hd} ) \\\\\n\\nonumber &f(y_{jd} | s_{jd} ) = \\textit{Pois}(\\psi(\\boldsymbol{u}_h, \\boldsymbol{\\mu}_d) s_{jd}) \\\\\n\\nonumber &f(y_{jd} ) = \\int f(y_{jd} | s_{jd}) f(s_{jd}) ds = \\mathcal{NB}(\\psi(\\boldsymbol{u}_h; \\boldsymbol{\\mu}_d),\\phi_{hd})\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle f(s_{jd})=\\textit{Gam}(\\phi_{hd},\\phi_{hd})\" display=\"inline\"><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mtext>\ud835\udc3a\ud835\udc4e\ud835\udc5a</mtext><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo>,</mo><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle f(y_{jd}|s_{jd})=\\textit{Pois}(\\psi(\\boldsymbol{u}_{h},%&#10;\\boldsymbol{\\mu}_{d})s_{jd})\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">|</mo><msub><mi>s</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>\ud835\udc43\ud835\udc5c\ud835\udc56\ud835\udc60</mtext><mrow><mo stretchy=\"false\">(</mo><mi>\u03c8</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>,</mo><msub><mi>\ud835\udf41</mi><mi>d</mi></msub><mo stretchy=\"false\">)</mo></mrow><msub><mi>s</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle f(y_{jd})=\\int f(y_{jd}|s_{jd})f(s_{jd})ds=\\mathcal{NB}(\\psi(%&#10;\\boldsymbol{u}_{h};\\boldsymbol{\\mu}_{d}),\\phi_{hd})\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" symmetric=\"true\">\u222b</mo></mstyle><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">|</mo><msub><mi>s</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><mi>s</mi><mo>=</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udca9</mi><mi class=\"ltx_font_mathcaligraphic\">\u212c</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03c8</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc96</mi><mi>h</mi></msub><mo>;</mo><msub><mi>\ud835\udf41</mi><mi>d</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><msub><mi>\u03d5</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>d</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\n\n\n", "itemtype": "equation", "pos": 23974, "prevtext": "\nwhich allows us to use a Gibbs sampler for the mean parameters $\\mu_i$.\n\n\n\n\\subsection{Modelling spatial correlation with a CAR structure}\n\nThe units/observations (in our case, genes or genomic locations) are not independent but spatially correlated. We introduce the spatial correlation by allowing the primary weights $\\pi_i $ to be $j$-varying and we denote them as $\\pi_{ij}$. The spatial relationship is taken into account by allowing the weights of the mixture in (\\ref{mod2}) to vary from one gene to another. The way we formulate it is inspired by the work proposed by \\cite{Fern}. They first introduced $k$ independent $p$-dimensional latent variables with a Markov random-field distribution. The weights are then a non-linear function of these latent variables and spatial relationships are expressed in terms of neighborhood relationships. In other terms, two genes may be considered neighbour or not, despite their factual distance. This could be restrictive because the correlation between two genes should decrease as their distance increases. We extended the approach by considering a Gaussian conditional auto-regressive model \\citep{Pettitt}, where the distances are directly used to model correlations instead of dummies denoting the neighborhood condition. In a Bayesian framework, this is accomplished by introducing additional layers to the hierarchy formulation show in Eq. \\ref{hier}, with their own set of hyper-parameters. With reference to $\\boldsymbol\\pi$, we introduce the spatial latent vectors, denoted by $\\boldsymbol{x}_1,\\ldots, \\boldsymbol{x}_i, \\ldots, \\boldsymbol{x}_k$, with $i=1,\\ldots,k$: each $\\boldsymbol{x}_i$ is a Gaussian conditional autoregressive model given by\n\\begin{eqnarray}\\label{eqn:car}\nf(\\boldsymbol{x}_i)=\\mathcal{N}(\\boldsymbol{0},Q^{-1})\n\\end{eqnarray}\nwhere $Q$ is a matrix of order $p$ with\n\\begin{itemize}\n\\item $Q=I_p + \\Delta - \\Gamma $\n\\item $\\gamma_{jj'}$ is a non-linear function of $\\delta_{jj'}$, which are the distances between all the units\n\\end{itemize}\n\n\n", "index": 21, "text": "$$ Q=\\left\\{\n\\begin{array}{ll}\n\t1+ \\sum_{j'=1}^{p} \\gamma_{jj'}  & \\mbox{if diagonal element} \\\\\n\t-\\gamma_{jj'} & \\mbox{elsewhere} \\\\\n\\end{array}\n\\right. $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"Q=\\left\\{\\begin{array}[]{ll}1+\\sum_{j^{\\prime}=1}^{p}\\gamma_{jj^{\\prime}}&amp;%&#10;\\mbox{if diagonal element}\\\\&#10;-\\gamma_{jj^{\\prime}}&amp;\\mbox{elsewhere}\\\\&#10;\\end{array}\\right.\" display=\"block\"><mrow><mi>Q</mi><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><msub><mi>\u03b3</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub></mrow></mrow></mtd><mtd columnalign=\"left\"><mtext>if diagonal element</mtext></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mo>-</mo><msub><mi>\u03b3</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub></mrow></mtd><mtd columnalign=\"left\"><mtext>elsewhere</mtext></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\nand\n\n\n", "itemtype": "equation", "pos": 24133, "prevtext": "\n\n\n\n", "index": 23, "text": "$$  \\Delta=\\left[\n\\begin{array}{cccc}\n  \\ddots  & 0 & \\dots & 0 \\\\\n  0 & \\sum_{j \\sim j'}^{p}  \\gamma_{jj'} & \\dots & 0 \\\\\n  0 & 0 & \\ddots & 0 \\\\\n  0 & 0 & \\dots & 0 \\\\\n\\end{array}\n\\right] $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\Delta=\\left[\\begin{array}[]{cccc}\\ddots&amp;0&amp;\\dots&amp;0\\\\&#10;0&amp;\\sum_{j\\sim j^{\\prime}}^{p}\\gamma_{jj^{\\prime}}&amp;\\dots&amp;0\\\\&#10;0&amp;0&amp;\\ddots&amp;0\\\\&#10;0&amp;0&amp;\\dots&amp;0\\\\&#10;\\end{array}\\right]\" display=\"block\"><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>=</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u223c</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow><mi>p</mi></munderover><msub><mi>\u03b3</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub></mrow></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\n\nAfter some algebraic steps it is possible to show that (\\ref{eqn:car}) is equivalent to\n\\begin{eqnarray}\\label{eqn:carbis}\nf(\\boldsymbol{x}_i )=\nc \\cdot \\exp \\left\\{ -\\frac{1}{2} \\left[ \\sum_{j=1}^{p} \\sum_{j'=1}^{p} \\gamma_{jj'} (x_{ij}-x_{ij'})^2 + \\sum_{j=1}^{p} x_{ij}^{2} \\right] \\right\\}\n\\end{eqnarray}\nwith $c$ the normalization constant\n\n", "itemtype": "equation", "pos": 24332, "prevtext": "\n\nand\n\n\n", "index": 25, "text": "$$ \\Gamma=\\left[\n\\begin{array}{cccc}\n  0  & \\gamma_{1,2} & \\dots & \\gamma_{1,p} \\\\\n  \\gamma_{2,1} & 0 & \\dots & \\vdots \\\\\n  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n  \\gamma_{p,1} & \\dots & \\dots & 0 \\\\\n\\end{array}\n\\right]\n $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\Gamma=\\left[\\begin{array}[]{cccc}0&amp;\\gamma_{1,2}&amp;\\dots&amp;\\gamma_{1,p}\\\\&#10;\\gamma_{2,1}&amp;0&amp;\\dots&amp;\\vdots\\\\&#10;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\&#10;\\gamma_{p,1}&amp;\\dots&amp;\\dots&amp;0\\\\&#10;\\end{array}\\right]\" display=\"block\"><mrow><mi mathvariant=\"normal\">\u0393</mi><mo>=</mo><mrow><mo>[</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><msub><mi>\u03b3</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><msub><mi>\u03b3</mi><mrow><mn>1</mn><mo>,</mo><mi>p</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>\u03b3</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22f1</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u22ee</mi></mtd></mtr><mtr><mtd columnalign=\"center\"><msub><mi>\u03b3</mi><mrow><mi>p</mi><mo>,</mo><mn>1</mn></mrow></msub></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mi mathvariant=\"normal\">\u2026</mi></mtd><mtd columnalign=\"center\"><mn>0</mn></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nIn the previous expression, $v_j$'s denote the eigenvalues of the spatial matrix $\\Delta-\\Gamma$. Given $\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_k$, the weights for location $j$ can be obtained via logistic formulation\n\n", "itemtype": "equation", "pos": 24901, "prevtext": "\n\nAfter some algebraic steps it is possible to show that (\\ref{eqn:car}) is equivalent to\n\\begin{eqnarray}\\label{eqn:carbis}\nf(\\boldsymbol{x}_i )=\nc \\cdot \\exp \\left\\{ -\\frac{1}{2} \\left[ \\sum_{j=1}^{p} \\sum_{j'=1}^{p} \\gamma_{jj'} (x_{ij}-x_{ij'})^2 + \\sum_{j=1}^{p} x_{ij}^{2} \\right] \\right\\}\n\\end{eqnarray}\nwith $c$ the normalization constant\n\n", "index": 27, "text": "$$ c=(2\\pi)^{-p/2} \\prod_{j=1}^{p} (1+v_j)^{1/2} $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"c=(2\\pi)^{-p/2}\\prod_{j=1}^{p}(1+v_{j})^{1/2}\" display=\"block\"><mrow><mi>c</mi><mo>=</mo><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mo>-</mo><mrow><mi>p</mi><mo>/</mo><mn>2</mn></mrow></mrow></msup><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>+</mo><msub><mi>v</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwhere $\\eta$ is a `shrink-or-stretch' tuning parameter to be estimated that provides a way to exaggerate the differences in units allocation among the clusters.\n\n\n\\subsection{Conditional Auto-Regressive Multiple Allocation Mixture (\\emph{CAR-MAM})}\n\nIn order to account for spatial correlation between the units/observations (in our case, genes or genetic locations), we introduce another layer in the hierarchical structure of the model. Starting from Eq. \\ref{jcl}, the updated joint complete likelihood is:\n\n", "itemtype": "equation", "pos": 25171, "prevtext": "\nIn the previous expression, $v_j$'s denote the eigenvalues of the spatial matrix $\\Delta-\\Gamma$. Given $\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_k$, the weights for location $j$ can be obtained via logistic formulation\n\n", "index": 29, "text": "$$ \\pi_{ij}= \\frac{\\exp(x_{ij}/ \\eta)}{1+\\exp(x_{ij}/ \\eta)} $$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\pi_{ij}=\\frac{\\exp(x_{ij}/\\eta)}{1+\\exp(x_{ij}/\\eta)}\" display=\"block\"><mrow><msub><mi>\u03c0</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nleading to the following posterior distribution\n\n", "itemtype": "equation", "pos": 25745, "prevtext": "\nwhere $\\eta$ is a `shrink-or-stretch' tuning parameter to be estimated that provides a way to exaggerate the differences in units allocation among the clusters.\n\n\n\\subsection{Conditional Auto-Regressive Multiple Allocation Mixture (\\emph{CAR-MAM})}\n\nIn order to account for spatial correlation between the units/observations (in our case, genes or genetic locations), we introduce another layer in the hierarchical structure of the model. Starting from Eq. \\ref{jcl}, the updated joint complete likelihood is:\n\n", "index": 31, "text": "\\begin{equation}\nf(\\boldsymbol{y},\\boldsymbol{z}^*, \\boldsymbol{x} | \\boldsymbol{\\mu}, \\boldsymbol{\\phi}, \\eta, \\boldsymbol{\\xi}) = f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\boldsymbol{\\mu}, \\boldsymbol{\\phi})  f(\\boldsymbol{z}^*| \\boldsymbol{x}, \\eta)  f(\\boldsymbol{x} | \\boldsymbol{\\xi})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"f(\\boldsymbol{y},\\boldsymbol{z}^{*},\\boldsymbol{x}|\\boldsymbol{\\mu},%&#10;\\boldsymbol{\\phi},\\eta,\\boldsymbol{\\xi})=f(\\boldsymbol{y}|\\boldsymbol{z}^{*},%&#10;\\boldsymbol{\\mu},\\boldsymbol{\\phi})f(\\boldsymbol{z}^{*}|\\boldsymbol{x},\\eta)f(%&#10;\\boldsymbol{x}|\\boldsymbol{\\xi})\" display=\"block\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo>,</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo>,</mo><mi>\u03b7</mi><mo>,</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi>\ud835\udc99</mi><mo>,</mo><mi>\u03b7</mi><mo stretchy=\"false\">)</mo></mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwhere the vector $\\boldsymbol{\\xi}$ now also contains the hyper-parameters for the new latent layer and $f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\boldsymbol{\\mu}, \\boldsymbol{\\phi})$ is defined as in Eq. \\ref{postNegBin}. More precisely, the complete latent structure in Eq. \\ref{postcar} is equal to:\n\n", "itemtype": "equation", "pos": 26094, "prevtext": "\nleading to the following posterior distribution\n\n", "index": 33, "text": "\\begin{align}\\label{postcar}\nf(\\boldsymbol{z}^*, \\boldsymbol{x}, \\boldsymbol{\\mu}, \\boldsymbol{\\phi}, \\eta & |\\boldsymbol{y}, \\boldsymbol{\\xi})  \\propto f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\boldsymbol{\\mu}, \\boldsymbol{\\phi})  f(\\boldsymbol{z}^*| \\eta, \\boldsymbol{x})  f(\\boldsymbol{x}| \\boldsymbol{\\xi}) f(\\boldsymbol{\\mu} | \\boldsymbol{\\xi}) f(\\boldsymbol{\\phi} | \\boldsymbol{\\xi})\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle f(\\boldsymbol{z}^{*},\\boldsymbol{x},\\boldsymbol{\\mu},\\boldsymbol%&#10;{\\phi},\\eta\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udc99</mi><mo>,</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo>,</mo><mi>\u03b7</mi></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle|\\boldsymbol{y},\\boldsymbol{\\xi})\\propto f(\\boldsymbol{y}|%&#10;\\boldsymbol{z}^{*},\\boldsymbol{\\mu},\\boldsymbol{\\phi})f(\\boldsymbol{z}^{*}|%&#10;\\eta,\\boldsymbol{x})f(\\boldsymbol{x}|\\boldsymbol{\\xi})f(\\boldsymbol{\\mu}|%&#10;\\boldsymbol{\\xi})f(\\boldsymbol{\\phi}|\\boldsymbol{\\xi})\" display=\"inline\"><mrow><mo stretchy=\"false\">|</mo><mi>\ud835\udc9a</mi><mo>,</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo><mo>\u221d</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udf41</mi><mo>,</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">)</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo stretchy=\"false\">|</mo><mi>\u03b7</mi><mo>,</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">)</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>\ud835\udf41</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">\u03d5</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf43</mi><mo stretchy=\"false\">)</mo></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": "\nwhere $c$ is the constant defined in Eq. \\ref{eqn:carbis}.\nAs proposed in \\cite{Fern}, we integrate out the latent allocation variable $\\boldsymbol{z}$ when implementing the Metropolis sampler for $\\boldsymbol{x}$ in order to employ the information carried by the data $\\boldsymbol{y}$ and bring closer the two layers of the hierarchical structure of the model.\n\n\n\n\\section{Results}\n\\label{sec3}\n\n\\subsection{Simulation study --- Multiple Allocation Mixture (\\emph{MAM}) model}\n\nWe assess the performance of our model (\\emph{MAM}) under different scenarios and we compare it with a classical non-overlapping components mixture (\\emph{NegBinMix}). Data are generated from two independent Negative Binomial distributions ($D=2$) and $p=2000$ units, allowing for overlapping clusters with a number of groups $k=\\{2,3\\}$: in the augmented $k^*$ space this equals to represent a situation, as in a classical model-based clustering framework, where the actual number of groups ranges from $k^*=4$ to $k^*=8$. We explore three degrees of clustering between primary and outward/non-primary groups by selecting three scenarios which we call low, medium and high activation: this is achieved by setting all the $\\pi$ equal to - respectively - $0.25$, $0.50$ and $0.75$. We run both algorithms (\\emph{MAM} and \\emph{NegBinMix}) for 10000 MCMC iterations and a 5000 burn-in window is selected. Convergence is checked for every chain and we choose as an overall performance indicator the misclassification error rate (see Table \\ref{tabNegBinMix}). The posterior means for the parameters in the selected models (both the overlapping and non-overlapping mixtures) are consistent with the true values and do not show any substantial bias. We report the misclassification error rates for the estimated models in Table \\ref{tabNegBinMix}: the percentage of misclassified units is always lower in the low activation scenario because most of the observations are allocated in the outward component, which has small variance and near zero (fixed) mean, thus simplifying the clustering task. As we can see in Table \\ref{tabNegBinMix}, our model has comparable (sometimes better) classification rates, with respect to the conventional mixture of Negative Binomial, in simpler simulated dataset ($k=2$). When $k=3$, \\emph{MAM} model always outperforms the compared mixture with noticeable improvements on the misclassification error rate.\n\n\\subsection{Simulation study --- \\emph{MAM} with Conditional Autoregressive model (\\emph{CAR-MAM})}\n\nWe simulate data from a mixture of Negative Binomials with multiple allocation and spatial information; we choose $k=2,3,4$ $(k^*=4,8,16)$ and for every number of groups we adopt two different spatial structures. In the former, the latent variable $\\boldsymbol{x}$ is drawn from a CAR model using a reciprocal function $\\gamma_{jj'}$ \\citep[see][]{Pettitt}, which is an inverse function of the distances between uniformly drawn positions ($pos_j$, $j=1,\\dots,p$). In the latter, a sine function is employed in the data generating process, in order to have stronger spatial relationships. More precisely, we assume that the spatial latent vectors, $\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_k$ are:\n\n", "itemtype": "equation", "pos": 26789, "prevtext": "\nwhere the vector $\\boldsymbol{\\xi}$ now also contains the hyper-parameters for the new latent layer and $f(\\boldsymbol{y} | \\boldsymbol{z}^*,\\boldsymbol{\\mu}, \\boldsymbol{\\phi})$ is defined as in Eq. \\ref{postNegBin}. More precisely, the complete latent structure in Eq. \\ref{postcar} is equal to:\n\n", "index": 35, "text": "\\begin{align*}\nf(\\boldsymbol{z}^*, \\boldsymbol{x}| \\eta) &= \\prod_{j=1}^p \\prod_{h=1}^{k^*} \\left[ \\prod_{i=1}^k\\left( \\frac{\\exp(x_{ij}/\\eta)}{1+\\exp(x_{ij}/\\eta)}  \\right)^{u_{hi}}  \\left(1- \\frac{\\exp(x_{ij}/\\eta)}{1+\\exp(x_{ij}/\\eta)}  \\right)^{1-u_{hi}}  \\right]^{z_{jh}^*}  \\times \\\\\n\\times & \\prod_{i=1}^k c\\exp \\left\\{ -\\frac{1}{2} \\left[  \\sum_{j=1}^{p} \\sum_{j'=1}^{p} \\gamma_{jj'} (x_{ij}-x_{ij'})^2 + \\sum_{j=1}^{p} x_{ij}^2 \\right] \\right\\}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle f(\\boldsymbol{z}^{*},\\boldsymbol{x}|\\eta)\" display=\"inline\"><mrow><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc9b</mi><mo>*</mo></msup><mo>,</mo><mi>\ud835\udc99</mi><mo stretchy=\"false\">|</mo><mi>\u03b7</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\prod_{j=1}^{p}\\prod_{h=1}^{k^{*}}\\left[\\prod_{i=1}^{k}\\left(%&#10;\\frac{\\exp(x_{ij}/\\eta)}{1+\\exp(x_{ij}/\\eta)}\\right)^{u_{hi}}\\left(1-\\frac{%&#10;\\exp(x_{ij}/\\eta)}{1+\\exp(x_{ij}/\\eta)}\\right)^{1-u_{hi}}\\right]^{z_{jh}^{*}}\\times\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><msup><mi>k</mi><mo>*</mo></msup></munderover></mstyle><msup><mrow><mo>[</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover></mstyle><msup><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></msup><msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>/</mo><mi>\u03b7</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>u</mi><mrow><mi>h</mi><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow></msup><mo>]</mo></mrow><msubsup><mi>z</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>h</mi></mrow><mo>*</mo></msubsup></msup><mo>\u00d7</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\times\" display=\"inline\"><mo>\u00d7</mo></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\prod_{i=1}^{k}c\\exp\\left\\{-\\frac{1}{2}\\left[\\sum_{j=1}^{p}\\sum_{%&#10;j^{\\prime}=1}^{p}\\gamma_{jj^{\\prime}}(x_{ij}-x_{ij^{\\prime}})^{2}+\\sum_{j=1}^{%&#10;p}x_{ij}^{2}\\right]\\right\\}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover></mstyle><mrow><mi>c</mi><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mo>-</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo>[</mo><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msup><mi>j</mi><mo>\u2032</mo></msup><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><mrow><msub><mi>\u03b3</mi><mrow><mi>j</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover></mstyle><msubsup><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mn>2</mn></msubsup></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04879.tex", "nexttext": " Figure \\ref{sine} shows the spatial latent functions for $i$ up to $k=4$. For each scenario we run three algorithms assuming $k$ is known: \\emph{NegBinMix}, which is a mixture of Negative Binomials without any further specification, and our two proposed models \\emph{MAM} and \\emph{CAR-MAM} assuming that the conditional autoregressive structure is computed through a reciprocal function $\\gamma_{jj'}$. We average the misclassification error rates across 100 independent datasets simulated for each scenario and we compare the results to assess the performance. In Figure \\ref{figCARMAM} and Figure \\ref{figCARMAMsine} we summarize the misclassification error for each model: boxplots of 100 runs are provided in both scenarios, where data were generated - respectively - with a reciprocal function for the \\emph{CAR} part of the model or a sine function. As clear from the figures, we achieve improved accuracy in the clustering task with  \\emph{CAR-MAM} model over the simpler \\emph{MAM} model and both of them perform better with respect to \\emph{NegBinMix} (Table \\ref{tabCARMAM}) even when the estimated conditional autoregressive structure is not the same as the one used in the data generating process (Table \\ref{tabCARMAMsine}).\n\n\n\\subsection{Real data application on p300 protein binding ChIP-Seq experiment}\n\nWe apply our model to the data already discussed in the introduction and previously analysed by \\cite{Ramos2010}. We select two technical replicates (T01, T02) collected 30 minutes after the initial interaction between the chromatin and the protein p300 on a sequence of 1000 base-pairs windows describing the pre-processed raw counts across 33916 regions of the chromosome 21 (see Figure \\ref{plot_full}). We focus our analysis on a smaller size of the sample consisting of 4000 units ranging from region 16500 to region 20499 (see Figure \\ref{plot_zoom}). As we can see in the plot, showing data for technical replicate T01, the majority of the observations lie in a `band' of counts lower than 5, aggregated into segments that are spanned by smaller batch of regions exhibiting a higher count level, thus suggesting a spatial effect with respect to the protein binding process. In ChIP-Seq data like the one investigated, researchers usually associate the counts to two specific components: a background level, which accounts for the noise in the process and the inactivity of the regions with respect to protein binding; a signal level, that is described by a higher counts of sequenced DNA fragments, indicating that the protein is actually interacting with those specific genomic regions. We thus run the algorithm with $k=2$ ($k^*=4$) in order to capture the two aforementioned expected groups and potentially a better characterization of them through our multiple allocation cluster, while simultaneously taking into account the spatial dependency between the genomic regions. We choose the geometric mean as our $\\psi(\\cdot)$ function to lessen the effect (on the multiple allocation cluster mean values) produced by the highest counts. Out of the 4000 genomic regions, 159 are allocated in the outward cluster, which accounts for the zero-inflation in the data, represented by the observations around positions 17200 and 18000 (see Figure \\ref{plot_results}). This group has fixed mean values equal to 0.01 for both replicates T01 and T02, while the dispersion parameters are estimated by the algorithm. The first primary cluster $i=1$, whose units are indicated by green dots in Figure \\ref{plot_results}, has posterior means equal to $\\boldsymbol{\\mu}_1=(1.61, 1.07)$ and represents the background process of the protein binding: 3478 possibly inactive genomic regions, with very low counts, are allocated in this group. The second primary cluster, $i=2$, is representative of a signaling group of 48 genomic regions having a higher mean count level of $\\boldsymbol{\\mu}_2=(19.27,34.23)$ depicted with red dots in Figure \\ref{plot_results}. The multiple allocation cluster in our analysis is interpretable as a group of 315 units involved in both the background and signal clusters: in this case, given that we are observing these counts after 30 minutes from the initial interaction of the protein with the strand of chromosome 21, the genomic regions allocated in this cluster could be thought as either being locations that were active immediately at the beginning and now not signaling anymore or the opposite, meaning that those locations are starting only after 30 minutes to interact with the p300 protein. The mean values for this multiple allocation cluster are equal to $5.57$ and $6.06$ in the two replicates T01 and T02: the units belonging to it are shown as blue dots in Figure \\ref{plot_results}. Finally, the posterior probability for each unit to be allocated in the signaling group is shown in Figure \\ref{plot_results} as a magenta solid line. We can see from the plot that this probability is higher in those segments where genomic regions with higher counts are observed; moreover, the allocation weight of the signal component follows a spatial pattern, increasing and decreasing across the analyzed strand and thus accounting for the spatial effect occurring among the observations. We also run the algorithm for a conventional four components Negative Binomial mixture model where we fix to $0.01$ the location parameters of the first one, as in our model. The result shows that only a total of three clusters are estimated, with one of them capturing the same background mean level shared by the fixed component, thus producing a blurred classification with respect to one of the two main processes of interest.\n\n\n\\section{Conclusions}\n\\label{sec4}\n\nMotivated by the analysis of data coming from ChIP-Seq experiments, we proposed an extension of the conventional mixture model that allows for units to simultaneously belong to more than one group. As a by product of the model specification, an outward cluster has been introduced that can be used to describe specific features of the data such as zero-inflation, outliers and so forth. A dependency layer among the units is encoded in the formulation by the means of a conditional autoregressive model, allowing for spatial information to aid the clustering task. We compared our proposed model with a mixture of Negative Binomials to investigate its advantages with respect to the conventional approach: results on the simulated data show an increase in performances in terms of misclassification error rates. We applied our model to data previously analyzed by \\cite{Ramos2010}: a promising richer description of the signal in the observations is found, calling for a potentially deeper biological investigation of those genomic regions associated with it. \nThere are some delicate issues that deserve more future investigation. First, the choice of $k$ is a fundamental aspect because it identifies the number of primary clusters. Some well-known methods such as reversible jump \\citep{GreenRJ} and birth-death process \\citep{Stephens} do not allow an extensive exploration of the range of values for $k$ without incurring in computational issues. However, in some application, this choice could be suggested by the empirical context such as in our case, where a number of primary clusters equal to two was reasonable because they represented background and signal groups. A secondary issue is that, for fixed $k$, identifiability problems may arise when the order of interaction is high. \\cite{Zhang} solved the problem by limiting the overlapped clusters to the second order. From our experimental results, we experienced that this trade-off is more severe when the number of variables is low and in general when the order is four or more.\n\n\n\\section{Software}\n\\label{sec5}\n\nSoftware in the form of R code is available on\nrequest from the corresponding author\\\\(saverio.ranciati2@unibo.it).\n\n\n\n\n\n\n\n\n\n\n\\section*{Acknowledgments}\n\n{\\it Conflict of Interest}: None declared.\n\n\\begin{thebibliography}{1}\n\n\\bibitem[Banerjee \\emph{and others}(2005)\nBanerjee, Krumpleman, Basu, Mooney and Ghosh]{Banerjee}\n\\textsc{Banerjee, A., Krumpleman, S., Basu, S.,\nMooney, R. and Ghosh, J.} (2005).\nModel-based overlapping clustering.\n\\emph{Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining}, ACM, 532--537.\n\n\\bibitem[Battle  \\emph{and others}(2005)\nBattle, Segal, and Koller]{Battle}\n\\textsc{{Battle, A.} and {Segal, E.} and {Koller, D.}} (2005).\nProbabilistic Discovery of Overlapping Cellular Processes and their regulation.\n\\emph{Journal of Computational Biology}, \\textbf{12}, 909--927.\n\n\\bibitem[Banfield and Raftery(1993)\nBanfield and Raftery]{Banfield1993}\n\\textsc{{Banfield, J. P.} and {Raftery, A. E.}} (1993).\nModel-based Gaussian and non-Gaussian clustering.\n\\emph{Biometrics}, \\textbf{49}, 803--821.\n\n\\bibitem[Bao \\emph{and others}(2014)\nBao, Vinciotti, Wit and `t Hoen]{Bao}\n\\textsc{Bao, Y., Vinciotti, V., Wit, E. and A. C. 't Hoen, P.} (2014). Joint modeling of ChIP-seq data via a Markov random field model. \\emph{Biostatistics}, \\textbf{15}(2), 296--310.\n\n\\bibitem[Bezdek(1981)Bezdek]{Bezdek}\n\\textsc{{Bezdek, James C.}} (1981).\n\\emph{Pattern Recognition with Fuzzy Objective Function Algorithms},\nKluwer Academic Publishers, Norwell, MA, USA.\n\n\n\\bibitem[Fern\\'{a}ndez and Green(2002)\nFern\\'{a}ndez and Green]{Fern}\n\\textsc{Fern\\'{a}ndez, C. and Green, P.J.} (2002).\nModelling spatially correlated data via mixtures: a Bayesian approach.\n\\emph{Journal of the Royal Statistical Society: Series B}, \\textbf{64}, 805--826.\n\n\\bibitem[Fraley and Raftery(2002)\nFraley and Raftery]{Fraley2002}\n\\textsc{{Fraley, C.} and {Raftery, A. E.}} (2002).\nModel-based clustering, discriminant analysis and density\nestimation. \\emph{Journal of the American Statistical\nAssociation}, \\textbf{97}, 611--631.\n\n\\bibitem[Fu and Banerjee(2008)\nFu and Banerjee]{Fu}\n\\textsc{{Fu, Q.} and {Banerjee, A.}} (2008).\nMultiplicative Mixture Models for Overlapping Clustering. \\emph{Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. IEEE}, 791--796.\n\n\\bibitem[Green(1995)\nGreen]{GreenRJ}\n\\textsc{{Green, P. J.}} (1995).\nReversible jump Markov Chain, Monte Carlo computation and Bayesian model determination. \\emph{Biometrika}, \\textbf{82}, 711-732.\n\n\\bibitem[Heller and Ghahramani(2007)\nHeller and Ghahramani]{Heller1}\n\\textsc{{Heller, A.K.} and {Ghahramani, Z.}} (2007).\nA Nonparametric Bayesian Approach to Modeling Overlapping Clusters. \\emph{International Conference on Artificial Intelligence and Statistics}, 187--194.\n\n\\bibitem[Heller \\emph{and others}(2008)\nHeller, Wiliamson and Ghahramani]{Heller2}\n\\textsc{{Heller, A.K.} and {Wiliamson, S.} and {Ghahramani, Z.}} (2008).\nStatistical Models for Partial Membership. \\emph{Proceedings of the 25th international conference on Machine learning}, ACM, 392--399.\n\n\\bibitem[McLachlan and Peel(2000)\nMcLachlan and Peel]{McLachlan2000}\n\\textsc{{McLachlan, G. J.} and {Peel, D.}} (2000).\n\\emph{Finite Mixture Models}. Wiley, New York.\n\n\\bibitem[Mo(2012)\n2012]{Mo}\n\\textsc{{Mo, Q.}} (2012).\nA fully Bayesian hidden Ising model for ChIP-seq data analysis. \\emph{Biostatistics}, \\textbf{13}(1), 113--128.\n\n\n\\bibitem[Nagalakshmi \\emph{and others}(2008)\nNagalakshmi, Wang, Waern, Shou, Raha, Gerstein and Snyder]{nag}\n\\textsc{Nagalakshmi, U., and Wang, Z. and Waern, K.  and Shou, C. and Raha, D. and Gerstein, M. and Snyder, M.} (2008).\nThe transcriptional\nlandscape of the yeast genome defined by {RNA} sequencing. \\emph{Science}, \\textbf{320}, 1344:1349, 2008.\n\n\\bibitem[Pettitt \\emph{and others}(2002)\nPettitt, Weir and Hart]{Pettitt}\n\\textsc{Pettitt, A.N., Weir, I.S. and Hart, A.G.,} (2002). A conditional autoregressive Gaussian process for irregularly spaced multivariate data with application to modelling large sets of binary data, \\emph{Statistics and Computing}, \\textbf{12}, 353--367.\n\n\\bibitem[Ramos \\emph{and others}(2010)\nRamos, Hestand, Verlaan, Krabbendam, Ariyurek, van Dam, van Ommen, den Dunnen, Zantema and `t Hoen]{Ramos2010}\n\\textsc{Ramos Y, Hestand M, Verlaan M, Krabbendam E, Ariyurek Y, van Dam H, van Ommen G, den Dunnen J, Zantema A, `t Hoen P} (2010). Genome-wide assessment of differential roles for p300 and CBP in transcription regulation, \\emph{Nucleic Acids Res}, \\textbf{38(16)}, 5396-5408.\n\n\\bibitem[Stephens(2000)\nStephens]{Stephens}\n\\textsc{{Stephens, M.}} (2000).\nBayesian analysis of mixtures models with an unknown number of components - an alternative to reversible jump methods. \\emph{Annals of Statistics}, \\textbf{20}, 40-74.\n\n\n\\bibitem[Zhang(2013)Zhang]{Zhang}\n\\textsc{{Zhang, J.}} (2013). Epistatic Clustering: A Model-Based Approach for Identifying Links Between Clusters. \\textit{Journal of the American Statistical Association}, \\textbf{108}, 1366--1384.\n\n\n\n\\end{thebibliography}\n\n\\begin{table}[!p]\n\\caption{Misclassification error rate (in percentage) for \\emph{NegBinMix} and \\emph{MAM} for the three scenarios of activation.}\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|c|}\n\\hline\n\\multirow{2}{*}{Number of clusters} & \\multirow{2}{*}{Model} & \\multicolumn{3}{|c|}{Degree of activation} \\\\\n\\cline{3-5}\n& & $\\pi_i = 0.25$ & $\\pi_i = 0.50$ & $\\pi_i = 0.75$ \\\\\n\\hline\n$k=2$ & \\emph{MAM} & \\textbf{1.05} & 2.70 & 2.65 \\\\\n($k^*=4$) & \\emph{NegBinMix} & 1.20 & \\textbf{2.65} & \\textbf{2.55} \\\\\n\\hline\n$k=3$ & \\emph{MAM}  & \\textbf{0.95} & \\textbf{3.05} & \\textbf{5.10} \\\\\n($k^*=8$) & \\emph{NegBinMix} & 11.00 & 25.05 & 9.15 \\\\\n\\hline\n\n\\end{tabular}\n\\end{center}\n\\label{tabNegBinMix}\n\\end{table}\n\n\\begin{table}[!p]\n\\caption{Average misclassification error rate (in percentage) over 100 simulated datasets with standard errors in brackets; CAR structure with reciprocal function.}\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|}\n\\hline\nNumber of clusters & \\emph{CAR-MAM} & \\emph{MAM} & \\emph{NegBinMix} \\\\\n\\hline\n$k=2$ $(k^*=4)$ & 26.58 (\\emph{0.001}) & 26.87 (\\emph{0.001}) & 30.40 (\\emph{0.001}) \\\\\n\\hline\n$k=3$ $(k^*=8)$ & 23.60 (\\emph{0.001}) & 28.65 (\\emph{0.009}) & 41.00 (\\emph{0.002}) \\\\\n\\hline\n$k=4$ $(k^*=16)$ & 36.32 (\\emph{0.009}) & 49.84 (\\emph{0.013}) & 60.39 (\\emph{0.002}) \\\\\n\\hline\n\n\\end{tabular}\n\\end{center}\n\\label{tabCARMAM}\n\\end{table}\n\n\\begin{table}[!p]\n\\caption{Average misclassification error rate (in percentage) over 100 simulated datasets with standard errors in brackets; CAR structure with sine function.}\n\\begin{center}\n\\begin{tabular}{|c|c|c|c|}\n\\hline\nNumber of clusters & \\emph{CAR-MAM} & \\emph{MAM} & \\emph{NegBinMix} \\\\\n\\hline\n$k=2$ $(k^*=4)$ & 27.71 (\\emph{0.002}) & 29.13 (\\emph{0.001}) & 35.42 (\\emph{0.001})\\\\\n\\hline\n$k=3$ $(k^*=8)$ & 31.31 (\\emph{0.006}) & 35.06 (\\emph{0.011}) & 40.11 (\\emph{0.002})\\\\\n\\hline\n$k=4$ $(k^*=16)$ & 44.93 (\\emph{0.005}) & 56.12 (\\emph{0.007}) & 57.18 (\\emph{0.003})\\\\\n\\hline\n\n\\end{tabular}\n\\end{center}\n\\label{tabCARMAMsine}\n\\end{table}\n\n\\begin{figure}[!p]\n\\begin{center}\n\\includegraphics[width=12cm,keepaspectratio=TRUE]{plot_full.pdf}\n\\caption{Summarized counts for 33916 bins from the chromosome 21.}\n\\label{plot_full}\n\\end{center}\n\\end{figure}\n\n\\begin{figure}[!p]\n\\begin{center}\n\\includegraphics[width=12cm,keepaspectratio=TRUE]{plot_zoom.pdf}\n\\caption{Summarized counts from bin 16500 to bin 20499.}\n\\label{plot_zoom}\n\\end{center}\n\\end{figure}\n\n\\begin{figure}[!p]\n\\begin{center}\n\\includegraphics[width=12cm,keepaspectratio=TRUE]{sine.pdf}\n\\caption{Graphical visualization of the sine functions for $i=1$ up to $k=4$.}\n\\label{sine}\n\\end{center}\n\\end{figure}\n\n\n\\begin{figure}[!p]\n\\begin{center}\n\\includegraphics[width=15cm,keepaspectratio=TRUE]{boxplot_reciprocal.pdf}\n\\caption{Boxplots of misclassification errors over 100 datasets generated from CAR model using reciprocal function.}\n\\label{figCARMAM}\n\\end{center}\n\\end{figure}\n\n\\begin{figure}[!p]\n\\begin{center}\n\\includegraphics[width=15cm,keepaspectratio=TRUE]{boxplot_sine.pdf}\n\\caption{Boxplots of misclassification errors over 100 datasets generated from CAR model using sine function.}\n\\label{figCARMAMsine}\n\\end{center}\n\\end{figure}\n\n\n\\begin{figure}[h]\n\\hspace{-14mm}  \\includegraphics[scale=0.6]{counts_weight.pdf}\n\\caption{Clustering result for the two technical replicates T01 (\\emph{top}) and T02 (\\emph{bottom}); solid line is the posterior probability to be allocated to the signal group.}\n\\label{plot_results}\n\\end{figure}\n\n\n\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $c$ is the constant defined in Eq. \\ref{eqn:carbis}.\nAs proposed in \\cite{Fern}, we integrate out the latent allocation variable $\\boldsymbol{z}$ when implementing the Metropolis sampler for $\\boldsymbol{x}$ in order to employ the information carried by the data $\\boldsymbol{y}$ and bring closer the two layers of the hierarchical structure of the model.\n\n\n\n\\section{Results}\n\\label{sec3}\n\n\\subsection{Simulation study --- Multiple Allocation Mixture (\\emph{MAM}) model}\n\nWe assess the performance of our model (\\emph{MAM}) under different scenarios and we compare it with a classical non-overlapping components mixture (\\emph{NegBinMix}). Data are generated from two independent Negative Binomial distributions ($D=2$) and $p=2000$ units, allowing for overlapping clusters with a number of groups $k=\\{2,3\\}$: in the augmented $k^*$ space this equals to represent a situation, as in a classical model-based clustering framework, where the actual number of groups ranges from $k^*=4$ to $k^*=8$. We explore three degrees of clustering between primary and outward/non-primary groups by selecting three scenarios which we call low, medium and high activation: this is achieved by setting all the $\\pi$ equal to - respectively - $0.25$, $0.50$ and $0.75$. We run both algorithms (\\emph{MAM} and \\emph{NegBinMix}) for 10000 MCMC iterations and a 5000 burn-in window is selected. Convergence is checked for every chain and we choose as an overall performance indicator the misclassification error rate (see Table \\ref{tabNegBinMix}). The posterior means for the parameters in the selected models (both the overlapping and non-overlapping mixtures) are consistent with the true values and do not show any substantial bias. We report the misclassification error rates for the estimated models in Table \\ref{tabNegBinMix}: the percentage of misclassified units is always lower in the low activation scenario because most of the observations are allocated in the outward component, which has small variance and near zero (fixed) mean, thus simplifying the clustering task. As we can see in Table \\ref{tabNegBinMix}, our model has comparable (sometimes better) classification rates, with respect to the conventional mixture of Negative Binomial, in simpler simulated dataset ($k=2$). When $k=3$, \\emph{MAM} model always outperforms the compared mixture with noticeable improvements on the misclassification error rate.\n\n\\subsection{Simulation study --- \\emph{MAM} with Conditional Autoregressive model (\\emph{CAR-MAM})}\n\nWe simulate data from a mixture of Negative Binomials with multiple allocation and spatial information; we choose $k=2,3,4$ $(k^*=4,8,16)$ and for every number of groups we adopt two different spatial structures. In the former, the latent variable $\\boldsymbol{x}$ is drawn from a CAR model using a reciprocal function $\\gamma_{jj'}$ \\citep[see][]{Pettitt}, which is an inverse function of the distances between uniformly drawn positions ($pos_j$, $j=1,\\dots,p$). In the latter, a sine function is employed in the data generating process, in order to have stronger spatial relationships. More precisely, we assume that the spatial latent vectors, $\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_k$ are:\n\n", "index": 37, "text": "$$x_{ij}=sin\\left(i  \\pi  \\frac{pos_j}{max\\left\\{pos_j\\right\\}_{j=1,\\dots,p}}\\right).$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"x_{ij}=sin\\left(i\\pi\\frac{pos_{j}}{max\\left\\{pos_{j}\\right\\}_{j=1,\\dots,p}}%&#10;\\right).\" display=\"block\"><mrow><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><mi>s</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mfrac><mrow><mi>p</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi><mo>\u2062</mo><msub><mrow><mo>{</mo><mrow><mi>p</mi><mo>\u2062</mo><mi>o</mi><mo>\u2062</mo><msub><mi>s</mi><mi>j</mi></msub></mrow><mo>}</mo></mrow><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>p</mi></mrow></mrow></msub></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]