[{"file": "1601.00318.tex", "nexttext": "\nwhere both the objective function and the inequaility constraints are posynomials and the equality constraints are monomials. Note that in GP there is also an implicit constraint that $\\mathbf{x}\\in{\\mathbb{R}}^n_{++}$. GP in its standard form is not a convex program since posynomials are not convex functions in general. However, we can effectively transform it into a convex problem by using the \\emph{logarithmic transformation trick} on $\\mathbf{x}$, the multiplicative coefficients of each monomial and also each objective/constraint function~\\citep{chiang2005geometric,boyd2007tutorial}. We make the following change: let $\\mathbf{y} = \\log(\\mathbf{x})$, $c_{ik} = \\log(d_{ik}),\\forall i,k$ and take $\\log(\\cdot)$ of each function in (\\ref{equ:gp}). Then the standard GP form is equivalent to the following formulation:\n\n", "itemtype": "equation", "pos": 10741, "prevtext": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\title{A Unified Approach for Learning the Parameters of Sum-Product Networks}\n\\author{\nHan Zhao \\\\\nMachine Learning Department \\\\\nCarnegie Mellon University\\\\\n\\texttt{han.zhao@cs.cmu.edu}\n\\And\nPascal Poupart \\\\\nDavid R. Cheriton School of Computer Science \\\\\nUniversity of Waterloo \\\\\n\\texttt{ppoupart@uwaterloo.ca}\n}\n\n\\maketitle\n\n\\begin{abstract}\nWe present a unified approach for learning the parameters of Sum-Product networks (SPNs). We prove that any complete and decomposable SPN is equivalent to a mixture of trees where each tree corresponds to a product of univariate distributions. Based on the mixture model perspective, we characterize the objective function when learning SPNs based on the maximum likelihood estimation (MLE) principle and show that the optimization problem can be formulated as a signomial program. Both the projected gradient descent (PGD) and the exponentiated gradient (EG) in this setting can be viewed as first order approximations of the signomial program after proper transformation of the objective function. Based on the signomial program formulation, we construct two parameter learning algorithms for SPNs by using sequential monomial approximations (SMA) and the concave-convex procedure (CCCP), respectively. The two proposed methods naturally admit multiplicative updates, hence effectively avoiding the projection operation. With the help of the unified framework, we also show that, in the case of SPNs, CCCP leads to the same algorithm as Expectation Maximization (EM) despite the fact that they are different in general. Extensive experiments on 20 data sets demonstrate the effectiveness and efficiency of the two proposed approaches for learning SPNs. We also show that the proposed methods can improve the performance of structure learning and yield state-of-the-art results. \n\\end{abstract}\n\n\\section{Introduction}\nSum-product networks (SPNs) are new deep architectures that admit exact probabilistic inference in linear time in the size of the network~\\citep{poon2011sum}. Different from traditional graphical models, where a compact representation does not necessarily lead to tractable inference, one of the most appealing advantages of SPNs is that they directly relate the inference complexity with the network size, thus leading to a notion of \\emph{inference-aware learning}~\\citep{peharz2015foundations}, where practitioners can explicitly control the inference cost during the learning of the model. This conceptual simplicity of SPNs does not sacrifice expressiveness. In fact, it has been shown recently that SPNs share the same modeling power as Bayesian networks (BNs) while at the same time being more flexible to encode context-specific independence in the network structure~\\citep{zhao2015spnbn}. Because of their flexibility and modeling power, SPNs have been widely applied in many fields of AI~\\citep{cheng2014spnlm,amer2012sum,peharz2014modeling}.\n\nSimilar to traditional graphical models, there are two main problems when learning SPNs: structure learning and parameter learning. In structure learning the goal is to infer the structure of SPNs directly from the data, and in general this process will also learn a set of parameters for the constructed SPNs (see \\citet{gens2013learning} for more details). However, the parameters obtained along with structure learning are often greedily or locally optimized in the sense that they do not necessarily maximize (minimize) the objective function of interest globally. As a result, structure learning algorithms alone usually cannot fully exploit the expressiveness of the constructed model even when an oracle provides the best structure. Hence an efficient parameter learning algorithm for SPNs can be helpful both as a fine-tuning step after structure learning and as a parameter estimation procedure by itself. \n\n\\citet{poon2011sum,gens2012discriminative} proposed both generative and discriminative learning algorithms for parameters in SPNs. At a high level, these approaches view SPNs as deep architectures and apply projected gradient descent (PGD) to optimize the data log-likelihood. There are several drawbacks associated with PGD.  For example, the projection step in PGD hurts the convergence of the algorithm and it will often lead to solutions on the boundary of the feasible region. In~\\citep{poon2011sum,gens2012discriminative}, they also mentioned the possibility of applying EM algorithms to train SPNs by viewing sum nodes in SPNs as hidden variables. They presented an EM update formula without details. However, the update formula for EM given in~\\citep{poon2011sum,gens2012discriminative} is incorrect, as pointed out by~\\cite{peharz2015foundations}. \n\nIn this paper we take a different perspective and present a unified framework for learning the parameters of SPNs. We prove that any complete and decomposable SPN is equivalent to a mixture of trees where each tree corresponds to a product of univariate distributions. Based on the mixture model perspective, we can precisely characterize the functional form of the objective function based on the network structure. We show that the optimization problem associated with learning the parameters of SPNs based on the MLE principle can be formulated as a signomial program (SP), where both PGD and EG can be viewed as first order approximations of the signomial program after suitable transformations of the objective function. We also show that the signomial program formulation can be equivalently transformed into a difference of convex functions (DCP) formulation, where the objective function of the program can be naturally expressed as a difference of two convex functions. The DCP formulation allows us to develop two efficient optimization algorithms for learning the parameters of SPNs based on sequential monomial approximations (SMA) and the concave-convex procedure (CCCP), respectively. Both proposed approaches naturally admit multiplicative updates, hence effectively deals with the positivity constraints of the optimization. Furthermore, under our unified framework, we also show that CCCP leads to the same algorithm as EM despite that these two approaches are different from each other in general. PGD, EG, SMA and CCCP can all be viewed as different levels of convex relaxation of the original SP.  Hence the framework also provides an intuitive way to compare all four approaches. We conduct extensive experiments on 20 benchmark data sets to compare the empirical performance of PGD, EG, SMA and CCCP. Experimental results validate our theoretical analysis that CCCP is the best among all 4 approaches, showing that it converges consistently faster and with more stability than the other three methods. Furthermore, we use CCCP to boost the performance of LearnSPN~\\citep{gens2013learning}, showing that it can achieve results comparable to state-of-the-art structure learning algorithms using SPNs with much smaller sizes. \n\n\\section{Background}\n\\subsection{Sum-Product Networks}\nTo simplify the discussion of the main idea of our unified framework, we focus our attention on SPNs over Boolean random variables. However, the framework presented here is general and can be easily extended into other discrete and continuous random variables. We first define the notion of \\emph{network polynomial}. We use $\\mathbb{I}_x$ to denote an indicator variable that returns 1 when $X = x$ and 0 otherwise. \n\\begin{definition}[Network Polynomial~\\citep{darwiche2003differential}]\n\\label{def:networkpolynomial}\nLet $f(\\cdot)\\geq 0$ be an unnormalized probability distribution over a Boolean random vector $\\mathbf{X}_{1:n}$. The network polynomial of $f(\\cdot)$ is a multilinear function $\\sum_{\\mathbf{x}}f(\\mathbf{x})\\prod_{i=1}^n\\mathbb{I}_{\\mathbf{x}_i}$ of indicator variables, where the summation is over all possible instantiations of the Boolean random vector $\\mathbf{X}_{1:n}$.\n\\end{definition}\n\\begin{definition}[Sum-Product Network~\\citep{poon2011sum}]\n\\label{def:spn}\nA Sum-Product Network (SPN) over Boolean variables $\\mathbf{X}_{1:n}$ is a rooted DAG whose leaves are the indicators $\\mathbb{I}_{x_1},\\ldots,\\mathbb{I}_{x_n}$ and $\\mathbb{I}_{\\bar{x}_1}, \\ldots, \\mathbb{I}_{\\bar{x}_n}$ and whose internal nodes are sums and products. Each edge $(v_i,v_j)$ emanating from a sum node $v_i$ has a positive weight $w_{ij}$. The value of a product node is the product of the values of its children. The value of a sum node is $\\sum_{v_j\\in Ch(v_i)}w_{ij}val(v_j)$ \nwhere $Ch(v_i)$ are the children of $v_i$ and \n$val(v_j)$ is the value of node $v_j$. The value of an SPN is the value of its root.\n\\end{definition}\nThe \\emph{scope} of a node in an SPN is defined as the set of variables that have indicators among the node's descendants. For any node $v$ in an SPN, if $v$ is a terminal node, say, an indicator variable over $X$, then $\\text{scope}(v)=\\{X\\}$, else $\\text{scope}(v)=\\bigcup_{\\tilde{v}\\in Ch(v)}\\text{scope}(\\tilde{v})$.\n\\citet{poon2011sum} also define the following properties of an SPN:\n\\begin{definition}[Complete]\n\\label{def:complete}\nAn SPN is \\emph{complete} iff each sum node has children with the same scope.\n\\end{definition}\n\\begin{definition}[Decomposable]\n\\label{def:decomposable}\nAn SPN is decomposable iff for every product node $v$, scope($v_i$) $\\bigcap$ scope($v_j$) $=\\varnothing$ where $v_i, v_j\\in Ch(v), i\\neq j$. \n\\end{definition}\nIn this paper, we focus on complete and decomposable SPNs. For a complete and decomposable SPN $\\mathcal{S}$, each node $v$ in $\\mathcal{S}$ defines a network polynomial $f_v(\\cdot)$ which corresponds to the sub-SPN (subgraph) rooted at $v$. The network polynomial of $\\mathcal{S}$, denoted by $f_{\\mathcal{S}}$, is the network polynomial defined by the root of $\\mathcal{S}$, which can be computed recursively from its children. The probability distribution induced by an SPN $\\mathcal{S}$ is defined as $\\Pr_{\\mathcal{S}}(\\mathbf{x})\\triangleq \\frac{f_{\\mathcal{S}}(\\mathbf{x})}{\\sum_{\\mathbf{x}}f_{\\mathcal{S}}(\\mathbf{x})}$.\n\n\\subsection{Signomial Programming (SP)}\nBefore introducing SP, we first introduce geometric programming (GP), which is a strict subclass of SP. A \\emph{monomial} is defined as a function $h:{\\mathbb{R}}_{++}\\mapsto{\\mathbb{R}}$:\n$h(\\mathbf{x}) = dx_1^{a_1}x_2^{a_2}\\cdots x_n^{a_n}$,\nwhere the domain is restricted to be the positive orthant, the coefficient $d$ is positive and the exponents $a_i\\in{\\mathbb{R}}, \\forall i$. A \\emph{posynomial} is a sum of monomials: $g(\\mathbf{x}) = \\sum_{k=1}^K d_k x_1^{a_{1k}}x_2^{a_{2k}}\\cdots x_n^{a_{nk}}$. One of the key properties of posynomials is its positivity, which allows us to transform it into the log-domain. A GP in standard form has the following form:\n\n", "index": 1, "text": "\\begin{equation}\n\\label{equ:gp}\n\\begin{aligned}\n& \\text{minimize} && \\sum_{k=1}^{K_0}d_{0k}\\prod_{t=1}^n \\mathbf{x}_t^{a_{0kt}} \\\\\n& \\text{subject to} && \\sum_{k=1}^{K_i}d_{ik}\\prod_{t=1}^n \\mathbf{x}_t^{a_{ikt}} \\leq 1,\\quad i = 1, \\ldots, p \\\\\n&&& d_{j}\\prod_{t=1}^n \\mathbf{x}_t^{a_{jt}} = 1,\\quad j = 1, \\ldots, q\n\\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{k=1}^{K_{0}}d_{0k}\\prod_{t=1}^{n}\\mathbf{x}_{t}^{a_{0kt}}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mn>0</mn></msub></munderover></mstyle><mrow><msub><mi>d</mi><mrow><mn>0</mn><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><msubsup><mi>\ud835\udc31</mi><mi>t</mi><msub><mi>a</mi><mrow><mn>0</mn><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msubsup></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{k=1}^{K_{i}}d_{ik}\\prod_{t=1}^{n}\\mathbf{x}_{t}^{a_{ikt}}%&#10;\\leq 1,\\quad i=1,\\ldots,p\" display=\"inline\"><mrow><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>i</mi></msub></munderover></mstyle><mrow><msub><mi>d</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><msubsup><mi>\ud835\udc31</mi><mi>t</mi><msub><mi>a</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msubsup></mrow></mrow></mrow><mo>\u2264</mo><mn>1</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>p</mi></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1Xb.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle d_{j}\\prod_{t=1}^{n}\\mathbf{x}_{t}^{a_{jt}}=1,\\quad j=1,\\ldots,q\" display=\"inline\"><mrow><mrow><mrow><msub><mi>d</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><msubsup><mi>\ud835\udc31</mi><mi>t</mi><msub><mi>a</mi><mrow><mi>j</mi><mo>\u2062</mo><mi>t</mi></mrow></msub></msubsup></mrow></mrow><mo>=</mo><mn>1</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>q</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhich is a convex program since the \\emph{log-sum-exp} function is convex in its argument and $\\mathbf{a}^T\\mathbf{y} + c$ is affine in $\\mathbf{y}$. Furthermore, in the convex formulation of GP we have $\\mathbf{y}\\in{\\mathbb{R}}^n$, i.e., we naturally remove the positive constraint on $\\mathbf{x}$ by taking the log transformation. \n\nSP has the same form as GP except that the multiplicative constant $d$ inside each monomial is not restricted to be positive, i.e., $d$ can take any real value. Although the difference seems to be small, there is a huge difference between GP and SP from the computational perspective. The negative multiplicative constant in monomials invalidates the log-log transformation trick frequently used in GP. As a result, SP cannot be reduced into a convex program and is believed to be hard to solve in general~\\citep{boyd2007tutorial}. \n\n\\section{Unified Approach for Learning}\nIn this section we will first show that the parameter learning problem of SPNs based on the MLE principle can be formulated as an SP. Although SP is hard to solve in general, the structure of the problem at hand leads to efficient algorithms based on sequential convex approximations. More specifically, we will use a sequence of optimal monomial approximations combined with backtracking line search and the concave-convex procedure to tackle the SP. \n\n\\subsection{Sum-Product Networks as a Mixture of Trees}\nWe introduce the notion of \\emph{induced trees} from SPNs and use it to show that every complete and decomposable SPN can be interpreted as a mixture of induced trees, where each induced tree corresponds to a product of univariate distributions. From this perspective, SPNs in general can be understood as a huge mixture model where the effective number of components in the mixture model is determined by its network structure. \n\n\\begin{definition}[Induced SPN]\n\\label{def:treespn}\nGiven a complete and decomposable SPN $\\mathcal{S}$ over $X_{1:N}$, $\\mathcal{T}$ is called an \\emph{induced SPN} from $\\mathcal{S}$ if \n\\begin{enumerate}\n    \\item   $Root(\\mathcal{S})\\in\\mathcal{T}_V$.\n    \\item   If $v\\in\\mathcal{T}_V$ is a sum node, then exactly one child of $v$ in $\\mathcal{S}$ is in $\\mathcal{T}_V$, the corresponding edge in $\\mathcal{T}_E$.\n    \\item   If $v\\in\\mathcal{T}_V$ is a product node, then all the children of $v$ in $\\mathcal{S}$ are in $\\mathcal{T}_V$, the corresponding edges in $\\mathcal{T}_E$.\n\\end{enumerate}\nwhere in the definition above $\\mathcal{T}_V$ is the node set of $\\mathcal{T}$ and $\\mathcal{T}_E$ is the edge set of $\\mathcal{T}$.\n\\end{definition}\nFor notational convenience we will call $\\mathcal{T}$ an induced SPN by omitting the fact that $\\mathcal{T}$ is induced from $\\mathcal{S}$ if there is no confusion in the context. \n\\begin{theorem}\n\\label{thm:treespn}\nIf $\\mathcal{T}$ is an induced SPN from $\\mathcal{S}$, then $\\mathcal{T}$ is a tree that is complete and decomposable. \n\\end{theorem}\n\\begin{proof}\nArgue by contradiction that $\\mathcal{T}$ is not a tree, then there must exist a node $v\\in\\mathcal{T}$ such that $v$ has more than one parent in $\\mathcal{T}$. This means that there exist at least two paths $R, p_1, \\ldots, v$ and $R, q_1, \\ldots, v$ that connect the root of $\\mathcal{S}(\\mathcal{T})$, which we denote by $R$, and $v$. Let $t$ be the last node in $R, p_1, \\ldots, v$ and $R, q_1, \\ldots, v$ such that $R, \\ldots, t$ are common prefix of these two paths. By construction we know that such $t$ must exist since these two paths start from the same root node $R$ ($R$ will be one candidate of such $t$). Also, we claim that $t\\neq v$ otherwise these two paths overlap with each other, which contradicts the assumption that $v$ has multiple parents. This shows that these two paths can be represented as $R, \\ldots, t, p, \\ldots, v$ and $R, \\ldots, t, q, \\ldots, v$ where $R, \\ldots, t$ are the common prefix shared by these two paths and $p\\neq q$ since $t$ is the last common node. From the construction process defined in Def.~\\ref{def:treespn}, we know that both $p$ and $q$ are children of $t$ in $\\mathcal{S}$. Recall that for each sum node in $\\mathcal{S}$, Def.~\\ref{def:treespn} takes at most one child, hence we claim that $t$ must be a product node, since both $p$ and $q$ are children of $t$. Then the paths that $t\\rightarrow p\\leadsto v$ and $t\\rightarrow q\\leadsto v$ indicate that $\\text{scope}(v)\\subseteq \\text{scope}(p)\\subseteq\\text{scope}(t)$ and $\\text{scope}(v)\\subseteq \\text{scope}(q)\\subseteq\\text{scope}(t)$, leading to $\\varnothing\\neq \\text{scope}(v)\\subseteq \\text{scope}(p)\\cap\\text{scope}(q)$, which is a contradiction of the decomposability of the product node $t$. Hence as long as $\\mathcal{S}$ is complete and decomposable, $\\mathcal{T}$ must be a tree.\n\nThe completeness of $\\mathcal{T}$ is trivially satisfied because each sum node has only one child in $\\mathcal{T}$. It is also straightforward to verify that $\\mathcal{T}$ satisfies the decomposability as $\\mathcal{T}$ is an induced subgraph of $\\mathcal{S}$, which is decomposable.\n\\end{proof}\nAs a result of Thm.~\\ref{thm:treespn}, we will use the terms \\emph{induced SPNs} and \\emph{induced trees} interchangeably. With some abuse of notation, we use $\\mathcal{T}(\\mathbf{x})$ to mean the value of the network polynomial of $\\mathcal{T}$ with input vector $\\mathbf{x}$.\n\\begin{theorem}\n\\label{thm:sp}\nIf $\\mathcal{T}$ is an induced tree from $\\mathcal{S}$ over $X_{1:N}$, then $\\mathcal{T}(\\mathbf{x}) = \\prod_{(v_i, v_j)\\in\\mathcal{T}_E}w_{ij}\\prod_{n=1}^N\\mathbb{I}_{x_n}$, where $w_{ij}$ is the edge weight of $(v_i, v_j)$ provided $v_i$ is a sum node and $\\mathbb{I}_{x_n}$ is the leaf indicator variable in $\\mathcal{T}$ of $X_n$.\n\\end{theorem}\n\\begin{proof}\nFirst, the scope of $\\mathcal{T}$ is the same as the scope of $\\mathcal{S}$ because the root of $\\mathcal{S}$ is also the root of $\\mathcal{T}$. This shows that for each $X_i$ there is at least one indicator $\\mathbb{I}_{x_i}$ in the leaves otherwise the scope of the root node of $\\mathcal{T}$ will be a strict subset of the scope of the root node of $\\mathcal{S}$. Furthermore, for each variable $X_i$ there is at most one indicator $\\mathbb{I}_{x_i}$ in the leaves. This is observed by the fact that there is at most one child collected from a sum node into $\\mathcal{T}$ and if $\\mathbb{I}_{x_i}$ and $\\mathbb{I}_{\\bar{x}_i}$ appear simultaneously in the leaves, then their least common ancestor must be a product node. Note that the least common ancestor of $\\mathbb{I}_{x_i}$ and $\\mathbb{I}_{\\bar{x}_i}$ is guaranteed to exist because of the tree structure of $\\mathcal{T}$. However, this leads to a contradiction of the fact that $\\mathcal{S}$ is decomposable. As a result, there is exactly one indicator $\\mathbb{I}_{x_i}$ for each variable $X_i$ in $\\mathcal{T}$. Hence the multiplicative constant of the monomial admits the form $\\prod_{i=1}^n\\mathbb{I}_{x_i}$, which is a product of univariate distributions. More specifically, it is a product of indicator variables in the case of Boolean input variables. \n\nWe have already shown that $\\mathcal{T}$ is a tree and only product nodes in $\\mathcal{T}$ can have multiple children. It follows that the functional form of $f_{\\mathcal{T}}(\\mathbf{x})$ must be a monomial, and only edge weights that are in $\\mathcal{T}$ contribute to the monomial. Combing all the above, we know that $f_{\\mathcal{T}}(\\mathbf{x}) = \\prod_{(v_i, v_i)\\in\\mathcal{T}_E}w_{ij}\\prod_{n=1}^N\\mathbb{I}_{x_n}$.\n\\end{proof}\n\\textbf{Remark}. Although we focus our attention on Boolean random variables for the simplicity of discussion and illustration, Thm.~\\ref{thm:sp} can be extended to the case where the univariate distributions at the leaf nodes are continuous or discrete distributions with countably infinitely many values, e.g., Gaussian distributions or Poisson distributions. We can simply replace the product of univariate distributions term, $\\prod_{n=1}^N\\mathbb{I}_{x_n}$, in Thm.~\\ref{thm:sp} to be the general form $\\prod_{n=1}^N p(X_n)$, where $p(X_n)$ is a univariate distribution over $X_n$. Also note that it is possible for two unique induced trees to share the same product of univariate distributions, but their weight terms, $\\prod_{(v_i, v_i)\\in\\mathcal{T}_E}w_{ij}$ are guaranteed to be different. Such intricate connection among different trees induced from SPNs is one of the reason that makes the model very flexible to model distributions.\n\\begin{definition}[Network cardinality]\nThe network cardinality $\\tau_\\mathcal{S}$ of an SPN $\\mathcal{S}$ is the number of unique induced trees from $\\mathcal{S}$.\n\\end{definition}\n\\begin{theorem}\n\\label{thm:polynomial}\n$\\tau_\\mathcal{S} = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$ and $\\mathcal{S}(\\mathbf{x}) = \\sum_{t=1}^{\\tau_\\mathcal{S}}\\mathcal{T}_t(\\mathbf{x})$, where $\\mathcal{T}_t$ is the $t$th unique induced tree of $\\mathcal{S}$ and $f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$ is the value of the network polynomial of $\\mathcal{S}$ with input vector $\\mathbf{1}$ and all edge weights set to be $1$.\n\\end{theorem}\n\\begin{proof}\nWe prove by induction on the height of $\\mathcal{S}$. If the height of $\\mathcal{S}$ is 2, then depending on the type of the root node, we have two cases:\n\\begin{enumerate}\n    \\item   If the root is a sum node with $K$ children, then there are $C_K^1 = K$ different subgraphs that satisfy Def.~\\ref{def:treespn}, which is exactly the value of the network by setting all the indicators and edge weights from the root to be 1. \n    \\item   If the root is a product node then there is only 1 subgraph which is the graph itself. Again, this equals to the value of $\\mathcal{S}$ by setting all indicators to be 1. \n\\end{enumerate}\nAssume the theorem is true for SPNs with height $\\leq h$. Consider an SPN $\\mathcal{S}$ with height $h+1$. Again, depends on the type of the root node, we need to discuss two cases:\n\\begin{enumerate}\n    \\item   If the root is a sum node with $K$ children, where the $k$th sub-SPN has $f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1})$ unique induced trees, then by Def.~\\ref{def:treespn} the total number of unique induced trees of $\\mathcal{S}$ is $\\sum_{k=1}^K f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = \\sum_{k=1}^K 1\\cdot f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$.\n    \\item   If the root is a product node with $K$ children, then the total number of unique induced trees of $\\mathcal{S}$ can then be computed by $\\prod_{k=1}^K f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$.\n\\end{enumerate}\nThe second part of the theorem follows by using distributive law between multiplication and addition to combine unique trees that share the same prefix in bottom-up order. \n\\end{proof}\n\\textbf{Remark}. The above three theorems prove the fact that an SPN $\\mathcal{S}$ is essentially an ensemble of trees, where each tree computes an unnormalized distribution over $X_{1:N}$. The total number of unique trees in $\\mathcal{S}$ is characterized by the network cardinality $\\tau_\\mathcal{S}$, which only depends on the structure of $\\mathcal{S}$. Equivalently, this means that an SPN $\\mathcal{S}$ can be treated as a mixture model with $\\tau_\\mathcal{S}$ effective components, where each component is a simple product of univariate distribution. We illustrate the theorems above with a simple example shown in Fig.~\\ref{fig:treespn}.\n\\begin{figure*}[htb]\n\\centering\n    \\includegraphics[width=\\textwidth]{spntrees.pdf}\n\\caption{A complete and decomposable SPN is a mixture of induced trees. Double circle indicates univariate distributions over $X_1$ and $X_2$. Different colors are used to highlight unique induced trees where each induced tree is a product of univariate distributions over $X_1$ and $X_2$.}\n\\label{fig:treespn}\n\\end{figure*}\n\n\\citep{zhao2015spnbn} show that every complete and decomposable SPN is equivalent to a bipartite Bayesian network with a layer of hidden variables and a layer of observable random variables. The number of hidden variables in the bipartite Bayesian network is equal to the number of sum nodes in $\\mathcal{S}$. A naive expansion of such Bayesian network to a mixture model will lead to a huge mixture model with $O(2^M)$ components, where $M$ is the number of sum nodes in $\\mathcal{S}$. Here we complement their theory and show that each complete and decomposable SPN is essentially a mixture of trees and the effective number of unique induced trees is given by $\\tau_\\mathcal{S}$. Note that $\\tau_\\mathcal{S} = f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ depends only on the network structure. Without loss of generality assuming that in $\\mathcal{S}$ layers of sum nodes are alternating with layers of product nodes, then $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1}) = \\Omega(2^h)$, where $h$ is the height of $\\mathcal{S}$. However, the exponentially many trees are recursively merged and combined in $\\mathcal{S}$ such that the overall network size is still tractable. \n\n\\subsection{Maximum Likelihood Estimation as SP}\nWithout loss of generality, let's consider the likelihood function computed by an SPN $\\mathcal{S}$ over $N$ binary random variables with model parameters $\\mathbf{w}\\in{\\mathbb{R}}_{++}^D$ and input vector $\\mathbf{x}\\in\\{0,1\\}^N$. Here the model parameters in $\\mathcal{S}$ are edge weights from every sum node and we collect them together into a long vector $\\mathbf{w}$, where $D$ corresponds to the number of edges emanating from sum nodes in $\\mathcal{S}$. By definition, the probability distribution induced by $\\mathcal{S}$ can be computed by \n\n", "itemtype": "equation", "pos": 11915, "prevtext": "\nwhere both the objective function and the inequaility constraints are posynomials and the equality constraints are monomials. Note that in GP there is also an implicit constraint that $\\mathbf{x}\\in{\\mathbb{R}}^n_{++}$. GP in its standard form is not a convex program since posynomials are not convex functions in general. However, we can effectively transform it into a convex problem by using the \\emph{logarithmic transformation trick} on $\\mathbf{x}$, the multiplicative coefficients of each monomial and also each objective/constraint function~\\citep{chiang2005geometric,boyd2007tutorial}. We make the following change: let $\\mathbf{y} = \\log(\\mathbf{x})$, $c_{ik} = \\log(d_{ik}),\\forall i,k$ and take $\\log(\\cdot)$ of each function in (\\ref{equ:gp}). Then the standard GP form is equivalent to the following formulation:\n\n", "index": 3, "text": "\\begin{equation}\n\\begin{aligned}\n& \\text{minimize} && \\log\\left(\\sum_{k=1}^{K_0}\\exp(\\mathbf{a}_{0k}^T\\mathbf{y} + c_{0k})\\right) \\\\\n& \\text{subject to} && \\log\\left(\\sum_{k=1}^{K_i}\\exp(\\mathbf{a}_{ik}^T\\mathbf{y} + c_{ik})\\right) \\leq 0,\\quad i = 1,\\ldots, p \\\\\n&&& \\mathbf{a}_j^T\\mathbf{y} + c_j = 0, \\quad j = 1, \\ldots, q\n\\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\log\\left(\\sum_{k=1}^{K_{0}}\\exp(\\mathbf{a}_{0k}^{T}\\mathbf{y}+c_%&#10;{0k})\\right)\" display=\"inline\"><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mn>0</mn></msub></munderover></mstyle><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>\ud835\udc1a</mi><mrow><mn>0</mn><mo>\u2062</mo><mi>k</mi></mrow><mi>T</mi></msubsup><mo>\u2062</mo><mi>\ud835\udc32</mi></mrow><mo>+</mo><msub><mi>c</mi><mrow><mn>0</mn><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\log\\left(\\sum_{k=1}^{K_{i}}\\exp(\\mathbf{a}_{ik}^{T}\\mathbf{y}+c_%&#10;{ik})\\right)\\leq 0,\\quad i=1,\\ldots,p\" display=\"inline\"><mrow><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>K</mi><mi>i</mi></msub></munderover></mstyle><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msubsup><mi>\ud835\udc1a</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow><mi>T</mi></msubsup><mo>\u2062</mo><mi>\ud835\udc32</mi></mrow><mo>+</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>\u2264</mo><mn>0</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>p</mi></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2Xb.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{a}_{j}^{T}\\mathbf{y}+c_{j}=0,\\quad j=1,\\ldots,q\" display=\"inline\"><mrow><mrow><mrow><mrow><msubsup><mi>\ud835\udc1a</mi><mi>j</mi><mi>T</mi></msubsup><mo>\u2062</mo><mi>\ud835\udc32</mi></mrow><mo>+</mo><msub><mi>c</mi><mi>j</mi></msub></mrow><mo>=</mo><mn>0</mn></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>q</mi></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhere $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})$ means the value of the network polynomial by setting all the indicators at the leaves of the network to be 1. The second equation in (\\ref{equ:partition}) comes from the fact that the partition function of SPNs can be computed efficiently by setting all the indicators to 1 and evaluating the network in a bottom-up fashion. \n\n\\begin{theorem}\n\\label{thm:mle}\nLet $\\mathcal{S}$ be an SPN with weights $\\mathbf{w}\\in{\\mathbb{R}}_{++}^D$ over input vector $\\mathbf{x}\\in\\{0,1\\}^N$, the network polynomial $f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})$ is a posynomial of the following form:\n\n", "itemtype": "equation", "pos": 25850, "prevtext": "\nwhich is a convex program since the \\emph{log-sum-exp} function is convex in its argument and $\\mathbf{a}^T\\mathbf{y} + c$ is affine in $\\mathbf{y}$. Furthermore, in the convex formulation of GP we have $\\mathbf{y}\\in{\\mathbb{R}}^n$, i.e., we naturally remove the positive constraint on $\\mathbf{x}$ by taking the log transformation. \n\nSP has the same form as GP except that the multiplicative constant $d$ inside each monomial is not restricted to be positive, i.e., $d$ can take any real value. Although the difference seems to be small, there is a huge difference between GP and SP from the computational perspective. The negative multiplicative constant in monomials invalidates the log-log transformation trick frequently used in GP. As a result, SP cannot be reduced into a convex program and is believed to be hard to solve in general~\\citep{boyd2007tutorial}. \n\n\\section{Unified Approach for Learning}\nIn this section we will first show that the parameter learning problem of SPNs based on the MLE principle can be formulated as an SP. Although SP is hard to solve in general, the structure of the problem at hand leads to efficient algorithms based on sequential convex approximations. More specifically, we will use a sequence of optimal monomial approximations combined with backtracking line search and the concave-convex procedure to tackle the SP. \n\n\\subsection{Sum-Product Networks as a Mixture of Trees}\nWe introduce the notion of \\emph{induced trees} from SPNs and use it to show that every complete and decomposable SPN can be interpreted as a mixture of induced trees, where each induced tree corresponds to a product of univariate distributions. From this perspective, SPNs in general can be understood as a huge mixture model where the effective number of components in the mixture model is determined by its network structure. \n\n\\begin{definition}[Induced SPN]\n\\label{def:treespn}\nGiven a complete and decomposable SPN $\\mathcal{S}$ over $X_{1:N}$, $\\mathcal{T}$ is called an \\emph{induced SPN} from $\\mathcal{S}$ if \n\\begin{enumerate}\n    \\item   $Root(\\mathcal{S})\\in\\mathcal{T}_V$.\n    \\item   If $v\\in\\mathcal{T}_V$ is a sum node, then exactly one child of $v$ in $\\mathcal{S}$ is in $\\mathcal{T}_V$, the corresponding edge in $\\mathcal{T}_E$.\n    \\item   If $v\\in\\mathcal{T}_V$ is a product node, then all the children of $v$ in $\\mathcal{S}$ are in $\\mathcal{T}_V$, the corresponding edges in $\\mathcal{T}_E$.\n\\end{enumerate}\nwhere in the definition above $\\mathcal{T}_V$ is the node set of $\\mathcal{T}$ and $\\mathcal{T}_E$ is the edge set of $\\mathcal{T}$.\n\\end{definition}\nFor notational convenience we will call $\\mathcal{T}$ an induced SPN by omitting the fact that $\\mathcal{T}$ is induced from $\\mathcal{S}$ if there is no confusion in the context. \n\\begin{theorem}\n\\label{thm:treespn}\nIf $\\mathcal{T}$ is an induced SPN from $\\mathcal{S}$, then $\\mathcal{T}$ is a tree that is complete and decomposable. \n\\end{theorem}\n\\begin{proof}\nArgue by contradiction that $\\mathcal{T}$ is not a tree, then there must exist a node $v\\in\\mathcal{T}$ such that $v$ has more than one parent in $\\mathcal{T}$. This means that there exist at least two paths $R, p_1, \\ldots, v$ and $R, q_1, \\ldots, v$ that connect the root of $\\mathcal{S}(\\mathcal{T})$, which we denote by $R$, and $v$. Let $t$ be the last node in $R, p_1, \\ldots, v$ and $R, q_1, \\ldots, v$ such that $R, \\ldots, t$ are common prefix of these two paths. By construction we know that such $t$ must exist since these two paths start from the same root node $R$ ($R$ will be one candidate of such $t$). Also, we claim that $t\\neq v$ otherwise these two paths overlap with each other, which contradicts the assumption that $v$ has multiple parents. This shows that these two paths can be represented as $R, \\ldots, t, p, \\ldots, v$ and $R, \\ldots, t, q, \\ldots, v$ where $R, \\ldots, t$ are the common prefix shared by these two paths and $p\\neq q$ since $t$ is the last common node. From the construction process defined in Def.~\\ref{def:treespn}, we know that both $p$ and $q$ are children of $t$ in $\\mathcal{S}$. Recall that for each sum node in $\\mathcal{S}$, Def.~\\ref{def:treespn} takes at most one child, hence we claim that $t$ must be a product node, since both $p$ and $q$ are children of $t$. Then the paths that $t\\rightarrow p\\leadsto v$ and $t\\rightarrow q\\leadsto v$ indicate that $\\text{scope}(v)\\subseteq \\text{scope}(p)\\subseteq\\text{scope}(t)$ and $\\text{scope}(v)\\subseteq \\text{scope}(q)\\subseteq\\text{scope}(t)$, leading to $\\varnothing\\neq \\text{scope}(v)\\subseteq \\text{scope}(p)\\cap\\text{scope}(q)$, which is a contradiction of the decomposability of the product node $t$. Hence as long as $\\mathcal{S}$ is complete and decomposable, $\\mathcal{T}$ must be a tree.\n\nThe completeness of $\\mathcal{T}$ is trivially satisfied because each sum node has only one child in $\\mathcal{T}$. It is also straightforward to verify that $\\mathcal{T}$ satisfies the decomposability as $\\mathcal{T}$ is an induced subgraph of $\\mathcal{S}$, which is decomposable.\n\\end{proof}\nAs a result of Thm.~\\ref{thm:treespn}, we will use the terms \\emph{induced SPNs} and \\emph{induced trees} interchangeably. With some abuse of notation, we use $\\mathcal{T}(\\mathbf{x})$ to mean the value of the network polynomial of $\\mathcal{T}$ with input vector $\\mathbf{x}$.\n\\begin{theorem}\n\\label{thm:sp}\nIf $\\mathcal{T}$ is an induced tree from $\\mathcal{S}$ over $X_{1:N}$, then $\\mathcal{T}(\\mathbf{x}) = \\prod_{(v_i, v_j)\\in\\mathcal{T}_E}w_{ij}\\prod_{n=1}^N\\mathbb{I}_{x_n}$, where $w_{ij}$ is the edge weight of $(v_i, v_j)$ provided $v_i$ is a sum node and $\\mathbb{I}_{x_n}$ is the leaf indicator variable in $\\mathcal{T}$ of $X_n$.\n\\end{theorem}\n\\begin{proof}\nFirst, the scope of $\\mathcal{T}$ is the same as the scope of $\\mathcal{S}$ because the root of $\\mathcal{S}$ is also the root of $\\mathcal{T}$. This shows that for each $X_i$ there is at least one indicator $\\mathbb{I}_{x_i}$ in the leaves otherwise the scope of the root node of $\\mathcal{T}$ will be a strict subset of the scope of the root node of $\\mathcal{S}$. Furthermore, for each variable $X_i$ there is at most one indicator $\\mathbb{I}_{x_i}$ in the leaves. This is observed by the fact that there is at most one child collected from a sum node into $\\mathcal{T}$ and if $\\mathbb{I}_{x_i}$ and $\\mathbb{I}_{\\bar{x}_i}$ appear simultaneously in the leaves, then their least common ancestor must be a product node. Note that the least common ancestor of $\\mathbb{I}_{x_i}$ and $\\mathbb{I}_{\\bar{x}_i}$ is guaranteed to exist because of the tree structure of $\\mathcal{T}$. However, this leads to a contradiction of the fact that $\\mathcal{S}$ is decomposable. As a result, there is exactly one indicator $\\mathbb{I}_{x_i}$ for each variable $X_i$ in $\\mathcal{T}$. Hence the multiplicative constant of the monomial admits the form $\\prod_{i=1}^n\\mathbb{I}_{x_i}$, which is a product of univariate distributions. More specifically, it is a product of indicator variables in the case of Boolean input variables. \n\nWe have already shown that $\\mathcal{T}$ is a tree and only product nodes in $\\mathcal{T}$ can have multiple children. It follows that the functional form of $f_{\\mathcal{T}}(\\mathbf{x})$ must be a monomial, and only edge weights that are in $\\mathcal{T}$ contribute to the monomial. Combing all the above, we know that $f_{\\mathcal{T}}(\\mathbf{x}) = \\prod_{(v_i, v_i)\\in\\mathcal{T}_E}w_{ij}\\prod_{n=1}^N\\mathbb{I}_{x_n}$.\n\\end{proof}\n\\textbf{Remark}. Although we focus our attention on Boolean random variables for the simplicity of discussion and illustration, Thm.~\\ref{thm:sp} can be extended to the case where the univariate distributions at the leaf nodes are continuous or discrete distributions with countably infinitely many values, e.g., Gaussian distributions or Poisson distributions. We can simply replace the product of univariate distributions term, $\\prod_{n=1}^N\\mathbb{I}_{x_n}$, in Thm.~\\ref{thm:sp} to be the general form $\\prod_{n=1}^N p(X_n)$, where $p(X_n)$ is a univariate distribution over $X_n$. Also note that it is possible for two unique induced trees to share the same product of univariate distributions, but their weight terms, $\\prod_{(v_i, v_i)\\in\\mathcal{T}_E}w_{ij}$ are guaranteed to be different. Such intricate connection among different trees induced from SPNs is one of the reason that makes the model very flexible to model distributions.\n\\begin{definition}[Network cardinality]\nThe network cardinality $\\tau_\\mathcal{S}$ of an SPN $\\mathcal{S}$ is the number of unique induced trees from $\\mathcal{S}$.\n\\end{definition}\n\\begin{theorem}\n\\label{thm:polynomial}\n$\\tau_\\mathcal{S} = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$ and $\\mathcal{S}(\\mathbf{x}) = \\sum_{t=1}^{\\tau_\\mathcal{S}}\\mathcal{T}_t(\\mathbf{x})$, where $\\mathcal{T}_t$ is the $t$th unique induced tree of $\\mathcal{S}$ and $f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$ is the value of the network polynomial of $\\mathcal{S}$ with input vector $\\mathbf{1}$ and all edge weights set to be $1$.\n\\end{theorem}\n\\begin{proof}\nWe prove by induction on the height of $\\mathcal{S}$. If the height of $\\mathcal{S}$ is 2, then depending on the type of the root node, we have two cases:\n\\begin{enumerate}\n    \\item   If the root is a sum node with $K$ children, then there are $C_K^1 = K$ different subgraphs that satisfy Def.~\\ref{def:treespn}, which is exactly the value of the network by setting all the indicators and edge weights from the root to be 1. \n    \\item   If the root is a product node then there is only 1 subgraph which is the graph itself. Again, this equals to the value of $\\mathcal{S}$ by setting all indicators to be 1. \n\\end{enumerate}\nAssume the theorem is true for SPNs with height $\\leq h$. Consider an SPN $\\mathcal{S}$ with height $h+1$. Again, depends on the type of the root node, we need to discuss two cases:\n\\begin{enumerate}\n    \\item   If the root is a sum node with $K$ children, where the $k$th sub-SPN has $f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1})$ unique induced trees, then by Def.~\\ref{def:treespn} the total number of unique induced trees of $\\mathcal{S}$ is $\\sum_{k=1}^K f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = \\sum_{k=1}^K 1\\cdot f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$.\n    \\item   If the root is a product node with $K$ children, then the total number of unique induced trees of $\\mathcal{S}$ can then be computed by $\\prod_{k=1}^K f_{\\mathcal{S}_k}(\\mathbf{1}|\\mathbf{1}) = f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{1})$.\n\\end{enumerate}\nThe second part of the theorem follows by using distributive law between multiplication and addition to combine unique trees that share the same prefix in bottom-up order. \n\\end{proof}\n\\textbf{Remark}. The above three theorems prove the fact that an SPN $\\mathcal{S}$ is essentially an ensemble of trees, where each tree computes an unnormalized distribution over $X_{1:N}$. The total number of unique trees in $\\mathcal{S}$ is characterized by the network cardinality $\\tau_\\mathcal{S}$, which only depends on the structure of $\\mathcal{S}$. Equivalently, this means that an SPN $\\mathcal{S}$ can be treated as a mixture model with $\\tau_\\mathcal{S}$ effective components, where each component is a simple product of univariate distribution. We illustrate the theorems above with a simple example shown in Fig.~\\ref{fig:treespn}.\n\\begin{figure*}[htb]\n\\centering\n    \\includegraphics[width=\\textwidth]{spntrees.pdf}\n\\caption{A complete and decomposable SPN is a mixture of induced trees. Double circle indicates univariate distributions over $X_1$ and $X_2$. Different colors are used to highlight unique induced trees where each induced tree is a product of univariate distributions over $X_1$ and $X_2$.}\n\\label{fig:treespn}\n\\end{figure*}\n\n\\citep{zhao2015spnbn} show that every complete and decomposable SPN is equivalent to a bipartite Bayesian network with a layer of hidden variables and a layer of observable random variables. The number of hidden variables in the bipartite Bayesian network is equal to the number of sum nodes in $\\mathcal{S}$. A naive expansion of such Bayesian network to a mixture model will lead to a huge mixture model with $O(2^M)$ components, where $M$ is the number of sum nodes in $\\mathcal{S}$. Here we complement their theory and show that each complete and decomposable SPN is essentially a mixture of trees and the effective number of unique induced trees is given by $\\tau_\\mathcal{S}$. Note that $\\tau_\\mathcal{S} = f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ depends only on the network structure. Without loss of generality assuming that in $\\mathcal{S}$ layers of sum nodes are alternating with layers of product nodes, then $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1}) = \\Omega(2^h)$, where $h$ is the height of $\\mathcal{S}$. However, the exponentially many trees are recursively merged and combined in $\\mathcal{S}$ such that the overall network size is still tractable. \n\n\\subsection{Maximum Likelihood Estimation as SP}\nWithout loss of generality, let's consider the likelihood function computed by an SPN $\\mathcal{S}$ over $N$ binary random variables with model parameters $\\mathbf{w}\\in{\\mathbb{R}}_{++}^D$ and input vector $\\mathbf{x}\\in\\{0,1\\}^N$. Here the model parameters in $\\mathcal{S}$ are edge weights from every sum node and we collect them together into a long vector $\\mathbf{w}$, where $D$ corresponds to the number of edges emanating from sum nodes in $\\mathcal{S}$. By definition, the probability distribution induced by $\\mathcal{S}$ can be computed by \n\n", "index": 5, "text": "\\begin{equation}\n\\label{equ:partition}\n\\Pr_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})\\triangleq\\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{\\sum_{\\mathbf{x}}f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})} = \\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\Pr_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})\\triangleq\\frac{f_{\\mathcal{S}}(%&#10;\\mathbf{x}|\\mathbf{w})}{\\sum_{\\mathbf{x}}f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}%&#10;)}=\\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_{\\mathcal{S}}(\\mathbf{1}|%&#10;\\mathbf{w})}\" display=\"block\"><mrow><mrow><munder><mi>Pr</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u225c</mo><mfrac><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>\ud835\udc31</mi></msub><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhere $\\mathcal{T}_t$ is the $t$th unique induced tree taken from $\\mathcal{S}$, and $\\mathbb{I}_{x_n}^{(t)}$ is the indicator variable of $X_n$ appearing in $\\mathcal{T}_t$. $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ is the value of the network polynomial obtained by setting all indicators and weights to be 1.\n\\end{theorem}\nThis theorem is a direct corollary of Thm.~\\ref{thm:treespn} and Thm.~\\ref{thm:sp}. From the definition of network polynomial, we know that $f_\\mathcal{S}$ is a multilinear function of the indicator variables. Thm.~\\ref{thm:mle} works as a complement to characterize the functional form of a network polynomial in terms of $\\mathbf{w}$. Each monomial in (\\ref{equ:posy}) corresponds exactly to a unique induced tree SPN from $\\mathcal{S}$. It follows that the likelihood function $\\mathcal{L}_\\mathcal{S}(\\mathbf{w}) \\triangleq\\Pr_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})$ can be expressed as the ratio of two posynomial functions. We now show that the optimization problem based on MLE is an SP. \n\\begin{proposition}\n\\label{prop:1}\nThe MLE problem for SPNs is a signomial program.\n\\end{proposition}\n\\begin{proof}\nUsing the definition of $\\Pr(\\mathbf{x}|\\mathbf{w})$ and Thm.~\\ref{thm:mle}, let $\\tau = f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$, the MLE problem can be rewritten as\n\n", "itemtype": "equation", "pos": 26770, "prevtext": "\nwhere $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})$ means the value of the network polynomial by setting all the indicators at the leaves of the network to be 1. The second equation in (\\ref{equ:partition}) comes from the fact that the partition function of SPNs can be computed efficiently by setting all the indicators to 1 and evaluating the network in a bottom-up fashion. \n\n\\begin{theorem}\n\\label{thm:mle}\nLet $\\mathcal{S}$ be an SPN with weights $\\mathbf{w}\\in{\\mathbb{R}}_{++}^D$ over input vector $\\mathbf{x}\\in\\{0,1\\}^N$, the network polynomial $f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})$ is a posynomial of the following form:\n\n", "index": 7, "text": "\\begin{equation}\n\\label{equ:posy}\nf_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}) = \\sum_{t = 1}^{f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})} \\prod_{n=1}^N\\mathbb{I}_{x_n}^{(l)}\\prod_{d=1}^Dw_d^{\\mathbb{I}_{w_d\\in\\mathcal{T}_t}}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})=\\sum_{t=1}^{f_{\\mathcal{S}}(\\mathbf{1}|%&#10;\\mathbf{1})}\\prod_{n=1}^{N}\\mathbb{I}_{x_{n}}^{(l)}\\prod_{d=1}^{D}w_{d}^{%&#10;\\mathbb{I}_{w_{d}\\in\\mathcal{T}_{t}}}\" display=\"block\"><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">)</mo></mrow></mrow></munderover><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msubsup><mi>\ud835\udd40</mi><msub><mi>x</mi><mi>n</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><msubsup><mi>w</mi><mi>d</mi><msub><mi>\ud835\udd40</mi><mrow><msub><mi>w</mi><mi>d</mi></msub><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi><mi>t</mi></msub></mrow></msub></msubsup></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhich we claim is equivalent to:\n\n", "itemtype": "equation", "pos": 28294, "prevtext": "\nwhere $\\mathcal{T}_t$ is the $t$th unique induced tree taken from $\\mathcal{S}$, and $\\mathbb{I}_{x_n}^{(t)}$ is the indicator variable of $X_n$ appearing in $\\mathcal{T}_t$. $f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ is the value of the network polynomial obtained by setting all indicators and weights to be 1.\n\\end{theorem}\nThis theorem is a direct corollary of Thm.~\\ref{thm:treespn} and Thm.~\\ref{thm:sp}. From the definition of network polynomial, we know that $f_\\mathcal{S}$ is a multilinear function of the indicator variables. Thm.~\\ref{thm:mle} works as a complement to characterize the functional form of a network polynomial in terms of $\\mathbf{w}$. Each monomial in (\\ref{equ:posy}) corresponds exactly to a unique induced tree SPN from $\\mathcal{S}$. It follows that the likelihood function $\\mathcal{L}_\\mathcal{S}(\\mathbf{w}) \\triangleq\\Pr_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})$ can be expressed as the ratio of two posynomial functions. We now show that the optimization problem based on MLE is an SP. \n\\begin{proposition}\n\\label{prop:1}\nThe MLE problem for SPNs is a signomial program.\n\\end{proposition}\n\\begin{proof}\nUsing the definition of $\\Pr(\\mathbf{x}|\\mathbf{w})$ and Thm.~\\ref{thm:mle}, let $\\tau = f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$, the MLE problem can be rewritten as\n\n", "index": 9, "text": "\\begin{equation}\n\\label{equ:primal}\n\\begin{aligned}\n& \\text{maximize}_{\\mathbf{w}} && \\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{w})} = \\frac{\\sum_{t = 1}^\\tau \\prod_{n=1}^N\\mathbb{I}_{x_n}^{(t)}\\prod_{d=1}^Dw_d^{\\mathbb{I}_{w_d\\in\\mathcal{T}_t}}}\n{\\sum_{t = 1}^\\tau \\prod_{d=1}^Dw_d^{\\mathbb{I}_{w_d\\in\\mathcal{T}_t}}} \\\\\n& \\text{subject to} && \\mathbf{w}\\in{\\mathbb{R}}_{++}^D\n\\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{maximize}_{\\mathbf{w}}\" display=\"inline\"><msub><mtext>maximize</mtext><mi>\ud835\udc30</mi></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_{\\mathcal{S}}(%&#10;\\mathbf{1}|\\mathbf{w})}=\\frac{\\sum_{t=1}^{\\tau}\\prod_{n=1}^{N}\\mathbb{I}_{x_{n%&#10;}}^{(t)}\\prod_{d=1}^{D}w_{d}^{\\mathbb{I}_{w_{d}\\in\\mathcal{T}_{t}}}}{\\sum_{t=1%&#10;}^{\\tau}\\prod_{d=1}^{D}w_{d}^{\\mathbb{I}_{w_{d}\\in\\mathcal{T}_{t}}}}\" display=\"inline\"><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>\u03c4</mi></msubsup><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u220f</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msubsup><mi>\ud835\udd40</mi><msub><mi>x</mi><mi>n</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u220f</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></msubsup><msubsup><mi>w</mi><mi>d</mi><msub><mi>\ud835\udd40</mi><mrow><msub><mi>w</mi><mi>d</mi></msub><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi><mi>t</mi></msub></mrow></msub></msubsup></mrow></mrow></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>\u03c4</mi></msubsup><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u220f</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></msubsup><msubsup><mi>w</mi><mi>d</mi><msub><mi>\ud835\udd40</mi><mrow><msub><mi>w</mi><mi>d</mi></msub><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi><mi>t</mi></msub></mrow></msub></msubsup></mrow></mrow></mfrac></mstyle></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{w}\\in{\\mathbb{R}}_{++}^{D}\" display=\"inline\"><mrow><mi>\ud835\udc30</mi><mo>\u2208</mo><msubsup><mi>\u211d</mi><mrow><mi/><mo>+</mo><mo>+</mo></mrow><mi>D</mi></msubsup></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nIt is easy to check that both the objective function and constraint function in~(\\ref{equ:sp}) are signomials. To see the equivalence of (\\ref{equ:primal}) and (\\ref{equ:sp}), let $p^*$ be the optimal value of (\\ref{equ:primal}) achieved at $\\mathbf{w}^*$. Choose $z = p^*$ and $\\mathbf{w} = \\mathbf{w}^*$ in (\\ref{equ:sp}), then $-z$ is also the optimal solution of (\\ref{equ:sp}) otherwise we can find feasible $(z', \\mathbf{w}')$ in (\\ref{equ:sp}) which has $-z' < -z \\Leftrightarrow z' > z$. Combined with the constraint function in (\\ref{equ:sp}), we have $p^* = z < z' \\leq \\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}')}{f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{w}')}$, which contradicts the optimality of $p^*$. In the other direction, let $z^*, \\mathbf{w}^*$ be the solution that achieves optimal value of (\\ref{equ:sp}), then we claim that $z^*$ is also the optimal value of (\\ref{equ:primal}), otherwise there exists a feasible $\\mathbf{w}$ in (\\ref{equ:primal}) such that $z\\triangleq\\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})} > z^*$. Since $(\\mathbf{w}, z)$ is also feasible in (\\ref{equ:sp}) with $-z < -z^*$, this contradicts the optimality of $z^*$.\n\\end{proof}\nThe transformation from (\\ref{equ:primal}) to (\\ref{equ:sp}) does not make the problem any easier to solve.  Rather, it destroys the structure of (\\ref{equ:primal}), i.e., the objective function of (\\ref{equ:primal}) is the ratio of two posynomials. However, the equivalent transformation does reveal some insights about the intrinsic complexity of the optimization problem, which indicates that it is hard to solve (\\ref{equ:primal}) efficiently with the guarantee of achieving a globally optimal solution.\n\n\\subsection{Sequential Convex Approximations}\n\n\nPGD optimizes the log-likelihood by projecting the intermediate solution back to the positive orthant after each gradient update. Since the constraint in (\\ref{equ:primal}) is an open set, we need to manually create a closed set on which the projection operation can be well defined. One feasible choice is to project on to ${\\mathbb{R}}_{\\epsilon}^{D}\\triangleq\\{\\mathbf{w}\\in{\\mathbb{R}}^D_{++}~|~w_d\\geq\\epsilon, \\forall d\\}$ where $\\epsilon > 0$ is assumed to be very small. \n\n\n\n\n\nTo avoid the projection, one direct solution is to use the exponentiated gradient (EG) method\\citep{kivinen1997exponentiated}, which was first applied in an online setting and latter successfully extended to batch settings when training with convex models~\\citep{collins2005exponentiated,globerson2007exponentiated,collins2008exponentiated}.\nEG admits a multiplicative update at each iteration and hence avoids the need for projection in PGD. Both PGD and EG are first-order methods and they can be viewed as approximating the SP after applying a log-transformation to the objective function only.\n\n\n\n\nNotice that although (\\ref{equ:primal}) is a signomial program, its objective function is expressed as the ratio of two posynomials. Hence, we can still apply the \\emph{logarithmic transformation trick} used in geometric programming to its objective function and to the variables to be optimized. More concretely, let $w_d = \\exp(y_d), \\forall d$ and take the $\\log$ of the objective function, it becomes equivalent to maximize the following new objective without any constraint on $\\mathbf{y}$:\n\n", "itemtype": "equation", "pos": 28773, "prevtext": "\nwhich we claim is equivalent to:\n\n", "index": 11, "text": "\\begin{equation}\n\\label{equ:sp}\n\\small\n\\begin{aligned}\n& \\text{minimize}_{\\mathbf{w}, z} && -z \\\\\n& \\text{subject to} &&  \n\\sum_{t = 1}^\\tau z\\prod_{d=1}^Dw_d^{\\mathbb{I}_{w_d\\in\\mathcal{T}_t}}\n - \n \\sum_{l = 1}^\\tau \\prod_{n=1}^N\\mathbb{I}_{x_n}^{(t)}\\prod_{d=1}^Dw_d^{\\mathbb{I}_{w_d\\in\\mathcal{T}_t}}\n \\leq 0 \\\\\n& && \\mathbf{w}\\in{\\mathbb{R}}_{++}^D, z > 0\n\\end{aligned}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6X.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\text{minimize}_{\\mathbf{w},z}\" display=\"inline\"><msub><mtext mathsize=\"90%\">minimize</mtext><mrow><mi mathsize=\"90%\">\ud835\udc30</mi><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mi mathsize=\"90%\">z</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6X.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle-z\" display=\"inline\"><mrow><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mi mathsize=\"90%\">z</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6Xa.m4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum_{t=1}^{\\tau}z\\prod_{d=1}^{D}w_{d}^{\\mathbb{I}_{w_{d}\\in%&#10;\\mathcal{T}_{t}}}-\\sum_{l=1}^{\\tau}\\prod_{n=1}^{N}\\mathbb{I}_{x_{n}}^{(t)}%&#10;\\prod_{d=1}^{D}w_{d}^{\\mathbb{I}_{w_{d}\\in\\mathcal{T}_{t}}}\\leq 0\" display=\"inline\"><mrow><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">t</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">\u03c4</mi></munderover></mstyle><mrow><mi mathsize=\"90%\">z</mi><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi mathsize=\"90%\">d</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">D</mi></munderover></mstyle><msubsup><mi mathsize=\"90%\">w</mi><mi mathsize=\"90%\">d</mi><msub><mi mathsize=\"90%\">\ud835\udd40</mi><mrow><msub><mi mathsize=\"90%\">w</mi><mi mathsize=\"90%\">d</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"90%\">\ud835\udcaf</mi><mi mathsize=\"90%\">t</mi></msub></mrow></msub></msubsup></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">-</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">l</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">\u03c4</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi mathsize=\"90%\">n</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">N</mi></munderover></mstyle><mrow><msubsup><mi mathsize=\"90%\">\ud835\udd40</mi><msub><mi mathsize=\"90%\">x</mi><mi mathsize=\"90%\">n</mi></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">t</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi mathsize=\"90%\">d</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">D</mi></munderover></mstyle><msubsup><mi mathsize=\"90%\">w</mi><mi mathsize=\"90%\">d</mi><msub><mi mathsize=\"90%\">\ud835\udd40</mi><mrow><msub><mi mathsize=\"90%\">w</mi><mi mathsize=\"90%\">d</mi></msub><mo mathsize=\"90%\" stretchy=\"false\">\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"90%\">\ud835\udcaf</mi><mi mathsize=\"90%\">t</mi></msub></mrow></msub></msubsup></mrow></mrow></mrow></mrow></mrow><mo mathsize=\"90%\" stretchy=\"false\">\u2264</mo><mn mathsize=\"90%\">0</mn></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6Xb.m3\" class=\"ltx_Math\" alttext=\"\\displaystyle\\mathbf{w}\\in{\\mathbb{R}}_{++}^{D},z&gt;0\" display=\"inline\"><mrow><mrow><mi mathsize=\"90%\">\ud835\udc30</mi><mo mathsize=\"90%\" stretchy=\"false\">\u2208</mo><msubsup><mi mathsize=\"90%\">\u211d</mi><mrow><mi/><mo mathsize=\"90%\" stretchy=\"false\">+</mo><mo mathsize=\"90%\" stretchy=\"false\">+</mo></mrow><mi mathsize=\"90%\">D</mi></msubsup></mrow><mo mathsize=\"90%\" stretchy=\"false\">,</mo><mrow><mi mathsize=\"90%\">z</mi><mo mathsize=\"90%\" stretchy=\"false\">&gt;</mo><mn mathsize=\"90%\">0</mn></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nNote that in the first term of Eq.~\\ref{equ:cccp} the upper index $\\tau(\\mathbf{x})\\leq \\tau\\triangleq f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ depends on the current input $\\mathbf{x}$ because not all the induced tree SPNs take positive value for the current input $\\mathbf{x}$. By transforming into the log-space, we naturally guarantee the positivity of the solution at each iteration, hence transforming a constrained optimization problem into an unconstrained optimization problem without any sacrifice. Furthermore, both terms in Eq.~\\ref{equ:cccp} are convex functions in $\\mathbf{y}$ after the transformation. Hence, the transformed objective function is now expressed as the difference of two convex functions, which is called a DC function~\\citep{hartman1959functions}. The class of DC functions is a super class of convex functions and is closed under most of the operations that can be encountered in mathematical optimization~\\citep{piot2014difference}. The optimization problem with respect to DC functions is known as DCP. The DCP formulation helps us to design two efficient algorithms to solve the problem based on the general idea of sequential convex approximations for nonlinear programming. \n\n\n\n\\begin{figure}[thb]\n\\centering\n    \\includegraphics[scale=1.0]{update.pdf}\n\\caption{Information flow about the computation of the gradient of log-network polynomial with respect to $y_{ij} (w_{ij})$. Each edge $y_{ij}(w_{ij})$ collects the evaluation value from $v_j$ in bottom-up pass and also differentiation value from $v_i$ in top-down pass.}\n\\label{fig:update}\n\\end{figure}\n\\subsubsection{Sequential Monomial Approximation}\nLet's consider the linearization of both terms in Eq.~\\ref{equ:cccp} in order to apply first-order methods in the transformed space. To compute the gradient with respect to different components of $\\mathbf{y}$, we view each node of an SPN as an intermediate function of the network polynomial and apply the chain rule to back propagate the gradient. \nThe differentiation of $f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})$ with respect to the root node of the network is set to be 1. The differentiation of the network polynomial with respect to a partial function at each node can then be computed in two passes of the network: the bottom-up pass evaluates the values of all partial functions given the current input $\\mathbf{x}$ and the top-down pass differentiates the network polynomial with respect to each partial function. Since the model parameters $\\mathbf{y}(\\mathbf{w})$ are only associated with sum nodes, they can be easily computed once we have obtained the differentiations for each node:\n\n", "itemtype": "equation", "pos": 32514, "prevtext": "\nIt is easy to check that both the objective function and constraint function in~(\\ref{equ:sp}) are signomials. To see the equivalence of (\\ref{equ:primal}) and (\\ref{equ:sp}), let $p^*$ be the optimal value of (\\ref{equ:primal}) achieved at $\\mathbf{w}^*$. Choose $z = p^*$ and $\\mathbf{w} = \\mathbf{w}^*$ in (\\ref{equ:sp}), then $-z$ is also the optimal solution of (\\ref{equ:sp}) otherwise we can find feasible $(z', \\mathbf{w}')$ in (\\ref{equ:sp}) which has $-z' < -z \\Leftrightarrow z' > z$. Combined with the constraint function in (\\ref{equ:sp}), we have $p^* = z < z' \\leq \\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}')}{f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{w}')}$, which contradicts the optimality of $p^*$. In the other direction, let $z^*, \\mathbf{w}^*$ be the solution that achieves optimal value of (\\ref{equ:sp}), then we claim that $z^*$ is also the optimal value of (\\ref{equ:primal}), otherwise there exists a feasible $\\mathbf{w}$ in (\\ref{equ:primal}) such that $z\\triangleq\\frac{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})} > z^*$. Since $(\\mathbf{w}, z)$ is also feasible in (\\ref{equ:sp}) with $-z < -z^*$, this contradicts the optimality of $z^*$.\n\\end{proof}\nThe transformation from (\\ref{equ:primal}) to (\\ref{equ:sp}) does not make the problem any easier to solve.  Rather, it destroys the structure of (\\ref{equ:primal}), i.e., the objective function of (\\ref{equ:primal}) is the ratio of two posynomials. However, the equivalent transformation does reveal some insights about the intrinsic complexity of the optimization problem, which indicates that it is hard to solve (\\ref{equ:primal}) efficiently with the guarantee of achieving a globally optimal solution.\n\n\\subsection{Sequential Convex Approximations}\n\n\nPGD optimizes the log-likelihood by projecting the intermediate solution back to the positive orthant after each gradient update. Since the constraint in (\\ref{equ:primal}) is an open set, we need to manually create a closed set on which the projection operation can be well defined. One feasible choice is to project on to ${\\mathbb{R}}_{\\epsilon}^{D}\\triangleq\\{\\mathbf{w}\\in{\\mathbb{R}}^D_{++}~|~w_d\\geq\\epsilon, \\forall d\\}$ where $\\epsilon > 0$ is assumed to be very small. \n\n\n\n\n\nTo avoid the projection, one direct solution is to use the exponentiated gradient (EG) method\\citep{kivinen1997exponentiated}, which was first applied in an online setting and latter successfully extended to batch settings when training with convex models~\\citep{collins2005exponentiated,globerson2007exponentiated,collins2008exponentiated}.\nEG admits a multiplicative update at each iteration and hence avoids the need for projection in PGD. Both PGD and EG are first-order methods and they can be viewed as approximating the SP after applying a log-transformation to the objective function only.\n\n\n\n\nNotice that although (\\ref{equ:primal}) is a signomial program, its objective function is expressed as the ratio of two posynomials. Hence, we can still apply the \\emph{logarithmic transformation trick} used in geometric programming to its objective function and to the variables to be optimized. More concretely, let $w_d = \\exp(y_d), \\forall d$ and take the $\\log$ of the objective function, it becomes equivalent to maximize the following new objective without any constraint on $\\mathbf{y}$:\n\n", "index": 13, "text": "\\begin{equation}\n\\label{equ:cccp}\n\\text{maximize}\\qquad\\log\\left(\\sum_{t=1}^{\\tau(\\mathbf{x})}\\exp(\\sum_{d=1}^Dy_d\\mathbb{I}_{y_d\\in\\mathcal{T}_t})\\right) - \\log\\left(\\sum_{t=1}^{\\tau}\\exp(\\sum_{d=1}^Dy_d\\mathbb{I}_{y_d\\in\\mathcal{T}_t})\\right)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\text{maximize}\\qquad\\log\\left(\\sum_{t=1}^{\\tau(\\mathbf{x})}\\exp(\\sum_{d=1}^{D%&#10;}y_{d}\\mathbb{I}_{y_{d}\\in\\mathcal{T}_{t}})\\right)-\\log\\left(\\sum_{t=1}^{\\tau}%&#10;\\exp(\\sum_{d=1}^{D}y_{d}\\mathbb{I}_{y_{d}\\in\\mathcal{T}_{t}})\\right)\" display=\"block\"><mrow><mtext>maximize</mtext><mo mathvariant=\"italic\" separator=\"true\">\u2003\u2003</mo><mrow><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>\u03c4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">)</mo></mrow></mrow></munderover><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mrow><msub><mi>y</mi><mi>d</mi></msub><mo>\u2062</mo><msub><mi>\ud835\udd40</mi><mrow><msub><mi>y</mi><mi>d</mi></msub><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi><mi>t</mi></msub></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mi>log</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>\u03c4</mi></munderover><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mrow><msub><mi>y</mi><mi>d</mi></msub><mo>\u2062</mo><msub><mi>\ud835\udd40</mi><mrow><msub><mi>y</mi><mi>d</mi></msub><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi><mi>t</mi></msub></mrow></msub></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhere $v_i$ is restricted to be a sum node and $v_j$ is a child of $v_i$. Following the evaluation-differentiation passes, the gradient of the objective function in (\\ref{equ:cccp}) can be computed in $O(|\\mathcal{S}|)$. Furthermore, although the computation is conducted in $\\mathbf{y}$, the results are fully expressed in terms of $\\mathbf{w}$, which suggests that in practice we do not need to explicitly construct $\\mathbf{y}$ from $\\mathbf{w}$. An illustration of the process is provided in Fig.~\\ref{fig:update}.\n\nLet $f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\mathbf{\\exp(\\mathbf{y})}) - \\log f_\\mathcal{S}(\\mathbf{1}|\\mathbf{\\exp(\\mathbf{y})})$, consider the optimal first-order approximation of $f(\\mathbf{y})$ at point $\\mathbf{y}^{(k)}$:\n\n", "itemtype": "equation", "pos": 35412, "prevtext": "\nNote that in the first term of Eq.~\\ref{equ:cccp} the upper index $\\tau(\\mathbf{x})\\leq \\tau\\triangleq f_\\mathcal{S}(\\mathbf{1}|\\mathbf{1})$ depends on the current input $\\mathbf{x}$ because not all the induced tree SPNs take positive value for the current input $\\mathbf{x}$. By transforming into the log-space, we naturally guarantee the positivity of the solution at each iteration, hence transforming a constrained optimization problem into an unconstrained optimization problem without any sacrifice. Furthermore, both terms in Eq.~\\ref{equ:cccp} are convex functions in $\\mathbf{y}$ after the transformation. Hence, the transformed objective function is now expressed as the difference of two convex functions, which is called a DC function~\\citep{hartman1959functions}. The class of DC functions is a super class of convex functions and is closed under most of the operations that can be encountered in mathematical optimization~\\citep{piot2014difference}. The optimization problem with respect to DC functions is known as DCP. The DCP formulation helps us to design two efficient algorithms to solve the problem based on the general idea of sequential convex approximations for nonlinear programming. \n\n\n\n\\begin{figure}[thb]\n\\centering\n    \\includegraphics[scale=1.0]{update.pdf}\n\\caption{Information flow about the computation of the gradient of log-network polynomial with respect to $y_{ij} (w_{ij})$. Each edge $y_{ij}(w_{ij})$ collects the evaluation value from $v_j$ in bottom-up pass and also differentiation value from $v_i$ in top-down pass.}\n\\label{fig:update}\n\\end{figure}\n\\subsubsection{Sequential Monomial Approximation}\nLet's consider the linearization of both terms in Eq.~\\ref{equ:cccp} in order to apply first-order methods in the transformed space. To compute the gradient with respect to different components of $\\mathbf{y}$, we view each node of an SPN as an intermediate function of the network polynomial and apply the chain rule to back propagate the gradient. \nThe differentiation of $f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})$ with respect to the root node of the network is set to be 1. The differentiation of the network polynomial with respect to a partial function at each node can then be computed in two passes of the network: the bottom-up pass evaluates the values of all partial functions given the current input $\\mathbf{x}$ and the top-down pass differentiates the network polynomial with respect to each partial function. Since the model parameters $\\mathbf{y}(\\mathbf{w})$ are only associated with sum nodes, they can be easily computed once we have obtained the differentiations for each node:\n\n", "index": 15, "text": "\\begin{align}\n\\label{equ:diff}\n\\frac{\\partial \\log f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial y_{ij}}\n\n& = \\frac{\\partial \\log f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}f_{v_j}(\\mathbf{x}|\\mathbf{w})w_{ij}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\frac{\\partial\\log f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{%&#10;\\partial y_{ij}}\\par&#10;\" display=\"inline\"><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mi>log</mi><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></mfrac></mstyle></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{\\partial\\log f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{%&#10;\\partial f_{v_{i}}(\\mathbf{x}|\\mathbf{w})}f_{v_{j}}(\\mathbf{x}|\\mathbf{w})w_{ij}\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mo>\u2202</mo><mi>log</mi><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhich is equivalent to\n\n", "itemtype": "equation", "pos": 36424, "prevtext": "\nwhere $v_i$ is restricted to be a sum node and $v_j$ is a child of $v_i$. Following the evaluation-differentiation passes, the gradient of the objective function in (\\ref{equ:cccp}) can be computed in $O(|\\mathcal{S}|)$. Furthermore, although the computation is conducted in $\\mathbf{y}$, the results are fully expressed in terms of $\\mathbf{w}$, which suggests that in practice we do not need to explicitly construct $\\mathbf{y}$ from $\\mathbf{w}$. An illustration of the process is provided in Fig.~\\ref{fig:update}.\n\nLet $f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\mathbf{\\exp(\\mathbf{y})}) - \\log f_\\mathcal{S}(\\mathbf{1}|\\mathbf{\\exp(\\mathbf{y})})$, consider the optimal first-order approximation of $f(\\mathbf{y})$ at point $\\mathbf{y}^{(k)}$:\n\n", "index": 17, "text": "\\begin{equation}\n\\label{equ:fo}\n\\hat{f}(\\mathbf{y}) = f(\\mathbf{y}^{(k)}) + \\nabla_\\mathbf{y}f(\\mathbf{y}^{(k)})^T(\\mathbf{y} - \\mathbf{y}^{(k)})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\hat{f}(\\mathbf{y})=f(\\mathbf{y}^{(k)})+\\nabla_{\\mathbf{y}}f(\\mathbf{y}^{(k)})%&#10;^{T}(\\mathbf{y}-\\mathbf{y}^{(k)})\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><mi>f</mi></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc32</mi><mo>-</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nin the original space, where $C_1$ is a positive constant irrelevant of $\\mathbf{y}(\\mathbf{w})$. Eq.~\\ref{equ:mono} suggests that approximating $\\hat{f}(\\mathbf{y})$ with the best linear function is equivalent to using the best monomial approximation of the signomial program~(\\ref{equ:primal}). This leads to a sequential monomial approximation of the original SP formulation: at each iteration $\\mathbf{y}^{(k)}$, we linearize both terms in Eq.~\\ref{equ:cccp} and form the optimal monomial function in terms of $\\mathbf{w}^{(k)}$. The additive update of $\\mathbf{y}^{(k)}$ in Eq.~\\ref{equ:fo} leads to a multiplicative update of $\\mathbf{w}^{(k)}$. We use a backtracking line search to determine the step size of the update in each iteration.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Concave-convex Procedure}\n\nSequential monomial approximation is a general approximation technique that is applicable to any SP~\\citep{boyd2007tutorial,chiang2005geometric}. It linearizes both terms in $f(\\mathbf{y})$ to obtain an approximation of (\\ref{equ:cccp}) and then applies gradient descent in the transformed space. However, it fails to utilize the structure of the problem when learning SPNs. Here we propose another approach based on the concave-convex procedure (CCCP)~\\citep{yuille2002concave} to utilize the fact that the objective function is expressed as the difference of two convex functions. \nAt a high level CCCP solves a sequence of concave surrogate optimizations until convergence. In most of the cases, the maximum of a concave surrogate function can only be solved using other convex solvers and as a result the efficiency of the CCCP highly depends on the choice of the convex solvers. However, we show that by a suitable transformation of the network we can compute the maximum of the concave surrogate in closed form in time that is linear in the network size, which leads to a very efficient algorithm for learning the parameters of SPNs. We also prove the convergence properties of our algorithm.\n\nConsider the objective function to be maximized in DCP: $f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y})) - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y})) \\triangleq f_1(\\mathbf{y}) + f_2(\\mathbf{y})$ where $f_1(\\mathbf{y})\\triangleq \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y}))$ is a convex function and $f_2(\\mathbf{y})\\triangleq - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y}))$ is a concave function. We can linearize only the convex part $f_1(\\mathbf{y})$ to obtain a surrogate function\n\n", "itemtype": "equation", "pos": 36608, "prevtext": "\nwhich is equivalent to\n\n", "index": 19, "text": "\\begin{equation}\n\\label{equ:mono}\n\\exp(\\hat{f}(\\mathbf{w})) = \\exp\\{f(\\mathbf{y}^{(k)}) + \\nabla_\\mathbf{y}f(\\mathbf{y}^{(k)})^T(\\mathbf{y} - \\mathbf{y}^{(k)})\\} \n= C_1\\prod_{d=1}^D w_d^{\\nabla_{y_d}f(\\mathbf{y}^{(k)})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\exp(\\hat{f}(\\mathbf{w}))=\\exp\\{f(\\mathbf{y}^{(k)})+\\nabla_{\\mathbf{y}}f(%&#10;\\mathbf{y}^{(k)})^{T}(\\mathbf{y}-\\mathbf{y}^{(k)})\\}=C_{1}\\prod_{d=1}^{D}w_{d}%&#10;^{\\nabla_{y_{d}}f(\\mathbf{y}^{(k)})}\" display=\"block\"><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><mi>f</mi></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc32</mi><mo>-</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>C</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><msubsup><mi>w</mi><mi>d</mi><mrow><mrow><msub><mo>\u2207</mo><msub><mi>y</mi><mi>d</mi></msub></msub><mo>\u2061</mo><mi>f</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></msubsup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nfor $\\forall \\mathbf{y}, \\mathbf{z}\\in{\\mathbb{R}}^D$. Due to the convexity of $f_1(\\mathbf{y})$ we have $f_1(\\mathbf{y})\\geq f_1(\\mathbf{z}) + \\nabla_\\mathbf{y}f_1(\\mathbf{z})^T(\\mathbf{y} - \\mathbf{z}), \\forall\\mathbf{y}, \\mathbf{z}$ and as a result the following two properties always hold for $\\forall \\mathbf{y}, \\mathbf{z}$:\n\n", "itemtype": "equation", "pos": 39374, "prevtext": "\nin the original space, where $C_1$ is a positive constant irrelevant of $\\mathbf{y}(\\mathbf{w})$. Eq.~\\ref{equ:mono} suggests that approximating $\\hat{f}(\\mathbf{y})$ with the best linear function is equivalent to using the best monomial approximation of the signomial program~(\\ref{equ:primal}). This leads to a sequential monomial approximation of the original SP formulation: at each iteration $\\mathbf{y}^{(k)}$, we linearize both terms in Eq.~\\ref{equ:cccp} and form the optimal monomial function in terms of $\\mathbf{w}^{(k)}$. The additive update of $\\mathbf{y}^{(k)}$ in Eq.~\\ref{equ:fo} leads to a multiplicative update of $\\mathbf{w}^{(k)}$. We use a backtracking line search to determine the step size of the update in each iteration.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsubsection{Concave-convex Procedure}\n\nSequential monomial approximation is a general approximation technique that is applicable to any SP~\\citep{boyd2007tutorial,chiang2005geometric}. It linearizes both terms in $f(\\mathbf{y})$ to obtain an approximation of (\\ref{equ:cccp}) and then applies gradient descent in the transformed space. However, it fails to utilize the structure of the problem when learning SPNs. Here we propose another approach based on the concave-convex procedure (CCCP)~\\citep{yuille2002concave} to utilize the fact that the objective function is expressed as the difference of two convex functions. \nAt a high level CCCP solves a sequence of concave surrogate optimizations until convergence. In most of the cases, the maximum of a concave surrogate function can only be solved using other convex solvers and as a result the efficiency of the CCCP highly depends on the choice of the convex solvers. However, we show that by a suitable transformation of the network we can compute the maximum of the concave surrogate in closed form in time that is linear in the network size, which leads to a very efficient algorithm for learning the parameters of SPNs. We also prove the convergence properties of our algorithm.\n\nConsider the objective function to be maximized in DCP: $f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y})) - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y})) \\triangleq f_1(\\mathbf{y}) + f_2(\\mathbf{y})$ where $f_1(\\mathbf{y})\\triangleq \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y}))$ is a convex function and $f_2(\\mathbf{y})\\triangleq - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y}))$ is a concave function. We can linearize only the convex part $f_1(\\mathbf{y})$ to obtain a surrogate function\n\n", "index": 21, "text": "\\begin{equation}\n\\label{equ:surrogate}\n\\hat{f}(\\mathbf{y}, \\mathbf{z}) = f_1(\\mathbf{z}) + \\nabla_\\mathbf{y}f_1(\\mathbf{z})^T(\\mathbf{y} - \\mathbf{z}) + f_2(\\mathbf{y})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\hat{f}(\\mathbf{y},\\mathbf{z})=f_{1}(\\mathbf{z})+\\nabla_{\\mathbf{y}}f_{1}(%&#10;\\mathbf{z})^{T}(\\mathbf{y}-\\mathbf{z})+f_{2}(\\mathbf{y})\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><mi>\ud835\udc33</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc33</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><msub><mi>f</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc33</mi><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc32</mi><mo>-</mo><mi>\ud835\udc33</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>f</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nHence, $\\hat{f}(\\mathbf{y}, \\mathbf{z})$ is a concave function in $\\mathbf{y}$. CCCP updates $\\mathbf{y}$ at each iteration $k$ by solving\n\n", "itemtype": "equation", "pos": 39889, "prevtext": "\nfor $\\forall \\mathbf{y}, \\mathbf{z}\\in{\\mathbb{R}}^D$. Due to the convexity of $f_1(\\mathbf{y})$ we have $f_1(\\mathbf{y})\\geq f_1(\\mathbf{z}) + \\nabla_\\mathbf{y}f_1(\\mathbf{z})^T(\\mathbf{y} - \\mathbf{z}), \\forall\\mathbf{y}, \\mathbf{z}$ and as a result the following two properties always hold for $\\forall \\mathbf{y}, \\mathbf{z}$:\n\n", "index": 23, "text": "\\begin{equation}\n\\label{equ:properties}\n\\hat{f}(\\mathbf{y}, \\mathbf{z})\\leq f(\\mathbf{y})\\quad\\text{and}\\quad\n\\hat{f}(\\mathbf{y}, \\mathbf{y}) = f(\\mathbf{y})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\hat{f}(\\mathbf{y},\\mathbf{z})\\leq f(\\mathbf{y})\\quad\\text{and}\\quad\\hat{f}(%&#10;\\mathbf{y},\\mathbf{y})=f(\\mathbf{y})\" display=\"block\"><mrow><mrow><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><mi>\ud835\udc33</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mtext>and</mtext></mrow></mrow><mo mathvariant=\"italic\" separator=\"true\">\u2003</mo><mrow><mrow><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nunless we already have $\\mathbf{y}^{(k-1)}\\in{\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$, in which case a generalized fixed point $\\mathbf{y}^{(k-1)}$ has been found and the algorithm stops. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is easy to show that at each iteration of CCCP we always have $f(\\mathbf{y}^{(k)})\\geq f(\\mathbf{y}^{(k-1)})$. Note also that $f(\\mathbf{y})$ is computing the log-likelihood of input $\\mathbf{x}$ and therefore it is bounded above by 0. By the monotone convergence theorem, $\\lim_{k\\rightarrow\\infty}f(\\mathbf{y}^{(k)})$ exists and the sequence $\\{f(\\mathbf{y}^{(k)})\\}$ converges. \n\nWe now discuss how to compute a closed form solution for the maximization of the concave surrogate $\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$. Since $\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ is concave for any fixed $\\mathbf{y}^{(k-1)}$, a sufficient and necessary condition to find its maximum is \n\n", "itemtype": "equation", "pos": 40201, "prevtext": "\nHence, $\\hat{f}(\\mathbf{y}, \\mathbf{z})$ is a concave function in $\\mathbf{y}$. CCCP updates $\\mathbf{y}$ at each iteration $k$ by solving\n\n", "index": 25, "text": "\\begin{equation}\n\\mathbf{y}^{(k)}\\in {\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\mathbf{y}^{(k)}\\in{\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y},%&#10;\\mathbf{y}^{(k-1)})\" display=\"block\"><mrow><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2208</mo><mrow><mrow><msub><mrow><mpadded width=\"+1.7pt\"><mi>arg</mi></mpadded><mo>\u2062</mo><mi>max</mi></mrow><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nIn the above equation, if we consider only the partial derivative with respect to $y_{ij}(w_{ij})$, we obtain\n\n\n\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 41259, "prevtext": "\nunless we already have $\\mathbf{y}^{(k-1)}\\in{\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$, in which case a generalized fixed point $\\mathbf{y}^{(k-1)}$ has been found and the algorithm stops. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is easy to show that at each iteration of CCCP we always have $f(\\mathbf{y}^{(k)})\\geq f(\\mathbf{y}^{(k-1)})$. Note also that $f(\\mathbf{y})$ is computing the log-likelihood of input $\\mathbf{x}$ and therefore it is bounded above by 0. By the monotone convergence theorem, $\\lim_{k\\rightarrow\\infty}f(\\mathbf{y}^{(k)})$ exists and the sequence $\\{f(\\mathbf{y}^{(k)})\\}$ converges. \n\nWe now discuss how to compute a closed form solution for the maximization of the concave surrogate $\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$. Since $\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ is concave for any fixed $\\mathbf{y}^{(k-1)}$, a sufficient and necessary condition to find its maximum is \n\n", "index": 27, "text": "\\begin{equation}\n\\label{equ:equilibrium}\n\\nabla_\\mathbf{y}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)}) = \\nabla_\\mathbf{y}f_1(\\mathbf{y}^{(k-1)}) + \\nabla_\\mathbf{y}f_2(\\mathbf{y})  = 0\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\nabla_{\\mathbf{y}}\\hat{f}(\\mathbf{y},\\mathbf{y}^{(k-1)})=\\nabla_{\\mathbf{y}}f%&#10;_{1}(\\mathbf{y}^{(k-1)})+\\nabla_{\\mathbf{y}}f_{2}(\\mathbf{y})=0\" display=\"block\"><mrow><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><mover accent=\"true\"><mi>f</mi><mo stretchy=\"false\">^</mo></mover></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><msub><mi>f</mi><mn>1</mn></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc32</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><msub><mo>\u2207</mo><mi>\ud835\udc32</mi></msub><mo>\u2061</mo><msub><mi>f</mi><mn>2</mn></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nSince there are $D$ partial derivatives in the gradient, this leads to a system of $D$ nonlinear equations, which is hard to solve in closed form.  However, if we do a change of variable by considering locally normalized weights $w'_{ij}$ (i.e., $w'_{ij} \\ge 0$ and $\\sum_j w'_{ij} =1 \\; \\forall i$), then a solution can be easily computed.  As described in~\\citep{peharz2015theoretical,zhao2015spnbn}, any SPN can be transformed into an equivalent {\\em normal} SPN with locally normalized weights in a bottom up pass as follows: \n\n", "itemtype": "equation", "pos": 41574, "prevtext": "\nIn the above equation, if we consider only the partial derivative with respect to $y_{ij}(w_{ij})$, we obtain\n\n\n\n\n\n\n\n\n\n\n", "index": 29, "text": "\\begin{equation}\n\\label{equ:ne}\n \\frac{w^{(k-1)}_{ij}f_{v_j}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w}^{(k-1)})} \n= \n\\frac{w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})}{f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})}\n\\frac{\\partial f_\\mathcal{S}(\\mathbf{1}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{1}|\\mathbf{w})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\frac{w^{(k-1)}_{ij}f_{v_{j}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{f_{\\mathcal{S}}(%&#10;\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{x}|%&#10;\\mathbf{w}^{(k-1)})}{\\partial f_{v_{i}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}=\\frac{%&#10;w_{ij}f_{v_{j}}(\\mathbf{1}|\\mathbf{w})}{f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{w})%&#10;}\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{1}|\\mathbf{w})}{\\partial f_{v_{i}}(%&#10;\\mathbf{1}|\\mathbf{w})}\" display=\"block\"><mrow><mrow><mfrac><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>=</mo><mrow><mfrac><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nWe can then replace $w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})$ in the above equation by the expression it is equal to in Eq.~\\ref{equ:ne} to obtain a closed form solution: \n\n", "itemtype": "equation", "pos": 42548, "prevtext": "\nSince there are $D$ partial derivatives in the gradient, this leads to a system of $D$ nonlinear equations, which is hard to solve in closed form.  However, if we do a change of variable by considering locally normalized weights $w'_{ij}$ (i.e., $w'_{ij} \\ge 0$ and $\\sum_j w'_{ij} =1 \\; \\forall i$), then a solution can be easily computed.  As described in~\\citep{peharz2015theoretical,zhao2015spnbn}, any SPN can be transformed into an equivalent {\\em normal} SPN with locally normalized weights in a bottom up pass as follows: \n\n", "index": 31, "text": "\\begin{equation}\n\\label{eq:normalize}\nw'_{ij} = \\frac{w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})}{\\sum_j w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"w^{\\prime}_{ij}=\\frac{w_{ij}f_{v_{j}}(\\mathbf{1}|\\mathbf{w})}{\\sum_{j}w_{ij}f_%&#10;{v_{j}}(\\mathbf{1}|\\mathbf{w})}\" display=\"block\"><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2032</mo></msubsup><mo>=</mo><mfrac><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\n\n\n\n\n\n\n\n\nEq.~\\ref{equ:update} also suggests that in order to obtain a solution to Eq.~\\ref{equ:ne}, for each edge weight $w_{ij}$, the sufficient statistics include only three terms, i.e, the evaluation value at $v_j$, the differentiation value at $v_i$ and the previous edge weight $w_{ij}^{(k-1)}$, all of which can be obtained in two passes of the network for each input $\\mathbf{x}$ as illustrated in Fig.~\\ref{fig:update}. Thus the computational complexity to obtain a maximum of the concave surrogate is $O(|\\mathcal{S}|)$. Interestingly, Eq.~\\ref{equ:update} leads to the same update formula as in the EM algorithm~\\citep{peharz2015foundations} despite the fact that CCCP and EM start from different perspectives. \n\nWe discussed before that the sequence of function values $\\{f(\\mathbf{y}^{(k)})\\}$ converges to a limiting point. However, this fact alone does not necessarily indicate that $\\{f(\\mathbf{y}^{(k)})\\}$ converges to $f(\\mathbf{y}^*)$ where $\\mathbf{y}^*$ is a stationary point of $f(\\cdot)$ nor does it imply that the sequence $\\{\\mathbf{y}^{(k)}\\}$ converges as $k\\rightarrow\\infty$. \\emph{Zangwill's global convergence theory}~\\citep{zangwill1969nonlinear} has been successfully applied to study the convergence properties of many iterative algorithms frequently used in machine learning, including EM~\\citep{wu1983convergence}, generalized alternating minimization~\\citep{gunawardana2005convergence} and also CCCP~\\citep{lanckriet2009convergence}. Here we also apply Zangwill's theory and combine the analysis from \\cite{lanckriet2009convergence} to show the following theorem:\n\\begin{restatable}{theorem}{thmb}\n\\label{thm:convergence}\nLet $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$ be any sequence generated using Eq.~\\ref{equ:update} from any positive initial point, then all the limiting points of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$ are stationary points of the DCP in (\\ref{equ:cccp}). In addition, $\\lim_{k\\rightarrow\\infty}f(\\mathbf{y}^{(k)}) = f(\\mathbf{y}^*)$, where $\\mathbf{y}^*$ is some stationary point of (\\ref{equ:cccp}).\n\\end{restatable}\nWe delay the proof of this theorem to appendix. It is worth to point out that the above theorem \\emph{does not} imply the convergence of the sequence $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$. Thm.~\\ref{thm:convergence} only indicates that all the limiting points of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, i.e., the limits of subsequences of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, are stationary points of the DCP in (\\ref{equ:cccp}). We also present a negative example in the appendix that invalidates the application of Zangwill's global convergence theory on the analysis in this case.\n\nThe convergence rate of general CCCP is still an open problem~\\citep{lanckriet2009convergence}. \\cite{salakhutdinov2002convergence} studied the convergence rate of unconstrained bound optimization algorithms with differentiable objective functions, of which our problem is a special case. The conclusion is that depending on the curvature of $f_1$ and $f_2$ (which are functions of the training data), CCCP will exhibit either a quasi-Newton behavior with superlinear convergence or first-order convergence. We show in experiments that CCCP normally exhibits a fast, superlinear convergence rate compared with PGD, EG and SMA. Both CCCP and EM are special cases of a more general framework known as Majorization-Maximization~\\cite{hunter2004tutorial}. We show that in the case of SPNs these two algorithms coincide with each other, i.e., they lead to the same update formulas despite the fact that they start from totally different perspectives. We refer interested readers to the appendix for a detailed derivation and discussion. We summarize all 4 algorithms and highlight their connections and differences in Table~\\ref{table:summary}.\n\\begin{table*}[htb]\n\\centering\n\\small\n\\caption{Summary of PGD, EG, SMA and CCCP. Var. means the optimization variables.}\n\\label{table:summary}\n\\begin{tabular}{|l|l|l|l|l|}\\hline\n\\textbf{Algo} & \\textbf{Var.} & \\textbf{Update Type} & \\textbf{Approx. Type} & \\textbf{Update Formula}\\\\\\hline\nPGD & $\\mathbf{w}$ & Additive & Linearization  & $w_d^{(k+1)}\\leftarrow P_{{\\mathbb{R}}_{++}^\\epsilon}\\left\\lbrace w_d^{(k)} + \\gamma(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\right\\rbrace$ \\\\\\hline\nEG & $\\mathbf{w}$ & Multiplicative & Linearization & $w_d^{(k+1)}\\leftarrow w_d^{(k)}\\exp\\{\\gamma(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\}$ \\\\\\hline\nSMA & $\\log\\mathbf{w}$ & Multiplicative & Monomial & $w_d^{(k+1)}\\leftarrow w_d^{(k)}\\exp\\{\\gamma w_d^{(k)}\\times(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\}$ \\\\\\hline\nCCCP & $\\log\\mathbf{w}$ & Multiplicative & Log-sum-exp+Affine & $w_{ij}^{(k+1)}\\propto w_{ij}^{(k)}\\times\\nabla_{v_i}f_{\\mathcal{S}}(\\mathbf{w}^{(k)})\\times f_{v_j}(\\mathbf{w}^{(k)})$\\\\\\hline\n\\end{tabular}\n\\end{table*}\n\\section{Experiments}\n\\subsection{Experimental Setting}\nWe conduct experiments on 20 benchmark data sets from various domains to compare and evaluate the convergence performance of the four algorithms: PGD, EG, SMA and CCCP. These 20 data sets are widely used in~\\citep{gens2013learning,rooshenas2014learning} to assess different SPNs for the task of density estimation. The domain of these 20 data sets include click-through logs, plant habitats, nucleic acid sequences, text documents, movie rates and many others. All the features in the 20 data sets are binary features. The 20 data sets cover three typical statistical estimation settings where the number of training instances is either greater, similar or much smaller than the number of optimization variables. Hence, they enable a thorough experimental comparison to test these 4 algorithms under different applications and statistical scenarios. Detailed information about these 20 datasets and the SPNs used in the experiments are provided in Table.~\\ref{table:statistics} and Table.~\\ref{table:sizes}. All the SPNs that are used for comparisons of PGD, EG, SMA and EM are trained using LearnSPN~\\citep{gens2013learning}. We discard the weights returned by LearnSPN and use random weights as initial model parameters. The random weights are determined by the same random seed in all four algorithms.\n\\begin{table*}[htb]\n\\centering\n\\caption{Statistics of data sets and models. $N$ is the number of variables modeled by the network, $|\\mathcal{S}|$ is the size of the network and $D$ is the number of parameters to be estimated in the network. $N \\times V/D$ means the ratio of training instances times the number of variables to the number parameters.}\n\\label{table:statistics}\n\\begin{tabular}{|l||r|r|r|r|r|r|r|}\\hline\n\\textbf{Data set} & $N$ & $|\\mathcal{S}|$ & $D$ & Train & Valid & Test & $N\\times V/D$ \\\\\\hline\nNLTCS & 16 & 13,733 & 1,716 & 16,181 & 2,157 & 3,236 & 150.871 \\\\ \nMSNBC & 17 & 54,839 & 24,452 & 291,326 & 38,843 & 58,265 & 202.541\\\\\nKDD 2k & 64 & 48,279 & 14,292 & 180,092 & 19,907 & 34,955 & 806.457\\\\\nPlants & 69 & 132,959 & 58,853 &17,412 & 2,321 & 3,482 & 20.414\\\\\nAudio & 100 & 739,525 & 196,103 & 15,000 & 2,000 & 3,000 & 7.649\\\\\nJester & 100 & 314,013 & 180,750 & 9,000 & 1,000 & 4,116 & 4.979 \\\\\nNetflix & 100 & 161,655 & 51,601 & 15,000 & 2,000 & 3,000 & 29.069\\\\\nAccidents & 111 & 204,501 & 74,804 & 12,758 & 1,700 & 2,551 & 18.931\\\\\nRetail & 135 & 56,931 & 22,113 & 22,041 & 2,938 & 4,408 & 134.560\\\\\nPumsb-star & 163 & 140,339 & 63,173 & 12,262 & 1,635 & 2,452 & 31.638\\\\\nDNA & 180 & 108,021 & 52,121 & 1,600 & 400 & 1,186 & 5.526\\\\\nKosarak & 190 & 203,321 & 53,204 & 33,375 & 4,450 & 6,675 & 119.187\\\\\nMSWeb & 294 & 68,853 & 20,346 & 29,441 & 3,270 & 5,000 & 425.423 \\\\\nBook & 500 & 190,625 & 41,122 & 8,700 & 1,159 & 1,739 & 105.783\\\\\nEachMovie & 500 & 522,753 & 188,387 & 4,524 & 1,002 & 591 & 12.007\\\\\nWebKB & 839 & 1,439,751 & 879,893 & 2,803 & 558 & 838 & 2.673\\\\\nReuters-52 & 889 & 2,210,325 & 1,453,390 & 6,532 & 1,028 & 1,540 & 3.995\\\\\n20 Newsgrp & 910 & 14,561,965 & 8,295,407 & 11,293 & 3,764 & 3,764 & 1.239 \\\\\nBBC & 1058 & 1,879,921 & 1,222,536 & 1,670 & 225 & 330 & 1.445\\\\\nAd & 1556 & 4,133,421 & 1,380,676 & 2,461 & 327 & 491 & 2.774 \\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Parameter Learning}\nWe implement all four algorithms in C++ and test them on a compute server with 32 cores. Each core is Intel Xeon(R) CPU E5 2.00GHz. For each algorithm, we set the maximum number of iterations to 50. If the absolute difference in the training log-likelihood at two consecutive steps is less than $0.001$, the algorithms are stopped. We combine PGD, EG and SMA with backtracking line search and use a weight shrinking coefficient set at $0.8$. The learning rates are initialized to $1.0$ for all three methods. For PGD, we set the projection margin $\\epsilon$ to 0.01. There is no learning rate and no backtracking line search in CCCP. We set the smoothing parameter to $0.001$ in CCCP to avoid numerical issues. \n\nWe show in Fig.~\\ref{fig:lld} the average log-likelihood scores on 20 training data sets to evaluate the convergence speed and stability of PGD, EG, SMA and CCCP. Clearly, CCCP wins by a large margin over PGD, EG and SMA, both in convergence speed and solution quality. Furthermore, among the four algorithms, CCCP is the most stable one due to its guarantee that the log-likelihood (on training data) will not decrease after each iteration. These 20 experiments also clearly show that CCCP often converges in a few iterations, exhibiting a superlinear convergence speed. On the other hand, PGD, EG and SMA are on par with each other since they are all first-order methods. SMA is more stable than PGD and EG and often achieves better solutions than PGD and EG. On large data sets, SMA also converges faster than PGD and EG. Surprisingly, EG performs worse than PGD in some cases and is quite unstable despite the fact that it admits multiplicative updates. The ``hook shape'' curves of PGD in some data sets are due to the projection operations, which makes PGD the most unstable one among the four algorithms. The computational complexity per update is $O(|\\mathcal{S}|)$ in all four algorithms. The constant involved in the $|\\mathcal{S}|$ term of CCCP is slightly larger than those of the other three algorithms as there are more $\\exp(\\cdot)$ calls in CCCP. However, in practice, CCCP often takes less time than the other three algorithms because it takes fewer iterations to converge. We list detailed running time statistics for all four algorithms on the 20 data sets in Table.~\\ref{table:time}.\n\n\\begin{figure*}[htb]\n\\centering\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{nltcs.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{msnbc.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{kdd.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{plants.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{baudio.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{jester.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{bnetflix.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{accidents.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{tretail.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{pumsb_star.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{dna.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{kosarek.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{msweb.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{book.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{tmovie.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{cwebkb.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{cr52.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{c20ng.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{bbc.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{ad.pdf}\n\\end{subfigure}\n\\caption{Negative log-likelihood values on training data versus number of iterations for PGD, EG, SMA and CCCP.}\n\\label{fig:lld}\n\\end{figure*}\n\n\\begin{table*}[htb]\n\\centering\n\\caption{Running time of 4 algorithms on 20 data sets, measured in seconds.}\n\\label{table:time}\n\\begin{tabular}{|l|r|r|r|r|}\\hline\n\\textbf{Data set} & PGD & EG & SMA & CCCP\\\\\\hline\nNLTCS & 438.35 & 718.98 & 458.99 & 206.10 \\\\\nMSNBC & 2720.73 & 2917.72 & 8078.41 & 2008.07 \\\\\nKDD 2k & 46388.60 & 22154.10 & 27101.50 & 29541.20 \\\\\nPlants & 12595.60 & 10752.10 & 7604.09 & 13049.80 \\\\\nAudio & 19647.90 & 3430.69 & 12801.70 & 14307.30 \\\\\nJester & 6099.44 & 6272.80 &  4082.65 & 1931.41 \\\\\nNetflix & 29573.10 & 27931.50 & 15080.50 &  8400.20 \\\\\nAccidents & 14266.50 & 3431.82 & 5776.00 & 20345.90 \\\\\nRetail & 28669.50 & 7729.89 & 9866.94 & 5200.20 \\\\\nPumsb-star & 3115.58 & 13872.80 & 4864.72 & 2377.54 \\\\\nDNA & 599.93 & 199.63 & 727.56 & 1380.36 \\\\\nKosarak & 122204.00 & 112273.00 & 49120.50 & 42809.30 \\\\\nMSWeb & 136524.00 & 13478.10 & 65221.20 & 45132.30 \\\\\nBook & 190398.00 & 6487.84 & 69730.50 & 23076.40 \\\\\nEachMovie & 30071.60 & 32793.60 & 17751.10 & 60184.00 \\\\\nWebKB & 123088.00 & 50290.90 & 44004.50 & 168142.00 \\\\\nReuters-52 & 13092.10 & 5438.35 & 20603.70 & 1194.31 \\\\\n20 Newsgrp & 151243.00 & 96025.80 & 173921.00 & 11031.80 \\\\\nBBC & 20920.60 & 18065.00 & 36952.20 & 3440.37 \\\\\nAd & 12246.40 & 2183.08 & 12346.70 & 731.48\\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Boosting Structure Learning}\nIn this experiment, we combine CCCP as a ``fine tuning'' procedure with the structure learning algorithm LearnSPN and compare it to the state-of-the-art structure learning algorithm ID-SPN~\\citep{rooshenas2014learning}. More concretely, we keep the model parameters learned from LearnSPN and use them to initialize CCCP. We then update the model parameters globally using CCCP as a fine tuning technique. This normally helps to obtain a better generative model since the original parameters are learned greedily and locally during the structure learning algorithm. The final CCCP procedure adjusts all the parameters globally toward a better solution. In this experiment, we use the validation set log-likelihood score to avoid overfitting. The algorithm returns the set of parameters that achieve the best validation set log-likelihood score as output. Experimental results are reported in Table.~\\ref{table:log-likelihood}.\n\nAs shown in Table~\\ref{table:log-likelihood}, the use of CCCP after LearnSPN always helps to improve the model performance. By optimizing model parameters on these 20 data sets, we boost LearnSPN to achieve better results than state-of-the-art ID-SPN on 7 data sets, where the original LearnSPN only outperforms ID-SPN on 1 data set. Note that the sizes of the SPNs returned by LearnSPN are much smaller than those produced by ID-SPNs. Hence, it is remarkable that by fine tuning the parameters with CCCP, we can achieve better performance despite the fact that the models are smaller.  For a fair comparison, we also list the size of the SPNs returned by ID-SPN in Table.~\\ref{table:sizes}. As a result, we suggest using CCCP after structure learning algorithms to fully exploit the expressiveness of the constructed model.\n\n\\begin{table}[htb]\n\\begin{minipage}[b]{0.6\\textwidth}\n\\centering\n\\caption{Average log-likelihoods on test data. Highest average log-likelihoods are highlighted in bold.}\n\\label{table:log-likelihood}\n\\begin{tabular}{|l||r|r|r|}\\hline\n\\textbf{Data set} & CCCP & LearnSPN & ID-SPN \\\\\\hline\nNLTCS & \\textbf{-6.029} & -6.099 & -6.050  \\\\\nMSNBC & \\textbf{-6.045} & -6.113 & -6.048 \\\\\nKDD 2k & \\textbf{-2.134} & -2.233 & -2.153 \\\\\nPlants & -12.872 & -12.955 & \\textbf{-12.554} \\\\\nAudio & -40.020 & -40.510 & \\textbf{-39.824} \\\\\nJester & \\textbf{-52.880} & -53.454 & -52.912 \\\\\nNetflix & -56.782 & -57.385 & \\textbf{-56.554} \\\\\nAccidents & -27.700 & -29.907 & \\textbf{-27.232} \\\\\nRetail & \\textbf{-10.919} & -11.138 & -10.945 \\\\\nPumsb-star & -24.229 & -24.577 & \\textbf{-22.552} \\\\\nDNA & -84.921 & -85.237 & \\textbf{-84.693} \\\\\nKosarak & -10.880 & -11.057 & \\textbf{-10.605} \\\\\nMSWeb & -9.970 & -10.269 & \\textbf{-9.800} \\\\\nBook & -35.009 & -36.247 & \\textbf{-34.436} \\\\\nEachMovie & -52.557 & -52.816 & \\textbf{-51.550} \\\\\nWebKB & -157.492 & -158.542 & \\textbf{-153.293} \\\\\nReuters-52 & -84.628 & -85.979 & \\textbf{-84.389} \\\\\n20 Newsgrp & -153.205 & -156.605 & \\textbf{-151.666} \\\\\nBBC & \\textbf{-248.602} & -249.794 & -252.602\\\\\nAd & \\textbf{-27.202} & -27.409 & -40.012 \\\\\\hline\n\\end{tabular}\n\\end{minipage}\n\\begin{minipage}[b]{0.4\\textwidth}\n\\caption{Sizes of SPNs produced by LearnSPN and ID-SPN.}\n\\label{table:sizes}\n\\begin{tabular}{|l||r|r|}\\hline\n\\textbf{Data set} & LearnSPN & ID-SPN \\\\\\hline\nNLTCS & 13,733 & 24,690 \\\\\nMSNBC & 54,839 & 579,364 \\\\\nKDD 2k & 48,279 & 1,286,657 \\\\\nPlants & 132,959 & 2,063,708 \\\\\nAudio & 739,525 & 2,643,948\\\\\nJester & 314,013 & 4,225,471 \\\\\nNetflix & 161,655 & 7,958,088 \\\\\nAccidents & 204,501 & 2,273,186\\\\\nRetail & 56,931 & 60,961 \\\\\nPumsb-star & 140,339 & 1,751,092\\\\\nDNA & 108,021 & 3,228,616\\\\\nKosarak &  203,321 & 1,272,981\\\\\nMSWeb & 68,853 & 1,886,777\\\\\nBook & 190,625 & 1,445,501\\\\\nEachMovie & 522,753 & 2,440,864\\\\\nWebKB & 1,439,751 & 2,605,141 \\\\\nReuters-52 & 2,210,325 & 4,563,861 \\\\\n20 Newsgrp & 14,561,965 & 3,485,029\\\\\nBBC & 1,879,921 & 2,426,602\\\\\nAd & 4,133,421 & 2,087,253\\\\\\hline\n\\end{tabular}\n\\end{minipage}\n\\end{table}\n\n\\section{Conclusion}\nIn this paper we show that the network polynomial of an SPN is a posynomial function of the model parameters and that learning the parameter by maximum likelihood yields a signomial program. We propose two convex relaxations to solve the SP based on sequential monomial approximations and the concave-convex procedure. We analyze the convergence properties of CCCP for learning SPNs. Extensive experiments are conducted to evaluate the proposed approaches and current methods. \n\n\\newpage\n\\bibliography{reference}\n\\bibliographystyle{abbrvnat}\n\n\\begin{appendices}\n\\section{Convergence of CCCP for SPNs}\n\\thmb*\n\\begin{proof}\nWe will use Zangwill's global convergence theory for iterative algorithms~\\citep{zangwill1969nonlinear} to show the convergence in our case. Before showing the proof, we need to first introduce the notion of ``point-to-set mapping'', where the output of the mapping is defined to be a set. More formally, a point-to-set map $\\Phi$ from a set $\\mathcal{X}$ to $\\mathcal{Y}$ is defined as $\\Phi:\\mathcal{X}\\mapsto\\mathcal{P}(\\mathcal{Y})$, where $\\mathcal{P}(\\mathcal{Y})$ is the power set of $\\mathcal{Y}$. Suppose $\\mathcal{X}$ and $\\mathcal{Y}$ are equipped with the norm $||\\cdot||_\\mathcal{X}$ and $||\\cdot||_\\mathcal{Y}$, respectively. A point-to-set map $\\Phi$ is said to be \\emph{closed} at $x^*\\in\\mathcal{X}$ if $x_k\\in\\mathcal{X}$, $\\{x_k\\}_{k=1}^\\infty\\rightarrow x^*$ and $y_k\\in\\mathcal{Y}, \\{y_k\\}_{k=1}^\\infty\\rightarrow y^*, y_k\\in\\Phi(x_k)$ imply that $y^*\\in\\Phi(x^*)$. A point-to-set map $\\Phi$ is said to be closed on $S\\subseteq\\mathcal{X}$ if $\\Phi$ is closed at every point in $S$. The concept of \\emph{closedness} in the point-to-set map setting reduces to \\emph{continuity} if we restrict that the output of $\\Phi$ to be a set of singleton for every possible input, i.e., when $\\Phi$ is a point-to-point mapping. \n\\begin{theorem}[Global Convergence Theorem~\\citep{zangwill1969nonlinear}]\nLet the sequence $\\{x_k\\}_{k=1}^\\infty$ be generated by $x_{k+1}\\in\\Phi(x_k)$, where $\\Phi(\\cdot)$ is a point-to-set map from $\\mathcal{X}$ to $\\mathcal{X}$. Let a solution set $\\Gamma\\subseteq\\mathcal{X}$ be given, and suppose that:\n\\begin{enumerate}\n\t\\item \tall points $x_k$ are contained in a compact set $S\\subseteq \\mathcal{X}$.\n\t\\item \t$\\Phi$ is closed over the complement of $\\Gamma$.\n\t\\item \tthere is a continuous function $\\alpha$ on $\\mathcal{X}$ such that:\n\t\\begin{enumerate}\n\t\t\\item \tif $x\\not\\in\\Gamma$, $\\alpha(x') > \\alpha(x)$ for $\\forall x'\\in\\Phi(x)$.\n\t\t\\item \tif $x\\in\\Gamma, \\alpha(x')\\geq \\alpha(x)$ for $\\forall x'\\in\\Phi(x)$.\n\t\\end{enumerate}\t \n\\end{enumerate}\nThen all the limit points of $\\{x_k\\}_{k=1}^\\infty$ are in the solution set $\\Gamma$ and $\\alpha(x_k)$ converges monotonically to $\\alpha(x^*)$ for some $x^*\\in\\Gamma$.\n\\end{theorem}\nLet $\\mathbf{w}\\in{\\mathbb{R}}_{+}^D$. Let $\\Phi(\\mathbf{w}^{(k-1)}) = \\exp( {\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)}))$ and let $\\alpha(\\mathbf{w}) = f(\\log\\mathbf{w}) = f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y})) - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y}))$. Here we use $\\mathbf{w}$ and $\\mathbf{y}$ interchangeably as $\\mathbf{w} = \\exp(\\mathbf{y})$ or each component is a one-to-one mapping.  Note that since the ${\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ given $\\mathbf{y}^{(k-1)}$ is achievable, $\\Phi(\\cdot)$ is a well defined point-to-set map for $\\mathbf{w}\\in{\\mathbb{R}}_{+}^D$. \n\nSpecifically, in our case given $\\mathbf{w}^{(k-1)}$, at each iteration of Eq.~\\ref{equ:update} we have \n\n", "itemtype": "equation", "pos": 42869, "prevtext": "\nWe can then replace $w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})$ in the above equation by the expression it is equal to in Eq.~\\ref{equ:ne} to obtain a closed form solution: \n\n", "index": 33, "text": "\\begin{equation}\n\\label{equ:update}\nw'_{ij} \\propto w_{ij}^{(k-1)}\\frac{f_{v_j}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"w^{\\prime}_{ij}\\propto w_{ij}^{(k-1)}\\frac{f_{v_{j}}(\\mathbf{x}|\\mathbf{w}^{(k%&#10;-1)})}{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{\\partial f_{%&#10;\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_{i}}(\\mathbf{x}|%&#10;\\mathbf{w}^{(k-1)})}\" display=\"block\"><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2032</mo></msubsup><mo>\u221d</mo><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mfrac><mrow><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\ni.e., the point-to-set mapping is given by\n\n", "itemtype": "equation", "pos": 64849, "prevtext": "\n\n\n\n\n\n\n\n\nEq.~\\ref{equ:update} also suggests that in order to obtain a solution to Eq.~\\ref{equ:ne}, for each edge weight $w_{ij}$, the sufficient statistics include only three terms, i.e, the evaluation value at $v_j$, the differentiation value at $v_i$ and the previous edge weight $w_{ij}^{(k-1)}$, all of which can be obtained in two passes of the network for each input $\\mathbf{x}$ as illustrated in Fig.~\\ref{fig:update}. Thus the computational complexity to obtain a maximum of the concave surrogate is $O(|\\mathcal{S}|)$. Interestingly, Eq.~\\ref{equ:update} leads to the same update formula as in the EM algorithm~\\citep{peharz2015foundations} despite the fact that CCCP and EM start from different perspectives. \n\nWe discussed before that the sequence of function values $\\{f(\\mathbf{y}^{(k)})\\}$ converges to a limiting point. However, this fact alone does not necessarily indicate that $\\{f(\\mathbf{y}^{(k)})\\}$ converges to $f(\\mathbf{y}^*)$ where $\\mathbf{y}^*$ is a stationary point of $f(\\cdot)$ nor does it imply that the sequence $\\{\\mathbf{y}^{(k)}\\}$ converges as $k\\rightarrow\\infty$. \\emph{Zangwill's global convergence theory}~\\citep{zangwill1969nonlinear} has been successfully applied to study the convergence properties of many iterative algorithms frequently used in machine learning, including EM~\\citep{wu1983convergence}, generalized alternating minimization~\\citep{gunawardana2005convergence} and also CCCP~\\citep{lanckriet2009convergence}. Here we also apply Zangwill's theory and combine the analysis from \\cite{lanckriet2009convergence} to show the following theorem:\n\\begin{restatable}{theorem}{thmb}\n\\label{thm:convergence}\nLet $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$ be any sequence generated using Eq.~\\ref{equ:update} from any positive initial point, then all the limiting points of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$ are stationary points of the DCP in (\\ref{equ:cccp}). In addition, $\\lim_{k\\rightarrow\\infty}f(\\mathbf{y}^{(k)}) = f(\\mathbf{y}^*)$, where $\\mathbf{y}^*$ is some stationary point of (\\ref{equ:cccp}).\n\\end{restatable}\nWe delay the proof of this theorem to appendix. It is worth to point out that the above theorem \\emph{does not} imply the convergence of the sequence $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$. Thm.~\\ref{thm:convergence} only indicates that all the limiting points of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, i.e., the limits of subsequences of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, are stationary points of the DCP in (\\ref{equ:cccp}). We also present a negative example in the appendix that invalidates the application of Zangwill's global convergence theory on the analysis in this case.\n\nThe convergence rate of general CCCP is still an open problem~\\citep{lanckriet2009convergence}. \\cite{salakhutdinov2002convergence} studied the convergence rate of unconstrained bound optimization algorithms with differentiable objective functions, of which our problem is a special case. The conclusion is that depending on the curvature of $f_1$ and $f_2$ (which are functions of the training data), CCCP will exhibit either a quasi-Newton behavior with superlinear convergence or first-order convergence. We show in experiments that CCCP normally exhibits a fast, superlinear convergence rate compared with PGD, EG and SMA. Both CCCP and EM are special cases of a more general framework known as Majorization-Maximization~\\cite{hunter2004tutorial}. We show that in the case of SPNs these two algorithms coincide with each other, i.e., they lead to the same update formulas despite the fact that they start from totally different perspectives. We refer interested readers to the appendix for a detailed derivation and discussion. We summarize all 4 algorithms and highlight their connections and differences in Table~\\ref{table:summary}.\n\\begin{table*}[htb]\n\\centering\n\\small\n\\caption{Summary of PGD, EG, SMA and CCCP. Var. means the optimization variables.}\n\\label{table:summary}\n\\begin{tabular}{|l|l|l|l|l|}\\hline\n\\textbf{Algo} & \\textbf{Var.} & \\textbf{Update Type} & \\textbf{Approx. Type} & \\textbf{Update Formula}\\\\\\hline\nPGD & $\\mathbf{w}$ & Additive & Linearization  & $w_d^{(k+1)}\\leftarrow P_{{\\mathbb{R}}_{++}^\\epsilon}\\left\\lbrace w_d^{(k)} + \\gamma(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\right\\rbrace$ \\\\\\hline\nEG & $\\mathbf{w}$ & Multiplicative & Linearization & $w_d^{(k+1)}\\leftarrow w_d^{(k)}\\exp\\{\\gamma(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\}$ \\\\\\hline\nSMA & $\\log\\mathbf{w}$ & Multiplicative & Monomial & $w_d^{(k+1)}\\leftarrow w_d^{(k)}\\exp\\{\\gamma w_d^{(k)}\\times(\\nabla_{w_d}f_1(\\mathbf{w}^{(k)}) - \\nabla_{w_d}f_2(\\mathbf{w}^{(k)}))\\}$ \\\\\\hline\nCCCP & $\\log\\mathbf{w}$ & Multiplicative & Log-sum-exp+Affine & $w_{ij}^{(k+1)}\\propto w_{ij}^{(k)}\\times\\nabla_{v_i}f_{\\mathcal{S}}(\\mathbf{w}^{(k)})\\times f_{v_j}(\\mathbf{w}^{(k)})$\\\\\\hline\n\\end{tabular}\n\\end{table*}\n\\section{Experiments}\n\\subsection{Experimental Setting}\nWe conduct experiments on 20 benchmark data sets from various domains to compare and evaluate the convergence performance of the four algorithms: PGD, EG, SMA and CCCP. These 20 data sets are widely used in~\\citep{gens2013learning,rooshenas2014learning} to assess different SPNs for the task of density estimation. The domain of these 20 data sets include click-through logs, plant habitats, nucleic acid sequences, text documents, movie rates and many others. All the features in the 20 data sets are binary features. The 20 data sets cover three typical statistical estimation settings where the number of training instances is either greater, similar or much smaller than the number of optimization variables. Hence, they enable a thorough experimental comparison to test these 4 algorithms under different applications and statistical scenarios. Detailed information about these 20 datasets and the SPNs used in the experiments are provided in Table.~\\ref{table:statistics} and Table.~\\ref{table:sizes}. All the SPNs that are used for comparisons of PGD, EG, SMA and EM are trained using LearnSPN~\\citep{gens2013learning}. We discard the weights returned by LearnSPN and use random weights as initial model parameters. The random weights are determined by the same random seed in all four algorithms.\n\\begin{table*}[htb]\n\\centering\n\\caption{Statistics of data sets and models. $N$ is the number of variables modeled by the network, $|\\mathcal{S}|$ is the size of the network and $D$ is the number of parameters to be estimated in the network. $N \\times V/D$ means the ratio of training instances times the number of variables to the number parameters.}\n\\label{table:statistics}\n\\begin{tabular}{|l||r|r|r|r|r|r|r|}\\hline\n\\textbf{Data set} & $N$ & $|\\mathcal{S}|$ & $D$ & Train & Valid & Test & $N\\times V/D$ \\\\\\hline\nNLTCS & 16 & 13,733 & 1,716 & 16,181 & 2,157 & 3,236 & 150.871 \\\\ \nMSNBC & 17 & 54,839 & 24,452 & 291,326 & 38,843 & 58,265 & 202.541\\\\\nKDD 2k & 64 & 48,279 & 14,292 & 180,092 & 19,907 & 34,955 & 806.457\\\\\nPlants & 69 & 132,959 & 58,853 &17,412 & 2,321 & 3,482 & 20.414\\\\\nAudio & 100 & 739,525 & 196,103 & 15,000 & 2,000 & 3,000 & 7.649\\\\\nJester & 100 & 314,013 & 180,750 & 9,000 & 1,000 & 4,116 & 4.979 \\\\\nNetflix & 100 & 161,655 & 51,601 & 15,000 & 2,000 & 3,000 & 29.069\\\\\nAccidents & 111 & 204,501 & 74,804 & 12,758 & 1,700 & 2,551 & 18.931\\\\\nRetail & 135 & 56,931 & 22,113 & 22,041 & 2,938 & 4,408 & 134.560\\\\\nPumsb-star & 163 & 140,339 & 63,173 & 12,262 & 1,635 & 2,452 & 31.638\\\\\nDNA & 180 & 108,021 & 52,121 & 1,600 & 400 & 1,186 & 5.526\\\\\nKosarak & 190 & 203,321 & 53,204 & 33,375 & 4,450 & 6,675 & 119.187\\\\\nMSWeb & 294 & 68,853 & 20,346 & 29,441 & 3,270 & 5,000 & 425.423 \\\\\nBook & 500 & 190,625 & 41,122 & 8,700 & 1,159 & 1,739 & 105.783\\\\\nEachMovie & 500 & 522,753 & 188,387 & 4,524 & 1,002 & 591 & 12.007\\\\\nWebKB & 839 & 1,439,751 & 879,893 & 2,803 & 558 & 838 & 2.673\\\\\nReuters-52 & 889 & 2,210,325 & 1,453,390 & 6,532 & 1,028 & 1,540 & 3.995\\\\\n20 Newsgrp & 910 & 14,561,965 & 8,295,407 & 11,293 & 3,764 & 3,764 & 1.239 \\\\\nBBC & 1058 & 1,879,921 & 1,222,536 & 1,670 & 225 & 330 & 1.445\\\\\nAd & 1556 & 4,133,421 & 1,380,676 & 2,461 & 327 & 491 & 2.774 \\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Parameter Learning}\nWe implement all four algorithms in C++ and test them on a compute server with 32 cores. Each core is Intel Xeon(R) CPU E5 2.00GHz. For each algorithm, we set the maximum number of iterations to 50. If the absolute difference in the training log-likelihood at two consecutive steps is less than $0.001$, the algorithms are stopped. We combine PGD, EG and SMA with backtracking line search and use a weight shrinking coefficient set at $0.8$. The learning rates are initialized to $1.0$ for all three methods. For PGD, we set the projection margin $\\epsilon$ to 0.01. There is no learning rate and no backtracking line search in CCCP. We set the smoothing parameter to $0.001$ in CCCP to avoid numerical issues. \n\nWe show in Fig.~\\ref{fig:lld} the average log-likelihood scores on 20 training data sets to evaluate the convergence speed and stability of PGD, EG, SMA and CCCP. Clearly, CCCP wins by a large margin over PGD, EG and SMA, both in convergence speed and solution quality. Furthermore, among the four algorithms, CCCP is the most stable one due to its guarantee that the log-likelihood (on training data) will not decrease after each iteration. These 20 experiments also clearly show that CCCP often converges in a few iterations, exhibiting a superlinear convergence speed. On the other hand, PGD, EG and SMA are on par with each other since they are all first-order methods. SMA is more stable than PGD and EG and often achieves better solutions than PGD and EG. On large data sets, SMA also converges faster than PGD and EG. Surprisingly, EG performs worse than PGD in some cases and is quite unstable despite the fact that it admits multiplicative updates. The ``hook shape'' curves of PGD in some data sets are due to the projection operations, which makes PGD the most unstable one among the four algorithms. The computational complexity per update is $O(|\\mathcal{S}|)$ in all four algorithms. The constant involved in the $|\\mathcal{S}|$ term of CCCP is slightly larger than those of the other three algorithms as there are more $\\exp(\\cdot)$ calls in CCCP. However, in practice, CCCP often takes less time than the other three algorithms because it takes fewer iterations to converge. We list detailed running time statistics for all four algorithms on the 20 data sets in Table.~\\ref{table:time}.\n\n\\begin{figure*}[htb]\n\\centering\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{nltcs.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{msnbc.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{kdd.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{plants.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{baudio.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{jester.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{bnetflix.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{accidents.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{tretail.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{pumsb_star.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{dna.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{kosarek.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{msweb.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{book.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{tmovie.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{cwebkb.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{cr52.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{c20ng.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{bbc.pdf}\n\\end{subfigure}\n~\n\\begin{subfigure}[b]{0.23\\textwidth}\n    \\includegraphics[width=\\textwidth]{ad.pdf}\n\\end{subfigure}\n\\caption{Negative log-likelihood values on training data versus number of iterations for PGD, EG, SMA and CCCP.}\n\\label{fig:lld}\n\\end{figure*}\n\n\\begin{table*}[htb]\n\\centering\n\\caption{Running time of 4 algorithms on 20 data sets, measured in seconds.}\n\\label{table:time}\n\\begin{tabular}{|l|r|r|r|r|}\\hline\n\\textbf{Data set} & PGD & EG & SMA & CCCP\\\\\\hline\nNLTCS & 438.35 & 718.98 & 458.99 & 206.10 \\\\\nMSNBC & 2720.73 & 2917.72 & 8078.41 & 2008.07 \\\\\nKDD 2k & 46388.60 & 22154.10 & 27101.50 & 29541.20 \\\\\nPlants & 12595.60 & 10752.10 & 7604.09 & 13049.80 \\\\\nAudio & 19647.90 & 3430.69 & 12801.70 & 14307.30 \\\\\nJester & 6099.44 & 6272.80 &  4082.65 & 1931.41 \\\\\nNetflix & 29573.10 & 27931.50 & 15080.50 &  8400.20 \\\\\nAccidents & 14266.50 & 3431.82 & 5776.00 & 20345.90 \\\\\nRetail & 28669.50 & 7729.89 & 9866.94 & 5200.20 \\\\\nPumsb-star & 3115.58 & 13872.80 & 4864.72 & 2377.54 \\\\\nDNA & 599.93 & 199.63 & 727.56 & 1380.36 \\\\\nKosarak & 122204.00 & 112273.00 & 49120.50 & 42809.30 \\\\\nMSWeb & 136524.00 & 13478.10 & 65221.20 & 45132.30 \\\\\nBook & 190398.00 & 6487.84 & 69730.50 & 23076.40 \\\\\nEachMovie & 30071.60 & 32793.60 & 17751.10 & 60184.00 \\\\\nWebKB & 123088.00 & 50290.90 & 44004.50 & 168142.00 \\\\\nReuters-52 & 13092.10 & 5438.35 & 20603.70 & 1194.31 \\\\\n20 Newsgrp & 151243.00 & 96025.80 & 173921.00 & 11031.80 \\\\\nBBC & 20920.60 & 18065.00 & 36952.20 & 3440.37 \\\\\nAd & 12246.40 & 2183.08 & 12346.70 & 731.48\\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Boosting Structure Learning}\nIn this experiment, we combine CCCP as a ``fine tuning'' procedure with the structure learning algorithm LearnSPN and compare it to the state-of-the-art structure learning algorithm ID-SPN~\\citep{rooshenas2014learning}. More concretely, we keep the model parameters learned from LearnSPN and use them to initialize CCCP. We then update the model parameters globally using CCCP as a fine tuning technique. This normally helps to obtain a better generative model since the original parameters are learned greedily and locally during the structure learning algorithm. The final CCCP procedure adjusts all the parameters globally toward a better solution. In this experiment, we use the validation set log-likelihood score to avoid overfitting. The algorithm returns the set of parameters that achieve the best validation set log-likelihood score as output. Experimental results are reported in Table.~\\ref{table:log-likelihood}.\n\nAs shown in Table~\\ref{table:log-likelihood}, the use of CCCP after LearnSPN always helps to improve the model performance. By optimizing model parameters on these 20 data sets, we boost LearnSPN to achieve better results than state-of-the-art ID-SPN on 7 data sets, where the original LearnSPN only outperforms ID-SPN on 1 data set. Note that the sizes of the SPNs returned by LearnSPN are much smaller than those produced by ID-SPNs. Hence, it is remarkable that by fine tuning the parameters with CCCP, we can achieve better performance despite the fact that the models are smaller.  For a fair comparison, we also list the size of the SPNs returned by ID-SPN in Table.~\\ref{table:sizes}. As a result, we suggest using CCCP after structure learning algorithms to fully exploit the expressiveness of the constructed model.\n\n\\begin{table}[htb]\n\\begin{minipage}[b]{0.6\\textwidth}\n\\centering\n\\caption{Average log-likelihoods on test data. Highest average log-likelihoods are highlighted in bold.}\n\\label{table:log-likelihood}\n\\begin{tabular}{|l||r|r|r|}\\hline\n\\textbf{Data set} & CCCP & LearnSPN & ID-SPN \\\\\\hline\nNLTCS & \\textbf{-6.029} & -6.099 & -6.050  \\\\\nMSNBC & \\textbf{-6.045} & -6.113 & -6.048 \\\\\nKDD 2k & \\textbf{-2.134} & -2.233 & -2.153 \\\\\nPlants & -12.872 & -12.955 & \\textbf{-12.554} \\\\\nAudio & -40.020 & -40.510 & \\textbf{-39.824} \\\\\nJester & \\textbf{-52.880} & -53.454 & -52.912 \\\\\nNetflix & -56.782 & -57.385 & \\textbf{-56.554} \\\\\nAccidents & -27.700 & -29.907 & \\textbf{-27.232} \\\\\nRetail & \\textbf{-10.919} & -11.138 & -10.945 \\\\\nPumsb-star & -24.229 & -24.577 & \\textbf{-22.552} \\\\\nDNA & -84.921 & -85.237 & \\textbf{-84.693} \\\\\nKosarak & -10.880 & -11.057 & \\textbf{-10.605} \\\\\nMSWeb & -9.970 & -10.269 & \\textbf{-9.800} \\\\\nBook & -35.009 & -36.247 & \\textbf{-34.436} \\\\\nEachMovie & -52.557 & -52.816 & \\textbf{-51.550} \\\\\nWebKB & -157.492 & -158.542 & \\textbf{-153.293} \\\\\nReuters-52 & -84.628 & -85.979 & \\textbf{-84.389} \\\\\n20 Newsgrp & -153.205 & -156.605 & \\textbf{-151.666} \\\\\nBBC & \\textbf{-248.602} & -249.794 & -252.602\\\\\nAd & \\textbf{-27.202} & -27.409 & -40.012 \\\\\\hline\n\\end{tabular}\n\\end{minipage}\n\\begin{minipage}[b]{0.4\\textwidth}\n\\caption{Sizes of SPNs produced by LearnSPN and ID-SPN.}\n\\label{table:sizes}\n\\begin{tabular}{|l||r|r|}\\hline\n\\textbf{Data set} & LearnSPN & ID-SPN \\\\\\hline\nNLTCS & 13,733 & 24,690 \\\\\nMSNBC & 54,839 & 579,364 \\\\\nKDD 2k & 48,279 & 1,286,657 \\\\\nPlants & 132,959 & 2,063,708 \\\\\nAudio & 739,525 & 2,643,948\\\\\nJester & 314,013 & 4,225,471 \\\\\nNetflix & 161,655 & 7,958,088 \\\\\nAccidents & 204,501 & 2,273,186\\\\\nRetail & 56,931 & 60,961 \\\\\nPumsb-star & 140,339 & 1,751,092\\\\\nDNA & 108,021 & 3,228,616\\\\\nKosarak &  203,321 & 1,272,981\\\\\nMSWeb & 68,853 & 1,886,777\\\\\nBook & 190,625 & 1,445,501\\\\\nEachMovie & 522,753 & 2,440,864\\\\\nWebKB & 1,439,751 & 2,605,141 \\\\\nReuters-52 & 2,210,325 & 4,563,861 \\\\\n20 Newsgrp & 14,561,965 & 3,485,029\\\\\nBBC & 1,879,921 & 2,426,602\\\\\nAd & 4,133,421 & 2,087,253\\\\\\hline\n\\end{tabular}\n\\end{minipage}\n\\end{table}\n\n\\section{Conclusion}\nIn this paper we show that the network polynomial of an SPN is a posynomial function of the model parameters and that learning the parameter by maximum likelihood yields a signomial program. We propose two convex relaxations to solve the SP based on sequential monomial approximations and the concave-convex procedure. We analyze the convergence properties of CCCP for learning SPNs. Extensive experiments are conducted to evaluate the proposed approaches and current methods. \n\n\\newpage\n\\bibliography{reference}\n\\bibliographystyle{abbrvnat}\n\n\\begin{appendices}\n\\section{Convergence of CCCP for SPNs}\n\\thmb*\n\\begin{proof}\nWe will use Zangwill's global convergence theory for iterative algorithms~\\citep{zangwill1969nonlinear} to show the convergence in our case. Before showing the proof, we need to first introduce the notion of ``point-to-set mapping'', where the output of the mapping is defined to be a set. More formally, a point-to-set map $\\Phi$ from a set $\\mathcal{X}$ to $\\mathcal{Y}$ is defined as $\\Phi:\\mathcal{X}\\mapsto\\mathcal{P}(\\mathcal{Y})$, where $\\mathcal{P}(\\mathcal{Y})$ is the power set of $\\mathcal{Y}$. Suppose $\\mathcal{X}$ and $\\mathcal{Y}$ are equipped with the norm $||\\cdot||_\\mathcal{X}$ and $||\\cdot||_\\mathcal{Y}$, respectively. A point-to-set map $\\Phi$ is said to be \\emph{closed} at $x^*\\in\\mathcal{X}$ if $x_k\\in\\mathcal{X}$, $\\{x_k\\}_{k=1}^\\infty\\rightarrow x^*$ and $y_k\\in\\mathcal{Y}, \\{y_k\\}_{k=1}^\\infty\\rightarrow y^*, y_k\\in\\Phi(x_k)$ imply that $y^*\\in\\Phi(x^*)$. A point-to-set map $\\Phi$ is said to be closed on $S\\subseteq\\mathcal{X}$ if $\\Phi$ is closed at every point in $S$. The concept of \\emph{closedness} in the point-to-set map setting reduces to \\emph{continuity} if we restrict that the output of $\\Phi$ to be a set of singleton for every possible input, i.e., when $\\Phi$ is a point-to-point mapping. \n\\begin{theorem}[Global Convergence Theorem~\\citep{zangwill1969nonlinear}]\nLet the sequence $\\{x_k\\}_{k=1}^\\infty$ be generated by $x_{k+1}\\in\\Phi(x_k)$, where $\\Phi(\\cdot)$ is a point-to-set map from $\\mathcal{X}$ to $\\mathcal{X}$. Let a solution set $\\Gamma\\subseteq\\mathcal{X}$ be given, and suppose that:\n\\begin{enumerate}\n\t\\item \tall points $x_k$ are contained in a compact set $S\\subseteq \\mathcal{X}$.\n\t\\item \t$\\Phi$ is closed over the complement of $\\Gamma$.\n\t\\item \tthere is a continuous function $\\alpha$ on $\\mathcal{X}$ such that:\n\t\\begin{enumerate}\n\t\t\\item \tif $x\\not\\in\\Gamma$, $\\alpha(x') > \\alpha(x)$ for $\\forall x'\\in\\Phi(x)$.\n\t\t\\item \tif $x\\in\\Gamma, \\alpha(x')\\geq \\alpha(x)$ for $\\forall x'\\in\\Phi(x)$.\n\t\\end{enumerate}\t \n\\end{enumerate}\nThen all the limit points of $\\{x_k\\}_{k=1}^\\infty$ are in the solution set $\\Gamma$ and $\\alpha(x_k)$ converges monotonically to $\\alpha(x^*)$ for some $x^*\\in\\Gamma$.\n\\end{theorem}\nLet $\\mathbf{w}\\in{\\mathbb{R}}_{+}^D$. Let $\\Phi(\\mathbf{w}^{(k-1)}) = \\exp( {\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)}))$ and let $\\alpha(\\mathbf{w}) = f(\\log\\mathbf{w}) = f(\\mathbf{y}) = \\log f_\\mathcal{S}(\\mathbf{x}|\\exp(\\mathbf{y})) - \\log f_\\mathcal{S}(\\mathbf{1}|\\exp(\\mathbf{y}))$. Here we use $\\mathbf{w}$ and $\\mathbf{y}$ interchangeably as $\\mathbf{w} = \\exp(\\mathbf{y})$ or each component is a one-to-one mapping.  Note that since the ${\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ given $\\mathbf{y}^{(k-1)}$ is achievable, $\\Phi(\\cdot)$ is a well defined point-to-set map for $\\mathbf{w}\\in{\\mathbb{R}}_{+}^D$. \n\nSpecifically, in our case given $\\mathbf{w}^{(k-1)}$, at each iteration of Eq.~\\ref{equ:update} we have \n\n", "index": 35, "text": "$$w'_{ij} = \\frac{w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})}{\\sum_j w_{ij}f_{v_j}(\\mathbf{1}|\\mathbf{w})}\\propto w_{ij}^{(k-1)} \\frac{f_{v_j}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"w^{\\prime}_{ij}=\\frac{w_{ij}f_{v_{j}}(\\mathbf{1}|\\mathbf{w})}{\\sum_{j}w_{ij}f_%&#10;{v_{j}}(\\mathbf{1}|\\mathbf{w})}\\propto w_{ij}^{(k-1)}\\frac{f_{v_{j}}(\\mathbf{x%&#10;}|\\mathbf{w}^{(k-1)})}{f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}\\frac{%&#10;\\partial f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_{i}}(%&#10;\\mathbf{x}|\\mathbf{w}^{(k-1)})}\" display=\"block\"><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mo>\u2032</mo></msubsup><mo>=</mo><mfrac><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mi>j</mi></msub><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mn>\ud835\udfcf</mn><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u221d</mo><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mfrac><mrow><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nLet $S = [0,1]^D$, the $D$ dimensional hyper cube. Then the above update formula indicates that $\\Phi(\\mathbf{w}^{(k-1)})\\in S$. Furthermore, if we assume $\\mathbf{w}^{(1)}\\in S$, which can be obtained by local normalization before any update, we can guarantee that $\\{\\mathbf{w}_k\\}_{k=1}^\\infty\\subseteq S$, which is a compact set in ${\\mathbb{R}}_+^D$. \n\nThe solution to $\\max_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ is not unique. In fact, there are infinitely many solutions to this nonlinear equations. However, as we define above, $\\Phi(\\mathbf{w}^{(k-1)})$ returns \\emph{one} solution to this convex program in the $D$ dimensional hyper cube. Hence in our case $\\Phi(\\cdot)$ reduces to a point-to-point map, where the definition of \\emph{closedness} of a point-to-set map reduces to the notion of \\emph{continuity} of a point-to-point map. Define $\\Gamma = \\{\\mathbf{w}^*~|~\\mathbf{w}^* \\text{ is a stationary point of }\\alpha(\\cdot)\\}$. Hence we only need to verify the continuity of $\\Phi(\\mathbf{w})$ when $\\mathbf{w}\\in S$. To show this, we first characterize the functional form of $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$ as it is used inside $\\Phi(\\cdot)$. We claim that for each node $v_i$, $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$ is again, a posynomial function of $\\mathbf{w}$. A graphical illustration is given in Fig.~\\ref{fig:partial} to explain the process. This can also be derived from the sum rules and product rules used during top-down differentiation. \n\\begin{figure}\n\\centering\n\t\\includegraphics[scale=1.0]{partial.pdf}\n\\caption{Graphical illustration of $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$. The partial derivative of $f_\\mathcal{S}$ with respect to $f_{v_i}$ (in red) is a posynomial that is a product of edge weights lying on the path from root to $v_i$ and network polynomials from nodes that are children of product nodes on the path (highlighted in blue).}\n\\label{fig:partial}\n\\end{figure}\nMore specifically, if $v_i$ is a product node, let $v_j, j=1,\\ldots, J$ be its parents in the network, which are assumed to be sum nodes, the differentiation of $f_\\mathcal{S}$ with respect to $f_{v_i}$ is given by\n$\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})} = \\sum_{j=1}^J \\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}\\frac{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$. We reach\n\n", "itemtype": "equation", "pos": 65219, "prevtext": "\ni.e., the point-to-set mapping is given by\n\n", "index": 37, "text": "\\begin{align*}\n\\Phi_{ij}(\\mathbf{w}^{(k-1)}) = \\frac{w_{ij}^{(k-1)}f_{v_j}(\\mathbf{x}|\\mathbf{w}^{(k-1)})\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}}{\\sum_{j'} w_{ij'}^{(k-1)}f_{v_{j'}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}}\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\Phi_{ij}(\\mathbf{w}^{(k-1)})=\\frac{w_{ij}^{(k-1)}f_{v_{j}}(%&#10;\\mathbf{x}|\\mathbf{w}^{(k-1)})\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{x}|%&#10;\\mathbf{w}^{(k-1)})}{\\partial f_{v_{i}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}}{\\sum_%&#10;{j^{\\prime}}w_{ij^{\\prime}}^{(k-1)}f_{v_{j^{\\prime}}}(\\mathbf{x}|\\mathbf{w}^{(%&#10;k-1)})\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}{\\partial f%&#10;_{v_{i}}(\\mathbf{x}|\\mathbf{w}^{(k-1)})}}\" display=\"inline\"><mrow><mrow><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><msup><mi>j</mi><mo>\u2032</mo></msup></msub><msubsup><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><msup><mi>j</mi><mo>\u2032</mo></msup></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><msub><mi>f</mi><msub><mi>v</mi><msup><mi>j</mi><mo>\u2032</mo></msup></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><msup><mi>\ud835\udc30</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mfrac></mstyle></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nSimilarly, if $v_i$ is a sum node and its parents $v_j, j=1,\\ldots,J$ are assumed to be product nodes, we have\n\n", "itemtype": "equation", "pos": 68250, "prevtext": "\nLet $S = [0,1]^D$, the $D$ dimensional hyper cube. Then the above update formula indicates that $\\Phi(\\mathbf{w}^{(k-1)})\\in S$. Furthermore, if we assume $\\mathbf{w}^{(1)}\\in S$, which can be obtained by local normalization before any update, we can guarantee that $\\{\\mathbf{w}_k\\}_{k=1}^\\infty\\subseteq S$, which is a compact set in ${\\mathbb{R}}_+^D$. \n\nThe solution to $\\max_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$ is not unique. In fact, there are infinitely many solutions to this nonlinear equations. However, as we define above, $\\Phi(\\mathbf{w}^{(k-1)})$ returns \\emph{one} solution to this convex program in the $D$ dimensional hyper cube. Hence in our case $\\Phi(\\cdot)$ reduces to a point-to-point map, where the definition of \\emph{closedness} of a point-to-set map reduces to the notion of \\emph{continuity} of a point-to-point map. Define $\\Gamma = \\{\\mathbf{w}^*~|~\\mathbf{w}^* \\text{ is a stationary point of }\\alpha(\\cdot)\\}$. Hence we only need to verify the continuity of $\\Phi(\\mathbf{w})$ when $\\mathbf{w}\\in S$. To show this, we first characterize the functional form of $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$ as it is used inside $\\Phi(\\cdot)$. We claim that for each node $v_i$, $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$ is again, a posynomial function of $\\mathbf{w}$. A graphical illustration is given in Fig.~\\ref{fig:partial} to explain the process. This can also be derived from the sum rules and product rules used during top-down differentiation. \n\\begin{figure}\n\\centering\n\t\\includegraphics[scale=1.0]{partial.pdf}\n\\caption{Graphical illustration of $\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$. The partial derivative of $f_\\mathcal{S}$ with respect to $f_{v_i}$ (in red) is a posynomial that is a product of edge weights lying on the path from root to $v_i$ and network polynomials from nodes that are children of product nodes on the path (highlighted in blue).}\n\\label{fig:partial}\n\\end{figure}\nMore specifically, if $v_i$ is a product node, let $v_j, j=1,\\ldots, J$ be its parents in the network, which are assumed to be sum nodes, the differentiation of $f_\\mathcal{S}$ with respect to $f_{v_i}$ is given by\n$\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})} = \\sum_{j=1}^J \\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}\\frac{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$. We reach\n\n", "index": 39, "text": "\\begin{equation}\n\\label{equ:prod}\n\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})} = \\sum_{j=1}^J w_{ij}\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_{i}}(%&#10;\\mathbf{x}|\\mathbf{w})}=\\sum_{j=1}^{J}w_{ij}\\frac{\\partial f_{\\mathcal{S}}(%&#10;\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_{j}}(\\mathbf{x}|\\mathbf{w})}\" display=\"block\"><mrow><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mfrac><mrow><mo>\u2202</mo><msub><mi>f</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcae</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo>\u2202</mo><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nSince $v_j$ is a product node and $v_j$ is a parent of $v_i$, so the last term in Eq.~\\ref{equ:sum} can be equivalently expressed as\n\n", "itemtype": "equation", "pos": 68619, "prevtext": "\nSimilarly, if $v_i$ is a sum node and its parents $v_j, j=1,\\ldots,J$ are assumed to be product nodes, we have\n\n", "index": 41, "text": "\\begin{equation}\n\\label{equ:sum}\n\\small\n\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})} = \\sum_{j=1}^J \\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_j}(\\mathbf{x}|\\mathbf{w})}\\frac{f_{v_j}(\\mathbf{x}|\\mathbf{w})}{f_{v_i}(\\mathbf{x}|\\mathbf{w})}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"\\small\\frac{\\partial f_{\\mathcal{S}}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_{i}%&#10;}(\\mathbf{x}|\\mathbf{w})}=\\sum_{j=1}^{J}\\frac{\\partial f_{\\mathcal{S}}(\\mathbf%&#10;{x}|\\mathbf{w})}{\\partial f_{v_{j}}(\\mathbf{x}|\\mathbf{w})}\\frac{f_{v_{j}}(%&#10;\\mathbf{x}|\\mathbf{w})}{f_{v_{i}}(\\mathbf{x}|\\mathbf{w})}\" display=\"block\"><mrow><mfrac><mrow><mo mathsize=\"90%\" stretchy=\"false\">\u2202</mo><msub><mi mathsize=\"90%\">f</mi><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"90%\">\ud835\udcae</mi></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mrow><mo mathsize=\"90%\" stretchy=\"false\">\u2202</mo><msub><mi mathsize=\"90%\">f</mi><msub><mi mathsize=\"90%\">v</mi><mi mathsize=\"90%\">i</mi></msub></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mfrac><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mrow><munderover><mo largeop=\"true\" mathsize=\"90%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathsize=\"90%\">j</mi><mo mathsize=\"90%\" stretchy=\"false\">=</mo><mn mathsize=\"90%\">1</mn></mrow><mi mathsize=\"90%\">J</mi></munderover><mrow><mfrac><mrow><mo mathsize=\"90%\" stretchy=\"false\">\u2202</mo><msub><mi mathsize=\"90%\">f</mi><mi class=\"ltx_font_mathcaligraphic\" mathsize=\"90%\">\ud835\udcae</mi></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mrow><mo mathsize=\"90%\" stretchy=\"false\">\u2202</mo><msub><mi mathsize=\"90%\">f</mi><msub><mi mathsize=\"90%\">v</mi><mi mathsize=\"90%\">j</mi></msub></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><msub><mi mathsize=\"90%\">f</mi><msub><mi mathsize=\"90%\">v</mi><mi mathsize=\"90%\">j</mi></msub></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow><mrow><msub><mi mathsize=\"90%\">f</mi><msub><mi mathsize=\"90%\">v</mi><mi mathsize=\"90%\">i</mi></msub></msub><mrow><mo maxsize=\"90%\" minsize=\"90%\">(</mo><mi mathsize=\"90%\">\ud835\udc31</mi><mo maxsize=\"90%\" minsize=\"90%\">|</mo><mi mathsize=\"90%\">\ud835\udc30</mi><mo maxsize=\"90%\" minsize=\"90%\">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.00318.tex", "nexttext": "\nwhere the index is range from all the children of $v_j$ except $v_i$. Combining the fact that the partial differentiation of $f_\\mathcal{S}$ with respect to the root node is 1 and that each $f_v$ is a posynomial function,  it follows by induction in top-down order that \n$\\frac{\\partial f_\\mathcal{S}(\\mathbf{x}|\\mathbf{w})}{\\partial f_{v_i}(\\mathbf{x}|\\mathbf{w})}$ is also a posynomial function of $\\mathbf{w}$.\n\nWe have shown that both the numerator and the denominator of $\\Phi(\\cdot)$ are posynomial functions of $\\mathbf{w}$. Because posynomial functions are continuous functions, in order to show that $\\Phi(\\cdot)$ is also continuous on $S\\backslash\\Gamma$, we need to guarantee that the denominator is not a degenerate posynomial function, i.e., the denominator of $\\Phi(\\mathbf{w})\\neq 0$ for all possible input vector $\\mathbf{x}$. Recall that $\\Gamma = \\{\\mathbf{w}^*~|~\\mathbf{w}^*\\text{ is a stationary point of }\\alpha(\\cdot)\\}$, hence $\\forall \\mathbf{w}\\in S\\backslash\\Gamma$, $\\mathbf{w}\\not\\in\\text{bd}~S$, where $\\text{bd}~S$ is the boundary of the $D$ dimensional hyper cube $S$. Hence we have $\\forall \\mathbf{w}\\in S\\backslash\\Gamma\\Rightarrow \\mathbf{w}\\in\\text{int}~S\\Rightarrow\\mathbf{w} > 0$ for each component. This immediately leads to $f_v(\\mathbf{x}|\\mathbf{w}) > 0, \\forall v$. As a result, $\\Phi(\\mathbf{w})$ is continuous on $S\\backslash\\Gamma$ since it is the ratio of two strictly positive posynomial functions. \n\nWe now verify the third property in Zangwill's global convergence theory. At each iteration of CCCP, we have the following two cases to consider:\n\\begin{enumerate}\n\t\\item \tIf $\\mathbf{w}^{(k-1)}\\not\\in\\Gamma$, i.e., $\\mathbf{w}^{(k-1)}$ is not a stationary point of $\\alpha(\\mathbf{w})$, then $\\mathbf{y}^{(k-1)}\\not\\in{\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$, so we have $\\alpha(\\mathbf{w}^{(k)}) = f(\\mathbf{y}^{(k)})\\geq \\hat{f}(\\mathbf{y}^{(k)}, \\mathbf{y}^{(k-1)}) > \\hat{f}(\\mathbf{y}^{(k-1)}, \\mathbf{y}^{(k-1)}) = f(\\mathbf{y}^{(k-1)}) = \\alpha(\\mathbf{w}^{(k-1)})$, where the first inequality and the third equality comes from (\\ref{equ:properties}).\n\t\\item \tIf $\\mathbf{w}^{(k-1)}\\in\\Gamma$, i.e., $\\mathbf{w}^{(k-1)}$ is a stationary point of $\\alpha(\\mathbf{w})$, then $\\mathbf{y}^{(k-1)}\\in{\\operatorname{arg\\,max}}_{\\mathbf{y}}\\hat{f}(\\mathbf{y}, \\mathbf{y}^{(k-1)})$, so we have  $\\alpha(\\mathbf{w}^{(k)}) = f(\\mathbf{y}^{(k)})\\geq \\hat{f}(\\mathbf{y}^{(k)}, \\mathbf{y}^{(k-1)}) = \\hat{f}(\\mathbf{y}^{(k-1)}, \\mathbf{y}^{(k-1)}) = f(\\mathbf{y}^{(k-1)}) = \\alpha(\\mathbf{w}^{(k-1)})$.\n\\end{enumerate}\n\nBy Zangwill's global convergence theory, we now conclude that all the limit points of $\\{\\mathbf{w}_k\\}_{k=1}^\\infty$ are in $\\Gamma$ and $\\alpha(\\mathbf{w}_k)$ converges monotonically to $\\alpha(\\mathbf{w}^*)$ for some stationary point $\\mathbf{w}^*\\in\\Gamma$.\n\\end{proof}\n\\begin{remark}\nTechnically we need to choose $\\mathbf{w}_0\\in \\text{int }S$ to ensure the continuity of $\\Phi(\\cdot)$. This initial condition combined with the fact that inside each iteration of CCCP the algorithm only applies positive multiplicative update and renormalization, ensure that after any finite  $k$ steps, $\\mathbf{w}_k\\in\\text{int} S$. Theoretically, only in the limit it is possible that some components of $\\mathbf{w}_\\infty$ may become 0. However in practice, due to the numerical precision of float numbers on computers, it is possible that after some finite update steps some of the components in $\\mathbf{w}_k$ become 0. So in practical implementation we recommend to use a small positive number $\\epsilon$ to smooth out such 0 components in $\\mathbf{w}_k$ during the iterations of CCCP. Such smoothing may hurt the monotonic property of CCCP, but this can only happens when $\\mathbf{w}_k$ is close to $\\mathbf{w}^*$ and we can use early stopping to obtain a solution in the interior of $S$.\n\\end{remark}\n\\begin{remark}\nThm.~\\ref{thm:convergence} only implies that any limiting point of the sequence $\\{\\mathbf{w}_k\\}_{k=1}^\\infty (\\{\\mathbf{y}_k\\}_{k=1}^\\infty)$ must be a stationary point of the log-likelihood function and $\\{f(\\mathbf{y})_k\\}_{k=1}^\\infty$ must converge to some $f(\\mathbf{y}^*)$ where $\\mathbf{y}^*$ is a stationary point. Thm.~\\ref{thm:convergence} does not imply that the sequence $\\{\\mathbf{w}_k\\}_{k=1}^\\infty (\\{\\mathbf{y}_k\\}_{k=1}^\\infty)$ is guaranteed to converge. \\cite{lanckriet2009convergence} studies the convergence property of general CCCP procedure. Under more strong conditions, i.e., the strict concavity of the surrogate function or that $\\Phi()$ to be a contraction mapping, it is possible to show that the sequence $\\{\\mathbf{w}_k\\}_{k=1}^\\infty (\\{\\mathbf{y}_k\\}_{k=1}^\\infty)$ also converges. However, none of such conditions hold in our case. In fact, in general there are infinitely many fixed points of $\\Phi(\\cdot)$, i.e., the equation $\\Phi(\\mathbf{w}) = \\mathbf{w}$ has infinitely many solutions in $S$. Also, for a fixed value $t$, if $\\alpha(\\mathbf{w}) = t$ has at least one solution, then there are infinitely many solutions. Such properties of SPNs make it generally very hard to guarantee the convergence of the sequence $\\{\\mathbf{w}_k\\}_{k=1}^\\infty (\\{\\mathbf{y}_k\\}_{k=1}^\\infty)$. We give a very simple example below to illustrate the hardness in SPNs in Fig.~\\ref{fig:counter}. \n\\begin{figure}\n\\centering\n\t\\includegraphics[scale=1.0]{example.pdf}\n\\caption{A counterexample of SPN over two binary random variables where the weights $w_1, w_2, w_3$ are symmetric and indistinguishable.}\n\\label{fig:counter}\n\\end{figure}\nConsider applying the CCCP procedure to learn the parameters on the SPN given in Fig.~\\ref{fig:counter} with three instances $\\{(0, 1), (1, 0), (1, 1)\\}$. Then if we choose the initial parameter $\\mathbf{w}_0$ such that the weights over the indicator variables are set as shown in Fig.~\\ref{fig:counter}, then any assignment of $(w_1, w_2, w_3)$ in the probability simplex will be equally optimal in terms of likelihood on inputs. In this example, there are uncountably infinite equal solutions, which invalidates the finite solution set requirement given in~\\citep{lanckriet2009convergence} in order to show the convergence of $\\{\\mathbf{w}_k\\}_{k=1}^\\infty$. However, we emphasize that the convergence of the sequence $\\{\\mathbf{w}_k\\}_{k=1}^\\infty$ is not as important as the convergence of $\\{\\alpha(\\mathbf{w})_k\\}_{k=1}^\\infty$ to desired locations on the log-likelihood surface as in practice any $\\mathbf{w}^*$ with equally good log-likelihood may suffice for the inference/prediction task. \n\\end{remark}\n\nIt is worth to point out that the above theorem \\emph{does not} imply the convergence of the sequence $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$. Thm.~\\ref{thm:convergence} only indicates that all the limiting points of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, i.e., the limits of subsequences of $\\{\\mathbf{w}^{(k)}\\}_{k=1}^\\infty$, are stationary points of the DCP in (\\ref{equ:cccp}). We also present a negative example in Fig.~\\ref{fig:counter} that invalidates the application of Zangwill's global convergence theory on the analysis in this case.\n\nThe convergence rate of general CCCP is still an open problem~\\citep{lanckriet2009convergence}. \\cite{salakhutdinov2002convergence} studied the convergence rate of unconstrained bound optimization algorithms with differentiable objective functions, of which our problem is a special case. The conclusion is that depending on the curvature of $f_1$ and $f_2$ (which are functions of the training data), CCCP will exhibit either a quasi-Newton behavior with superlinear convergence or first-order convergence. We show in experiments that CCCP normally exhibits a fast, superlinear convergence rate compared with PGD, EG and SMA. Both CCCP and EM are special cases of a more general framework known as Majorization-Maximization~\\citep{hunter2004tutorial}. We show that in the case of SPNs these two algorithms coincide with each other, i.e., they lead to the same update formulas despite the fact that they start from totally different perspectives.\n\n\\end{appendices}\n\n", "itemtype": "equation", "pos": 69079, "prevtext": "\nSince $v_j$ is a product node and $v_j$ is a parent of $v_i$, so the last term in Eq.~\\ref{equ:sum} can be equivalently expressed as\n\n", "index": 43, "text": "$$\n\\frac{f_{v_j}(\\mathbf{x}|\\mathbf{w})}{f_{v_i}(\\mathbf{x}|\\mathbf{w})} = \\prod_{h\\neq i}f_{v_h}(\\mathbf{x}|\\mathbf{w})\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\frac{f_{v_{j}}(\\mathbf{x}|\\mathbf{w})}{f_{v_{i}}(\\mathbf{x}|\\mathbf{w})}=%&#10;\\prod_{h\\neq i}f_{v_{h}}(\\mathbf{x}|\\mathbf{w})\" display=\"block\"><mrow><mfrac><mrow><msub><mi>f</mi><msub><mi>v</mi><mi>j</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>f</mi><msub><mi>v</mi><mi>i</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>h</mi><mo>\u2260</mo><mi>i</mi></mrow></munder><msub><mi>f</mi><msub><mi>v</mi><mi>h</mi></msub></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc31</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc30</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}]