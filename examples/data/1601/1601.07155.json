[{"file": "1601.07155.tex", "nexttext": "\nwith the topological charge density $q(x)$ defined through the Wilson flow.\n\nThe signal-to-noise problem present at large distances in the $\\langle\nq(x)q(y)\\rangle$ correlation function translates into a lack of volume\naveraging of $\\chi_\\mathrm{top}$: the statistical error of the susceptibility\nfrom a given number of configurations does not improve with increasing volume.\nIn pure gauge theory this can be partially overcome with large statistics, but in practice, \nrather small lattices are still used and the finite size effect needs to\nbe carefully controlled~\\cite{Ce:2015qha}. In large volume, it is therefore \nbeneficial to study the dependence of $\\langle q(x) q(y) \\rangle$  on $|x-y|$ \ndirectly and model the large distance behavior~\\cite{Bazavov:2010xr} or integrate \nit such that the contribution of the tail can be neglected~\\cite{Bruno:2014ova} \ngiven the statistical accuracy. \n\nOn a related note, we also point out that it has been suggested to extract the masses of glueballs from\nthe large distance behavior of two-point functions of the  smoothed topological \ncharge and energy density~\\cite{Chowdhury:2014kfa}. For this \napproach to work, it is highly beneficial to have a precise determination of the \ntail of the correlator at large distances.\n\nOne way to deal with the signal-to-noise problem is to use multi-level algorithms \nwhich rely on the locality of the observable and of the action~\\cite{Luscher:2001up}.\nIf it is possible to decompose the observables in contributions from different\nparts of the lattice, each of them can be updated independently.  Depending on the number\nof sub-lattices and the efficiency of the decomposition, the signal-to-noise problem\ncan be eliminated or at least reduced substantially. Recently, such type of algorithms \nhave also been adapted to the case of quenched lattice QCD to compute fermionic \ncorrelators~\\cite{Ce:2016idq}. \n\nIn the case of flow observables, multi-level algorithms can not be applied directly \nbasically due to the fact that the flow has a footprint which is not finite. In this \npaper we propose a first step in the direction of solving this problem. We study a two-level \nalgorithm where the lattice is decomposed into two sub-volumes and observables \nare defined such that they depend only on the fields in the respective sub-volume.\n\nThe paper is organized as follows. In Sect.~\\ref{sec:Algorithm} we describe the \nalgorithm and in Sect.~\\ref{sec:NumericalObs} we define the observables that \nwe use in this study. Then, in Sect.~\\ref{sec:Results} we demonstrate the \nfeasibility of this setup and discuss how the improvement works before we conclude.\n\n\n\\section{Algorithm}\\label{sec:Algorithm}\n\nIn order to make the discussion of the algorithm as self contained as possible,\nwe shall briefly present the main ideas introduced in~\\cite{Luscher:2001up,Meyer:2002cd}, \nin a context which is directly applicable to our case.\n\n\\subsection{Factorized observables}\n\nFor simplicity, we consider $\\mathrm{SU}(N)$ Yang-Mills gauge theory on the lattice with the standard Wilson\naction, although more general type of actions can be used,\n\n\n", "itemtype": "equation", "pos": 1975, "prevtext": "\n\n\n\\title{A multilevel algorithm for flow observables in gauge theories}\n\n\n\\author[DESY,HU]{Miguel~Garc\\'ia~Vera}\n\\author[DESY]{Stefan~Schaefer}\n\n\\address[DESY]{John von Neumann Institute for Computing (NIC), DESY, \\\\\n    Platanenallee 6, D-15738 Zeuthen, Germany }\n\\address[HU]{Insitut f{\\\"u}r Physik, Humboldt Universit{\\\"a}t zu Berlin, \\\\\n    Newtonstr. 15, D-12489 Berlin, Germany}\n    \n\\preprintno{DESY 16-016}\n\n\\begin{abstract}\nWe study the possibility of using  multilevel algorithms for\nthe computation of correlation functions of gradient flow observables.\nFor each point in the correlation function an approximate flow is defined\nwhich depends only on links in a subset of the lattice. Together with \na local action this allows for independent updates and consequently a\nconvergence of the Monte Carlo process faster than the inverse square root of the number\nof measurements. We demonstrate the feasibility of this idea in the correlation\nfunctions of the topological charge and the energy density.\n\\end{abstract}\n\n\\maketitle\n\n\\section{Introduction}\\label{sec:Introduction}\n\nIn Monte Carlo simulations of Yang-Mills gauge theories, correlation functions \nof gluonic operators suffer from a severe signal-to-noise problem~\\cite{Parisi:1983ae}. \nWhile the signal of a two-point function itself falls off exponentially with \nthe distance between the operators, the variance is largely independent of \ntheir separation. Since the error decreases only like $1/\\sqrt{N}$, with \n$N$ the number of measurements, this makes their measurement in numerical calculations \nfor large separations exceedingly difficult.\n\nDue to their favourable renormalization properties, correlation functions of observables \ndefined through the Yang-Mills gradient flow are an important tool \nto study gauge theories~\\cite{Narayanan:2006rf,Luscher:2010iy,Luscher:2011bx}. \nIn particular, they allow for a computationally economical definition of \nthe topological susceptibility on the lattice\n\n", "index": 1, "text": "\\begin{equation*}\n\\chi_\\mathrm{top}=\\frac{1}{V}\\int  dx \\, dy \\, \\langle q(x) q(y) \\rangle \\,,\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\chi_{\\mathrm{top}}=\\frac{1}{V}\\int dx\\,dy\\,\\langle q(x)q(y)\\rangle\\,,\" display=\"block\"><mrow><mrow><msub><mi>\u03c7</mi><mi>top</mi></msub><mo>=</mo><mrow><mfrac><mn>1</mn><mi>V</mi></mfrac><mo>\u2062</mo><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mrow><mo>\ud835\udc51</mo><mpadded width=\"+1.7pt\"><mi>x</mi></mpadded></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mpadded width=\"+1.7pt\"><mi>y</mi></mpadded></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">\u27e8</mo><mrow><mi>q</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>q</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">\u27e9</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $U(P)$ is the product of gauge links around the plaquette $P$. \n\nTake $B$, $L$ and $R$ to be three disjoint subsets of gauge links, such that \nthey make up for the totality of gauge links on the lattice. We choose \n$B$ in such a way that the gauge action $S\\left[U_L,U_B,U_R\\right]$ can be \ndecomposed as $S_L\\left[U_L,U_B\\right] + S_R\\left[U_B,U_R\\right] + S_B\\left[U_B\\right]$, \nwhere by $U_{L,B,R}$ we refer to the set of gauge links which belong to $L$, $B$ \nand $R$ respectively. One natural choice for $B$ is the subset \nof all spatial links at a fixed time-slice $x_0^B$, so that, $L$ and $R$ are simply \ndefined as all gauge links that are located to the left or to the right of the boundary $B$. \nThis setup is depicted in Fig.~\\ref{fig:Lattice_setup}. \n\n\nFor two observables $\\mathcal{O}(x)$, and $\\mathcal{O'}(y)$, which are defined  \nfor $x \\in L$ and $y \\in R$, the decomposition of the action makes it \npossible to write\n\n\\begin{figure}\\centering \\includegraphics[width=0.5 \\textwidth]{Fig0_setup.pdf}\n\\caption{Factorized lattice setup. The lattice is split into two sub-volumes \n$L$ and $R$ which are separated by the boundary links $B$ defined as the spatial \nlinks at the timeslice $x_0^B$.}\\label{fig:Lattice_setup} \\end{figure}\n\n\n", "itemtype": "equation", "pos": 5204, "prevtext": "\nwith the topological charge density $q(x)$ defined through the Wilson flow.\n\nThe signal-to-noise problem present at large distances in the $\\langle\nq(x)q(y)\\rangle$ correlation function translates into a lack of volume\naveraging of $\\chi_\\mathrm{top}$: the statistical error of the susceptibility\nfrom a given number of configurations does not improve with increasing volume.\nIn pure gauge theory this can be partially overcome with large statistics, but in practice, \nrather small lattices are still used and the finite size effect needs to\nbe carefully controlled~\\cite{Ce:2015qha}. In large volume, it is therefore \nbeneficial to study the dependence of $\\langle q(x) q(y) \\rangle$  on $|x-y|$ \ndirectly and model the large distance behavior~\\cite{Bazavov:2010xr} or integrate \nit such that the contribution of the tail can be neglected~\\cite{Bruno:2014ova} \ngiven the statistical accuracy. \n\nOn a related note, we also point out that it has been suggested to extract the masses of glueballs from\nthe large distance behavior of two-point functions of the  smoothed topological \ncharge and energy density~\\cite{Chowdhury:2014kfa}. For this \napproach to work, it is highly beneficial to have a precise determination of the \ntail of the correlator at large distances.\n\nOne way to deal with the signal-to-noise problem is to use multi-level algorithms \nwhich rely on the locality of the observable and of the action~\\cite{Luscher:2001up}.\nIf it is possible to decompose the observables in contributions from different\nparts of the lattice, each of them can be updated independently.  Depending on the number\nof sub-lattices and the efficiency of the decomposition, the signal-to-noise problem\ncan be eliminated or at least reduced substantially. Recently, such type of algorithms \nhave also been adapted to the case of quenched lattice QCD to compute fermionic \ncorrelators~\\cite{Ce:2016idq}. \n\nIn the case of flow observables, multi-level algorithms can not be applied directly \nbasically due to the fact that the flow has a footprint which is not finite. In this \npaper we propose a first step in the direction of solving this problem. We study a two-level \nalgorithm where the lattice is decomposed into two sub-volumes and observables \nare defined such that they depend only on the fields in the respective sub-volume.\n\nThe paper is organized as follows. In Sect.~\\ref{sec:Algorithm} we describe the \nalgorithm and in Sect.~\\ref{sec:NumericalObs} we define the observables that \nwe use in this study. Then, in Sect.~\\ref{sec:Results} we demonstrate the \nfeasibility of this setup and discuss how the improvement works before we conclude.\n\n\n\\section{Algorithm}\\label{sec:Algorithm}\n\nIn order to make the discussion of the algorithm as self contained as possible,\nwe shall briefly present the main ideas introduced in~\\cite{Luscher:2001up,Meyer:2002cd}, \nin a context which is directly applicable to our case.\n\n\\subsection{Factorized observables}\n\nFor simplicity, we consider $\\mathrm{SU}(N)$ Yang-Mills gauge theory on the lattice with the standard Wilson\naction, although more general type of actions can be used,\n\n\n", "index": 3, "text": "\\begin{equation}\\label{eq:Action} S\\left[ U \\right] = \\frac{\\beta}{N} \\sum_P\n\\text{Tr} \\left\\lbrace 1 - U \\left( P \\right) \\right\\rbrace \\,, \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"S\\left[U\\right]=\\frac{\\beta}{N}\\sum_{P}\\text{Tr}\\left\\{1-U\\left(P\\right)\\right%&#10;\\}\\,,\" display=\"block\"><mrow><mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo>[</mo><mi>U</mi><mo>]</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mi>\u03b2</mi><mi>N</mi></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>P</mi></munder><mrow><mtext>Tr</mtext><mo>\u2062</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>P</mi><mo>)</mo></mrow></mrow></mrow><mo rspace=\"4.2pt\">}</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $\\mathcal{A}$ is either $\\mathcal{O}$ or $\\mathcal{O'}$, $Z_L$ and $Z_R$ \nare the normalization factors such that $\\left[1\\right]_{L,R}=1$,  \nand $p(B) = \\frac{Z_L Z_R}{Z} e^{-S[U_B]}$, with $Z$ the standard partition function.\n\nEq. \\eqref{eq:fact_obs} expresses the fact that one can average an observable over $L$\nand $R$ independently while keeping $B$ fixed and then take the average over\nthe possible values of $B$. As discussed in~\\cite{Luscher:2001up,Meyer:2002cd}, \nthis process can be iterated if the\noperators $\\mathcal{O}$ or $\\mathcal{O'}$ can be subsequently factorized.\nThis is the property of factorization that was exploited originally in\n\\cite{Luscher:2001up} to show an exponential reduction in the error of the\nexpectation value of large Wilson loops.\n\nThe idea presented above can be realized in a Monte Carlo simulation as follows. \nFirst generate $N_0$ regular updates which are used to perform the integration \nover $U_B$ in Eq. \\eqref{eq:fact_obs}. Then, for each of the $N_0$ \noriginal configurations, $N_1$ updates of $L$ and $R$ are done independently \nwhile keeping $B$ fixed, so that for the product \n$\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R$, the error decreases \nideally as $1/N_1$ instead of the standard $1/\\sqrt{N_1}$. \n\nNote that factorization makes it possible to obtain a better \nscaling for the errors in $\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R$, but the \nerror on the final expectation value $\\left\\langle{\\mathcal{O}\\mathcal{O'}}\\right\\rangle$ depends on the average over $B$ which \nscales as $1/\\sqrt{N_0}$. This means that for large values of $N_1$ the error is \ncontrolled by the fluctuations of $B$ and hence the dominant scaling will be the $1/\\sqrt{N_0}$.\nAs discussed in the following sections and as shown in the Appendix~\\ref{sec:Appendix}, \nin practice one can take very large values of $N_1$ before the ideal scaling is no \nlonger valid.\n\n\n\\subsection{Modified flow Observables}\n\nGiven the gauge link variables $U(x,\\mu)$, the flow variables $V^t(x,\\mu)$\nassociated to them are defined by the equation\n\\cite{Luscher:2009eq,Luscher:2010iy,Narayanan:2006rf}\n\n\n", "itemtype": "equation", "pos": 6614, "prevtext": "\nwhere $U(P)$ is the product of gauge links around the plaquette $P$. \n\nTake $B$, $L$ and $R$ to be three disjoint subsets of gauge links, such that \nthey make up for the totality of gauge links on the lattice. We choose \n$B$ in such a way that the gauge action $S\\left[U_L,U_B,U_R\\right]$ can be \ndecomposed as $S_L\\left[U_L,U_B\\right] + S_R\\left[U_B,U_R\\right] + S_B\\left[U_B\\right]$, \nwhere by $U_{L,B,R}$ we refer to the set of gauge links which belong to $L$, $B$ \nand $R$ respectively. One natural choice for $B$ is the subset \nof all spatial links at a fixed time-slice $x_0^B$, so that, $L$ and $R$ are simply \ndefined as all gauge links that are located to the left or to the right of the boundary $B$. \nThis setup is depicted in Fig.~\\ref{fig:Lattice_setup}. \n\n\nFor two observables $\\mathcal{O}(x)$, and $\\mathcal{O'}(y)$, which are defined  \nfor $x \\in L$ and $y \\in R$, the decomposition of the action makes it \npossible to write\n\n\\begin{figure}\\centering \\includegraphics[width=0.5 \\textwidth]{Fig0_setup.pdf}\n\\caption{Factorized lattice setup. The lattice is split into two sub-volumes \n$L$ and $R$ which are separated by the boundary links $B$ defined as the spatial \nlinks at the timeslice $x_0^B$.}\\label{fig:Lattice_setup} \\end{figure}\n\n\n", "index": 5, "text": "\\begin{align}\\label{eq:fact_obs} \\left\\langle \\mathcal{O} \\mathcal{O'}\n\\right\\rangle &= \\int dU_B \\, p(B) \\, \\left[ \\mathcal{O} \\right]_{L}\n\\left[ \\mathcal{O'} \\right]_{R} \\, ,\\\\\\nonumber\n \\left[ \\mathcal{A}\\right]_{L,R} &= \\frac{1}{Z_{L,R}}\\int dU_{L,R} \\, \\mathcal{A} \\, e^{-S_{L,R}[U_{L,R},U_B]}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\langle\\mathcal{O}\\mathcal{O^{\\prime}}\\right\\rangle\" display=\"inline\"><mrow><mo>\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup></mrow><mo>\u27e9</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int dU_{B}\\,p(B)\\,\\left[\\mathcal{O}\\right]_{L}\\left[\\mathcal{O^%&#10;{\\prime}}\\right]_{R}\\,,\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mrow><mo>\ud835\udc51</mo><mpadded width=\"+1.7pt\"><msub><mi>U</mi><mi>B</mi></msub></mpadded></mrow><mo>\u2062</mo><mi>p</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>B</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msub><mrow><mo>[</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>]</mo></mrow><mi>L</mi></msub><mo>\u2062</mo><mpadded width=\"+1.7pt\"><msub><mrow><mo>[</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>]</mo></mrow><mi>R</mi></msub></mpadded></mrow></mrow></mstyle></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left[\\mathcal{A}\\right]_{L,R}\" display=\"inline\"><msub><mrow><mo>[</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi><mo>]</mo></mrow><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{Z_{L,R}}\\int dU_{L,R}\\,\\mathcal{A}\\,e^{-S_{L,R}[U_{L,R}%&#10;,U_{B}]}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>Z</mi><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub></mfrac></mstyle><mo>\u2062</mo><mstyle displaystyle=\"true\"><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mrow><mrow><mo>\ud835\udc51</mo><mpadded width=\"+1.7pt\"><msub><mi>U</mi><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub></mpadded></mrow><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9c</mi></mpadded><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msub><mi>S</mi><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">[</mo><msub><mi>U</mi><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub><mo>,</mo><msub><mi>U</mi><mi>B</mi></msub><mo stretchy=\"false\">]</mo></mrow></mrow></mrow></msup></mrow></mrow></mstyle></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\n\nThe effect of the flow can be viewed as a smoothing of the gauge fields over a\nspherical range with a mean square radius of $\\sqrt{8t}$. Because of this, any observable \ndefined in $L$ or $R$ has a non-trivial dependence on gauge links from the opposite \ndomain at positive flow time $t$, and it can not be factorized as \nrequired for Eq. \\eqref{eq:fact_obs} to hold. However, the smoothing produced \nby the flow is exponentially suppressed at large distances, which leads us to propose a slightly \nmodified version of the flow equations, such that an observable computed with the modified \nflow gauge links $\\tilde{V}^t$ is a good approximation to the original one and \ncan be factorized as required in Eq.~\\eqref{eq:fact_obs}.\n\nIf the Wilson action is also used in the definition of the flow, we propose the\nfollowing modified flow equation\n\n\n", "itemtype": "equation", "pos": 9070, "prevtext": "\nwhere $\\mathcal{A}$ is either $\\mathcal{O}$ or $\\mathcal{O'}$, $Z_L$ and $Z_R$ \nare the normalization factors such that $\\left[1\\right]_{L,R}=1$,  \nand $p(B) = \\frac{Z_L Z_R}{Z} e^{-S[U_B]}$, with $Z$ the standard partition function.\n\nEq. \\eqref{eq:fact_obs} expresses the fact that one can average an observable over $L$\nand $R$ independently while keeping $B$ fixed and then take the average over\nthe possible values of $B$. As discussed in~\\cite{Luscher:2001up,Meyer:2002cd}, \nthis process can be iterated if the\noperators $\\mathcal{O}$ or $\\mathcal{O'}$ can be subsequently factorized.\nThis is the property of factorization that was exploited originally in\n\\cite{Luscher:2001up} to show an exponential reduction in the error of the\nexpectation value of large Wilson loops.\n\nThe idea presented above can be realized in a Monte Carlo simulation as follows. \nFirst generate $N_0$ regular updates which are used to perform the integration \nover $U_B$ in Eq. \\eqref{eq:fact_obs}. Then, for each of the $N_0$ \noriginal configurations, $N_1$ updates of $L$ and $R$ are done independently \nwhile keeping $B$ fixed, so that for the product \n$\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R$, the error decreases \nideally as $1/N_1$ instead of the standard $1/\\sqrt{N_1}$. \n\nNote that factorization makes it possible to obtain a better \nscaling for the errors in $\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R$, but the \nerror on the final expectation value $\\left\\langle{\\mathcal{O}\\mathcal{O'}}\\right\\rangle$ depends on the average over $B$ which \nscales as $1/\\sqrt{N_0}$. This means that for large values of $N_1$ the error is \ncontrolled by the fluctuations of $B$ and hence the dominant scaling will be the $1/\\sqrt{N_0}$.\nAs discussed in the following sections and as shown in the Appendix~\\ref{sec:Appendix}, \nin practice one can take very large values of $N_1$ before the ideal scaling is no \nlonger valid.\n\n\n\\subsection{Modified flow Observables}\n\nGiven the gauge link variables $U(x,\\mu)$, the flow variables $V^t(x,\\mu)$\nassociated to them are defined by the equation\n\\cite{Luscher:2009eq,Luscher:2010iy,Narayanan:2006rf}\n\n\n", "index": 7, "text": "\\begin{equation}\\label{eq:Wflow} \\dot{V}^t(x,\\mu)= -g_0^2 \\left\\lbrace\n\\partial_{x,\\mu} S(V) \\right\\rbrace V^t(x,\\mu), \\qquad V^{t=0}(x,\\mu) = U(x,\\mu)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\dot{V}^{t}(x,\\mu)=-g_{0}^{2}\\left\\{\\partial_{x,\\mu}S(V)\\right\\}V^{t}(x,\\mu),%&#10;\\qquad V^{t=0}(x,\\mu)=U(x,\\mu)\" display=\"block\"><mrow><mrow><mrow><msup><mover accent=\"true\"><mi>V</mi><mo>\u02d9</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><msubsup><mi>g</mi><mn>0</mn><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo>{</mo><mrow><mrow><msub><mo>\u2202</mo><mrow><mi>x</mi><mo>,</mo><mi>\u03bc</mi></mrow></msub><mo>\u2061</mo><mi>S</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>V</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><msup><mi>V</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><msup><mi>V</mi><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\n\nThe modified version accounts for integrating the flow equations while the \nlinks at $B$ are kept fixed. For an observable $\\mathcal{O}(x)$, in either $L$ \nor $R$, the modified flow observable $\\widetilde{\\mathcal{O}}^t(x)$ is also a \nfunction of gauge links in $L$ or $R$ only. If $\\widetilde{\\mathcal{O}}^t(x)$ \nis a good approximation of $\\mathcal{O}^t(x)$, one can take advantage of factorization \nto obtain a better scaling of the errors of $\\left\\langle{\\mathcal{O}\\mathcal{O'}}\\right\\rangle$ with \nrespect to the $N_1$ nested Monte Carlo updates.\n\n\\subsection{Two point correlation function}\n\nWe now consider the case of the connected two point correlation function \n$\\mathcal{O}(x)\\mathcal{O}(y)$ for $x$ and $y$ spacetime points in the four \ndimensional lattice, and put together the modified flow observables with the \nmulti-level scheme. We define\n\n\n", "itemtype": "equation", "pos": 10082, "prevtext": "\n\nThe effect of the flow can be viewed as a smoothing of the gauge fields over a\nspherical range with a mean square radius of $\\sqrt{8t}$. Because of this, any observable \ndefined in $L$ or $R$ has a non-trivial dependence on gauge links from the opposite \ndomain at positive flow time $t$, and it can not be factorized as \nrequired for Eq. \\eqref{eq:fact_obs} to hold. However, the smoothing produced \nby the flow is exponentially suppressed at large distances, which leads us to propose a slightly \nmodified version of the flow equations, such that an observable computed with the modified \nflow gauge links $\\tilde{V}^t$ is a good approximation to the original one and \ncan be factorized as required in Eq.~\\eqref{eq:fact_obs}.\n\nIf the Wilson action is also used in the definition of the flow, we propose the\nfollowing modified flow equation\n\n\n", "index": 9, "text": "\\begin{equation}\\label{eq:Wflow_modified} \\dot{\\tilde{V}}^t(x,\\mu)=\n\\begin{cases} -g_0^2 \\left\\lbrace \\partial_{x,\\mu} S(\\tilde{V}^t) \\right\\rbrace\n\\tilde{V}^t(x,\\mu), \\quad \\tilde{V}^{t=0}(x,\\mu) = U(x,\\mu), & \\text{if $U(x,\\mu) \\in L\n\\cup R$}.\\\\ U(x,\\mu), & \\text{if $U(x,\\mu) \\in B$}. \\end{cases} \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\dot{\\tilde{V}}^{t}(x,\\mu)=\\begin{cases}-g_{0}^{2}\\left\\{\\partial_{x,\\mu}S(%&#10;\\tilde{V}^{t})\\right\\}\\tilde{V}^{t}(x,\\mu),\\quad\\tilde{V}^{t=0}(x,\\mu)=U(x,\\mu%&#10;),&amp;\\text{if $U(x,\\mu)\\in L\\cup R$}.\\\\&#10;U(x,\\mu),&amp;\\text{if $U(x,\\mu)\\in B$}.\\end{cases}\" display=\"block\"><mrow><mrow><msup><mover accent=\"true\"><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover><mo>\u02d9</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mrow><mo>-</mo><mrow><msubsup><mi>g</mi><mn>0</mn><mn>2</mn></msubsup><mo>\u2062</mo><mrow><mo>{</mo><mrow><mrow><msub><mo>\u2202</mo><mrow><mi>x</mi><mo>,</mo><mi>\u03bc</mi></mrow></msub><mo>\u2061</mo><mi>S</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover><mi>t</mi></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>}</mo></mrow><mo>\u2062</mo><msup><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><msup><mover accent=\"true\"><mi>V</mi><mo stretchy=\"false\">~</mo></mover><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mrow><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2208</mo><mrow><mi>L</mi><mo>\u222a</mo><mi>R</mi></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mrow><mrow><mi>U</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>\u03bc</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2208</mo><mi>B</mi></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nas the connected ($C$) correlation function of the observable $\\mathcal{O}$. \nIf the two points $x$ and $y$ are separated from the boundary $B$ by a distance \nmuch larger than the radius of the flow $\\sqrt{8t}$, then the modified \nversion of Eq.~\\eqref{eq:correlator} using the gauge links $\\tilde{V}^t$ \nis a good approximation to the original correlator. To show this, we look at the correction term \n$\\Delta$, defined as the difference between the flow observable and the \nobservable computed using the modified flow\n\n\n", "itemtype": "equation", "pos": 11258, "prevtext": "\n\nThe modified version accounts for integrating the flow equations while the \nlinks at $B$ are kept fixed. For an observable $\\mathcal{O}(x)$, in either $L$ \nor $R$, the modified flow observable $\\widetilde{\\mathcal{O}}^t(x)$ is also a \nfunction of gauge links in $L$ or $R$ only. If $\\widetilde{\\mathcal{O}}^t(x)$ \nis a good approximation of $\\mathcal{O}^t(x)$, one can take advantage of factorization \nto obtain a better scaling of the errors of $\\left\\langle{\\mathcal{O}\\mathcal{O'}}\\right\\rangle$ with \nrespect to the $N_1$ nested Monte Carlo updates.\n\n\\subsection{Two point correlation function}\n\nWe now consider the case of the connected two point correlation function \n$\\mathcal{O}(x)\\mathcal{O}(y)$ for $x$ and $y$ spacetime points in the four \ndimensional lattice, and put together the modified flow observables with the \nmulti-level scheme. We define\n\n\n", "index": 11, "text": "\\begin{equation}\\label{eq:correlator}\nC_{\\mathcal{O}}^t(x,y) = \\left\\langle{\\mathcal{O}^t(x) \\mathcal{O}^t(y)}\\right\\rangle_C = \n\\left\\langle{\\mathcal{O}^t(x) \\mathcal{O}^t(y)}\\right\\rangle - \\left\\langle{\\mathcal{O}^t(x)}\\right\\rangle\\left\\langle{\\mathcal{O}^t(y)}\\right\\rangle\\, ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"C_{\\mathcal{O}}^{t}(x,y)=\\left\\langle{\\mathcal{O}^{t}(x)\\mathcal{O}^{t}(y)}%&#10;\\right\\rangle_{C}=\\left\\langle{\\mathcal{O}^{t}(x)\\mathcal{O}^{t}(y)}\\right%&#10;\\rangle-\\left\\langle{\\mathcal{O}^{t}(x)}\\right\\rangle\\left\\langle{\\mathcal{O}^%&#10;{t}(y)}\\right\\rangle\\,,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>C</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mrow><mo>\u27e8</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mi>C</mi></msub><mo>=</mo><mrow><mrow><mo>\u27e8</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mo>-</mo><mrow><mrow><mo>\u27e8</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mo>\u2062</mo><mrow><mo>\u27e8</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"4.2pt\">\u27e9</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\n\nNotice that we have left the dependence on both $x$ and $y$ explicit, as the presence of the \nboundary $B$ breaks full translation invariance and one must keep track not only \nof the distance $|x-y|$ between source and sink, but also of the distance of \nboth $x$ and $y$ with respect to $B$. The reason for this will become evident in the \nnext section when we discuss a practical application of the algorithm. \nWhen not explicitly needed we will drop the $t$ index in every quantity.\n\nFor the observables discussed in the next section, our data shows that \nfor a sufficiently large separation from $B$, $\\Delta$ becomes\nnegligible. In spite of that, our strategy is not to\nneglect the correction term $\\Delta$. Instead, in a nested Monte Carlo simulation, \nthe idea is  to use first the $N_0$ generated configurations to estimate $\\Delta$ \nand then use this estimation to correct for the value of $\\widetilde{C}_{\\mathcal{O}}(x,y)$. \nFor this to work, we need that the fluctuations of $\\Delta$ are much \nsmaller than the fluctuations of $C_{\\mathcal{O}}$ in such a way that \nwe can use the $N_0$ updates to estimate $\\Delta$ and subsequently perform \nthe $N_1$ nested Monte Carlo updates independently in $L$ and $R$ \nto compute $\\widetilde{C}_{\\mathcal{O}}$.\n\nThe main equation of this paper is a modified version of Eq.~\\eqref{eq:fact_obs} \nwhich takes into account the correction term $\\Delta$ and is applicable \nfor any two point correlation function of Wilson flow observables. \nWe define an estimator $\\widehat{C}_{\\mathcal{O}}^t(x,y)$ of \n$C^t_{\\mathcal{O}}(x,y)$ as\n\n\n", "itemtype": "equation", "pos": 12077, "prevtext": "\nas the connected ($C$) correlation function of the observable $\\mathcal{O}$. \nIf the two points $x$ and $y$ are separated from the boundary $B$ by a distance \nmuch larger than the radius of the flow $\\sqrt{8t}$, then the modified \nversion of Eq.~\\eqref{eq:correlator} using the gauge links $\\tilde{V}^t$ \nis a good approximation to the original correlator. To show this, we look at the correction term \n$\\Delta$, defined as the difference between the flow observable and the \nobservable computed using the modified flow\n\n\n", "index": 13, "text": "\\begin{equation}\n\\label{eq:corr_term} \n\\Delta_{\\mathcal{O}}^t(x,y) = C^t_{\\mathcal{O}}(x,y) - \\widetilde{C}^t_{\\mathcal{O}}(x,y) \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\Delta_{\\mathcal{O}}^{t}(x,y)=C^{t}_{\\mathcal{O}}(x,y)-\\widetilde{C}^{t}_{%&#10;\\mathcal{O}}(x,y)\\,.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi mathvariant=\"normal\">\u0394</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msubsup><mi>C</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msubsup><mover accent=\"true\"><mi>C</mi><mo>~</mo></mover><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $(x,y) \\in L \\times R$. The estimator in Eq.~\\eqref{eq:main} is correct up to \nerrors of order $O(1/\\sqrt{N_0})$, which comes from the fact that $\\Delta$ is only \ncomputed on the $N_0$ standard updates. However, in the next section we show that \nthe fluctuations of $\\Delta$ are exponentially suppressed with the distance \nto the boundary, so that the leading term for the scaling of the error in $\\widehat{C}$ \ncomes from the correlator of the modified flow observables.\n\n\\section{Numerical test of the modified flow observables}\\label{sec:NumericalObs}\n\nTo test our algorithm we work with the $\\mathrm{SU}(3)$ gauge group and a set of gauge\nconfigurations generated with the parameters shown in Table\n\\ref{tab:Ensembles}. The configurations are generated for a value of $\\beta = 6.11$, which \ncorresponds to a lattice spacing of $a \\approx 0.08 \\, \\text{fm}$ and a effective \nsmearing radius $\\sqrt{8 t_0} \\approx 6 a$. Open boundary conditions are used in the time direction\n\\cite{Luscher:2011kk}. We consider two observables, the topological charge density\n$q$ and the Yang-Mills energy density $e$. In particular, we look at the\nconnected two point correlation function of the timeslice summed \n$\\bar{q}$ and $\\bar{e}$\n\n\\begin{table} \n\\centering \n\\begin{tabular}{cccccc} \n\\toprule \n$\\beta$   & $(T/a) \\times (L/a)^3$    & $t_0/a^2$     & $a \\, \\text{[fm]}$ & $N_0$\\\\\n\\midrule $6.11 $  & $80 \\times 20^3$ & $4.5776(15)$   &  $0.078$ & $384$\\\\ \n\\bottomrule \n\\end{tabular} \n\\caption{Lattice\nparameters. We report the lattice bare coupling $\\beta$, the lattice dimensions $L$ and \n$T$, the scale parameter $t_0$ defined in~\\cite{Luscher:2010iy}, the lattice spacing \n$a$ computed using the $r_0 = 0.5 \\, \\text{[fm]}$ scale from \\cite{Necco:2001xg}, and the number of \ngenerated configurations $N_0$.}\n\\label{tab:Ensembles} \\end{table}\n\n\n", "itemtype": "equation", "pos": 13803, "prevtext": "\n\nNotice that we have left the dependence on both $x$ and $y$ explicit, as the presence of the \nboundary $B$ breaks full translation invariance and one must keep track not only \nof the distance $|x-y|$ between source and sink, but also of the distance of \nboth $x$ and $y$ with respect to $B$. The reason for this will become evident in the \nnext section when we discuss a practical application of the algorithm. \nWhen not explicitly needed we will drop the $t$ index in every quantity.\n\nFor the observables discussed in the next section, our data shows that \nfor a sufficiently large separation from $B$, $\\Delta$ becomes\nnegligible. In spite of that, our strategy is not to\nneglect the correction term $\\Delta$. Instead, in a nested Monte Carlo simulation, \nthe idea is  to use first the $N_0$ generated configurations to estimate $\\Delta$ \nand then use this estimation to correct for the value of $\\widetilde{C}_{\\mathcal{O}}(x,y)$. \nFor this to work, we need that the fluctuations of $\\Delta$ are much \nsmaller than the fluctuations of $C_{\\mathcal{O}}$ in such a way that \nwe can use the $N_0$ updates to estimate $\\Delta$ and subsequently perform \nthe $N_1$ nested Monte Carlo updates independently in $L$ and $R$ \nto compute $\\widetilde{C}_{\\mathcal{O}}$.\n\nThe main equation of this paper is a modified version of Eq.~\\eqref{eq:fact_obs} \nwhich takes into account the correction term $\\Delta$ and is applicable \nfor any two point correlation function of Wilson flow observables. \nWe define an estimator $\\widehat{C}_{\\mathcal{O}}^t(x,y)$ of \n$C^t_{\\mathcal{O}}(x,y)$ as\n\n\n", "index": 15, "text": "\\begin{align}\\label{eq:main} \\widehat{C}_{\\mathcal{O}}^t(x,y) &= \\frac{1}{N_0}\\sum_{N_0}\n\\left\\lbrace \\left[\\widetilde{\\mathcal{O}}^t(x)\\right]_L \\left[\\widetilde{\\mathcal{O}}^t(y)\\right]_R +\n\\Delta^t_{\\mathcal{O}}(x,y) \\right\\rbrace\\\\\\nonumber\n\\left[\\widetilde{\\mathcal{O}}^t(z)\\right]_{L,R} &= \\frac{1}{N_1} \\sum_{N_1}\n\\widetilde{\\mathcal{O}}^t(z) \\, , \\qquad z=x,y \\, , \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\widehat{C}_{\\mathcal{O}}^{t}(x,y)\" display=\"inline\"><mrow><msubsup><mover accent=\"true\"><mi>C</mi><mo>^</mo></mover><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{N_{0}}\\sum_{N_{0}}\\left\\{\\left[\\widetilde{\\mathcal{O}}^%&#10;{t}(x)\\right]_{L}\\left[\\widetilde{\\mathcal{O}}^{t}(y)\\right]_{R}+\\Delta^{t}_{%&#10;\\mathcal{O}}(x,y)\\right\\}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msub><mi>N</mi><mn>0</mn></msub></munder></mstyle><mrow><mo>{</mo><mrow><mrow><msub><mrow><mo>[</mo><mrow><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>~</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>]</mo></mrow><mi>L</mi></msub><mo>\u2062</mo><msub><mrow><mo>[</mo><mrow><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>~</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>]</mo></mrow><mi>R</mi></msub></mrow><mo>+</mo><mrow><msubsup><mi mathvariant=\"normal\">\u0394</mi><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>}</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left[\\widetilde{\\mathcal{O}}^{t}(z)\\right]_{L,R}\" display=\"inline\"><msub><mrow><mo>[</mo><mrow><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>~</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>]</mo></mrow><mrow><mi>L</mi><mo>,</mo><mi>R</mi></mrow></msub></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{1}{N_{1}}\\sum_{N_{1}}\\widetilde{\\mathcal{O}}^{t}(z)\\,,%&#10;\\qquad z=x,y\\,,\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac></mstyle><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><msub><mi>N</mi><mn>1</mn></msub></munder></mstyle><mrow><msup><mover accent=\"true\"><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>~</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>z</mi><mo>=</mo><mrow><mi>x</mi><mo>,</mo><mpadded width=\"+1.7pt\"><mi>y</mi></mpadded></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere we have left the $x_0$ dependence explicit in order to keep track of the\ndistance to the boundary $B$, which is chosen to be the subset of spatial links with \ntime coordinate $x^B_0=T/2$. All computations are done in such a way that both $x_0$ \nand $x_0 + r$ are placed far enough from the open boundaries. From now on we \nshall use $\\mathcal{O}$ to refer to either $q$ or $e$ when there is no need to make a \ndistinction between them.\n\nWe use the 384 independent configurations to study the dependence of the fluctuations \nof $\\Delta$ on both $x_0$ and $r$. First we consider the correlators which are\nsymmetric with respect to $B$, so we choose a source which is placed at the value \nof $x_0 = (T -r)/2$. In this case, the correlator is only a function of \n$r$ and given by $C_{\\mathcal{O}}(r) = C_{\\mathcal{O}}\\left(\\left(T-r\\right)/2,r\\right)$.\n\nFig.~\\ref{fig:Errors_Delta_r} shows the dependence of the error of both\n$C_{\\mathcal{O}}(r)$ and $\\Delta_{\\mathcal{O}}(r)$ for a \nfixed value of the flow time $t=t_0$. The errors are computed by measuring the autocorrelation \nfunction as described in \\cite{Wolff:2003sm}. As a reference, the dotted vertical line indicates\nthe value of $r$ for which the fluctuations in $\\Delta$ are below 5\\% of those\nof the observable. As will be discussed in Sect.~\\ref{sec:Parameters_choice}, \nthe fact that the ratio between the fluctuations of the observable and those of the \ncorrection term decrease at large distances contributes to the fact that the \nalgorithm is efficient up to very large values of $N_1$.\n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig1_sigma_delta_log.pdf}\n\\caption{Statistical error $\\sigma$ of $\\Delta_{\\mathcal{O}}$ and $C_{\\mathcal{O}}$ at flow time\n$t=t_0$. For both observables, $\\bar{e}$ and $\\bar{q}$, the error in the correlator is independent \nof the distance $r$, but the errors of $\\Delta$ seem to decay at least exponentially with the \ndistance. The dotted vertical is added as a reference to show the value of $r$ for which \nthe errors in $\\Delta_{\\mathcal{O}}$ are below 5\\% those of $C_{\\mathcal{O}}$. \nErrors are smaller than the data markers.}\\label{fig:Errors_Delta_r} \\end{figure}\n\nSince the effective smearing radius produced by the flow grows as $\\sqrt{t}$, the\neffect of freezing the boundary links at $B$ increases monotonically with the\nflow time. We have observed this behaviour in our data, but we are more \ninterested in the behaviour of the correlation functions at the reference flow scale \n$t =t_0$. For different values of the flow, a similar analysis can be performed. \nHowever, it is clear that if the fluctuations of $\\Delta$ are ``small'' for a given \nvalue of $t'$, they are also small for $t < t'$.\n\nNext, we go beyond the symmetric case and look at the $x_0$ dependence of $\\Delta$.\nFig.~\\ref{fig:Errors_Delta_x0} shows a plot of the errors in $\\Delta$ as a function of\n$x_0$ for two fixed values of $r$ at $t=t_0$. \n\nNotice that the effect of the flow is that of a Gaussian smearing, so we should \nexpect that the errors in $\\Delta$ decay at least exponentially with the distance \nto the boundary $B$. Both Figs.~\\ref{fig:Errors_Delta_r} \nand~\\ref{fig:Errors_Delta_x0} show a behaviour which is compatible with this statement.\n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig3_sigma_delta_log.pdf} \n\\caption{Statistical error $\\sigma$ of $\\Delta_{\\mathcal{O}}$ as a function of $x_0$ \nfor two values of $r$ at flow time $t=t_0$. Open symbols correspond to a value of \n$r=20 a$, while filled symbols to a value of $r = 28 a$. The smallest error corresponds \nto the symmetric point in which both source and sink are placed far from the boundary. \nErrors are smaller than the data markers.}\\label{fig:Errors_Delta_x0}\\end{figure}\n\nThe results presented in this section show that using the modified flow\nequations has little impact in the two point function, and the effect can be\nincorporated in the correction term $\\Delta$. When using equation\n\\eqref{eq:main} it is important to tune the value of $N_0$ and $N_1$ in such a\nway that the effect of $\\Delta$ remains under control. In particular, due to\nthe exponential smoothing of the flow, $N_1$ can be chosen larger at larger\nvalues of $r$, which is precisely where a higher precision is required.\n\n\n\\section{Results}\\label{sec:Results}\n\nWe consider the ensemble in Table \\ref{tab:Ensembles} and for each of the $N_0$\nconfigurations we perform $N_1 = 40$ Monte Carlo updates while keeping $B$\nfixed. The updates are separated by 60 sweeps, where one sweep is composed of \n8 over-relaxation updates followed by 1 heat-bath update. \nBoth updates are performed using the Cabibbo-Marinari technique \napplied to three $\\mathrm{SU}(2)$ subgroups~\\cite{Cabibbo:1982zn,Brown:1987rra}.\n\nIn the following we present our findings concerning the scaling of the \nerrors with respect to $N_1$ and show the application of our algorithm \nfor the computation of the two point correlation function over the whole range \nof distances allowed in our finite size lattice. The limitations of the method \nare also discussed. We conclude this section by using our method to compute the \ntopological susceptibility and compare it to the result obtained with the standard \nalgorithm.\n\n\\subsection{Autocorrelation times}\n\nAn interesting question to explore is whether or not an undesirable growth of \nthe autocorrelations is introduced due to the freezing of the boundary $B$. Such an \neffect could have an impact on the cost of the measurement in our nested Monte Carlo \nscheme. To investigate that, we look at the integrated autocorrelation \ntime $\\tau_{\\mathrm{int}}$ of $\\mathcal{O}(x_0)$ as a function of the time coordinate $x_0$.\nGiven that the $N_0$ standard updates are completely decorrelated, the relevant \nautocorrelation function is given by the average over $N_0$ of the autocorrelation \nfunction for the $N_1$ nested updates,\n$\\widetilde{\\Gamma}(t) = \\frac{1}{N_0} \\sum_{i=1}^{N_0} \\Gamma^i(t)$. Where $\\Gamma^i(t)$ is \nprecisely the autocorrelation function for each of the nested chains. \n\nNow, $\\tau_{\\mathrm{int}}$ can be defined in the usual way~\\cite{Wolff:2003sm} in \nterms of the average autocorrelation function $\\widetilde{\\Gamma}(t)$. Our data \nshows that $\\tau_{\\mathrm{int}}$ increases at most by a factor of $1.5$ when \nthe observables approach the boundary $B$, so there is not a significant effect. \nHowever, on different observables, it could have a more severe impact which \nthen must be taken into account when spacing the $N_1$ nested updates and \ncalculating the cost of the simulation.\n\n\\subsection{Choice of the parameters}\\label{sec:Parameters_choice}\n\nThe introduction of the nested updates adds an extra parameter to be \ntuned in the algorithm, as the parameter $N_1$ can be chosen to minimize \nthe errors at a given computational effort. We argue that for the connected \ncorrelator $\\widehat{C}_{\\mathcal{O}}$, when source and sink are placed far away \nfrom the boundary, the value of $N_1$ up to which the algorithm is efficient can \nbe scaled exponentially with respect to the distance to $B$. \n\nTo show this, in appendix~\\ref{sec:Appendix} we \nhave looked into the scaling of errors with respect to $N_0$ and $N_1$ in a \nMonte Carlo simulation. Our results show that the leading contribution to the \nerror in the connected correlator scales as $1/\\sqrt{N_0}N_1$, which corresponds \nto the ideal case, but additionally there are other terms that scale as $1/\\sqrt{N_0N_1}$ and as \n$1/\\sqrt{N_0}$. Such terms however, are exponentially suppressed as $e^{-m_0|x^M_0 - x^B_0|}$, \nwhere $x^M_0$ is the time coordinate of either source or sink, whichever is the closest to \nthe boundary, and $m_0$ is the mass of the lightest mode which is compatible with \nthe symmetries of $\\mathcal{O}$. This means that we can expect the ideal scaling up to very large \nvalues of $N_1$ given that source and sink are far away from the boundary in units of $1/m_0$.\n\nAnother effect that must be taken into account is the presence of the correction \nterm $\\Delta$. Such term is measured only over the $N_0$ standard updates, so that \nits error should scale in the standard way as $1/\\sqrt{N_0}$. This will add another \nterm which is independent of $N_1$ to the final error. We can see from  \nour results in Fig.~\\ref{fig:Errors_Delta_x0} that for a fixed $N_0$, the error in $\\Delta$ decays \nat least exponentially fast with the distance of either source or sink to the boundary \n$B$. This means that for the final estimator $\\widehat{C}$, the value of $N_1$ can \nbe scaled exponentially with the distance to the boundary as long as \n$|x^M_0 - x^B_0|$ is larger than the relevant scale, either $1/m_0$ for the effects coming \nfrom $\\widetilde{C}$ or $\\sqrt{8t}$ for those coming from $\\Delta$.\n\n\\subsection{$N_1$ dependence of the error}\\label{sec:Scaling_errors}\n\nTo show the way in which our algorithm improves over the standard one, we\nmeasure the scaling of errors with respect to $N_1$ for the symmetric\ncorrelator. The results for two different values of $r$ are shown in Fig.~\\ref{fig:Scaling_errors}. \nFor the larger $r = 28 a$, and for $N_1=40$, we \nare still in the regime where the ideal scaling is the dominant one, so on \nthe left subplot we see an scaling of the error which is compatible with \n$1/N_1$ for the whole range of $N_1$ values.\n\nFor the smaller value of $r = 14 a$, in particular when looking at the case \nof $\\widehat{C}_e$, we observe that for $N_1 \\gtrsim 6$ the error improves only \nmarginally with $N_1$, which means that we are already in the regime where the \nterm independent of $N_1$ becomes relevant. This supports the discussion of the \nprevious section and shows that for small values of $r$ \nthere is no significant improvement by performing a very large number of $N_1$ nested Monte Carlo \nupdates. In practice, one can use all the $N_1$ generated nested updates for all \nvalues of $r$, but for small separations, the effect of using all of them \nis not significative. \n\nFor a given $N_0$ and $N_1$, the value of $r$ at which the ideal scaling is not \nvalid anymore is observable dependent and so it has to be studied on a case by case basis. \nIn our particular case, we observe that for $N_1 =40$ we are on the ideal scaling \nregime for the correlator at distances starting at values of \n$r = 16 a = 7.5 \\sqrt{t_0}$ at a flow time $t=t_0$. \n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig5_scaling_log.pdf}\n\\caption{Scaling of the error of $\\widehat{C}_{\\mathcal{O}}$ as a function of \n$N_1$. On the left for a value of $r= 28 a = 13.2 \\sqrt{t_0}$ and on the right for a \nvalue of $r=14 a = 6.6 \\sqrt{t_0}$. The solid line indicates a scaling of the \nerror proportional to $1/N_1$, while the dotted line corresponds to the standard \n$1/\\sqrt{N_1}$ scaling. For the smaller value of $r$ (right plot), \nwe observe a saturation in the number of effective $N_1$ nested updates that \ncan be used to reduce the errors. In fact, after $N_1 \\approx 6$ we observe no \nsignificant improvement. }\\label{fig:Scaling_errors} \\end{figure}\n\n\n\\subsection{Application of the algorithm}\\label{sec:Application_algo}\n\nTo show how the algorithm performs for the whole range of distances in the \ntwo point correlator, we compute $C_q$ and $C_e$ using the standard\nalgorithm and using our nested Monte Carlo scheme. \nFor each value of $r$ and $x_0$ we compute $C_{\\mathcal{O}}$ and $\\widehat{C}_{\\mathcal{O}}$. \nWe use the $N_0=384$ standard updates to compute $C_{\\mathcal{O}}$ in the usual way. For \nour nested algorithm we employ the $N_1=40$ nested updates for each of the standard ones. \n\nWhen using the standard approach, the correlator at distance $r$ is computed by averaging \nover all the $x_0$ values in the plateau region. In the case of our algorithm this is  not the best strategy, \nas translation invariance is lost due to the presence of the boundary $B$. Instead, we find \nit beneficial not to use those timeslices for which source or sink are closer to $B$ than \na given distance $r_B$, which is tuned as part of the analysis. When \nworking at $t=t_0$ we find the best choice to be $r_B = 6a$, which \nis compatible with the smearing radius $\\sqrt{8t_0} \\approx 6a$.\n\nThe inclusion of $r_B$ in the analysis means that for separations smaller \nthan $2 r_B$ the average is done only when source and sink are in the same \ndomain, either $L$ or $R$. In those cases, we expect no improvement with respect \nto the standard algorithm. For larger distances however, one can choose to have \n$x_0 \\in L$ and $x_0 +r \\in R$, where the better scaling is expected. Notice that \nfor intermediate distances, the average over timeslices would also include terms \nfor which source and sink are in the same domain. These terms would contribute to \nthe error with the usual scaling $1/\\sqrt{N_0N_1}$, so we find the better performance \nwhen they are also not included in the average and we sum only over the factorized \nterms.\n\nWe also look at smaller values of the flow time $t$, in particular we look at a value of \n$t=t_0/10$. Smaller flow times can be of interest if one is looking at obtaining \nthe glueball masses. In such cases, the analysis is the \nsame as described above, but only the value of $r_B$ changes; for example, at \n$t=t_0/10$ we find an optimal value of $r_{B}=3 a$, which is also compatible with \nthe value of the smearing radius.\n\n\\subsection{Performance of the algorithm}\n\nWe apply the strategy described above to compute the $\\widehat{C}_{\\mathcal{O}}$ \nand $C_{\\mathcal{O}}$ correlators for a wide range of separations $r$ between \nsource and sink. To assess the performance of the algorithm, in Fig.~\\ref{fig:ErrorRatio} \nwe plot the ratio between the error of the improved correlator \n$\\widehat{\\sigma}_{\\mathcal{O}}=\\sigma(\\widehat{C}_{\\mathcal{O}})$ and the error \nof the standard correlator $\\sigma_{\\mathcal{O}}$. With the standard algorithm,\nif the statistics are increased by a factor $N_1=40$, the error should scale down \nby a factor $\\sqrt{N_1} \\approx 6.3$. The lower horizontal line in Fig.~\\ref{fig:ErrorRatio} shows \nthe theoretical improvement of the standard algorithm for the same statistics as the \nones we use in our two-level algorithm.  \n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig7_imp.pdf}\n\\caption{Ratio of the errors $\\hat{\\sigma}_{\\mathcal{O}}/\\sigma_{\\mathcal{O}}$ \nas a function of $r$. Open symbols are the results for a flow time $t=t_0/10$, while \nfilled symbols corresponds to the value of $t=t_0$. One can see that the improvement \ncan be split into three distinct regions. For short distances, our algorithm is not as \nefficient as the standard one. For intermediate distances our algorithm is already better \nthan the standard one but does not reach the theoretical maximum improvement, which is \nonly achieved in the large distance regime. The two horizontal lines represent the \ntheoretical maximum improvement of the standard algorithm and the one expected from our algorithm. \n}\\label{fig:ErrorRatio} \\end{figure}\n\nFor the short distance region, we observe an improvement which is below the theoretical \none of the standard algorithm. As explained before, this is expected due to the fact \nthat one can not make full use of translation invariance and the our algorithm is not \ndesigned to be the most efficient for such short distances when the effects of the \nflow are more relevant.\n\nAs soon as $r \\geq 2 r_{B}$ one enters the region where the new algorithm outperforms the standard one. \nThis is expected as for most of these values of $r$ we can make full use of the $N_1 = 40$ nested \nupdates. However, at intermediate distances, we lose due to the lack of translation invariance in \nthe $x_0$ direction. This is precisely what we observe as the improvement rises \ncontinually from $r=2 r_B$ until it reaches the theoretical maximum improvement \nequal to $N_1=40$. For values of $r$ sufficiently large, our algorithm performs as \nexpected and we obtain the theoretical maximum improvement which is shown in \nthe figure by the upper horizontal line. We observe the same qualitative behaviour \nfor different values of the flow time, the only difference being the different \nvalue of $r_B$ which is used in the analysis. Clearly, for smaller values \nof the flow time we are able to outperform the standard algorithm at \neven shorter distances, which could be useful for certain applications.\n\n\n\\subsection{Topological susceptibility}\n\nAs a final test of our proposal, we compute the topological susceptibility $\\chi$ \nat $t=t_0$ and compare it to the result obtained when using the standard algorithm. For the \ncomparison we use the same statistics in both cases, i.e, $N_0N_1 = 15360$ measurements, \nso that the computational effort is roughly the same. \nFor the definition of the susceptibility we use the one in~\\cite{Bruno:2014ova}. To write this \nin terms of our observables, we define $\\overline{C}_q(r)$ as the average of $C_q(x_0,r)$ over \n$x_0$. We proceed as described in the previous section, so for the standard algorithm we average \nover all values of $x_0$, while in the case of the new algorithm we use only those values of $x_0$ \nsuch that source and sink are not closer than $r_B$ to the boundary $B$. Then, we define the \ntopological susceptibility as\n\n\n", "itemtype": "equation", "pos": 16031, "prevtext": "\nwhere $(x,y) \\in L \\times R$. The estimator in Eq.~\\eqref{eq:main} is correct up to \nerrors of order $O(1/\\sqrt{N_0})$, which comes from the fact that $\\Delta$ is only \ncomputed on the $N_0$ standard updates. However, in the next section we show that \nthe fluctuations of $\\Delta$ are exponentially suppressed with the distance \nto the boundary, so that the leading term for the scaling of the error in $\\widehat{C}$ \ncomes from the correlator of the modified flow observables.\n\n\\section{Numerical test of the modified flow observables}\\label{sec:NumericalObs}\n\nTo test our algorithm we work with the $\\mathrm{SU}(3)$ gauge group and a set of gauge\nconfigurations generated with the parameters shown in Table\n\\ref{tab:Ensembles}. The configurations are generated for a value of $\\beta = 6.11$, which \ncorresponds to a lattice spacing of $a \\approx 0.08 \\, \\text{fm}$ and a effective \nsmearing radius $\\sqrt{8 t_0} \\approx 6 a$. Open boundary conditions are used in the time direction\n\\cite{Luscher:2011kk}. We consider two observables, the topological charge density\n$q$ and the Yang-Mills energy density $e$. In particular, we look at the\nconnected two point correlation function of the timeslice summed \n$\\bar{q}$ and $\\bar{e}$\n\n\\begin{table} \n\\centering \n\\begin{tabular}{cccccc} \n\\toprule \n$\\beta$   & $(T/a) \\times (L/a)^3$    & $t_0/a^2$     & $a \\, \\text{[fm]}$ & $N_0$\\\\\n\\midrule $6.11 $  & $80 \\times 20^3$ & $4.5776(15)$   &  $0.078$ & $384$\\\\ \n\\bottomrule \n\\end{tabular} \n\\caption{Lattice\nparameters. We report the lattice bare coupling $\\beta$, the lattice dimensions $L$ and \n$T$, the scale parameter $t_0$ defined in~\\cite{Luscher:2010iy}, the lattice spacing \n$a$ computed using the $r_0 = 0.5 \\, \\text{[fm]}$ scale from \\cite{Necco:2001xg}, and the number of \ngenerated configurations $N_0$.}\n\\label{tab:Ensembles} \\end{table}\n\n\n", "index": 17, "text": "\\begin{align} \nC_q^t(x_0,r) &= \\left\\langle{\\bar{q}^t(x_0) \\bar{q}^t(x_0+r)}\\right\\rangle_C, \n\\qquad\n\\bar{q}^t(x_0) = a^3\\sum_{\\vec{x}} q^t(\\vec{x},x_0)\\\\\n\\nonumber C_e^t(x_0,r) &=\\left\\langle{\\bar{e}^t(x_0) \\bar{e}^t(x_0+r)}\\right\\rangle_C, \n\\qquad \\bar{e}^t(x_0) =a^3 \\sum_{\\vec{x}}e^t(\\vec{x},x_0) \\, ,\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle C_{q}^{t}(x_{0},r)\" display=\"inline\"><mrow><msubsup><mi>C</mi><mi>q</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><mi>r</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left\\langle{\\bar{q}^{t}(x_{0})\\bar{q}^{t}(x_{0}+r)}\\right%&#10;\\rangle_{C},\\qquad\\bar{q}^{t}(x_{0})=a^{3}\\sum_{\\vec{x}}q^{t}(\\vec{x},x_{0})\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><msub><mrow><mo>\u27e8</mo><mrow><msup><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><mi>r</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mi>C</mi></msub></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><msup><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>a</mi><mn>3</mn></msup><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover></munder></mstyle><mrow><msup><mi>q</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle C_{e}^{t}(x_{0},r)\" display=\"inline\"><mrow><msubsup><mi>C</mi><mi>e</mi><mi>t</mi></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><mi>r</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\left\\langle{\\bar{e}^{t}(x_{0})\\bar{e}^{t}(x_{0}+r)}\\right%&#10;\\rangle_{C},\\qquad\\bar{e}^{t}(x_{0})=a^{3}\\sum_{\\vec{x}}e^{t}(\\vec{x},x_{0})\\,,\" display=\"inline\"><mrow><mrow><mrow><mi/><mo>=</mo><msub><mrow><mo>\u27e8</mo><mrow><msup><mover accent=\"true\"><mi>e</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mover accent=\"true\"><mi>e</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><mi>r</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mi>C</mi></msub></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mrow><msup><mover accent=\"true\"><mi>e</mi><mo stretchy=\"false\">\u00af</mo></mover><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>a</mi><mn>3</mn></msup><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover></munder></mstyle><mrow><msup><mi>e</mi><mi>t</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo stretchy=\"false\">\u2192</mo></mover><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $r_{\\mathrm{cut}}$ should be chosen so that the statistical error in the sum is larger than the \nestimated systematic error from cutting the sumation. We are not so interested in \nchoosing the best value of $r_{\\mathrm{cut}}$ but more on comparing the performance of the \ntwo-level algorithm with respect to the standard one. \n\nIn Table~\\ref{tab:Suscept} we show the results at three different values of $r_{\\mathrm{cut}}$ using \nboth the standard algorithm and the new nested Monte Carlo algorithm that we propose in \nthis paper. As already pointed out in the introduction, with the traditional approach, \nsumming up the correlator to large values of $r_{\\mathrm{cut}}$ only increases the error \nwhile the signal remains relatively constant~\\cite{Bazavov:2010xr,Bruno:2014ova}. We \nclearly observe this effect in our data when using the standard method. On the other \nhand, the error when using our algorithm remains relatively constant when the \nvalue of $r_{\\mathrm{cut}}$ is increased from values of $0.85 \\, \\text{fm}$ up to $4.19 \\, \\text{fm}$. \nIn fact, for the largest value of $r_{\\mathrm{cut}}$, the improvement when using our algorithm \nis more than twofold, corresponding to an increase in statistics by a factor $5$.\n\n\\begin{table}\n  \\centering\n  \\begin{tabular}{cccc}\n    \\toprule\n     $r_{\\mathrm{cut}}/\\sqrt{t_0}$ & $r_{\\mathrm{cut}}\\, \\text{[fm]}$ & Standard &  New \\\\\n    \\midrule\n     $5.1$  & $0.85$ & $6.405(46)$  & $6.347(60)$  \\\\ \n     $15.4$ & $2.56$ & $6.507(94)$  & $6.291(61)$ \\\\\n     $25.2$ & $4.19$ & $6.518(164)$ & $6.254(69)$ \\\\\n    \\bottomrule\n  \\end{tabular} \n  \\caption{Results for the topological susceptibility $10^4 t_0^2 \\, \\chi(r_{\\mathrm{cut}})$ \n  using the standard algorithm and the new algorithm that we propose in this paper. \n  The values of $r_{\\mathrm{cut}}$ in physical units were computed using the $r_0$ scale \n  from \\cite{Necco:2001xg}.}  \n  \\label{tab:Suscept}\n\\end{table}\n\n\n\\section{Conclusion}\n\nIn this paper we have studied a multi-level algorithm for computing the two point\ncorrelation function of flow observables. It is based on the\nidea originally introduced in~\\cite{Luscher:2001up}. \nBasically, we split the lattice into two sub-volumes separated by a boundary $B$ and \nuse the locality of the action to perform independent updates on each of them. \nSuch an approach would not work for observables at positive flow time, so we slightly \nmodify the flow equations to build a ``good'' approximation of the original observable \nwhich can be factorized as required for a multi-level type scheme to \nwork. \n\nIn this type of algorithms one starts by performing $N_0$ standard updates \nfollowed by $N_1$ nested updates for each of the original $N_0$ generated \nconfigurations. In the ideal case one expects the scaling of the error to be \nproportional to $1/N_1$ instead of the standard $1/\\sqrt{N_1}$. We put this \nto the test and for the case of the connected two point correlation function \n$\\left\\langle{\\mathcal{O}(x)\\mathcal{O}(y)}\\right\\rangle - \\left\\langle{\\mathcal{O}(x)}\\right\\rangle\\left\\langle{\\mathcal{O}(y)}\\right\\rangle$ \nwe find that our algorithm outperforms the standard one when $x$ and $y$ are \nfar from the boundary $B$ in units of $1/m_0$ and of the flow radius $\\sqrt{8t}$, \nwhere $m_0$ is the lightest mass compatible with the observable $\\mathcal{O}$. \nIn the case of short separations our algorithm \nis not better than the standard one, which is expected from the way \nthe observables are constructed. \n\nWe also showed that our algorithm can be used to obtain a better lattice \ndetermination of the topological susceptibility $\\chi$, where the \nlarge statistical errors coming from the tail of the correlator are tamed. \nWith our choice of parameters, we observe a decrease of errors by a factor \nlarger than two for the same statistics as the standard algorithm, which would \ncorrespond to a fivefold decrease of the computational time required for a \nfixed target error.\n\nAlthough we performed our analysis with the Yang-Mills energy density $e$ and the \ntopological charge $q$, the idea can be applied to any correlation \nfunction of flow observables in the lattice Yang-Mills gauge theory. Also, the idea \nthat we presented in this paper can be generalized to a four dimensional approach in \nwhich the decomposition is not limited to the time direction. In that case we expect \nan even better performance of the algorithm.\n\n\\begin{acknowledgement}\nWe are very thankful to R. Sommer for extensive discussions. \nWe also would like to thank L. Giusti, M. C\\`e and D. Banerjee \nfor discussions related to multi-level algorithms. \nOur simulations were performed at the ZIB computer center with the \ncomputer resources granted by The North-German \nSupercomputing Alliance (HLRN). M.G.V acknowledges the \nsupport from the Research Training Group GRK1504/2 ``Mass, Spectrum, Symmetry'' \nfounded by the German Research Foundation (DFG). \n\n\\end{acknowledgement}\n\n\n\n\n\n\\begin{appendices}\n\\section{Error reduction}\\label{sec:Appendix}\n\nIn a two-level nested Monte Carlo algorithm as the one described in the main text, we are \ninterested in the scaling of errors with \nrespect to $N_0$ and $N_1$. In particular, we look at the case of the two point \ncorrelator\n\n\n", "itemtype": "equation", "pos": 33589, "prevtext": "\nwhere we have left the $x_0$ dependence explicit in order to keep track of the\ndistance to the boundary $B$, which is chosen to be the subset of spatial links with \ntime coordinate $x^B_0=T/2$. All computations are done in such a way that both $x_0$ \nand $x_0 + r$ are placed far enough from the open boundaries. From now on we \nshall use $\\mathcal{O}$ to refer to either $q$ or $e$ when there is no need to make a \ndistinction between them.\n\nWe use the 384 independent configurations to study the dependence of the fluctuations \nof $\\Delta$ on both $x_0$ and $r$. First we consider the correlators which are\nsymmetric with respect to $B$, so we choose a source which is placed at the value \nof $x_0 = (T -r)/2$. In this case, the correlator is only a function of \n$r$ and given by $C_{\\mathcal{O}}(r) = C_{\\mathcal{O}}\\left(\\left(T-r\\right)/2,r\\right)$.\n\nFig.~\\ref{fig:Errors_Delta_r} shows the dependence of the error of both\n$C_{\\mathcal{O}}(r)$ and $\\Delta_{\\mathcal{O}}(r)$ for a \nfixed value of the flow time $t=t_0$. The errors are computed by measuring the autocorrelation \nfunction as described in \\cite{Wolff:2003sm}. As a reference, the dotted vertical line indicates\nthe value of $r$ for which the fluctuations in $\\Delta$ are below 5\\% of those\nof the observable. As will be discussed in Sect.~\\ref{sec:Parameters_choice}, \nthe fact that the ratio between the fluctuations of the observable and those of the \ncorrection term decrease at large distances contributes to the fact that the \nalgorithm is efficient up to very large values of $N_1$.\n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig1_sigma_delta_log.pdf}\n\\caption{Statistical error $\\sigma$ of $\\Delta_{\\mathcal{O}}$ and $C_{\\mathcal{O}}$ at flow time\n$t=t_0$. For both observables, $\\bar{e}$ and $\\bar{q}$, the error in the correlator is independent \nof the distance $r$, but the errors of $\\Delta$ seem to decay at least exponentially with the \ndistance. The dotted vertical is added as a reference to show the value of $r$ for which \nthe errors in $\\Delta_{\\mathcal{O}}$ are below 5\\% those of $C_{\\mathcal{O}}$. \nErrors are smaller than the data markers.}\\label{fig:Errors_Delta_r} \\end{figure}\n\nSince the effective smearing radius produced by the flow grows as $\\sqrt{t}$, the\neffect of freezing the boundary links at $B$ increases monotonically with the\nflow time. We have observed this behaviour in our data, but we are more \ninterested in the behaviour of the correlation functions at the reference flow scale \n$t =t_0$. For different values of the flow, a similar analysis can be performed. \nHowever, it is clear that if the fluctuations of $\\Delta$ are ``small'' for a given \nvalue of $t'$, they are also small for $t < t'$.\n\nNext, we go beyond the symmetric case and look at the $x_0$ dependence of $\\Delta$.\nFig.~\\ref{fig:Errors_Delta_x0} shows a plot of the errors in $\\Delta$ as a function of\n$x_0$ for two fixed values of $r$ at $t=t_0$. \n\nNotice that the effect of the flow is that of a Gaussian smearing, so we should \nexpect that the errors in $\\Delta$ decay at least exponentially with the distance \nto the boundary $B$. Both Figs.~\\ref{fig:Errors_Delta_r} \nand~\\ref{fig:Errors_Delta_x0} show a behaviour which is compatible with this statement.\n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig3_sigma_delta_log.pdf} \n\\caption{Statistical error $\\sigma$ of $\\Delta_{\\mathcal{O}}$ as a function of $x_0$ \nfor two values of $r$ at flow time $t=t_0$. Open symbols correspond to a value of \n$r=20 a$, while filled symbols to a value of $r = 28 a$. The smallest error corresponds \nto the symmetric point in which both source and sink are placed far from the boundary. \nErrors are smaller than the data markers.}\\label{fig:Errors_Delta_x0}\\end{figure}\n\nThe results presented in this section show that using the modified flow\nequations has little impact in the two point function, and the effect can be\nincorporated in the correction term $\\Delta$. When using equation\n\\eqref{eq:main} it is important to tune the value of $N_0$ and $N_1$ in such a\nway that the effect of $\\Delta$ remains under control. In particular, due to\nthe exponential smoothing of the flow, $N_1$ can be chosen larger at larger\nvalues of $r$, which is precisely where a higher precision is required.\n\n\n\\section{Results}\\label{sec:Results}\n\nWe consider the ensemble in Table \\ref{tab:Ensembles} and for each of the $N_0$\nconfigurations we perform $N_1 = 40$ Monte Carlo updates while keeping $B$\nfixed. The updates are separated by 60 sweeps, where one sweep is composed of \n8 over-relaxation updates followed by 1 heat-bath update. \nBoth updates are performed using the Cabibbo-Marinari technique \napplied to three $\\mathrm{SU}(2)$ subgroups~\\cite{Cabibbo:1982zn,Brown:1987rra}.\n\nIn the following we present our findings concerning the scaling of the \nerrors with respect to $N_1$ and show the application of our algorithm \nfor the computation of the two point correlation function over the whole range \nof distances allowed in our finite size lattice. The limitations of the method \nare also discussed. We conclude this section by using our method to compute the \ntopological susceptibility and compare it to the result obtained with the standard \nalgorithm.\n\n\\subsection{Autocorrelation times}\n\nAn interesting question to explore is whether or not an undesirable growth of \nthe autocorrelations is introduced due to the freezing of the boundary $B$. Such an \neffect could have an impact on the cost of the measurement in our nested Monte Carlo \nscheme. To investigate that, we look at the integrated autocorrelation \ntime $\\tau_{\\mathrm{int}}$ of $\\mathcal{O}(x_0)$ as a function of the time coordinate $x_0$.\nGiven that the $N_0$ standard updates are completely decorrelated, the relevant \nautocorrelation function is given by the average over $N_0$ of the autocorrelation \nfunction for the $N_1$ nested updates,\n$\\widetilde{\\Gamma}(t) = \\frac{1}{N_0} \\sum_{i=1}^{N_0} \\Gamma^i(t)$. Where $\\Gamma^i(t)$ is \nprecisely the autocorrelation function for each of the nested chains. \n\nNow, $\\tau_{\\mathrm{int}}$ can be defined in the usual way~\\cite{Wolff:2003sm} in \nterms of the average autocorrelation function $\\widetilde{\\Gamma}(t)$. Our data \nshows that $\\tau_{\\mathrm{int}}$ increases at most by a factor of $1.5$ when \nthe observables approach the boundary $B$, so there is not a significant effect. \nHowever, on different observables, it could have a more severe impact which \nthen must be taken into account when spacing the $N_1$ nested updates and \ncalculating the cost of the simulation.\n\n\\subsection{Choice of the parameters}\\label{sec:Parameters_choice}\n\nThe introduction of the nested updates adds an extra parameter to be \ntuned in the algorithm, as the parameter $N_1$ can be chosen to minimize \nthe errors at a given computational effort. We argue that for the connected \ncorrelator $\\widehat{C}_{\\mathcal{O}}$, when source and sink are placed far away \nfrom the boundary, the value of $N_1$ up to which the algorithm is efficient can \nbe scaled exponentially with respect to the distance to $B$. \n\nTo show this, in appendix~\\ref{sec:Appendix} we \nhave looked into the scaling of errors with respect to $N_0$ and $N_1$ in a \nMonte Carlo simulation. Our results show that the leading contribution to the \nerror in the connected correlator scales as $1/\\sqrt{N_0}N_1$, which corresponds \nto the ideal case, but additionally there are other terms that scale as $1/\\sqrt{N_0N_1}$ and as \n$1/\\sqrt{N_0}$. Such terms however, are exponentially suppressed as $e^{-m_0|x^M_0 - x^B_0|}$, \nwhere $x^M_0$ is the time coordinate of either source or sink, whichever is the closest to \nthe boundary, and $m_0$ is the mass of the lightest mode which is compatible with \nthe symmetries of $\\mathcal{O}$. This means that we can expect the ideal scaling up to very large \nvalues of $N_1$ given that source and sink are far away from the boundary in units of $1/m_0$.\n\nAnother effect that must be taken into account is the presence of the correction \nterm $\\Delta$. Such term is measured only over the $N_0$ standard updates, so that \nits error should scale in the standard way as $1/\\sqrt{N_0}$. This will add another \nterm which is independent of $N_1$ to the final error. We can see from  \nour results in Fig.~\\ref{fig:Errors_Delta_x0} that for a fixed $N_0$, the error in $\\Delta$ decays \nat least exponentially fast with the distance of either source or sink to the boundary \n$B$. This means that for the final estimator $\\widehat{C}$, the value of $N_1$ can \nbe scaled exponentially with the distance to the boundary as long as \n$|x^M_0 - x^B_0|$ is larger than the relevant scale, either $1/m_0$ for the effects coming \nfrom $\\widetilde{C}$ or $\\sqrt{8t}$ for those coming from $\\Delta$.\n\n\\subsection{$N_1$ dependence of the error}\\label{sec:Scaling_errors}\n\nTo show the way in which our algorithm improves over the standard one, we\nmeasure the scaling of errors with respect to $N_1$ for the symmetric\ncorrelator. The results for two different values of $r$ are shown in Fig.~\\ref{fig:Scaling_errors}. \nFor the larger $r = 28 a$, and for $N_1=40$, we \nare still in the regime where the ideal scaling is the dominant one, so on \nthe left subplot we see an scaling of the error which is compatible with \n$1/N_1$ for the whole range of $N_1$ values.\n\nFor the smaller value of $r = 14 a$, in particular when looking at the case \nof $\\widehat{C}_e$, we observe that for $N_1 \\gtrsim 6$ the error improves only \nmarginally with $N_1$, which means that we are already in the regime where the \nterm independent of $N_1$ becomes relevant. This supports the discussion of the \nprevious section and shows that for small values of $r$ \nthere is no significant improvement by performing a very large number of $N_1$ nested Monte Carlo \nupdates. In practice, one can use all the $N_1$ generated nested updates for all \nvalues of $r$, but for small separations, the effect of using all of them \nis not significative. \n\nFor a given $N_0$ and $N_1$, the value of $r$ at which the ideal scaling is not \nvalid anymore is observable dependent and so it has to be studied on a case by case basis. \nIn our particular case, we observe that for $N_1 =40$ we are on the ideal scaling \nregime for the correlator at distances starting at values of \n$r = 16 a = 7.5 \\sqrt{t_0}$ at a flow time $t=t_0$. \n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig5_scaling_log.pdf}\n\\caption{Scaling of the error of $\\widehat{C}_{\\mathcal{O}}$ as a function of \n$N_1$. On the left for a value of $r= 28 a = 13.2 \\sqrt{t_0}$ and on the right for a \nvalue of $r=14 a = 6.6 \\sqrt{t_0}$. The solid line indicates a scaling of the \nerror proportional to $1/N_1$, while the dotted line corresponds to the standard \n$1/\\sqrt{N_1}$ scaling. For the smaller value of $r$ (right plot), \nwe observe a saturation in the number of effective $N_1$ nested updates that \ncan be used to reduce the errors. In fact, after $N_1 \\approx 6$ we observe no \nsignificant improvement. }\\label{fig:Scaling_errors} \\end{figure}\n\n\n\\subsection{Application of the algorithm}\\label{sec:Application_algo}\n\nTo show how the algorithm performs for the whole range of distances in the \ntwo point correlator, we compute $C_q$ and $C_e$ using the standard\nalgorithm and using our nested Monte Carlo scheme. \nFor each value of $r$ and $x_0$ we compute $C_{\\mathcal{O}}$ and $\\widehat{C}_{\\mathcal{O}}$. \nWe use the $N_0=384$ standard updates to compute $C_{\\mathcal{O}}$ in the usual way. For \nour nested algorithm we employ the $N_1=40$ nested updates for each of the standard ones. \n\nWhen using the standard approach, the correlator at distance $r$ is computed by averaging \nover all the $x_0$ values in the plateau region. In the case of our algorithm this is  not the best strategy, \nas translation invariance is lost due to the presence of the boundary $B$. Instead, we find \nit beneficial not to use those timeslices for which source or sink are closer to $B$ than \na given distance $r_B$, which is tuned as part of the analysis. When \nworking at $t=t_0$ we find the best choice to be $r_B = 6a$, which \nis compatible with the smearing radius $\\sqrt{8t_0} \\approx 6a$.\n\nThe inclusion of $r_B$ in the analysis means that for separations smaller \nthan $2 r_B$ the average is done only when source and sink are in the same \ndomain, either $L$ or $R$. In those cases, we expect no improvement with respect \nto the standard algorithm. For larger distances however, one can choose to have \n$x_0 \\in L$ and $x_0 +r \\in R$, where the better scaling is expected. Notice that \nfor intermediate distances, the average over timeslices would also include terms \nfor which source and sink are in the same domain. These terms would contribute to \nthe error with the usual scaling $1/\\sqrt{N_0N_1}$, so we find the better performance \nwhen they are also not included in the average and we sum only over the factorized \nterms.\n\nWe also look at smaller values of the flow time $t$, in particular we look at a value of \n$t=t_0/10$. Smaller flow times can be of interest if one is looking at obtaining \nthe glueball masses. In such cases, the analysis is the \nsame as described above, but only the value of $r_B$ changes; for example, at \n$t=t_0/10$ we find an optimal value of $r_{B}=3 a$, which is also compatible with \nthe value of the smearing radius.\n\n\\subsection{Performance of the algorithm}\n\nWe apply the strategy described above to compute the $\\widehat{C}_{\\mathcal{O}}$ \nand $C_{\\mathcal{O}}$ correlators for a wide range of separations $r$ between \nsource and sink. To assess the performance of the algorithm, in Fig.~\\ref{fig:ErrorRatio} \nwe plot the ratio between the error of the improved correlator \n$\\widehat{\\sigma}_{\\mathcal{O}}=\\sigma(\\widehat{C}_{\\mathcal{O}})$ and the error \nof the standard correlator $\\sigma_{\\mathcal{O}}$. With the standard algorithm,\nif the statistics are increased by a factor $N_1=40$, the error should scale down \nby a factor $\\sqrt{N_1} \\approx 6.3$. The lower horizontal line in Fig.~\\ref{fig:ErrorRatio} shows \nthe theoretical improvement of the standard algorithm for the same statistics as the \nones we use in our two-level algorithm.  \n\n\\begin{figure} \\includegraphics[width=\\textwidth]{Fig7_imp.pdf}\n\\caption{Ratio of the errors $\\hat{\\sigma}_{\\mathcal{O}}/\\sigma_{\\mathcal{O}}$ \nas a function of $r$. Open symbols are the results for a flow time $t=t_0/10$, while \nfilled symbols corresponds to the value of $t=t_0$. One can see that the improvement \ncan be split into three distinct regions. For short distances, our algorithm is not as \nefficient as the standard one. For intermediate distances our algorithm is already better \nthan the standard one but does not reach the theoretical maximum improvement, which is \nonly achieved in the large distance regime. The two horizontal lines represent the \ntheoretical maximum improvement of the standard algorithm and the one expected from our algorithm. \n}\\label{fig:ErrorRatio} \\end{figure}\n\nFor the short distance region, we observe an improvement which is below the theoretical \none of the standard algorithm. As explained before, this is expected due to the fact \nthat one can not make full use of translation invariance and the our algorithm is not \ndesigned to be the most efficient for such short distances when the effects of the \nflow are more relevant.\n\nAs soon as $r \\geq 2 r_{B}$ one enters the region where the new algorithm outperforms the standard one. \nThis is expected as for most of these values of $r$ we can make full use of the $N_1 = 40$ nested \nupdates. However, at intermediate distances, we lose due to the lack of translation invariance in \nthe $x_0$ direction. This is precisely what we observe as the improvement rises \ncontinually from $r=2 r_B$ until it reaches the theoretical maximum improvement \nequal to $N_1=40$. For values of $r$ sufficiently large, our algorithm performs as \nexpected and we obtain the theoretical maximum improvement which is shown in \nthe figure by the upper horizontal line. We observe the same qualitative behaviour \nfor different values of the flow time, the only difference being the different \nvalue of $r_B$ which is used in the analysis. Clearly, for smaller values \nof the flow time we are able to outperform the standard algorithm at \neven shorter distances, which could be useful for certain applications.\n\n\n\\subsection{Topological susceptibility}\n\nAs a final test of our proposal, we compute the topological susceptibility $\\chi$ \nat $t=t_0$ and compare it to the result obtained when using the standard algorithm. For the \ncomparison we use the same statistics in both cases, i.e, $N_0N_1 = 15360$ measurements, \nso that the computational effort is roughly the same. \nFor the definition of the susceptibility we use the one in~\\cite{Bruno:2014ova}. To write this \nin terms of our observables, we define $\\overline{C}_q(r)$ as the average of $C_q(x_0,r)$ over \n$x_0$. We proceed as described in the previous section, so for the standard algorithm we average \nover all values of $x_0$, while in the case of the new algorithm we use only those values of $x_0$ \nsuch that source and sink are not closer than $r_B$ to the boundary $B$. Then, we define the \ntopological susceptibility as\n\n\n", "index": 19, "text": "\\begin{equation}\\label{eq:chi_corr_def}\n \\chi(r_{\\mathrm{cut}}) =  \\frac{a}{L^3} \n \\sum_{z_0=-r_{\\mathrm{cut}}}^{r_{\\mathrm{cut}}}  \\overline{C}_q(|z_0|) \\, ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\chi(r_{\\mathrm{cut}})=\\frac{a}{L^{3}}\\sum_{z_{0}=-r_{\\mathrm{cut}}}^{r_{%&#10;\\mathrm{cut}}}\\overline{C}_{q}(|z_{0}|)\\,,\" display=\"block\"><mrow><mrow><mrow><mi>\u03c7</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>r</mi><mi>cut</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mi>a</mi><msup><mi>L</mi><mn>3</mn></msup></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><msub><mi>z</mi><mn>0</mn></msub><mo>=</mo><mrow><mo>-</mo><msub><mi>r</mi><mi>cut</mi></msub></mrow></mrow><msub><mi>r</mi><mi>cut</mi></msub></munderover><mrow><msub><mover accent=\"true\"><mi>C</mi><mo>\u00af</mo></mover><mi>q</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mo stretchy=\"false\">|</mo><msub><mi>z</mi><mn>0</mn></msub><mo stretchy=\"false\">|</mo></mrow><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $\\mathcal{O}(x_0) \\in L$ and $\\mathcal{O}(x_0) \\in R$. To simplify the notation \nwe write $\\mathcal{O} \\equiv \\mathcal{O}(x_0)$ and $\\mathcal{O'} \\equiv \\mathcal{O}(y_0)$.\n\nIn a Monte Carlo simulation, an estimator for $A$ is given by\n\n\n", "itemtype": "equation", "pos": 39006, "prevtext": "\nwhere $r_{\\mathrm{cut}}$ should be chosen so that the statistical error in the sum is larger than the \nestimated systematic error from cutting the sumation. We are not so interested in \nchoosing the best value of $r_{\\mathrm{cut}}$ but more on comparing the performance of the \ntwo-level algorithm with respect to the standard one. \n\nIn Table~\\ref{tab:Suscept} we show the results at three different values of $r_{\\mathrm{cut}}$ using \nboth the standard algorithm and the new nested Monte Carlo algorithm that we propose in \nthis paper. As already pointed out in the introduction, with the traditional approach, \nsumming up the correlator to large values of $r_{\\mathrm{cut}}$ only increases the error \nwhile the signal remains relatively constant~\\cite{Bazavov:2010xr,Bruno:2014ova}. We \nclearly observe this effect in our data when using the standard method. On the other \nhand, the error when using our algorithm remains relatively constant when the \nvalue of $r_{\\mathrm{cut}}$ is increased from values of $0.85 \\, \\text{fm}$ up to $4.19 \\, \\text{fm}$. \nIn fact, for the largest value of $r_{\\mathrm{cut}}$, the improvement when using our algorithm \nis more than twofold, corresponding to an increase in statistics by a factor $5$.\n\n\\begin{table}\n  \\centering\n  \\begin{tabular}{cccc}\n    \\toprule\n     $r_{\\mathrm{cut}}/\\sqrt{t_0}$ & $r_{\\mathrm{cut}}\\, \\text{[fm]}$ & Standard &  New \\\\\n    \\midrule\n     $5.1$  & $0.85$ & $6.405(46)$  & $6.347(60)$  \\\\ \n     $15.4$ & $2.56$ & $6.507(94)$  & $6.291(61)$ \\\\\n     $25.2$ & $4.19$ & $6.518(164)$ & $6.254(69)$ \\\\\n    \\bottomrule\n  \\end{tabular} \n  \\caption{Results for the topological susceptibility $10^4 t_0^2 \\, \\chi(r_{\\mathrm{cut}})$ \n  using the standard algorithm and the new algorithm that we propose in this paper. \n  The values of $r_{\\mathrm{cut}}$ in physical units were computed using the $r_0$ scale \n  from \\cite{Necco:2001xg}.}  \n  \\label{tab:Suscept}\n\\end{table}\n\n\n\\section{Conclusion}\n\nIn this paper we have studied a multi-level algorithm for computing the two point\ncorrelation function of flow observables. It is based on the\nidea originally introduced in~\\cite{Luscher:2001up}. \nBasically, we split the lattice into two sub-volumes separated by a boundary $B$ and \nuse the locality of the action to perform independent updates on each of them. \nSuch an approach would not work for observables at positive flow time, so we slightly \nmodify the flow equations to build a ``good'' approximation of the original observable \nwhich can be factorized as required for a multi-level type scheme to \nwork. \n\nIn this type of algorithms one starts by performing $N_0$ standard updates \nfollowed by $N_1$ nested updates for each of the original $N_0$ generated \nconfigurations. In the ideal case one expects the scaling of the error to be \nproportional to $1/N_1$ instead of the standard $1/\\sqrt{N_1}$. We put this \nto the test and for the case of the connected two point correlation function \n$\\left\\langle{\\mathcal{O}(x)\\mathcal{O}(y)}\\right\\rangle - \\left\\langle{\\mathcal{O}(x)}\\right\\rangle\\left\\langle{\\mathcal{O}(y)}\\right\\rangle$ \nwe find that our algorithm outperforms the standard one when $x$ and $y$ are \nfar from the boundary $B$ in units of $1/m_0$ and of the flow radius $\\sqrt{8t}$, \nwhere $m_0$ is the lightest mass compatible with the observable $\\mathcal{O}$. \nIn the case of short separations our algorithm \nis not better than the standard one, which is expected from the way \nthe observables are constructed. \n\nWe also showed that our algorithm can be used to obtain a better lattice \ndetermination of the topological susceptibility $\\chi$, where the \nlarge statistical errors coming from the tail of the correlator are tamed. \nWith our choice of parameters, we observe a decrease of errors by a factor \nlarger than two for the same statistics as the standard algorithm, which would \ncorrespond to a fivefold decrease of the computational time required for a \nfixed target error.\n\nAlthough we performed our analysis with the Yang-Mills energy density $e$ and the \ntopological charge $q$, the idea can be applied to any correlation \nfunction of flow observables in the lattice Yang-Mills gauge theory. Also, the idea \nthat we presented in this paper can be generalized to a four dimensional approach in \nwhich the decomposition is not limited to the time direction. In that case we expect \nan even better performance of the algorithm.\n\n\\begin{acknowledgement}\nWe are very thankful to R. Sommer for extensive discussions. \nWe also would like to thank L. Giusti, M. C\\`e and D. Banerjee \nfor discussions related to multi-level algorithms. \nOur simulations were performed at the ZIB computer center with the \ncomputer resources granted by The North-German \nSupercomputing Alliance (HLRN). M.G.V acknowledges the \nsupport from the Research Training Group GRK1504/2 ``Mass, Spectrum, Symmetry'' \nfounded by the German Research Foundation (DFG). \n\n\\end{acknowledgement}\n\n\n\n\n\n\\begin{appendices}\n\\section{Error reduction}\\label{sec:Appendix}\n\nIn a two-level nested Monte Carlo algorithm as the one described in the main text, we are \ninterested in the scaling of errors with \nrespect to $N_0$ and $N_1$. In particular, we look at the case of the two point \ncorrelator\n\n\n", "index": 21, "text": "\\begin{equation*}\nA = \\left\\langle{\\mathcal{O}(x_0) \\mathcal{O}(y_0)}\\right\\rangle \\, ,\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"A=\\left\\langle{\\mathcal{O}(x_{0})\\mathcal{O}(y_{0})}\\right\\rangle\\,,\" display=\"block\"><mrow><mrow><mi>A</mi><mo>=</mo><mrow><mo>\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"4.2pt\">\u27e9</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nThe error $\\sigma^2_A$ on the estimator is then computed in the usual way\n\n\n", "itemtype": "equation", "pos": 39352, "prevtext": "\nwhere $\\mathcal{O}(x_0) \\in L$ and $\\mathcal{O}(x_0) \\in R$. To simplify the notation \nwe write $\\mathcal{O} \\equiv \\mathcal{O}(x_0)$ and $\\mathcal{O'} \\equiv \\mathcal{O}(y_0)$.\n\nIn a Monte Carlo simulation, an estimator for $A$ is given by\n\n\n", "index": 23, "text": "\\begin{equation}\\label{eq:A_estimator}\n\\hat{A} = \\frac{1}{N_0} \\sum_{i=1}^{N_0} \\frac{1}{N^2_1} \\sum_{j=1}^{N_1} \\sum_{k=1}^{N_1} \n\\mathcal{O}^{ij} \\mathcal{O'}^{ik} \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\hat{A}=\\frac{1}{N_{0}}\\sum_{i=1}^{N_{0}}\\frac{1}{N^{2}_{1}}\\sum_{j=1}^{N_{1}}%&#10;\\sum_{k=1}^{N_{1}}\\mathcal{O}^{ij}\\mathcal{O^{\\prime}}^{ik}\\,.\" display=\"block\"><mrow><mrow><mover accent=\"true\"><mi>A</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>0</mn></msub></munderover><mrow><mfrac><mn>1</mn><msubsup><mi>N</mi><mn>1</mn><mn>2</mn></msubsup></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></munderover><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mn>1</mn></msub></munderover><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mrow><mi>i</mi><mo>\u2062</mo><mi>j</mi></mrow></msup><mo>\u2062</mo><mpadded width=\"+1.7pt\"><mmultiscripts><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><none/><mo>\u2032</mo><none/><mrow><mi>i</mi><mo>\u2062</mo><mi>k</mi></mrow></mmultiscripts></mpadded></mrow></mrow></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $\\left\\langle{~}\\right\\rangle_{LBR}$ stands for the average over all the gauge links in \n$L \\cup B \\cup R$, and $\\bar{A}= \\left\\langle{\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R}\\right\\rangle_B$ \nis the real expectation value of $A$. \n\nBy inserting $\\hat{A}$ from Eq.~\\eqref{eq:A_estimator} into Eq.~\\eqref{eq:A_error} \nand using the fact that the $N_0$ updates are independent one obtains\n\n\n", "itemtype": "equation", "pos": 39613, "prevtext": "\nThe error $\\sigma^2_A$ on the estimator is then computed in the usual way\n\n\n", "index": 25, "text": "\\begin{equation}\\label{eq:A_error}\n\\sigma^2_A = \\left\\langle{\\left(\\hat{A} - \\bar{A}\\right)^2}\\right\\rangle_{LBR} \\, ,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\sigma^{2}_{A}=\\left\\langle{\\left(\\hat{A}-\\bar{A}\\right)^{2}}\\right\\rangle_{%&#10;LBR}\\,,\" display=\"block\"><mrow><mrow><msubsup><mi>\u03c3</mi><mi>A</mi><mn>2</mn></msubsup><mo>=</mo><mpadded width=\"+1.7pt\"><msub><mrow><mo>\u27e8</mo><msup><mrow><mo>(</mo><mrow><mover accent=\"true\"><mi>A</mi><mo stretchy=\"false\">^</mo></mover><mo>-</mo><mover accent=\"true\"><mi>A</mi><mo stretchy=\"false\">\u00af</mo></mover></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>\u27e9</mo></mrow><mrow><mi>L</mi><mo>\u2062</mo><mi>B</mi><mo>\u2062</mo><mi>R</mi></mrow></msub></mpadded></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\nwhere $\\text{Var}_L\\left(\\mathcal{O}\\right) = \\left[\\mathcal{O}^2\\right]_L - \\left[\\mathcal{O}\\right]_L^2$ and \nsimilarly for $\\text{Var}_R \\left(\\mathcal{O'}\\right)$. By looking at Eq.~\\eqref{eq:A_scaling} \nit is clear that the error scales not only as the ideal case $1/\\sqrt{N_0}N_1$, but it has \nalso subleading contributions.\n\nNote however, that using the transfer matrix formalism, one can show that the second \nterm proportional to $1/N_0$ is exponentially suppresed as $e^{-m_0 | x^B_0 - x^M_0|}$, \nwhere $m_0$ is the mass of the lightest state compatible with the \nsymmetries of $\\mathcal{O}$ and $x^M_0$ corresponds to $x_0$ or $y_0$, whichever \nis the closest to $x^B_0$. \n\nThe third term is also exponentially suppressed if one considers the case of \nthe connected correlator \n\n\n", "itemtype": "equation", "pos": 40156, "prevtext": "\nwhere $\\left\\langle{~}\\right\\rangle_{LBR}$ stands for the average over all the gauge links in \n$L \\cup B \\cup R$, and $\\bar{A}= \\left\\langle{\\left[\\mathcal{O}\\right]_L \\left[\\mathcal{O'}\\right]_R}\\right\\rangle_B$ \nis the real expectation value of $A$. \n\nBy inserting $\\hat{A}$ from Eq.~\\eqref{eq:A_estimator} into Eq.~\\eqref{eq:A_error} \nand using the fact that the $N_0$ updates are independent one obtains\n\n\n", "index": 27, "text": "\\begin{multline}\\label{eq:A_scaling}\n\\sigma^2_A = \\frac{1}{N_0 N^2_1} \\left\\langle{\\text{Var}_L\\left(\\mathcal{O}\\right)\\text{Var}_R\\left(\\mathcal{O'}\\right)}\\right\\rangle_B\n+ \\frac{1}{N_0} \\left( \\left\\langle{\\left[\\mathcal{O}\\right]^2_L \\left[\\mathcal{O}'\\right]^2_R}\\right\\rangle_B - \\bar{A}^2 \\right) +\\\\\n+\\frac{1}{N_0 N_1} \\left( \\left\\langle{\\text{Var}_L\\left(\\mathcal{O}\\right) \\left[\\mathcal{O}'\\right]^2_R + \\text{Var}_R\\left(\\mathcal{O}'\\right) \\left[\\mathcal{O}^{~}\\right]^2_L}\\right\\rangle_B   \\right)\\, ,\n\\end{multline}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sigma^{2}_{A}=\\frac{1}{N_{0}N^{2}_{1}}\\left\\langle{\\text{Var}_{L%&#10;}\\left(\\mathcal{O}\\right)\\text{Var}_{R}\\left(\\mathcal{O^{\\prime}}\\right)}%&#10;\\right\\rangle_{B}+\\frac{1}{N_{0}}\\left(\\left\\langle{\\left[\\mathcal{O}\\right]^{%&#10;2}_{L}\\left[\\mathcal{O}^{\\prime}\\right]^{2}_{R}}\\right\\rangle_{B}-\\bar{A}^{2}%&#10;\\right)+\\\\&#10;\\displaystyle+\\frac{1}{N_{0}N_{1}}\\left(\\left\\langle{\\text{Var}_{L}\\left(%&#10;\\mathcal{O}\\right)\\left[\\mathcal{O}^{\\prime}\\right]^{2}_{R}+\\text{Var}_{R}%&#10;\\left(\\mathcal{O}^{\\prime}\\right)\\left[\\mathcal{O}\\right]^{2}_{L}}\\right%&#10;\\rangle_{B}\\right)\\,,\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msubsup><mi>\u03c3</mi><mi>A</mi><mn>2</mn></msubsup><mo>=</mo><mrow><mrow><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mn>0</mn></msub><mo>\u2062</mo><msubsup><mi>N</mi><mn>1</mn><mn>2</mn></msubsup></mrow></mfrac><mo>\u2062</mo><msub><mrow><mo>\u27e8</mo><mrow><msub><mtext>Var</mtext><mi>L</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>)</mo></mrow><mo>\u2062</mo><msub><mtext>Var</mtext><mi>R</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mi>B</mi></msub></mrow><mo>+</mo><mrow><mrow><mfrac><mn>1</mn><msub><mi>N</mi><mn>0</mn></msub></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mrow><mo>\u27e8</mo><mrow><msubsup><mrow><mo>[</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>]</mo></mrow><mi>L</mi><mn>2</mn></msubsup><mo>\u2062</mo><msubsup><mrow><mo>[</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>]</mo></mrow><mi>R</mi><mn>2</mn></msubsup></mrow><mo>\u27e9</mo></mrow><mi>B</mi></msub><mo>-</mo><msup><mover accent=\"true\"><mi>A</mi><mo stretchy=\"false\">\u00af</mo></mover><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow><mo>+</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mo>+</mo><mrow><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>N</mi><mn>1</mn></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo>(</mo><msub><mrow><mo>\u27e8</mo><mrow><mrow><msub><mtext>Var</mtext><mi>L</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>)</mo></mrow><mo>\u2062</mo><msubsup><mrow><mo>[</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>]</mo></mrow><mi>R</mi><mn>2</mn></msubsup></mrow><mo>+</mo><mrow><msub><mtext>Var</mtext><mi>R</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>)</mo></mrow><mo>\u2062</mo><msubsup><mrow><mo>[</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>]</mo></mrow><mi>L</mi><mn>2</mn></msubsup></mrow></mrow><mo>\u27e9</mo></mrow><mi>B</mi></msub><mo rspace=\"4.2pt\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\n\nThen only the first term gives the leading contribution to the error and it is \nthe one that has the ideal scaling for which a nested Monte Carlo scheme would \nbe useful. \n\nThe final formula for the error of the connected correlator is\n\n\n", "itemtype": "equation", "pos": 41478, "prevtext": "\nwhere $\\text{Var}_L\\left(\\mathcal{O}\\right) = \\left[\\mathcal{O}^2\\right]_L - \\left[\\mathcal{O}\\right]_L^2$ and \nsimilarly for $\\text{Var}_R \\left(\\mathcal{O'}\\right)$. By looking at Eq.~\\eqref{eq:A_scaling} \nit is clear that the error scales not only as the ideal case $1/\\sqrt{N_0}N_1$, but it has \nalso subleading contributions.\n\nNote however, that using the transfer matrix formalism, one can show that the second \nterm proportional to $1/N_0$ is exponentially suppresed as $e^{-m_0 | x^B_0 - x^M_0|}$, \nwhere $m_0$ is the mass of the lightest state compatible with the \nsymmetries of $\\mathcal{O}$ and $x^M_0$ corresponds to $x_0$ or $y_0$, whichever \nis the closest to $x^B_0$. \n\nThe third term is also exponentially suppressed if one considers the case of \nthe connected correlator \n\n\n", "index": 29, "text": "\\begin{equation*}\nC=\\left\\langle{\\mathcal{O}(x_0) \\mathcal{O}(y_0)}\\right\\rangle -\\left\\langle{\\mathcal{O}(x_0)}\\right\\rangle\\left\\langle{\\mathcal{O}(y_0)}\\right\\rangle\\, .\n\\end{equation*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"C=\\left\\langle{\\mathcal{O}(x_{0})\\mathcal{O}(y_{0})}\\right\\rangle-\\left\\langle%&#10;{\\mathcal{O}(x_{0})}\\right\\rangle\\left\\langle{\\mathcal{O}(y_{0})}\\right\\rangle\\,.\" display=\"block\"><mrow><mrow><mi>C</mi><mo>=</mo><mrow><mrow><mo>\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mo>-</mo><mrow><mrow><mo>\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mo>\u2062</mo><mrow><mo>\u27e8</mo><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"4.2pt\">\u27e9</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.07155.tex", "nexttext": "\n\n\\end{appendices}\n\n\\providecommand{\\href}[2]{#2}\\begingroup\\raggedright\\begin{thebibliography}{10}\n\n\\bibitem{Parisi:1983ae}\nG.~Parisi, {\\it {The Strategy for Computing the Hadronic Mass Spectrum}},  {\\em\n  Phys. Rept.} {\\bf 103} (1984) 203--211.\n\n\\bibitem{Narayanan:2006rf}\nR.~Narayanan and H.~Neuberger, {\\it {Infinite N phase transitions in continuum\n  Wilson loop operators}},  {\\em JHEP} {\\bf 03} (2006) 064,\n  [\\href{http://arxiv.org/abs/hep-th/0601210}{{\\tt hep-th/0601210}}].\n\n\\bibitem{Luscher:2010iy}\nM.~L{\\\"u}scher, {\\it {Properties and uses of the Wilson flow in lattice QCD}},\n  {\\em JHEP} {\\bf 08} (2010) 071, [\\href{http://arxiv.org/abs/1006.4518}{{\\tt\n  arXiv:1006.4518}}]. [Erratum: JHEP03,092(2014)].\n\n\\bibitem{Luscher:2011bx}\nM.~L{\\\"u}scher and P.~Weisz, {\\it {Perturbative analysis of the gradient flow\n  in non-abelian gauge theories}},  {\\em JHEP} {\\bf 02} (2011) 051,\n  [\\href{http://arxiv.org/abs/1101.0963}{{\\tt arXiv:1101.0963}}].\n\n\\bibitem{Ce:2015qha}\nM.~C{\\`e}, C.~Consonni, G.~P. Engel, and L.~Giusti, {\\it {Non-Gaussianities in\n  the topological charge distribution of the SU(3) Yang--Mills theory}},  {\\em\n  Phys. Rev.} {\\bf D92} (2015), no.~7 074502,\n  [\\href{http://arxiv.org/abs/1506.0605}{{\\tt arXiv:1506.0605}}].\n\n\\bibitem{Bazavov:2010xr}\n{\\bf MILC} Collaboration, A.~Bazavov et~al., {\\it {Topological susceptibility\n  with the asqtad action}},  {\\em Phys. Rev.} {\\bf D81} (2010) 114501,\n  [\\href{http://arxiv.org/abs/1003.5695}{{\\tt arXiv:1003.5695}}].\n\n\\bibitem{Bruno:2014ova}\n{\\bf ALPHA} Collaboration, M.~Bruno, S.~Schaefer, and R.~Sommer, {\\it\n  {Topological susceptibility and the sampling of field space in N$_{f}$ = 2\n  lattice QCD simulations}},  {\\em JHEP} {\\bf 08} (2014) 150,\n  [\\href{http://arxiv.org/abs/1406.5363}{{\\tt arXiv:1406.5363}}].\n\n\\bibitem{Chowdhury:2014kfa}\nA.~Chowdhury, A.~Harindranath, and J.~Maiti, {\\it {Open Boundary Condition,\n  Wilson Flow and the Scalar Glueball Mass}},  {\\em JHEP} {\\bf 06} (2014) 067,\n  [\\href{http://arxiv.org/abs/1402.7138}{{\\tt arXiv:1402.7138}}].\n\n\\bibitem{Luscher:2001up}\nM.~L{\\\"u}scher and P.~Weisz, {\\it {Locality and exponential error reduction in\n  numerical lattice gauge theory}},  {\\em JHEP} {\\bf 09} (2001) 010,\n  [\\href{http://arxiv.org/abs/hep-lat/0108014}{{\\tt hep-lat/0108014}}].\n\n\\bibitem{Ce:2016idq}\nM.~C\u00c3\u00a8, L.~Giusti, and S.~Schaefer, {\\it {Domain decomposition, multi-level\n  integration and exponential noise reduction in lattice QCD}},\n  \\href{http://arxiv.org/abs/1601.0458}{{\\tt arXiv:1601.0458}}.\n\n\\bibitem{Meyer:2002cd}\nH.~B. Meyer, {\\it {Locality and statistical error reduction on correlation\n  functions}},  {\\em JHEP} {\\bf 01} (2003) 048,\n  [\\href{http://arxiv.org/abs/hep-lat/0209145}{{\\tt hep-lat/0209145}}].\n\n\\bibitem{Luscher:2009eq}\nM.~L{\\\"u}scher, {\\it {Trivializing maps, the Wilson flow and the HMC\n  algorithm}},  {\\em Commun. Math. Phys.} {\\bf 293} (2010) 899--919,\n  [\\href{http://arxiv.org/abs/0907.5491}{{\\tt arXiv:0907.5491}}].\n\n\\bibitem{Luscher:2011kk}\nM.~L{\\\"u}scher and S.~Schaefer, {\\it {Lattice QCD without topology barriers}},\n  {\\em JHEP} {\\bf 07} (2011) 036, [\\href{http://arxiv.org/abs/1105.4749}{{\\tt\n  arXiv:1105.4749}}].\n\n\\bibitem{Necco:2001xg}\nS.~Necco and R.~Sommer, {\\it {The N(f) = 0 heavy quark potential from short to\n  intermediate distances}},  {\\em Nucl. Phys.} {\\bf B622} (2002) 328--346,\n  [\\href{http://arxiv.org/abs/hep-lat/0108008}{{\\tt hep-lat/0108008}}].\n\n\\bibitem{Wolff:2003sm}\n{\\bf ALPHA} Collaboration, U.~Wolff, {\\it {Monte Carlo errors with less\n  errors}},  {\\em Comput. Phys. Commun.} {\\bf 156} (2004) 143--153,\n  [\\href{http://arxiv.org/abs/hep-lat/0306017}{{\\tt hep-lat/0306017}}].\n  [Erratum: Comput. Phys. Commun.176,383(2007)].\n\n\\bibitem{Cabibbo:1982zn}\nN.~Cabibbo and E.~Marinari, {\\it {A New Method for Updating SU(N) Matrices in\n  Computer Simulations of Gauge Theories}},  {\\em Phys. Lett.} {\\bf B119}\n  (1982) 387--390.\n\n\\bibitem{Brown:1987rra}\nF.~R. Brown and T.~J. Woch, {\\it {Overrelaxed Heat Bath and Metropolis\n  Algorithms for Accelerating Pure Gauge Monte Carlo Calculations}},  {\\em\n  Phys. Rev. Lett.} {\\bf 58} (1987) 2394.\n\n\\end{thebibliography}\\endgroup\n\n\n\n", "itemtype": "equation", "pos": 41905, "prevtext": "\n\nThen only the first term gives the leading contribution to the error and it is \nthe one that has the ideal scaling for which a nested Monte Carlo scheme would \nbe useful. \n\nThe final formula for the error of the connected correlator is\n\n\n", "index": 31, "text": "\\begin{equation}\\label{eq:C_scaling}\n\\sigma^2_C \\approx \\frac{1}{N_0 N^2_1} \\left\\langle{\\text{Var}_L\\left(\\mathcal{O}\\right)\\text{Var}_R\\left(\\mathcal{O'}\\right)}\\right\\rangle_B\n+ e^{-m_0 | x^B_0 - x^M_0|} \\left( \\frac{c_1}{N_0N_1} + \\frac{c_2}{N_0}   \\right) \\, .\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\sigma^{2}_{C}\\approx\\frac{1}{N_{0}N^{2}_{1}}\\left\\langle{\\text{Var}_{L}\\left(%&#10;\\mathcal{O}\\right)\\text{Var}_{R}\\left(\\mathcal{O^{\\prime}}\\right)}\\right%&#10;\\rangle_{B}+e^{-m_{0}|x^{B}_{0}-x^{M}_{0}|}\\left(\\frac{c_{1}}{N_{0}N_{1}}+%&#10;\\frac{c_{2}}{N_{0}}\\right)\\,.\" display=\"block\"><mrow><mrow><msubsup><mi>\u03c3</mi><mi>C</mi><mn>2</mn></msubsup><mo>\u2248</mo><mrow><mrow><mfrac><mn>1</mn><mrow><msub><mi>N</mi><mn>0</mn></msub><mo>\u2062</mo><msubsup><mi>N</mi><mn>1</mn><mn>2</mn></msubsup></mrow></mfrac><mo>\u2062</mo><msub><mrow><mo>\u27e8</mo><mrow><msub><mtext>Var</mtext><mi>L</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>)</mo></mrow><mo>\u2062</mo><msub><mtext>Var</mtext><mi>R</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaa</mi><mo>\u2032</mo></msup><mo>)</mo></mrow></mrow><mo>\u27e9</mo></mrow><mi>B</mi></msub></mrow><mo>+</mo><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msub><mi>m</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><msubsup><mi>x</mi><mn>0</mn><mi>B</mi></msubsup><mo>-</mo><msubsup><mi>x</mi><mn>0</mn><mi>M</mi></msubsup></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></msup><mo>\u2062</mo><mrow><mo>(</mo><mrow><mfrac><msub><mi>c</mi><mn>1</mn></msub><mrow><msub><mi>N</mi><mn>0</mn></msub><mo>\u2062</mo><msub><mi>N</mi><mn>1</mn></msub></mrow></mfrac><mo>+</mo><mfrac><msub><mi>c</mi><mn>2</mn></msub><msub><mi>N</mi><mn>0</mn></msub></mfrac></mrow><mo rspace=\"4.2pt\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}]