[{"file": "1601.05633.tex", "nexttext": "\nwhere $\\alpha(x^\\ast\\mid x^{(i)})$ is the probability of accepting the proposal $x^\\ast$ as $x^{(i+1)}$, i.e., \n\n", "itemtype": "equation", "pos": 6476, "prevtext": "\n\\nolinenumbers\n\\thispagestyle{empty}\n\n\n\\begin{center}\n{\\bf \\Large A Repulsive-Attractive Metropolis Algorithm for Multimodality}\\vskip10pt\nHyungsuk Tak$^{\\dag}$, Xiao-Li Meng$^{\\dag}$, and David A. van Dyk$^{\\ddag}$\\\\\\vskip10pt\n$^{\\dag}$Department of Statistics, Harvard University\\\\\n$^{\\ddag}$Statistics Section, Department of Mathematics, Imperial College London\\\\\n\\end{center}\n\\begin{abstract}\nWe propose a repulsive-attractive Metropolis algorithm that expedites a Markov chain's  jumping between modes of a multi-modal distribution in a simple and fast manner. This algorithm is essentially a Metropolis-Hastings algorithm with a proposal that consists of a downhill move in density that aims to make local modes repulsive, followed by an uphill move in density that aims to make local modes attractive. The  downhill move is achieved via a reciprocal Metropolis ratio so that the algorithm prefers downward movement. The uphill move does the opposite using the standard Metropolis ratio which prefers upward movement. This down-up movement in density increases the probability of a proposed move to a different mode. Because the acceptance probability of the proposal involves a ratio of intractable integrals, we introduce an auxiliary variable which introduces a term that cancels with the intractable ratio.  Using two examples, we demonstrate the potential for the proposed algorithm to explore a multi-modal distribution more effectively and with less tuning than is commonly required by tempering-based methods.\n\\end{abstract}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\noindent\n{\\it Keywords:}  Auxiliary variable, Equi-energy sampler, Forced Metropolis algorithm, Markov chain Monte Carlo, Parallel tempering, Pseudo-marginal algorithm, Tempered transitions.\n\n\\section{Introduction}\n\nMultimodal distributions are common in statistical applications.  A popular Markov chain Monte Carlo strategy for dealing with multimodality is tempering. Tempering melts down the modes of a target density to create a flatter surface and hence improved mixing. There are many temperature-based methods such as parallel tempering \\citep{geyer1991}, simulated tempering \\citep{geyer1995}, tempered transitions \\citep{neal1996}, and equi-energy sampler \\citep{kou2006}. Though powerful, these methods typically require extensive tuning and tend to be computationally expensive.\n\n\n\n\nIn this paper, we propose an alternative, easy-to-implement and temperature-free repulsive-attractive Metropolis algorithm that enables a Markov chain to jump between modes more frequently. The proposed algorithm generates a proposal via forced downhill and forced uphill Metropolis transitions. The term \\emph{forced} emphasizes that neither Metropolis transition is allowed to stay at its current state because we repeatedly make proposals  until one is accepted. Together the downhill and uphill transitions form a proposal for a Metropolis-Hastings sample; a final accept-reject step preserves the target stationary distribution. The forced downhill Metropolis transition uses a reciprocal ratio of the target densities in its acceptance probability. This encourages the intermediate proposal to prefer downward moves since a lower density state has a higher chance of acceptance, hence local modes become repulsive. The subsequent forced uphill Metropolis transition  generates a final proposal with a standard Metropolis ratio. The final proposal  has a higher chance to be in a mode other than the one of the current state, as shown in Fig.~\\ref{idea_FM}, and it is then accepted or rejected in the usual way.  The scale of the proposal distributions iterated within the downhill and uphill transitions is the only tuning parameter of this algorithm if the proposal distributions are Gaussian. As with other Metropolis-Hastings samplers, the normalizing constant of the target density need not be known. \n\n\nAlthough we can draw a sample using the down-up proposal rule,  the acceptance probability of the final proposal contains a ratio of intractable integrals. We solve this problem by introducing an auxiliary variable,  using the idea of \\cite{moller2006}. This auxiliary variable approach  marginally preserves the target density and requires another forced downhill Metropolis transition for the auxiliary variable. Thus, the repulsive-attractive Metropolis algorithm generates a proposal via three forced Metropolis transitions but accepts the proposal with an easy-to-compute acceptance probability.\n\n\n\n\n\n\n\n\\begin{figure}\n\\begin{center}\n\\includegraphics[scale = 0.26]{ram_idea2.eps}\n\n\\caption{A repulsive-attractive Metropolis algorithm is a Metropolis-Hastings algorithm that generates a proposal $x^\\ast$ given the current state $x^{(i)}$ by making a down-up movement in density via forced downhill and uphill Metropolis transitions.}\n\\label{idea_FM}\n\\end{center}\n\\end{figure}\n\n\nWe compare  the performance of the proposed algorithm to that of several commonly-used methods, namely parallel tempering,  equi-energy sampler, and tempered transitions via two numerical examples. The target distribution in the first example is a mixture of 20 bivariate Gaussian distributions with either equal-variance and equally-weighted modes or  unequal-variance and unequally-weighted modes \\citep{kou2006}. In this example, we show that the mean squared error of moment estimates from the proposed algorithm is better than that of both parallel tempering and equi-energy sampler. The second example is from our applied work in astrophysics, which motivated this research. In this example, we show that the proposed algorithm explores a highly multimodal target distribution better than tempered transitions. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{A repulsive-attractive Metropolis algorithm}\nWe use the notation of \\citet{chib1995} to briefly review the Metropolis-Hastings algorithm. A transition kernel on $\\mathbf{R}^d$, denoted  $P(B\\mid x)$, is the conditional probability distribution function of transition from $x\\in \\mathbf{R}^d$ to a point in a Borel set $B$ in $\\mathbf{R}^d$; $P(\\mathbf{R}^d\\mid x)=1$ and $P( \\{x\\}\\mid x)$ need not be zero. A proposal density given the current state $x^{(i)}$ is a conditional  density that generates a proposal $x^\\ast$. We denote this proposal density  by $q(x^\\ast\\mid x^{(i)})$ which must satisfy $\\int q(x^\\ast\\mid x^{(i)})dx^\\ast=1$. With a target density denoted by $\\pi$, either normalized or unnormalized, a transition kernel of the Metropolis-Hastings  algorithm is defined as\n\n", "index": 1, "text": "\\begin{equation}\nP(dx^\\ast\\mid x^{(i)})=q(x^\\ast\\mid x^{(i)})\\alpha(x^\\ast\\mid x^{(i)})dx^\\ast +\\delta_{x^{(i)}}(dx^\\ast)\\{1-A(x^{(i)})\\},\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"P(dx^{\\ast}\\mid x^{(i)})=q(x^{\\ast}\\mid x^{(i)})\\alpha(x^{\\ast}\\mid x^{(i)})dx%&#10;^{\\ast}+\\delta_{x^{(i)}}(dx^{\\ast})\\{1-A(x^{(i)})\\},\" display=\"block\"><mrow><mi>P</mi><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>\u03b1</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>x</mi><mo>\u2217</mo></msup><mo>+</mo><msub><mi>\u03b4</mi><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></msub><mrow><mo stretchy=\"false\">(</mo><mi>d</mi><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>-</mo><mi>A</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": " \n$1-A(x^{(i)})$ is the probability of staying at $x^{(i)}$  and thus $A(x^{(i)})$ is that of moving from $x^{(i)}$,\n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $\\alpha(x^\\ast\\mid x^{(i)})$ is the probability of accepting the proposal $x^\\ast$ as $x^{(i+1)}$, i.e., \n\n", "index": 3, "text": "\\begin{equation}\n\\alpha(x^\\ast\\mid x^{(i)})=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^\\ast)q(x^{(i)}\\mid x^\\ast)}{\\pi(x^{(i)})q(x^\\ast\\mid x^{(i)})}\\right\\};\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\alpha(x^{\\ast}\\mid x^{(i)})=\\textrm{min}\\left\\{1,~{}\\frac{\\pi(x^{\\ast})q(x^{(%&#10;i)}\\mid x^{\\ast})}{\\pi(x^{(i)})q(x^{\\ast}\\mid x^{(i)})}\\right\\};\" display=\"block\"><mrow><mi>\u03b1</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>}</mo></mrow><mo>;</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nand the Dirac measure $\\delta_{x^{(i)}}(dx^\\ast)$ is one if $x^{(i)}\\in dx^\\ast$ and zero otherwise.  If the proposal density is symmetric, satisfying $q(x^\\ast\\mid x^{(i)})=q(x^{(i)}\\mid x^\\ast)$, then the Metropolis-Hastings algorithm reduces to a Metropolis algorithm, whose acceptance probability is\n\n", "itemtype": "equation", "pos": 7042, "prevtext": " \n$1-A(x^{(i)})$ is the probability of staying at $x^{(i)}$  and thus $A(x^{(i)})$ is that of moving from $x^{(i)}$,\n\n", "index": 5, "text": "\\begin{equation}\nA(x^{(i)})= \\int q(x^\\ast\\mid x^{(i)})\\alpha(x^\\ast\\mid x^{(i)})dx^\\ast;\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"A(x^{(i)})=\\int q(x^{\\ast}\\mid x^{(i)})\\alpha(x^{\\ast}\\mid x^{(i)})dx^{\\ast};\" display=\"block\"><mrow><mi>A</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>\u03b1</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>x</mi><mo>\u2217</mo></msup><mo>;</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": " \n\n\n\n\n\n\n\nThe repulsive-attractive Metropolis algorithm is  a Metropolis-Hastings algorithm with a proposal density  that is designed to boost the down-up movement via two forced Metropolis transitions.  The forced Metropolis algorithm is the same as a standard Metropolis algorithm except that the forced algorithm repeatedly makes proposals until one is accepted. Without a forced transition, the final proposal $x^\\ast$ could be the same as the current state $x^{(i)}$ after  consecutive  rejections in both the downhill and uphill Metropolis transitions, which is wasteful. (A standard Metropolis algorithm with a continuous proposal distribution, on the other hand, generates $x^\\ast$ different from $x^{(i)}$.) Also, if the forced transitions were not included, the final proposal would be generated via only one of the two Metropolis transitions if the other were rejected. This would not be helpful for our purposes because it would not induce a down-up movement. \n\n\n\nThe forced downhill Metropolis transition generates an intermediate proposal $x'$ from the current state $x^{(i)}$ using the reciprocal ratio of the target densities in its acceptance probability, \n\n", "itemtype": "equation", "pos": -1, "prevtext": "\nand the Dirac measure $\\delta_{x^{(i)}}(dx^\\ast)$ is one if $x^{(i)}\\in dx^\\ast$ and zero otherwise.  If the proposal density is symmetric, satisfying $q(x^\\ast\\mid x^{(i)})=q(x^{(i)}\\mid x^\\ast)$, then the Metropolis-Hastings algorithm reduces to a Metropolis algorithm, whose acceptance probability is\n\n", "index": 7, "text": "\\begin{equation}\\label{accept_m}\n\\alpha(x^\\ast\\mid x^{(i)})=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^\\ast)}{\\pi(x^{(i)})}\\right\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"\\alpha(x^{\\ast}\\mid x^{(i)})=\\textrm{min}\\left\\{1,~{}\\frac{\\pi(x^{\\ast})}{\\pi(%&#10;x^{(i)})}\\right\\}.\" display=\"block\"><mrow><mi>\u03b1</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>}</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere the superscript, D, indicates that the ratio has been flipped for a downward move;  the appearance of $\\epsilon$ in \\eqref{accept_fm} is discussed below. The reciprocal density ratio in \\eqref{accept_fm} makes local modes repulsive rather than attractive: If the density of $x'$ is smaller than that of $x^{(i)}$,  $x'$  is accepted with probability one.  The forced uphill Metropolis transition restores the attractiveness of local modes as with the original Metropolis ratio which prefers upward movement in density. The  forced uphill Metropolis transition generates the final proposal $x^\\ast$ given  $x'$, whose acceptance probability is\n\n", "itemtype": "equation", "pos": 8772, "prevtext": " \n\n\n\n\n\n\n\nThe repulsive-attractive Metropolis algorithm is  a Metropolis-Hastings algorithm with a proposal density  that is designed to boost the down-up movement via two forced Metropolis transitions.  The forced Metropolis algorithm is the same as a standard Metropolis algorithm except that the forced algorithm repeatedly makes proposals until one is accepted. Without a forced transition, the final proposal $x^\\ast$ could be the same as the current state $x^{(i)}$ after  consecutive  rejections in both the downhill and uphill Metropolis transitions, which is wasteful. (A standard Metropolis algorithm with a continuous proposal distribution, on the other hand, generates $x^\\ast$ different from $x^{(i)}$.) Also, if the forced transitions were not included, the final proposal would be generated via only one of the two Metropolis transitions if the other were rejected. This would not be helpful for our purposes because it would not induce a down-up movement. \n\n\n\nThe forced downhill Metropolis transition generates an intermediate proposal $x'$ from the current state $x^{(i)}$ using the reciprocal ratio of the target densities in its acceptance probability, \n\n", "index": 9, "text": "\\begin{equation}\\label{accept_fm}\n\\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x')+\\epsilon}\\right\\},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\alpha^{\\textrm{D}}_{\\epsilon}(x^{\\prime}\\mid x^{(i)})=\\textrm{min}\\left\\{1,~{%&#10;}\\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x^{\\prime})+\\epsilon}\\right\\},\" display=\"block\"><mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac><mo>}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere the superscript, U, indicates that the acceptance probability prefers an upward movement. The acceptance probability in \\eqref{flippedback_accept_prob} is the same as  in \\eqref{accept_m} except that $\\epsilon$ is added to the numerator and denominator. This is done for numerical stability; both $\\pi(x')$ and $\\pi(x^\\ast)$ can be nearly zero  when  both $x'$ and $x^\\ast$ are in a flat valley between two distant modes. In this case, adding $\\epsilon$ prevents a ratio of zeros in the acceptance probability. However,  $\\epsilon$ may affect the convergence rate of the sampler because a large value of $\\epsilon$ that dominates $\\pi$ results in $x^\\ast$ almost always being accepted, regardless of whether $x^\\ast$ is an uphill move or not. To minimize its impact on the acceptance probability in~\\eqref{flippedback_accept_prob}, $\\epsilon$ must be small and our default choice is $\\epsilon=10^{-323}$, a constant that R  treats as positive \\citep{r2015}; R treats $10^{-324}$ as zero. For a symmetry, we also use $\\epsilon$ in the same way in the acceptance probability of the downhill transition in \\eqref{accept_fm}.   \n\n\n\n\n\n\n\n\nThus, the proposed algorithm is a Metropolis-Hastings algorithm with a down-up proposal density\n\n", "itemtype": "equation", "pos": 9594, "prevtext": "\nwhere the superscript, D, indicates that the ratio has been flipped for a downward move;  the appearance of $\\epsilon$ in \\eqref{accept_fm} is discussed below. The reciprocal density ratio in \\eqref{accept_fm} makes local modes repulsive rather than attractive: If the density of $x'$ is smaller than that of $x^{(i)}$,  $x'$  is accepted with probability one.  The forced uphill Metropolis transition restores the attractiveness of local modes as with the original Metropolis ratio which prefers upward movement in density. The  forced uphill Metropolis transition generates the final proposal $x^\\ast$ given  $x'$, whose acceptance probability is\n\n", "index": 11, "text": "\\begin{equation}\\label{flippedback_accept_prob}\n\\alpha^\\textrm{U}_\\epsilon(x^\\ast\\mid x')=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(x')+\\epsilon}\\right\\},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\alpha^{\\textrm{U}}_{\\epsilon}(x^{\\ast}\\mid x^{\\prime})=\\textrm{min}\\left\\{1,~%&#10;{}\\frac{\\pi(x^{\\ast})+\\epsilon}{\\pi(x^{\\prime})+\\epsilon}\\right\\},\" display=\"block\"><mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac><mo>}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere $q^{\\textrm{D}}$ and $q^{\\textrm{U}}$ are the forced downhill and uphill transition kernel densities, respectively. Specifically, the forced downhill kernel density is\n\n", "itemtype": "equation", "pos": 11012, "prevtext": "\nwhere the superscript, U, indicates that the acceptance probability prefers an upward movement. The acceptance probability in \\eqref{flippedback_accept_prob} is the same as  in \\eqref{accept_m} except that $\\epsilon$ is added to the numerator and denominator. This is done for numerical stability; both $\\pi(x')$ and $\\pi(x^\\ast)$ can be nearly zero  when  both $x'$ and $x^\\ast$ are in a flat valley between two distant modes. In this case, adding $\\epsilon$ prevents a ratio of zeros in the acceptance probability. However,  $\\epsilon$ may affect the convergence rate of the sampler because a large value of $\\epsilon$ that dominates $\\pi$ results in $x^\\ast$ almost always being accepted, regardless of whether $x^\\ast$ is an uphill move or not. To minimize its impact on the acceptance probability in~\\eqref{flippedback_accept_prob}, $\\epsilon$ must be small and our default choice is $\\epsilon=10^{-323}$, a constant that R  treats as positive \\citep{r2015}; R treats $10^{-324}$ as zero. For a symmetry, we also use $\\epsilon$ in the same way in the acceptance probability of the downhill transition in \\eqref{accept_fm}.   \n\n\n\n\n\n\n\n\nThus, the proposed algorithm is a Metropolis-Hastings algorithm with a down-up proposal density\n\n", "index": 13, "text": "\\begin{equation}\nq^{\\textrm{DU}}(x^\\ast\\mid x^{(i)}) = \\int q^{\\textrm{D}}(x'\\mid x^{(i)}) q^{\\textrm{U}}(x^\\ast\\mid x')dx',  \\label{transition_VMH}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"q^{\\textrm{DU}}(x^{\\ast}\\mid x^{(i)})=\\int q^{\\textrm{D}}(x^{\\prime}\\mid x^{(i%&#10;)})q^{\\textrm{U}}(x^{\\ast}\\mid x^{\\prime})dx^{\\prime},\" display=\"block\"><mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msup><mi>q</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>U</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>x</mi><mo>\u2032</mo></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere $A^\\textrm{D}(x^{(i)})$ is the  probability of accepting any single  proposal from $q(x'\\mid x^{(i)})$.  Note $\\int q^{\\textrm{D}}(x'\\mid x^{(i)}) dx'=1$ because its support is defined by the region $U\\le  \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})$, where $U\\sim \\textrm{Uniform}(0, 1)$ and is independent of $(x', x^{(i)})$.  Similarly, the forced uphill kernel density is \n\n", "itemtype": "equation", "pos": 11350, "prevtext": "\nwhere $q^{\\textrm{D}}$ and $q^{\\textrm{U}}$ are the forced downhill and uphill transition kernel densities, respectively. Specifically, the forced downhill kernel density is\n\n", "index": 15, "text": "\\begin{align}\nq^{\\textrm{D}}(x'\\mid x^{(i)})&=\\frac{q(x'\\mid x^{(i)}) \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})}{A^\\textrm{D}(x^{(i)})},\\label{mixture_f}\\\\\nA^\\textrm{D}(x^{(i)})&=\\int q(x'\\mid x^{(i)}) \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})dx',\\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle q^{\\textrm{D}}(x^{\\prime}\\mid x^{(i)})\" display=\"inline\"><mrow><msup><mi>q</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{q(x^{\\prime}\\mid x^{(i)})\\alpha^{\\textrm{D}}_{\\epsilon}(x^%&#10;{\\prime}\\mid x^{(i)})}{A^{\\textrm{D}}(x^{(i)})},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>A</mi><mtext>D</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A^{\\textrm{D}}(x^{(i)})\" display=\"inline\"><mrow><msup><mi>A</mi><mtext>D</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int q(x^{\\prime}\\mid x^{(i)})\\alpha^{\\textrm{D}}_{\\epsilon}(x^{%&#10;\\prime}\\mid x^{(i)})dx^{\\prime},\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" symmetric=\"true\">\u222b</mo></mstyle><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>x</mi><mo>\u2032</mo></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nand $\\int q^{\\textrm{U}}(x^\\ast\\mid x') dx^\\ast=1$. Consequently, the down-up proposal density in \\eqref{transition_VMH} satisfies $\\int q^{\\textrm{DU}}(x^\\ast\\mid x^{(i)}) dx^\\ast=1$.  The conditional density $q$ in \\eqref{mixture_f} and \\eqref{mixture_m} may be any symmetric density with a positive probability of reaching all possible states. For example, we can set $q(a\\mid b)=N(a\\mid b, \\sigma^2I_d)$, a $d$-dimensional Gaussian density of $a$ with mean $b$ and variance-covariance matrix $\\sigma^2I_d$. In this case,  the scale  parameter, $\\sigma$, is the only tuning parameter that can be used to improve the mixing of the proposed algorithm.  \n\n\n\nGiven the proposal, the Metropolis-Hastings acceptance ratio is\n\n", "itemtype": "equation", "pos": 12009, "prevtext": "\nwhere $A^\\textrm{D}(x^{(i)})$ is the  probability of accepting any single  proposal from $q(x'\\mid x^{(i)})$.  Note $\\int q^{\\textrm{D}}(x'\\mid x^{(i)}) dx'=1$ because its support is defined by the region $U\\le  \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})$, where $U\\sim \\textrm{Uniform}(0, 1)$ and is independent of $(x', x^{(i)})$.  Similarly, the forced uphill kernel density is \n\n", "index": 17, "text": "\\begin{align}\nq^{\\textrm{U}}(x^\\ast\\mid x')&= \\frac{q(x^\\ast\\mid x') \\alpha^{\\textrm{U}}_\\epsilon( x^\\ast\\mid x')}{A^\\textrm{U}(x')},\\label{mixture_m}\\\\\nA^\\textrm{U}(x')&=\\int q(x^\\ast\\mid x') \\alpha^{\\textrm{U}}_\\epsilon(x^\\ast\\mid x')dx^\\ast,\\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle q^{\\textrm{U}}(x^{\\ast}\\mid x^{\\prime})\" display=\"inline\"><mrow><msup><mi>q</mi><mtext>U</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\frac{q(x^{\\ast}\\mid x^{\\prime})\\alpha^{\\textrm{U}}_{\\epsilon}(x%&#10;^{\\ast}\\mid x^{\\prime})}{A^{\\textrm{U}}(x^{\\prime})},\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>A</mi><mtext>U</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A^{\\textrm{U}}(x^{\\prime})\" display=\"inline\"><mrow><msup><mi>A</mi><mtext>U</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int q(x^{\\ast}\\mid x^{\\prime})\\alpha^{\\textrm{U}}_{\\epsilon}(x^%&#10;{\\ast}\\mid x^{\\prime})dx^{\\ast},\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" symmetric=\"true\">\u222b</mo></mstyle><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><msup><mi>x</mi><mo>\u2217</mo></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nThe second equation in \\eqref{final_acceptance} holds because \n\n", "itemtype": "equation", "pos": 12997, "prevtext": "\nand $\\int q^{\\textrm{U}}(x^\\ast\\mid x') dx^\\ast=1$. Consequently, the down-up proposal density in \\eqref{transition_VMH} satisfies $\\int q^{\\textrm{DU}}(x^\\ast\\mid x^{(i)}) dx^\\ast=1$.  The conditional density $q$ in \\eqref{mixture_f} and \\eqref{mixture_m} may be any symmetric density with a positive probability of reaching all possible states. For example, we can set $q(a\\mid b)=N(a\\mid b, \\sigma^2I_d)$, a $d$-dimensional Gaussian density of $a$ with mean $b$ and variance-covariance matrix $\\sigma^2I_d$. In this case,  the scale  parameter, $\\sigma$, is the only tuning parameter that can be used to improve the mixing of the proposed algorithm.  \n\n\n\nGiven the proposal, the Metropolis-Hastings acceptance ratio is\n\n", "index": 19, "text": "\\begin{equation}\n\\alpha^{\\textrm{DU}}(x^\\ast\\mid x^{(i)})=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^\\ast)q^\\textrm{DU}(x^{(i)}\\mid x^\\ast)}{\\pi(x^{(i)})q^\\textrm{DU}(x^\\ast\\mid x^{(i)})}\\right\\}=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)A^\\textrm{D}(x^{(i)})}{\\pi(x^{(i)})A^\\textrm{D}(x^\\ast)}\\right\\}.\\label{final_acceptance}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\alpha^{\\textrm{DU}}(x^{\\ast}\\mid x^{(i)})=\\textrm{min}\\left\\{1,~{}\\frac{\\pi(x%&#10;^{\\ast})q^{\\textrm{DU}}(x^{(i)}\\mid x^{\\ast})}{\\pi(x^{(i)})q^{\\textrm{DU}}(x^{%&#10;\\ast}\\mid x^{(i)})}\\right\\}=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})A^{\\textrm{D}}(%&#10;x^{(i)})}{\\pi(x^{(i)})A^{\\textrm{D}}(x^{\\ast})}\\right\\}.\" display=\"block\"><mrow><msup><mi>\u03b1</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>}</mo></mrow><mo>=</mo><mi>min</mi><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mfrac><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>A</mi><mtext>D</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>A</mi><mtext>D</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>}</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nand thus with a symmetric density $q$\n\n", "itemtype": "equation", "pos": 13385, "prevtext": "\nThe second equation in \\eqref{final_acceptance} holds because \n\n", "index": 21, "text": "\\begin{align}\n\\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)})&=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}=\\alpha^{\\textrm{U}}_\\epsilon(x^{(i)}\\mid x'),\\nonumber\\\\ \n\\alpha^{\\textrm{U}}_\\epsilon(x^\\ast\\mid x')&=\\textrm{min}\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}=\\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^\\ast), \\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha^{\\textrm{D}}_{\\epsilon}(x^{\\prime}\\mid x^{(i)})\" display=\"inline\"><mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\textrm{min}\\left\\{1,~{}\\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x^{%&#10;\\prime})+\\epsilon}\\right\\}=\\alpha^{\\textrm{U}}_{\\epsilon}(x^{(i)}\\mid x^{%&#10;\\prime}),\" display=\"inline\"><mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac></mstyle><mo>}</mo></mrow><mo>=</mo><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha^{\\textrm{U}}_{\\epsilon}(x^{\\ast}\\mid x^{\\prime})\" display=\"inline\"><mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\textrm{min}\\left\\{1,~{}\\frac{\\pi(x^{\\ast})+\\epsilon}{\\pi(x^{%&#10;\\prime})+\\epsilon}\\right\\}=\\alpha^{\\textrm{D}}_{\\epsilon}(x^{\\prime}\\mid x^{%&#10;\\ast}),\" display=\"inline\"><mrow><mo>=</mo><mtext>min</mtext><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac></mstyle><mo>}</mo></mrow><mo>=</mo><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\n\nUnfortunately, the acceptance probability in \\eqref{final_acceptance} is difficult to compute due to its ratio of intractable integrals, $A^\\textrm{D}(x^{(i)})/A^\\textrm{D}(x^\\ast)$. \\cite{moller2006} use an auxiliary variable approach to cancel out a ratio of intractable normalizing constants of a target density. We follow this approach, but our case arises from the intractable down-up proposal density, $q^{\\textrm{DU}}$.  We introduce an auxiliary variable in such a way that the marginal target density for $x$ remains $\\pi$. This auxiliary variable results in a term that cancels with the intractable ratio. \n\n\n\nSpecifically, let $z \\in \\mathbf{R}^d$ be an auxiliary variable that shares the same space with $x$, via a conditional density $\\pi^\\textrm{C}(z\\mid x)$ to be specified. We denote a joint proposal  density that proposes $(z^\\ast, x^\\ast)$ given the current states $(z^{(i)}, x^{(i)})$ by $q^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})$ and assume that it factors and can be simplified as\n\n", "itemtype": "equation", "pos": 13808, "prevtext": "\nand thus with a symmetric density $q$\n\n", "index": 23, "text": "\\begin{align}\nq^{\\textrm{DU}}(x^\\ast\\mid x^{(i)})A^\\textrm{D}(x^{(i)})&=\\int  q(x'\\mid x^{(i)}) \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^{(i)}) \\frac{q(x^\\ast\\mid x')\\alpha^{\\textrm{U}}_\\epsilon(x^\\ast\\mid x')}{A^\\textrm{U}(x')} dx'\\nonumber\\\\\n&= \\int q(x^{(i)}\\mid x') \\alpha^{\\textrm{U}}_\\epsilon(x^{(i)}\\mid x') \\frac{q(x'\\mid x^\\ast) \\alpha^{\\textrm{D}}_\\epsilon(x'\\mid x^\\ast)}{A^\\textrm{U}(x')} dx'\\nonumber\\\\\n&=q^{\\textrm{DU}}(x^{(i)}\\mid x^\\ast)A^\\textrm{D}(x^\\ast).\\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle q^{\\textrm{DU}}(x^{\\ast}\\mid x^{(i)})A^{\\textrm{D}}(x^{(i)})\" display=\"inline\"><mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>A</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int q(x^{\\prime}\\mid x^{(i)})\\alpha^{\\textrm{D}}_{\\epsilon}(x^{%&#10;\\prime}\\mid x^{(i)})\\frac{q(x^{\\ast}\\mid x^{\\prime})\\alpha^{\\textrm{U}}_{%&#10;\\epsilon}(x^{\\ast}\\mid x^{\\prime})}{A^{\\textrm{U}}(x^{\\prime})}dx^{\\prime}\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" symmetric=\"true\">\u222b</mo></mstyle><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>A</mi><mtext>U</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mi>d</mi><msup><mi>x</mi><mo>\u2032</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\int q(x^{(i)}\\mid x^{\\prime})\\alpha^{\\textrm{U}}_{\\epsilon}(x^{%&#10;(i)}\\mid x^{\\prime})\\frac{q(x^{\\prime}\\mid x^{\\ast})\\alpha^{\\textrm{D}}_{%&#10;\\epsilon}(x^{\\prime}\\mid x^{\\ast})}{A^{\\textrm{U}}(x^{\\prime})}dx^{\\prime}\" display=\"inline\"><mrow><mo>=</mo><mstyle displaystyle=\"true\"><mo largeop=\"true\" symmetric=\"true\">\u222b</mo></mstyle><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>U</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>A</mi><mtext>U</mtext></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2032</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mi>d</mi><msup><mi>x</mi><mo>\u2032</mo></msup></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=q^{\\textrm{DU}}(x^{(i)}\\mid x^{\\ast})A^{\\textrm{D}}(x^{\\ast}).\" display=\"inline\"><mrow><mo>=</mo><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>A</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nso that the Metropolis-Hastings acceptance probability for the joint proposal is\n\n", "itemtype": "equation", "pos": 15314, "prevtext": "\n\nUnfortunately, the acceptance probability in \\eqref{final_acceptance} is difficult to compute due to its ratio of intractable integrals, $A^\\textrm{D}(x^{(i)})/A^\\textrm{D}(x^\\ast)$. \\cite{moller2006} use an auxiliary variable approach to cancel out a ratio of intractable normalizing constants of a target density. We follow this approach, but our case arises from the intractable down-up proposal density, $q^{\\textrm{DU}}$.  We introduce an auxiliary variable in such a way that the marginal target density for $x$ remains $\\pi$. This auxiliary variable results in a term that cancels with the intractable ratio. \n\n\n\nSpecifically, let $z \\in \\mathbf{R}^d$ be an auxiliary variable that shares the same space with $x$, via a conditional density $\\pi^\\textrm{C}(z\\mid x)$ to be specified. We denote a joint proposal  density that proposes $(z^\\ast, x^\\ast)$ given the current states $(z^{(i)}, x^{(i)})$ by $q^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})$ and assume that it factors and can be simplified as\n\n", "index": 25, "text": "\\begin{equation}\nq^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})=q_1(x^\\ast \\mid  z^{(i)}, x^{(i)})q_2(z^\\ast \\mid  x^\\ast, z^{(i)}, x^{(i)})=q_1(x^\\ast \\mid  x^{(i)})q_2(z^\\ast \\mid  x^\\ast)\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"q^{\\textrm{J}}(z^{\\ast},x^{\\ast}\\mid z^{(i)},x^{(i)})=q_{1}(x^{\\ast}\\mid z^{(i%&#10;)},x^{(i)})q_{2}(z^{\\ast}\\mid x^{\\ast},z^{(i)},x^{(i)})=q_{1}(x^{\\ast}\\mid x^{%&#10;(i)})q_{2}(z^{\\ast}\\mid x^{\\ast})\" display=\"block\"><mrow><msup><mi>q</mi><mtext>J</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>q</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msub><mi>q</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nSuppose it is possible to draw a sample from $q_1$ but difficult to evaluate $q_1$. We can find a function $f$ such that $q_1(x^{(i)} \\mid  x^\\ast)/q_1(x^\\ast \\mid  x^{(i)}) = f(x^{(i)})/ f(x^\\ast)$ because the ratio of two (compatible) conditional densities is the ratio of two marginal densities. The function $f$ may or may not be computable and can be a normalizing constant of $q_1$ but not necessarily. If we can find a function $q_2$ whose normalizing constant is proportional to $f$, then the joint acceptance probability in \\eqref{joint_accept_prob} becomes free of the intractable quantities.\n\nFor the repulsive-attractive Metropolis algorithm, we set $q_1(x^\\ast \\mid  x^{(i)})=q^\\textrm{DU}(x^\\ast\\mid x^{(i)})$ to propose a down-up movement from $x^{(i)}$ to $x^\\ast$, where $q^{\\textrm{DU}}$ is specified in \\eqref{transition_VMH}. In this case, $f(x^{(i)})=A^\\textrm{D}(x^{(i)})$ which is the normalizing constant of the forced downhill kernel density $q^{\\textrm{D}}$ in \\eqref{mixture_f}. To eliminate this intractable integral, we choose $q_2(z^\\ast\\mid  x^\\ast)=q^\\textrm{D}(z^\\ast\\mid x^\\ast)$. \\cite{moller2006} suggest choosing $\\pi^\\textrm{C}$ similar to $q_2$ and thus we assume $\\pi^\\textrm{C}(z^\\ast\\mid x^\\ast)$ equals $q(z^\\ast\\mid x^\\ast)$. With these choices, the acceptance probability in  \\eqref{joint_accept_prob} reduces to\n\n", "itemtype": "equation", "pos": 15613, "prevtext": "\nso that the Metropolis-Hastings acceptance probability for the joint proposal is\n\n", "index": 27, "text": "\\begin{align}\n\\alpha^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})&=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)\\pi^\\textrm{C}(z^\\ast\\mid x^\\ast)q^\\textrm{J}(z^{(i)}, x^{(i)} \\mid z^\\ast, x^\\ast)}{\\pi(x^{(i)})\\pi^\\textrm{C}(z^{(i)}\\mid x^{(i)})q^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})}\\right\\}\\nonumber\\\\\n&=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)\\pi^\\textrm{C}(z^\\ast\\mid x^\\ast)q_1(x^{(i)} \\mid  x^\\ast)q_2(z^{(i)} \\mid  x^{(i)})}{\\pi(x^{(i)})\\pi^\\textrm{C}(z^{(i)}\\mid x^{(i)})q_1(x^\\ast \\mid  x^{(i)})q_2(z^\\ast \\mid  x^\\ast)}\\right\\}.\\label{joint_accept_prob}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha^{\\textrm{J}}(z^{\\ast},x^{\\ast}\\mid z^{(i)},x^{(i)})\" display=\"inline\"><mrow><msup><mi>\u03b1</mi><mtext>J</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})\\pi^{\\textrm{C}}(z^{\\ast}\\mid&#10;x%&#10;^{\\ast})q^{\\textrm{J}}(z^{(i)},x^{(i)}\\mid z^{\\ast},x^{\\ast})}{\\pi(x^{(i)})\\pi%&#10;^{\\textrm{C}}(z^{(i)}\\mid x^{(i)})q^{\\textrm{J}}(z^{\\ast},x^{\\ast}\\mid z^{(i)}%&#10;,x^{(i)})}\\right\\}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>\u03c0</mi><mtext>C</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>J</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>\u03c0</mi><mtext>C</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>J</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})\\pi^{\\textrm{C}}(z^{\\ast}\\mid&#10;x%&#10;^{\\ast})q_{1}(x^{(i)}\\mid x^{\\ast})q_{2}(z^{(i)}\\mid x^{(i)})}{\\pi(x^{(i)})\\pi%&#10;^{\\textrm{C}}(z^{(i)}\\mid x^{(i)})q_{1}(x^{\\ast}\\mid x^{(i)})q_{2}(z^{\\ast}%&#10;\\mid x^{\\ast})}\\right\\}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>\u03c0</mi><mtext>C</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>\u03c0</mi><mtext>C</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>1</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msub><mi>q</mi><mn>2</mn></msub><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nIn \\eqref{joint_accept_prob2}, $\\pi(z^{(i)})$ is likely to be smaller than $\\pi(x^{(i)})$ because $z^{(i)}$ is generated by the forced downhill  transition. Similarly, $\\pi(z^\\ast)$ is likely to be smaller than $\\pi(x^\\ast)$. If $z^{(i)}$ and $z^\\ast$ have lower target densities than $x^{(i)}$ and $x^\\ast$, respectively (a likely, but not required situation), then the acceptance probability in \\eqref{joint_accept_prob2}  reduces  to $\\min\\{1, \\pi(x^\\ast)/\\pi(x^{(i)})\\}$, the acceptance probability of the Metropolis algorithm in \\eqref{accept_m}. The proposed algorithm accepts the joint proposal $(z^\\ast, x^\\ast)$ as $(z^{(i+1)}, x^{(i+1)})$ with the probability in \\eqref{joint_accept_prob2} and sets $(z^{(i+1)}, x^{(i+1)})$ to $(z^{(i)}, x^{(i)})$ otherwise.  In Section~\\ref{conclusion}, we discuss the difference between our auxiliary variable approach and a grouped independence Metropolis-Hastings algorithm \\citep{beaumont2003, andrieu2009}.\n \n\n\n\n\n\n\n\\begin{algorithm}[!h]\n\n\\caption{(Proposed Algorithm) A  repulsive-attractive Metropolis algorithm.~~~~~~~~~~~~~~~~~~~~~} \\label{al1}\n\\vspace*{-12pt}\n\\begin{tabbing}\n   \\enspace Set initial values $Z^{(0)}$ and $x^{(0)}$. For $i=0, 1, \\ldots$\\\\\n   \\enspace \\emph{Step} 1: Resample $x'\\sim q(x'\\mid x^{(i)})$ and  $u_1\\sim \\textrm{Uniform}(0, 1)$ until $u_1< \\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}$.\\\\\n    \\enspace \\emph{Step} 2: Resample $x^\\ast\\sim q(x^\\ast\\mid x')$ and $u_2\\sim \\textrm{Uniform}(0, 1)$ until $u_2<\\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}$.\\\\\n   \\enspace \\emph{Step} 3: Resample $z^\\ast\\sim q(z^\\ast\\mid x^\\ast)$ and $u_3\\sim \\textrm{Uniform}(0, 1)$ until $u_3< \\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(z^\\ast)+\\epsilon}\\right\\}$.\\\\\n   \\enspace \\emph{Step} 4: Sample $u_4\\sim  \\textrm{Uniform}(0, 1)$.\\\\\n   \\enspace \\emph{Step} 5: Set $(z^{(i+1)}, x^{(i+1)})=(z^\\ast, x^\\ast)$ if $u_4<\\alpha^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})$ with $\\alpha^\\textrm{J}$ given in \\eqref{joint_accept_prob2}\\\\\n   \\qquad ~~~~~ and  set $(z^{(i+1)}, x^{(i+1)})=(z^{(i)}, x^{(i)})$ otherwise.\n\\end{tabbing}\n\\end{algorithm}\n\nAltogether, each iteration of the proposed algorithm is composed of five steps as shown in  Algorithm \\ref{al1} above. The first three  generate a proposal via  three consecutive forced transitions; \\emph{Step} 1 for the downward proposal $x'$ given $x^{(i)}$, \\emph{Step} 2 for the upward proposal $x^\\ast$ given $x'$, and \\emph{Step} 3 for the downward proposal $z^\\ast$ given $x^\\ast$. The last two steps determine whether the joint proposal, $(z^\\ast, x^\\ast)$, is accepted or not. \n\n\n\n\n\n\n\n\n\n\n\\section{Numerical examples}\\label{examples}\n\n\n\\begin{figure}[b!]\n\\begin{center}\n\\includegraphics[scale = 0.3]{ee_contour8.eps}\n\n\\caption{The first panel exhibits the contour plot of the target density in Example 1, case (a) and the second panel shows that of the target density in Example 1, case (b). The plotted contours outline regimes with probability 1\\%, 10\\%, 50\\%, and 95\\% under $\\pi(x)$.}\n\\label{ee_contour}\n\\end{center}\n\\end{figure}\n\n\\subsection{Example 1: A mixture of 20 bivariate Gaussian densities}\nOur first numerical illustration targets a mixture of 20 bivariate Gaussian distributions, given in  \\cite{kou2006},\n\n", "itemtype": "equation", "pos": 17539, "prevtext": "\nSuppose it is possible to draw a sample from $q_1$ but difficult to evaluate $q_1$. We can find a function $f$ such that $q_1(x^{(i)} \\mid  x^\\ast)/q_1(x^\\ast \\mid  x^{(i)}) = f(x^{(i)})/ f(x^\\ast)$ because the ratio of two (compatible) conditional densities is the ratio of two marginal densities. The function $f$ may or may not be computable and can be a normalizing constant of $q_1$ but not necessarily. If we can find a function $q_2$ whose normalizing constant is proportional to $f$, then the joint acceptance probability in \\eqref{joint_accept_prob} becomes free of the intractable quantities.\n\nFor the repulsive-attractive Metropolis algorithm, we set $q_1(x^\\ast \\mid  x^{(i)})=q^\\textrm{DU}(x^\\ast\\mid x^{(i)})$ to propose a down-up movement from $x^{(i)}$ to $x^\\ast$, where $q^{\\textrm{DU}}$ is specified in \\eqref{transition_VMH}. In this case, $f(x^{(i)})=A^\\textrm{D}(x^{(i)})$ which is the normalizing constant of the forced downhill kernel density $q^{\\textrm{D}}$ in \\eqref{mixture_f}. To eliminate this intractable integral, we choose $q_2(z^\\ast\\mid  x^\\ast)=q^\\textrm{D}(z^\\ast\\mid x^\\ast)$. \\cite{moller2006} suggest choosing $\\pi^\\textrm{C}$ similar to $q_2$ and thus we assume $\\pi^\\textrm{C}(z^\\ast\\mid x^\\ast)$ equals $q(z^\\ast\\mid x^\\ast)$. With these choices, the acceptance probability in  \\eqref{joint_accept_prob} reduces to\n\n", "index": 29, "text": "\\begin{align}\n&\\alpha^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)q(z^\\ast\\mid x^\\ast)q^\\textrm{DU}(x^{(i)}\\mid x^\\ast)q^\\textrm{D}(z^{(i)}\\mid x^{(i)})}{\\pi(x^{(i)})q(z^{(i)}\\mid x^{(i)})q^\\textrm{DU}(x^\\ast\\mid x^{(i)})q^\\textrm{D}( z^\\ast\\mid x^\\ast)}\\right\\}\\nonumber\\\\\n&=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)q(z^\\ast\\mid x^\\ast)A^\\textrm{D}(x^{(i)})q(z^{(i)}\\mid x^{(i)}) \\alpha^{\\textrm{D}}_\\epsilon(z^{(i)}\\mid x^{(i)})/A^\\textrm{D}(x^{(i)}) }{\\pi(x^{(i)})q(z^{(i)}\\mid x^{(i)})A^\\textrm{D}(x^\\ast)\\}q(z^\\ast\\mid x^\\ast) \\alpha^{\\textrm{D}}_\\epsilon(z^\\ast\\mid x^\\ast)/A^\\textrm{D}(x^\\ast)}\\right\\}\\nonumber\\\\\n&=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)\\alpha^{\\textrm{D}}_\\epsilon(z^{(i)}\\mid x^{(i)})  }{\\pi(x^{(i)}) \\alpha^{\\textrm{D}}_\\epsilon(z^\\ast\\mid x^\\ast) }\\right\\}=\\min\\left\\{1,~ \\frac{\\pi(x^\\ast)\\min\\{1, \\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(z^{(i)})+\\epsilon}\\}}{\\pi(x^{(i)})\\min\\{1, \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(z^\\ast)+\\epsilon}\\} }\\right\\}.\\label{joint_accept_prob2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha^{\\textrm{J}}(z^{\\ast},x^{\\ast}\\mid z^{(i)},x^{(i)})=\\min%&#10;\\left\\{1,~{}\\frac{\\pi(x^{\\ast})q(z^{\\ast}\\mid x^{\\ast})q^{\\textrm{DU}}(x^{(i)}%&#10;\\mid x^{\\ast})q^{\\textrm{D}}(z^{(i)}\\mid x^{(i)})}{\\pi(x^{(i)})q(z^{(i)}\\mid x%&#10;^{(i)})q^{\\textrm{DU}}(x^{\\ast}\\mid x^{(i)})q^{\\textrm{D}}(z^{\\ast}\\mid x^{%&#10;\\ast})}\\right\\}\" display=\"inline\"><mrow><msup><mi>\u03b1</mi><mtext>J</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>,</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>min</mi><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>DU</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>q</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})q(z^{\\ast}\\mid x^{\\ast})A^{%&#10;\\textrm{D}}(x^{(i)})q(z^{(i)}\\mid x^{(i)})\\alpha^{\\textrm{D}}_{\\epsilon}(z^{(i%&#10;)}\\mid x^{(i)})/A^{\\textrm{D}}(x^{(i)})}{\\pi(x^{(i)})q(z^{(i)}\\mid x^{(i)})A^{%&#10;\\textrm{D}}(x^{\\ast})\\}q(z^{\\ast}\\mid x^{\\ast})\\alpha^{\\textrm{D}}_{\\epsilon}(%&#10;z^{\\ast}\\mid x^{\\ast})/A^{\\textrm{D}}(x^{\\ast})}\\right\\}\" display=\"inline\"><mrow><mi/><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>A</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><msup><mi>A</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mi>q</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msup><mi>A</mi><mtext>D</mtext></msup><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo><mi>q</mi><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo><mi>\u03b1</mi><msup><mi/><mtext>D</mtext></msup><msub><mi/><mi>\u03f5</mi></msub><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo><mo>/</mo><mi>A</mi><msup><mi/><mtext>D</mtext></msup><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})\\alpha^{\\textrm{D}}_{\\epsilon%&#10;}(z^{(i)}\\mid x^{(i)})}{\\pi(x^{(i)})\\alpha^{\\textrm{D}}_{\\epsilon}(z^{\\ast}%&#10;\\mid x^{\\ast})}\\right\\}=\\min\\left\\{1,~{}\\frac{\\pi(x^{\\ast})\\min\\{1,\\frac{\\pi(x%&#10;^{(i)})+\\epsilon}{\\pi(z^{(i)})+\\epsilon}\\}}{\\pi(x^{(i)})\\min\\{1,\\frac{\\pi(x^{%&#10;\\ast})+\\epsilon}{\\pi(z^{\\ast})+\\epsilon}\\}}\\right\\}.\" display=\"inline\"><mrow><mrow><mi/><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>\u2223</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><msubsup><mi>\u03b1</mi><mi>\u03f5</mi><mtext>D</mtext></msubsup><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo>\u2223</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mfrac><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>z</mi><mo>\u2217</mo></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03f5</mi></mrow></mfrac><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mfrac></mstyle><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere $x=(x_1, x_2)^{ \\mathrm{\\scriptscriptstyle T} }$, The 20 mean vectors,  $\\{\\mu_1, \\ldots, \\mu_{20}\\}$,  are specified in \\cite{kou2006} and plotted in the first panel of Fig.~\\ref{ee_contour}. Following \\cite{kou2006}, we consider two cases; in case (a), the modes are equally weighted and have equal variances, $w_j=1/20$ and  $\\tau^2_j=1/100$, and in case (b) weights and variances are unequal, $w_j=1/\\lVert \\mu_j- (5, 5)^{ \\mathrm{\\scriptscriptstyle T} }\\rVert$ and {$\\tau^2_j=\\lVert \\mu_j-(5, 5)^{ \\mathrm{\\scriptscriptstyle T} }\\rVert/20$}. In case (b), modes near (5, 5) are more heavily weighted and have smaller variances.  Contour plots of the target distributions in cases (a) and (b), respectively, appear in Fig.~\\ref{ee_contour}. Contour lines correspond to 1\\%, 10\\%, 50\\%, and 95\\% probability.\n\n\n\n\\cite{kou2006} used this target distribution to compare the equi-energy sampler and parallel tempering. We follow their simulation configurations by running the proposed algorithm for 100,000 iterations,  discarding the first 50,000  for each of the two cases. Our repulsive-attractive algorithm is initialized at two random values of $x^{(0)}$ and $z^{(0)}$ in the unit square, $[0, 1]\\times[0, 1]$.  The proposed algorithm requires choosing $q(a\\mid b)$ and  we set $q(a\\mid b)=\\textrm{Normal}(a\\mid b, \\sigma^2I_2)$. For tuning $\\sigma$, we ran ten independent chains with ten different values of $\\sigma\\in\\{3\\!\\cdot\\!0, 3\\!\\cdot\\!5, 4\\!\\cdot\\!0, \\ldots, 7\\!\\cdot\\!5\\}$. To choose an appropriate value of $\\sigma$ we consider both whether a chain visited all the modes and its autocorrelation function; \\cite{kou2006} used these criteria to tune a temperature-related parameter. The value of $\\sigma$ that led to the best autocorrelation function of a chain that visited all the modes was 4 in case (a) and $3\\!\\cdot\\!5$ in case (b). The acceptance rate is $0\\!\\cdot\\!048$ for case (a) and $0\\!\\cdot\\!228$ for case~(b).  \\cite{kou2006} did not report the CPU time required by the equi-energy sampler or that required by the parallel tempering. The proposed algorithm, however, takes an average of 4,680 seconds in case (a) and 4,950 seconds in case (b) (averaging over 20 independent runs using two 8-core Intel Xeon E5-2690 at $2\\!\\cdot\\!9$ GHz and 64 GB of memory). \n\n\n\n\\begin{figure}[b!]\n\\begin{center}\n\\includegraphics[scale = 0.3]{ee_dumh3.eps}\n\n\\caption{Results of the repulsive-attractive Metropolis algorithm in Example 1. The first column displays bivariate scatter plots for 50,000 samples, the middle column displays the bivariate trace plots for the last 2,000 samples for case (a) and  the last 1,000 samples for case (b), and the last column displays the autocorrelation functions for 50,000 samples of $x_1$. }\n\\label{example_summary2}\n\\end{center}\n\\end{figure}\n\n\n\nUsing the samples obtained with $\\sigma=4$ for case (a) and $\\sigma=3\\!\\cdot\\!5$ for case (b), we display the bivariate scatter plots for 50,000 samples, the bivariate trace plots for the last 2,000 iterations for case (a) and the last 1,000 iterations for case (b), and the autocorrelation functions for 50,000 samples of $x_1$ in Fig.~\\ref{example_summary2}. The  numbers of iterations used in the trace plots are the same as those in \\cite{kou2006}. These plots can be compared to those for the equi-energy sampler and those for the parallel tempering provided in \\cite{kou2006}.\n\n\n\n\n\\begin{table}[t!]\n\\def~{\\hphantom{0}}\n\\tbl{Moment estimates for cases (a) and (b) of Example 1 based on 20 independent chains, each of length 50,000,  generated with our proposed algorithm, the equi-energy sampler, and parallel tempering. Results for the latter two samplers are reproduced from \\cite{kou2006}. Estimates are the means over the 20 runs; standard deviations of the 20 runs are given in the parentheses next to estimates}{\n\\begin{tabular}{lrrrrcc}\n \\\\\n\\multirow{2}{*}{Case (a)}& \\multicolumn{1}{c}{\\multirow{2}{*}{Truth}}  & \\multicolumn{1}{c}{\\multirow{2}{*}{RAM}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{EE}} &   \\multicolumn{1}{c}{\\multirow{2}{*}{PT}} & {\\sc MSE} ratio & {\\sc MSE} ratio \\\\\n&   &  &  &   & (EE~/~RAM) & (PT~/~RAM)\\[3pt]\n$E(x_1)$ &  $4\\!\\cdot\\!478$  & $4\\!\\cdot\\!4741$ $(0\\!\\cdot\\!094)$ & $4\\!\\cdot\\!5019$ $(0\\!\\cdot\\!107)$ & $4\\!\\cdot\\!4185$ $(0\\!\\cdot\\!170)$ & $1\\!\\cdot\\!36$ & $3\\!\\cdot\\!67$\\\\\n$E(x_2)$ & $4\\!\\cdot\\!905$  & $4\\!\\cdot\\!9016$ $(0\\!\\cdot\\!107)$ & $4\\!\\cdot\\!9439$ $(0\\!\\cdot\\!139)$ & $4\\!\\cdot\\!8790$ $(0\\!\\cdot\\!283)$ & $1\\!\\cdot\\!82$ & $7\\!\\cdot\\!05$\\\\\n$E(x^2_1)$ & $25\\!\\cdot\\!605$  & $25\\!\\cdot\\!6251$ $(0\\!\\cdot\\!943)$ & $25\\!\\cdot\\!9241$ $(1\\!\\cdot\\!098)$ & $24\\!\\cdot\\!9856$ $(1\\!\\cdot\\!713)$ & $1\\!\\cdot\\!47$ & $3\\!\\cdot\\!73$\\\\\n$E(x^2_2)$ & $33\\!\\cdot\\!920$  & $33\\!\\cdot\\!8972$ $(1\\!\\cdot\\!083)$ & $34\\!\\cdot\\!4763$ $(1\\!\\cdot\\!373)$ & $33\\!\\cdot\\!5966$ $(2\\!\\cdot\\!867)$ & $1\\!\\cdot\\!87$ & $7\\!\\cdot\\!09$\\\\\n\\\\\n\\multirow{2}{*}{Case (b)}&  \\multicolumn{1}{c}{\\multirow{2}{*}{Truth}}   &  \\multicolumn{1}{c}{\\multirow{2}{*}{RAM}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{EE}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{PT}} & {\\sc MSE} ratio & {\\sc MSE} ratio \\\\\n&   &  &  &   & (EE~/~RAM) & (PT~/~RAM)\\[3pt]\n$E(x_1)$ &  $4\\!\\cdot\\!688$  & $4\\!\\cdot\\!687$ $(0\\!\\cdot\\!026)$ & $4\\!\\cdot\\!699$ $(0\\!\\cdot\\!072)$ & $4\\!\\cdot\\!709$ $(0\\!\\cdot\\!116)$ & $7\\!\\cdot\\!84$ & $20\\!\\cdot\\!53$\\\\\n$E(x_2)$ & $5\\!\\cdot\\!030$  & $5\\!\\cdot\\!035$ $(0\\!\\cdot\\!039)$ & $5\\!\\cdot\\!037$ $(0\\!\\cdot\\!086)$ & $5\\!\\cdot\\!001$ $(0\\!\\cdot\\!134)$ & $4\\!\\cdot\\!82$ & $12\\!\\cdot\\!16$\\\\\n$E(x^2_1)$ & $25\\!\\cdot\\!558$  & $25\\!\\cdot\\!662$ $(0\\!\\cdot\\!252)$ & $25\\!\\cdot\\!693$ $(0\\!\\cdot\\!739)$ & $25\\!\\cdot\\!813$ $(1\\!\\cdot\\!122)$ & $7\\!\\cdot\\!59$ & $17\\!\\cdot\\!81$\\\\\n$E(x^2_2)$ & $31\\!\\cdot\\!378$  & $31\\!\\cdot\\!532$ $(0\\!\\cdot\\!330)$ & $31\\!\\cdot\\!433$ $(0\\!\\cdot\\!839)$ & $31\\!\\cdot\\!105$ $(1\\!\\cdot\\!186)$ & $5\\!\\cdot\\!33$ & $11\\!\\cdot\\!17$\\\\\n\\end{tabular}}\n\\label{summary_table}\n\\begin{tabnote}\nRAM, repulsive-attractive Metropolis; EE, Equi-Energy sampler; PT, Parallel Tempering; MSE, Mean Squared Error.\n\\end{tabnote}\n\\end{table}\n\n\n\n\n\nTo estimate moments, we again follow \\cite{kou2006} and run 20 independent chains using our proposed algorithm. Table~\\ref{summary_table} summarizes the moment estimates, where results of the equi-energy sampler and parallel tempering  are from \\cite{kou2006}. The ratios of the mean squared error of both the equi-energy sampler and parallel tempering to that of the proposed algorithm are greater than one, meaning that in terms of mean squared error the proposed algorithm performs uniformly better than both. The improvement is particularly striking for the case with unequal weights and variances. However, we emphasize that this comparison does not take into account the CPU time, because it is not reported in \\cite{kou2006}.  We do, however, compare CPU time in a more realistic example in Section \\ref{example2}.\n\n\n\\subsection{Example 2: Time delay estimation problem}\\label{example2}\nOur second numerical illustration involves an applied astrophysical problem that originally motivated the repulsive-attractive Metropolis algorithm.  Quasars are highly luminous astronomical sources in the\ndistant Universe. If there is a massive galaxy between a quasar and the Earth, the gravitational field of the intervening galaxy may act as a strong lens, bending the light rays emitted by the quasar. From our vantage points, two (or more) images of the  quasar may appear in slightly different locations on the sky. This effect is known as strong gravitational lensing \\citep{schneider2006}.  Because the light corresponding to the two images may take different routes to the Earth, their travel times may also  differ. This difference is called a time delay. If we construct a time series of the brightness of each image, temporal features appear shifted in time between the two or more images because of the time delay. Accurate time delay estimation is important because it is, for example, used to calculate the current expansion rate of the Universe \\citep{refsdal1964}.  \n\n\n\n\nFigure~\\ref{tdc1} displays two irregularly-observed  time series of the brightness of doubly-lensed quasar Q0957+561 \\citep{hainline2012}; the two time series are labeled $A$ and $B$. Brightness is reported on a magnitude scale where smaller values correspond to brighter images. Let $x(t)\\equiv \\{x(t_1), \\ldots, x(t_n)\\}$ and $y(t)\\equiv\\{y(t_1), \\ldots, y(t_n)\\}$ denote the $n$ observed magnitudes in time series $A$ and $B$, respectively. Let $\\delta(t)\\equiv \\{\\delta(t_1),  \\ldots, \\delta(t_n)\\}$ and $\\eta(t)\\equiv\\{\\eta(t_1), \\ldots, \\eta(t_n)\\}$ represent the  $n$ known standard deviations of the measurement errors for $x(t)$ and $y(t)$, respectively. There are 57 observations in the time series of Q0957+561, i.e.,  $n=57$.\n\\begin{figure}[t!]\n\\begin{center}\n\\includegraphics[scale = 0.33]{tdc_data9.eps}\n\n\\caption{Two observed time series of doubly-lensed quasar Q0957+561 \\citep{hainline2012}.  Time series $A$ is denoted by triangles and time series $B$ is denoted by circles. Magnitude is an astronomical  measure of brightness. Both time series are plotted with an offset (constant) in magnitude, but this obviously does not matter for estimating the time delay. Here we shifted time series $B$ by 0$\\cdot$4 magnitude in the $y$-axis to display two time series in the same plot. The convention in astrophysics is to plot the magnitude inversely so that  smaller magnitudes (brighter image) appear on the top and larger ones (fainter image) on the bottom.}\n\\label{tdc1}\n\\end{center}\n\\end{figure}\n\n\n\n\nWe assume that for each observed time series there is an unobserved underlying brightness curve. Let $X(t)\\equiv \\{X(t_1), \\ldots, X(t_n)\\}$ denote the latent magnitudes for time series~$A$ and $Y(t)\\equiv \\{Y(t_1), \\ldots, Y(t_n)\\}$ denote those for time series~$B$. We assume that one of the latent brightness curves is a shifted version of the other, i.e., \n\n", "itemtype": "equation", "pos": 21884, "prevtext": "\nIn \\eqref{joint_accept_prob2}, $\\pi(z^{(i)})$ is likely to be smaller than $\\pi(x^{(i)})$ because $z^{(i)}$ is generated by the forced downhill  transition. Similarly, $\\pi(z^\\ast)$ is likely to be smaller than $\\pi(x^\\ast)$. If $z^{(i)}$ and $z^\\ast$ have lower target densities than $x^{(i)}$ and $x^\\ast$, respectively (a likely, but not required situation), then the acceptance probability in \\eqref{joint_accept_prob2}  reduces  to $\\min\\{1, \\pi(x^\\ast)/\\pi(x^{(i)})\\}$, the acceptance probability of the Metropolis algorithm in \\eqref{accept_m}. The proposed algorithm accepts the joint proposal $(z^\\ast, x^\\ast)$ as $(z^{(i+1)}, x^{(i+1)})$ with the probability in \\eqref{joint_accept_prob2} and sets $(z^{(i+1)}, x^{(i+1)})$ to $(z^{(i)}, x^{(i)})$ otherwise.  In Section~\\ref{conclusion}, we discuss the difference between our auxiliary variable approach and a grouped independence Metropolis-Hastings algorithm \\citep{beaumont2003, andrieu2009}.\n \n\n\n\n\n\n\n\\begin{algorithm}[!h]\n\n\\caption{(Proposed Algorithm) A  repulsive-attractive Metropolis algorithm.~~~~~~~~~~~~~~~~~~~~~} \\label{al1}\n\\vspace*{-12pt}\n\\begin{tabbing}\n   \\enspace Set initial values $Z^{(0)}$ and $x^{(0)}$. For $i=0, 1, \\ldots$\\\\\n   \\enspace \\emph{Step} 1: Resample $x'\\sim q(x'\\mid x^{(i)})$ and  $u_1\\sim \\textrm{Uniform}(0, 1)$ until $u_1< \\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^{(i)})+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}$.\\\\\n    \\enspace \\emph{Step} 2: Resample $x^\\ast\\sim q(x^\\ast\\mid x')$ and $u_2\\sim \\textrm{Uniform}(0, 1)$ until $u_2<\\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(x')+\\epsilon}\\right\\}$.\\\\\n   \\enspace \\emph{Step} 3: Resample $z^\\ast\\sim q(z^\\ast\\mid x^\\ast)$ and $u_3\\sim \\textrm{Uniform}(0, 1)$ until $u_3< \\textrm{min}\\!\\left\\{1,~ \\frac{\\pi(x^\\ast)+\\epsilon}{\\pi(z^\\ast)+\\epsilon}\\right\\}$.\\\\\n   \\enspace \\emph{Step} 4: Sample $u_4\\sim  \\textrm{Uniform}(0, 1)$.\\\\\n   \\enspace \\emph{Step} 5: Set $(z^{(i+1)}, x^{(i+1)})=(z^\\ast, x^\\ast)$ if $u_4<\\alpha^\\textrm{J}(z^\\ast, x^\\ast\\mid z^{(i)}, x^{(i)})$ with $\\alpha^\\textrm{J}$ given in \\eqref{joint_accept_prob2}\\\\\n   \\qquad ~~~~~ and  set $(z^{(i+1)}, x^{(i+1)})=(z^{(i)}, x^{(i)})$ otherwise.\n\\end{tabbing}\n\\end{algorithm}\n\nAltogether, each iteration of the proposed algorithm is composed of five steps as shown in  Algorithm \\ref{al1} above. The first three  generate a proposal via  three consecutive forced transitions; \\emph{Step} 1 for the downward proposal $x'$ given $x^{(i)}$, \\emph{Step} 2 for the upward proposal $x^\\ast$ given $x'$, and \\emph{Step} 3 for the downward proposal $z^\\ast$ given $x^\\ast$. The last two steps determine whether the joint proposal, $(z^\\ast, x^\\ast)$, is accepted or not. \n\n\n\n\n\n\n\n\n\n\n\\section{Numerical examples}\\label{examples}\n\n\n\\begin{figure}[b!]\n\\begin{center}\n\\includegraphics[scale = 0.3]{ee_contour8.eps}\n\n\\caption{The first panel exhibits the contour plot of the target density in Example 1, case (a) and the second panel shows that of the target density in Example 1, case (b). The plotted contours outline regimes with probability 1\\%, 10\\%, 50\\%, and 95\\% under $\\pi(x)$.}\n\\label{ee_contour}\n\\end{center}\n\\end{figure}\n\n\\subsection{Example 1: A mixture of 20 bivariate Gaussian densities}\nOur first numerical illustration targets a mixture of 20 bivariate Gaussian distributions, given in  \\cite{kou2006},\n\n", "index": 31, "text": "\\begin{equation}\n\\pi(x)\\propto \\sum_{j=1}^{20}\\frac{w_j}{\\tau^2_j}\\exp\\left(-\\frac{1}{2\\tau^2_j}(x-\\mu_j)^{ \\mathrm{\\scriptscriptstyle T} }(x-\\mu_j)\\right),\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\pi(x)\\propto\\sum_{j=1}^{20}\\frac{w_{j}}{\\tau^{2}_{j}}\\exp\\left(-\\frac{1}{2%&#10;\\tau^{2}_{j}}(x-\\mu_{j})^{\\mathrm{\\scriptscriptstyle T}}(x-\\mu_{j})\\right),\" display=\"block\"><mrow><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u221d</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mn>20</mn></munderover><mrow><mfrac><msub><mi>w</mi><mi>j</mi></msub><msubsup><mi>\u03c4</mi><mi>j</mi><mn>2</mn></msubsup></mfrac><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><msubsup><mi>\u03c4</mi><mi>j</mi><mn>2</mn></msubsup></mrow></mfrac><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>\u03bc</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mi mathsize=\"71%\" mathvariant=\"normal\">T</mi></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>x</mi><mo>-</mo><msub><mi>\u03bc</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere $\\Delta$ is the unknown time delay and $\\beta_0$ is an unknown magnitude offset. This  is called a curve-shifted model. \n\nEach observed magnitude is assumed to be independent Gaussian  conditioning on its  latent magnitude,\n\n", "itemtype": "equation", "pos": 31976, "prevtext": "\nwhere $x=(x_1, x_2)^{ \\mathrm{\\scriptscriptstyle T} }$, The 20 mean vectors,  $\\{\\mu_1, \\ldots, \\mu_{20}\\}$,  are specified in \\cite{kou2006} and plotted in the first panel of Fig.~\\ref{ee_contour}. Following \\cite{kou2006}, we consider two cases; in case (a), the modes are equally weighted and have equal variances, $w_j=1/20$ and  $\\tau^2_j=1/100$, and in case (b) weights and variances are unequal, $w_j=1/\\lVert \\mu_j- (5, 5)^{ \\mathrm{\\scriptscriptstyle T} }\\rVert$ and {$\\tau^2_j=\\lVert \\mu_j-(5, 5)^{ \\mathrm{\\scriptscriptstyle T} }\\rVert/20$}. In case (b), modes near (5, 5) are more heavily weighted and have smaller variances.  Contour plots of the target distributions in cases (a) and (b), respectively, appear in Fig.~\\ref{ee_contour}. Contour lines correspond to 1\\%, 10\\%, 50\\%, and 95\\% probability.\n\n\n\n\\cite{kou2006} used this target distribution to compare the equi-energy sampler and parallel tempering. We follow their simulation configurations by running the proposed algorithm for 100,000 iterations,  discarding the first 50,000  for each of the two cases. Our repulsive-attractive algorithm is initialized at two random values of $x^{(0)}$ and $z^{(0)}$ in the unit square, $[0, 1]\\times[0, 1]$.  The proposed algorithm requires choosing $q(a\\mid b)$ and  we set $q(a\\mid b)=\\textrm{Normal}(a\\mid b, \\sigma^2I_2)$. For tuning $\\sigma$, we ran ten independent chains with ten different values of $\\sigma\\in\\{3\\!\\cdot\\!0, 3\\!\\cdot\\!5, 4\\!\\cdot\\!0, \\ldots, 7\\!\\cdot\\!5\\}$. To choose an appropriate value of $\\sigma$ we consider both whether a chain visited all the modes and its autocorrelation function; \\cite{kou2006} used these criteria to tune a temperature-related parameter. The value of $\\sigma$ that led to the best autocorrelation function of a chain that visited all the modes was 4 in case (a) and $3\\!\\cdot\\!5$ in case (b). The acceptance rate is $0\\!\\cdot\\!048$ for case (a) and $0\\!\\cdot\\!228$ for case~(b).  \\cite{kou2006} did not report the CPU time required by the equi-energy sampler or that required by the parallel tempering. The proposed algorithm, however, takes an average of 4,680 seconds in case (a) and 4,950 seconds in case (b) (averaging over 20 independent runs using two 8-core Intel Xeon E5-2690 at $2\\!\\cdot\\!9$ GHz and 64 GB of memory). \n\n\n\n\\begin{figure}[b!]\n\\begin{center}\n\\includegraphics[scale = 0.3]{ee_dumh3.eps}\n\n\\caption{Results of the repulsive-attractive Metropolis algorithm in Example 1. The first column displays bivariate scatter plots for 50,000 samples, the middle column displays the bivariate trace plots for the last 2,000 samples for case (a) and  the last 1,000 samples for case (b), and the last column displays the autocorrelation functions for 50,000 samples of $x_1$. }\n\\label{example_summary2}\n\\end{center}\n\\end{figure}\n\n\n\nUsing the samples obtained with $\\sigma=4$ for case (a) and $\\sigma=3\\!\\cdot\\!5$ for case (b), we display the bivariate scatter plots for 50,000 samples, the bivariate trace plots for the last 2,000 iterations for case (a) and the last 1,000 iterations for case (b), and the autocorrelation functions for 50,000 samples of $x_1$ in Fig.~\\ref{example_summary2}. The  numbers of iterations used in the trace plots are the same as those in \\cite{kou2006}. These plots can be compared to those for the equi-energy sampler and those for the parallel tempering provided in \\cite{kou2006}.\n\n\n\n\n\\begin{table}[t!]\n\\def~{\\hphantom{0}}\n\\tbl{Moment estimates for cases (a) and (b) of Example 1 based on 20 independent chains, each of length 50,000,  generated with our proposed algorithm, the equi-energy sampler, and parallel tempering. Results for the latter two samplers are reproduced from \\cite{kou2006}. Estimates are the means over the 20 runs; standard deviations of the 20 runs are given in the parentheses next to estimates}{\n\\begin{tabular}{lrrrrcc}\n \\\\\n\\multirow{2}{*}{Case (a)}& \\multicolumn{1}{c}{\\multirow{2}{*}{Truth}}  & \\multicolumn{1}{c}{\\multirow{2}{*}{RAM}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{EE}} &   \\multicolumn{1}{c}{\\multirow{2}{*}{PT}} & {\\sc MSE} ratio & {\\sc MSE} ratio \\\\\n&   &  &  &   & (EE~/~RAM) & (PT~/~RAM)\\[3pt]\n$E(x_1)$ &  $4\\!\\cdot\\!478$  & $4\\!\\cdot\\!4741$ $(0\\!\\cdot\\!094)$ & $4\\!\\cdot\\!5019$ $(0\\!\\cdot\\!107)$ & $4\\!\\cdot\\!4185$ $(0\\!\\cdot\\!170)$ & $1\\!\\cdot\\!36$ & $3\\!\\cdot\\!67$\\\\\n$E(x_2)$ & $4\\!\\cdot\\!905$  & $4\\!\\cdot\\!9016$ $(0\\!\\cdot\\!107)$ & $4\\!\\cdot\\!9439$ $(0\\!\\cdot\\!139)$ & $4\\!\\cdot\\!8790$ $(0\\!\\cdot\\!283)$ & $1\\!\\cdot\\!82$ & $7\\!\\cdot\\!05$\\\\\n$E(x^2_1)$ & $25\\!\\cdot\\!605$  & $25\\!\\cdot\\!6251$ $(0\\!\\cdot\\!943)$ & $25\\!\\cdot\\!9241$ $(1\\!\\cdot\\!098)$ & $24\\!\\cdot\\!9856$ $(1\\!\\cdot\\!713)$ & $1\\!\\cdot\\!47$ & $3\\!\\cdot\\!73$\\\\\n$E(x^2_2)$ & $33\\!\\cdot\\!920$  & $33\\!\\cdot\\!8972$ $(1\\!\\cdot\\!083)$ & $34\\!\\cdot\\!4763$ $(1\\!\\cdot\\!373)$ & $33\\!\\cdot\\!5966$ $(2\\!\\cdot\\!867)$ & $1\\!\\cdot\\!87$ & $7\\!\\cdot\\!09$\\\\\n\\\\\n\\multirow{2}{*}{Case (b)}&  \\multicolumn{1}{c}{\\multirow{2}{*}{Truth}}   &  \\multicolumn{1}{c}{\\multirow{2}{*}{RAM}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{EE}} &  \\multicolumn{1}{c}{\\multirow{2}{*}{PT}} & {\\sc MSE} ratio & {\\sc MSE} ratio \\\\\n&   &  &  &   & (EE~/~RAM) & (PT~/~RAM)\\[3pt]\n$E(x_1)$ &  $4\\!\\cdot\\!688$  & $4\\!\\cdot\\!687$ $(0\\!\\cdot\\!026)$ & $4\\!\\cdot\\!699$ $(0\\!\\cdot\\!072)$ & $4\\!\\cdot\\!709$ $(0\\!\\cdot\\!116)$ & $7\\!\\cdot\\!84$ & $20\\!\\cdot\\!53$\\\\\n$E(x_2)$ & $5\\!\\cdot\\!030$  & $5\\!\\cdot\\!035$ $(0\\!\\cdot\\!039)$ & $5\\!\\cdot\\!037$ $(0\\!\\cdot\\!086)$ & $5\\!\\cdot\\!001$ $(0\\!\\cdot\\!134)$ & $4\\!\\cdot\\!82$ & $12\\!\\cdot\\!16$\\\\\n$E(x^2_1)$ & $25\\!\\cdot\\!558$  & $25\\!\\cdot\\!662$ $(0\\!\\cdot\\!252)$ & $25\\!\\cdot\\!693$ $(0\\!\\cdot\\!739)$ & $25\\!\\cdot\\!813$ $(1\\!\\cdot\\!122)$ & $7\\!\\cdot\\!59$ & $17\\!\\cdot\\!81$\\\\\n$E(x^2_2)$ & $31\\!\\cdot\\!378$  & $31\\!\\cdot\\!532$ $(0\\!\\cdot\\!330)$ & $31\\!\\cdot\\!433$ $(0\\!\\cdot\\!839)$ & $31\\!\\cdot\\!105$ $(1\\!\\cdot\\!186)$ & $5\\!\\cdot\\!33$ & $11\\!\\cdot\\!17$\\\\\n\\end{tabular}}\n\\label{summary_table}\n\\begin{tabnote}\nRAM, repulsive-attractive Metropolis; EE, Equi-Energy sampler; PT, Parallel Tempering; MSE, Mean Squared Error.\n\\end{tabnote}\n\\end{table}\n\n\n\n\n\nTo estimate moments, we again follow \\cite{kou2006} and run 20 independent chains using our proposed algorithm. Table~\\ref{summary_table} summarizes the moment estimates, where results of the equi-energy sampler and parallel tempering  are from \\cite{kou2006}. The ratios of the mean squared error of both the equi-energy sampler and parallel tempering to that of the proposed algorithm are greater than one, meaning that in terms of mean squared error the proposed algorithm performs uniformly better than both. The improvement is particularly striking for the case with unequal weights and variances. However, we emphasize that this comparison does not take into account the CPU time, because it is not reported in \\cite{kou2006}.  We do, however, compare CPU time in a more realistic example in Section \\ref{example2}.\n\n\n\\subsection{Example 2: Time delay estimation problem}\\label{example2}\nOur second numerical illustration involves an applied astrophysical problem that originally motivated the repulsive-attractive Metropolis algorithm.  Quasars are highly luminous astronomical sources in the\ndistant Universe. If there is a massive galaxy between a quasar and the Earth, the gravitational field of the intervening galaxy may act as a strong lens, bending the light rays emitted by the quasar. From our vantage points, two (or more) images of the  quasar may appear in slightly different locations on the sky. This effect is known as strong gravitational lensing \\citep{schneider2006}.  Because the light corresponding to the two images may take different routes to the Earth, their travel times may also  differ. This difference is called a time delay. If we construct a time series of the brightness of each image, temporal features appear shifted in time between the two or more images because of the time delay. Accurate time delay estimation is important because it is, for example, used to calculate the current expansion rate of the Universe \\citep{refsdal1964}.  \n\n\n\n\nFigure~\\ref{tdc1} displays two irregularly-observed  time series of the brightness of doubly-lensed quasar Q0957+561 \\citep{hainline2012}; the two time series are labeled $A$ and $B$. Brightness is reported on a magnitude scale where smaller values correspond to brighter images. Let $x(t)\\equiv \\{x(t_1), \\ldots, x(t_n)\\}$ and $y(t)\\equiv\\{y(t_1), \\ldots, y(t_n)\\}$ denote the $n$ observed magnitudes in time series $A$ and $B$, respectively. Let $\\delta(t)\\equiv \\{\\delta(t_1),  \\ldots, \\delta(t_n)\\}$ and $\\eta(t)\\equiv\\{\\eta(t_1), \\ldots, \\eta(t_n)\\}$ represent the  $n$ known standard deviations of the measurement errors for $x(t)$ and $y(t)$, respectively. There are 57 observations in the time series of Q0957+561, i.e.,  $n=57$.\n\\begin{figure}[t!]\n\\begin{center}\n\\includegraphics[scale = 0.33]{tdc_data9.eps}\n\n\\caption{Two observed time series of doubly-lensed quasar Q0957+561 \\citep{hainline2012}.  Time series $A$ is denoted by triangles and time series $B$ is denoted by circles. Magnitude is an astronomical  measure of brightness. Both time series are plotted with an offset (constant) in magnitude, but this obviously does not matter for estimating the time delay. Here we shifted time series $B$ by 0$\\cdot$4 magnitude in the $y$-axis to display two time series in the same plot. The convention in astrophysics is to plot the magnitude inversely so that  smaller magnitudes (brighter image) appear on the top and larger ones (fainter image) on the bottom.}\n\\label{tdc1}\n\\end{center}\n\\end{figure}\n\n\n\n\nWe assume that for each observed time series there is an unobserved underlying brightness curve. Let $X(t)\\equiv \\{X(t_1), \\ldots, X(t_n)\\}$ denote the latent magnitudes for time series~$A$ and $Y(t)\\equiv \\{Y(t_1), \\ldots, Y(t_n)\\}$ denote those for time series~$B$. We assume that one of the latent brightness curves is a shifted version of the other, i.e., \n\n", "index": 33, "text": "\\begin{equation}\\label{fundamental}\nY(t_j)=X(t_j-\\Delta)+\\beta_0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"Y(t_{j})=X(t_{j}-\\Delta)+\\beta_{0},\" display=\"block\"><mrow><mrow><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>t</mi><mi>j</mi></msub><mo>-</mo><mi mathvariant=\"normal\">\u0394</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03b2</mi><mn>0</mn></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nUsing the model in  \\eqref{fundamental}, we can express  \\eqref{lik2} as\n\n", "itemtype": "equation", "pos": 32287, "prevtext": "\nwhere $\\Delta$ is the unknown time delay and $\\beta_0$ is an unknown magnitude offset. This  is called a curve-shifted model. \n\nEach observed magnitude is assumed to be independent Gaussian  conditioning on its  latent magnitude,\n\n", "index": 35, "text": "\\begin{align}\nx(t_j)\\mid X(t_j) &\\sim \\textrm{Normal}\\!\\left(X(t_j),~  \\delta^2(t_j)\\right)\\!,\\nonumber\\\\\ny(t_j)\\mid Y(t_j ) &\\sim \\textrm{Normal}\\!\\left(Y(t_j),~ \\eta^2(t_j)\\right)\\!.\\label{lik2}\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle x(t_{j})\\mid X(t_{j})\" display=\"inline\"><mrow><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\textrm{Normal}\\!\\left(X(t_{j}),~{}\\delta^{2}(t_{j})\\right)\\!,\" display=\"inline\"><mrow><mrow><mi/><mo>\u223c</mo><mrow><mpadded width=\"-1.7pt\"><mtext>Normal</mtext></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"5.8pt\">,</mo><mrow><msup><mi>\u03b4</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.8pt\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle y(t_{j})\\mid Y(t_{j})\" display=\"inline\"><mrow><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi>Y</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\textrm{Normal}\\!\\left(Y(t_{j}),~{}\\eta^{2}(t_{j})\\right)\\!.\" display=\"inline\"><mrow><mrow><mi/><mo>\u223c</mo><mrow><mpadded width=\"-1.7pt\"><mtext>Normal</mtext></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"5.8pt\">,</mo><mrow><msup><mi>\u03b7</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.8pt\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\n\nWe  assume that the latent magnitudes follow an Ornstein-Uhlenbeck process \\citep{kelly2009}. The solution of a stochastic differential equation of the Ornstein-Uhlenbeck process yields the sampling distribution of the time-sorted latent magnitudes $X(t^\\Delta)$, where $t^\\Delta\\equiv(t^\\Delta_1, \\ldots, t^\\Delta_{2n})^{ \\mathrm{\\scriptscriptstyle T} }$ is the sorted $2n$ times among the $n$ observation times, $t$, and the $n$ time-delay-shifted observation times, $t-\\Delta$. Specifically,\n\n", "itemtype": "equation", "pos": 32569, "prevtext": "\nUsing the model in  \\eqref{fundamental}, we can express  \\eqref{lik2} as\n\n", "index": 37, "text": "\\begin{equation}\\nonumber\ny(t_j)\\mid X(t_j - \\Delta), \\Delta, \\beta_0 \\sim \\textrm{Normal}\\!\\left(X(t_j - \\Delta) + \\beta_0,~ \\eta^2(t_j)\\right)\\!.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"y(t_{j})\\mid X(t_{j}-\\Delta),\\Delta,\\beta_{0}\\sim\\textrm{Normal}\\!\\left(X(t_{j%&#10;}-\\Delta)+\\beta_{0},~{}\\eta^{2}(t_{j})\\right)\\!.\" display=\"block\"><mrow><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo>-</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><msub><mi>\u03b2</mi><mn>0</mn></msub><mo>\u223c</mo><mpadded width=\"-1.7pt\"><mtext>Normal</mtext></mpadded><mrow><mo>(</mo><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo>-</mo><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">)</mo></mrow><mo>+</mo><msub><mi>\u03b2</mi><mn>0</mn></msub><mo rspace=\"5.8pt\">,</mo><msup><mi>\u03b7</mi><mn>2</mn></msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"0.8pt\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nwhere $\\theta\\equiv (\\mu, \\phi^2, \\tau)^{ \\mathrm{\\scriptscriptstyle T} }$ and $a_j=\\exp( -(t^\\Delta_j-t^\\Delta_{j-1})/\\tau)$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nA Bayesian analysis requires prior distributions on the several parameters; $\\Delta$ follows a Uniform[$t_1-t_n,~t_n-t_1]=[-1178.939,~1178.939]$, $\\beta_0$ follows a Uniform$[-60, 60]$, $\\mu$ follows a Uniform$[-30, 30]$, $\\phi^2$ follows an inverse-Gamma$(1, 2/10^{7})$,  and $\\tau$ follows an inverse-Gamma(1, 1), where $v\\sim \\textrm{inverse-Gamma}(a, b)$ has a density function proportional to $v^{-a-1}\\exp(-b/v)$. Further details and motivation for this model, including the choice  of prior distributions, are given in an unpublished technical report available from the first author.   \n\n\n\n\nTo sample from the   joint posterior density function, ${\\pi(X(t^\\Delta), \\Delta, \\beta_0, \\theta \\mid x(t), y(t))}$, we adopt a Metropolis-Hastings within Gibbs sampler \\citep{tierney1994} composed of three steps as shown in Algorithm \\ref{al2} below. We suppress conditioning on $x(t)$ and $y(t)$ in all three steps here and elsewhere. \n\\begin{algorithm}[h!]\n\\caption{A Metropolis-Hastings within Gibbs sampler for the time delay model.~~~~~~~~~~~~~~~} \\label{al2}\n\\vspace*{-8pt}\n\\begin{tabbing}\n   \\enspace Set initial values $\\Delta^{(0)}$,  $X^{(0)}(t^{\\Delta^{(0)}})$, $\\beta_0^{(0)}$, and $\\theta^{(0)}$. For $i=1, 2, \\ldots$\\\\\n   \\enspace \\emph{Step} 1: Draw $\\left(X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}\\right)\\sim  \\pi\\left(X(t^\\Delta), \\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right)$\\\\\n   \\enspace ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=~$\\pi\\left(X(t^\\Delta)\\mid \\Delta, \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right) \\pi\\left(\\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right).$\\\\\n    \\enspace \\emph{Step} 2: Draw $\\beta^{(i)}_0\\sim \\pi\\left(\\beta_0 \\mid \\theta^{(i-1)}, X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}\\right)$.\\\\\n   \\enspace \\emph{Step} 3: Draw $\\theta^{(i)} \\sim \\pi\\left(\\theta \\mid X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}, \\beta^{(i)}_0\\right).$\n\\end{tabbing}\n\\end{algorithm}\n\nThe factorization in \\emph{Step}~1 means that we first sample $\\Delta$ given $\\beta_0$ and $\\theta$, and then sample $X(t^\\Delta)$ given $\\Delta$, $\\beta_0$, and $\\theta$. See the supplementary material available online for details of the necessary complete conditional distributions.\n\n\nBecause the marginal posterior distribution of the time delay  is often multimodal, we compare  tempered transitions \\citep{neal1996} with our repulsive-attractive Metropolis algorithm to  sample $\\Delta$ from $\\pi(\\Delta\\mid\\beta_0, \\theta)$ in \\emph{Step} 1 of Algorithm \\ref{al2} above. At each iteration, the tempered transitions ascend (heating) the temperature ladder to explore a flatter surface where the modes are melted down, and then descend (cooling) the ladder, accepting the last candidate with a modified acceptance probability to maintain the stationary distribution. Specifically, suppose ${\\pi_j(\\Delta)\\propto  \\{\\pi(\\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)})\\}^{1/T_j}}$, where $T_j$ is the temperature at rung $j$ of the temperature ladder, for $j=1, \\ldots, J$). The target density is $\\pi_0(\\Delta)$ with $T_0=1$ and the ladder  has $J$ rungs with  {$T_0=1<T_1<\\cdots<T_{J}$}.  At the beginning of iteration $i$, we generate $\\hat{\\Delta}_1$ from $\\textrm{Normal}(\\Delta^{(i-1)}, \\sigma^2)$, and accept it with probability $\\min(1, \\pi_1(\\hat{\\Delta}_1)/\\pi_1(\\Delta^{(i-1)}))$ and  set $\\hat{\\Delta}_1=\\Delta^{(i-1)}$ otherwise. Next, we generate $\\hat{\\Delta}_2$ from $\\textrm{Normal}(\\hat{\\Delta}_1, \\sigma^2)$, and accept it with  probability $\\min(1, \\pi_2(\\hat{\\Delta}_2)/\\pi_2(\\hat{\\Delta}_1))$ and  set $\\hat{\\Delta}_2=\\hat{\\Delta}_1$ otherwise. We repeat this process until we reach the top of the temperature ladder, collecting $\\hat{\\Delta}_1, \\ldots, \\hat{\\Delta}_J$. At the top, we generate $\\check{\\Delta}_{J-1}$ from  $\\textrm{Normal}(\\hat{\\Delta}_J, \\sigma^2)$, and accept it with probability $\\min(1, \\pi_{J-1}(\\check{\\Delta}_{J-1})/\\pi_{J-1}(\\hat{\\Delta}_J))$ and set $\\check{\\Delta}_{J-1}=\\hat{\\Delta}_J$ otherwise. We repeat this process until  we reach the bottom of the temperature ladder, collecting $\\check{\\Delta}_{J-1}, \\ldots, \\check{\\Delta}_{0}$. We set $\\Delta^{(i)}=\\check{\\Delta}_{0}$  with probability\n\n", "itemtype": "equation", "pos": 33228, "prevtext": "\n\nWe  assume that the latent magnitudes follow an Ornstein-Uhlenbeck process \\citep{kelly2009}. The solution of a stochastic differential equation of the Ornstein-Uhlenbeck process yields the sampling distribution of the time-sorted latent magnitudes $X(t^\\Delta)$, where $t^\\Delta\\equiv(t^\\Delta_1, \\ldots, t^\\Delta_{2n})^{ \\mathrm{\\scriptscriptstyle T} }$ is the sorted $2n$ times among the $n$ observation times, $t$, and the $n$ time-delay-shifted observation times, $t-\\Delta$. Specifically,\n\n", "index": 39, "text": "\\begin{align} \nX(t_1^\\Delta)\\mid \\Delta, \\theta &~\\sim~ \\textrm{Normal}\\!\\left(\\mu,~ \\frac{\\tau\\phi^2}{2}\\right)\\!, ~~~~~\\textrm{and for}~ j=2, 3, \\ldots, 2n,\\nonumber\\\\\n~~X(t_j^\\Delta)\\mid X(t_{j-1}^\\Delta), \\Delta, \\theta &~\\sim~ \\textrm{Normal}\\!\\left(\\mu + a_j\\big(X(t_{j-1}^\\Delta) - \\mu\\big) ,~\\frac{\\tau \\phi^2}{2}(1-a^2_j)\\right)\\!,\\nonumber\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle X(t_{1}^{\\Delta})\\mid\\Delta,\\theta\" display=\"inline\"><mrow><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>t</mi><mn>1</mn><mi mathvariant=\"normal\">\u0394</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><mi>\u03b8</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle~{}\\sim~{}\\textrm{Normal}\\!\\left(\\mu,~{}\\frac{\\tau\\phi^{2}}{2}%&#10;\\right)\\!,~{}~{}~{}~{}~{}\\textrm{and for}~{}j=2,3,\\ldots,2n,\" display=\"inline\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u00a0</mi><mo rspace=\"5.8pt\">\u223c</mo><mrow><mpadded width=\"-1.7pt\"><mtext>Normal</mtext></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mi>\u03bc</mi><mo rspace=\"5.8pt\">,</mo><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c4</mi><mo>\u2062</mo><msup><mi>\u03d5</mi><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle><mo rspace=\"0.8pt\">)</mo></mrow></mrow></mrow><mo rspace=\"19pt\">,</mo><mrow><mrow><mpadded width=\"+3.3pt\"><mtext>and for</mtext></mpadded><mo>\u2062</mo><mi>j</mi></mrow><mo>=</mo><mrow><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>n</mi></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle~{}~{}X(t_{j}^{\\Delta})\\mid X(t_{j-1}^{\\Delta}),\\Delta,\\theta\" display=\"inline\"><mrow><mpadded width=\"+3.3pt\"><mi mathvariant=\"normal\">\u00a0</mi></mpadded><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>t</mi><mi>j</mi><mi mathvariant=\"normal\">\u0394</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>\u2223</mo><mi>X</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>t</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u0394</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi mathvariant=\"normal\">\u0394</mi><mo>,</mo><mi>\u03b8</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle~{}\\sim~{}\\textrm{Normal}\\!\\left(\\mu+a_{j}\\big{(}X(t_{j-1}^{%&#10;\\Delta})-\\mu\\big{)},~{}\\frac{\\tau\\phi^{2}}{2}(1-a^{2}_{j})\\right)\\!,\" display=\"inline\"><mrow><mrow><mi mathvariant=\"normal\">\u00a0</mi><mo rspace=\"5.8pt\">\u223c</mo><mrow><mpadded width=\"-1.7pt\"><mtext>Normal</mtext></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><msub><mi>a</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>t</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u0394</mi></msubsup><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>\u03bc</mi></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo rspace=\"5.8pt\">,</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>\u03c4</mi><mo>\u2062</mo><msup><mi>\u03d5</mi><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msubsup><mi>a</mi><mi>j</mi><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo rspace=\"0.8pt\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05633.tex", "nexttext": "\nand set $\\Delta^{(i)}=\\Delta^{(i-1)}$ otherwise. \n\nTo sample $\\Delta$ from $\\pi(\\Delta\\mid\\beta_0, \\theta)$ in \\emph{Step} 1 via the repulsive-attractive Metropolis algorithm, we additionally keep track of the auxiliary variable during the run, i.e., \\{$z^{(i)}$, $i=0, 1, 2, \\ldots$\\}. Our sampler  requires that we set $q(a\\mid b)$ and here we use $\\textrm{Normal}(a\\mid b, \\sigma^2)$. At iteration~$i$, we  sequentially draw {$\\Delta'\\sim q^{\\textrm{D}}(\\Delta'\\mid \\Delta^{(i-1)})$}, {$\\Delta^\\ast\\sim q^{\\textrm{U}}(\\Delta^\\ast\\mid \\Delta')$}, and {$z^\\ast\\sim q^{\\textrm{D}}(z^\\ast\\mid \\Delta^\\ast)$}. We set $(z^{(i)}, \\Delta^{(i)})$ to $(z^\\ast, \\Delta^\\ast)$ with  probability $\\alpha^\\textrm{J}(z^\\ast, \\Delta^\\ast\\mid z^{(i-1)}, \\Delta^{(i-1)})$ given  in \\eqref{joint_accept_prob2}, and set $(z^{(i)}, \\Delta^{(i)})$ to $(z^{(i-1)}, \\Delta^{(i-1)})$ otherwise.  Because \\{$z^{(i)}$, $i=0, 1, 2, \\ldots$\\} are introduced solely to enable sampling $\\Delta$ from $\\pi(\\Delta\\mid\\beta_0, \\theta)$, only $\\Delta^{(i)}$ is used to sample $X(t^\\Delta)$, $\\beta_0$, and $\\theta$  for the following steps in  Algorithm \\ref{al2}. \n\n\nWe fit the time delay model using the Metropolis-Hastings within Gibbs sampler equipped with either the tempered transitions or the repulsive-attractive Metropolis algorithm. In both cases, we draw 110,000 samples and discarded the first 10,000. Both algorithms were initialized at the same point;  $\\Delta^{(0)}=0$, $\\beta_0^{(0)}=\\sum_{j=1}^n\\{y(t_j)-x(t_j)\\}/n=-0\\!\\cdot\\!113$, $\\mu^{(0)}=\\sum_{j=1}^nx(t_j)/n={2\\!\\cdot\\!658}$, $\\phi^{(0)}=0\\!\\cdot\\!01$,  $\\tau^{(0)}=200$, and $X^{(0)}(t^{\\Delta^{(0)}})$ is a vector of $x(t)$ and $y(t-\\Delta^{(0)})-\\beta_0^{(0)}$ that are sorted in time. For our proposed algorithm we set $z^{(0)}=0$. \n\n\nTempered transitions require several tuning parameters, i.e., the number of rungs of the temperature ladder, the temperature of each rung, and the proposal scale. Setting these parameters can be challenging in practice \\citep{behrens2012}.  To fit the  Q0957+561 data, we set $J=10$ and  $T_j=3^j$ for $j=1, \\ldots, 10$. The scale of the proposal density $\\sigma$ plays the same role as that in the repulsive-attractive Metropolis algorithm. To choose an effective $\\sigma$, we ran twelve  chains independently with twelve different values of $\\sigma\\in\\{50, 100, 150, \\ldots, 600\\}$, selecting the one that maximized the number of jumps between modes, i.e., $\\sigma=150$ for  tempered transitions and $\\sigma=400$ for our proposed algorithm. \n\nOnce $\\sigma$ was set, we ran ten chains independently for each algorithm and combined them. The average CPU time for running a chain via the Metropolis-Hastings within Gibbs sampler equipped with tempered transitions is 10,209 seconds and that with our proposed algorithm is 4,590 seconds (averaging over ten independent runs and using two 8-core Intel Xeon E5-2690 at $2\\!\\cdot\\!9$ GHz and 64 GB of memory). The average acceptance rate for our algorithm ($0\\!\\cdot\\!126$) is about twice as large as that for the tempered transitions ($0\\!\\cdot\\!066$).\n\n\n\n\n\\begin{figure}[b!]\n\\begin{center}\n\\includegraphics[scale = 0.29]{tdc_comp3.eps}\n\n\\caption{The histograms and trace plots of 1,000,000 samples of $\\Delta$ based on the tempered transitions, TT, (1st row) and the repulsive-attractive Metropolis, RAM, algorithm (2nd row).}\n\\label{tdc2}\n\\end{center}\n\\end{figure}\n\n\n\n\nFigure \\ref{tdc2} shows the histograms and trace plots of the combined one million samples of $\\Delta$ based on tempered transitions (1st row) and the repulsive-attractive Metropolis algorithm (2nd row).  The mode near 400 days is about 600 standard deviations away from the  modes near 1,100 days. (The standard deviation of the mode near 400 days is $1\\!\\cdot\\!2$ days). It is clear that the proposed algorithm enables jumps between extremely distant modes more frequently than the tempered transitions. The numbers of jumps between the mode near 400 days and modes near 1,100 days for ten independent runs of the tempered transitions are \\{2,  16, 2, 8, 0, 2, 16, 14, 4, 6\\}, summing  to 70. Similarly, the numbers of jumps for ten independent runs of our proposed algorithm are {\\{0, 2, 18, 8, 12, 30, 24, 17, 12, 16\\}}, summing  to 139. This means that the total number of jumps per unit CPU time for our proposed algorithm is $4\\!\\cdot\\!42$ times larger than that for  tempered transitions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Concluding remarks}\\label{conclusion}\nEven with bug-free compact code, running an algorithm may require significant human time if the algorithm must be tuned. Unfortunately, most temperature-based methods may require significant human time for tuning, especially for non-experts. Also, running multiple chains for different temperature levels is computationally burdensome. In this sense, our repulsive-attractive Metropolis algorithm can be a simpler and faster alternative to temperature-based methods. This is because our algorithm can be coded  as simply as a standard Metropolis algorithm with a single tuning parameter. \n\n\nAlthough we use an auxiliary variable technique to derive the acceptance probability in \\eqref{joint_accept_prob}, the acceptance probability may resemble that of a grouped independence Metropolis-Hastings algorithm \\citep{beaumont2003, andrieu2009} that focuses on an unbiased estimator for an intractable target density. However, our auxiliary variable approach is different from the grouped independence Metropolis-Hastings algorithm because our approach focuses on canceling an intractable integral that arises from an intractable proposal density (from which we can draw a sample but we cannot evaluate it) given a completely computable target density $\\pi$. \n\n\n\n\n\n\n\nWe do not believe, however, that our algorithm will always perform more favorably than the tempering-based methods, and  more work needs to be done to extend its applicability. In particular, we need to compare the theoretical convergence rate of our algorithm to others. Also, different ways to encourage a down-up movement in density may exist.  Another avenue for further improvement would be allowing an  asymmetric density $q$ because the current algorithm constrains $q$ to be symmetric. Furthermore, it may be possible to generalize our method to handle a case where $\\pi$ itself is intractable.  Applying this down-up idea to finding a global optimum of a multimodal density function is another possible   extension. We leave these for  future research.\n\n\n\n \n\n\n\\section{Acknowledgement}\nThis project was conducted under the auspices of the CHASC International Astrostatistics Center. CHASC is supported by the United States National Science Foundation grants DMS 1208791, DMS 1209232, DMS 1513492, DMS 1513484, and DMS 1513546. Xiao-Li Meng acknowledges partial financial support from the United States National Science Foundation. David A. van Dyk acknowledges support from a Wolfson Research Merit Award provided by the British Royal Society and from a Marie-Curie Career Integration Grant provided by the European Commission.  The authors thank Steven Finch for his careful proofreading.\n\n\n\\section{Supplementary material}\n\\label{SM}\nSupplementary materials are available  online that include both the details of the conditional distributions used in the Metropolis-Hastings within Gibbs sampler  in  Algorithm \\ref{al2}, i.e., $p(X(t^\\Delta)\\mid \\Delta, \\beta_0, \\theta)$, $p(\\Delta \\mid \\beta_0, \\theta)$, $p(\\beta_0 \\mid \\theta, X(t^{\\Delta}), \\Delta)$, and ${p(\\theta \\mid X(t^{\\Delta}), \\Delta, \\beta_0)}$ and all the R codes used in this article.\n\n\n\n\n\n\\bibliographystyle{apalike}\n\\bibliography{bibliography}\n\n\n\n", "itemtype": "equation", "pos": 37894, "prevtext": "\nwhere $\\theta\\equiv (\\mu, \\phi^2, \\tau)^{ \\mathrm{\\scriptscriptstyle T} }$ and $a_j=\\exp( -(t^\\Delta_j-t^\\Delta_{j-1})/\\tau)$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nA Bayesian analysis requires prior distributions on the several parameters; $\\Delta$ follows a Uniform[$t_1-t_n,~t_n-t_1]=[-1178.939,~1178.939]$, $\\beta_0$ follows a Uniform$[-60, 60]$, $\\mu$ follows a Uniform$[-30, 30]$, $\\phi^2$ follows an inverse-Gamma$(1, 2/10^{7})$,  and $\\tau$ follows an inverse-Gamma(1, 1), where $v\\sim \\textrm{inverse-Gamma}(a, b)$ has a density function proportional to $v^{-a-1}\\exp(-b/v)$. Further details and motivation for this model, including the choice  of prior distributions, are given in an unpublished technical report available from the first author.   \n\n\n\n\nTo sample from the   joint posterior density function, ${\\pi(X(t^\\Delta), \\Delta, \\beta_0, \\theta \\mid x(t), y(t))}$, we adopt a Metropolis-Hastings within Gibbs sampler \\citep{tierney1994} composed of three steps as shown in Algorithm \\ref{al2} below. We suppress conditioning on $x(t)$ and $y(t)$ in all three steps here and elsewhere. \n\\begin{algorithm}[h!]\n\\caption{A Metropolis-Hastings within Gibbs sampler for the time delay model.~~~~~~~~~~~~~~~} \\label{al2}\n\\vspace*{-8pt}\n\\begin{tabbing}\n   \\enspace Set initial values $\\Delta^{(0)}$,  $X^{(0)}(t^{\\Delta^{(0)}})$, $\\beta_0^{(0)}$, and $\\theta^{(0)}$. For $i=1, 2, \\ldots$\\\\\n   \\enspace \\emph{Step} 1: Draw $\\left(X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}\\right)\\sim  \\pi\\left(X(t^\\Delta), \\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right)$\\\\\n   \\enspace ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~=~$\\pi\\left(X(t^\\Delta)\\mid \\Delta, \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right) \\pi\\left(\\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)}\\right).$\\\\\n    \\enspace \\emph{Step} 2: Draw $\\beta^{(i)}_0\\sim \\pi\\left(\\beta_0 \\mid \\theta^{(i-1)}, X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}\\right)$.\\\\\n   \\enspace \\emph{Step} 3: Draw $\\theta^{(i)} \\sim \\pi\\left(\\theta \\mid X^{(i)}(t^{\\Delta^{(i)}}), \\Delta^{(i)}, \\beta^{(i)}_0\\right).$\n\\end{tabbing}\n\\end{algorithm}\n\nThe factorization in \\emph{Step}~1 means that we first sample $\\Delta$ given $\\beta_0$ and $\\theta$, and then sample $X(t^\\Delta)$ given $\\Delta$, $\\beta_0$, and $\\theta$. See the supplementary material available online for details of the necessary complete conditional distributions.\n\n\nBecause the marginal posterior distribution of the time delay  is often multimodal, we compare  tempered transitions \\citep{neal1996} with our repulsive-attractive Metropolis algorithm to  sample $\\Delta$ from $\\pi(\\Delta\\mid\\beta_0, \\theta)$ in \\emph{Step} 1 of Algorithm \\ref{al2} above. At each iteration, the tempered transitions ascend (heating) the temperature ladder to explore a flatter surface where the modes are melted down, and then descend (cooling) the ladder, accepting the last candidate with a modified acceptance probability to maintain the stationary distribution. Specifically, suppose ${\\pi_j(\\Delta)\\propto  \\{\\pi(\\Delta \\mid \\beta^{(i-1)}_0, \\theta^{(i-1)})\\}^{1/T_j}}$, where $T_j$ is the temperature at rung $j$ of the temperature ladder, for $j=1, \\ldots, J$). The target density is $\\pi_0(\\Delta)$ with $T_0=1$ and the ladder  has $J$ rungs with  {$T_0=1<T_1<\\cdots<T_{J}$}.  At the beginning of iteration $i$, we generate $\\hat{\\Delta}_1$ from $\\textrm{Normal}(\\Delta^{(i-1)}, \\sigma^2)$, and accept it with probability $\\min(1, \\pi_1(\\hat{\\Delta}_1)/\\pi_1(\\Delta^{(i-1)}))$ and  set $\\hat{\\Delta}_1=\\Delta^{(i-1)}$ otherwise. Next, we generate $\\hat{\\Delta}_2$ from $\\textrm{Normal}(\\hat{\\Delta}_1, \\sigma^2)$, and accept it with  probability $\\min(1, \\pi_2(\\hat{\\Delta}_2)/\\pi_2(\\hat{\\Delta}_1))$ and  set $\\hat{\\Delta}_2=\\hat{\\Delta}_1$ otherwise. We repeat this process until we reach the top of the temperature ladder, collecting $\\hat{\\Delta}_1, \\ldots, \\hat{\\Delta}_J$. At the top, we generate $\\check{\\Delta}_{J-1}$ from  $\\textrm{Normal}(\\hat{\\Delta}_J, \\sigma^2)$, and accept it with probability $\\min(1, \\pi_{J-1}(\\check{\\Delta}_{J-1})/\\pi_{J-1}(\\hat{\\Delta}_J))$ and set $\\check{\\Delta}_{J-1}=\\hat{\\Delta}_J$ otherwise. We repeat this process until  we reach the bottom of the temperature ladder, collecting $\\check{\\Delta}_{J-1}, \\ldots, \\check{\\Delta}_{0}$. We set $\\Delta^{(i)}=\\check{\\Delta}_{0}$  with probability\n\n", "index": 41, "text": "\\begin{equation}\n\\min\\left\\{1,~~ \\frac{\\pi_1(\\Delta^{(i-1)})}{\\pi_0(\\Delta^{(i-1)})}\\times\\cdots\\times\\frac{\\pi_J(\\hat{\\Delta}_{J-1})}{\\pi_{J-1}(\\hat{\\Delta}_{J-1})} \\frac{\\pi_{J-1}(\\check{\\Delta}_{J-1})}{\\pi_{J}(\\check{\\Delta}_{J-1})}\\times\\cdots\\times\\frac{\\pi_0(\\check{\\Delta}_0)}{\\pi_1(\\check{\\Delta}_0)}\\right\\}\\nonumber\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"\\min\\left\\{1,~{}~{}\\frac{\\pi_{1}(\\Delta^{(i-1)})}{\\pi_{0}(\\Delta^{(i-1)})}%&#10;\\times\\cdots\\times\\frac{\\pi_{J}(\\hat{\\Delta}_{J-1})}{\\pi_{J-1}(\\hat{\\Delta}_{J%&#10;-1})}\\frac{\\pi_{J-1}(\\check{\\Delta}_{J-1})}{\\pi_{J}(\\check{\\Delta}_{J-1})}%&#10;\\times\\cdots\\times\\frac{\\pi_{0}(\\check{\\Delta}_{0})}{\\pi_{1}(\\check{\\Delta}_{0%&#10;})}\\right\\}\" display=\"block\"><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo rspace=\"9.1pt\">,</mo><mrow><mrow><mrow><mfrac><mrow><msub><mi>\u03c0</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u0394</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c0</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi mathvariant=\"normal\">\u0394</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u00d7</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>\u00d7</mo><mfrac><mrow><msub><mi>\u03c0</mi><mi>J</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c0</mi><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">^</mo></mover><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>\u2062</mo><mfrac><mrow><msub><mi>\u03c0</mi><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u02c7</mo></mover><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c0</mi><mi>J</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u02c7</mo></mover><mrow><mi>J</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>\u00d7</mo><mi mathvariant=\"normal\">\u22ef</mi><mo>\u00d7</mo><mfrac><mrow><msub><mi>\u03c0</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u02c7</mo></mover><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msub><mi>\u03c0</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"normal\">\u0394</mi><mo stretchy=\"false\">\u02c7</mo></mover><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>}</mo></mrow></mrow></math>", "type": "latex"}]