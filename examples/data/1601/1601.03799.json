[{"file": "1601.03799.tex", "nexttext": "\nand we recognize this as the discrete-time version of an integrator (summer) with a variable gain.\nAs mentioned earlier, the gain sequence $\\{A_n\\}$ is designed to enhance the stability margins of the closed-loop system and\nreduce oscillations of the tracking algorithm while speeding up its convergence. As we shall see, one way to achieve that\nis to have $A_{n}$ be defined as\n\n", "itemtype": "equation", "pos": 5655, "prevtext": "\n\\begin{frontmatter}\n\n\\title{Performance Regulation of Event-Driven Dynamical Systems  Using\n\tInfinitesimal Perturbation Analysis}\n\n\n\n\n\n\n\n\\tnotetext[]{{Research  supported in\n\t\tpart by  the NSF under Grant CNS-1239225.}  }\n\n\n\n\n\n\\author[First]{Y. Wardi}\n\\author[Second]{C. Seatzu}\n\\author[Third]{X. Chen}\n\\author[Fourth]{S. Yalamanchili}\n\n\n\\address[First]{School of Electrical and Computer Engineering,\n\t\\\\ Georgia Institute of Technology, Atlanta, Georgia, USA \\\\ (e-mail:\n\tywardi@ece.gatech.edu).}\n\\address[Second]{Department of Electrical and Electronic\nEngineering,\\\\ University of Cagliari, Italy \\\\ (e-mail:\nseatzu @ diee.unica.it).}\n\\address[Third]{School of Electrical and Computer Engineering,\n\t\\\\ Georgia Institute of Technology, Atlanta, Georgia, USA \\\\ (e-mail:\n\txchen318@gatech.edu).}\n\\address[Fourth]{School of Electrical and Computer Engineering,\n\t\\\\ Georgia Institute of Technology, Atlanta, Georgia, USA \\\\ (e-mail:\n\tsudha@ece.gatech.edu).}\n\n\n\n\n\n\n\n\n\n\\begin{abstract}\n This paper presents a performance-regulation method for a class of stochastic timed event-driven systems\naimed at output tracking of a given reference setpoint. The systems are either Discrete Event Dynamic Systems (DEDS)\nsuch as queueing networks or Petri nets, or Hybrid Systems (HS) with time-driven dynamics and event-driven dynamics,\nlike fluid queues and hybrid Petri nets.\nThe regulator,\ndesigned for simplicity and speed of computation, is comprised of  a single integrator having a variable gain to ensure\n effective tracking under time-varying plants.\n The gain's computation  is based on the Infinitesimal Perturbation Analysis (IPA) gradient of the plant function with\nrespect to the control variable, and the resultant tracking  can be quite robust with respect to modeling inaccuracies and gradient-estimation errors.\nThe proposed  technique is tested on examples taken from various application\nareas and modeled with different formalisms, including queueing models, Petri-net model of a production-inventory\n control system, and a stochastic DEDS model of a multicore chip control.\nSimulation results are presented in support of the proposed approach.\n \\end{abstract}\n\n\\begin{keyword}\nInfinitesimal perturbation analysis,  timed DEDS, stochastic hybrid systems,   performance regulation.\n\\end{keyword}\n\\end{frontmatter}\n\n\n\n\n\n\n\\section{Introduction}\n\n\nThis paper describes a regulation technique for a class of dynamical systems,\ndesigned for output tracking of a given setpoint reference.\nThe regulator consists of an integral control with a variable gain, computed on-line so as to enhance\nthe closed-loop system's stability margins and yield effective tracking. The gain-adjustment algorithm is based on\nthe derivative of the plant's output  with respect to  its input control, and therefore  the regulation technique\nis suitable for systems  where such derivatives are readily computable in real time. This includes a class of\nstochastic timed Discrete Event Dynamic Systems (DEDS) and Hybrid Systems (HD) where the derivative is computable by the\nInfinitesimal Perturbation Analysis (IPA) sample-gradient technique.\n Our motivation is derived from the problem of\nregulating instructions' throughput in multicore computer processors, and following an initial study of that problem in Ref. \\cite{Almoosa12a}\nwe extend  the technique to a general class  of DEDS and HS.\n\nThe need for regulating instruction throughput at the hardware level in modern computer processors stems from\nreal-time applications where constant throughput\nfacilitates effective real-time task and thread (subprogram) scheduling, as well as  from multimedia\napplications where  a fixed frame rate\nmust be maintained to avoid choppy video or audio. The design of effective regulators is challenging\n because of the lack of predictive analytical or prescriptive models,  and  unpredictable high-rate fluctuations of instructions-related\n switching activity factors at the cores.   For this reason, we believe, most of the published control techniques are ad hoc\n (see the survey in Ref. \\cite{Lohn11}). A systematic control-theoretic  approach has been pursued in Refs.\n \\cite{Brinkschulte09,Bauer10,Lohn11} which applied a PID controller and analyzed  the effects of\n proportional\n controls with fixed gains. Concerned with the  unpredictability\n and rapid changes in the thread-related activity    factors, Ref. \\cite{Almoosa12a}  sought a controller with adaptive gain.\n Furthermore, it considered scenarios where measurements and computations in the control loop must be performed as\n quickly as possible, even at the expense of accuracy.  To this end it considered\n controlling the instruction throughput by a core's clock rate, and applied an integral controller\n  whose real-time gain-adaptation algorithm is designed\n for stabilizing the closed-loop system and yielding   effective tracking convergence. The gain-adaptation algorithm is based on IPA\n as described in the sequel.\n\nAn abstract, discrete-time  configuration of the closed-loop system is shown in Figure 1,\nwhere $n$ denotes the time-counter, $r$ is the setpoint reference, $u_n$ is the control input to the plant,   $y_n$ is the\nresulting output, and $e_n:=r-y_n$ is the error signal. The system is single-input-single-output so that all\nthe quantities $u_n$, $y_n$, $e_n$ and $r$ are scalar.\n\nLet $J:R\\rightarrow R$ represent a performance function of the plant with respect to its input $u$, and assume that the function $J(u)$\nis  differentiable. Given the $nth$ input variable $u_n$,  suppose that\nthe the plant's output $y_n$ provides an estimation of $J(u_n)$.\nThe controller that we consider has the form\n\n", "index": 1, "text": "\\begin{equation}\nu_n=u_{n-1}+A_ne_{n-1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"u_{n}=u_{n-1}+A_{n}e_{n-1},\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><msub><mi>A</mi><mi>n</mi></msub><mo>\u2062</mo><msub><mi>e</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwith ``prime'' denoting derivative with respect to $u$.\nHowever,  it may not be possible to compute the derivative term\n$J^{\\prime}(u_{n-1})$, and approximations have to be used. Denoting the approximation error by\n$\\phi_{n-1}$, the computed gain $A_n$ is defined as\n\n", "itemtype": "equation", "pos": 6090, "prevtext": "\nand we recognize this as the discrete-time version of an integrator (summer) with a variable gain.\nAs mentioned earlier, the gain sequence $\\{A_n\\}$ is designed to enhance the stability margins of the closed-loop system and\nreduce oscillations of the tracking algorithm while speeding up its convergence. As we shall see, one way to achieve that\nis to have $A_{n}$ be defined as\n\n", "index": 3, "text": "\\begin{equation}\nA_n=\\Big(J^{\\prime}(u_{n-1})\\Big)^{-1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"A_{n}=\\Big{(}J^{\\prime}(u_{n-1})\\Big{)}^{-1},\" display=\"block\"><mrow><mrow><msub><mi>A</mi><mi>n</mi></msub><mo>=</mo><msup><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><msup><mi>J</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\nIn the systems considered in this paper the  plant  represents average measurements taken from a physical system or a cyber system\nover contiguous time-intervals\ncalled {\\it control cycles}. For example, suppose that the physical\n system is a continuous-time dynamical system with input $\\upsilon(t)$ and output $\\zeta(t)$, $t\\geq 0$;\n its state variable is immaterial for the purpose of this discussion. Divide the  time axis into contiguous control cycles $C_n$, $n=1,2,\\ldots$,  suppose that  the control input\nis fixed during $C_{n}$ to a value $u_n:=v(t)$  $\\forall t\\in C_n$, and define $y_n$ by\n", "itemtype": "equation", "pos": 6429, "prevtext": "\nwith ``prime'' denoting derivative with respect to $u$.\nHowever,  it may not be possible to compute the derivative term\n$J^{\\prime}(u_{n-1})$, and approximations have to be used. Denoting the approximation error by\n$\\phi_{n-1}$, the computed gain $A_n$ is defined as\n\n", "index": 5, "text": "\\begin{equation}\nA_n=\\Big(J^{\\prime}(u_{n-1})+\\phi_{n-1}\\Big)^{-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"A_{n}=\\Big{(}J^{\\prime}(u_{n-1})+\\phi_{n-1}\\Big{)}^{-1}.\" display=\"block\"><mrow><mrow><msub><mi>A</mi><mi>n</mi></msub><mo>=</mo><msup><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><msup><mi>J</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwhere $|C_n|$ is the duration of $C_n$. Alternatively, $y_n$ can represent average measurements taken from the output of a\ndiscrete-time or discrete-event system. Generally we impose no restriction on the way the control\ncycles are defined, they can be fixed a priori or determined by\ncounting events in a DEDS; we only require that\nthe input $u_n$ remains unchanged during $C_{n}$ and can be modified only when the next control cycle\nbegins.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.85\\textwidth]{Figure_1.pdf}\n\n{\\small \\caption{Basic regulation system}}\n\\end{figure}\n\nObserve that Eq. (3) suggests that the computation of $A_{n}$ takes place during\nthe control cycle $C_{n-1}$. In fact, we assume that  the implementation of the control law takes place in the following temporal framework. Suppose that\nthe quantities  $u_{n-1}$, and $y_{n-1}$, $e_{n-1}$, and $A_{n}$ have been computed or measured by the starting time\nof $C_{n}$.\nThen $u_{n}$ is computed from Eq. (1) at the start of $C_{n}$ and we assume that this computation is immediate. During $C_{n}$,\n the plant produces $y_{n}$ from the applied input $u_{n}$ while $A_{n+1}$ is computed from\n Eq. (3), with the index $n+1$ instead of $n$. Finally, $e_{n}$ is computed at the end of $C_{n}$ from the equation\n \n", "itemtype": "equation", "pos": 7114, "prevtext": "\n\nIn the systems considered in this paper the  plant  represents average measurements taken from a physical system or a cyber system\nover contiguous time-intervals\ncalled {\\it control cycles}. For example, suppose that the physical\n system is a continuous-time dynamical system with input $\\upsilon(t)$ and output $\\zeta(t)$, $t\\geq 0$;\n its state variable is immaterial for the purpose of this discussion. Divide the  time axis into contiguous control cycles $C_n$, $n=1,2,\\ldots$,  suppose that  the control input\nis fixed during $C_{n}$ to a value $u_n:=v(t)$  $\\forall t\\in C_n$, and define $y_n$ by\n", "index": 7, "text": "\n\\[\ny_n\\ :=\\ \\frac{1}{|C_n|}\\int_{C_n}\\zeta(t)dt,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"y_{n}\\ :=\\ \\frac{1}{|C_{n}|}\\int_{C_{n}}\\zeta(t)dt,\" display=\"block\"><mrow><mrow><mpadded width=\"+5pt\"><msub><mi>y</mi><mi>n</mi></msub></mpadded><mo rspace=\"7.5pt\">:=</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy=\"false\">|</mo><msub><mi>C</mi><mi>n</mi></msub><mo stretchy=\"false\">|</mo></mrow></mfrac><mo>\u2062</mo><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><msub><mi>C</mi><mi>n</mi></msub></msub><mrow><mi>\u03b6</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n and we assume that this computation is immediate.\n\n The plant's actions yielding  $y_{n}$ from $u_n$ during $C_n$ may represent a physical or cyber process or measurements thereof,\n and  the computation of $A_{n+1}$ is assumed to be carried out concurrently. Of a particular interest to us is the case where\n $J(u_n)$ is an expected-value performance function of a DEDS or HS,\n $y_{n}$ is an approximation thereof computed from a sample path of the system,  and the  term $J^{\\prime}(u_n)+\\phi_n$ in\n the Right-Hand Side (RHS) of Eq. (3) (with $n+1$)\n is computable by IPA.\n One of the main appealing features of IPA is the simplicity of its gradient (derivative)\n algorithms and efficiency of their computation.\n This, however, comes at the expense of accuracy. In particular,  in its principal  application area of queueing systems\n during its earlier development, IPA often yielded  statistically biased gradient estimators (see Refs. \\cite{Ho91,Cassandras99}).\n To ameliorate this problem, Stochastic Flow Models (SFM) consisting of fluid queues (see Refs. \\cite{Cassandras02,Sun04,Cassandras06,Panayiotou06}) and\n later extended to more general\n stochastic HS in Refs.   \\cite{Cassandras10,Wardi10,Wardi13}, offer an alternative framework to queueing networks\n for the application  of IPA; in their setting   the IPA gradients typically are simpler and more accurate.\n Still approximations must be made either in the IPA algorithms or in the system's model when\n a stochastic HS is used as\n a\n  modeling abstraction for a\nDEDS. However, our overriding concern regarding the regulation's control law is that of simplicity and\n computational efficiency even if\n they come at the expense of accuracy.\n This is justified by  sensitivity-analysis  results, derived below,  showing that asymptotic tracking of the regulation\n scheme holds under substantial relative errors in the gradient estimation.\n\n The objective of this paper is to investigate the performance of our proposed tracking  technique on a number of\n DEDS and HS by using the IPA method for computing the integrator's adaptive gain in the loop. In this we leverage on the\n simplicity and low computational efforts required for the IPA derivatives. Furthermore,\n simulation experiments suggest that the regulation algorithm works well despite substantial errors in the\n gradient estimation, thus allowing  us to tilt the balance  between precision and low computing times towards\n fast computation at the expense of accuracy. It may be asked why we use an integral control and not a PI or PID controller, and it\n is pointed out that\n we have tested via simulation (not reported here) the\n addition of a proportional element to the integral control, and found no improvement. This is not surprising since, as indicated\n by the analysis in Section 2, the particular gain-adaptation of the integral controller stabilizes the system for a class of\n plant functions $J(u)$. In summary, the contributions of this paper are: 1). It  proposes the first general-purpose, systematic   performance-regulation technique for a class of timed DEDS and HS. 2). To-date, the main use of IPA has been in optimization, while this paper\n pursues a new kind of application, namely performance regulation. 3). It moves away from the traditional pursuit of unbiased IPA gradients, and instead searches for low-complexity approximations perhaps at the expense of accuracy or unbiasedness. We believe that these three\n points of novelty may open up a new  dimension in the research and applications   of IPA.\n\n  The rest of the paper is organized as follows.\n Section 2  describes the regulation technique in an abstract setting. The following three sections present\n simulation results on three types of systems, and highlight the tradeoffs between simplicity and accuracy.\n Section 3 concerns a queue, Section 4 considers  a fluid Petri net production-control model, and\n Section 5 discusses a DEDS model of throughput  in computer processors. Finally,  Section 6 concludes the paper.\\footnote{The second queueing example in Section 3, and the Petri-net example in Section 4 were presented in, and are part of  \\cite{Seatzu14}.}\n\n\n\n\n\n\n\\section{Regulation Algorithm in an Abstract Setting}\n\nThe rationale behind the choice of $A_{n}$ in Eq. (2) (if its RHS  can be computed exactly) can be seen by considering the simple case where\nthe plant consists of a deterministic, time-invariant, memoryless nonlinearity, and hence the $u_n$~-~to~-~$y_n$ relation has the form\n\n", "itemtype": "equation", "pos": 8466, "prevtext": "\nwhere $|C_n|$ is the duration of $C_n$. Alternatively, $y_n$ can represent average measurements taken from the output of a\ndiscrete-time or discrete-event system. Generally we impose no restriction on the way the control\ncycles are defined, they can be fixed a priori or determined by\ncounting events in a DEDS; we only require that\nthe input $u_n$ remains unchanged during $C_{n}$ and can be modified only when the next control cycle\nbegins.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.85\\textwidth]{Figure_1.pdf}\n\n{\\small \\caption{Basic regulation system}}\n\\end{figure}\n\nObserve that Eq. (3) suggests that the computation of $A_{n}$ takes place during\nthe control cycle $C_{n-1}$. In fact, we assume that  the implementation of the control law takes place in the following temporal framework. Suppose that\nthe quantities  $u_{n-1}$, and $y_{n-1}$, $e_{n-1}$, and $A_{n}$ have been computed or measured by the starting time\nof $C_{n}$.\nThen $u_{n}$ is computed from Eq. (1) at the start of $C_{n}$ and we assume that this computation is immediate. During $C_{n}$,\n the plant produces $y_{n}$ from the applied input $u_{n}$ while $A_{n+1}$ is computed from\n Eq. (3), with the index $n+1$ instead of $n$. Finally, $e_{n}$ is computed at the end of $C_{n}$ from the equation\n \n", "index": 9, "text": "\\begin{equation}\n e_{n}=r-y_{n},\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"e_{n}=r-y_{n},\" display=\"block\"><mrow><mrow><msub><mi>e</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>r</mi><mo>-</mo><msub><mi>y</mi><mi>n</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n Suppose that the function $J(u)$ is differentiable,\nand denote its derivative by $J^{\\prime}(u)$.\nAn application of the Newton-Raphson method for solving the\nequation\n\n", "itemtype": "equation", "pos": 13024, "prevtext": "\n and we assume that this computation is immediate.\n\n The plant's actions yielding  $y_{n}$ from $u_n$ during $C_n$ may represent a physical or cyber process or measurements thereof,\n and  the computation of $A_{n+1}$ is assumed to be carried out concurrently. Of a particular interest to us is the case where\n $J(u_n)$ is an expected-value performance function of a DEDS or HS,\n $y_{n}$ is an approximation thereof computed from a sample path of the system,  and the  term $J^{\\prime}(u_n)+\\phi_n$ in\n the Right-Hand Side (RHS) of Eq. (3) (with $n+1$)\n is computable by IPA.\n One of the main appealing features of IPA is the simplicity of its gradient (derivative)\n algorithms and efficiency of their computation.\n This, however, comes at the expense of accuracy. In particular,  in its principal  application area of queueing systems\n during its earlier development, IPA often yielded  statistically biased gradient estimators (see Refs. \\cite{Ho91,Cassandras99}).\n To ameliorate this problem, Stochastic Flow Models (SFM) consisting of fluid queues (see Refs. \\cite{Cassandras02,Sun04,Cassandras06,Panayiotou06}) and\n later extended to more general\n stochastic HS in Refs.   \\cite{Cassandras10,Wardi10,Wardi13}, offer an alternative framework to queueing networks\n for the application  of IPA; in their setting   the IPA gradients typically are simpler and more accurate.\n Still approximations must be made either in the IPA algorithms or in the system's model when\n a stochastic HS is used as\n a\n  modeling abstraction for a\nDEDS. However, our overriding concern regarding the regulation's control law is that of simplicity and\n computational efficiency even if\n they come at the expense of accuracy.\n This is justified by  sensitivity-analysis  results, derived below,  showing that asymptotic tracking of the regulation\n scheme holds under substantial relative errors in the gradient estimation.\n\n The objective of this paper is to investigate the performance of our proposed tracking  technique on a number of\n DEDS and HS by using the IPA method for computing the integrator's adaptive gain in the loop. In this we leverage on the\n simplicity and low computational efforts required for the IPA derivatives. Furthermore,\n simulation experiments suggest that the regulation algorithm works well despite substantial errors in the\n gradient estimation, thus allowing  us to tilt the balance  between precision and low computing times towards\n fast computation at the expense of accuracy. It may be asked why we use an integral control and not a PI or PID controller, and it\n is pointed out that\n we have tested via simulation (not reported here) the\n addition of a proportional element to the integral control, and found no improvement. This is not surprising since, as indicated\n by the analysis in Section 2, the particular gain-adaptation of the integral controller stabilizes the system for a class of\n plant functions $J(u)$. In summary, the contributions of this paper are: 1). It  proposes the first general-purpose, systematic   performance-regulation technique for a class of timed DEDS and HS. 2). To-date, the main use of IPA has been in optimization, while this paper\n pursues a new kind of application, namely performance regulation. 3). It moves away from the traditional pursuit of unbiased IPA gradients, and instead searches for low-complexity approximations perhaps at the expense of accuracy or unbiasedness. We believe that these three\n points of novelty may open up a new  dimension in the research and applications   of IPA.\n\n  The rest of the paper is organized as follows.\n Section 2  describes the regulation technique in an abstract setting. The following three sections present\n simulation results on three types of systems, and highlight the tradeoffs between simplicity and accuracy.\n Section 3 concerns a queue, Section 4 considers  a fluid Petri net production-control model, and\n Section 5 discusses a DEDS model of throughput  in computer processors. Finally,  Section 6 concludes the paper.\\footnote{The second queueing example in Section 3, and the Petri-net example in Section 4 were presented in, and are part of  \\cite{Seatzu14}.}\n\n\n\n\n\n\n\\section{Regulation Algorithm in an Abstract Setting}\n\nThe rationale behind the choice of $A_{n}$ in Eq. (2) (if its RHS  can be computed exactly) can be seen by considering the simple case where\nthe plant consists of a deterministic, time-invariant, memoryless nonlinearity, and hence the $u_n$~-~to~-~$y_n$ relation has the form\n\n", "index": 11, "text": "\\begin{equation}\ny_n=J(u_n).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"y_{n}=J(u_{n}).\" display=\"block\"><mrow><mrow><msub><mi>y</mi><mi>n</mi></msub><mo>=</mo><mrow><mi>J</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nresults in the recursive equation\n\n", "itemtype": "equation", "pos": 13236, "prevtext": "\n Suppose that the function $J(u)$ is differentiable,\nand denote its derivative by $J^{\\prime}(u)$.\nAn application of the Newton-Raphson method for solving the\nequation\n\n", "index": 13, "text": "\\begin{equation}\nr-J(u)=0\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"r-J(u)=0\" display=\"block\"><mrow><mrow><mi>r</mi><mo>-</mo><mrow><mi>J</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwhere  $A_{n}:=\\big(J^{\\prime}(u_{n-1})\\big)^{-1}$ is defined by (2). This yields\nEq. (1), and we discern that the control law, comprised of repeated recursive applications of Eqs.\n$(2)\\rightarrow(1)\\rightarrow(5)\\rightarrow(4)$, amounts to an implementation of the Newton-Raphson method.\n\n\nAn application of this control technique to a class of dynamic, time-varying systems is one of the main objectives of the present paper.\nIts convergence is underscored by   established results on the sensitivity of the Newton--Raphson method with respect to variations in\nfunction and gradient-evaluations \\cite{Lancaster66}. Therefore, the  analysis  of the paper next will be presented\nin an abstract setting of the Newton-Raphson method, and then related to the control configuration of Figure 1.\n\n Let $g:R\\rightarrow R$ be a continuously-differentiable function, and consider\nthe problem of finding a root of the equation $g(u)=0$, $u\\in R$. The basic step of the Newton-Raphson method is\n\n", "itemtype": "equation", "pos": 13311, "prevtext": "\nresults in the recursive equation\n\n", "index": 15, "text": "\\begin{equation}\nu_n=u_{n-1}+\\frac{1}{J^{\\prime}(u_{n-1})}e_{n-1}=u_{n-1}+A_ne_{n-1},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"u_{n}=u_{n-1}+\\frac{1}{J^{\\prime}(u_{n-1})}e_{n-1}=u_{n-1}+A_{n}e_{n-1},\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><mfrac><mn>1</mn><mrow><msup><mi>J</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><msub><mi>e</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mrow><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><msub><mi>A</mi><mi>n</mi></msub><mo>\u2062</mo><msub><mi>e</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n and the algorithm is comprised of running this equation recursively\nfor $n=1,2,\\ldots$ starting from an initial guess $u_0\\in R$. Convergence of the algorithm can be characterized by\nthe equation\n\n", "itemtype": "equation", "pos": 14397, "prevtext": "\nwhere  $A_{n}:=\\big(J^{\\prime}(u_{n-1})\\big)^{-1}$ is defined by (2). This yields\nEq. (1), and we discern that the control law, comprised of repeated recursive applications of Eqs.\n$(2)\\rightarrow(1)\\rightarrow(5)\\rightarrow(4)$, amounts to an implementation of the Newton-Raphson method.\n\n\nAn application of this control technique to a class of dynamic, time-varying systems is one of the main objectives of the present paper.\nIts convergence is underscored by   established results on the sensitivity of the Newton--Raphson method with respect to variations in\nfunction and gradient-evaluations \\cite{Lancaster66}. Therefore, the  analysis  of the paper next will be presented\nin an abstract setting of the Newton-Raphson method, and then related to the control configuration of Figure 1.\n\n Let $g:R\\rightarrow R$ be a continuously-differentiable function, and consider\nthe problem of finding a root of the equation $g(u)=0$, $u\\in R$. The basic step of the Newton-Raphson method is\n\n", "index": 17, "text": "\\begin{equation}\nu_{n}=u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})}g(u_{n-1}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"u_{n}=u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})}g(u_{n-1}),\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwhich implies that every accumulation point of the sequence $\\{u_n\\}$, $\\hat{u}$, satisfies the equation\n$g(\\hat{u})=0$.\n\nConvergence of the Newton-Raphson method is well known under broad assumptions (see, e.g., Ref.\n\\cite{Ortega70}).\nRef. \\cite{Lancaster66} investigated the case where the derivative term $g^{\\prime}(u_{n-1})$ in\nEq. (8) is approximated rather than evaluated exactly, and showed that convergence is maintained under suitable\nbounds on the errors. Taking it a step further, we consider the case where  errors arise in the function\nevaluations $g(u_{n-1})$ as well. Then Eq. (9) no longer can be expected, but (see \\cite{Almoosa12})\nthe limit\n$\\limsup_{n\\rightarrow\\infty}|g(u_{n})|$ is bounded from above by a term that depends on the magnitude of the errors\nin a suitable sense.\nSpecifically, let\n$\\psi_{n-1}$ and $\\phi_{n-1}$ denote additive  error terms in the computations of the function\n$g(u_{n-1})$ and its derivative $g^{\\prime}(u_{n-1})$, respectively,\nso that Eq. (8) is transformed into\n\n", "itemtype": "equation", "pos": 14681, "prevtext": "\n and the algorithm is comprised of running this equation recursively\nfor $n=1,2,\\ldots$ starting from an initial guess $u_0\\in R$. Convergence of the algorithm can be characterized by\nthe equation\n\n", "index": 19, "text": "\\begin{equation}\n\\lim_{n\\rightarrow\\infty}g(u_n)=0,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\lim_{n\\rightarrow\\infty}g(u_{n})=0,\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mn>0</mn></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nDefine the relative errors\n${\\cal G}_{n-1}:=\\frac{|\\psi_{n-1}|}{|g(u_{-1})|}$ and ${\\cal E}_{n-1}:=\\frac{|\\phi_{n-1}|}{|g^{\\prime}(u_{n-1})|}$.\nThe following results, Lemma 2.2 and Proposition 2.3,\n are proved under the following assumption.\\footnote{A weaker result than Lemma 2.2 and Proposition 2.3 was stated by Proposition 2 in\n\\cite{Almoosa12}, but its statement is incorrect.}\n\\begin{assumption}\nThe function $g(\\cdot)$ is continuously differentiable.\n\\end{assumption}\nGiven a closed interval $I:=[u_1,u_2]\\subset R$, define $|g^{\\prime}|_{I,min}:=\\min\\{|g^{\\prime}(u)|~:~u\\in I\\}$,\nand\n$|g^{\\prime}|_{I,max}:=\\max\\{|g^{\\prime}(u)|~:~u\\in I\\}$.\n Consider the algorithm comprised of recursive runs\nof Eq. (10). For every $n=1,\\ldots$, define\n", "itemtype": "equation", "pos": 15765, "prevtext": "\nwhich implies that every accumulation point of the sequence $\\{u_n\\}$, $\\hat{u}$, satisfies the equation\n$g(\\hat{u})=0$.\n\nConvergence of the Newton-Raphson method is well known under broad assumptions (see, e.g., Ref.\n\\cite{Ortega70}).\nRef. \\cite{Lancaster66} investigated the case where the derivative term $g^{\\prime}(u_{n-1})$ in\nEq. (8) is approximated rather than evaluated exactly, and showed that convergence is maintained under suitable\nbounds on the errors. Taking it a step further, we consider the case where  errors arise in the function\nevaluations $g(u_{n-1})$ as well. Then Eq. (9) no longer can be expected, but (see \\cite{Almoosa12})\nthe limit\n$\\limsup_{n\\rightarrow\\infty}|g(u_{n})|$ is bounded from above by a term that depends on the magnitude of the errors\nin a suitable sense.\nSpecifically, let\n$\\psi_{n-1}$ and $\\phi_{n-1}$ denote additive  error terms in the computations of the function\n$g(u_{n-1})$ and its derivative $g^{\\prime}(u_{n-1})$, respectively,\nso that Eq. (8) is transformed into\n\n", "index": 21, "text": "\\begin{equation}\nu_{n}=u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})+\\phi_{n-1}}\\big(g(u_{n-1})+\\psi_{n-1}\\big).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"u_{n}=u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})+\\phi_{n-1}}\\big{(}g(u_{n-1})+\\psi_{%&#10;n-1}\\big{)}.\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nin other words, if $g(u_{n})\\geq 0$ then $m_{n}$ is the next integer $m>n$ such that $g(u_{m})\\geq 0$,\nand if $g(u_{n})\\leq 0$ then $m_{n}$ is the next integer $m>n$ such that $g(u_{m})\\leq 0$.\n\n\\begin{lemma}\nFor every   $M>1$  and $\\beta\\in(0,M^{-1})$  there exist $\\alpha\\in(0,1)$ and\n$\\theta\\in(0,1)$ such that, for every closed interval $I$ where the function $g(u)$ has  the following three\nproperties:  (i) $g(\\cdot)$ is either monotone nondecreasing throughout $I$ or monotone non-increasing throughout $I$; (ii) $g(\\cdot)$ is either convex throughout $I$ or concave\nthroughout $I$; and (iii)\n$\\frac{|g^{\\prime}|_{I,max}}{|g^{\\prime}|_{I,min}}<M$, the following\n holds: if, for some $n=1,\\ldots$, (a)  for every $j=n,\\ldots,m_{n}$,\n$u_{j}\\in I$;    (b) for every $j=n,\\ldots,m_{n}-1$,\n${\\cal E}_{j}<\\alpha$; and   (c) for every $j=n,\\ldots,m_{n}-1$, ${\\cal G}_{j}<\\beta$,\nthen\n\n", "itemtype": "equation", "pos": 16631, "prevtext": "\nDefine the relative errors\n${\\cal G}_{n-1}:=\\frac{|\\psi_{n-1}|}{|g(u_{-1})|}$ and ${\\cal E}_{n-1}:=\\frac{|\\phi_{n-1}|}{|g^{\\prime}(u_{n-1})|}$.\nThe following results, Lemma 2.2 and Proposition 2.3,\n are proved under the following assumption.\\footnote{A weaker result than Lemma 2.2 and Proposition 2.3 was stated by Proposition 2 in\n\\cite{Almoosa12}, but its statement is incorrect.}\n\\begin{assumption}\nThe function $g(\\cdot)$ is continuously differentiable.\n\\end{assumption}\nGiven a closed interval $I:=[u_1,u_2]\\subset R$, define $|g^{\\prime}|_{I,min}:=\\min\\{|g^{\\prime}(u)|~:~u\\in I\\}$,\nand\n$|g^{\\prime}|_{I,max}:=\\max\\{|g^{\\prime}(u)|~:~u\\in I\\}$.\n Consider the algorithm comprised of recursive runs\nof Eq. (10). For every $n=1,\\ldots$, define\n", "index": 23, "text": "\n\\[\nm_{n}:=\\min\\{m>n~:~g(u_{m})g(u_{n})\\geq 0\\};\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"m_{n}:=\\min\\{m&gt;n~{}:~{}g(u_{m})g(u_{n})\\geq 0\\};\" display=\"block\"><mrow><mrow><msub><mi>m</mi><mi>n</mi></msub><mo>:=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mrow><mi>m</mi><mo>&gt;</mo><mpadded width=\"+3.3pt\"><mi>n</mi></mpadded></mrow><mo rspace=\"5.8pt\">:</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>m</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mn>0</mn></mrow></mrow><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mo>;</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\\end{lemma}\n\\hfill$\\Box$\n\n\n\n\n\nThe proof, tedious but  based on standard arguments from convex analysis,\nis relegated to the appendix.\n\nA few remarks are due.\n\n\\begin{enumerate}\n\\item\nIn situations where $g(u)$ is the expected-value performance function of a DEDS\n or HS, it may be impossible to  verify some of the assumptions underscoring Lemma 2.2, such as\nthe continuous differentiability  of $g(u)$, bounds on the relative errors ${\\cal E}_{k-1}$ and\n${\\cal G}_{k-1}$, or  bounds on the terms $g^{\\prime}_{I,max}$ and $g^{\\prime}_{I,min}$. We point out that  analysis techniques\nfor their verifications have\nbeen developed in the literature on IPA, mainly for convex sample performance functions  (see, e.g., \\cite{Cassandras99, Cassandras06, Cassandras10}). However, in other situations these\nassumptions  may have\nto be stipulated or  justified by empirical evidence derived, for instance, from  simulation.\n\\item\nSuppose that  the variable $u$ has to be constrained to a closed interval $I:=[u_{min},u_{max}]$ satisfying the conditions of Lemma 2.2.\nTo ensure that $u_{n}$, $n=1,\\ldots$ are contained in $I$, it is possible to modify Eq. (10) by following it with a projection onto\n$I$. Define the projection function $P_{I}:R\\rightarrow I$ by\n", "itemtype": "equation", "pos": 17567, "prevtext": "\nin other words, if $g(u_{n})\\geq 0$ then $m_{n}$ is the next integer $m>n$ such that $g(u_{m})\\geq 0$,\nand if $g(u_{n})\\leq 0$ then $m_{n}$ is the next integer $m>n$ such that $g(u_{m})\\leq 0$.\n\n\\begin{lemma}\nFor every   $M>1$  and $\\beta\\in(0,M^{-1})$  there exist $\\alpha\\in(0,1)$ and\n$\\theta\\in(0,1)$ such that, for every closed interval $I$ where the function $g(u)$ has  the following three\nproperties:  (i) $g(\\cdot)$ is either monotone nondecreasing throughout $I$ or monotone non-increasing throughout $I$; (ii) $g(\\cdot)$ is either convex throughout $I$ or concave\nthroughout $I$; and (iii)\n$\\frac{|g^{\\prime}|_{I,max}}{|g^{\\prime}|_{I,min}}<M$, the following\n holds: if, for some $n=1,\\ldots$, (a)  for every $j=n,\\ldots,m_{n}$,\n$u_{j}\\in I$;    (b) for every $j=n,\\ldots,m_{n}-1$,\n${\\cal E}_{j}<\\alpha$; and   (c) for every $j=n,\\ldots,m_{n}-1$, ${\\cal G}_{j}<\\beta$,\nthen\n\n", "index": 25, "text": "\\begin{equation}\n|g(u_{m_{n-1}})|<\\theta|g(u_{n-1})|.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"|g(u_{m_{n-1}})|&lt;\\theta|g(u_{n-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><msub><mi>m</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>&lt;</mo><mrow><mi>\u03b8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nand change Eq. (10)  to the following equation,\n\n", "itemtype": "equation", "pos": 18886, "prevtext": "\n\\end{lemma}\n\\hfill$\\Box$\n\n\n\n\n\nThe proof, tedious but  based on standard arguments from convex analysis,\nis relegated to the appendix.\n\nA few remarks are due.\n\n\\begin{enumerate}\n\\item\nIn situations where $g(u)$ is the expected-value performance function of a DEDS\n or HS, it may be impossible to  verify some of the assumptions underscoring Lemma 2.2, such as\nthe continuous differentiability  of $g(u)$, bounds on the relative errors ${\\cal E}_{k-1}$ and\n${\\cal G}_{k-1}$, or  bounds on the terms $g^{\\prime}_{I,max}$ and $g^{\\prime}_{I,min}$. We point out that  analysis techniques\nfor their verifications have\nbeen developed in the literature on IPA, mainly for convex sample performance functions  (see, e.g., \\cite{Cassandras99, Cassandras06, Cassandras10}). However, in other situations these\nassumptions  may have\nto be stipulated or  justified by empirical evidence derived, for instance, from  simulation.\n\\item\nSuppose that  the variable $u$ has to be constrained to a closed interval $I:=[u_{min},u_{max}]$ satisfying the conditions of Lemma 2.2.\nTo ensure that $u_{n}$, $n=1,\\ldots$ are contained in $I$, it is possible to modify Eq. (10) by following it with a projection onto\n$I$. Define the projection function $P_{I}:R\\rightarrow I$ by\n", "index": 27, "text": "\n\\[\nP_{I}(u):=\\left\\{\n\\begin{array}{ll}\nu, & {\\rm if}\\ u\\in I\\\\\nu_{min}, & {\\rm if}\\ u<u_{min}\\\\\nu_{max}, & {\\rm if}\\ u>u_{max},\n\\end{array}\n\\right.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"P_{I}(u):=\\left\\{\\begin{array}[]{ll}u,&amp;{\\rm if}\\ u\\in I\\\\&#10;u_{min},&amp;{\\rm if}\\ u&lt;u_{min}\\\\&#10;u_{max},&amp;{\\rm if}\\ u&gt;u_{max},\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>P</mi><mi>I</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>:=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mi>u</mi><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mi>u</mi></mrow><mo>\u2208</mo><mi>I</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>u</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mi>u</mi></mrow><mo>&lt;</mo><msub><mi>u</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>i</mi><mo>\u2062</mo><mi>n</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>u</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mi>u</mi></mrow><mo>&gt;</mo><msub><mi>u</mi><mrow><mi>m</mi><mo>\u2062</mo><mi>a</mi><mo>\u2062</mo><mi>x</mi></mrow></msub></mrow><mo>,</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nIf $I$ contains a point $\\hat{u}$ such that $g(\\hat{u})=0$, in addition to satisfying the conditions of the lemma, then it is readily seen\nthat using Eq. (12) instead of (10) does not weaken the statement of the lemma.\n\\end{enumerate}\n\n\\begin{proposition}\nFor every $\\eta>0$,   $M>1$, and $\\varepsilon>0$   there exist $\\alpha\\in(0,1)$ and $\\delta>0$\n such that, for every closed, finite-length  interval $I$ such that (i) throughout $I$ the function\n $g(\\cdot)$ is either monotone increasing or monotone decreasing, and either convex or concave,\n  (ii) the set $\\{u\\in I~|~g(u)=0\\}$ is nonempty, and\n(iii) $|g^{\\prime}|_{I,min}>\\eta$ and $\\frac{|g^{\\prime}|_{I,max}}{|g^{\\prime}|_{I,min}}<M$;\nand for every sequence $\\{u_n\\}_{n=1}^{\\infty}$\ncomputed by a recursive application of Eq. (10) such that, for every $n=1,2,\\ldots$,\n(a) $u_n\\in I$,\n(b)\n${\\cal E}_{n}<\\alpha$, and (c)  $|\\psi_{n}|<\\delta$,\n the following two inequalities are in force:\n\n", "itemtype": "equation", "pos": 19086, "prevtext": "\nand change Eq. (10)  to the following equation,\n\n", "index": 29, "text": "\\begin{equation}\nu_{n}=P_{I}\\Big(u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})+\\phi_{n-1}}\\big(g(u_{n-1})+\\psi_{n-1}\\big)\\Big).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"u_{n}=P_{I}\\Big{(}u_{n-1}-\\frac{1}{g^{\\prime}(u_{n-1})+\\phi_{n-1}}\\big{(}g(u_{%&#10;n-1})+\\psi_{n-1}\\big{)}\\Big{)}.\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>P</mi><mi>I</mi></msub><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nand\n\n", "itemtype": "equation", "pos": 20166, "prevtext": "\nIf $I$ contains a point $\\hat{u}$ such that $g(\\hat{u})=0$, in addition to satisfying the conditions of the lemma, then it is readily seen\nthat using Eq. (12) instead of (10) does not weaken the statement of the lemma.\n\\end{enumerate}\n\n\\begin{proposition}\nFor every $\\eta>0$,   $M>1$, and $\\varepsilon>0$   there exist $\\alpha\\in(0,1)$ and $\\delta>0$\n such that, for every closed, finite-length  interval $I$ such that (i) throughout $I$ the function\n $g(\\cdot)$ is either monotone increasing or monotone decreasing, and either convex or concave,\n  (ii) the set $\\{u\\in I~|~g(u)=0\\}$ is nonempty, and\n(iii) $|g^{\\prime}|_{I,min}>\\eta$ and $\\frac{|g^{\\prime}|_{I,max}}{|g^{\\prime}|_{I,min}}<M$;\nand for every sequence $\\{u_n\\}_{n=1}^{\\infty}$\ncomputed by a recursive application of Eq. (10) such that, for every $n=1,2,\\ldots$,\n(a) $u_n\\in I$,\n(b)\n${\\cal E}_{n}<\\alpha$, and (c)  $|\\psi_{n}|<\\delta$,\n the following two inequalities are in force:\n\n", "index": 31, "text": "\\begin{equation}\n\\limsup_{n\\rightarrow\\infty}|g(u_n)|<\\varepsilon,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"\\limsup_{n\\rightarrow\\infty}|g(u_{n})|&lt;\\varepsilon,\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim sup</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow><mo>&lt;</mo><mi>\u03b5</mi></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\\end{proposition}\n\\hfill$\\Box$\n\nRemarks:\n\\begin{enumerate}\n\\item\nConsider  the case where $g(u)$ is computed exactly and the errors are only in its derivative. Then every interval\n$I$ and a sequence $\\{u_{n}\\}$ satisfying the conditions of the proposition also satisfy all the condition of Lemma 2.2, and hence,\nEq. (11) for all $n=1,\\ldots$ implies (9).\n\\item\nNotice that the conditions assumed in the proposition's statement include upper bounds on the {\\it absolute} error of\nthe function's estimation, $|\\psi_{n-1}|$, and on the {\\it relative} error in the derivative, ${\\cal E}_{n-1}$.\nThe reason for this discrepancy will be made clear in the proof of Proposition 2.3, where it will be shown  that\nEqs. (13) and (14) are due to such upper bounds.\n\\item\nIn light of Remark 2  following Lemma 2.2, if an interval $I$ satisfying the conditions of Proposition 2.3 is a constraint\nset for the sequence $\\{u_{n}\\}$, then replacing Eq. 10) by (12) will not alter the assertions of the proposition expressed by Eqs. (13) and (14).\n\\end{enumerate}\n\nConsider the case where $g(u)$ is an expected-value performance function on a stochastic dynamical system, and suppose that Eq. (10)\nis run recursively in order to solve the equation $g(u)=0$. Suppose moreover that at the $nth$ iteration the function $g(u_{n-1})$\nand its derivative $g^{\\prime}(u_{n-1})$ are estimated by sample averages over\na control cycle $C_{n-1}$.  Generally, even under conditions of stochastic stability and arbitrarily long control cycles, it is not true\n that\n$\\{{\\cal E}\\}_{n-1}<\\alpha$ and $|\\psi_{n-1}|<\\delta$ {\\it for all} $n=1,\\ldots$, as stipulated in the statement of Proposition 2.3. However practically,   by the inequality in Eq. (11),  with suitably-long\ncontrol cycles we expect the sequence $\\{|g(u_n)|\\}$ to decline towards  0 as in (13) except for sporadic jumps away from zero, and this\nwill be evident from the simulation results described in the next section. This is due to Lemma 2.2,\nwhile Proposition 2.3 provides a unified result under more ideal conditions.\n\nIn the context of  the aforementioned control system, we note that the error in\n the derivative estimation is reflected by Eq. (3) rather than (2), and to account for the error in\n function evaluations, Eq. (5) is replaced by\n \n", "itemtype": "equation", "pos": 20252, "prevtext": "\nand\n\n", "index": 33, "text": "\\begin{equation}\n\\limsup_{n\\rightarrow\\infty}|g(u_n)+\\psi_{n}|<\\varepsilon.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"\\limsup_{n\\rightarrow\\infty}|g(u_{n})+\\psi_{n}|&lt;\\varepsilon.\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim sup</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mi>n</mi></msub></mrow><mo stretchy=\"false\">|</mo></mrow></mrow><mo>&lt;</mo><mi>\u03b5</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nNow the control loop is defined by a recursive application of Eqs. $(3)\\rightarrow(1)\\rightarrow(15)\\rightarrow(4)$.\nTo translate the algorithm defined by Eq. (1) into this  control setting we define $g(u)=r-J(u)$. We  can also\napply it  to time-varying systems of the form $y_n=J_n(u_n)$, where convergence in the sense of Eqs. (13) -(14)\nis expected\n if the systems vary slowly. Finally, we mention that from a practical standpoint the algorithm's convergence is ascertained\n from Eq. (14) rather than (13), since the observed quantity is $y_n=J(u_n)+\\psi_n$ rather than $J(u_n)$.\n\n\n\n\n\nThe next section presents simulation examples of various DEDS and hybrid systems.\nThey include two noteworthy situations concerning queueing systems where IPA is biased.\nThe error term $\\phi_{n-1}$ is due in one case to the use of   SFM as a basis for the IPA formula,\nand in the other case, to a direct use of the DEDS-based IPA in spite of its bias. In both cases the regulation algorithm is shown to converge. While situations of the first case have stimulated an\ninterest in SFM as a means to circumvent the bias inherent in IPA,  the example of the second case\ndemonstrates that IPA can be successfully used even when it is biased.\n\n\n\n\n\n\n\n\n\n\n\n \\section{Regulation of Average Delay and Loss Rate of a Single Queue}\\label{sec:queues}\n This section illustrates the aforementioned regulation framework by applying it to two examples concerning,\n respectively,\n delay and loss rate in an M/D/1   queue.\n Both delay and loss  are controlled  by the service times. In the first example  the IPA derivative\n is unbiased and hence we use it to adjust the integrator's gain. In contrast, in the second example the IPA derivative is\n biased and hence  we apply a formula which is derived from an SFM (fluid-queue) approximation\n to the sample paths obtained from the discrete queue.  While this yields estimation errors due to modeling discrepancies, it\n guarantees the unbiasedness of IPA for the SFM and results in convergence of the regulation algorithm\n as applied to the discrete queue.\n\n \\subsection{Average Delay}\n Consider an M/D/1/$\\infty$ queue with a given arrival rate $\\lambda$ and service times of $s$ time-units. Given positive integers $M$ and $N$, a control cycle consists\n of\n $M$ jobs,  and the regulation process is run for  $N$ cycles.  We set the queue to empty at the start of\n each control cycle.\n In the notation established  in Section 1,\n we define $u=s$;  for $n=1,\\ldots,N$, $C_{n}$ is the $nth$ control cycle; and\n $y_{n}$ is the average delay  of jobs arriving during  $C_{n}$. Note that $y_n$ is not an expected-value\n function but rather a random function of $u$\n  whose realization depends of the samples drawn during $C_{n}$. Let $J(u)$ denote the\n expected-value delay according to the stationary distribution. It is known that  $y_n$ is a strongly-consistent estimator\n of $J(u_n)$ in the following sense (see \\cite{Ho91,Cassandras99}): for a given\n $n=1,2,\\ldots$,\n \n", "itemtype": "equation", "pos": 22625, "prevtext": "\n\\end{proposition}\n\\hfill$\\Box$\n\nRemarks:\n\\begin{enumerate}\n\\item\nConsider  the case where $g(u)$ is computed exactly and the errors are only in its derivative. Then every interval\n$I$ and a sequence $\\{u_{n}\\}$ satisfying the conditions of the proposition also satisfy all the condition of Lemma 2.2, and hence,\nEq. (11) for all $n=1,\\ldots$ implies (9).\n\\item\nNotice that the conditions assumed in the proposition's statement include upper bounds on the {\\it absolute} error of\nthe function's estimation, $|\\psi_{n-1}|$, and on the {\\it relative} error in the derivative, ${\\cal E}_{n-1}$.\nThe reason for this discrepancy will be made clear in the proof of Proposition 2.3, where it will be shown  that\nEqs. (13) and (14) are due to such upper bounds.\n\\item\nIn light of Remark 2  following Lemma 2.2, if an interval $I$ satisfying the conditions of Proposition 2.3 is a constraint\nset for the sequence $\\{u_{n}\\}$, then replacing Eq. 10) by (12) will not alter the assertions of the proposition expressed by Eqs. (13) and (14).\n\\end{enumerate}\n\nConsider the case where $g(u)$ is an expected-value performance function on a stochastic dynamical system, and suppose that Eq. (10)\nis run recursively in order to solve the equation $g(u)=0$. Suppose moreover that at the $nth$ iteration the function $g(u_{n-1})$\nand its derivative $g^{\\prime}(u_{n-1})$ are estimated by sample averages over\na control cycle $C_{n-1}$.  Generally, even under conditions of stochastic stability and arbitrarily long control cycles, it is not true\n that\n$\\{{\\cal E}\\}_{n-1}<\\alpha$ and $|\\psi_{n-1}|<\\delta$ {\\it for all} $n=1,\\ldots$, as stipulated in the statement of Proposition 2.3. However practically,   by the inequality in Eq. (11),  with suitably-long\ncontrol cycles we expect the sequence $\\{|g(u_n)|\\}$ to decline towards  0 as in (13) except for sporadic jumps away from zero, and this\nwill be evident from the simulation results described in the next section. This is due to Lemma 2.2,\nwhile Proposition 2.3 provides a unified result under more ideal conditions.\n\nIn the context of  the aforementioned control system, we note that the error in\n the derivative estimation is reflected by Eq. (3) rather than (2), and to account for the error in\n function evaluations, Eq. (5) is replaced by\n \n", "index": 35, "text": "\\begin{equation}\n y_n=J(u_n)+\\psi_n.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"y_{n}=J(u_{n})+\\psi_{n}.\" display=\"block\"><mrow><mrow><msub><mi>y</mi><mi>n</mi></msub><mo>=</mo><mrow><mrow><mi>J</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mi>n</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n where $M$ is the length of the control cycle. Consequently the estimation error\n $\\psi_n:=J(u_n)-y_n$ can be made smaller by choosing longer control cycles.\n\n The  IPA derivative, $\\frac{\\partial y_n}{\\partial u_n}$,  is known\n to have the following form\n (see \\cite{Ho91,Cassandras99}). For every $m=1,\\ldots,M$, let $k_{m,n}$ denote the index (counter) of the job that started the busy\n period containing job $m$ during $C_{n}$. Then,\n \n", "itemtype": "equation", "pos": 25664, "prevtext": "\nNow the control loop is defined by a recursive application of Eqs. $(3)\\rightarrow(1)\\rightarrow(15)\\rightarrow(4)$.\nTo translate the algorithm defined by Eq. (1) into this  control setting we define $g(u)=r-J(u)$. We  can also\napply it  to time-varying systems of the form $y_n=J_n(u_n)$, where convergence in the sense of Eqs. (13) -(14)\nis expected\n if the systems vary slowly. Finally, we mention that from a practical standpoint the algorithm's convergence is ascertained\n from Eq. (14) rather than (13), since the observed quantity is $y_n=J(u_n)+\\psi_n$ rather than $J(u_n)$.\n\n\n\n\n\nThe next section presents simulation examples of various DEDS and hybrid systems.\nThey include two noteworthy situations concerning queueing systems where IPA is biased.\nThe error term $\\phi_{n-1}$ is due in one case to the use of   SFM as a basis for the IPA formula,\nand in the other case, to a direct use of the DEDS-based IPA in spite of its bias. In both cases the regulation algorithm is shown to converge. While situations of the first case have stimulated an\ninterest in SFM as a means to circumvent the bias inherent in IPA,  the example of the second case\ndemonstrates that IPA can be successfully used even when it is biased.\n\n\n\n\n\n\n\n\n\n\n\n \\section{Regulation of Average Delay and Loss Rate of a Single Queue}\\label{sec:queues}\n This section illustrates the aforementioned regulation framework by applying it to two examples concerning,\n respectively,\n delay and loss rate in an M/D/1   queue.\n Both delay and loss  are controlled  by the service times. In the first example  the IPA derivative\n is unbiased and hence we use it to adjust the integrator's gain. In contrast, in the second example the IPA derivative is\n biased and hence  we apply a formula which is derived from an SFM (fluid-queue) approximation\n to the sample paths obtained from the discrete queue.  While this yields estimation errors due to modeling discrepancies, it\n guarantees the unbiasedness of IPA for the SFM and results in convergence of the regulation algorithm\n as applied to the discrete queue.\n\n \\subsection{Average Delay}\n Consider an M/D/1/$\\infty$ queue with a given arrival rate $\\lambda$ and service times of $s$ time-units. Given positive integers $M$ and $N$, a control cycle consists\n of\n $M$ jobs,  and the regulation process is run for  $N$ cycles.  We set the queue to empty at the start of\n each control cycle.\n In the notation established  in Section 1,\n we define $u=s$;  for $n=1,\\ldots,N$, $C_{n}$ is the $nth$ control cycle; and\n $y_{n}$ is the average delay  of jobs arriving during  $C_{n}$. Note that $y_n$ is not an expected-value\n function but rather a random function of $u$\n  whose realization depends of the samples drawn during $C_{n}$. Let $J(u)$ denote the\n expected-value delay according to the stationary distribution. It is known that  $y_n$ is a strongly-consistent estimator\n of $J(u_n)$ in the following sense (see \\cite{Ho91,Cassandras99}): for a given\n $n=1,2,\\ldots$,\n \n", "index": 37, "text": "\\begin{equation}\n \\lim_{M\\rightarrow\\infty}y_n=J(u_n),\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"\\lim_{M\\rightarrow\\infty}y_{n}=J(u_{n}),\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim</mo><mrow><mi>M</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><msub><mi>y</mi><mi>n</mi></msub></mrow><mo>=</mo><mrow><mi>J</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n In other words, the IPA derivative of the delay of job $m$ as a function of $u_n$ is the position of that job in its\n busy period, namely $m-k_{m,n}+1$. This IPA is unbiased and strongly consistent; see Refs. \\cite{Ho91,Cassandras99}.\n Furthermore, by the Pollaczek-Khinchin formula,\n  $J(u)$ is a continuously-differentiable function of $u$. It is obviously monotone increasing, and also  convex on $R^+$ since, by Eq. (17), $J^{\\prime}(u)$ is monotone increasing as well. Therefore the conditions\n for Proposition 2.3 are satisfied on any closed interval contained in $R^+$,\n and we expect the simulation experiments to yield fast convergence of the output $y_n$\n to an $\\varepsilon$-band around the target value $r$ (in the sense of Eq. (13)), where $\\varepsilon$ can be made smaller by choosing longer control cycles.\n\n In the first simulation experiment we set the arrival rate to $\\lambda=0.9$, and the target reference delay to $r=3.0$.\n The control cycles consist of $M=10,000$ jobs each, and we ran the control algorithm for $N=100$ cycles starting from\n the initial guess of $u_1=1.1$.  The results, shown in Figure 2, indicate an approach of $y_n$ to about a\n steady value in about 5 iterations.    Thereafter we notice fluctuations of $y_{n}$, and a closer view of the results, obtained in Figure 3 by focusing the graph on the range $n=6,\\ldots,100$,  shows\n them to be in the range of $2.5 - 3.5$ except for a single exception at $n=69$.  These fluctuations do not seem to abate at larger $n$, and they likely are due\n to the variances of $y_{n}$ and its IPA derivative $\\frac{\\partial y_n}{\\partial u_n}$. We point out that the average value of\n $y_{n}$, obtained over the range $n=6,\\ldots,100$, is 3.031 (recall that the target value is 3.0).\n Correspondingly, the graph of the service times $u_n$, $n=1,\\ldots,100$, is shown in Figure 4, and their mean over $n=6,\\ldots,100$ is 0.913.\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_21.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay.  $M=10,000$, $n=1,\\ldots,100$.}}\n \\end{figure}\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_3.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay, $n=6\\ldots,\\infty$.  $M=10,000$, $n=5,\\ldots,100$.}}\n \\end{figure}\n\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_4.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - service times.  $M=10,000$, $n=1,\\ldots,100$.}}\n \\end{figure}\n\n Lesser variance of $\\{y_n\\}$ can be  obtained from increasing the cycle length $M$ or reducing the reference target\n $y_{ref}$.\nIn the first case, where we set $M=100,000$ while keeping $y_{ref}$ at 3.00,   $y_n$,$, n=6,\\ldots,100$,  fluctuated between\n2.85 and 3.2 except for two values of $n$, and their mean was 3.008. In the second case, with $y_{{\\rm ref}}=1.5$ and\n$N=10,000$,\n$y_{n}$ fluctuated mostly in the $[1.35-1.65]$-range with two exceptions, and its mean over $n=6,\\ldots,100$ was\n1.505.  In all three cases the regulation algorithm\n converged in about 5 iterations independently of the variances of the delays and their IPA derivatives; those seem to affect mostly the magnitude of the output fluctuations.\n\n In order to test the effects of changing the target reference during an experiment, we ran the regulation algorithm\n for 120 cycles starting with $u_1=1.1$; in the first 40 cycles $y_{ref}=3.0$, in the next 40 cycles $y_{ref}=4.5$, and in the last 40\n cycles, $y_{ref}=1.5$. The results are shown in Figure 5, and they indicate convergence to each value of $y_{ref}$ in about 5\n iterations. Furthermore, it is evident that the variations are larger for larger $y_{ref}$, and the reason is that\n the service times converge to larger values and hence the queue has larger traffic intensities. For\n $y_{ref}=3.0$ the mean of $y_{n}$ over $n=5,\\ldots,40$ is 3.052,  for\n $y_{ref}=4.5$ the mean of $y_{n}$ over $n=45,\\ldots,80$ is 4.653,  and for\n $y_{ref}=1.5$ the mean of $y_{n}$ over $n=85,\\ldots,120$ is 1.504. The corresponding average gains $A_n$  obtained\n from the simulation were 0.063, 0.030, and 0.198. The respective  average service times were 0.918, 0.977, and 0.745. These values correspond to\n traffic intensities (product of $\\lambda$ and the service time) of  0.826, 0.879, and 0.671, which explain the\n noticeable differences in variability. When we took $M=100,000$ the variability declined (as expected) and the obtained\n means are 3.041, 4.515, and 1.501, respectively.\n\n\n\n\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_51.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay, variable setpoint.  $M=10,000$, $n=1,\\ldots,120$.}}\n \\end{figure}\n\nLastly, we demonstrate the advantage of using the variable-gain controller over fixed-gain integral controls. To this\nend we simulated the system described in the last paragraph with two fixed gains, and compared the results to those obtained\nearlier from the variable-gain control. The constant gains are 0.030 and 0.198 which, as reported above, are the average\n gains driven by the variable-gain controller for the respective extreme setpoint references of 4.5 and 1.5.\n\n Figure 6 depicts the graph of $y_n$, $n=5,\\ldots,120$, obtained from an application of the smaller\n fixed gain of 0.030 (the dashed curve), while the analogous graph obtained from the variable-gain\n controller  (the solid curve) is shown for the sake of comparison.\nWe discern slower response of the fixed-gain controller to changes in the setpoint,  and this is not\nsurprising since the variable-gain controller has larger gains  for the setpoints\n of 3.0 and 1.5.\n For  the larger fixed gain of 0.198, the graph of $y_n$ is shown in Figure 7.\\footnote{This graph  could not be adequately shown in\n the same figure as the graphs in Figure 6  due to the large peaks of $y_n$.}   The controller performs well for the setpoint of 1.5, but\n it exhibits large oscillations suggesting instability for the setpoint of\n 4.5, where the obtained gains of the variable-gain controller are smaller.\n These results are not surprising since, generally,\n   tracking controllers with too-small gains may result in slow adjustment to variations in the target setpoint,\n while overly-large gains may result in oscillations and even instability. The variable-gain controller in this example\n seems to adjust well to changes in the setpoint and thus perform better than the considered fixed-gain controls.\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{111_2.pdf}\n \t{\\small \\caption{Comparison of a small, fixed-gain control to the variable-gain controller.}}\n \\end{figure}\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.88\\textwidth]{222_2.pdf}\n \t{\\small \\caption{Oscillations due to a large, fixed-gain control.}}\n \\end{figure}\n\n\n \\subsection{Average loss-rate}\n\n\nConsider  an M/D/1/k queue with a finite buffer, where jobs arriving at a full queue are\nbeing discarded. Given an arrival rate, a buffer size, and a horizon period (cycle time), we aim at\ncontrolling (regulating)    the mean loss rate   to a given reference by adjusting the service times.\n Accordingly, we denote the arrival rate by $\\lambda$, the service times by $s$, the buffer size (including the holding\n  place at the server) by $k$, and the horizon period by $t_{f}$.\n\n\n  Let us divide the time-axis into consecutive control cycles, $C_{n}$, each of\n  duration $t_{f}$ seconds. The control parameter is the service time, namely $u=s$, and during $C_{n}$ its\n  value is denoted by\n  $u_{n}$. The performance function of interest, $J(u)$, is the mean loss rate\n  per control cycle. We approximate $J(u_n)$ by $y_n$, defined as  the number of  jobs\n  discarded during $C_{n}$ divided by $t_{f}$.\n\n  It is readily seen that the function $u_n\\rightarrow y_n$ is piecewise\n  constant and  almost surely no arrival would occur at the same time when another job enters or exits the server,\n  and therefore, the IPA derivative  along a sample path  is $\\frac{dy_n}{du_n}=0$. This does not provide an adequate\n  approximation to $J^{\\prime}(u_n)$, and hence an alternative approach to the estimation of\n  $J^{\\prime}(u_n)$ is needed.\n  To this end we use a  fluid-queue SFM  as described\n  in the next paragraph.\n\n  Consider a fluid queue with a finite buffer, a time-varying inflow rate,  and a constant service\n  rate. Suppose that the queue operates in a given time-interval $[0,t_{f}]$, where its instantaneous\n  arrival rate, denoted by $\\alpha(t)$, is a random process. Denote its service rate by $\\beta$. Let $u:=\\beta^{-1}$ be the control\n  variable,\n  and let $\\gamma(u,t)$ denote the instantaneous overflow (spillover) rate due to the limited buffer.\n  Let $L(u)$ denote the sample-based average loss rate per cycle as a function of the input service rate $u$, defined\n   as\n  \n", "itemtype": "equation", "pos": 26174, "prevtext": "\n where $M$ is the length of the control cycle. Consequently the estimation error\n $\\psi_n:=J(u_n)-y_n$ can be made smaller by choosing longer control cycles.\n\n The  IPA derivative, $\\frac{\\partial y_n}{\\partial u_n}$,  is known\n to have the following form\n (see \\cite{Ho91,Cassandras99}). For every $m=1,\\ldots,M$, let $k_{m,n}$ denote the index (counter) of the job that started the busy\n period containing job $m$ during $C_{n}$. Then,\n \n", "index": 39, "text": "\\begin{equation}\n \\frac{\\partial y_n}{\\partial u_n}=\\frac{1}{M}\\sum_{m=1}^{M}(m-k_{m,n}+1).\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\frac{\\partial y_{n}}{\\partial u_{n}}=\\frac{1}{M}\\sum_{m=1}^{M}(m-k_{m,n}+1).\" display=\"block\"><mrow><mrow><mfrac><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>y</mi><mi>n</mi></msub></mrow><mrow><mo>\u2202</mo><mo>\u2061</mo><msub><mi>u</mi><mi>n</mi></msub></mrow></mfrac><mo>=</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>m</mi><mo>-</mo><msub><mi>k</mi><mrow><mi>m</mi><mo>,</mo><mi>n</mi></mrow></msub></mrow><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n  Observe that $L(u)$ provides an approximation to $J(u)$ to the extent that the fluid\n  queue serves to approximate the discrete queue. The main difference between $J(u)$ and $L(u)$ is that $J(u)$ is the\n  mean loss rate of the discrete queue, while $L(u)$ is the sample time-average loss rate per cycle of the continuous queue.\n\n  Reference \\cite{Cassandras02} showed that the IPA derivative $L^{\\prime}(u)$ is unbiased, and\n  it is computable by a simple, model-free  formula (listed below) that can act on the sample paths of the discrete queue.\n  Furthermore, it can serve as an approximation to $J^{\\prime}(u)$.\n  Therefore we  implement the regulation algorithm in the following way.\n  During cycle $C_{n-1}$, the service time is $u_{n-1}$,   $y_{n-1}$  is the resulting\n  sample-average loss rate of the discrete queue, and $\\psi_{n-1}:=y_{n-1}-J(u_{n-1})$. The IPA derivative  $L^{\\prime}(u_{n-1})$,\n  specified below,\n   is the sample derivative of the average loss rate of the continuous queue as defined by Eq. (18),\n   and $\\phi_{n-1}:=L^{\\prime}(u_{n-1})-J^{\\prime}(u_{n-1})$.\n  Eq. (3) becomes\n  \n", "itemtype": "equation", "pos": 35220, "prevtext": "\n In other words, the IPA derivative of the delay of job $m$ as a function of $u_n$ is the position of that job in its\n busy period, namely $m-k_{m,n}+1$. This IPA is unbiased and strongly consistent; see Refs. \\cite{Ho91,Cassandras99}.\n Furthermore, by the Pollaczek-Khinchin formula,\n  $J(u)$ is a continuously-differentiable function of $u$. It is obviously monotone increasing, and also  convex on $R^+$ since, by Eq. (17), $J^{\\prime}(u)$ is monotone increasing as well. Therefore the conditions\n for Proposition 2.3 are satisfied on any closed interval contained in $R^+$,\n and we expect the simulation experiments to yield fast convergence of the output $y_n$\n to an $\\varepsilon$-band around the target value $r$ (in the sense of Eq. (13)), where $\\varepsilon$ can be made smaller by choosing longer control cycles.\n\n In the first simulation experiment we set the arrival rate to $\\lambda=0.9$, and the target reference delay to $r=3.0$.\n The control cycles consist of $M=10,000$ jobs each, and we ran the control algorithm for $N=100$ cycles starting from\n the initial guess of $u_1=1.1$.  The results, shown in Figure 2, indicate an approach of $y_n$ to about a\n steady value in about 5 iterations.    Thereafter we notice fluctuations of $y_{n}$, and a closer view of the results, obtained in Figure 3 by focusing the graph on the range $n=6,\\ldots,100$,  shows\n them to be in the range of $2.5 - 3.5$ except for a single exception at $n=69$.  These fluctuations do not seem to abate at larger $n$, and they likely are due\n to the variances of $y_{n}$ and its IPA derivative $\\frac{\\partial y_n}{\\partial u_n}$. We point out that the average value of\n $y_{n}$, obtained over the range $n=6,\\ldots,100$, is 3.031 (recall that the target value is 3.0).\n Correspondingly, the graph of the service times $u_n$, $n=1,\\ldots,100$, is shown in Figure 4, and their mean over $n=6,\\ldots,100$ is 0.913.\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_21.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay.  $M=10,000$, $n=1,\\ldots,100$.}}\n \\end{figure}\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_3.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay, $n=6\\ldots,\\infty$.  $M=10,000$, $n=5,\\ldots,100$.}}\n \\end{figure}\n\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_4.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - service times.  $M=10,000$, $n=1,\\ldots,100$.}}\n \\end{figure}\n\n Lesser variance of $\\{y_n\\}$ can be  obtained from increasing the cycle length $M$ or reducing the reference target\n $y_{ref}$.\nIn the first case, where we set $M=100,000$ while keeping $y_{ref}$ at 3.00,   $y_n$,$, n=6,\\ldots,100$,  fluctuated between\n2.85 and 3.2 except for two values of $n$, and their mean was 3.008. In the second case, with $y_{{\\rm ref}}=1.5$ and\n$N=10,000$,\n$y_{n}$ fluctuated mostly in the $[1.35-1.65]$-range with two exceptions, and its mean over $n=6,\\ldots,100$ was\n1.505.  In all three cases the regulation algorithm\n converged in about 5 iterations independently of the variances of the delays and their IPA derivatives; those seem to affect mostly the magnitude of the output fluctuations.\n\n In order to test the effects of changing the target reference during an experiment, we ran the regulation algorithm\n for 120 cycles starting with $u_1=1.1$; in the first 40 cycles $y_{ref}=3.0$, in the next 40 cycles $y_{ref}=4.5$, and in the last 40\n cycles, $y_{ref}=1.5$. The results are shown in Figure 5, and they indicate convergence to each value of $y_{ref}$ in about 5\n iterations. Furthermore, it is evident that the variations are larger for larger $y_{ref}$, and the reason is that\n the service times converge to larger values and hence the queue has larger traffic intensities. For\n $y_{ref}=3.0$ the mean of $y_{n}$ over $n=5,\\ldots,40$ is 3.052,  for\n $y_{ref}=4.5$ the mean of $y_{n}$ over $n=45,\\ldots,80$ is 4.653,  and for\n $y_{ref}=1.5$ the mean of $y_{n}$ over $n=85,\\ldots,120$ is 1.504. The corresponding average gains $A_n$  obtained\n from the simulation were 0.063, 0.030, and 0.198. The respective  average service times were 0.918, 0.977, and 0.745. These values correspond to\n traffic intensities (product of $\\lambda$ and the service time) of  0.826, 0.879, and 0.671, which explain the\n noticeable differences in variability. When we took $M=100,000$ the variability declined (as expected) and the obtained\n means are 3.041, 4.515, and 1.501, respectively.\n\n\n\n\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{Fig_51.pdf}\n \t{\\small \\caption{$M/D/1/\\infty$ queue - delay, variable setpoint.  $M=10,000$, $n=1,\\ldots,120$.}}\n \\end{figure}\n\nLastly, we demonstrate the advantage of using the variable-gain controller over fixed-gain integral controls. To this\nend we simulated the system described in the last paragraph with two fixed gains, and compared the results to those obtained\nearlier from the variable-gain control. The constant gains are 0.030 and 0.198 which, as reported above, are the average\n gains driven by the variable-gain controller for the respective extreme setpoint references of 4.5 and 1.5.\n\n Figure 6 depicts the graph of $y_n$, $n=5,\\ldots,120$, obtained from an application of the smaller\n fixed gain of 0.030 (the dashed curve), while the analogous graph obtained from the variable-gain\n controller  (the solid curve) is shown for the sake of comparison.\nWe discern slower response of the fixed-gain controller to changes in the setpoint,  and this is not\nsurprising since the variable-gain controller has larger gains  for the setpoints\n of 3.0 and 1.5.\n For  the larger fixed gain of 0.198, the graph of $y_n$ is shown in Figure 7.\\footnote{This graph  could not be adequately shown in\n the same figure as the graphs in Figure 6  due to the large peaks of $y_n$.}   The controller performs well for the setpoint of 1.5, but\n it exhibits large oscillations suggesting instability for the setpoint of\n 4.5, where the obtained gains of the variable-gain controller are smaller.\n These results are not surprising since, generally,\n   tracking controllers with too-small gains may result in slow adjustment to variations in the target setpoint,\n while overly-large gains may result in oscillations and even instability. The variable-gain controller in this example\n seems to adjust well to changes in the setpoint and thus perform better than the considered fixed-gain controls.\n\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.65\\textwidth]{111_2.pdf}\n \t{\\small \\caption{Comparison of a small, fixed-gain control to the variable-gain controller.}}\n \\end{figure}\n\n \\vspace{.2in}\n \\begin{figure}[h]\n \t\\centering\n \t\\includegraphics[width=0.88\\textwidth]{222_2.pdf}\n \t{\\small \\caption{Oscillations due to a large, fixed-gain control.}}\n \\end{figure}\n\n\n \\subsection{Average loss-rate}\n\n\nConsider  an M/D/1/k queue with a finite buffer, where jobs arriving at a full queue are\nbeing discarded. Given an arrival rate, a buffer size, and a horizon period (cycle time), we aim at\ncontrolling (regulating)    the mean loss rate   to a given reference by adjusting the service times.\n Accordingly, we denote the arrival rate by $\\lambda$, the service times by $s$, the buffer size (including the holding\n  place at the server) by $k$, and the horizon period by $t_{f}$.\n\n\n  Let us divide the time-axis into consecutive control cycles, $C_{n}$, each of\n  duration $t_{f}$ seconds. The control parameter is the service time, namely $u=s$, and during $C_{n}$ its\n  value is denoted by\n  $u_{n}$. The performance function of interest, $J(u)$, is the mean loss rate\n  per control cycle. We approximate $J(u_n)$ by $y_n$, defined as  the number of  jobs\n  discarded during $C_{n}$ divided by $t_{f}$.\n\n  It is readily seen that the function $u_n\\rightarrow y_n$ is piecewise\n  constant and  almost surely no arrival would occur at the same time when another job enters or exits the server,\n  and therefore, the IPA derivative  along a sample path  is $\\frac{dy_n}{du_n}=0$. This does not provide an adequate\n  approximation to $J^{\\prime}(u_n)$, and hence an alternative approach to the estimation of\n  $J^{\\prime}(u_n)$ is needed.\n  To this end we use a  fluid-queue SFM  as described\n  in the next paragraph.\n\n  Consider a fluid queue with a finite buffer, a time-varying inflow rate,  and a constant service\n  rate. Suppose that the queue operates in a given time-interval $[0,t_{f}]$, where its instantaneous\n  arrival rate, denoted by $\\alpha(t)$, is a random process. Denote its service rate by $\\beta$. Let $u:=\\beta^{-1}$ be the control\n  variable,\n  and let $\\gamma(u,t)$ denote the instantaneous overflow (spillover) rate due to the limited buffer.\n  Let $L(u)$ denote the sample-based average loss rate per cycle as a function of the input service rate $u$, defined\n   as\n  \n", "index": 41, "text": "\\begin{equation}\n  L(u)=\\frac{1}{t_{f}}\\int_{0}^{t_{f}}\\gamma(u,t)dt.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"L(u)=\\frac{1}{t_{f}}\\int_{0}^{t_{f}}\\gamma(u,t)dt.\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>t</mi><mi>f</mi></msub></mfrac><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><msub><mi>t</mi><mi>f</mi></msub></msubsup><mrow><mi>\u03b3</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n In this  we apply\n  the IPA derivative-formula,    obtained from an analysis of the SFM,  to the sample\n  path of the discrete queue during $C_{n-1}$. In contrast, the plant's output $y_{n-1}$ that is used in the control loop via\n  Eq. (1) with $e_{n-1}:=r-y_{n-1}$ corresponds to the discrete queue  since it represents the\n  ``real'' system.\n  The effectiveness  of the resulting regulation algorithm is related to the  quality of the approximation\n  of $J(u_n)$ and $J^{\\prime}(u_n)$ by $y_n$ and $L^{\\prime}(u_n)$,\n  respectively. Now Ref. \\cite{Cassandras02} showed that the function $L(u)$ is Lipschitz continuous in\n  $u$, w.p.1. Furthermore, by Eq. (20), below, $L^{\\prime}(u)\\geq 0$, and $L(u)$ and $L^{\\prime}(u)$ are monotone increasing and hence\n  the function $L(u)$ is convex w.p.1. Therefore we believe that $J(u)$ is convex as well although we do not know of a proof,\n  and in this case the assumptions of  Lemma 2.2 and Proposition 2.3 are in force. In any event, the effectiveness of the regulation\n  algorithm will be tested by simulation.\n\n  The  IPA derivative $L^{\\prime}(u)$ has the following form (see \\cite{Cassandras02}).\n   Suppose that there are $Q$ lossy busy periods during the horizon interval $[0,t_{f}]$, indexed\n  by $q=1,\\ldots,Q$ in increasing order (a busy period is {\\it lossy} if  any positive amount of overflow\n  is incurred throughout its duration).\n  For the $qth$ lossy busy period, let $u_{q}$ be the first time loss occurs during it, and let $v_{q}$ be its end point; in other words,\n  $u_{q}$ is the first time in that busy period when the buffer becomes full, and $v_{q}$ is the next time the buffer becomes empty. Then, under mild assumptions \\cite{Cassandras02},\n  \n", "itemtype": "equation", "pos": 36418, "prevtext": "\n  Observe that $L(u)$ provides an approximation to $J(u)$ to the extent that the fluid\n  queue serves to approximate the discrete queue. The main difference between $J(u)$ and $L(u)$ is that $J(u)$ is the\n  mean loss rate of the discrete queue, while $L(u)$ is the sample time-average loss rate per cycle of the continuous queue.\n\n  Reference \\cite{Cassandras02} showed that the IPA derivative $L^{\\prime}(u)$ is unbiased, and\n  it is computable by a simple, model-free  formula (listed below) that can act on the sample paths of the discrete queue.\n  Furthermore, it can serve as an approximation to $J^{\\prime}(u)$.\n  Therefore we  implement the regulation algorithm in the following way.\n  During cycle $C_{n-1}$, the service time is $u_{n-1}$,   $y_{n-1}$  is the resulting\n  sample-average loss rate of the discrete queue, and $\\psi_{n-1}:=y_{n-1}-J(u_{n-1})$. The IPA derivative  $L^{\\prime}(u_{n-1})$,\n  specified below,\n   is the sample derivative of the average loss rate of the continuous queue as defined by Eq. (18),\n   and $\\phi_{n-1}:=L^{\\prime}(u_{n-1})-J^{\\prime}(u_{n-1})$.\n  Eq. (3) becomes\n  \n", "index": 43, "text": "\\begin{equation}\n  A_{n}:=\\big(L^{\\prime}(u_{n-1})\\big)^{-1}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"A_{n}:=\\big{(}L^{\\prime}(u_{n-1})\\big{)}^{-1}.\" display=\"block\"><mrow><mrow><msub><mi>A</mi><mi>n</mi></msub><mo>:=</mo><msup><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msup><mi>L</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\n  With $A_{n}$ defined by (19), we ran a simulation with the following parameters: $y_{{\\rm ref}}=0.1$, $t_{f}=4,000$,\n  $k=3$, $\\lambda=0.9$, the initial parameter-value was $u_{1}=1.5$, and the number of cycles was $N=100$. The resulting\n  graph of $y_{n}$, $n=1,\\ldots,100$ is shown in Figure 8, where we notice convergence of the tracking algorithm in 3 iterations,\n  to a band around the target value of 0.1. Within this band $y_{n}$ fluctuates between 0.08 and 0.125, except for a single value of $n$ where $y_{n}=0.139$. The mean of $y_{n}$ in the range $n=5,\\ldots,100$ was 0.1005. To reduce the variability we ran the simulation for\n  $t_{f}=20,000$, and the results, shown in Figure 9, exhibit an equally-fast convergence of the regulation algorithm\n  with fluctuations in the range of $[0.091,0.114]$, and  with mean (over $n=5,\\ldots,100$) of 0.1000.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Fig_6.pdf}\n{\\small \\caption{M/D/1/k queue - loss.  $t_{f}=4,000$, $n=1,\\ldots,100$.}}\n\\end{figure}\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Fig_7.pdf}\n{\\small \\caption{M/D/1/k queue - loss.  $t_{f}=20,000$, $n=1,\\ldots,100$.}}\n\\end{figure}\n\n\\section{Application to a production system modeled by a Petri net}\\label{sec:PN}\n\nThe IPA technique recently has been extended from fluid queueing networks\nto a class of continuous Petri nets \\cite{Xie02,Wardi13b}. References \\cite{Wardi13b,Seatzu13} applied the results to an optimization example\nof balancing part-inventories with product backorders in a single-stage manufacturing system,  and tested the\napplication of IPA in conjunction with a stochastic approximation algorithm. This section uses the same example to test\nour approach to regulation.\n\nThe considered manufacturing system  consists of a machine that produces a sequence of single-type\n products.\nThe production schedule is driven by products' orders while  parts' inventories are maintained as safety stocks.\nTo make a product, the\nsystem must have an available  part and a product order; parts without orders accumulate in the form of\ninventories, while orders without parts result in cumulative backorders. Naturally\nboth excessive inventories and backorders are undesirable, and References\n\\cite{Wardi13b,Seatzu13} devise an IPA-based algorithm for optimally balancing\nthem. The underlying model for the algorithm is comprised of the\ncontinuous (fluid) Petri net (event graph) shown in Figure 10.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_6.pdf}\n{\\small \\caption{Basic  event graph}}\n\\end{figure}\n\nContinuous Petri nets are hybrid Petri nets where the flow of fluid tokens through transitions is represented by\npiecewise-continuous rate processes; see, e.g., \\cite{Silva04} for comprehensive presentations.\nWith regard to our system shown in Figure 10,\n transitions\n$T_{1}$, $T_{2}$, and $T_{3}$ represent, respectively, the processes of product-orders,\n parts' arrivals,\nand the machine's operation. Each transition $T_{i}$, $i=1,2,3$, is\ncharacterized by a maximum fluid-flow rate $V_{i}(t)>0$, which acts as an upper bound on its actual flow rate,\ndenoted by $v_{i}(t)$. The places $p_{1}$ and $p_{2}$ are used for holding fluid, and at time $t$ the amount\nof stored fluid is denoted by $m_{1}(t)$ and $m_{2}(t)$, respectively. The processes $\\{V_{i}(t)\\}$, $\\{v_{i}(t)\\}$\n($i=1,2,3$) and $\\{m_{j}(t)\\}$ ($j=1,2$) can be viewed as random processes defined over a common\nprobability space $(\\Omega,{\\cal F},P)$.\n\nThe dynamics of the system are described by the following three equations relating the above processes: For $i=1,2$,\n\n", "itemtype": "equation", "pos": 38213, "prevtext": "\n In this  we apply\n  the IPA derivative-formula,    obtained from an analysis of the SFM,  to the sample\n  path of the discrete queue during $C_{n-1}$. In contrast, the plant's output $y_{n-1}$ that is used in the control loop via\n  Eq. (1) with $e_{n-1}:=r-y_{n-1}$ corresponds to the discrete queue  since it represents the\n  ``real'' system.\n  The effectiveness  of the resulting regulation algorithm is related to the  quality of the approximation\n  of $J(u_n)$ and $J^{\\prime}(u_n)$ by $y_n$ and $L^{\\prime}(u_n)$,\n  respectively. Now Ref. \\cite{Cassandras02} showed that the function $L(u)$ is Lipschitz continuous in\n  $u$, w.p.1. Furthermore, by Eq. (20), below, $L^{\\prime}(u)\\geq 0$, and $L(u)$ and $L^{\\prime}(u)$ are monotone increasing and hence\n  the function $L(u)$ is convex w.p.1. Therefore we believe that $J(u)$ is convex as well although we do not know of a proof,\n  and in this case the assumptions of  Lemma 2.2 and Proposition 2.3 are in force. In any event, the effectiveness of the regulation\n  algorithm will be tested by simulation.\n\n  The  IPA derivative $L^{\\prime}(u)$ has the following form (see \\cite{Cassandras02}).\n   Suppose that there are $Q$ lossy busy periods during the horizon interval $[0,t_{f}]$, indexed\n  by $q=1,\\ldots,Q$ in increasing order (a busy period is {\\it lossy} if  any positive amount of overflow\n  is incurred throughout its duration).\n  For the $qth$ lossy busy period, let $u_{q}$ be the first time loss occurs during it, and let $v_{q}$ be its end point; in other words,\n  $u_{q}$ is the first time in that busy period when the buffer becomes full, and $v_{q}$ is the next time the buffer becomes empty. Then, under mild assumptions \\cite{Cassandras02},\n  \n", "index": 45, "text": "\\begin{equation}\n  L^{\\prime}(u)=\\frac{1}{t_{f}}u^2\\sum_{q=1}^{Q}\\big(v_{q}-u_{q}\\big).\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"L^{\\prime}(u)=\\frac{1}{t_{f}}u^{2}\\sum_{q=1}^{Q}\\big{(}v_{q}-u_{q}\\big{)}.\" display=\"block\"><mrow><mrow><mrow><msup><mi>L</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>t</mi><mi>f</mi></msub></mfrac><mo>\u2062</mo><msup><mi>u</mi><mn>2</mn></msup><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><msub><mi>v</mi><mi>q</mi></msub><mo>-</mo><msub><mi>u</mi><mi>q</mi></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n For $i=3$, define $\\varepsilon_{3}(t):=\\big\\{j\\in\\{1,2\\}:m_{j}(t)=0\\big\\}$; then\n\n", "itemtype": "equation", "pos": 42003, "prevtext": "\n\n  With $A_{n}$ defined by (19), we ran a simulation with the following parameters: $y_{{\\rm ref}}=0.1$, $t_{f}=4,000$,\n  $k=3$, $\\lambda=0.9$, the initial parameter-value was $u_{1}=1.5$, and the number of cycles was $N=100$. The resulting\n  graph of $y_{n}$, $n=1,\\ldots,100$ is shown in Figure 8, where we notice convergence of the tracking algorithm in 3 iterations,\n  to a band around the target value of 0.1. Within this band $y_{n}$ fluctuates between 0.08 and 0.125, except for a single value of $n$ where $y_{n}=0.139$. The mean of $y_{n}$ in the range $n=5,\\ldots,100$ was 0.1005. To reduce the variability we ran the simulation for\n  $t_{f}=20,000$, and the results, shown in Figure 9, exhibit an equally-fast convergence of the regulation algorithm\n  with fluctuations in the range of $[0.091,0.114]$, and  with mean (over $n=5,\\ldots,100$) of 0.1000.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Fig_6.pdf}\n{\\small \\caption{M/D/1/k queue - loss.  $t_{f}=4,000$, $n=1,\\ldots,100$.}}\n\\end{figure}\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Fig_7.pdf}\n{\\small \\caption{M/D/1/k queue - loss.  $t_{f}=20,000$, $n=1,\\ldots,100$.}}\n\\end{figure}\n\n\\section{Application to a production system modeled by a Petri net}\\label{sec:PN}\n\nThe IPA technique recently has been extended from fluid queueing networks\nto a class of continuous Petri nets \\cite{Xie02,Wardi13b}. References \\cite{Wardi13b,Seatzu13} applied the results to an optimization example\nof balancing part-inventories with product backorders in a single-stage manufacturing system,  and tested the\napplication of IPA in conjunction with a stochastic approximation algorithm. This section uses the same example to test\nour approach to regulation.\n\nThe considered manufacturing system  consists of a machine that produces a sequence of single-type\n products.\nThe production schedule is driven by products' orders while  parts' inventories are maintained as safety stocks.\nTo make a product, the\nsystem must have an available  part and a product order; parts without orders accumulate in the form of\ninventories, while orders without parts result in cumulative backorders. Naturally\nboth excessive inventories and backorders are undesirable, and References\n\\cite{Wardi13b,Seatzu13} devise an IPA-based algorithm for optimally balancing\nthem. The underlying model for the algorithm is comprised of the\ncontinuous (fluid) Petri net (event graph) shown in Figure 10.\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_6.pdf}\n{\\small \\caption{Basic  event graph}}\n\\end{figure}\n\nContinuous Petri nets are hybrid Petri nets where the flow of fluid tokens through transitions is represented by\npiecewise-continuous rate processes; see, e.g., \\cite{Silva04} for comprehensive presentations.\nWith regard to our system shown in Figure 10,\n transitions\n$T_{1}$, $T_{2}$, and $T_{3}$ represent, respectively, the processes of product-orders,\n parts' arrivals,\nand the machine's operation. Each transition $T_{i}$, $i=1,2,3$, is\ncharacterized by a maximum fluid-flow rate $V_{i}(t)>0$, which acts as an upper bound on its actual flow rate,\ndenoted by $v_{i}(t)$. The places $p_{1}$ and $p_{2}$ are used for holding fluid, and at time $t$ the amount\nof stored fluid is denoted by $m_{1}(t)$ and $m_{2}(t)$, respectively. The processes $\\{V_{i}(t)\\}$, $\\{v_{i}(t)\\}$\n($i=1,2,3$) and $\\{m_{j}(t)\\}$ ($j=1,2$) can be viewed as random processes defined over a common\nprobability space $(\\Omega,{\\cal F},P)$.\n\nThe dynamics of the system are described by the following three equations relating the above processes: For $i=1,2$,\n\n", "index": 47, "text": "\\begin{equation}\nv_{i}(t)=V_{i}(t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"v_{i}(t)=V_{i}(t).\" display=\"block\"><mrow><mrow><mrow><msub><mi>v</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>V</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nAs for $m_{j}(t)$, $j=1,2$, we have that\n\n", "itemtype": "equation", "pos": 42136, "prevtext": "\n For $i=3$, define $\\varepsilon_{3}(t):=\\big\\{j\\in\\{1,2\\}:m_{j}(t)=0\\big\\}$; then\n\n", "index": 49, "text": "\\begin{equation}\nv_{3}(t)=\\left\\{\n\\begin{array}{ll}\nV_{3}(t), & {\\rm if}\\ \\varepsilon_{3}(t)=\\emptyset\\\\\nmin\\big(v_{i}(t):i\\in\\varepsilon_{3}(t)\\big), & {\\rm if}\\ \\varepsilon_{3}(t)\\neq\\emptyset.\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"v_{3}(t)=\\left\\{\\begin{array}[]{ll}V_{3}(t),&amp;{\\rm if}\\ \\varepsilon_{3}(t)=%&#10;\\emptyset\\\\&#10;min\\big{(}v_{i}(t):i\\in\\varepsilon_{3}(t)\\big{)},&amp;{\\rm if}\\ \\varepsilon_{3}(t)%&#10;\\neq\\emptyset.\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>v</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi>V</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><msub><mi>\u03b5</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mi mathvariant=\"normal\">\u2205</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><msub><mi>v</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>:</mo><mi>i</mi><mo>\u2208</mo><msub><mi>\u03b5</mi><mn>3</mn></msub><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><msub><mi>\u03b5</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2260</mo><mi mathvariant=\"normal\">\u2205</mi></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nIn the forthcoming discussion we assume  that the system evolves in a given time-interval $[0,t_{f}]$ with given\ninitial conditions $m_{1}(0)$ and $m_{2}(0)$.\n\nIn the typical case where the three processes $\\{V_{i}(t)\\}$ are exogenous, the other network processes,\n$\\{v_{i}(t)\\}$ and $\\{m_{j}(t)\\}$,\n are defined\nin their terms via Eqs. (21)-(23). In other situations some of the processes $\\{V_{i}(t)\\}$ are exogenous\nwhile others are controlled, and in this case the equations describing the controls together with (21)-(23)\ndefine all of the network processes.\nIn the example considered in \\cite{Wardi13b,Seatzu13} the processes $\\{V_{1}(t)\\}$ and $\\{V_{3}(t)\\}$ are\nexogenous while $\\{V_{2}(t)\\}$ is controlled. Specifically, product orders are assumed to arrive in batches, and hence\n\n", "itemtype": "equation", "pos": 42408, "prevtext": "\nAs for $m_{j}(t)$, $j=1,2$, we have that\n\n", "index": 51, "text": "\\begin{equation}\n\\dot{m}_{j}(t)=v_{j}(t)-v_{3}(t).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\dot{m}_{j}(t)=v_{j}(t)-v_{3}(t).\" display=\"block\"><mrow><mrow><mrow><msub><mover accent=\"true\"><mi>m</mi><mo>\u02d9</mo></mover><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>v</mi><mi>j</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msub><mi>v</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwhere $\\delta(\\cdot)$ is the Dirac delta function, $s_{k}$, $k=1,2,\\ldots$,  are the arrival times, and $\\alpha_{k}$ represent the quantities of the orders. The machine is assumed\nto have deterministic service times, and hence $V_{3}(t)=V_{3}$ for a given $V_{3}>0$. The parts' arrival rates are controlled by the backorders via a threshold in the following fashion: $V_{2}(t)$ has a given low value  if the backorder levels  are below the threshold,\nand a given higher value if the backorder levels are above the threshold. Formally, given a threshold $\\rho>0$,\nand given constants $V_{2,1}\\geq 0$ and\n$V_{2,2}>V_{2,1}$, $V_{2}(t)$ is defined via\n\n", "itemtype": "equation", "pos": 43263, "prevtext": "\nIn the forthcoming discussion we assume  that the system evolves in a given time-interval $[0,t_{f}]$ with given\ninitial conditions $m_{1}(0)$ and $m_{2}(0)$.\n\nIn the typical case where the three processes $\\{V_{i}(t)\\}$ are exogenous, the other network processes,\n$\\{v_{i}(t)\\}$ and $\\{m_{j}(t)\\}$,\n are defined\nin their terms via Eqs. (21)-(23). In other situations some of the processes $\\{V_{i}(t)\\}$ are exogenous\nwhile others are controlled, and in this case the equations describing the controls together with (21)-(23)\ndefine all of the network processes.\nIn the example considered in \\cite{Wardi13b,Seatzu13} the processes $\\{V_{1}(t)\\}$ and $\\{V_{3}(t)\\}$ are\nexogenous while $\\{V_{2}(t)\\}$ is controlled. Specifically, product orders are assumed to arrive in batches, and hence\n\n", "index": 53, "text": "\\begin{equation}\nV_{1}(t)=\\sum_{k\\geq 1}\\alpha_{k}\\delta(t-s_{k}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"V_{1}(t)=\\sum_{k\\geq 1}\\alpha_{k}\\delta(t-s_{k}),\" display=\"block\"><mrow><mrow><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>k</mi><mo>\u2265</mo><mn>1</mn></mrow></munder><mrow><msub><mi>\u03b1</mi><mi>k</mi></msub><mo>\u2062</mo><mi>\u03b4</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo><msub><mi>s</mi><mi>k</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nWe assumed that $V_{2,1}\\leq V_{3}\\leq V_{2,2}$. It is obvious that Equations (21)-(23) and (25) have a unique joint solution for\nevery set of initial conditions.\n\nNow let us consider the threshold $\\rho$ as the control parameter and hence denote it by $u=\\rho$.\n Then the processes\n$\\{V_{2}(t)\\}$, $\\{v_{i}(t)\\}$, $i=2,3$, and $\\{m_{j}(t)\\}$, $j=1,2$ are functions of $u$ as well,\nand hence are denoted by $\\{V_{2}(u,t)\\}$, $\\{v_{i}(u,t)\\}$, and $\\{m_{j}(u,t)\\}$, respectively. Assume that\na particular value of $u$ remains fixed throughout the evolution of the system in a given interval\n$[0,t_{f}]$. Consider the sample performance\nfunction $L(u)$ defined as\n\n", "itemtype": "equation", "pos": 43993, "prevtext": "\nwhere $\\delta(\\cdot)$ is the Dirac delta function, $s_{k}$, $k=1,2,\\ldots$,  are the arrival times, and $\\alpha_{k}$ represent the quantities of the orders. The machine is assumed\nto have deterministic service times, and hence $V_{3}(t)=V_{3}$ for a given $V_{3}>0$. The parts' arrival rates are controlled by the backorders via a threshold in the following fashion: $V_{2}(t)$ has a given low value  if the backorder levels  are below the threshold,\nand a given higher value if the backorder levels are above the threshold. Formally, given a threshold $\\rho>0$,\nand given constants $V_{2,1}\\geq 0$ and\n$V_{2,2}>V_{2,1}$, $V_{2}(t)$ is defined via\n\n", "index": 55, "text": "\\begin{equation}\nV_{2}(t)=\\left\\{\n\\begin{array}{ll}\nV_{2,1}, & {\\rm if}\\ m_{1}(t)\\leq\\rho\\\\\nV_{2,2}, & {\\rm if}\\ m_{1}(t)> \\rho.\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"V_{2}(t)=\\left\\{\\begin{array}[]{ll}V_{2,1},&amp;{\\rm if}\\ m_{1}(t)\\leq\\rho\\\\&#10;V_{2,2},&amp;{\\rm if}\\ m_{1}(t)&gt;\\rho.\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>V</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><msub><mi>V</mi><mrow><mn>2</mn><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><msub><mi>m</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mi>\u03c1</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><msub><mi>V</mi><mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><msub><mi>m</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>\u03c1</mi></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nfor a given distribution of the initial conditions $m_{j}(0)$, $j=1,2$, and let $J(u):=E\\big(L(u)\\big)$\ndenote its expected value.\nReferences \\cite{Wardi13b,Seatzu13} considered the problem of minimizing\n a weighted sum of\n$J(u)$ and the expected-value of the average workload at $p_{1}$. Here we use the same system\nexcept that we perform regulation of $L(u)$ rather than optimization.\n\nTo put it all in the setting described\nin Section 1, we define a control cycle to consist of $t_f$ time units, $u_n$ denotes the input during the $nth$ control\ncycle $C_n$,\nand $y_n:=L(u_n)$ as defined by Eq. (26). Therefore, for every $n=1,\\ldots$,\n$y_n\\rightarrow J(u_n)$ as $t_f\\rightarrow\\infty$ w.p.1. Moreover,\nRefs.  \\cite{Wardi13b,Seatzu13} prove that the IPA derivative $L^{\\prime}(u)$ is unbiased, hence\n$\\frac{\\partial y_n}{\\partial u_n}\\rightarrow_{t_f\\rightarrow\\infty}J^{\\prime}(u_n)$ w.p.1. Consequently, the error terms\n$\\psi_n$ and $\\phi_n$ can be  reduced by taking  longer cycle times $t_f$. Regarding monotonicity and convexity of $J(u)$,\nlarger threshold $u$ results in smaller inventories and hence $J(u)$ is monotone non-increasing. However, we have\nno way of proving convexity or concavity of $J(u)$, hence we put the regulation algorithm to the test\nby simulation.\n\nIn the considered example, $V_{3}=6$, $V_{2,1}=2.15$, and $V_{2,2}=6$; these numbers are taken from\n\\cite{Wardi13b,Seatzu13}. The product-orders process $\\{V_{1}(t)\\}$, defined\nby\n(24), consists of equally-spaced arrivals every 50 seconds (deterministic), and each arrival\nbrings in an amount of fluid that is uniformly distributed in the $[30,70]$-range. The reference value to be tracked is\n$J_{{\\rm ref}}=758.70$, and it is the computed value of $J$ obtained for the aforementioned optimization problem in\n\\cite{Seatzu13}.\nThe IPA derivative $L^{\\prime}(\\theta)$ is computable via a recursive algorithm\nconstructed according to  the event-calculus framework defined in \\cite{Cassandras10,Wardi13b};  a detailed presentation thereof\ncan be found in \\cite{Seatzu13}.\n\nWe ran the regulation algorithm for 100 control cycles with $t_f=1,000$. The\nresults of two typical runs are shown in Figure 11 for two respective values of the initial control parameter,\n$u_{1}=35$ and $u_{1}=15$. The corresponding  graphs of $y_{n}:=L_{n}(u_{n})$ are plotted\nby the dashed curve and solid curve, and both indicate convergence to a band around $y_{{\\rm ref}}=758.70$ after 3 iterations.\nThis band has\na maximum range of 47.17, and the averages of the outputs $y_{n}$, taken over $n=20,\\ldots,100$, are 758.55 for the dashed plot,\nand 758.73 for the solid plot. Although these results indicate convergence of the outputs' average to $y_{{\\rm ref}}$, variations\nin the output values are discernable.  These variations, as well as those in the IPA derivatives, yield\n fluctuations in the values of $u_{n}$, $n=1,2,\\ldots$, as can be seen in Figure 12. We believe that the\n major cause of these variations is in the variance of $L(u)$ and   not inherent in the regulation\n algorithm. To test this point, we ran 100 independent simulations of the system at the fixed value of\n $u=24.8$, which is close to the\n average of $u_{n}$, $n=20,\\ldots,100$ obtained by the regulation algorithm. The results,\n $\\big\\{L(u)\\big\\}_{i}$, shown in Figure 13,\n indicate a persistent variation with a maximum range of 42, which is comparable to the range obtained from Figure 11.\n\n To further test the convergence rate of the regulation algorithm we chose more extreme starting values of the control\n parameter, namely $u_{1}=45$ and $u_{1}=5$. The corresponding values of $y_{1}$ are 635 and 883, which are more extreme\n than those obtained in Figure 11, but nonetheless the regulation algorithm converged to a similar band around $y_{{\\rm ref}}$\n in 3 iterations.\n\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_7.pdf}\n{\\small \\caption{Petri net - inventory. $t_{f}=1,000$, $n=1,\\ldots,100$}}\n\\end{figure}\n\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_8_2.pdf}\n{\\small \\caption{Petri net - threshold control.  $t_{f}=1,000$, $n=1,\\ldots,100$}}\n\\end{figure}\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_9_2.pdf}\n{\\small \\caption{Variations in $L(u)$: 100 independent simulations}}\n\\end{figure}\n\n\n\\section{Application to throughput regulation in computer processors}\\label{sec:chip}\n\nThe problem of maintaining stable instruction execution rates in computer\nprocessors arises\nin several application areas. For instance, in real-time\napplications, guaranteeing a constant instruction execution rate\nsimplifies otherwise complex real-time scheduling tasks\nby enabling tighter bounds on deadlines to be met \\cite{Shakkottaia01}. Variable rate\ninstruction execution often leads to a reliance on worst case\nexecution-time estimates that far exceed the average execution\ntimes, resulting in a  poorer processor utilization than is\nnecessary.  A second application concerns a tradeoff between\ninstruction execution rate and power dissipation.   Dynamic Voltage\nFrequency Scaling (DVFS) can be used to navigate this tradeoff to\narrive at an instruction rate that is the most power-efficient~\\cite{c3}\\cite{c4}.  This approach, described in the\nIntroduction, was followed by~\\cite{Almoosa12a} for throughput regulation in\nprocessor cores. In this section we pursue a similar approach but use a\nmore-precise system-model for the throughput simulation and hence obtain\nbetter results, including far-faster convergence, as described in the sequel.\n\nWe consider a multiprogrammed multi-core processor where programs are\nassigned for execution to the cores by the operating system.  Each\ncore is assigned an instruction-execution rate setpoint by a\nsupervisory controller, and has to control (regulate) its instruction\nrate to that level.  In this paper we are not concerned with the way\nthese setpoint levels are assigned, and consider them as given and\nfixed.  Furthermore, we assume that each core is in a separate clock domain\nand can independently control its own clock rate.  Each core exploits\ninstruction-level parallelism (ILP) utilizing an Out-of-Order (OOO)\ntechnology whereby instructions may complete execution in an order different\nfrom program order (i.e., out of order). OOO execution enables\ninstruction execution to be limited only by data dependencies rather than\nthe order in which they appear in the program thereby serving as the\nprimary means for exploiting ILP in modern processors.\n\n\nA high-level functional and logical description of programs' execution in an OOO core is depicted in Figure 14.\nInstructions are fetched sequentially from memory and placed in the Instruction queue. There they are processed by\nfunctional units which can be thought of as servers in the queueing parlance.  It is often the case\nthat there are enough functional units available for concurrent execution of all of the instructions\nin the queue. What holds up the execution of an instruction is its dependency on data that would become\navailable from the execution of another instruction. For example, the instruction of adding two variables, $x$ and $y$,\nrequires that both variables have numerical values. $x$ may be obtained from another numerical instruction,\nwhile $y$ may be fetched from memory. Thus, it is evident that the addition of $x$ and $y$ cannot commence before the\ninstructions of computing $x$ and fetching $y$ are completed.\n\nInstructions can be classified as {\\it data dependent} vs. {\\it data independent} according to whether\nthey depend on data provided by the execution of other instructions. If an instruction is data dependent then\nits execution can commence as soon as all such data and a functional unit become available. If the instruction\nis data independent then its execution can start as soon as a functional unit is available.\n\nMemory instructions can take one-to-two orders of magnitude more time to execute than computational\ninstructions. Therefore most architectures make use of a hierarchical memory\narrangement where on-chip cache access takes less time than external memory such as DRAM. First the cache is searched,\nand if the variable is found there then it is fetched and the instruction is completed. If the variable\nis not stored in cache then a cache miss occurs and a cache line\n(containing the variable) is fetched from external memory\n(typically DRAM) and placed in the cache. The variable is then\naccessed and the instruction is completed. We can\nthink of all external-memory (non-cache) accesses as placed in a\nFirst-in-First-out queue designated by the {\\it Memory} box in the\nfigure. Furthermore, this queue has a finite buffer, and when it becomes\nfull the entire memory access, including from the cache, is stalled.\n\nDuring its processing the instruction is still stored in the Instruction queue, where it has been placed since its\narrival at the start of the aforementioned process. Although it may be executed concurrently with other instructions\nsubject to data-dependency constraints, it may not be released from the queue upon completion of its execution; in fact, its\nrelease time is the later of its completion time and the release time of the previous instruction. However, the variables it computes\nbecome available to other instructions upon its completion and not release. We point out that the term {\\it release} used here\nis called {\\it commitment} in the parlance of computer architectures. It is this quantity that is used to compute the instruction's throughput, as\nwill be made clear in the sequel.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.95\\textwidth]{Figure_logic.pdf}\n{\\small \\caption{Functional description of OOO processing}}\n\\end{figure}\n\nA high-level\ndescription of the hardware  of an\nOOO core is depicted in Figure 15 (see~\\cite{c5} for a more detailed\ndescription). The acronyms in the various blocks indicate the\nfollowing entities: IQ - Instruction Queue; ROB - Reorder Buffer; RS -\nReservation Station; FU - Functional Unit; RF - Register File;\nL/S~Q - Load/Store Queue; MSHR - Miss Status\nHandling Register; and MEM - memory other than cache, typically DRAM.\nDuring a program's execution, the instruction unit of the processor fetches\nprogram instructions sequentially from memory and places them in the\nInstruction Queue (IQ). Instructions are issued from the IQ to a\nreservation station waiting for access to the corresponding functional\nunit. An instruction is granted access  (starts processing) after (i)  all its operands are available, for\nexample, the result from  preceding instructions, and (ii) the\nfunctional unit is available. When an instruction\nis issued to an RS, it is also allocated an entry in the ROB in the original program\norder.\n\nInstructions in the RS are issued to the functional units when their\noperands are available (note that this issue order may be different from\nprogram order hence the OOO designation). While the instruction is\nwaiting for its operands, it is said to be {\\em stalled}. Instruction\nexecution results are broadcast to all reservation stations and the\nROB - they are stored along with the instruction's entry in the\nROB. When an instruction reaches the head of the ROB and it has\ncompleted execution, its result is placed in the RF. This\nprocess is called {\\em instruction committment (IC)}. The {\\it IC}\nstage basically signifies the termination of the instruction processing. Note that\nwhile instructions may complete execution out of order, they are\ncommitted in program order. For the purpose of this discussion and its\nrelated model, we can view the IQ and ROB as a single block where\ninstructions are buffered in order according to their issue (arrival)\norder from the instruction fetch unit of the processor.\n\n\n\n\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure11y.pdf}\n{\\small \\caption{High-level OOO architecture}}\n\\end{figure}\n\n\n\n\n\n\n{\\it Memory} instructions such as load and store instructions are\ndirected to the Load/Store Queue (L/SQ) shown in Figure 15. Consider\nthe execution of a load instruction. First an attempt is made to\naccess the data from the data cache. If that is successful (cache\nhit), the data is read from the cache line and sent to the\ncorresponding instruction entry in ROB.  If the requested data is not\nin the cache (cache miss) it has to be fetched from the next level of\nthe memory hierarchy, for example main memory, typically DRAM.  In that case a request is sent to the Miss Status\nHandling Register (MSHR), which serves as a finite-buffer queue for\nbuffering outstanding non-cache memory access requests.  When the MSHR\nis full all new instructions that generate memory-accesses are\nstalled.  Upon completion of the memory access, the data is sent to\nthe ROB and the instruction clears the MSHR.  Note that the MSHR is a\nfinite-buffer queue that holds only non-cache memory instructions. However,\nwhen it becomes full, it halts all new memory access requests, and thus\n comprises a fairly nonstandard queueing model.\n\n\nTo quantify all of this (see also \\cite{Chen15}), consider a control cycle comprised of\ninstructions $I_{i}$, $i=1,\\ldots,M$ for a given $M>0$.  Let us set\nthe time to $t=0$ at the moment the first instruction is issued.  In\nthe framework of the closed-loop system defined by the regulation algorithm,\nthe control variable $u$ will be the clock frequency (rate) of\nthe core, but it is easier to carry out the IPA computations in terms\nof the clock cycle, $\\tau:=u^{-1}$.\n\nFor instruction $I_{i}$, define  $\\xi_{i}$ to be its issue time in terms  of clock cycles (counting from the issue time of\n$I_{1}$); $\\alpha_{i}(\\tau)$  - its execution starting time (in seconds), and\n$\\beta_{i}(\\tau)$ - its completion time (in seconds), not to be confused with its commit\ntime which may occur later. Note that we use two kinds of timing variables, namely  in units of clock cycles or seconds. The  former can be measured  in real time for the purpose of the control law,\n while the latter\nare used only in the analysis.\n\nConsider first the case where   $I_{i}$ is not a memory instruction; memory instructions will be\nhandled later.\nThe issue time  of $I_{i}$ (in seconds) is $\\xi_{i}\\tau$, and we assume that there are available resources in the\nROB and RS so that the instruction is forwarded there at the same time,\n$\\xi_{i}\\tau$.  If $I_{i}$ is data dependent,\ndenote by $k(i)$ the index (counter) of the instruction which is the last to provide a variable to $I_{i}$.\nThen, we have that\n\n", "itemtype": "equation", "pos": 44819, "prevtext": "\nWe assumed that $V_{2,1}\\leq V_{3}\\leq V_{2,2}$. It is obvious that Equations (21)-(23) and (25) have a unique joint solution for\nevery set of initial conditions.\n\nNow let us consider the threshold $\\rho$ as the control parameter and hence denote it by $u=\\rho$.\n Then the processes\n$\\{V_{2}(t)\\}$, $\\{v_{i}(t)\\}$, $i=2,3$, and $\\{m_{j}(t)\\}$, $j=1,2$ are functions of $u$ as well,\nand hence are denoted by $\\{V_{2}(u,t)\\}$, $\\{v_{i}(u,t)\\}$, and $\\{m_{j}(u,t)\\}$, respectively. Assume that\na particular value of $u$ remains fixed throughout the evolution of the system in a given interval\n$[0,t_{f}]$. Consider the sample performance\nfunction $L(u)$ defined as\n\n", "index": 57, "text": "\\begin{equation}\nL(u)=\\frac{1}{t_{f}}\\int_{0}^{t_{f}}m_{2}(u,t)dt,\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"L(u)=\\frac{1}{t_{f}}\\int_{0}^{t_{f}}m_{2}(u,t)dt,\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msub><mi>t</mi><mi>f</mi></msub></mfrac><mo>\u2062</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><msub><mi>t</mi><mi>f</mi></msub></msubsup><mrow><msub><mi>m</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nAs for the completion time, let\n$\\mu_{i}$ denote the execution time of $I_{i}$ in terms of clock cycles. Then,\n\n", "itemtype": "equation", "pos": 59488, "prevtext": "\nfor a given distribution of the initial conditions $m_{j}(0)$, $j=1,2$, and let $J(u):=E\\big(L(u)\\big)$\ndenote its expected value.\nReferences \\cite{Wardi13b,Seatzu13} considered the problem of minimizing\n a weighted sum of\n$J(u)$ and the expected-value of the average workload at $p_{1}$. Here we use the same system\nexcept that we perform regulation of $L(u)$ rather than optimization.\n\nTo put it all in the setting described\nin Section 1, we define a control cycle to consist of $t_f$ time units, $u_n$ denotes the input during the $nth$ control\ncycle $C_n$,\nand $y_n:=L(u_n)$ as defined by Eq. (26). Therefore, for every $n=1,\\ldots$,\n$y_n\\rightarrow J(u_n)$ as $t_f\\rightarrow\\infty$ w.p.1. Moreover,\nRefs.  \\cite{Wardi13b,Seatzu13} prove that the IPA derivative $L^{\\prime}(u)$ is unbiased, hence\n$\\frac{\\partial y_n}{\\partial u_n}\\rightarrow_{t_f\\rightarrow\\infty}J^{\\prime}(u_n)$ w.p.1. Consequently, the error terms\n$\\psi_n$ and $\\phi_n$ can be  reduced by taking  longer cycle times $t_f$. Regarding monotonicity and convexity of $J(u)$,\nlarger threshold $u$ results in smaller inventories and hence $J(u)$ is monotone non-increasing. However, we have\nno way of proving convexity or concavity of $J(u)$, hence we put the regulation algorithm to the test\nby simulation.\n\nIn the considered example, $V_{3}=6$, $V_{2,1}=2.15$, and $V_{2,2}=6$; these numbers are taken from\n\\cite{Wardi13b,Seatzu13}. The product-orders process $\\{V_{1}(t)\\}$, defined\nby\n(24), consists of equally-spaced arrivals every 50 seconds (deterministic), and each arrival\nbrings in an amount of fluid that is uniformly distributed in the $[30,70]$-range. The reference value to be tracked is\n$J_{{\\rm ref}}=758.70$, and it is the computed value of $J$ obtained for the aforementioned optimization problem in\n\\cite{Seatzu13}.\nThe IPA derivative $L^{\\prime}(\\theta)$ is computable via a recursive algorithm\nconstructed according to  the event-calculus framework defined in \\cite{Cassandras10,Wardi13b};  a detailed presentation thereof\ncan be found in \\cite{Seatzu13}.\n\nWe ran the regulation algorithm for 100 control cycles with $t_f=1,000$. The\nresults of two typical runs are shown in Figure 11 for two respective values of the initial control parameter,\n$u_{1}=35$ and $u_{1}=15$. The corresponding  graphs of $y_{n}:=L_{n}(u_{n})$ are plotted\nby the dashed curve and solid curve, and both indicate convergence to a band around $y_{{\\rm ref}}=758.70$ after 3 iterations.\nThis band has\na maximum range of 47.17, and the averages of the outputs $y_{n}$, taken over $n=20,\\ldots,100$, are 758.55 for the dashed plot,\nand 758.73 for the solid plot. Although these results indicate convergence of the outputs' average to $y_{{\\rm ref}}$, variations\nin the output values are discernable.  These variations, as well as those in the IPA derivatives, yield\n fluctuations in the values of $u_{n}$, $n=1,2,\\ldots$, as can be seen in Figure 12. We believe that the\n major cause of these variations is in the variance of $L(u)$ and   not inherent in the regulation\n algorithm. To test this point, we ran 100 independent simulations of the system at the fixed value of\n $u=24.8$, which is close to the\n average of $u_{n}$, $n=20,\\ldots,100$ obtained by the regulation algorithm. The results,\n $\\big\\{L(u)\\big\\}_{i}$, shown in Figure 13,\n indicate a persistent variation with a maximum range of 42, which is comparable to the range obtained from Figure 11.\n\n To further test the convergence rate of the regulation algorithm we chose more extreme starting values of the control\n parameter, namely $u_{1}=45$ and $u_{1}=5$. The corresponding values of $y_{1}$ are 635 and 883, which are more extreme\n than those obtained in Figure 11, but nonetheless the regulation algorithm converged to a similar band around $y_{{\\rm ref}}$\n in 3 iterations.\n\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_7.pdf}\n{\\small \\caption{Petri net - inventory. $t_{f}=1,000$, $n=1,\\ldots,100$}}\n\\end{figure}\n\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_8_2.pdf}\n{\\small \\caption{Petri net - threshold control.  $t_{f}=1,000$, $n=1,\\ldots,100$}}\n\\end{figure}\n\n\\vspace{.1in}\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure_9_2.pdf}\n{\\small \\caption{Variations in $L(u)$: 100 independent simulations}}\n\\end{figure}\n\n\n\\section{Application to throughput regulation in computer processors}\\label{sec:chip}\n\nThe problem of maintaining stable instruction execution rates in computer\nprocessors arises\nin several application areas. For instance, in real-time\napplications, guaranteeing a constant instruction execution rate\nsimplifies otherwise complex real-time scheduling tasks\nby enabling tighter bounds on deadlines to be met \\cite{Shakkottaia01}. Variable rate\ninstruction execution often leads to a reliance on worst case\nexecution-time estimates that far exceed the average execution\ntimes, resulting in a  poorer processor utilization than is\nnecessary.  A second application concerns a tradeoff between\ninstruction execution rate and power dissipation.   Dynamic Voltage\nFrequency Scaling (DVFS) can be used to navigate this tradeoff to\narrive at an instruction rate that is the most power-efficient~\\cite{c3}\\cite{c4}.  This approach, described in the\nIntroduction, was followed by~\\cite{Almoosa12a} for throughput regulation in\nprocessor cores. In this section we pursue a similar approach but use a\nmore-precise system-model for the throughput simulation and hence obtain\nbetter results, including far-faster convergence, as described in the sequel.\n\nWe consider a multiprogrammed multi-core processor where programs are\nassigned for execution to the cores by the operating system.  Each\ncore is assigned an instruction-execution rate setpoint by a\nsupervisory controller, and has to control (regulate) its instruction\nrate to that level.  In this paper we are not concerned with the way\nthese setpoint levels are assigned, and consider them as given and\nfixed.  Furthermore, we assume that each core is in a separate clock domain\nand can independently control its own clock rate.  Each core exploits\ninstruction-level parallelism (ILP) utilizing an Out-of-Order (OOO)\ntechnology whereby instructions may complete execution in an order different\nfrom program order (i.e., out of order). OOO execution enables\ninstruction execution to be limited only by data dependencies rather than\nthe order in which they appear in the program thereby serving as the\nprimary means for exploiting ILP in modern processors.\n\n\nA high-level functional and logical description of programs' execution in an OOO core is depicted in Figure 14.\nInstructions are fetched sequentially from memory and placed in the Instruction queue. There they are processed by\nfunctional units which can be thought of as servers in the queueing parlance.  It is often the case\nthat there are enough functional units available for concurrent execution of all of the instructions\nin the queue. What holds up the execution of an instruction is its dependency on data that would become\navailable from the execution of another instruction. For example, the instruction of adding two variables, $x$ and $y$,\nrequires that both variables have numerical values. $x$ may be obtained from another numerical instruction,\nwhile $y$ may be fetched from memory. Thus, it is evident that the addition of $x$ and $y$ cannot commence before the\ninstructions of computing $x$ and fetching $y$ are completed.\n\nInstructions can be classified as {\\it data dependent} vs. {\\it data independent} according to whether\nthey depend on data provided by the execution of other instructions. If an instruction is data dependent then\nits execution can commence as soon as all such data and a functional unit become available. If the instruction\nis data independent then its execution can start as soon as a functional unit is available.\n\nMemory instructions can take one-to-two orders of magnitude more time to execute than computational\ninstructions. Therefore most architectures make use of a hierarchical memory\narrangement where on-chip cache access takes less time than external memory such as DRAM. First the cache is searched,\nand if the variable is found there then it is fetched and the instruction is completed. If the variable\nis not stored in cache then a cache miss occurs and a cache line\n(containing the variable) is fetched from external memory\n(typically DRAM) and placed in the cache. The variable is then\naccessed and the instruction is completed. We can\nthink of all external-memory (non-cache) accesses as placed in a\nFirst-in-First-out queue designated by the {\\it Memory} box in the\nfigure. Furthermore, this queue has a finite buffer, and when it becomes\nfull the entire memory access, including from the cache, is stalled.\n\nDuring its processing the instruction is still stored in the Instruction queue, where it has been placed since its\narrival at the start of the aforementioned process. Although it may be executed concurrently with other instructions\nsubject to data-dependency constraints, it may not be released from the queue upon completion of its execution; in fact, its\nrelease time is the later of its completion time and the release time of the previous instruction. However, the variables it computes\nbecome available to other instructions upon its completion and not release. We point out that the term {\\it release} used here\nis called {\\it commitment} in the parlance of computer architectures. It is this quantity that is used to compute the instruction's throughput, as\nwill be made clear in the sequel.\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.95\\textwidth]{Figure_logic.pdf}\n{\\small \\caption{Functional description of OOO processing}}\n\\end{figure}\n\nA high-level\ndescription of the hardware  of an\nOOO core is depicted in Figure 15 (see~\\cite{c5} for a more detailed\ndescription). The acronyms in the various blocks indicate the\nfollowing entities: IQ - Instruction Queue; ROB - Reorder Buffer; RS -\nReservation Station; FU - Functional Unit; RF - Register File;\nL/S~Q - Load/Store Queue; MSHR - Miss Status\nHandling Register; and MEM - memory other than cache, typically DRAM.\nDuring a program's execution, the instruction unit of the processor fetches\nprogram instructions sequentially from memory and places them in the\nInstruction Queue (IQ). Instructions are issued from the IQ to a\nreservation station waiting for access to the corresponding functional\nunit. An instruction is granted access  (starts processing) after (i)  all its operands are available, for\nexample, the result from  preceding instructions, and (ii) the\nfunctional unit is available. When an instruction\nis issued to an RS, it is also allocated an entry in the ROB in the original program\norder.\n\nInstructions in the RS are issued to the functional units when their\noperands are available (note that this issue order may be different from\nprogram order hence the OOO designation). While the instruction is\nwaiting for its operands, it is said to be {\\em stalled}. Instruction\nexecution results are broadcast to all reservation stations and the\nROB - they are stored along with the instruction's entry in the\nROB. When an instruction reaches the head of the ROB and it has\ncompleted execution, its result is placed in the RF. This\nprocess is called {\\em instruction committment (IC)}. The {\\it IC}\nstage basically signifies the termination of the instruction processing. Note that\nwhile instructions may complete execution out of order, they are\ncommitted in program order. For the purpose of this discussion and its\nrelated model, we can view the IQ and ROB as a single block where\ninstructions are buffered in order according to their issue (arrival)\norder from the instruction fetch unit of the processor.\n\n\n\n\n\n\\begin{figure}[h]\n\\centering\n\\includegraphics[width=0.65\\textwidth]{Figure11y.pdf}\n{\\small \\caption{High-level OOO architecture}}\n\\end{figure}\n\n\n\n\n\n\n{\\it Memory} instructions such as load and store instructions are\ndirected to the Load/Store Queue (L/SQ) shown in Figure 15. Consider\nthe execution of a load instruction. First an attempt is made to\naccess the data from the data cache. If that is successful (cache\nhit), the data is read from the cache line and sent to the\ncorresponding instruction entry in ROB.  If the requested data is not\nin the cache (cache miss) it has to be fetched from the next level of\nthe memory hierarchy, for example main memory, typically DRAM.  In that case a request is sent to the Miss Status\nHandling Register (MSHR), which serves as a finite-buffer queue for\nbuffering outstanding non-cache memory access requests.  When the MSHR\nis full all new instructions that generate memory-accesses are\nstalled.  Upon completion of the memory access, the data is sent to\nthe ROB and the instruction clears the MSHR.  Note that the MSHR is a\nfinite-buffer queue that holds only non-cache memory instructions. However,\nwhen it becomes full, it halts all new memory access requests, and thus\n comprises a fairly nonstandard queueing model.\n\n\nTo quantify all of this (see also \\cite{Chen15}), consider a control cycle comprised of\ninstructions $I_{i}$, $i=1,\\ldots,M$ for a given $M>0$.  Let us set\nthe time to $t=0$ at the moment the first instruction is issued.  In\nthe framework of the closed-loop system defined by the regulation algorithm,\nthe control variable $u$ will be the clock frequency (rate) of\nthe core, but it is easier to carry out the IPA computations in terms\nof the clock cycle, $\\tau:=u^{-1}$.\n\nFor instruction $I_{i}$, define  $\\xi_{i}$ to be its issue time in terms  of clock cycles (counting from the issue time of\n$I_{1}$); $\\alpha_{i}(\\tau)$  - its execution starting time (in seconds), and\n$\\beta_{i}(\\tau)$ - its completion time (in seconds), not to be confused with its commit\ntime which may occur later. Note that we use two kinds of timing variables, namely  in units of clock cycles or seconds. The  former can be measured  in real time for the purpose of the control law,\n while the latter\nare used only in the analysis.\n\nConsider first the case where   $I_{i}$ is not a memory instruction; memory instructions will be\nhandled later.\nThe issue time  of $I_{i}$ (in seconds) is $\\xi_{i}\\tau$, and we assume that there are available resources in the\nROB and RS so that the instruction is forwarded there at the same time,\n$\\xi_{i}\\tau$.  If $I_{i}$ is data dependent,\ndenote by $k(i)$ the index (counter) of the instruction which is the last to provide a variable to $I_{i}$.\nThen, we have that\n\n", "index": 59, "text": "\\begin{equation}\n\\alpha_{i}(\\tau)=\\left\\{\n\\begin{array}{ll}\n\\max\\big\\{\\xi_{i}\\tau,\\beta_{k(i)}(\\tau)\\big\\}+\\tau, & {\\rm if}\\ I_{i}\\ {\\rm is\\ data\\ dependent}\\\\\n\\xi_{i}\\tau+\\tau, & {\\rm otherwise}.\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"\\alpha_{i}(\\tau)=\\left\\{\\begin{array}[]{ll}\\max\\big{\\{}\\xi_{i}\\tau,\\beta_{k(i)%&#10;}(\\tau)\\big{\\}}+\\tau,&amp;{\\rm if}\\ I_{i}\\ {\\rm is\\ data\\ dependent}\\\\&#10;\\xi_{i}\\tau+\\tau,&amp;{\\rm otherwise}.\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><msub><mi>\u03be</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>,</mo><mrow><msub><mi>\u03b2</mi><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow><mo>+</mo><mi>\u03c4</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>data</mi></mpadded><mo>\u2062</mo><mi>dependent</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msub><mi>\u03be</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>+</mo><mi>\u03c4</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>otherwise</mi><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nConsider next the case where $I_{i}$ is a memory instruction. Upon its issuance at time $\\xi_{i}\\tau$ it is\ndirected to the L/SQ where a cache attempt is made. Let us regard the starting time of the cache attempt as\nthe starting time of the instruction's execution at the memory stage,\nand  denote it by $\\alpha_{i}(\\tau)$. If the MSHR is full at time $\\xi_{i}\\tau$, let $\\ell(i)$ denote the\nindex of the instruction at the head of the MSHR. Then,\n\n", "itemtype": "equation", "pos": 59831, "prevtext": "\nAs for the completion time, let\n$\\mu_{i}$ denote the execution time of $I_{i}$ in terms of clock cycles. Then,\n\n", "index": 61, "text": "\\begin{equation}\n\\beta_{i}(\\tau)=\\alpha_{i}(\\tau)+\\mu_{i}\\tau.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}(\\tau)=\\alpha_{i}(\\tau)+\\mu_{i}\\tau.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>\u03bc</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nLet $\\nu_{i}$ denote the time (in units of clock cycles) it takes the L/SQ to process $I_{i}$\nincluding the cache attempt. If the cache attempt result is successful (cache hit), then\n\n", "itemtype": "equation", "pos": 60357, "prevtext": "\nConsider next the case where $I_{i}$ is a memory instruction. Upon its issuance at time $\\xi_{i}\\tau$ it is\ndirected to the L/SQ where a cache attempt is made. Let us regard the starting time of the cache attempt as\nthe starting time of the instruction's execution at the memory stage,\nand  denote it by $\\alpha_{i}(\\tau)$. If the MSHR is full at time $\\xi_{i}\\tau$, let $\\ell(i)$ denote the\nindex of the instruction at the head of the MSHR. Then,\n\n", "index": 63, "text": "\\begin{equation}\n\\alpha_{i}(\\tau)=\\left\\{\n\\begin{array}{ll}\n\\xi_{i}\\tau+\\tau, & {\\rm if\\ MSHR\\ is\\ not\\ full\\ at\\ time}\\ \\xi_{i}\\tau\\\\\n\\beta_{\\ell(i)}(\\tau)+\\tau, & {\\rm if\\ MSHR\\ is\\ full\\ at\\ time}\\ \\xi_{i}\\tau.\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"\\alpha_{i}(\\tau)=\\left\\{\\begin{array}[]{ll}\\xi_{i}\\tau+\\tau,&amp;{\\rm if\\ MSHR\\ is%&#10;\\ not\\ full\\ at\\ time}\\ \\xi_{i}\\tau\\\\&#10;\\beta_{\\ell(i)}(\\tau)+\\tau,&amp;{\\rm if\\ MSHR\\ is\\ full\\ at\\ time}\\ \\xi_{i}\\tau.%&#10;\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msub><mi>\u03be</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>+</mo><mi>\u03c4</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>MSHR</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>not</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>full</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>at</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>time</mi></mpadded><mo>\u2062</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03c4</mi></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>MSHR</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>full</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>at</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>time</mi></mpadded><mo>\u2062</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nOn the other hand, in case of a cache miss, the instruction is directed to the MSHR for non-cache memory access.\nLet $m_{i}$ denote the processing time of\n the instruction in the MSHR in units of clock cycles, and let\n$MEM_{i}$ be the time it takes to access the memory.  Note that DRAM access is not governed by the core's clock  and hence it is not a function of $\\tau$. Let $j(i)$ denote the index of the instruction prior to $I_{i}$   in the MSHR.\nThen, the completion time\nof $I_{i}$ is given by\n\n", "itemtype": "equation", "pos": 60789, "prevtext": "\nLet $\\nu_{i}$ denote the time (in units of clock cycles) it takes the L/SQ to process $I_{i}$\nincluding the cache attempt. If the cache attempt result is successful (cache hit), then\n\n", "index": 65, "text": "\\begin{equation}\n\\beta_{i}(\\tau)=\\alpha_{i}(\\tau)+\\nu_{i}\\tau.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}(\\tau)=\\alpha_{i}(\\tau)+\\nu_{i}\\tau.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>\u03bd</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nFinally, the commit (departure) times of instructions $I_{i}$, $i=1,2,\\ldots$, denoted by $d_{i}(\\tau)$, are\ngiven by the following recursive equation,\n\n", "itemtype": "equation", "pos": 61368, "prevtext": "\nOn the other hand, in case of a cache miss, the instruction is directed to the MSHR for non-cache memory access.\nLet $m_{i}$ denote the processing time of\n the instruction in the MSHR in units of clock cycles, and let\n$MEM_{i}$ be the time it takes to access the memory.  Note that DRAM access is not governed by the core's clock  and hence it is not a function of $\\tau$. Let $j(i)$ denote the index of the instruction prior to $I_{i}$   in the MSHR.\nThen, the completion time\nof $I_{i}$ is given by\n\n", "index": 67, "text": "\\begin{equation}\n\\beta_{i}(\\tau)=\\max\\big\\{\\alpha_{i}(\\tau)+\\nu_{i}\\tau+m_{i}\\tau+MEM_{i},\\beta_{j(i)}(\\tau)+\\tau\\big\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}(\\tau)=\\max\\big{\\{}\\alpha_{i}(\\tau)+\\nu_{i}\\tau+m_{i}\\tau+MEM_{i},%&#10;\\beta_{j(i)}(\\tau)+\\tau\\big{\\}}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><mrow><msub><mi>\u03b1</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>\u03bd</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>+</mo><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>\u2062</mo><mi>\u03c4</mi></mrow><mo>+</mo><mrow><mi>M</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><msub><mi>M</mi><mi>i</mi></msub></mrow></mrow><mo>,</mo><mrow><mrow><msub><mi>\u03b2</mi><mrow><mi>j</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mi>\u03c4</mi></mrow><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\nNow recall that the control cycle consists of $M$ instructions, and define the\naverage throughput by\n\n", "itemtype": "equation", "pos": 61656, "prevtext": "\nFinally, the commit (departure) times of instructions $I_{i}$, $i=1,2,\\ldots$, denoted by $d_{i}(\\tau)$, are\ngiven by the following recursive equation,\n\n", "index": 69, "text": "\\begin{equation}\nd_{i}(\\tau)=\\max\\big\\{\\beta_{i}(\\tau),d_{i-1}(\\tau)\\big\\}+\\tau.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"d_{i}(\\tau)=\\max\\big{\\{}\\beta_{i}(\\tau),d_{i-1}(\\tau)\\big{\\}}+\\tau.\" display=\"block\"><mrow><mrow><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><msub><mi>\u03b2</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>d</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow><mo>+</mo><mi>\u03c4</mi></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nWith $u=\\tau^{-1}$, its IPA derivative  is\n\n", "itemtype": "equation", "pos": 61854, "prevtext": "\n\nNow recall that the control cycle consists of $M$ instructions, and define the\naverage throughput by\n\n", "index": 71, "text": "\\begin{equation}\ny:=L(u)=\\frac{M}{d_{M}(u)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"y:=L(u)=\\frac{M}{d_{M}(u)}.\" display=\"block\"><mrow><mrow><mi>y</mi><mo>:=</mo><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mi>M</mi><mrow><msub><mi>d</mi><mi>M</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nwhere we assume  that the throughput $y=L(u)$ can be  computed from the system.\nThe IPA term $d_{M}^{\\prime}(\\tau)$ is computable  in a recursive manner  as follows. By Equations (27)--(32),\nfor every\n$i=1,\\ldots,M$: If $I_{i}$ is not a memory  instruction, then\n\n", "itemtype": "equation", "pos": 61957, "prevtext": "\nWith $u=\\tau^{-1}$, its IPA derivative  is\n\n", "index": 73, "text": "\\begin{equation}\nL^{\\prime}(u)=\\frac{1}{M}\\Big(\\frac{y}{u}\\Big)^2d_{M}^{\\prime}(\\tau),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m1\" class=\"ltx_Math\" alttext=\"L^{\\prime}(u)=\\frac{1}{M}\\Big{(}\\frac{y}{u}\\Big{)}^{2}d_{M}^{\\prime}(\\tau),\" display=\"block\"><mrow><mrow><mrow><msup><mi>L</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><msup><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mfrac><mi>y</mi><mi>u</mi></mfrac><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi>d</mi><mi>M</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nand\n\n", "itemtype": "equation", "pos": 62322, "prevtext": "\nwhere we assume  that the throughput $y=L(u)$ can be  computed from the system.\nThe IPA term $d_{M}^{\\prime}(\\tau)$ is computable  in a recursive manner  as follows. By Equations (27)--(32),\nfor every\n$i=1,\\ldots,M$: If $I_{i}$ is not a memory  instruction, then\n\n", "index": 75, "text": "\\begin{equation}\n\\alpha_{i}^{\\prime}(\\tau)=\\left\\{\\begin{array}{ll}\n\\beta_{k(i)}^{\\prime}(\\tau)+1, & {\\rm if}\\ I_{i}\\ {\\rm is\\ stalled\\ due\\ to\\ data\\ dependency}\\\\\n\\xi_{i}+1, & {\\rm otherwise},\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35.m1\" class=\"ltx_Math\" alttext=\"\\alpha_{i}^{\\prime}(\\tau)=\\left\\{\\begin{array}[]{ll}\\beta_{k(i)}^{\\prime}(\\tau%&#10;)+1,&amp;{\\rm if}\\ I_{i}\\ {\\rm is\\ stalled\\ due\\ to\\ data\\ dependency}\\\\&#10;\\xi_{i}+1,&amp;{\\rm otherwise},\\end{array}\\right.\" display=\"block\"><mrow><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msubsup><mi>\u03b2</mi><mrow><mi>k</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>stalled</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>due</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>to</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>data</mi></mpadded><mo>\u2062</mo><mi>dependency</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi>\u03be</mi><mi>i</mi></msub><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>otherwise</mi><mo>,</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nOn the other hand, if $I_{i}$ is a memory instruction, then\n\n", "itemtype": "equation", "pos": 62556, "prevtext": "\nand\n\n", "index": 77, "text": "\\begin{equation}\n\\beta_{i}^{\\prime}(\\tau)=\\alpha_{i}^{\\prime}(\\tau)+\\mu_{i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}^{\\prime}(\\tau)=\\alpha_{i}^{\\prime}(\\tau)+\\mu_{i}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>\u03b2</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03bc</mi><mi>i</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nas for $\\beta_{i}^{\\prime}(\\tau)$, if $I_{i}$ results in a cache hit, then\n\n", "itemtype": "equation", "pos": 62708, "prevtext": "\nOn the other hand, if $I_{i}$ is a memory instruction, then\n\n", "index": 79, "text": "\\begin{equation}\n\\alpha_{i}^{\\prime}(\\tau)=\\left\\{\n\\begin{array}{ll}\n\\beta_{\\ell(i)}^{\\prime}(\\tau)+1, & {\\rm if}\\ I_{i}\\ {\\rm is\\ stalled\\ due\\ to\\ full\\ MSHR}\\\\\n\\xi_{i}+1, & {\\rm otherwise};\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"\\alpha_{i}^{\\prime}(\\tau)=\\left\\{\\begin{array}[]{ll}\\beta_{\\ell(i)}^{\\prime}(%&#10;\\tau)+1,&amp;{\\rm if}\\ I_{i}\\ {\\rm is\\ stalled\\ due\\ to\\ full\\ MSHR}\\\\&#10;\\xi_{i}+1,&amp;{\\rm otherwise};\\end{array}\\right.\" display=\"block\"><mrow><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msubsup><mi>\u03b2</mi><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>stalled</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>due</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>to</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>full</mi></mpadded><mo>\u2062</mo><mi>MSHR</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><msub><mi>\u03be</mi><mi>i</mi></msub><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>otherwise</mi><mo>;</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nand in the event of a cache miss,\n\n", "itemtype": "equation", "pos": 63011, "prevtext": "\nas for $\\beta_{i}^{\\prime}(\\tau)$, if $I_{i}$ results in a cache hit, then\n\n", "index": 81, "text": "\\begin{equation}\n\\beta_{i}^{\\prime}(\\tau)=\\alpha_{i}^{\\prime}(\\tau)+\\nu_{i},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}^{\\prime}(\\tau)=\\alpha_{i}^{\\prime}(\\tau)+\\nu_{i},\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>\u03b2</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03bd</mi><mi>i</mi></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nIt is reasonable to assume  that the quantities $\\xi_{i}$, $\\mu_{i}$, $\\nu_{i}$, and $m_{i}$ can be read from the system in real time\nduring instruction execution,\n and hence the computation of $\\beta_{i}^{\\prime}(\\tau)$, $i=1,\\ldots,$ can be performed in\nreal time in\na recursive fashion via Equations (35)-(39).\nFinally, by (32),\n\n", "itemtype": "equation", "pos": 63137, "prevtext": "\nand in the event of a cache miss,\n\n", "index": 83, "text": "\\begin{equation}\n\\beta_{i}^{\\prime}(\\tau)=\\left\\{\n\\begin{array}{ll}\n\\alpha_{i}^{\\prime}(\\tau)\n+\\nu_{i}+m_{i}, & {\\rm if}\\ I_{i}\\ {\\rm is\\ first\\ in\\ the\\ MSHR\\ queue\\ by\\ the\\ time}\\\\\n & {\\rm its\\ variable\\ is\\ read\\ from\\ memory}\\\\\n\\beta_{j(i)}(\\tau)+1, & {\\rm otherwise}.\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m1\" class=\"ltx_Math\" alttext=\"\\beta_{i}^{\\prime}(\\tau)=\\left\\{\\begin{array}[]{ll}\\alpha_{i}^{\\prime}(\\tau)+%&#10;\\nu_{i}+m_{i},&amp;{\\rm if}\\ I_{i}\\ {\\rm is\\ first\\ in\\ the\\ MSHR\\ queue\\ by\\ the%&#10;\\ time}\\\\&#10;&amp;{\\rm its\\ variable\\ is\\ read\\ from\\ memory}\\\\&#10;\\beta_{j(i)}(\\tau)+1,&amp;{\\rm otherwise}.\\end{array}\\right.\" display=\"block\"><mrow><mrow><msubsup><mi>\u03b2</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03bd</mi><mi>i</mi></msub><mo>+</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>first</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>in</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>the</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>MSHR</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>queue</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>by</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>the</mi></mpadded><mo>\u2062</mo><mi>time</mi></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>its</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>variable</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>read</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>from</mi></mpadded><mo>\u2062</mo><mi>memory</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mrow><mi>j</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mi>otherwise</mi><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nThis yields $d_{M}^{\\prime}(\\tau)$, and hence  $L^{\\prime}(u)$ via Equation (34).\n\nWe point out that this IPA derivative is biased due to the fact that\nthe DRAM and other non-cache memory accesses are not controlled by the\ncore's clock - the memory system is in a different clock\ndomain. We note that the  time required for such memory access  typically is one order\nof magnitude longer than  a cache-access time and can be two orders of\nmagnitude longer than computing  instructions. Therefore\nwe expect the regulation technique to perform better when applied to\ncomputation-intensive programs rather than to memory-intensive programs.  This is evident\nfrom the simulation results which will be presented in the following paragraphs.\n\nWe implemented the control algorithm  using Manifold,\na cycle-level, full system discrete event simulation platform for\nmulti-core architectures~\\cite{Yalamanchili}. A Manifold model boots a Linux\noperating system and executes stock 32-bit x86 binaries.  Our\nexperiments were applied to two programs from the SPLASH-2 suite of\nbenchmark programs~\\cite{c11}, {\\it Barnes} and {\\it\n  Radiosity}. Barnes is compute intensive while Radiosity is memory\nintensive. For both cases the Manifold processor model used is similar\nto the Intel Nehalem micro-architecture comprised of four cores, each\nhaving its own L1 cache and sharing an L2 cache \\cite{Thomadakis11}. Each core is in a\nseparate clock domain that is independently controlled. At the start of\nthe simulation the application is emulated   for\na million instructions (out of an order of   $10^{12}$\ninstructions)\nin\norder to warm up the architecture state. At this point, cycle-level\ntiming simulation is begun over program regions of interest.\n\nThe control cycle for each core consists of $M=10,000$ instructions.\nThus, for a given core, the control variable during the $nth$ cycle is\n$u_n$, and $y_n$ is the instruction throughput computed at the end of the cycle\nvia Eq. (33) (with the index $n$ added). The IPA  derivative is computed via Eq. (34).\nIt is not unbiased since the sample-performance function $L(u)$ is not necessarily continuous.\nThis is\nlargely due to the\n possibility of instruction stalls when the MSHR queue becomes full; see \\cite{Ho91} for the relation between discontinuous\n sample performance functions and the biasedness of IPA. However, we believe that the error introduced by the bias generally is not\n large enough to prevent convergence of the regulation algorithm. Therefore, in contrast with the\n case of the finite-buffer queue discussed in Section 3.2, we do not resort to a fluid queueing model but rather compute the IPA derivatives directly from the discrete model according to Eqs. (34)~-~(40).\n\nIn the simulation experiments we took the target\n instruction rates (setpoints) for Cores 0-3 to be  1.0 Giga\nInstruction Per Second (GIPS), 1.5 $GIPS$, 2.0 $GIPS$, and 2.5 $GIPS$,\nrespectively. Figure 16 shows simulation results for the benchmark\n {\\it Barnes} executing at all four cores, and they indicate convergence-times of the\nalgorithm between 0.02 $ms$ (Core 3) and 0.08 $ms$ (Core\n2).\\footnote{Using a cruder model, Reference \\cite{Almoosa12a} reports\n  convergence in about 1 ms.}  The apparent oscillations after\nconvergence are due to variations in the programs' instruction loads, and their\nmagnitudes are within 10\\% of the respective target values. However,\nthe average instruction rates from time 0.1 ms to the final time (0.25\nms) are 0.9998, 1.5025, 1.9997, and 2.4985, which are within 0.2 \\% of the respective   target\nvalues.\n\n  \\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure12x.pdf}\n\t{\\small \\caption{Instruction rate regulation: {\\it Barnes}}}\n\t\\label{fig:fig12}\n\\end{figure}\n\n\n\nFor the Radiosity benchmark we set the target instruction rates  for Cores 0-3\nto 1.0 $GIPS$, 1.3 $GIPS$, 1.5 $GIPS$, and 1.7 $GIPS$, respectively.\nTypical results are shown in Figure 17, where we discern convergence\ntimes between 0.12 $ms$ to 0.14 $ms$, with subsequent oscillations\nbelow 15\\% of the respective target values.  The slower convergence as\ncompared to Barnes is due to the fact that Radiosity is more memory\nintensive.\n\n\n\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure13x.pdf}\n\t{\\small \\caption{Instruction rate regulation: {\\it Radiosity}}}\n\t\\label{fig:fig13}\n\\end{figure}\n\nOne way to reduce the oscillations is to scale the integrator's gain\nin Equation (1) by a constant $k\\in(0,1)$, thereby replacing (1) by\nthe following equation,\n\n", "itemtype": "equation", "pos": 63778, "prevtext": "\nIt is reasonable to assume  that the quantities $\\xi_{i}$, $\\mu_{i}$, $\\nu_{i}$, and $m_{i}$ can be read from the system in real time\nduring instruction execution,\n and hence the computation of $\\beta_{i}^{\\prime}(\\tau)$, $i=1,\\ldots,$ can be performed in\nreal time in\na recursive fashion via Equations (35)-(39).\nFinally, by (32),\n\n", "index": 85, "text": "\\begin{equation}\nd_{i}^{\\prime}(\\tau)=\\left\\{\n\\begin{array}{ll}\nd_{i-1}^{\\prime}(\\tau)+1, & {\\rm if}\\ I_{i}\\ {\\rm is\\ stalled\\ in\\ ROB\\ following\\ its\\ execution}\\\\\n\\beta_{i}^{\\prime}(\\tau)+1, & {\\rm if}\\ I_{i}\\ {\\rm is\\ comitted\\ right\\ after\\ its\\ execution.}\n\\end{array}\n\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E40.m1\" class=\"ltx_Math\" alttext=\"d_{i}^{\\prime}(\\tau)=\\left\\{\\begin{array}[]{ll}d_{i-1}^{\\prime}(\\tau)+1,&amp;{\\rm&#10;if%&#10;}\\ I_{i}\\ {\\rm is\\ stalled\\ in\\ ROB\\ following\\ its\\ execution}\\\\&#10;\\beta_{i}^{\\prime}(\\tau)+1,&amp;{\\rm if}\\ I_{i}\\ {\\rm is\\ comitted\\ right\\ after\\ %&#10;its\\ execution.}\\end{array}\\right.\" display=\"block\"><mrow><mrow><msubsup><mi>d</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msubsup><mi>d</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>stalled</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>in</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>ROB</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>following</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>its</mi></mpadded><mo>\u2062</mo><mi>execution</mi></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mrow><mrow><msubsup><mi>\u03b2</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mn>1</mn></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mpadded width=\"+5pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><msub><mi>I</mi><mi>i</mi></msub></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>comitted</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>right</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>after</mi></mpadded><mo>\u2062</mo><mpadded width=\"+5pt\"><mi>its</mi></mpadded><mo>\u2062</mo><mi>execution</mi></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nAfter some experimentation we chose $k=0.2$. This resulted  in  reductions\nin the oscilations' magnitudes  from 10\\% to 5\\% for Barnes, and  from 15\\% to 10\\%\nfor radiosity. The results are shown in Figures 18 and\n19, respectively.\n\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure14x.pdf}\n\t{\\small \\caption{Instruction rate regulation (modified algorithm): {\\it Barnes}}}\n\t\\label{fig:fig14}\n\\end{figure}\n\n\n\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure15x.pdf}\n\t{\\small \\caption{Instruction rate regulation (modified algorithm): {\\it Radiosity}}}\n\t\\label{fig:fig15}\n\\end{figure}\n\n\n\\section{Conclusions}\nThis paper describes an IPA-based approach to performance regulation in stochastic timed discrete event dynamic systems.\nThe considered problem is to control the output of the system so as to have it track (asymptotically) a given\nperformance reference\nin the face of variations in the system's characteristics. The proposed approach is based on\nan integrator with adaptive gain. The system's plant is represented via a discrete-event or hybrid model, and the controller's gain is inverse proportional\nto the IPA derivative of its plant function with respect to the control parameter.\n\nThe paper summarizes the regulation technique and presents several examples, which highlight the fact that it can\nwork  well despite  errors in estimating  the IPA gradient.  The examples include delay and loss in a single queue, inventory control in a Petri-net model of\na production system, and throughput regulation in a computer core. Extensions and future investigations will\nfocus on emerging problems in  various application  areas.\n\n\\section{Appendix}\nThis section provides proofs to Lemma 2.2 and Proposition 2.3.\\\\ \\\\\n{\\bf Proof of Lemma 2.2.} Consider a closed, finite-length interval $I$ where $g(\\cdot)$ is monotone-nondecreasing and convex throughout $I$. We next prove the assertion of the lemma for this case, while the situations where\n $g(\\cdot)$ is monotone-non-increasing or concave can be analyzed by similar arguments and hence their proofs are omitted.\n\n By the monotonicity of $g(\\cdot)$ we have that\n $g^{\\prime}(u)\\geq 0~\\forall u\\in I$, and we will use this fact throughout the forthcoming analysis.\n By convexity of $g(\\cdot)$  we have the following inequalities for every $u\\in I$ and $\\Delta u\\in R$ such that\n $u+\\Delta u\\in I$:\n \n", "itemtype": "equation", "pos": 68621, "prevtext": "\nThis yields $d_{M}^{\\prime}(\\tau)$, and hence  $L^{\\prime}(u)$ via Equation (34).\n\nWe point out that this IPA derivative is biased due to the fact that\nthe DRAM and other non-cache memory accesses are not controlled by the\ncore's clock - the memory system is in a different clock\ndomain. We note that the  time required for such memory access  typically is one order\nof magnitude longer than  a cache-access time and can be two orders of\nmagnitude longer than computing  instructions. Therefore\nwe expect the regulation technique to perform better when applied to\ncomputation-intensive programs rather than to memory-intensive programs.  This is evident\nfrom the simulation results which will be presented in the following paragraphs.\n\nWe implemented the control algorithm  using Manifold,\na cycle-level, full system discrete event simulation platform for\nmulti-core architectures~\\cite{Yalamanchili}. A Manifold model boots a Linux\noperating system and executes stock 32-bit x86 binaries.  Our\nexperiments were applied to two programs from the SPLASH-2 suite of\nbenchmark programs~\\cite{c11}, {\\it Barnes} and {\\it\n  Radiosity}. Barnes is compute intensive while Radiosity is memory\nintensive. For both cases the Manifold processor model used is similar\nto the Intel Nehalem micro-architecture comprised of four cores, each\nhaving its own L1 cache and sharing an L2 cache \\cite{Thomadakis11}. Each core is in a\nseparate clock domain that is independently controlled. At the start of\nthe simulation the application is emulated   for\na million instructions (out of an order of   $10^{12}$\ninstructions)\nin\norder to warm up the architecture state. At this point, cycle-level\ntiming simulation is begun over program regions of interest.\n\nThe control cycle for each core consists of $M=10,000$ instructions.\nThus, for a given core, the control variable during the $nth$ cycle is\n$u_n$, and $y_n$ is the instruction throughput computed at the end of the cycle\nvia Eq. (33) (with the index $n$ added). The IPA  derivative is computed via Eq. (34).\nIt is not unbiased since the sample-performance function $L(u)$ is not necessarily continuous.\nThis is\nlargely due to the\n possibility of instruction stalls when the MSHR queue becomes full; see \\cite{Ho91} for the relation between discontinuous\n sample performance functions and the biasedness of IPA. However, we believe that the error introduced by the bias generally is not\n large enough to prevent convergence of the regulation algorithm. Therefore, in contrast with the\n case of the finite-buffer queue discussed in Section 3.2, we do not resort to a fluid queueing model but rather compute the IPA derivatives directly from the discrete model according to Eqs. (34)~-~(40).\n\nIn the simulation experiments we took the target\n instruction rates (setpoints) for Cores 0-3 to be  1.0 Giga\nInstruction Per Second (GIPS), 1.5 $GIPS$, 2.0 $GIPS$, and 2.5 $GIPS$,\nrespectively. Figure 16 shows simulation results for the benchmark\n {\\it Barnes} executing at all four cores, and they indicate convergence-times of the\nalgorithm between 0.02 $ms$ (Core 3) and 0.08 $ms$ (Core\n2).\\footnote{Using a cruder model, Reference \\cite{Almoosa12a} reports\n  convergence in about 1 ms.}  The apparent oscillations after\nconvergence are due to variations in the programs' instruction loads, and their\nmagnitudes are within 10\\% of the respective target values. However,\nthe average instruction rates from time 0.1 ms to the final time (0.25\nms) are 0.9998, 1.5025, 1.9997, and 2.4985, which are within 0.2 \\% of the respective   target\nvalues.\n\n  \\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure12x.pdf}\n\t{\\small \\caption{Instruction rate regulation: {\\it Barnes}}}\n\t\\label{fig:fig12}\n\\end{figure}\n\n\n\nFor the Radiosity benchmark we set the target instruction rates  for Cores 0-3\nto 1.0 $GIPS$, 1.3 $GIPS$, 1.5 $GIPS$, and 1.7 $GIPS$, respectively.\nTypical results are shown in Figure 17, where we discern convergence\ntimes between 0.12 $ms$ to 0.14 $ms$, with subsequent oscillations\nbelow 15\\% of the respective target values.  The slower convergence as\ncompared to Barnes is due to the fact that Radiosity is more memory\nintensive.\n\n\n\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure13x.pdf}\n\t{\\small \\caption{Instruction rate regulation: {\\it Radiosity}}}\n\t\\label{fig:fig13}\n\\end{figure}\n\nOne way to reduce the oscillations is to scale the integrator's gain\nin Equation (1) by a constant $k\\in(0,1)$, thereby replacing (1) by\nthe following equation,\n\n", "index": 87, "text": "\\begin{equation}\nu_{n}=u_{n-1}+kA_{n}e_{n-1}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E41.m1\" class=\"ltx_Math\" alttext=\"u_{n}=u_{n-1}+kA_{n}e_{n-1}.\" display=\"block\"><mrow><mrow><msub><mi>u</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><mi>k</mi><mo>\u2062</mo><msub><mi>A</mi><mi>n</mi></msub><mo>\u2062</mo><msub><mi>e</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n Given  $M\\geq 1$, $\\beta\\in(0,1)$, and $\\alpha\\in(0,1)$, suppose that, for some $j=1,\\ldots$,  $u_{j-1}\\in I$,\n ${\\cal E}_{j-1}<\\alpha$, and  ${\\cal G}_{j-1}<\\beta$.\n We next derive upper bounds on the ratio $|g(u_{j}|/|g(u_{j-1})|$ (for the case where $g(u_{j-1})\\neq 0$)  in terms of $M$, $\\beta$, and $\\alpha$. The\n analysis concerns four separate cases: (i) $g(u_{j-1})\\leq 0$ and $g(u_{j})\\leq 0$; (ii)  $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$;\n (iii) $g(u_{j-1})\\geq 0$ and $g(u_{j})\\leq 0$; and (iv) $g(u_{j-1})\\geq 0$ and $g(u_{j})\\geq 0$.\n The results, to be derived in the following paragraph, are:\n \\begin{itemize}\n \\item\n Case (i):\n \n", "itemtype": "equation", "pos": 71116, "prevtext": "\nAfter some experimentation we chose $k=0.2$. This resulted  in  reductions\nin the oscilations' magnitudes  from 10\\% to 5\\% for Barnes, and  from 15\\% to 10\\%\nfor radiosity. The results are shown in Figures 18 and\n19, respectively.\n\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure14x.pdf}\n\t{\\small \\caption{Instruction rate regulation (modified algorithm): {\\it Barnes}}}\n\t\\label{fig:fig14}\n\\end{figure}\n\n\n\n\n\\vspace{.2in}\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=1\\textwidth]{Figure15x.pdf}\n\t{\\small \\caption{Instruction rate regulation (modified algorithm): {\\it Radiosity}}}\n\t\\label{fig:fig15}\n\\end{figure}\n\n\n\\section{Conclusions}\nThis paper describes an IPA-based approach to performance regulation in stochastic timed discrete event dynamic systems.\nThe considered problem is to control the output of the system so as to have it track (asymptotically) a given\nperformance reference\nin the face of variations in the system's characteristics. The proposed approach is based on\nan integrator with adaptive gain. The system's plant is represented via a discrete-event or hybrid model, and the controller's gain is inverse proportional\nto the IPA derivative of its plant function with respect to the control parameter.\n\nThe paper summarizes the regulation technique and presents several examples, which highlight the fact that it can\nwork  well despite  errors in estimating  the IPA gradient.  The examples include delay and loss in a single queue, inventory control in a Petri-net model of\na production system, and throughput regulation in a computer core. Extensions and future investigations will\nfocus on emerging problems in  various application  areas.\n\n\\section{Appendix}\nThis section provides proofs to Lemma 2.2 and Proposition 2.3.\\\\ \\\\\n{\\bf Proof of Lemma 2.2.} Consider a closed, finite-length interval $I$ where $g(\\cdot)$ is monotone-nondecreasing and convex throughout $I$. We next prove the assertion of the lemma for this case, while the situations where\n $g(\\cdot)$ is monotone-non-increasing or concave can be analyzed by similar arguments and hence their proofs are omitted.\n\n By the monotonicity of $g(\\cdot)$ we have that\n $g^{\\prime}(u)\\geq 0~\\forall u\\in I$, and we will use this fact throughout the forthcoming analysis.\n By convexity of $g(\\cdot)$  we have the following inequalities for every $u\\in I$ and $\\Delta u\\in R$ such that\n $u+\\Delta u\\in I$:\n \n", "index": 89, "text": "\\begin{equation}\n g(u)+g^{\\prime}(u)\\Delta u\\leq g(u+\\Delta u)\\leq g(u)+g^{\\prime}(u+\\Delta u)\\Delta u.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E42.m1\" class=\"ltx_Math\" alttext=\"g(u)+g^{\\prime}(u)\\Delta u\\leq g(u+\\Delta u)\\leq g(u)+g^{\\prime}(u+\\Delta u)%&#10;\\Delta u.\" display=\"block\"><mrow><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>u</mi></mrow></mrow><mo>\u2264</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>u</mi><mo>+</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>u</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>u</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>u</mi><mo>+</mo><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>u</mi></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>u</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n \\item\n Case (ii):\n \n", "itemtype": "equation", "pos": 71882, "prevtext": "\n Given  $M\\geq 1$, $\\beta\\in(0,1)$, and $\\alpha\\in(0,1)$, suppose that, for some $j=1,\\ldots$,  $u_{j-1}\\in I$,\n ${\\cal E}_{j-1}<\\alpha$, and  ${\\cal G}_{j-1}<\\beta$.\n We next derive upper bounds on the ratio $|g(u_{j}|/|g(u_{j-1})|$ (for the case where $g(u_{j-1})\\neq 0$)  in terms of $M$, $\\beta$, and $\\alpha$. The\n analysis concerns four separate cases: (i) $g(u_{j-1})\\leq 0$ and $g(u_{j})\\leq 0$; (ii)  $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$;\n (iii) $g(u_{j-1})\\geq 0$ and $g(u_{j})\\leq 0$; and (iv) $g(u_{j-1})\\geq 0$ and $g(u_{j})\\geq 0$.\n The results, to be derived in the following paragraph, are:\n \\begin{itemize}\n \\item\n Case (i):\n \n", "index": 91, "text": "\\begin{equation}\n |g(u_{j})|\\leq\\Big(1-\\frac{1-\\beta}{1+\\alpha}\\Big)|g(u_{j-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E43.m1\" class=\"ltx_Math\" alttext=\"|g(u_{j})|\\leq\\Big{(}1-\\frac{1-\\beta}{1+\\alpha}\\Big{)}|g(u_{j-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n \\item\n Case (iii):\n \n", "itemtype": "equation", "pos": 72000, "prevtext": "\n \\item\n Case (ii):\n \n", "index": 93, "text": "\\begin{equation}\n |g(u_{j})|\\leq\\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)|g(u_{j-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E44.m1\" class=\"ltx_Math\" alttext=\"|g(u_{j})|\\leq\\Big{(}M\\frac{1+\\beta}{1-\\alpha}-1\\Big{)}|g(u_{j-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mi>M</mi><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n \\item\n Case (iv):\n \n", "itemtype": "equation", "pos": 72120, "prevtext": "\n \\item\n Case (iii):\n \n", "index": 95, "text": "\\begin{equation}\n |g(u_{j})|\\leq\\Big(\\frac{1+\\beta}{1-\\alpha}-1\\Big)|g(u_{j-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E45.m1\" class=\"ltx_Math\" alttext=\"|g(u_{j})|\\leq\\Big{(}\\frac{1+\\beta}{1-\\alpha}-1\\Big{)}|g(u_{j-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n \\end{itemize}\n We next prove these inequalities. In all cases we consider Eq. (42) with $u=u_{j-1}$ and\n\n", "itemtype": "equation", "pos": 72238, "prevtext": "\n \\item\n Case (iv):\n \n", "index": 97, "text": "\\begin{equation}\n |g(u_{j})|\\leq\\Big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big)|g(u_{j-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E46.m1\" class=\"ltx_Math\" alttext=\"|g(u_{j})|\\leq\\Big{(}1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big{)}|g(u_{j-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03b1</mi></mrow></mfrac></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n By Eq. (10), $u+\\Delta u=u_j$.\n\n {\\it Case (i): $g(u_{j-1})\\leq 0$ and $g(u_{j})\\leq 0$}. The left inequality of Eq. (42)  means that\n \n", "itemtype": "equation", "pos": 72453, "prevtext": "\n \\end{itemize}\n We next prove these inequalities. In all cases we consider Eq. (42) with $u=u_{j-1}$ and\n\n", "index": 99, "text": "\\[\n \\Delta u=-\\frac{1}{g^{\\prime}(u_{j-1})+\\phi_{j-1}}\\big(g(u_{j-1})+\\psi_{j-1}\\big).\n \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\Delta u=-\\frac{1}{g^{\\prime}(u_{j-1})+\\phi_{j-1}}\\big{(}g(u_{j-1})+\\psi_{j-1}%&#10;\\big{)}.\" display=\"block\"><mrow><mrow><mrow><mi mathvariant=\"normal\">\u0394</mi><mo>\u2062</mo><mi>u</mi></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n and with a straightforward algebra,\n \n", "itemtype": "equation", "pos": 72680, "prevtext": "\n By Eq. (10), $u+\\Delta u=u_j$.\n\n {\\it Case (i): $g(u_{j-1})\\leq 0$ and $g(u_{j})\\leq 0$}. The left inequality of Eq. (42)  means that\n \n", "index": 101, "text": "\\begin{equation}\n g(u_{j-1})-g^{\\prime}(u_{j-1})\\frac{1}{g^{\\prime}(u_{j-1})+\\phi_{j-1}}\\big(g(u_{j-1})+\\psi_{j-1}\\big)\\leq g(u_j),\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47.m1\" class=\"ltx_Math\" alttext=\"g(u_{j-1})-g^{\\prime}(u_{j-1})\\frac{1}{g^{\\prime}(u_{j-1})+\\phi_{j-1}}\\big{(}g%&#10;(u_{j-1})+\\psi_{j-1}\\big{)}\\leq g(u_{j}),\" display=\"block\"><mrow><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mfrac><mn>1</mn><mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mrow><mo>\u2264</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n By definition of ${\\cal E}_{j-1}$ and ${\\cal G}_{j-1}$, $|\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}|\\leq{\\cal E}_{j-1}$ and\n $|\\frac{\\psi_{j-1}}{g(u_{j-1})}|\\leq{\\cal G}_{j-1}$; and by assumption, ${\\cal E}_{j-1}\\leq\\alpha$ and\n ${\\cal G}_{j-1}\\leq\\beta$; hence, and by (48) and the assumption that $g(u_{j-1})\\leq 0$, we have that\n \n", "itemtype": "equation", "pos": 72866, "prevtext": "\n and with a straightforward algebra,\n \n", "index": 103, "text": "\\begin{equation}\n g(u_{j})\\geq g(u_{j-1})-\\frac{1}{1+\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}}\\Big(1+\\frac{\\psi_{j-1}}{g(u_{j-1})}\\Big)g(u_{j-1}).\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\geq g(u_{j-1})-\\frac{1}{1+\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}}\\Big%&#10;{(}1+\\frac{\\psi_{j-1}}{g(u_{j-1})}\\Big{)}g(u_{j-1}).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mfrac><msub><mi>\u03d5</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><msub><mi>\u03c8</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n By the assumption that $g(u_j)\\leq 0$, Eq. (43) follows.\n\n {\\it Case (ii): $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$}. The right inequality of (42) means that\n \n", "itemtype": "equation", "pos": 73358, "prevtext": "\n By definition of ${\\cal E}_{j-1}$ and ${\\cal G}_{j-1}$, $|\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}|\\leq{\\cal E}_{j-1}$ and\n $|\\frac{\\psi_{j-1}}{g(u_{j-1})}|\\leq{\\cal G}_{j-1}$; and by assumption, ${\\cal E}_{j-1}\\leq\\alpha$ and\n ${\\cal G}_{j-1}\\leq\\beta$; hence, and by (48) and the assumption that $g(u_{j-1})\\leq 0$, we have that\n \n", "index": 105, "text": "\\begin{equation}\n g(u_{j})\\geq\\Big(1-\\frac{1-\\beta}{1+\\alpha}\\Big)g(u_{j-1}).\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\geq\\Big{(}1-\\frac{1-\\beta}{1+\\alpha}\\Big{)}g(u_{j-1}).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n and multiplying and dividing the RHS of (50) by $g^{\\prime}(u_{j-1})$ and $g(u_{j-1})$ we obtain that\n \n", "itemtype": "equation", "pos": 73611, "prevtext": "\n By the assumption that $g(u_j)\\leq 0$, Eq. (43) follows.\n\n {\\it Case (ii): $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$}. The right inequality of (42) means that\n \n", "index": 107, "text": "\\begin{equation}\n g(u_{j})\\leq g(u_{j-1})-\\frac{g^{\\prime}(u_j)}{g^{\\prime}(u_{j-1})+\\phi_{j-1}}(g(u_{j-1})+\\psi_{j-1}),\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E50.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\leq g(u_{j-1})-\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})+\\phi_{j-1%&#10;}}(g(u_{j-1})+\\psi_{j-1}),\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03d5</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><msub><mi>\u03c8</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nBy definition of ${\\cal E}_{j-1}$ and ${\\cal G}_{j-1}$,\n$|\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}|\\leq{\\cal E}_{j-1}$ and\n $|\\frac{\\psi_{j-1}}{g(u_{j-1})}|\\leq{\\cal G}_{j-1}$; and by assumption, ${\\cal E}_{j-1}\\leq\\alpha$,\n ${\\cal G}_{j-1}\\leq\\beta$, and\n $\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})}\\leq M$; hence, and by (51) and the assumption that $g(u_{j-1})\\leq 0$, we have that\n \n", "itemtype": "equation", "pos": 73852, "prevtext": "\n and multiplying and dividing the RHS of (50) by $g^{\\prime}(u_{j-1})$ and $g(u_{j-1})$ we obtain that\n \n", "index": 109, "text": "\\begin{equation}\n g(u_{j})\\leq g(u_{j-1})-\\frac{g^{\\prime}(u_j)}{g^{\\prime}(u_{j-1})}\\frac{1}{1+\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}}\n \\Big(1+\\frac{\\psi_{j-1}}{g(u_{j-1})}\\Big)g(u_{j-1}).\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E51.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\leq g(u_{j-1})-\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})}\\frac{1}{%&#10;1+\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}}\\Big{(}1+\\frac{\\psi_{j-1}}{g(u_{j-1})%&#10;}\\Big{)}g(u_{j-1}).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mfrac><msub><mi>\u03d5</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mrow><msup><mi>g</mi><mo>\u2032</mo></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow></mfrac><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>+</mo><mfrac><msub><mi>\u03c8</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n Since by assumption $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$, Eq. (44) follows.\n\n {\\it Case (iii): $g(u_{j-1})\\geq 0$ and $g(u_{j})\\leq 0$}. As in Case (i), Eq. (48) is satisfied, and since $g(u_{j-1})\\geq 0$,\n \n", "itemtype": "equation", "pos": 74445, "prevtext": "\nBy definition of ${\\cal E}_{j-1}$ and ${\\cal G}_{j-1}$,\n$|\\frac{\\phi_{j-1}}{g^{\\prime}(u_{j-1})}|\\leq{\\cal E}_{j-1}$ and\n $|\\frac{\\psi_{j-1}}{g(u_{j-1})}|\\leq{\\cal G}_{j-1}$; and by assumption, ${\\cal E}_{j-1}\\leq\\alpha$,\n ${\\cal G}_{j-1}\\leq\\beta$, and\n $\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})}\\leq M$; hence, and by (51) and the assumption that $g(u_{j-1})\\leq 0$, we have that\n \n", "index": 111, "text": "\\begin{equation}\n g(u_{j})\\leq\\Big(1-M\\frac{1+\\beta}{1-\\alpha}\\Big)g(u_{j-1}).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E52.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\leq\\Big{(}1-M\\frac{1+\\beta}{1-\\alpha}\\Big{)}g(u_{j-1}).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mi>M</mi><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n Since $g(u_{j})\\leq 0$, Eq. (45) follows.\n\n\n\n {\\it Case (iv):  $g(u_{j-1})\\geq 0$ and $g(u_{j})\\geq 0$}.\n As in the analysis for Case (ii), Eq. (51) applies, and by the definition of $M$,\n $\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})}\\geq\\frac{1}{M}$. Therefore\n \n", "itemtype": "equation", "pos": 74750, "prevtext": "\n Since by assumption $g(u_{j-1})\\leq 0$ and $g(u_{j})\\geq 0$, Eq. (44) follows.\n\n {\\it Case (iii): $g(u_{j-1})\\geq 0$ and $g(u_{j})\\leq 0$}. As in Case (i), Eq. (48) is satisfied, and since $g(u_{j-1})\\geq 0$,\n \n", "index": 113, "text": "\\begin{equation}\n g(u_{j})\\geq g(u_{j-1})-\\frac{1+\\beta}{1-\\alpha}g(u_{j-1})=\\Big(1-\\frac{1+\\beta}{1-\\alpha}\\Big)g(u_{j-1}).\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E53.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\geq g(u_{j-1})-\\frac{1+\\beta}{1-\\alpha}g(u_{j-1})=\\Big{(}1-\\frac{1+%&#10;\\beta}{1-\\alpha}\\Big{)}g(u_{j-1}).\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n which is Eq. (46).\n\n Fix $M>1$ and $\\beta\\in(0,M^{-1})$. Consider $\\alpha\\in(0,1)$, and $n=1,\\ldots$, and suppose that all of the conditions specified\n in the assertion of the lemma are satisfied. We next prove that Eq. (11) is satisfied for an $\\alpha>0$ and a corresponding\n $\\theta\\in(0,1)$. There are two scenarios to consider: (a) $m_{n}=n+1$, and (b) $m_{n}>n+1$.\n\n Scenario (a) means that $g(u_{n})g(u_{n-1})\\geq 0$ and arises when either Case (i) or Case (iv) occur. In Case (i), Eq.\n (43) is in force, and since $\\big(1-\\frac{1-\\beta}{1+\\alpha}\\big)\\big|_{\\alpha=0}=\\beta<1$, it follows that there exists\n $\\alpha_{1}\\in(0,1)$ and $\\theta_{1}\\in(0,1)$ such that, for every $\\alpha\\in(0,\\alpha_{1})$, Eq. (11) is satisfied with $\\theta_{1}$ in\n lieu of $\\theta$. Similarly in Case (iv) and Eq. (46); since $\\big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\big)\\big|_{\\alpha=0}=1-\\frac{\\beta}{M}<1$,\n there exists $\\alpha_{4}\\in(0,1)$ and $\\theta_{4}\\in(0,1)$ such that, for every $\\alpha\\in(0,\\alpha_{4})$, Eq. (11)\n is satisfied with $\\theta_{4}$ in lieu of $\\theta$.\n\n Scenario (b) corresponds to either Case (ii) or Case (iii). In Case (iii), where $g(u_{n-1})\\geq 0$ while $g(u_{n})\\leq 0$,\n Eq. (45) is satisfied. Note that $\\big(\\frac{1+\\beta}{1-\\alpha}-1\\big)\\big|_{\\alpha=0}=\\beta<1$, and therefore, there exists\n $\\alpha_{3}\\in(0,1)$ and $\\theta_{3}\\in(0,1)$ such that, if $\\alpha\\in(0,\\alpha_{3})$, then\n \n", "itemtype": "equation", "pos": 75156, "prevtext": "\n Since $g(u_{j})\\leq 0$, Eq. (45) follows.\n\n\n\n {\\it Case (iv):  $g(u_{j-1})\\geq 0$ and $g(u_{j})\\geq 0$}.\n As in the analysis for Case (ii), Eq. (51) applies, and by the definition of $M$,\n $\\frac{g^{\\prime}(u_{j})}{g^{\\prime}(u_{j-1})}\\geq\\frac{1}{M}$. Therefore\n \n", "index": 115, "text": "\\begin{equation}\n g(u_{j})\\leq\\Big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big)g(u_{j-1}),\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E54.m1\" class=\"ltx_Math\" alttext=\"g(u_{j})\\leq\\Big{(}1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big{)}g(u_{j-1}),\" display=\"block\"><mrow><mrow><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03b1</mi></mrow></mfrac></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n In Case (ii), where $g(u_{n-1})\\leq 0$ while $g(u_{n})\\geq 0$, Eq. (44) holds, but unlike the other three cases,\n it is not true that $\\big(M\\frac{1+\\beta}{1-\\alpha}-1\\big)\\big|_{\\alpha=0}<1$. A different argument is needed.\n\n Suppose first that Case (ii) holds at $u_{n-1}$,  Case (iii) will be considered later. By definition of $m_{n}$,  Case (iii) holds at $m_{n}-1$\n  while Case (iv) is satisfied for all $j=n,\\ldots,m_{n}-2$.  By Equations (44)-(46),\n \n", "itemtype": "equation", "pos": 76679, "prevtext": "\n which is Eq. (46).\n\n Fix $M>1$ and $\\beta\\in(0,M^{-1})$. Consider $\\alpha\\in(0,1)$, and $n=1,\\ldots$, and suppose that all of the conditions specified\n in the assertion of the lemma are satisfied. We next prove that Eq. (11) is satisfied for an $\\alpha>0$ and a corresponding\n $\\theta\\in(0,1)$. There are two scenarios to consider: (a) $m_{n}=n+1$, and (b) $m_{n}>n+1$.\n\n Scenario (a) means that $g(u_{n})g(u_{n-1})\\geq 0$ and arises when either Case (i) or Case (iv) occur. In Case (i), Eq.\n (43) is in force, and since $\\big(1-\\frac{1-\\beta}{1+\\alpha}\\big)\\big|_{\\alpha=0}=\\beta<1$, it follows that there exists\n $\\alpha_{1}\\in(0,1)$ and $\\theta_{1}\\in(0,1)$ such that, for every $\\alpha\\in(0,\\alpha_{1})$, Eq. (11) is satisfied with $\\theta_{1}$ in\n lieu of $\\theta$. Similarly in Case (iv) and Eq. (46); since $\\big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\big)\\big|_{\\alpha=0}=1-\\frac{\\beta}{M}<1$,\n there exists $\\alpha_{4}\\in(0,1)$ and $\\theta_{4}\\in(0,1)$ such that, for every $\\alpha\\in(0,\\alpha_{4})$, Eq. (11)\n is satisfied with $\\theta_{4}$ in lieu of $\\theta$.\n\n Scenario (b) corresponds to either Case (ii) or Case (iii). In Case (iii), where $g(u_{n-1})\\geq 0$ while $g(u_{n})\\leq 0$,\n Eq. (45) is satisfied. Note that $\\big(\\frac{1+\\beta}{1-\\alpha}-1\\big)\\big|_{\\alpha=0}=\\beta<1$, and therefore, there exists\n $\\alpha_{3}\\in(0,1)$ and $\\theta_{3}\\in(0,1)$ such that, if $\\alpha\\in(0,\\alpha_{3})$, then\n \n", "index": 117, "text": "\\begin{equation}\n |g(u_{n})|\\leq\\theta_{3}|g(u_{n-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E55.m1\" class=\"ltx_Math\" alttext=\"|g(u_{n})|\\leq\\theta_{3}|g(u_{n-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><msub><mi>\u03b8</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n The above analysis of Case (iv) showed that if $\\alpha<\\alpha_4$ then $\\Big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big)<1$, and therefore,\n \n", "itemtype": "equation", "pos": 77210, "prevtext": "\n In Case (ii), where $g(u_{n-1})\\leq 0$ while $g(u_{n})\\geq 0$, Eq. (44) holds, but unlike the other three cases,\n it is not true that $\\big(M\\frac{1+\\beta}{1-\\alpha}-1\\big)\\big|_{\\alpha=0}<1$. A different argument is needed.\n\n Suppose first that Case (ii) holds at $u_{n-1}$,  Case (iii) will be considered later. By definition of $m_{n}$,  Case (iii) holds at $m_{n}-1$\n  while Case (iv) is satisfied for all $j=n,\\ldots,m_{n}-2$.  By Equations (44)-(46),\n \n", "index": 119, "text": "\\begin{equation}\n |g(u_{n_{n-1}})|\\leq\\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)\\Big(\\frac{1+\\beta}{1-\\alpha}-\n 1\\Big)\\Big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big)^{m_{n-1}-(n-1}|g(u_{n-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E56.m1\" class=\"ltx_Math\" alttext=\"|g(u_{n_{n-1}})|\\leq\\Big{(}M\\frac{1+\\beta}{1-\\alpha}-1\\Big{)}\\Big{(}\\frac{1+%&#10;\\beta}{1-\\alpha}-1\\Big{)}\\Big{(}1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big{)}^{%&#10;m_{n-1}-(n-1}|g(u_{n-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><msub><mi>n</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mi>M</mi><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><msup><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mn>1</mn><mo>-</mo><mrow><mfrac><mn>1</mn><mi>M</mi></mfrac><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>\u03b1</mi></mrow></mfrac></mrow></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mrow><msub><mi>m</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n But $\\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)\\Big(\\frac{1+\\beta}{1-\\alpha}-\n 1\\Big)\\Big|_{\\alpha=0}=\\big(M(1+\\beta)-1\\big)\\beta<M\\beta<1$, where the last two inequalities are due to the\n  assumption that $M\\beta<1$. Therefore, there exist $\\alpha_{2}\\in(0,1)$ and $\\theta_{2}\\in(0,1)$ such that, if\n  $\\alpha<\\alpha_{2}$, Eq. (11) is satisfied with $\\theta_{2}$ in lieu of $\\theta$.\n\n  Finally, in Case (iii) at $u_{n-1}$, Eq. (57) is provable in the same way as for Case (ii), and the conclusion is derivable in\n  the same way as well.\n\n  Now by defining $\\alpha=\\min\\{\\alpha_{i}:i=1,\\dots,4\\}$, Eq. (11) is satisfied with\n  $\\theta:=\\max\\{\\theta_{i}:i=1,\\ldots,4\\}$. This completes the proof. \\hfill $\\Box$\\\\ \\\\\n  {\\bf Proof of Proposition 2.3.}\n  Given $\\eta>0$, $M>1$, and $\\varepsilon>0$. Fix $\\beta\\in(0,M^{-1})$. Choose $\\alpha\\in(0,1)$ and $\\theta\\in(0,1)$ according\n  to Lemma 2.2. In particular, as in the proof of Lemma 2.2 we can assume, by reducing $\\alpha$ is necessary, that\n  \n", "itemtype": "equation", "pos": 77555, "prevtext": "\n The above analysis of Case (iv) showed that if $\\alpha<\\alpha_4$ then $\\Big(1-\\frac{1}{M}\\frac{1-\\beta}{1+\\alpha}\\Big)<1$, and therefore,\n \n", "index": 121, "text": "\\begin{equation}\n |g(u_{n_{n-1}})|\\leq\\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)\\Big(\\frac{1+\\beta}{1-\\alpha}-\n 1\\Big)|g(u_{n-1})|.\n \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E57.m1\" class=\"ltx_Math\" alttext=\"|g(u_{n_{n-1}})|\\leq\\Big{(}M\\frac{1+\\beta}{1-\\alpha}-1\\Big{)}\\Big{(}\\frac{1+%&#10;\\beta}{1-\\alpha}-1\\Big{)}|g(u_{n-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><msub><mi>n</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mi>M</mi><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n  Consider a closed, finite-length interval $I$ and a sequence of\n  points $\\{u_{n}\\}_{n=1}^{\\infty}$ satisfying the conditions of the proposition. Suppose, without loss of generality,\n  that $g(\\cdot)$ is monotone nondecreasing and convex\n  on $I$. Since $|g^{\\prime}(u)|\\geq\\eta$ for\n  every $u\\in I$, it follows by Eq. (10) that there exists $K>0$ (independent of $I$ or the sequence\n  $\\{u_{n}\\}$) such that, for every $n=1,\\ldots$,\n  \n", "itemtype": "equation", "pos": 78688, "prevtext": "\n But $\\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)\\Big(\\frac{1+\\beta}{1-\\alpha}-\n 1\\Big)\\Big|_{\\alpha=0}=\\big(M(1+\\beta)-1\\big)\\beta<M\\beta<1$, where the last two inequalities are due to the\n  assumption that $M\\beta<1$. Therefore, there exist $\\alpha_{2}\\in(0,1)$ and $\\theta_{2}\\in(0,1)$ such that, if\n  $\\alpha<\\alpha_{2}$, Eq. (11) is satisfied with $\\theta_{2}$ in lieu of $\\theta$.\n\n  Finally, in Case (iii) at $u_{n-1}$, Eq. (57) is provable in the same way as for Case (ii), and the conclusion is derivable in\n  the same way as well.\n\n  Now by defining $\\alpha=\\min\\{\\alpha_{i}:i=1,\\dots,4\\}$, Eq. (11) is satisfied with\n  $\\theta:=\\max\\{\\theta_{i}:i=1,\\ldots,4\\}$. This completes the proof. \\hfill $\\Box$\\\\ \\\\\n  {\\bf Proof of Proposition 2.3.}\n  Given $\\eta>0$, $M>1$, and $\\varepsilon>0$. Fix $\\beta\\in(0,M^{-1})$. Choose $\\alpha\\in(0,1)$ and $\\theta\\in(0,1)$ according\n  to Lemma 2.2. In particular, as in the proof of Lemma 2.2 we can assume, by reducing $\\alpha$ is necessary, that\n  \n", "index": 123, "text": "\\begin{equation}\n  \\Big(M\\frac{1+\\beta}{1-\\alpha}-1\\Big)\\Big(\\frac{1+\\beta}{1-\\alpha}-1\\Big)<1.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E58.m1\" class=\"ltx_Math\" alttext=\"\\Big{(}M\\frac{1+\\beta}{1-\\alpha}-1\\Big{)}\\Big{(}\\frac{1+\\beta}{1-\\alpha}-1\\Big%&#10;{)}&lt;1.\" display=\"block\"><mrow><mrow><mrow><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mrow><mi>M</mi><mo>\u2062</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac></mrow><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mo>\u2062</mo><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mrow><mfrac><mrow><mn>1</mn><mo>+</mo><mi>\u03b2</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>\u03b1</mi></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow></mrow><mo>&lt;</mo><mn>1</mn></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n  Fix $\\varepsilon^{\\prime}>0$ such that\n  \n", "itemtype": "equation", "pos": 79240, "prevtext": "\n  Consider a closed, finite-length interval $I$ and a sequence of\n  points $\\{u_{n}\\}_{n=1}^{\\infty}$ satisfying the conditions of the proposition. Suppose, without loss of generality,\n  that $g(\\cdot)$ is monotone nondecreasing and convex\n  on $I$. Since $|g^{\\prime}(u)|\\geq\\eta$ for\n  every $u\\in I$, it follows by Eq. (10) that there exists $K>0$ (independent of $I$ or the sequence\n  $\\{u_{n}\\}$) such that, for every $n=1,\\ldots$,\n  \n", "index": 125, "text": "\\begin{equation}\n  |g(u_{n})|\\leq K|g(u_{n-1})|.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E59.m1\" class=\"ltx_Math\" alttext=\"|g(u_{n})|\\leq K|g(u_{n-1})|.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n  Fix $\\delta>0$ such that\n  \n", "itemtype": "equation", "pos": 79349, "prevtext": "\n  Fix $\\varepsilon^{\\prime}>0$ such that\n  \n", "index": 127, "text": "\\begin{equation}\n  2K\\varepsilon^{\\prime}<\\varepsilon.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E60.m1\" class=\"ltx_Math\" alttext=\"2K\\varepsilon^{\\prime}&lt;\\varepsilon.\" display=\"block\"><mrow><mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>K</mi><mo>\u2062</mo><msup><mi>\u03b5</mi><mo>\u2032</mo></msup></mrow><mo>&lt;</mo><mi>\u03b5</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n  By assumption ${\\cal E}_{n}<\\alpha$ and $|\\psi_{n}|<\\delta$ for all $n=1,\\ldots,$. As a result of the inequality\n  $|\\psi_{n}|<\\delta$,\n  and by Eq. (61), if ${\\cal G}_{n}:=\\frac{|\\psi_{n}|}{|g(u_{n})|}>\\beta$ then $|g(u_{n})|<\\varepsilon^{\\prime}$.\n  Thus, if $|g(u_{n})|>\\varepsilon^{\\prime}$ then Eqs. (43)-(46) hold with $n+1$ in lieu of $j$, and if\n  $|g(u_{n})|<\\varepsilon^{\\prime}$ then\n  \n", "itemtype": "equation", "pos": 79450, "prevtext": "\n  Fix $\\delta>0$ such that\n  \n", "index": 129, "text": "\\begin{equation}\n  \\delta<\\min\\big\\{\\beta\\varepsilon^{\\prime},\\frac{\\varepsilon}{2}\\big\\}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E61.m1\" class=\"ltx_Math\" alttext=\"\\delta&lt;\\min\\big{\\{}\\beta\\varepsilon^{\\prime},\\frac{\\varepsilon}{2}\\big{\\}}.\" display=\"block\"><mrow><mrow><mi>\u03b4</mi><mo>&lt;</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><mi>\u03b2</mi><mo>\u2062</mo><msup><mi>\u03b5</mi><mo>\u2032</mo></msup></mrow><mo>,</mo><mfrac><mi>\u03b5</mi><mn>2</mn></mfrac><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n\nNow consider a point $u_{n}$ such that $|g(u_{n})|>\\varepsilon^{\\prime}$ and hence\n${\\cal G}_{n}\\leq\\beta$.\nConsider the four cases (i) - (iv) in the proof of Lemma 2.2.\nIn Case (i) and Case (iv), $m_{n}=n+1$, and Eq. (11) implies that\n$|g(u_{n+1})|<|g(u_{n})|$. In Case (iii), Eq. (55) implies the same inequality, namely $|g(u_{n+1})|<|g(u_{n})|$.\nOnly in Case (ii) the reverse inequality is possible, namely that\n$|g(u_{n+1})|\\geq|g(u_{n})|$.\n\nSuppose that Case (ii) holds at $u_{n}$. Then (by definition of Case (ii)) $g(u_{n})\\leq 0$, $g(u_{j})\\geq 0$ $\\forall~j=n+1,\\ldots,m_{n}-1$,\nand $g(u_{m_{n}})\\leq 0$. Moreover, for every $j=n+1,\\ldots,m_{n}-1$, either Case (iii) or (iv) holds, and\ntherefore, either $|g(u_{j+1})|<|g(u_{j})|$ if $|g(u_{j})|\\geq \\varepsilon^{\\prime}$, or\n$|g(u_{j+1})|\\leq K\\varepsilon^{\\prime}$ if\n$|(g(u_{j})|\\leq\\varepsilon^{\\prime}$. Consequently, and by Eq. (62), we have that\n\n", "itemtype": "equation", "pos": 79957, "prevtext": "\n  By assumption ${\\cal E}_{n}<\\alpha$ and $|\\psi_{n}|<\\delta$ for all $n=1,\\ldots,$. As a result of the inequality\n  $|\\psi_{n}|<\\delta$,\n  and by Eq. (61), if ${\\cal G}_{n}:=\\frac{|\\psi_{n}|}{|g(u_{n})|}>\\beta$ then $|g(u_{n})|<\\varepsilon^{\\prime}$.\n  Thus, if $|g(u_{n})|>\\varepsilon^{\\prime}$ then Eqs. (43)-(46) hold with $n+1$ in lieu of $j$, and if\n  $|g(u_{n})|<\\varepsilon^{\\prime}$ then\n  \n", "index": 131, "text": "\\begin{equation}\n  |g(u_{n+1})|\\leq K\\varepsilon^{\\prime}.\n  \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E62.m1\" class=\"ltx_Math\" alttext=\"|g(u_{n+1})|\\leq K\\varepsilon^{\\prime}.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mi>K</mi><mo>\u2062</mo><msup><mi>\u03b5</mi><mo>\u2032</mo></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\nAs a result we have the following situation: If $|g(u_{j})|\\leq\\varepsilon^{\\prime}$\nfor some $j=n,\\ldots,m_{n}-1$, then\n$|g(u_{m_{n}})|\\leq K\\varepsilon^{\\prime}$. On the other hand,\nif $|g(u_{j})|\\geq\\varepsilon^{\\prime}$ for every $j=n,\\ldots,m_{n}-1$,\nthen (by Lemma 2.2), Eq. (11) is in force.\nThis, in conjunction with Eq. (61), implies that\n\n", "itemtype": "equation", "pos": 80946, "prevtext": "\n\nNow consider a point $u_{n}$ such that $|g(u_{n})|>\\varepsilon^{\\prime}$ and hence\n${\\cal G}_{n}\\leq\\beta$.\nConsider the four cases (i) - (iv) in the proof of Lemma 2.2.\nIn Case (i) and Case (iv), $m_{n}=n+1$, and Eq. (11) implies that\n$|g(u_{n+1})|<|g(u_{n})|$. In Case (iii), Eq. (55) implies the same inequality, namely $|g(u_{n+1})|<|g(u_{n})|$.\nOnly in Case (ii) the reverse inequality is possible, namely that\n$|g(u_{n+1})|\\geq|g(u_{n})|$.\n\nSuppose that Case (ii) holds at $u_{n}$. Then (by definition of Case (ii)) $g(u_{n})\\leq 0$, $g(u_{j})\\geq 0$ $\\forall~j=n+1,\\ldots,m_{n}-1$,\nand $g(u_{m_{n}})\\leq 0$. Moreover, for every $j=n+1,\\ldots,m_{n}-1$, either Case (iii) or (iv) holds, and\ntherefore, either $|g(u_{j+1})|<|g(u_{j})|$ if $|g(u_{j})|\\geq \\varepsilon^{\\prime}$, or\n$|g(u_{j+1})|\\leq K\\varepsilon^{\\prime}$ if\n$|(g(u_{j})|\\leq\\varepsilon^{\\prime}$. Consequently, and by Eq. (62), we have that\n\n", "index": 133, "text": "\\begin{equation}\n|g(u_{m_{n}})|\\leq\\max\\big\\{K\\varepsilon^{\\prime},|g(u_{n+1})|\\big\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E63.m1\" class=\"ltx_Math\" alttext=\"|g(u_{m_{n}})|\\leq\\max\\big{\\{}K\\varepsilon^{\\prime},|g(u_{n+1})|\\big{\\}}.\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><msub><mi>m</mi><mi>n</mi></msub></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo>\u2264</mo><mrow><mi>max</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><mi>K</mi><mo>\u2062</mo><msup><mi>\u03b5</mi><mo>\u2032</mo></msup></mrow><mo>,</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.03799.tex", "nexttext": "\n hence the inequality in Eq. (13).\n\nFinally, Eq. (14) follows from (13) and the assumption that $\\delta<\\frac{\\varepsilon}{2}$, as specified in Eq. (61).\nThis completes the proof. \\hfill $\\Box$\n\n\n\n\n\n\n\n\n\\vspace{.4in}\n\\noindent{\\bf References}\n\\begin{thebibliography}{99}\n\n\n\n\n\n\\bibitem{Almoosa12}\nAlmoosa, N., Song, W., Wardi, Y., and Yalamanchili, S. (2012).\nA Power Capping Controller for Multicore Processors.\n\\emph{Proc.  2012 American Control Conference,}\nMontreal, Canada, June 27-29.\n\n\n\n\\bibitem{Almoosa12a}\nAlmoosa, N., Song, W., Wardi, Y., and Yalamanchili, S. (2012a).\nThroughput Regulation in Multicore Processors via IPA.\n\\emph{Proc. 51 IEEE Conference on Decision and Control (CDC)},\n Maui, Hawaii, December 10-13.\n\n\n\\bibitem{Bauer10}\nBauer, M., Pacher, M., and Brinkschulte, U. (2010).\nA Chip-size  Evaluation of  a Multi-threaded Processor Enhanced with a PID Controller.\n\\emph{Proc.   8th\nIFIP Workshop on Software Technologies for Future Embedded and\nUbiquitous Systems (SEUS 2010)}, Waidhofen, Austria, October 13-15, 2010.\n\n\\bibitem{Brinkschulte09}\nBrinkschulte, U., and  Pacher, M.\nA Theoretical Examination of a Self-Adaptation Approach to Improve the Real-Time\nCapabilities in Multi-Threaded Microprocessors.\n\\emph{Proc. 2009 Third IEEE International Conference on Self-Adaptive and Self-Organizing Systems},\nSan Francisco, California, September 14-18, 2009.\n\n\n\\bibitem{Cassandras99}\n\nCassandras, C., and Lafortune, S. (1999).\n\\emph{ Introduction to Discrete\nEvent Systems}.\nKluwer Academic Publishers, Boston, Massachusetts.\n\n\n\n\\bibitem{Cassandras02}\n\nCassandras, C.G., Wardi, Y.,  Melamed, B.,  Sun, G., and\nPanayiotou, C.G. (2002).\nPerturbation Analysis for On-Line Control and\nOptimization of Stochastic Fluid Models.\n\\emph{IEEE Transactions on Automatic Control},\n Vol. 47, No. 8, pp. 1234-1248.\n\n\n\n\n\\bibitem{Cassandras06}\nCassandras, C.G. (2006).\nStochastic flow systems: Modeling and sensitivity analysis.\nIn \\emph{ Stochastic Hybrid Systems: Recent Developments and Research\n  Trends,}\n Eds. C.G. Cassandras and J. Lygeros, CRC Press, New York, New York,\n  pp. 137--165.\n\n\n\n\n\\bibitem{Cassandras10}\nCassandras, C.G., Wardi, Y., Panayiotou, C.G., and Yao, C. (2010).\nPerturbation Analysis and Optimization of Stochastic Hybrid Systems.\n\\emph{European Journal of Control},\n Vol. 16, pp. 642-664.\n\n\\bibitem{Chen15}\nChen, X., Xiao, H., Wardi, Y., and Yalamanchili, S. (2015).\nThroughput Regulation in Shared Memory Multicore Prtocessors.\n{\\it Proc. 22nd IEEE Intl. Conference on High Performance Computing (HiPC)},\nBengaluru, India, December 16-19.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem{c5}\nHennessey, J.L.,  and  Patterson, D.A.  (2012). \\emph{Computer Architecture: A Quantitative Approach}, Morgan Kaufmann.\n\n\\bibitem{Ho91}\nHo, Y.C., and Cao, X.R. (1991).\n\\emph{Perturbation Analysis of Discrete Event\nDynamic Systems}.\nKluwer Academic Publishers, Boston,\nMassachusetts.\n\n\n\n\\bibitem{c3}  Howard, J.,  Dighe, S.,  Vangal, S.R.,  Ruhl, G.,  Borkar, N.,  Jain, S.,  Erraguntla, V.,  Konow, M. Ripen, M. Gries, M., Droege, G.,  Lund-Larsen, T.,  Steibl, S. Borkar, S.,  De, V.K., and  Van Det Wijngaart, R. A. (2011).\n     48-Core IA-32 Processor in 45 nm CMOS Using On-Die Message Passing and DVFS  for Performance and Power Scaling.\n    \\emph{J. Solid State Circuits}, Vol. 46, pp. 173-183.\n\n   \\bibitem{c4}  Kim,  W.,   Gupta, M.S.,   Wei, G.-Y., and  Brooks, D. (2008).\n   System Level Analysis of Fast, Per-Core DVFS using On-Chip Switching Regulators.\n    \\emph{Proc. IEEE Intl. Symposium on High Performance of Computer Architectures}.\n\n    \\bibitem{Lancaster66}\n   Lancaster, P.\n    Error analysis for the Newton-Raphson method.\n     \\emph{Numerische Mathematik},\n     Vol. 9, pp. 55-68, 1966.\n\n\n    \\bibitem{Lohn11}\n     Lohn, D.,  Pacher, M., and  Brinkschulte, U.\n    A Generalized Model to Control the Throughput in\na Processor for Real-Time Applications.\n \\emph{2011 14th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing},\n Newport Beach, California, March 28-31, 2011.\n\n\\bibitem{Ortega70}\nOrtega, J.M., and  Rheinboldt, W.C. (1970).\n\\emph{\nIterative Solutions of Nonlinear Equations in Several Variables.}\nAcademic Press, San Diego, California.\n\n\n\\bibitem{Panayiotou06}\nPanayiotou, C.G.,  and Cassandras, C.G. (2006).\nInfinitesimal Perturbation Analysis and\nOptimization for Make-To-Stock Manufacturing Systems Based on Stochastic Fluid\nModels.\n\\emph{Discrete Event Dynamic Systems: Theory and Applications,} Vol. 16, pp. 109-142.\n\n\n\n\n\n\n\n\\bibitem{Seatzu13}\nSeatzu, C., and Wardi, Y. (2013).\nOn the Use of IPA in Performance Optimization of Continuous Marked Graphs: A Case\nStudy.\n\\emph{Proc. IEEE Conf. on Emerging Technologies and Factory Automation\n(ETFA'13)}, Cagliari, Italy, September 10-13.\n\n\\bibitem{Seatzu14}\nSeatzu, C., and Wardi, Y. (2014).\nPerformance Regulation via Integral\nControl in a Class of Stochastic Discrete\nEvent Dynamic Systems.\n\\emph{Proc.  12th IFAC - IEEE International Workshop on Discrete Event Systems (WODES'14)}, Paris, France, May 14-16.\n\n\n\\bibitem{Shakkottaia01} Shakkottaia, S., and  Stolyarb, A.L. (2001).\nScheduling algorithms for a mixture of real-time and non-real-time data in HDR.\n \\emph{Teletraffic Science and Engineering},  Vol. 4, pp. 798-804.\n\n\n\\bibitem{Silva04}\nSilva, M. and Recalde, L. (2004).\nOn fluidification of {P}etri net models:\n            from discrete to hybrid and continuous models.\n\\emph{Annual Reviews in Control,} Vol. 28, pp. 253-266.\n\n\\bibitem{Sun04}\nSun, G.,  Cassandras, C.G.,  Wardi, Y.,  Panayiotou, C.G., and  Riley, G. (2004).\nPerturbation Analysis and Optimization of Stochastic Flow\nNetworks.\n\\emph{IEEE Transactions on Automatic Control}, Vol.\n 49, No. 12, pp. 2143-2159.\n\n\n\\bibitem{Thomadakis11}\nThomadakis, M.E. (2011).\n The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms. E-PRINT Network (pubs.), pp. 2-5.\n\n\\bibitem{Wardi10}\nWardi, Y., Adams, R., and Melamed, B. (2010).\nA Unified Approach to Infinitesimal Perturbation Analysis in Stochastic Flow Models:\nThe Single-Stage Case.\n \\emph{ IEEE Transactions on Automatic Control},\n Vol. AC-55, No. 1, pp. 89-103.\n\n\n\n\\bibitem{Wardi13}\nWardi, Y., and Cassandras, C.G. (2014).\nPerturbation\nAnalysis of Discrete Event Systems.\nin \\emph{Encyclopedia on Systems and Control},\nEds. T. Samad and J. Baillieul,\nSection\non Discrete Event Systems, Ed. C.G. Cassandras.\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem{Wardi13b}\nWardi, Y., Giua, A., and Seatzu, C.(2013b).\nIPA for Continuous  Stochastic Marked Graphs.\n\\emph{\nAutomatica},\nVol. 49, No. 5, pp. 1204-1215.\n\n\n\n\n\n\n\n\n\n\\bibitem{c11}\nWoo, S.C.,  Oharat, M.,  Torriet, E.,   et al. (1995).\nThe SPLASH-2 Programs: Characterization and Methodological Considerations.\n\\emph{ISCA '95 Proceedings of the 22nd annual international symposium on Computer architectures}, pp.   24-36.\n\n\\bibitem{Xie02}\nXie, X. (2002). Fluid Stochastic Event Graphs for Evoluation and Optimization of Discrete-Event Systems with Failurs.\n\\emph{IEEE Transactions on Robotics and Automation}, Vol. 18, pp. 360-367.\n\n\n\n\\bibitem{Yalamanchili}\nYalamanchili, S., Riley, G., and  Conte, T.M.  http://manifold.gatech.edu/.\n\n\n\n\n\n\n\n\n\n\n\n\\end{thebibliography}\n\n", "itemtype": "equation", "pos": 81396, "prevtext": "\nAs a result we have the following situation: If $|g(u_{j})|\\leq\\varepsilon^{\\prime}$\nfor some $j=n,\\ldots,m_{n}-1$, then\n$|g(u_{m_{n}})|\\leq K\\varepsilon^{\\prime}$. On the other hand,\nif $|g(u_{j})|\\geq\\varepsilon^{\\prime}$ for every $j=n,\\ldots,m_{n}-1$,\nthen (by Lemma 2.2), Eq. (11) is in force.\nThis, in conjunction with Eq. (61), implies that\n\n", "index": 135, "text": "\\begin{equation}\n\\limsup_{n\\rightarrow\\infty}|g(u_{n})|\\leq K\\varepsilon^{\\prime}\\leq\\frac{\\varepsilon}{2},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E64.m1\" class=\"ltx_Math\" alttext=\"\\limsup_{n\\rightarrow\\infty}|g(u_{n})|\\leq K\\varepsilon^{\\prime}\\leq\\frac{%&#10;\\varepsilon}{2},\" display=\"block\"><mrow><mrow><mrow><munder><mo movablelimits=\"false\">lim sup</mo><mrow><mi>n</mi><mo>\u2192</mo><mi mathvariant=\"normal\">\u221e</mi></mrow></munder><mo>\u2061</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>g</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>u</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow><mo>\u2264</mo><mrow><mi>K</mi><mo>\u2062</mo><msup><mi>\u03b5</mi><mo>\u2032</mo></msup></mrow><mo>\u2264</mo><mfrac><mi>\u03b5</mi><mn>2</mn></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}]