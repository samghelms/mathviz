[{"file": "1601.02900.tex", "nexttext": "\nwhere $L(t)$ is a driving noise process with independent increments, i.e., a L\u00c3\u00a9vy process. The initial state of the process $Y$ is defined as the value at the left-hand limit $Y(0-)$ due to the possibility of a jump at time $0$. In equation (\\ref{eq:OUprocess}), $\\mu\\in\\mathbb{R}$ is the mean\nlevel to which the process tends to revert, $\\lambda^{-1}>0$ denotes\nthe speed of mean reversion and $\\sigma>0$ is the volatility of\nthe OU process.  The unique strong solution to the SDE (\\ref{eq:OUprocess}) is\ngiven by \n\n", "itemtype": "equation", "pos": 14998, "prevtext": "\n\n\\begin{frontmatter}\n\n\n\\title{Bayesian calibration and number of jump components in electricity spot price models}\n\n\\author[label1]{Jhonny Gonzalez}\n\\author[label2]{John Moriarty\\footnote{Corresponding author. {\\em Email address:} {j.moriarty@qmul.ac.uk}}}\n\\author[label3]{Jan Palczewski}\n\n\\address[label1]{School of Mathematics, University of Manchester, Manchester M13 9PL, UK}\n\\address[label2]{School of Mathematical Sciences, Queen Mary University of London,\nLondon E1 4NS}\n\\address[label3]{School of Mathematics, University of Leeds, Leeds LS2 9JT, UK}\n\n\\begin{abstract}\nThe price spikes observed in electricity spot markets may be understood to arise from fundamental drivers on both the supply and demand sides. Each driver can potentially create spikes with different frequencies, height distributions and rates of decay. This behaviour can be accounted for in models with multiple superposed components, however their calibration is challenging. Given a price history we apply a Markov Chain Monte Carlo (MCMC) based procedure to generate posterior samples from an augmented state space comprising parameters and multiple driving jump processes. This also enables posterior predictive checking to assess model adequacy. The procedure is used to determine the number of signed jump components required in two different markets, in time periods both before and after the recent global financial crises.\n\\end{abstract}\n\n\\begin{keyword}\nMultifactor models \\sep Bayesian calibration \\sep Markov Chain Monte Carlo \\sep Ornstein-Uhlenbeck process \\sep Electricity spot price \\sep Negative jumps\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\n\n\\section{Introduction} \\label{sec:intro}\nElectricity spot prices exhibit a high degree of structure including jumps, mean reversion and seasonality. This complexity and variability makes their modelling both important for market participants and statistically challenging. A single-factor model including the above features was introduced by \\cite{clewlow_energy_2000}. The threshold model of \\cite{geman_understanding_2006} incorporates two jump regimes: when the price is below a threshold jumps are multiplied by a positive constant, and conversely, when the price exceeds the threshold the constant turns negative resulting in downward jumps. Several multifactor models have introduced further structure, beginning with \\citet{lucia_electricity_2002}. Such models express the price as a sum of unobservable or {\\em latent} processes ({\\em factors}) with distinct purposes, for example the modelling of short-term and long-term price variations respectively. \\citet{lucia_electricity_2002} complement a Gaussian mean-reverting process with an additional factor which is an arithmetic Brownian motion (scaled Brownian motion with drift) also removing the perfect correlation between changes in spot, future and forward prices. A multi-factor model with jumps appeared in \\cite{Benth2007} with estimation procedures discussed in \\citet{meyer-brandis_multi-factor_2008}. \\cite{seifert_modelling_2007} explicitly refer to the physical origins of various types of jumps while developing their two-factor model. We find the arguments of the latter paper enlightening, and in this paper we further probe the question of fundamental drivers by comparing two markets and two time periods, namely a period before the recent global financial crises (2000-2007) and another period afterwards (2011-2015), using the simple and flexible multifactor framework of \\cite{Benth2007}. By letting the data speak we perform calibration of the model and unveil the number of factors (and their interpretation) required to successfully model these four datasets. \n\nThe interdependency between parameters in multifactor models is a challenge to calibration methods. A straightforward approach is to first separate the observed values into factors using signal filtering techniques, in order to subsequently employ classical maximum likelihood estimation. Such methods effectively assume that some of these interdependencies may be neglected, and this approach is taken for example in \\citet{meyer-brandis_multi-factor_2008} and \\citet{benth_critical_2012}. An alternative is the joint estimation of latent factors, for which there are two leading methodologies in the literature: {\\em expectation-maximisation (EM)} and {\\em Markov Chain Monte Carlo (MCMC)} methods. While EM produces point estimates for parameters in either a Bayesian or frequentist framework\\footnote{Two possible approaches to the calibration of model parameters are commonly referred to as {\\em frequentist} and {\\em Bayesian}. In the frequentist approach one seeks to derive point estimates of `true' parameter values from the data, for example by finding the maximiser of a likelihood function. An alternative viewpoint is taken in the Bayesian approach, where the unknown parameters are first assigned a probability {\\em distribution} representing prior beliefs about their value. This prior distribution is combined with the observed data to produce an updated probability distribution representing the posterior beliefs about the parameters given both the prior and the data.} \n(see, for example, \\citet{ryden2008versus}), MCMC is able to generate samples from posterior parameter distributions. Particularly in models with multiple parameters and latent processes, these interdependencies may result in likelihood surfaces and posterior distributions which are rather flat around their maxima. While EM suffers from Monte Carlo errors which amplify the usual difficulties in numerical optimisation for such problems, MCMC estimates the posterior distribution providing an analyst with a complete picture of the interrelations between parameters.\n\nIn related contexts, MCMC has been applied to fit continuous-time stochastic volatility models to financial time series, where the price is a diffusion process whose volatility is a latent mean reverting jump process or the sum of a number of such processes (called a superposition model). In this line of research a missing data methodology is employed whereby the observed process is augmented with one or more latent marked Poisson processes and the MCMC procedure generates posterior samples in this high dimensional augmented state space. Examples include \n\\cite{roberts_bayesian_2004}, \\cite{griffin_inference_2006} and \\cite{fruhwirth2009bayesian}. \nSince energy prices additionally exhibit jumps directly in their paths,  MCMC has been applied to extensions of these models in which a diffusion process with stochastic volatility is superposed with a jump process, see \\citet{2203823} in the context of electricity and \\citet{brix2015estimation} for gas prices. Technically the latter two papers estimate a discrete approximation of the models whereas in this study we pursue \\emph{exact} inference for continuous time models.\n\nFrom the modelling point of view a novelty of the present study is that the price is a superposition of more than one jump component, each with its own sign, frequency, size distribution and decay rate, along with a diffusion component. This approach acknowledges that the negative price spikes attributable to rapid wind power fluctuations may, for example, have quicker decay than the infrequent larger positive spikes due to major disturbances such as outages of a traditional generation plant. \nThe inclusion of multiple jump components also addresses the following problem identified in \\citet{2203823} and \\citet{brix2015estimation}. In two-factor models jumps of intermediate size must be accounted for either in the diffusion process (forcing unlikely  spikes in the Brownian motion path) or the jump process (implying additional jumps). While the former can lead to an overestimation of volatility in the diffusion process, the latter may result in an overestimation of the intensity of the jump process, which is independent of the jump sizes. The inclusion of a second jump process with its own mean jump size and rate of mean reversion removes this dichotomy, offering an alternative to the inclusion of stochastic volatility in the diffusion process.\n\nOur first methodological contribution is an MCMC algorithm for \\emph{exact} Bayesian inference on superposed OU models with diffusion and multiple jump components.  We contrast exact inference with a commonly used estimation procedure using a discrete time model which is an approximation to continuous dynamics. While this approximation is often used for practical reasons including simplified and/or tractable implementation, it is not possible to assess {\\em a priori} the extent of the estimation error introduced by the approximation employed. Our MCMC procedure is not based on time discretisation of the model and the inference is therefore exact at the level of distributions. This is in contrast with the work in the aforementioned papers \\citep{seifert_modelling_2007, 2203823, brix2015estimation}. Despite the relative simplicity of our multifactor model, the MCMC procedure involves a number of challenging issues and in the Appendix we provide additional comments and details concerning efficient implementation.\n\nIn addition we demonstrate that model {\\em adequacy} may also be addressed by our MCMC method. The complexity of electricity spot price models naturally gives rise to parsimony considerations. While multifactor models (potentially also including latent volatility processes) offer great flexibility, the potential statistical pitfalls of overly flexible models, for example relating to issues of identifiability and out-of-sample prediction, are well known. In this context, the ability of MCMC to sample whole trajectories from the posterior distribution of the jump processes means in particular that the adequacy of latent variable models may be addressed. We exploit this fact by using the MCMC procedure to perform {\\em posterior predictive checks} in the sense of \\cite{rubin1984}. For two different electricity spot markets, over two different periods of time, we determine in this way the minimum number of superposed processes required in the model. We find that two or three factors are sufficient in each case. We also show that taking either constant or periodic deterministic jump intensity rates can provide a relatively simple but sufficiently flexible modelling palette. Since the jump processes influence the spot price directly (additively) and have their own proper dynamics such models are also rather interpretable. More generally, since multifactor models have been considered for a range of commodities including oil and gas \\citep{schwartz2000short, brix2015estimation} our algorithm is also potentially applicable in these contexts although this is outside the scope of the present paper (see \\citet[Chapter 5]{gonzalez_modelling_2015} for an application to gas prices).\n\n\nSection \\ref{sec:model} describes the model and the data which animates our study, while Section \\ref{sec:inference} presents our MCMC algorithm including the approach to assessing model adequacy through posterior predictive checking. The data is analysed in  Section \\ref{sec:real} and Section \\ref{sec:conclusion} concludes. Notes on the efficient implementation of the algorithm are provided in the Appendix. Throughout we denote probability distributions as follows: $\\mbox{N}(a,b)$ denotes the Normal distribution with mean $a$ and variance $b$, $\\mbox{Ga}(a,b)$ the Gamma distribution with mean $a/b$, $\\mbox{IG}(a,b)$ the Inverse-Gamma distribution with mean $b(a-1)^{-1}$ for $a>1$, $\\mbox{Ex}(a)$ the Exponential distribution with mean $a$ and $\\mbox{U}(a,b)$ the Uniform distribution on the interval $(a,b)$.\n\n\\section{Model}\\label{sec:model}\n\\label{sec:motivation}\n\\begin{figure}[t]\n\\begin{centering}\n\\includegraphics[scale=0.7]{figures/deseasonalisedAPXUK-EEX-all}\n\\par\\end{centering}\n\\caption{\\label{fig:deseasonalised-data}\nDeseasonalised APXUK (top panel) and EEX (bottom panel)  data over two sample periods. The first period starts on March 27, 2001 for APXUK and on June 16, 2000 for EEX and finishes on November 21, 2006 for both markets. The second period is January 24, 2011 to February 16, 2015 for both series. Details of the deseasonalisation procedure are given in the Appendix.\n}\n\\end{figure}\n\n\\subsection{Motivation}\nFigure \\ref{fig:deseasonalised-data} illustrates two electricity spot markets, the United Kingdom APXUK and European EEX, with weekend prices excluded. The left side of the figure plots daily average prices for the APXUK (March 2001 to November 2006) and the EEX (June 2000 to November 2006). This period was one of general growth in Europe, both economically and in electricity demand, and spot prices from this time have been studied by a number of authors including \\citet{2203823}, \\citet{meyer-brandis_multi-factor_2008} and \\citet{benth_critical_2012}. The right hand side of the figure plots daily average price data between 2011 and 2015, a period of decline in UK electricity demand, although the picture across Europe was mixed.\\footnote{Sources: European Commission Eurostat service; Digest of United Kingdom Energy Statistics (DUKES) 2015, UK Department of Energy \\& Climate Change.} In order to reveal the structure of these price series more clearly the four time series have been separately deseasonalised (for details see the Appendix). \n\nReversion to a constant level is strongly suggested in the EEX data (bottom panel) and also, to a slightly lesser extent, in the APXUK series (top panel). Taking first the 2001-2006 APXUK data, the presence of significant positive price spikes is clear. However visual inspection also suggests that while some spikes decayed very quickly, a significant number showed more gradual decay. In contrast the positive spikes in the 2000-2006 EEX data appear uniformly to decay quickly and, in addition, the presence of smaller but rather frequent negative spikes is suggested. \n\nWhile the 2011-2015 APXUK data also suggests regular positive spikes, their heights are significantly smaller than those observed in 2001-2006. In the 2011-2015 EEX data the presence of negative spikes is suggested perhaps more strongly than in 2000-2006. Further, once these negative spikes are taken into account, visual inspection reveals apparently little evidence of positive spikes. \n\nFor each series we apply the MCMC procedure described in Section \\ref{sec:inference} to verify the conclusions of our visual analysis and to establish the smallest number of signed jump components for which the posterior predictive check is favourable, in a sense made precise in Section \\ref{sec:real}.\n\nIn the following subsections we present in detail the class of spot price models to be calibrated.\n\n\\subsection{Ornstein-Uhlenbeck processes}\\label{subsec:OU}\n\nA process $Y(t)$, $0\\leq t\\leq T$ which is right continuous with left limits is called an\nOrnstein-Uhlenbeck (OU) process if it is the unique strong solution to the stochastic differential\nequation (SDE) \n\n", "index": 1, "text": "\\begin{equation}\ndY(t)=\\lambda^{-1}(\\mu-Y(t))dt+\\sigma dL(t),\\quad Y(0-)=y_{0},\\label{eq:OUprocess}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"dY(t)=\\lambda^{-1}(\\mu-Y(t))dt+\\sigma dL(t),\\quad Y(0-)=y_{0},\" display=\"block\"><mrow><mrow><mrow><mrow><mi>d</mi><mo>\u2062</mo><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03bc</mi><mo>-</mo><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>t</mi></mrow><mo>+</mo><mrow><mi>\u03c3</mi><mo>\u2062</mo><mi>d</mi><mo>\u2062</mo><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>0</mn><mo>-</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msub><mi>y</mi><mn>0</mn></msub></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\nWe consider two different specifications for the L\u00c3\u00a9vy process $L(t)$ driving $Y(t)$. On the one hand we consider an OU process where $L(t)=W(t)$\nis a standard Wiener process. In this case the conditional distribution of \n$Y(t+s)$ given $Y(t)$, $t \\in [0, T]$, $s \\in [0,T-t]$, is normal with the mean\n\n", "itemtype": "equation", "pos": 15630, "prevtext": "\nwhere $L(t)$ is a driving noise process with independent increments, i.e., a L\u00c3\u00a9vy process. The initial state of the process $Y$ is defined as the value at the left-hand limit $Y(0-)$ due to the possibility of a jump at time $0$. In equation (\\ref{eq:OUprocess}), $\\mu\\in\\mathbb{R}$ is the mean\nlevel to which the process tends to revert, $\\lambda^{-1}>0$ denotes\nthe speed of mean reversion and $\\sigma>0$ is the volatility of\nthe OU process.  The unique strong solution to the SDE (\\ref{eq:OUprocess}) is\ngiven by \n\n", "index": 3, "text": "\\begin{equation}\nY(t)=\\mu + (y_{0} - \\mu) e^{-\\lambda^{-1}t}+\\int_{0}^{t}\\sigma e^{-\\lambda^{-1}(t-s)}dL(s).\\label{eq:sol-OU}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"Y(t)=\\mu+(y_{0}-\\mu)e^{-\\lambda^{-1}t}+\\int_{0}^{t}\\sigma e^{-\\lambda^{-1}(t-s%&#10;)}dL(s).\" display=\"block\"><mrow><mrow><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mn>0</mn></msub><mo>-</mo><mi>\u03bc</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>t</mi></mrow></mrow></msup></mrow><mo>+</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>t</mi></msubsup><mrow><mi>\u03c3</mi><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo><mi>s</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>L</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nand the variance\n", "itemtype": "equation", "pos": 16074, "prevtext": "\n\nWe consider two different specifications for the L\u00c3\u00a9vy process $L(t)$ driving $Y(t)$. On the one hand we consider an OU process where $L(t)=W(t)$\nis a standard Wiener process. In this case the conditional distribution of \n$Y(t+s)$ given $Y(t)$, $t \\in [0, T]$, $s \\in [0,T-t]$, is normal with the mean\n\n", "index": 5, "text": "\n\\[\n\\mathbb{E}[Y(t+s)|Y(t)=y]=\\mu+\\left(y-\\mu\\right)e^{-\\lambda^{-1}s},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{E}[Y(t+s)|Y(t)=y]=\\mu+\\left(y-\\mu\\right)e^{-\\lambda^{-1}s},\" display=\"block\"><mrow><mi>\ud835\udd3c</mi><mrow><mo stretchy=\"false\">[</mo><mi>Y</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>Y</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>y</mi><mo stretchy=\"false\">]</mo></mrow><mo>=</mo><mi>\u03bc</mi><mo>+</mo><mrow><mo>(</mo><mi>y</mi><mo>-</mo><mi>\u03bc</mi><mo>)</mo></mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>s</mi></mrow></mrow></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nHence we call the process $Y(t)$ a Gaussian OU process. On the other hand we consider the case where $L(t)$ is a compound Poisson process, with the {\\em interval representation} \n\n", "itemtype": "equation", "pos": 16165, "prevtext": "\nand the variance\n", "index": 7, "text": "\n\\[\nVar[Y(t+s)|Y(t)=y]=\\lambda\\sigma^{2}(1-e^{-2\\lambda^{-1}s})/2.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"Var[Y(t+s)|Y(t)=y]=\\lambda\\sigma^{2}(1-e^{-2\\lambda^{-1}s})/2.\" display=\"block\"><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo stretchy=\"false\">[</mo><mi>Y</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">|</mo><mi>Y</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>y</mi><mo stretchy=\"false\">]</mo></mrow><mo>=</mo><mi>\u03bb</mi><msup><mi>\u03c3</mi><mn>2</mn></msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>s</mi></mrow></mrow></msup><mo stretchy=\"false\">)</mo></mrow><mo>/</mo><mn>2</mn><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere the $\\tau_{j}$ are the arrival times of a Poisson process and $\\xi_{j}$ represents the jump size at time $\\tau_{j}$ (these jump sizes are independent and identically distributed (i.i.d.) random variables). The dynamics of $Y(t)$ are explicitly given by\n\n", "itemtype": "equation", "pos": 16414, "prevtext": "\nHence we call the process $Y(t)$ a Gaussian OU process. On the other hand we consider the case where $L(t)$ is a compound Poisson process, with the {\\em interval representation} \n\n", "index": 9, "text": "\\begin{equation}\nL(t)=\\sum_{j=1}^{\\infty}\\xi_{j}1_{\\{t\\geq\\tau_{j}\\}},\\label{eq:interval-rep-for-L}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"L(t)=\\sum_{j=1}^{\\infty}\\xi_{j}1_{\\{t\\geq\\tau_{j}\\}},\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u221e</mi></munderover><mrow><msub><mi>\u03be</mi><mi>j</mi></msub><mo>\u2062</mo><msub><mn>1</mn><mrow><mo stretchy=\"false\">{</mo><mi>t</mi><mo>\u2265</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo stretchy=\"false\">}</mo></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nBelow we shall model the stochastic part of energy spot prices by superimposing a number of OU processes.\n\n\\subsection{A multi-factor model for energy spot prices\\label{sub:model-specification}}\n\n\nLet us denote by $X(t)$ the detrended and deseasonalised spot price at time $t\\geq0$ (presentation of the relation between $X(t)$ and the electricity spot price $S(t)$ is deferred until the end of this section). We assume that the deseasonalised price $X(t)$ is a sum of $n+1$ OU processes \n\n", "itemtype": "equation", "pos": 16788, "prevtext": "\nwhere the $\\tau_{j}$ are the arrival times of a Poisson process and $\\xi_{j}$ represents the jump size at time $\\tau_{j}$ (these jump sizes are independent and identically distributed (i.i.d.) random variables). The dynamics of $Y(t)$ are explicitly given by\n\n", "index": 11, "text": "\\begin{equation}\nY(t+s)=\\mu + (Y(t-) - \\mu) e^{-\\lambda^{-1}s}+\\sum_{j: t\\le\\tau_{j}\\leq t+s}e^{-\\lambda^{-1}(t+s-\\tau_{j})}\\xi_{j}, \\qquad s \\geq 0.\\label{eq:explicitY_Poisson}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"Y(t+s)=\\mu+(Y(t-)-\\mu)e^{-\\lambda^{-1}s}+\\sum_{j:t\\leq\\tau_{j}\\leq t+s}e^{-%&#10;\\lambda^{-1}(t+s-\\tau_{j})}\\xi_{j},\\qquad s\\geq 0.\" display=\"block\"><mrow><mrow><mrow><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>Y</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>\u03bc</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>s</mi></mrow></mrow></msup></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>:</mo><mrow><mi>t</mi><mo>\u2264</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>\u2264</mo><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow></mrow></mrow></munder><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03bb</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow><mo>-</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>\u2062</mo><msub><mi>\u03be</mi><mi>j</mi></msub></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>s</mi><mo>\u2265</mo><mn>0</mn></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $Y_{0}$ is a Gaussian OU process\n\\begin{eqnarray}\ndY_{0}(t) & = & \\lambda_{0}^{-1}(\\mu-Y_{0}(t))dt+\\sigma dW(t),\\quad Y_{0}(0)=y_{0},\\label{eq:Y0}\n\\end{eqnarray}\nand each $Y_{i},i\\geq1$ is a jump OU process\n\\begin{eqnarray}\ndY_{i}(t) & = & -\\lambda_{i}^{-1}Y_{i}(t)dt+dL_{i}(t),\\quad Y_{i}(0-)=y_{i},i=1,\\dots,n,\\label{eq:Yi}\n\\end{eqnarray}\neach $L_{i}$ being a (possibly inhomogeneous) compound Poisson process\nwith exponentially distributed jump sizes having mean $\\beta_{i}$. We will refer to this as the {\\em (n+1)-OU} model. The constants $w_{i}\\in\\{1,-1\\}$ are\nused to indicate whether positive or negative jumps are being modelled.\nNotice that each of the processes $Y_{i}(t),i\\geq1$, is non-negative since the $L_{i}$ are increasing processes.\nThus by setting $w_{i}=1$, we employ $Y_{i}(t)$ to capture positive\nprice spikes, whereas by setting $w_{i}=-1$,  $Y_{i}(t)$ is assumed to model\nnegative price spikes. Throughout we assume that $w_0$ is equal to 1.\n\nFor each compound Poisson process $L_i,i\\geq1$, we consider one of two specifications of the jump intensity rate. In the simpler specification we assume that the intensity rate is constant and equal to $\\eta_i$, and hence that jump frequency is independent of time. In the alternative specification we take account of periodicity in the jump rate as in \\citet{geman_understanding_2006} \nthrough the deterministic periodic intensity function\n\n", "itemtype": "equation", "pos": 17469, "prevtext": "\nBelow we shall model the stochastic part of energy spot prices by superimposing a number of OU processes.\n\n\\subsection{A multi-factor model for energy spot prices\\label{sub:model-specification}}\n\n\nLet us denote by $X(t)$ the detrended and deseasonalised spot price at time $t\\geq0$ (presentation of the relation between $X(t)$ and the electricity spot price $S(t)$ is deferred until the end of this section). We assume that the deseasonalised price $X(t)$ is a sum of $n+1$ OU processes \n\n", "index": 13, "text": "\\begin{equation}\nX(t)=\\sum_{i=0}^{n}w_{i}Y_{i}(t),\\label{eqn:superposition_model}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"X(t)=\\sum_{i=0}^{n}w_{i}Y_{i}(t),\" display=\"block\"><mrow><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>\u2062</mo><msub><mi>Y</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhich has period $k_i$ days, where $k_i \\in (0, \\infty)$ (see Figure \\ref{3c-EEX-average-number-pos-jumps} for a graph of the fitted intensity function $I_1$).\nThe parameter $\\eta_i \\in (0,\\infty)$ \nis the maximum jump rate \nwhilst the\nexponent $\\delta_i\\in(0,\\infty)$ controls the shape of \nthe periodic function.\n In order to have a compact notation covering both the above model specifications, the intensity function parameter vector associated with the process $Y_i$ will simply be denoted $\\vartheta_i$. In the constant intensity model specification we therefore understand that $\\vartheta_i=\\eta_i$, while in the periodic intensity model it is understood that $\\vartheta_i=(\\eta_i,\\theta_i,\\delta_i)$. \n\nWe aim to show that using the sum of a number of such OU processes\nprovides suitable flexibility for modelling electricity spot prices. A diffusive Gaussian component is used to model regular trading characterised by frequent small price variations. The jump components model the arrival of temporary system disturbances of various kinds causing imbalance between supply and demand.\nBy specifying two jump components, say, such that\n$\\lambda_{1}>\\lambda_{2}$, we can capture slowly and quickly decaying \nprice spikes. As discussed in \\cite{seifert_modelling_2007}, different decay rates may correspond to different {\\em physical causes} of spikes such as power plant outages or extreme changes in weather. The possibility of incorporating negative price spikes\nby taking $w_{i}=-1$  is explored in Section \\ref{sec:real}.\n\nIn the empirical studies of Section \\ref{sec:real} we assume that the relation between the spot price $S(t)$ and the deseasonalised price $X(t)$ is of the following form:\n\n", "itemtype": "equation", "pos": 18981, "prevtext": "\nwhere $Y_{0}$ is a Gaussian OU process\n\\begin{eqnarray}\ndY_{0}(t) & = & \\lambda_{0}^{-1}(\\mu-Y_{0}(t))dt+\\sigma dW(t),\\quad Y_{0}(0)=y_{0},\\label{eq:Y0}\n\\end{eqnarray}\nand each $Y_{i},i\\geq1$ is a jump OU process\n\\begin{eqnarray}\ndY_{i}(t) & = & -\\lambda_{i}^{-1}Y_{i}(t)dt+dL_{i}(t),\\quad Y_{i}(0-)=y_{i},i=1,\\dots,n,\\label{eq:Yi}\n\\end{eqnarray}\neach $L_{i}$ being a (possibly inhomogeneous) compound Poisson process\nwith exponentially distributed jump sizes having mean $\\beta_{i}$. We will refer to this as the {\\em (n+1)-OU} model. The constants $w_{i}\\in\\{1,-1\\}$ are\nused to indicate whether positive or negative jumps are being modelled.\nNotice that each of the processes $Y_{i}(t),i\\geq1$, is non-negative since the $L_{i}$ are increasing processes.\nThus by setting $w_{i}=1$, we employ $Y_{i}(t)$ to capture positive\nprice spikes, whereas by setting $w_{i}=-1$,  $Y_{i}(t)$ is assumed to model\nnegative price spikes. Throughout we assume that $w_0$ is equal to 1.\n\nFor each compound Poisson process $L_i,i\\geq1$, we consider one of two specifications of the jump intensity rate. In the simpler specification we assume that the intensity rate is constant and equal to $\\eta_i$, and hence that jump frequency is independent of time. In the alternative specification we take account of periodicity in the jump rate as in \\citet{geman_understanding_2006} \nthrough the deterministic periodic intensity function\n\n", "index": 15, "text": "\\begin{equation}\nI_i(\\eta_i,\\theta_i,\\delta_i,t) = \\eta_{i}\\left[\\frac{2}{1+|\\sin(\\pi(t-\\theta_{i})/k_i)|}-1\\right]^{\\delta_{i}},\n\\label{eq:periodic-intensity-rate}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"I_{i}(\\eta_{i},\\theta_{i},\\delta_{i},t)=\\eta_{i}\\left[\\frac{2}{1+|\\sin(\\pi(t-%&#10;\\theta_{i})/k_{i})|}-1\\right]^{\\delta_{i}},\" display=\"block\"><mrow><mrow><mrow><msub><mi>I</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03b7</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03b8</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03b4</mi><mi>i</mi></msub><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>\u03b7</mi><mi>i</mi></msub><mo>\u2062</mo><msup><mrow><mo>[</mo><mrow><mfrac><mn>2</mn><mrow><mn>1</mn><mo>+</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo><msub><mi>\u03b8</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>/</mo><msub><mi>k</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mfrac><mo>-</mo><mn>1</mn></mrow><mo>]</mo></mrow><msub><mi>\u03b4</mi><mi>i</mi></msub></msup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $f:[0,\\infty) \\rightarrow \\mathbb{R}$ is a deterministic bounded function that captures the long-term price trend and seasonality typically observed in energy spot prices. \nThe multiplicative seasonality in \\eqref{eq:Benth-spot} is in line with the exponential price trends standard in mathematical economics. We take\n\n", "itemtype": "equation", "pos": 20866, "prevtext": "\nwhich has period $k_i$ days, where $k_i \\in (0, \\infty)$ (see Figure \\ref{3c-EEX-average-number-pos-jumps} for a graph of the fitted intensity function $I_1$).\nThe parameter $\\eta_i \\in (0,\\infty)$ \nis the maximum jump rate \nwhilst the\nexponent $\\delta_i\\in(0,\\infty)$ controls the shape of \nthe periodic function.\n In order to have a compact notation covering both the above model specifications, the intensity function parameter vector associated with the process $Y_i$ will simply be denoted $\\vartheta_i$. In the constant intensity model specification we therefore understand that $\\vartheta_i=\\eta_i$, while in the periodic intensity model it is understood that $\\vartheta_i=(\\eta_i,\\theta_i,\\delta_i)$. \n\nWe aim to show that using the sum of a number of such OU processes\nprovides suitable flexibility for modelling electricity spot prices. A diffusive Gaussian component is used to model regular trading characterised by frequent small price variations. The jump components model the arrival of temporary system disturbances of various kinds causing imbalance between supply and demand.\nBy specifying two jump components, say, such that\n$\\lambda_{1}>\\lambda_{2}$, we can capture slowly and quickly decaying \nprice spikes. As discussed in \\cite{seifert_modelling_2007}, different decay rates may correspond to different {\\em physical causes} of spikes such as power plant outages or extreme changes in weather. The possibility of incorporating negative price spikes\nby taking $w_{i}=-1$  is explored in Section \\ref{sec:real}.\n\nIn the empirical studies of Section \\ref{sec:real} we assume that the relation between the spot price $S(t)$ and the deseasonalised price $X(t)$ is of the following form:\n\n", "index": 17, "text": "\\begin{equation}\nS(t)=e^{f(t)}X(t),\\label{eq:Benth-spot}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"S(t)=e^{f(t)}X(t),\" display=\"block\"><mrow><mrow><mrow><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>e</mi><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nalthough our methodology applies to any other specification of seasonality provided its effect can be removed from the series of spot prices prior to statistical inference for $X(t)$.\n\n\\begin{figure}\n\t\\begin{centering}\n\t\\includegraphics[scale=0.7]{figures/3c-EEX-average-number-Posjumps} \n\t\\par\\end{centering}\n\t\\caption{\\label{3c-EEX-average-number-pos-jumps}Monthly average number of positive jumps on the EEX market during 2000-6, together with the intensity function $I_1$ with parameter values taken from Table \\ref{tab:prior-3OU-EEX-5Lup-1} for the 3-OU-$I_1$ model.}\n\\end{figure}\n\n\n\\section{Inference} \\label{sec:inference}\n\n\nIn this section we present a Markov Chain Monte Carlo (MCMC) approach to Bayesian inference in the superposition model (\\ref{eqn:superposition_model}). We construct a Markov chain whose stationary distribution is the posterior distribution of the parameters in our model together with latent variables introduced to make the inference computationally tractable, see Section \\ref{sub:Data-augmentation}. The application of a Gibbs sampler allows single parameters or groups thereof to be updated conditioned on others being fixed -- a standard MCMC approach which aids computational tractability. Central to the performance of MCMC and particularly the Gibbs sampler is the notion of {\\em mixing} which is linked to the speed of convergence of the chain to its stationary distribution. Intuitively the better the mixing, the smaller the dependence between consecutive steps of the chain and, in effect, the less the chain gets blocked in small areas of the state space for long stretches of time. Mixing is negatively affected when the parameters which are updated at a given step of a Gibbs sampler depend on those upon which they are conditioned. This will be of particular importance in the choice of latent variables.\n\nIn Sections \\ref{sub:Data-augmentation}-\\ref{sec:MCMC_implementation} we present techniques for Bayesian inference in the superposition model (\\ref{eqn:superposition_model}) in the case of one jump OU component ($n=1$). This is then extended in Section \\ref{sec:Bayesian-inference-for-3-components}\nto the case of multiple jump components.  For simplicity, when it does not lead to ambiguity, we drop the subscript in the jump process\n$L_{1}$ and its parameters, so that $L=L_{1}$, $\\beta=\\beta_{1}$ and $\\vartheta=\\vartheta_{1}$. \n\n\\subsection{Data augmentation\\label{sub:Data-augmentation}}\n\nLet ${\\mathcal{X}}=\\{x_{0},\\dots,x_{N}\\}$ denote observations of the process (\\ref{eqn:superposition_model}) at times $0=t_{0},\\dots,t_{N}=T$, and $\\Delta_{i}=t_{i}-t_{i-1}>0$, $i=1,\\dots,N$,\nthe time increments between consecutive observations. The likelihood $\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\lambda_1, \\vartheta,\\beta)$ of the data given parameters is neither analytically tractable nor amenable to numerical integration since it involves an infinite sum of integrals over high dimensional spaces. However by augmenting the state space with observations ${\\mathcal{Y}}_{1}=\\{y_{1,0},\\ldots,y_{1,N}\\}$ of the process $Y_1$ at times  $t_{i}$,\nthe likelihood of ${\\mathcal{X}}$ given ${\\mathcal{Y}}_1$ becomes independent of $\\lambda_{1}$, $\\vartheta$ and $\\beta$. Thanks to the explicit form of the transition density of a Gaussian OU process we have\n\n", "itemtype": "equation", "pos": 21262, "prevtext": "\nwhere $f:[0,\\infty) \\rightarrow \\mathbb{R}$ is a deterministic bounded function that captures the long-term price trend and seasonality typically observed in energy spot prices. \nThe multiplicative seasonality in \\eqref{eq:Benth-spot} is in line with the exponential price trends standard in mathematical economics. We take\n\n", "index": 19, "text": "\\begin{equation}\nf(t; a_1, \\ldots, a_6)=a_{1}+a_{2}t+a_{3}\\sin(2\\pi t)+a_{4}\\cos(2\\pi t)+a_{5}\\sin(4\\pi t)+a_{6}\\cos(4\\pi t),\\label{eq:seasonal-trend}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"f(t;a_{1},\\ldots,a_{6})=a_{1}+a_{2}t+a_{3}\\sin(2\\pi t)+a_{4}\\cos(2\\pi t)+a_{5}%&#10;\\sin(4\\pi t)+a_{6}\\cos(4\\pi t),\" display=\"block\"><mrow><mrow><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>;</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><msub><mi>a</mi><mn>6</mn></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>a</mi><mn>1</mn></msub><mo>+</mo><mrow><msub><mi>a</mi><mn>2</mn></msub><mo>\u2062</mo><mi>t</mi></mrow><mo>+</mo><mrow><msub><mi>a</mi><mn>3</mn></msub><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><msub><mi>a</mi><mn>4</mn></msub><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><msub><mi>a</mi><mn>5</mn></msub><mo>\u2062</mo><mrow><mi>sin</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>4</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><msub><mi>a</mi><mn>6</mn></msub><mo>\u2062</mo><mrow><mi>cos</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>4</mn><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mi>t</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $\\Sigma_{i}^{2}=\\lambda_{0}\\sigma^{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_{i}})/2$ and \n\n", "itemtype": "equation", "pos": 24741, "prevtext": "\nalthough our methodology applies to any other specification of seasonality provided its effect can be removed from the series of spot prices prior to statistical inference for $X(t)$.\n\n\\begin{figure}\n\t\\begin{centering}\n\t\\includegraphics[scale=0.7]{figures/3c-EEX-average-number-Posjumps} \n\t\\par\\end{centering}\n\t\\caption{\\label{3c-EEX-average-number-pos-jumps}Monthly average number of positive jumps on the EEX market during 2000-6, together with the intensity function $I_1$ with parameter values taken from Table \\ref{tab:prior-3OU-EEX-5Lup-1} for the 3-OU-$I_1$ model.}\n\\end{figure}\n\n\n\\section{Inference} \\label{sec:inference}\n\n\nIn this section we present a Markov Chain Monte Carlo (MCMC) approach to Bayesian inference in the superposition model (\\ref{eqn:superposition_model}). We construct a Markov chain whose stationary distribution is the posterior distribution of the parameters in our model together with latent variables introduced to make the inference computationally tractable, see Section \\ref{sub:Data-augmentation}. The application of a Gibbs sampler allows single parameters or groups thereof to be updated conditioned on others being fixed -- a standard MCMC approach which aids computational tractability. Central to the performance of MCMC and particularly the Gibbs sampler is the notion of {\\em mixing} which is linked to the speed of convergence of the chain to its stationary distribution. Intuitively the better the mixing, the smaller the dependence between consecutive steps of the chain and, in effect, the less the chain gets blocked in small areas of the state space for long stretches of time. Mixing is negatively affected when the parameters which are updated at a given step of a Gibbs sampler depend on those upon which they are conditioned. This will be of particular importance in the choice of latent variables.\n\nIn Sections \\ref{sub:Data-augmentation}-\\ref{sec:MCMC_implementation} we present techniques for Bayesian inference in the superposition model (\\ref{eqn:superposition_model}) in the case of one jump OU component ($n=1$). This is then extended in Section \\ref{sec:Bayesian-inference-for-3-components}\nto the case of multiple jump components.  For simplicity, when it does not lead to ambiguity, we drop the subscript in the jump process\n$L_{1}$ and its parameters, so that $L=L_{1}$, $\\beta=\\beta_{1}$ and $\\vartheta=\\vartheta_{1}$. \n\n\\subsection{Data augmentation\\label{sub:Data-augmentation}}\n\nLet ${\\mathcal{X}}=\\{x_{0},\\dots,x_{N}\\}$ denote observations of the process (\\ref{eqn:superposition_model}) at times $0=t_{0},\\dots,t_{N}=T$, and $\\Delta_{i}=t_{i}-t_{i-1}>0$, $i=1,\\dots,N$,\nthe time increments between consecutive observations. The likelihood $\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\lambda_1, \\vartheta,\\beta)$ of the data given parameters is neither analytically tractable nor amenable to numerical integration since it involves an infinite sum of integrals over high dimensional spaces. However by augmenting the state space with observations ${\\mathcal{Y}}_{1}=\\{y_{1,0},\\ldots,y_{1,N}\\}$ of the process $Y_1$ at times  $t_{i}$,\nthe likelihood of ${\\mathcal{X}}$ given ${\\mathcal{Y}}_1$ becomes independent of $\\lambda_{1}$, $\\vartheta$ and $\\beta$. Thanks to the explicit form of the transition density of a Gaussian OU process we have\n\n", "index": 21, "text": "\\begin{equation}\n\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,{\\mathcal{Y}}_{1})=\\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\Sigma_{i}}\\exp\\left\\{ -\\frac{1}{2\\Sigma_{i}^{2}}\\left(z_{i}-\\mu-\\left(z_{i-1}-\\mu\\right)e^{-\\lambda_{0}^{-1}\\Delta_{i}}\\right)^{2}\\right\\} ,\\label{eq:likelihood}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,{\\mathcal{Y}}_{1})=\\prod_{i=1}^{N%&#10;}\\frac{1}{\\sqrt{2\\pi}\\Sigma_{i}}\\exp\\left\\{-\\frac{1}{2\\Sigma_{i}^{2}}\\left(z_{%&#10;i}-\\mu-\\left(z_{i-1}-\\mu\\right)e^{-\\lambda_{0}^{-1}\\Delta_{i}}\\right)^{2}%&#10;\\right\\},\" display=\"block\"><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mo>\u2062</mo><mi>\u03c0</mi></mrow></msqrt><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi></msub></mrow></mfrac><mi>exp</mi><mrow><mo>{</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mfrac><msup><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>-</mo><mi>\u03bc</mi><mo>-</mo><mrow><mo>(</mo><msub><mi>z</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>\u03bc</mi><mo>)</mo></mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup><mo>)</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\n\nSpace augmentation methods have been widely used in statistics to tackle computationally infeasible problems. However the choice of latent variables or processes has a profound influence on the properties of the resulting estimators, affecting in particular the mixing of a Markov chain approximating the posterior distribution. From a mathematical point of view, the body of work closest to the present inference problem is estimation in the context of stochastic volatility models, where the volatility process is driven by a jump process. Among these are the state space augmentations used in \\citep{jacquier_bayesian_1994,kim_stochastic_1998} and later criticised by\n\\citet[p. 188]{barndorff-nielsen_non-gaussian_2001} for high posterior correlation of the parameter $\\lambda_{1}$ with the input trajectory of the process $Y_{1}$. This correlation could lead to MCMC samplers based on this parameterisation performing poorly. Instead, \\citet{barndorff-nielsen_non-gaussian_2001} propose an alternative data augmentation scheme based\non a series representation of integrals with respect to a Possion process $L(t)$,  known as the Rosi\\'{n}ski or Ferguson-Klass representation. Bayesian inference for a stochastic volatility model under this parameterisation\nwas first explored in the discussion section of \\citet{barndorff-nielsen_non-gaussian_2001} and further developed in \\citet{griffin_inference_2006} and \\cite{fruhwirth2009bayesian}. In the present paper, however, we opt for the following more direct parametrisation independently suggested by several researchers (see, for example, \\citet{barndorff-nielsen_non-gaussian_2001} and  \\citet{roberts_bayesian_2004}). \n\nRecall from Section \\ref{sub:model-specification} that the process $L(t)$ driving $Y_1(t)$ is a compound Poisson process with intensity function $I(\\vartheta,t)$ and interval representation \\eqref{eq:interval-rep-for-L}. Recall also that\n\n", "itemtype": "equation", "pos": 25123, "prevtext": "\nwhere $\\Sigma_{i}^{2}=\\lambda_{0}\\sigma^{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_{i}})/2$ and \n\n", "index": 23, "text": "\\begin{equation}\nz_{i}=x_{i}-y_{1,i},\\quad i=0,\\dots,N.\\label{eq:process-Z-bayesian-inference}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"z_{i}=x_{i}-y_{1,i},\\quad i=0,\\dots,N.\" display=\"block\"><mrow><mrow><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>i</mi><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>N</mi></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhich motivates a data augmentation methodology where the set of pairs $\\{(\\tau_{j},\\xi_{j})\\}$, instead of the process $Y$,  is treated as the missing data. This has the benefit of introducing independence between $\\lambda_1$ and the latent variables, thus improving the mixing in Gibbs samplers.\n\nLet us denote by $\\Phi$ the marked Poisson process on $S=[0,T]\\times (0,\\infty)$\nwith locations $\\tau_{i}$ on $[0,T]$ and marks $\\xi_{i}$ on $(0,\\infty)$.\nThe probability density of $\\Phi$ is defined relative to a {\\em dominating measure}, namely that of a Poisson process with unit intensity on $[0,T]$ and exponential jump sizes with parameter $1$. Hence, thanks to the marking theorem \\citep{kingman_poisson_1992} and the likelihood ratio formula in \\cite{kutoyants_statistical_1998}, the density of $\\Phi$ with respect to this dominating measure is\n\n", "itemtype": "equation", "pos": 27149, "prevtext": "\n\n\nSpace augmentation methods have been widely used in statistics to tackle computationally infeasible problems. However the choice of latent variables or processes has a profound influence on the properties of the resulting estimators, affecting in particular the mixing of a Markov chain approximating the posterior distribution. From a mathematical point of view, the body of work closest to the present inference problem is estimation in the context of stochastic volatility models, where the volatility process is driven by a jump process. Among these are the state space augmentations used in \\citep{jacquier_bayesian_1994,kim_stochastic_1998} and later criticised by\n\\citet[p. 188]{barndorff-nielsen_non-gaussian_2001} for high posterior correlation of the parameter $\\lambda_{1}$ with the input trajectory of the process $Y_{1}$. This correlation could lead to MCMC samplers based on this parameterisation performing poorly. Instead, \\citet{barndorff-nielsen_non-gaussian_2001} propose an alternative data augmentation scheme based\non a series representation of integrals with respect to a Possion process $L(t)$,  known as the Rosi\\'{n}ski or Ferguson-Klass representation. Bayesian inference for a stochastic volatility model under this parameterisation\nwas first explored in the discussion section of \\citet{barndorff-nielsen_non-gaussian_2001} and further developed in \\citet{griffin_inference_2006} and \\cite{fruhwirth2009bayesian}. In the present paper, however, we opt for the following more direct parametrisation independently suggested by several researchers (see, for example, \\citet{barndorff-nielsen_non-gaussian_2001} and  \\citet{roberts_bayesian_2004}). \n\nRecall from Section \\ref{sub:model-specification} that the process $L(t)$ driving $Y_1(t)$ is a compound Poisson process with intensity function $I(\\vartheta,t)$ and interval representation \\eqref{eq:interval-rep-for-L}. Recall also that\n\n", "index": 25, "text": "\\begin{equation}\nY_1(t+s)=Y_1(t-)e^{-\\lambda_1^{-1}s}+\\sum_{j: t\\le\\tau_{j}\\leq t+s}e^{-\\lambda_1^{-1}(t+s-\\tau_{j})}\\xi_{j}, \\qquad s \\geq 0,\\label{eq:explicitY2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"Y_{1}(t+s)=Y_{1}(t-)e^{-\\lambda_{1}^{-1}s}+\\sum_{j:t\\leq\\tau_{j}\\leq t+s}e^{-%&#10;\\lambda_{1}^{-1}(t+s-\\tau_{j})}\\xi_{j},\\qquad s\\geq 0,\" display=\"block\"><mrow><mrow><mrow><mrow><msub><mi>Y</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>Y</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>t</mi><mo>-</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mi>s</mi></mrow></mrow></msup></mrow><mo>+</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>:</mo><mrow><mi>t</mi><mo>\u2264</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>\u2264</mo><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow></mrow></mrow></munder><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>t</mi><mo>+</mo><mi>s</mi></mrow><mo>-</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup><mo>\u2062</mo><msub><mi>\u03be</mi><mi>j</mi></msub></mrow></mrow></mrow></mrow><mo rspace=\"22.5pt\">,</mo><mrow><mi>s</mi><mo>\u2265</mo><mn>0</mn></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $N_T$ is the number of points in $S$. Here $L(\\vartheta;\\Phi)$ is the density, with respect to the Poisson process with unit intensity, of the Poisson process with intensity $I(\\vartheta, t)$:\n\n", "itemtype": "equation", "pos": 28180, "prevtext": "\nwhich motivates a data augmentation methodology where the set of pairs $\\{(\\tau_{j},\\xi_{j})\\}$, instead of the process $Y$,  is treated as the missing data. This has the benefit of introducing independence between $\\lambda_1$ and the latent variables, thus improving the mixing in Gibbs samplers.\n\nLet us denote by $\\Phi$ the marked Poisson process on $S=[0,T]\\times (0,\\infty)$\nwith locations $\\tau_{i}$ on $[0,T]$ and marks $\\xi_{i}$ on $(0,\\infty)$.\nThe probability density of $\\Phi$ is defined relative to a {\\em dominating measure}, namely that of a Poisson process with unit intensity on $[0,T]$ and exponential jump sizes with parameter $1$. Hence, thanks to the marking theorem \\citep{kingman_poisson_1992} and the likelihood ratio formula in \\cite{kutoyants_statistical_1998}, the density of $\\Phi$ with respect to this dominating measure is\n\n", "index": 27, "text": "\\begin{equation} \\label{eqn:density_of_Phi}\n\\ell(\\Phi\\mid\\vartheta,\\beta) = L(\\vartheta;\\Phi) \\cdot \\beta^{-N_T}\\exp\\Big\\{-(\\beta^{-1}-1)\\sum_{j=1}^{N_T}\\xi_{j}\\Big\\},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"\\ell(\\Phi\\mid\\vartheta,\\beta)=L(\\vartheta;\\Phi)\\cdot\\beta^{-N_{T}}\\exp\\Big{\\{}%&#10;-(\\beta^{-1}-1)\\sum_{j=1}^{N_{T}}\\xi_{j}\\Big{\\}},\" display=\"block\"><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2223</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>L</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>;</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u22c5</mo><msup><mi>\u03b2</mi><mrow><mo>-</mo><msub><mi>N</mi><mi>T</mi></msub></mrow></msup><mi>exp</mi><mrow><mo maxsize=\"160%\" minsize=\"160%\">{</mo><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>-</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>T</mi></msub></munderover><msub><mi>\u03be</mi><mi>j</mi></msub><mo maxsize=\"160%\" minsize=\"160%\">}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nWhen $L$ is a homogeneous Poisson process with constant intensity $\\eta$ we obtain\n\n", "itemtype": "equation", "pos": 28562, "prevtext": "\nwhere $N_T$ is the number of points in $S$. Here $L(\\vartheta;\\Phi)$ is the density, with respect to the Poisson process with unit intensity, of the Poisson process with intensity $I(\\vartheta, t)$:\n\n", "index": 29, "text": "\\begin{equation}\\label{eqn:density_L}\nL(\\vartheta;\\Phi) = \\exp \\left\\lbrace \\sum_{j=1}^{N_T} \\log I(\\vartheta,\\tau_j)\n\t\t\t\t- \\int_{0}^{T} I(\\vartheta,t)dt + T \n\t \\right\\rbrace.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"L(\\vartheta;\\Phi)=\\exp\\left\\{\\sum_{j=1}^{N_{T}}\\log I(\\vartheta,\\tau_{j})-\\int%&#10;_{0}^{T}I(\\vartheta,t)dt+T\\right\\}.\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>;</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>T</mi></msub></munderover><mrow><mrow><mi>log</mi><mo>\u2061</mo><mi>I</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>T</mi></msubsup><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo>\ud835\udc51</mo><mi>t</mi></mrow></mrow></mrow></mrow><mo>+</mo><mi>T</mi></mrow><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\nWe will use a Gibbs sampler  to simulate from the posterior distribution of the parameters and the missing data $\\Phi$ given the observed data ${\\mathcal{X}}$, using the factorisation\n\n", "itemtype": "equation", "pos": 28836, "prevtext": "\nWhen $L$ is a homogeneous Poisson process with constant intensity $\\eta$ we obtain\n\n", "index": 31, "text": "\\begin{equation}\nL(\\vartheta;\\Phi)=\\exp\\big\\{-(\\eta-1)T\\big\\} \\eta^{N_T}.\\label{eq:Poisson-likelihood}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"L(\\vartheta;\\Phi)=\\exp\\big{\\{}-(\\eta-1)T\\big{\\}}\\eta^{N_{T}}.\" display=\"block\"><mrow><mrow><mrow><mi>L</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>;</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">{</mo><mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03b7</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>T</mi></mrow></mrow><mo maxsize=\"120%\" minsize=\"120%\">}</mo></mrow></mrow><mo>\u2062</mo><msup><mi>\u03b7</mi><msub><mi>N</mi><mi>T</mi></msub></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_1,\\vartheta,\\beta)$ is the\njoint prior density of the parameters.\n\n\\subsection{Classes of prior distributions}\n\\label{sec:priorspecification}\nTo complete our Bayesian model we now specify classes of prior\ndistributions for the parameters, which are assumed to be mutually independent\\footnote{In Section \\ref{sec:Bayesian-inference-for-3-components} and following, where more than one jump OU component is considered, the only statistical dependence we assume is a strict ordering of the mean reversion parameters $\\lambda_{j}$, $j=1,\\dots,n$ when this is needed for identifiability.}. For computational efficiency the classes chosen correspond to conjugate priors where possible.\nIn the empirical studies presented in Section \\ref{sec:real} the prior distributions are chosen with a large spread (for example variance, where this exists) in order to {\\em let the data speak for itself}. Prior expectations are based on existing results in the literature, combined with further exploratory analysis of historical data as necessary. For details see the Appendix. Of course users of our methodology may also have prior beliefs about the model parameters, and in our Bayesian context the prior distributions  may alternatively be chosen to reflect these beliefs where appropriate.\n\n We specify a N$(a_{\\mu},b_{\\mu}^{2})$\nprior distribution for the mean level $\\mu$ of the Gaussian OU component, an $\\mbox{IG}(a_{\\sigma},b_{\\sigma})$\nfor its volatility $\\sigma^{2}$, an $\\mbox{IG}(a_{\\beta},b_{\\beta})$ for the jump size parameter $\\beta$ and an $\\mbox{IG}(a_{\\lambda_i},b_{\\lambda_i})$\nfor the mean reversion parameter  $\\lambda_i$, $i=0,1$. For the intensity function a $\\mbox{Ga}(a_{\\eta},b_{\\eta})$ prior is chosen for $\\eta$. Further when the intensity is periodic, a $\\mbox{Ga}(a_{\\delta},b_{\\delta})$ prior is taken for $\\delta$ and a $\\mbox{U}(a_{\\theta},b_{\\theta})$ prior for $\\theta$ (cf. \\eqref{eq:periodic-intensity-rate}).\n\n\n\\subsection{MCMC algorithm}\\label{sec:MCMC_implementation}\nIn the algorithm below the Gibbs step for updating the $\\lambda_i$ employs a random-walk Metropolis-Hastings procedure. To ensure that the mixing is of the same order for small and large values of $\\lambda_i$ the step of the proposal should be state dependent; equivalently an appropriate transformation of $\\lambda_i$ may be applied. For computational convenience we opt for the latter, swapping $\\lambda_i$ in the inference procedure with $\\rho_i=e^{-\\lambda_{i}^{-1}}$. \n\nAfter setting the initial state of the chain, the MCMC algorithm applied below cycles through the following steps:\n\n\n\\subsubsection*{MCMC algorithm for the 2-OU model}\n\n\\noindent Step 1: update $\\mu \\sim \\pi(\\mu\\mid \\rho_{0},\\sigma, \\rho_1, {\\mathcal{X}}, \\Phi)$\\\\\nStep 2: update $\\sigma^{2} \\sim \\pi(\\sigma^2 \\mid \\rho_{0}, \\rho_1, {\\mathcal{X}}, \\Phi)$\\\\\nStep 3: update $\\rho_{0}, \\rho_1 \\sim \\pi(\\rho_{0},\\rho_1\\mid \\mu, \\sigma, {\\mathcal{X}}, \\Phi)$\\\\\nStep 4: update $\\vartheta \\sim \\pi(\\vartheta \\mid \\Phi)$ \\\\\nStep 5: update $\\beta \\sim \\pi (\\beta \\mid \\Phi)$\\\\\nStep 6: update $\\Phi \\sim \\pi(\\Phi \\mid \\mu,\\rho_{0},\\sigma,\\rho_1, \\vartheta, \\beta, {\\mathcal{X}})$\n\\\\\nStep 7: Go to step 1.\\\\\n\\\\\nBelow we provide more details about each of these steps.\n\n\n\\subsubsection*{Step 1. Update $\\mu$}\n\nRecalling \\eqref{eq:likelihood}, the likelihood of the observed data conditional on the augmented state $(\\mu,\\lambda_{0},\\sigma,\\rho_1,\\Phi)$ is\n", "itemtype": "equation", "pos": 29139, "prevtext": "\n\nWe will use a Gibbs sampler  to simulate from the posterior distribution of the parameters and the missing data $\\Phi$ given the observed data ${\\mathcal{X}}$, using the factorisation\n\n", "index": 33, "text": "\\begin{equation}\n\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_1,\\vartheta,\\beta,\\Phi\\mid {\\mathcal{X}})\\propto\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\lambda_1,\\Phi)\\ell(\\Phi\\mid\\vartheta,\\beta)\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_1,\\vartheta,\\beta),\\label{eq:posterior}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\vartheta,\\beta,\\Phi\\mid{\\mathcal{X}})%&#10;\\propto\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\Phi)\\ell(\\Phi%&#10;\\mid\\vartheta,\\beta)\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\vartheta,\\beta),\" display=\"block\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>,</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2223</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2223</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>,</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $\\Sigma_i^{2}=\\lambda_{0}\\sigma^{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_i})/2$ and the $z_i$ are computed as the difference between the observations of $X$ and the trajectory of $Y$ implied by the realisation $\\Phi$ of the marked Poisson process. Using the conjugate prior for $\\mu$ specified in the previous section it can be easily shown that the conditional distribution $\\pi(\\mu\\mid \\rho_0, \\sigma,\\rho_1, {\\mathcal{X}}, \\Phi)$ is\n", "itemtype": "equation", "pos": 32872, "prevtext": "\nwhere $\\pi(\\mu,\\lambda_{0},\\sigma,\\lambda_1,\\vartheta,\\beta)$ is the\njoint prior density of the parameters.\n\n\\subsection{Classes of prior distributions}\n\\label{sec:priorspecification}\nTo complete our Bayesian model we now specify classes of prior\ndistributions for the parameters, which are assumed to be mutually independent\\footnote{In Section \\ref{sec:Bayesian-inference-for-3-components} and following, where more than one jump OU component is considered, the only statistical dependence we assume is a strict ordering of the mean reversion parameters $\\lambda_{j}$, $j=1,\\dots,n$ when this is needed for identifiability.}. For computational efficiency the classes chosen correspond to conjugate priors where possible.\nIn the empirical studies presented in Section \\ref{sec:real} the prior distributions are chosen with a large spread (for example variance, where this exists) in order to {\\em let the data speak for itself}. Prior expectations are based on existing results in the literature, combined with further exploratory analysis of historical data as necessary. For details see the Appendix. Of course users of our methodology may also have prior beliefs about the model parameters, and in our Bayesian context the prior distributions  may alternatively be chosen to reflect these beliefs where appropriate.\n\n We specify a N$(a_{\\mu},b_{\\mu}^{2})$\nprior distribution for the mean level $\\mu$ of the Gaussian OU component, an $\\mbox{IG}(a_{\\sigma},b_{\\sigma})$\nfor its volatility $\\sigma^{2}$, an $\\mbox{IG}(a_{\\beta},b_{\\beta})$ for the jump size parameter $\\beta$ and an $\\mbox{IG}(a_{\\lambda_i},b_{\\lambda_i})$\nfor the mean reversion parameter  $\\lambda_i$, $i=0,1$. For the intensity function a $\\mbox{Ga}(a_{\\eta},b_{\\eta})$ prior is chosen for $\\eta$. Further when the intensity is periodic, a $\\mbox{Ga}(a_{\\delta},b_{\\delta})$ prior is taken for $\\delta$ and a $\\mbox{U}(a_{\\theta},b_{\\theta})$ prior for $\\theta$ (cf. \\eqref{eq:periodic-intensity-rate}).\n\n\n\\subsection{MCMC algorithm}\\label{sec:MCMC_implementation}\nIn the algorithm below the Gibbs step for updating the $\\lambda_i$ employs a random-walk Metropolis-Hastings procedure. To ensure that the mixing is of the same order for small and large values of $\\lambda_i$ the step of the proposal should be state dependent; equivalently an appropriate transformation of $\\lambda_i$ may be applied. For computational convenience we opt for the latter, swapping $\\lambda_i$ in the inference procedure with $\\rho_i=e^{-\\lambda_{i}^{-1}}$. \n\nAfter setting the initial state of the chain, the MCMC algorithm applied below cycles through the following steps:\n\n\n\\subsubsection*{MCMC algorithm for the 2-OU model}\n\n\\noindent Step 1: update $\\mu \\sim \\pi(\\mu\\mid \\rho_{0},\\sigma, \\rho_1, {\\mathcal{X}}, \\Phi)$\\\\\nStep 2: update $\\sigma^{2} \\sim \\pi(\\sigma^2 \\mid \\rho_{0}, \\rho_1, {\\mathcal{X}}, \\Phi)$\\\\\nStep 3: update $\\rho_{0}, \\rho_1 \\sim \\pi(\\rho_{0},\\rho_1\\mid \\mu, \\sigma, {\\mathcal{X}}, \\Phi)$\\\\\nStep 4: update $\\vartheta \\sim \\pi(\\vartheta \\mid \\Phi)$ \\\\\nStep 5: update $\\beta \\sim \\pi (\\beta \\mid \\Phi)$\\\\\nStep 6: update $\\Phi \\sim \\pi(\\Phi \\mid \\mu,\\rho_{0},\\sigma,\\rho_1, \\vartheta, \\beta, {\\mathcal{X}})$\n\\\\\nStep 7: Go to step 1.\\\\\n\\\\\nBelow we provide more details about each of these steps.\n\n\n\\subsubsection*{Step 1. Update $\\mu$}\n\nRecalling \\eqref{eq:likelihood}, the likelihood of the observed data conditional on the augmented state $(\\mu,\\lambda_{0},\\sigma,\\rho_1,\\Phi)$ is\n", "index": 35, "text": "\n\\[\n\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\rho_1,\\Phi)\n\\propto \\frac{1}{\\prod_{i=1}^N\\Sigma_i}\\exp\\left\\{ -\\frac{1}{2}\\sum_{i=1}^{N}\\frac{1}{\\Sigma_i^{2}}\\left(z_{i} - z_{i-1} e^{-\\lambda_{0}^{-1}\\Delta_i}+\\mu\\left(e^{-\\lambda_{0}^{-1}\\Delta_i}-1\\right)\\right)^{2}\\right\\},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\ell({\\mathcal{X}}\\mid\\mu,\\lambda_{0},\\sigma,\\rho_{1},\\Phi)\\propto\\frac{1}{%&#10;\\prod_{i=1}^{N}\\Sigma_{i}}\\exp\\left\\{-\\frac{1}{2}\\sum_{i=1}^{N}\\frac{1}{\\Sigma%&#10;_{i}^{2}}\\left(z_{i}-z_{i-1}e^{-\\lambda_{0}^{-1}\\Delta_{i}}+\\mu\\left(e^{-%&#10;\\lambda_{0}^{-1}\\Delta_{i}}-1\\right)\\right)^{2}\\right\\},\" display=\"block\"><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><mfrac><mn>1</mn><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi></msub></mrow></mfrac><mi>exp</mi><mrow><mo>{</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mn>1</mn><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi><mn>2</mn></msubsup></mfrac><msup><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>-</mo><msub><mi>z</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup><mo>+</mo><mi>\u03bc</mi><mrow><mo>(</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>}</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\n\n\\subsubsection*{Step 2. Update $\\sigma^{2}$}\n\nDue to the choice of prior, the conditional distribution $\\pi(\\sigma^2 \\mid \\rho_{0}, \\rho_1, {\\mathcal{X}}, \\Phi)$ has the closed form\n", "itemtype": "equation", "pos": 33590, "prevtext": "\nwhere $\\Sigma_i^{2}=\\lambda_{0}\\sigma^{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_i})/2$ and the $z_i$ are computed as the difference between the observations of $X$ and the trajectory of $Y$ implied by the realisation $\\Phi$ of the marked Poisson process. Using the conjugate prior for $\\mu$ specified in the previous section it can be easily shown that the conditional distribution $\\pi(\\mu\\mid \\rho_0, \\sigma,\\rho_1, {\\mathcal{X}}, \\Phi)$ is\n", "index": 37, "text": "\n\\[\n\\mbox{N}\\left(\n\\frac{\n\\sum_{i=1}^{N}\n\\left(1-e^{-\\lambda_{0}^{-1}\\Delta_i}\\right)\\Sigma_i^{-2}\n\\left(z_{i}-z_{i-1}e^{-\\lambda_{0}^{-1}\\Delta_i}\\right)\n+\\frac{a_{\\mu}}{\\sigma_{0}^{2}}\n}\n{\\sum_{i=1}^N\\left(1-e^{-\\lambda_{0}^{-1}\\Delta_i}\\right)^{2}\\Sigma_i^{-2}\n+\\frac{1}{b_{\\mu}^{2}}},\n\\frac{1}{\\sum_{i=1}^N\\left(1-e^{-\\lambda_{0}^{-1}\\Delta_i}\\right)^{2}\\Sigma_i^{-2}\n+\\frac{1}{b_{\\mu}^{2}}}\\right).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\mbox{N}\\left(\\frac{\\sum_{i=1}^{N}\\left(1-e^{-\\lambda_{0}^{-1}\\Delta_{i}}%&#10;\\right)\\Sigma_{i}^{-2}\\left(z_{i}-z_{i-1}e^{-\\lambda_{0}^{-1}\\Delta_{i}}\\right%&#10;)+\\frac{a_{\\mu}}{\\sigma_{0}^{2}}}{\\sum_{i=1}^{N}\\left(1-e^{-\\lambda_{0}^{-1}%&#10;\\Delta_{i}}\\right)^{2}\\Sigma_{i}^{-2}+\\frac{1}{b_{\\mu}^{2}}},\\frac{1}{\\sum_{i=%&#10;1}^{N}\\left(1-e^{-\\lambda_{0}^{-1}\\Delta_{i}}\\right)^{2}\\Sigma_{i}^{-2}+\\frac{%&#10;1}{b_{\\mu}^{2}}}\\right).\" display=\"block\"><mrow><mrow><mtext>N</mtext><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow><mo>)</mo></mrow><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi><mrow><mo>-</mo><mn>2</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>-</mo><mrow><msub><mi>z</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>+</mo><mfrac><msub><mi>a</mi><mi>\u03bc</mi></msub><msubsup><mi>\u03c3</mi><mn>0</mn><mn>2</mn></msubsup></mfrac></mrow><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi><mrow><mo>-</mo><mn>2</mn></mrow></msubsup></mrow></mrow><mo>+</mo><mfrac><mn>1</mn><msubsup><mi>b</mi><mi>\u03bc</mi><mn>2</mn></msubsup></mfrac></mrow></mfrac><mo>,</mo><mfrac><mn>1</mn><mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup><mo>\u2062</mo><msubsup><mi mathvariant=\"normal\">\u03a3</mi><mi>i</mi><mrow><mo>-</mo><mn>2</mn></mrow></msubsup></mrow></mrow><mo>+</mo><mfrac><mn>1</mn><msubsup><mi>b</mi><mi>\u03bc</mi><mn>2</mn></msubsup></mfrac></mrow></mfrac><mo>)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere\n", "itemtype": "equation", "pos": 34180, "prevtext": "\n\n\n\\subsubsection*{Step 2. Update $\\sigma^{2}$}\n\nDue to the choice of prior, the conditional distribution $\\pi(\\sigma^2 \\mid \\rho_{0}, \\rho_1, {\\mathcal{X}}, \\Phi)$ has the closed form\n", "index": 39, "text": "\n\\[\n\n\\mbox{IG}\\left(\n\\frac{N}{2}+a_{\\sigma},\\frac{1}{\\lambda_0}\\sum_{i=1}^{N}\\frac{s_i}{(1-e^{-2\\lambda_{0}^{-1}\\Delta_i})}\n+b_{\\sigma}\\right\n),\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;\\mbox{IG}\\left(\\frac{N}{2}+a_{\\sigma},\\frac{1}{\\lambda_{0}}\\sum_{i=1}^{N}%&#10;\\frac{s_{i}}{(1-e^{-2\\lambda_{0}^{-1}\\Delta_{i}})}+b_{\\sigma}\\right),\" display=\"block\"><mrow><mrow><mtext>IG</mtext><mo>\u2062</mo><mrow><mo>(</mo><mrow><mfrac><mi>N</mi><mn>2</mn></mfrac><mo>+</mo><msub><mi>a</mi><mi>\u03c3</mi></msub></mrow><mo>,</mo><mrow><mrow><mfrac><mn>1</mn><msub><mi>\u03bb</mi><mn>0</mn></msub></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><msub><mi>s</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow></mrow><mo>+</mo><msub><mi>b</mi><mi>\u03c3</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\n\\subsubsection*{Step 3. Update $\\rho_0$ and $\\rho$}\n\nExplicit conditional distributions for $\\rho_0$ and $\\rho$ are not available and the density is only known up to a multiplicative constant:\n\n", "itemtype": "equation", "pos": 34333, "prevtext": "\nwhere\n", "index": 41, "text": "\n\\[\ns_i=\\left(z_{i}-z_{i-1}e^{-\\lambda_{0}^{-1}\\Delta_i}+\\mu\\left(e^{-\\lambda_{0}^{-1}\\Delta_i}-1\\right)\\right)^{2}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"s_{i}=\\left(z_{i}-z_{i-1}e^{-\\lambda_{0}^{-1}\\Delta_{i}}+\\mu\\left(e^{-\\lambda_%&#10;{0}^{-1}\\Delta_{i}}-1\\right)\\right)^{2}.\" display=\"block\"><mrow><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><msup><mrow><mo>(</mo><mrow><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>-</mo><mrow><msub><mi>z</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup></mrow></mrow><mo>+</mo><mrow><mi>\u03bc</mi><mo>\u2062</mo><mrow><mo>(</mo><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>i</mi></msub></mrow></mrow></msup><mo>-</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nHence we use a random-walk Metropolis-Hastings within Gibbs procedure to update $\\rho_0$ and $\\rho_1$.\nThe variance of the proposal distribution is tuned after pilot runs in order to achieve an acceptance rate between $20\\%$ and $50\\%$.\n\n\\subsubsection*{Step 4. Update $\\vartheta$}\n\nIn the case of constant intensity function, the conjugate prior for $\\eta$ yields an explicit conditional distribution\n\n", "itemtype": "equation", "pos": 34647, "prevtext": "\n\n\\subsubsection*{Step 3. Update $\\rho_0$ and $\\rho$}\n\nExplicit conditional distributions for $\\rho_0$ and $\\rho$ are not available and the density is only known up to a multiplicative constant:\n\n", "index": 43, "text": "\\begin{align*}\n\\pi(\\rho_{0}\\mid\\mu,\\sigma,\\rho_1,{\\mathcal{X}},\\Phi) &\\propto \\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1, \\Phi)\\pi(\\rho_{0}),\\\\\n\\pi(\\rho_1\\mid\\mu,\\sigma,\\rho_{0},{\\mathcal{X}},\\Phi)& \\propto \\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1,\\Phi)\\pi(\\rho_1).\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\pi(\\rho_{0}\\mid\\mu,\\sigma,\\rho_{1},{\\mathcal{X}},\\Phi)\" display=\"inline\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_{1},\\Phi)%&#10;\\pi(\\rho_{0}),\" display=\"inline\"><mrow><mo>\u221d</mo><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\pi(\\rho_{1}\\mid\\mu,\\sigma,\\rho_{0},{\\mathcal{X}},\\Phi)\" display=\"inline\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\propto\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_{1},\\Phi)%&#10;\\pi(\\rho_{1}).\" display=\"inline\"><mrow><mo>\u221d</mo><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nWhen the intensity function is time dependent we employ a random-walk Metropolis-Hastings within Gibbs procedure to update $\\eta,\\theta$ and $\\delta$:\n", "itemtype": "equation", "pos": 35342, "prevtext": "\nHence we use a random-walk Metropolis-Hastings within Gibbs procedure to update $\\rho_0$ and $\\rho_1$.\nThe variance of the proposal distribution is tuned after pilot runs in order to achieve an acceptance rate between $20\\%$ and $50\\%$.\n\n\\subsubsection*{Step 4. Update $\\vartheta$}\n\nIn the case of constant intensity function, the conjugate prior for $\\eta$ yields an explicit conditional distribution\n\n", "index": 45, "text": "\\begin{align*}\n\\eta \\mid \\Phi &\\sim \\text{Ga} \\left(a_\\eta + N_T, T + b_\\eta \\right).\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\eta\\mid\\Phi\" display=\"inline\"><mrow><mi>\u03b7</mi><mo>\u2223</mo><mi mathvariant=\"normal\">\u03a6</mi></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sim\\text{Ga}\\left(a_{\\eta}+N_{T},T+b_{\\eta}\\right).\" display=\"inline\"><mrow><mrow><mi/><mo>\u223c</mo><mrow><mtext>Ga</mtext><mo>\u2062</mo><mrow><mo>(</mo><mrow><msub><mi>a</mi><mi>\u03b7</mi></msub><mo>+</mo><msub><mi>N</mi><mi>T</mi></msub></mrow><mo>,</mo><mrow><mi>T</mi><mo>+</mo><msub><mi>b</mi><mi>\u03b7</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nHere the non-explicit function $L(\\vartheta |\\Phi)$ of \\eqref{eqn:density_L} is numerically calculated by a quadrature method. The variance of the proposal distribution is tuned after pilot runs as above.\n\\subsubsection*{Step 5. Update $\\beta$}\nThe conditional distribution of $\\beta$ given $\\Phi$ has the closed form\n", "itemtype": "equation", "pos": 35591, "prevtext": "\nWhen the intensity function is time dependent we employ a random-walk Metropolis-Hastings within Gibbs procedure to update $\\eta,\\theta$ and $\\delta$:\n", "index": 47, "text": "\n\\[\n\\pi(\\eta,\\theta,\\delta \\mid \\Phi) \\propto \\ell(\\Phi\\mid\\eta,\\theta,\\delta) \\pi(\\eta)\\pi(\\theta) \\pi(\\delta).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\pi(\\eta,\\theta,\\delta\\mid\\Phi)\\propto\\ell(\\Phi\\mid\\eta,\\theta,\\delta)\\pi(\\eta%&#10;)\\pi(\\theta)\\pi(\\delta).\" display=\"block\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b7</mi><mo>,</mo><mi>\u03b8</mi><mo>,</mo><mi>\u03b4</mi><mo>\u2223</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u221d</mo><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2223</mo><mi>\u03b7</mi><mo>,</mo><mi>\u03b8</mi><mo>,</mo><mi>\u03b4</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b7</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03b4</mi><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\n\\subsubsection{Step 6. Update the latent process $\\Phi$ }\n\\label{sec:phiupdate}\n\nThe Metropolis-Hastings step we use to update the process $\\Phi$ draws from the work of \\citet{geyer_simulation_1994}, \\citet{roberts_bayesian_2004} and \\citet{fruhwirth2009bayesian} on MCMC techniques for simulating point processes, extending it where appropriate to the case of inhomogeneous Poisson processes. \n\nLet us assume that the current state of the Markov chain is \n", "itemtype": "equation", "pos": 36024, "prevtext": "\nHere the non-explicit function $L(\\vartheta |\\Phi)$ of \\eqref{eqn:density_L} is numerically calculated by a quadrature method. The variance of the proposal distribution is tuned after pilot runs as above.\n\\subsubsection*{Step 5. Update $\\beta$}\nThe conditional distribution of $\\beta$ given $\\Phi$ has the closed form\n", "index": 49, "text": "\n\\[\n\\beta\\mid \\Phi \\sim \\text{IG} \\left(a_{\\beta}+N_T,\\sum_{i=1}^{N_T}\\xi_{i}+b_{\\beta}\\right).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex11.m1\" class=\"ltx_Math\" alttext=\"\\beta\\mid\\Phi\\sim\\text{IG}\\left(a_{\\beta}+N_{T},\\sum_{i=1}^{N_{T}}\\xi_{i}+b_{%&#10;\\beta}\\right).\" display=\"block\"><mrow><mi>\u03b2</mi><mo>\u2223</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u223c</mo><mtext>IG</mtext><mrow><mo>(</mo><msub><mi>a</mi><mi>\u03b2</mi></msub><mo>+</mo><msub><mi>N</mi><mi>T</mi></msub><mo>,</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>T</mi></msub></munderover><msub><mi>\u03be</mi><mi>i</mi></msub><mo>+</mo><msub><mi>b</mi><mi>\u03b2</mi></msub><mo>)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nthat is, there are $N_T$ points on the set $S$ with jump times given by $\\tau_{j}$ and the corresponding jump sizes by $\\xi_{j}$. We choose randomly, with equal probability, one of the following three proposals.\n\n\\bigskip\n\\noindent\\textit{Birth-and-death step}\n\\smallskip\\nopagebreak\n\n\\noindent\nIn the birth-and-death step we choose one\nof two moves. \nWith probability $p\\in(0,1)$ we choose\na birth move whereby a new-born point $(\\tau,\\xi)$ is added to the\ncurrent configuration of Poisson points. The proposed new state is\nthen $\\Phi\\cup\\left\\{ (\\tau,\\xi)\\right\\} $. The point $\\tau$ is\ndrawn uniformly from $[0,T]$, whilst $\\xi$ is drawn from the jump\nsize distribution $\\mbox{Ex}(\\beta)$. For this move the proposal\ntransition kernel $q(\\Phi, \\Phi \\cup \\{(\\tau, \\xi)\\})$ has the following density with respect to the product of Lebesgue measure on $[0,T]$ and $\\mbox{Ex}(1)$ measure on $(0, \\infty)$:\n", "itemtype": "equation", "pos": 36580, "prevtext": "\n\n\\subsubsection{Step 6. Update the latent process $\\Phi$ }\n\\label{sec:phiupdate}\n\nThe Metropolis-Hastings step we use to update the process $\\Phi$ draws from the work of \\citet{geyer_simulation_1994}, \\citet{roberts_bayesian_2004} and \\citet{fruhwirth2009bayesian} on MCMC techniques for simulating point processes, extending it where appropriate to the case of inhomogeneous Poisson processes. \n\nLet us assume that the current state of the Markov chain is \n", "index": 51, "text": "$$\\Phi=\\{(\\tau_{1},\\xi_{1}),\\dots,(\\tau_{N_T},\\xi_{N_T})\\},$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex12.m1\" class=\"ltx_Math\" alttext=\"\\Phi=\\{(\\tau_{1},\\xi_{1}),\\dots,(\\tau_{N_{T}},\\xi_{N_{T}})\\},\" display=\"block\"><mrow><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03be</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><msub><mi>N</mi><mi>T</mi></msub></msub><mo>,</mo><msub><mi>\u03be</mi><msub><mi>N</mi><mi>T</mi></msub></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nWith probability $1-p$ a death move is selected, a randomly chosen point $(\\tau_i,\\xi_i)$ being removed from $\\Phi$ (provided that $\\Phi$ is not empty).\nThe proposal transition kernel (with respect to the counting measure) is\n", "itemtype": "equation", "pos": 37546, "prevtext": "\nthat is, there are $N_T$ points on the set $S$ with jump times given by $\\tau_{j}$ and the corresponding jump sizes by $\\xi_{j}$. We choose randomly, with equal probability, one of the following three proposals.\n\n\\bigskip\n\\noindent\\textit{Birth-and-death step}\n\\smallskip\\nopagebreak\n\n\\noindent\nIn the birth-and-death step we choose one\nof two moves. \nWith probability $p\\in(0,1)$ we choose\na birth move whereby a new-born point $(\\tau,\\xi)$ is added to the\ncurrent configuration of Poisson points. The proposed new state is\nthen $\\Phi\\cup\\left\\{ (\\tau,\\xi)\\right\\} $. The point $\\tau$ is\ndrawn uniformly from $[0,T]$, whilst $\\xi$ is drawn from the jump\nsize distribution $\\mbox{Ex}(\\beta)$. For this move the proposal\ntransition kernel $q(\\Phi, \\Phi \\cup \\{(\\tau, \\xi)\\})$ has the following density with respect to the product of Lebesgue measure on $[0,T]$ and $\\mbox{Ex}(1)$ measure on $(0, \\infty)$:\n", "index": 53, "text": "\n\\[\nq(\\Phi, \\Phi \\cup \\{(\\tau, \\xi)\\}) =\\beta^{-1}\\exp\\left(-(\\beta^{-1}-1)\\xi\\right).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex13.m1\" class=\"ltx_Math\" alttext=\"q(\\Phi,\\Phi\\cup\\{(\\tau,\\xi)\\})=\\beta^{-1}\\exp\\left(-(\\beta^{-1}-1)\\xi\\right).\" display=\"block\"><mrow><mrow><mrow><mi>q</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u222a</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>\u03be</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>(</mo><mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\u03be</mi></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $N_T$ is the number of points in $\\Phi$ before the death move. Then the Metropolis-Hastings acceptance ratio for a birth move from $\\Phi$ to $\\Phi\\cup\\{(\\tau,\\xi)\\}$ is\n", "itemtype": "equation", "pos": 37861, "prevtext": "\nWith probability $1-p$ a death move is selected, a randomly chosen point $(\\tau_i,\\xi_i)$ being removed from $\\Phi$ (provided that $\\Phi$ is not empty).\nThe proposal transition kernel (with respect to the counting measure) is\n", "index": 55, "text": "\n\\[\nq(\\Phi, \\Phi \\setminus \\{(\\tau_i, \\xi_i)\\}) = \\frac{1}{N_T},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex14.m1\" class=\"ltx_Math\" alttext=\"q(\\Phi,\\Phi\\setminus\\{(\\tau_{i},\\xi_{i})\\})=\\frac{1}{N_{T}},\" display=\"block\"><mrow><mrow><mrow><mi>q</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2216</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mi>T</mi></msub></mfrac></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhile the acceptance ratio for a death move from $\\Phi$ to $\\Phi \\setminus \\{(\\tau_i,\\xi_i)\\}$ is\n", "itemtype": "equation", "pos": 38103, "prevtext": "\nwhere $N_T$ is the number of points in $\\Phi$ before the death move. Then the Metropolis-Hastings acceptance ratio for a birth move from $\\Phi$ to $\\Phi\\cup\\{(\\tau,\\xi)\\}$ is\n", "index": 57, "text": "\n\\[\n\\alpha(\\Phi,\\Phi\\cup\\{(\\tau,\\xi)\\})=\\min\\left\\{ 1,r(\\Phi,(\\tau,\\xi))\\right\\} ,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex15.m1\" class=\"ltx_Math\" alttext=\"\\alpha(\\Phi,\\Phi\\cup\\{(\\tau,\\xi)\\})=\\min\\left\\{1,r(\\Phi,(\\tau,\\xi))\\right\\},\" display=\"block\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u222a</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>\u03be</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mrow><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>\u03be</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n where\n \\begin{eqnarray*}\n \tr(\\tilde \\Phi,(\\tau,\\xi))\n \t& = & \\frac{\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1,\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\} )}\n\t\t\t   {\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1,\\tilde \\Phi)}\n \t\\frac{\\pi(\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\}\\mid \\vartheta,\\beta )}\n\t\t {\\pi(\\tilde \\Phi\\mid \\vartheta,\\beta)}\n \t\\frac{1-p}{p} \\frac{1}{(N_T+1)q(\\Phi, \\Phi \\cup \\{(\\tau, \\xi)\\})}\\\\\n \t& = & \\frac{\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_1,\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\})}\n \t           {\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_1,\\tilde \\Phi)}  \\frac{1-p}{p}\\frac{T}{\\tilde N_T+1} I(\\vartheta,\\tau),\n \\end{eqnarray*}\nwhere $\\tilde N_T$ is the number of points of $\\tilde \\Phi$, cf. \\eqref{eqn:density_of_Phi}.\n\n\\bigskip\n\\noindent\\textit{Local displacement move}\n\\smallskip\\nopagebreak\n\n\\noindent\nWithout loss of generality let us assume that the\njump times of the Poisson process are ordered, so that $\\tau_{1}<\\dots<\\tau_{N_T}$. In the local displacement move we choose randomly\none of the jump times, say $\\tau_{j}$, and generate a new jump time\n$\\tau$ uniformly on $[\\tau_{j-1},\\tau_{j+1}]$, putting\n $\\tau_{0}=0$ and $\\tau_{N_T+1}=T$. The point $(\\tau_{j},\\xi_{j})$ is then displaced and re-sized to $(\\tau, \\xi)$, where $\\xi = e^{-\\lambda_1^{-1}(\\tau-\\tau_{j})}\\xi_{j}$. Formally we choose uniformly one of $N_T$ transition kernels,  with the $j$-th one preserving the conditional distribution $\\pi(\\tau,\\xi|{\\mathcal{X}},\\mu,\\rho_{0},\\sigma,\\rho_1,\\vartheta,\\beta,\\Phi\\backslash\\{(\\tau_{j},\\xi_{j})\\})$. The proposal for the $j$-th kernel has a uniform distribution over $(\\tau_{j-1}, \\tau_{j+1})$ for the first variable with the second variable being then a deterministic transformation given by a 1-1 mapping $\\mathcal{T}(\\xi, \\tau, \\tau') = (\\xi e^{-\\lambda_1^{-1}(\\tau'-\\tau)}, \\tau', \\tau)$ such that $\\mathcal{T} = \\mathcal{T}^{-1}$. Following \\citet[Section 2]{tierney_note_1998}, the contribution of this deterministic transition to the Metropolis-Hastings acceptance ratio is $|\\det \\nabla \\mathcal{T} (\\xi_j, \\tau_j, \\tau) |$, where $\\tau$ is the new proposed location of the jump. Hence\nthe complete Metropolis-Hastings acceptance ratio is\n\n", "itemtype": "equation", "pos": 38286, "prevtext": "\nwhile the acceptance ratio for a death move from $\\Phi$ to $\\Phi \\setminus \\{(\\tau_i,\\xi_i)\\}$ is\n", "index": 59, "text": "\n\\[\n\\alpha(\\Phi,\\Phi\\setminus\\{(\\tau_i,\\xi_i)\\})=\\min\\left\\{ 1,\\frac1{r\\big(\\Phi \\setminus \\{(\\tau_i,\\xi_i)\\},(\\tau_i,\\xi_i)\\big)}\\right\\},\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex16.m1\" class=\"ltx_Math\" alttext=\"\\alpha(\\Phi,\\Phi\\setminus\\{(\\tau_{i},\\xi_{i})\\})=\\min\\left\\{1,\\frac{1}{r\\big{(%&#10;}\\Phi\\setminus\\{(\\tau_{i},\\xi_{i})\\},(\\tau_{i},\\xi_{i})\\big{)}}\\right\\},\" display=\"block\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2216</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mfrac><mn>1</mn><mrow><mi>r</mi><mo>\u2062</mo><mrow><mo maxsize=\"120%\" minsize=\"120%\">(</mo><mrow><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2216</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>,</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03be</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo maxsize=\"120%\" minsize=\"120%\">)</mo></mrow></mrow></mfrac><mo>}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $\\tilde q(\\tau, \\tau') = (\\tau_{j+1}- \\tau_{j-1})^{-1}$ is the transition density for the jump location with respect to Lebesgue measure on $(\\tau_{j-1}, \\tau_{j+1})$.\n\n\\bigskip\n\\noindent\\textit{Multiplicative jump size update}\n\\smallskip\\nopagebreak\n\n\\noindent\nIn this step the sizes of all jumps are independently updated. Specifically, for each jump $(\\tau_j, \\xi_j)$ we propose a new jump size $\\xi_{j}'=\\xi_{j}\\phi_{j}$, where $\\log(\\phi_j) \\sim \\mbox{N}(0,c^{2})$ are i.i.d. random variables.\nThe variance $c^2$ is chosen inversely proportional to the current number of jumps, and the performance of this update step appears rather insensitive to the constant of proportionality. Denoting by $\\Phi_{new}$ the Poisson point process with updated jump sizes, the Metropolis-Hastings acceptance ratio for this move is\n\n", "itemtype": "equation", "pos": 40622, "prevtext": "\n where\n \\begin{eqnarray*}\n \tr(\\tilde \\Phi,(\\tau,\\xi))\n \t& = & \\frac{\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1,\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\} )}\n\t\t\t   {\\ell({\\mathcal{X}}\\mid\\mu,\\rho_{0},\\sigma,\\rho_1,\\tilde \\Phi)}\n \t\\frac{\\pi(\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\}\\mid \\vartheta,\\beta )}\n\t\t {\\pi(\\tilde \\Phi\\mid \\vartheta,\\beta)}\n \t\\frac{1-p}{p} \\frac{1}{(N_T+1)q(\\Phi, \\Phi \\cup \\{(\\tau, \\xi)\\})}\\\\\n \t& = & \\frac{\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_1,\\tilde \\Phi  \\cup \\{ (\\tau, \\xi)\\})}\n \t           {\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_1,\\tilde \\Phi)}  \\frac{1-p}{p}\\frac{T}{\\tilde N_T+1} I(\\vartheta,\\tau),\n \\end{eqnarray*}\nwhere $\\tilde N_T$ is the number of points of $\\tilde \\Phi$, cf. \\eqref{eqn:density_of_Phi}.\n\n\\bigskip\n\\noindent\\textit{Local displacement move}\n\\smallskip\\nopagebreak\n\n\\noindent\nWithout loss of generality let us assume that the\njump times of the Poisson process are ordered, so that $\\tau_{1}<\\dots<\\tau_{N_T}$. In the local displacement move we choose randomly\none of the jump times, say $\\tau_{j}$, and generate a new jump time\n$\\tau$ uniformly on $[\\tau_{j-1},\\tau_{j+1}]$, putting\n $\\tau_{0}=0$ and $\\tau_{N_T+1}=T$. The point $(\\tau_{j},\\xi_{j})$ is then displaced and re-sized to $(\\tau, \\xi)$, where $\\xi = e^{-\\lambda_1^{-1}(\\tau-\\tau_{j})}\\xi_{j}$. Formally we choose uniformly one of $N_T$ transition kernels,  with the $j$-th one preserving the conditional distribution $\\pi(\\tau,\\xi|{\\mathcal{X}},\\mu,\\rho_{0},\\sigma,\\rho_1,\\vartheta,\\beta,\\Phi\\backslash\\{(\\tau_{j},\\xi_{j})\\})$. The proposal for the $j$-th kernel has a uniform distribution over $(\\tau_{j-1}, \\tau_{j+1})$ for the first variable with the second variable being then a deterministic transformation given by a 1-1 mapping $\\mathcal{T}(\\xi, \\tau, \\tau') = (\\xi e^{-\\lambda_1^{-1}(\\tau'-\\tau)}, \\tau', \\tau)$ such that $\\mathcal{T} = \\mathcal{T}^{-1}$. Following \\citet[Section 2]{tierney_note_1998}, the contribution of this deterministic transition to the Metropolis-Hastings acceptance ratio is $|\\det \\nabla \\mathcal{T} (\\xi_j, \\tau_j, \\tau) |$, where $\\tau$ is the new proposed location of the jump. Hence\nthe complete Metropolis-Hastings acceptance ratio is\n\n", "index": 61, "text": "\\begin{multline*}\nr(\\Phi, \\Phi_{new}) = \\frac{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_1,\\Phi_{new})}{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_1,\\Phi)}\\frac{\\pi(\\tau,\\xi|\\vartheta,\\beta)}{\\pi(\\tau_{j},\\xi_{j}|\\vartheta,\\beta)}\\frac{\\tilde{q}(\\tau,\\tau_{j})}{\\tilde{q}(\\tau_{j},\\tau)}|\\det \\nabla \\mathcal{T} (\\xi_j, \\tau_j, \\tau) |\\\\\n=\n\\frac{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_1,\\Phi_{new})}{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_1,\\Phi)}\\frac{I(\\vartheta,\\tau)}{I(\\vartheta,\\tau_{j})}\\frac{e^{-\\beta^{-1}\\xi}}{e^{-\\beta^{-1}\\xi_{j}}}e^{-\\lambda_{1}^{-1}(\\tau-\\tau_{j})},\n\\end{multline*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"p31.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle r(\\Phi,\\Phi_{new})=\\frac{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,%&#10;\\rho_{1},\\Phi_{new})}{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_{1},\\Phi)}%&#10;\\frac{\\pi(\\tau,\\xi|\\vartheta,\\beta)}{\\pi(\\tau_{j},\\xi_{j}|\\vartheta,\\beta)}%&#10;\\frac{\\tilde{q}(\\tau,\\tau_{j})}{\\tilde{q}(\\tau_{j},\\tau)}|\\det\\nabla\\mathcal{T%&#10;}(\\xi_{j},\\tau_{j},\\tau)|\\\\&#10;\\displaystyle=\\frac{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_{1},\\Phi_{new}%&#10;)}{\\ell({\\mathcal{X}}|\\mu,\\rho_{0},\\sigma,\\rho_{1},\\Phi)}\\frac{I(\\vartheta,%&#10;\\tau)}{I(\\vartheta,\\tau_{j})}\\frac{e^{-\\beta^{-1}\\xi}}{e^{-\\beta^{-1}\\xi_{j}}}%&#10;e^{-\\lambda_{1}^{-1}(\\tau-\\tau_{j})},\" display=\"block\"><mtable displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mrow><mi>r</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><mi>\u03be</mi><mo stretchy=\"false\">|</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>,</mo><msub><mi>\u03be</mi><mi>j</mi></msub><mo stretchy=\"false\">|</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03c4</mi><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mover accent=\"true\"><mi>q</mi><mo stretchy=\"false\">~</mo></mover><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">|</mo><mrow><mo movablelimits=\"false\">det</mo><mo>\u2061</mo><mrow><mrow><mo>\u2207</mo><mo>\u2061</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcaf</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03be</mi><mi>j</mi></msub><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo stretchy=\"false\">|</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"right\"><mrow><mrow><mi/><mo>=</mo><mrow><mfrac><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo stretchy=\"false\">|</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>I</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\u03d1</mi><mo>,</mo><msub><mi>\u03c4</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>\u2062</mo><mfrac><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><mi>\u03be</mi></mrow></mrow></msup><msup><mi>e</mi><mrow><mo>-</mo><mrow><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>\u2062</mo><msub><mi>\u03be</mi><mi>j</mi></msub></mrow></mrow></msup></mfrac><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\u03c4</mi><mo>-</mo><msub><mi>\u03c4</mi><mi>j</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msup></mrow></mrow><mo>,</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nNote that the product $\\prod_{i=1}^{N_T}\\frac{\\xi_{i}^{'}}{\\xi_{i}}$ is equivalent to $\\prod_{i=1}^{N_T}\\phi_{i}$.\n\n\\subsection{Bayesian inference for a sum of three OU processes}\\label{sec:Bayesian-inference-for-3-components}\n\nAs discussed in Section \\ref{sub:model-specification} we may believe {\\em a priori} that the price spikes observed in the market are of a certain number of types, corresponding to their differing possible physical causes. Accordingly we now describe the extension of the 2-OU model by the addition of a further independent jump OU component $Y_{2}(t)$, henceforth referring to the first jump component as $Y_{1}(t)$ and using appropriate subscripts to distinguish their parameters; further jump components are incorporated similarly. The new jump component $Y_2$ may either have a positive contribution to the price process (ie. the sign $w_2$ in \\eqref{eqn:superposition_model} is $1$) with a rate of decay differing from that of the first component, or alternatively it may have a negative contribution (ie. $w_2=-1$). For concreteness here we choose $w_1=w_2=1$, so that:\n\n", "itemtype": "equation", "pos": 42057, "prevtext": "\nwhere $\\tilde q(\\tau, \\tau') = (\\tau_{j+1}- \\tau_{j-1})^{-1}$ is the transition density for the jump location with respect to Lebesgue measure on $(\\tau_{j-1}, \\tau_{j+1})$.\n\n\\bigskip\n\\noindent\\textit{Multiplicative jump size update}\n\\smallskip\\nopagebreak\n\n\\noindent\nIn this step the sizes of all jumps are independently updated. Specifically, for each jump $(\\tau_j, \\xi_j)$ we propose a new jump size $\\xi_{j}'=\\xi_{j}\\phi_{j}$, where $\\log(\\phi_j) \\sim \\mbox{N}(0,c^{2})$ are i.i.d. random variables.\nThe variance $c^2$ is chosen inversely proportional to the current number of jumps, and the performance of this update step appears rather insensitive to the constant of proportionality. Denoting by $\\Phi_{new}$ the Poisson point process with updated jump sizes, the Metropolis-Hastings acceptance ratio for this move is\n\n", "index": 63, "text": "\\begin{align*}\n\\alpha(\\Phi,\\Phi_{new})\n= \\min\\left\\{ 1,\n\t\\frac{\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_{1},\\vartheta,\\beta,\\Phi_{new})}\n\t\t    {\\ell({\\mathcal{X}}\\mid\\mu,\\rho_0,\\sigma,\\rho_{1},\\vartheta,\\beta,\\Phi)}\n\t\t    \\exp\\left\\lbrace-(\\beta^{-1}-1)\\sum_{i=1}^{N_T}(\\xi_{i}'-\\xi_{i})\\right\\rbrace\\prod_{i=1}^{N_T}\\frac{\\xi_{i}^{'}}{\\xi_{i}}\n\t\t    \\right\\}.\n\\end{align*}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\alpha(\\Phi,\\Phi_{new})=\\min\\left\\{1,\\frac{\\ell({\\mathcal{X}}\\mid%&#10;\\mu,\\rho_{0},\\sigma,\\rho_{1},\\vartheta,\\beta,\\Phi_{new})}{\\ell({\\mathcal{X}}%&#10;\\mid\\mu,\\rho_{0},\\sigma,\\rho_{1},\\vartheta,\\beta,\\Phi)}\\exp\\left\\{-(\\beta^{-1}%&#10;-1)\\sum_{i=1}^{N_{T}}(\\xi_{i}^{\\prime}-\\xi_{i})\\right\\}\\prod_{i=1}^{N_{T}}%&#10;\\frac{\\xi_{i}^{{}^{\\prime}}}{\\xi_{i}}\\right\\}.\" display=\"inline\"><mrow><mrow><mrow><mi>\u03b1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo>{</mo><mn>1</mn><mo>,</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo>,</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mrow><mi>n</mi><mo>\u2062</mo><mi>e</mi><mo>\u2062</mo><mi>w</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb3</mi><mo>\u2223</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>,</mo><mi>\u03d1</mi><mo>,</mo><mi>\u03b2</mi><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mstyle><mo>\u2062</mo><mrow><mi>exp</mi><mo>\u2061</mo><mrow><mo>{</mo><mrow><mo>-</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msup><mi>\u03b2</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>T</mi></msub></munderover></mstyle><mrow><mo stretchy=\"false\">(</mo><mrow><msubsup><mi>\u03be</mi><mi>i</mi><mo>\u2032</mo></msubsup><mo>-</mo><msub><mi>\u03be</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>}</mo></mrow></mrow><mo>\u2062</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>T</mi></msub></munderover></mstyle><mstyle displaystyle=\"true\"><mfrac><msubsup><mi>\u03be</mi><mi>i</mi><msup><mi/><mo>\u2032</mo></msup></msubsup><msub><mi>\u03be</mi><mi>i</mi></msub></mfrac></mstyle></mrow></mrow><mo>}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nand we specify that $\\lambda_{1}>\\lambda_{2}$ for identification purposes, ie. the jumps of $Y_{1}(t)$ have slower decay than those of $Y_{2}(t)$. When $w_1=1, w_2=-1$ this constraint is not required.\n\nWe now have two marked Poisson processes $\\Phi_{1}$ and $\\Phi_{2}$, corresponding to $L_{1}(t)$\nand $L_{2}(t)$ respectively, which are conditionally independent given their parameters. \nThe augmented likelihood $\\ell({\\mathcal{X}} \\mid\\mu,\\lambda_{0},\\sigma,{\\mathcal{Y}}_{1}, {\\mathcal{Y}}_{2})$\nis given by equation (\\ref{eq:likelihood})  with $z_{j}=x_{j}-y_{1,j}-y_{2,j}$.\nThe likelihood of $\\Phi=(\\Phi_{1},\\Phi_{2})$\nwith respect to the dominating measure of a pair of independent marked Poisson process with unit intensity and jump sizes with a Ex$(1)$ distribution is given by \n", "itemtype": "equation", "pos": 43538, "prevtext": "\nNote that the product $\\prod_{i=1}^{N_T}\\frac{\\xi_{i}^{'}}{\\xi_{i}}$ is equivalent to $\\prod_{i=1}^{N_T}\\phi_{i}$.\n\n\\subsection{Bayesian inference for a sum of three OU processes}\\label{sec:Bayesian-inference-for-3-components}\n\nAs discussed in Section \\ref{sub:model-specification} we may believe {\\em a priori} that the price spikes observed in the market are of a certain number of types, corresponding to their differing possible physical causes. Accordingly we now describe the extension of the 2-OU model by the addition of a further independent jump OU component $Y_{2}(t)$, henceforth referring to the first jump component as $Y_{1}(t)$ and using appropriate subscripts to distinguish their parameters; further jump components are incorporated similarly. The new jump component $Y_2$ may either have a positive contribution to the price process (ie. the sign $w_2$ in \\eqref{eqn:superposition_model} is $1$) with a rate of decay differing from that of the first component, or alternatively it may have a negative contribution (ie. $w_2=-1$). For concreteness here we choose $w_1=w_2=1$, so that:\n\n", "index": 65, "text": "\\begin{equation}\n\tX(t)=Y_{0}(t)+Y_{1}(t)+Y_{2}(t),\\label{eq:3component-model}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"X(t)=Y_{0}(t)+Y_{1}(t)+Y_{2}(t),\" display=\"block\"><mrow><mrow><mrow><mi>X</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>Y</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>Y</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>Y</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere for $i=1,2$, \n", "itemtype": "equation", "pos": 44417, "prevtext": "\nand we specify that $\\lambda_{1}>\\lambda_{2}$ for identification purposes, ie. the jumps of $Y_{1}(t)$ have slower decay than those of $Y_{2}(t)$. When $w_1=1, w_2=-1$ this constraint is not required.\n\nWe now have two marked Poisson processes $\\Phi_{1}$ and $\\Phi_{2}$, corresponding to $L_{1}(t)$\nand $L_{2}(t)$ respectively, which are conditionally independent given their parameters. \nThe augmented likelihood $\\ell({\\mathcal{X}} \\mid\\mu,\\lambda_{0},\\sigma,{\\mathcal{Y}}_{1}, {\\mathcal{Y}}_{2})$\nis given by equation (\\ref{eq:likelihood})  with $z_{j}=x_{j}-y_{1,j}-y_{2,j}$.\nThe likelihood of $\\Phi=(\\Phi_{1},\\Phi_{2})$\nwith respect to the dominating measure of a pair of independent marked Poisson process with unit intensity and jump sizes with a Ex$(1)$ distribution is given by \n", "index": 67, "text": "\n\\[\n\\pi(\\Phi\\mid\\vartheta_{1},\\vartheta_{2},\\beta_{1},\\beta_{2})=\\pi(\\Phi_{1}\\mid\\vartheta_{1},\\beta_{1})\\pi(\\Phi_{2}\\mid\\vartheta_{2},\\beta_{2}),\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex18.m1\" class=\"ltx_Math\" alttext=\"\\pi(\\Phi\\mid\\vartheta_{1},\\vartheta_{2},\\beta_{1},\\beta_{2})=\\pi(\\Phi_{1}\\mid%&#10;\\vartheta_{1},\\beta_{1})\\pi(\\Phi_{2}\\mid\\vartheta_{2},\\beta_{2}),\" display=\"block\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">\u03a6</mi><mo>\u2223</mo><msub><mi>\u03d1</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03d1</mi><mn>2</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mn>1</mn></msub><mo>\u2223</mo><msub><mi>\u03d1</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mn>2</mn></msub><mo>\u2223</mo><msub><mi>\u03d1</mi><mn>2</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nHere $N_T^i$ denotes the number of points of $\\Phi_{i}$ in\nthe set $S$ and \n", "itemtype": "equation", "pos": 44586, "prevtext": "\nwhere for $i=1,2$, \n", "index": 69, "text": "\n\\[\n\\pi(\\Phi_{i}\\mid\\vartheta_{i},\\beta_{i}) =\n\t\\exp \\left\\lbrace \\sum_{j=1}^{N_T^i} \\log I_i(\\vartheta_i,\\tau_{i,j})\n- \\int_{0}^{T} I_i(\\vartheta_i,t)dt + T \n\\right\\rbrace \n\\beta_i^{N_T^i}\n\\exp\\left\\{ -(\\beta_{i}^{-1}-1)\\sum_{j=1}^{N_T^i}\\xi_{i,j}\\right\\}. \n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex19.m1\" class=\"ltx_Math\" alttext=\"\\pi(\\Phi_{i}\\mid\\vartheta_{i},\\beta_{i})=\\exp\\left\\{\\sum_{j=1}^{N_{T}^{i}}\\log&#10;I%&#10;_{i}(\\vartheta_{i},\\tau_{i,j})-\\int_{0}^{T}I_{i}(\\vartheta_{i},t)dt+T\\right\\}%&#10;\\beta_{i}^{N_{T}^{i}}\\exp\\left\\{-(\\beta_{i}^{-1}-1)\\sum_{j=1}^{N_{T}^{i}}\\xi_{%&#10;i,j}\\right\\}.\" display=\"block\"><mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi mathvariant=\"normal\">\u03a6</mi><mi>i</mi></msub><mo>\u2223</mo><msub><mi>\u03d1</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03b2</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mi>exp</mi><mrow><mo>{</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>N</mi><mi>T</mi><mi>i</mi></msubsup></munderover><mi>log</mi><msub><mi>I</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03d1</mi><mi>i</mi></msub><mo>,</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mi>T</mi></msubsup><msub><mi>I</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03d1</mi><mi>i</mi></msub><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><mi>t</mi><mo>+</mo><mi>T</mi><mo>}</mo></mrow><msubsup><mi>\u03b2</mi><mi>i</mi><msubsup><mi>N</mi><mi>T</mi><mi>i</mi></msubsup></msubsup><mi>exp</mi><mrow><mo>{</mo><mo>-</mo><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>\u03b2</mi><mi>i</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>-</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>N</mi><mi>T</mi><mi>i</mi></msubsup></munderover><msub><mi>\u03be</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>}</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nWe impose the condition $\\lambda_1>\\lambda_2$ by defining the prior distribution for $\\rho_2$ as \n", "itemtype": "equation", "pos": 44923, "prevtext": "\nHere $N_T^i$ denotes the number of points of $\\Phi_{i}$ in\nthe set $S$ and \n", "index": 71, "text": "\n\\[\n\\Phi_{i}=\\{(\\tau_{i,1},\\xi_{i,1}),\\ldots,(\\tau_{i,N_T^i},\\xi_{i,N_T^i})\\}.\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex20.m1\" class=\"ltx_Math\" alttext=\"\\Phi_{i}=\\{(\\tau_{i,1},\\xi_{i,1}),\\ldots,(\\tau_{i,N_{T}^{i}},\\xi_{i,N_{T}^{i}}%&#10;)\\}.\" display=\"block\"><mrow><mrow><msub><mi mathvariant=\"normal\">\u03a6</mi><mi>i</mi></msub><mo>=</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>\u03be</mi><mrow><mi>i</mi><mo>,</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c4</mi><mrow><mi>i</mi><mo>,</mo><msubsup><mi>N</mi><mi>T</mi><mi>i</mi></msubsup></mrow></msub><mo>,</mo><msub><mi>\u03be</mi><mrow><mi>i</mi><mo>,</mo><msubsup><mi>N</mi><mi>T</mi><mi>i</mi></msubsup></mrow></msub><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $\\rho_{i}=e^{-1/\\lambda_{i}}, i\\geq 1$, as before (see the Appendix for properties of $\\rho_2$). Since all other parameters are {\\em a priori} mutually independent, their update steps are identical to those for the 2-OU model.\n\nUpdates of $\\rho_{1}$ and $\\rho_{2}$ are made using a random-walk Metropolis-Hastings algorithm (with independent proposals  for each variable). The proposal distribution is Normal with the variance tuned as before after pilot runs.\n\n\\subsection{Posterior predictive check \\label{sec:Diagnostics-theory}}\n\nOur approach to assessing model adequacy is the following. Since $Y_{0}$ is a Gaussian OU process, its transition density specified in Section \\ref{subsec:OU} implies that $\\varepsilon_j$, $j=1, \\ldots, N,$ defined implicitly by \n\n", "itemtype": "equation", "pos": 45102, "prevtext": "\nWe impose the condition $\\lambda_1>\\lambda_2$ by defining the prior distribution for $\\rho_2$ as \n", "index": 73, "text": "\n\\[\n\\rho_{2}|\\rho_{1}\\sim\\rho_{1}\\mbox{U}(0,1),\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex21.m1\" class=\"ltx_Math\" alttext=\"\\rho_{2}|\\rho_{1}\\sim\\rho_{1}\\mbox{U}(0,1),\" display=\"block\"><mrow><msub><mi>\u03c1</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>\u223c</mo><msub><mi>\u03c1</mi><mn>1</mn></msub><mtext>U</mtext><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nare independent and distributed as $\\mbox{N}(0,1)$. Given observations of $Y_{0}$ at sampling times $t_0, \\ldots, t_N$ the distribution of $\\{\\varepsilon_{1},\\dots,\\varepsilon_{N}\\}$ may then be tested, and this test may be repeated across MCMC iterations. At each iteration $k$ of the MCMC algorithm (assuming the Markov chain has reached stationarity) we use the current state of parameters  $\\Theta^{(k)}=\\{\\mu^{(k)},\\lambda_{i}^{(k)},\\sigma^{(k)},\\vartheta_{i}^{(k)},\\beta_{i}^{(k)}\\}$ and missing data $\\Phi^{(k)}$ to recover the path of each jump process $y_{i,j}^{(k)} ,j=0,\\dots,N$. The path of $Y_{0}^{(k)}$ at times $t_0, \\ldots, t_N$ is then computed as \n\n", "itemtype": "equation", "pos": 45923, "prevtext": "\nwhere $\\rho_{i}=e^{-1/\\lambda_{i}}, i\\geq 1$, as before (see the Appendix for properties of $\\rho_2$). Since all other parameters are {\\em a priori} mutually independent, their update steps are identical to those for the 2-OU model.\n\nUpdates of $\\rho_{1}$ and $\\rho_{2}$ are made using a random-walk Metropolis-Hastings algorithm (with independent proposals  for each variable). The proposal distribution is Normal with the variance tuned as before after pilot runs.\n\n\\subsection{Posterior predictive check \\label{sec:Diagnostics-theory}}\n\nOur approach to assessing model adequacy is the following. Since $Y_{0}$ is a Gaussian OU process, its transition density specified in Section \\ref{subsec:OU} implies that $\\varepsilon_j$, $j=1, \\ldots, N,$ defined implicitly by \n\n", "index": 75, "text": "\\begin{equation}\nY_{0}(t_j)=\\mu+(Y_{0}(t_{j-1})-\\mu)e^{-\\lambda_{0}^{-1}\\Delta_j}+\\left(\\frac{\\sigma^{2}\\lambda_{0}}{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_j})\\right)^{1/2}\\varepsilon_{j},\\label{eq:Explicit-OU-process}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"Y_{0}(t_{j})=\\mu+(Y_{0}(t_{j-1})-\\mu)e^{-\\lambda_{0}^{-1}\\Delta_{j}}+\\left(%&#10;\\frac{\\sigma^{2}\\lambda_{0}}{2}(1-e^{-2\\lambda_{0}^{-1}\\Delta_{j}})\\right)^{1/%&#10;2}\\varepsilon_{j},\" display=\"block\"><mrow><mrow><mrow><msub><mi>Y</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03bc</mi><mo>+</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><msub><mi>Y</mi><mn>0</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mi>\u03bc</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>j</mi></msub></mrow></mrow></msup></mrow><mo>+</mo><mrow><msup><mrow><mo>(</mo><mrow><mfrac><mrow><msup><mi>\u03c3</mi><mn>2</mn></msup><mo>\u2062</mo><msub><mi>\u03bb</mi><mn>0</mn></msub></mrow><mn>2</mn></mfrac><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msubsup><mi>\u03bb</mi><mn>0</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo>\u2062</mo><msub><mi mathvariant=\"normal\">\u0394</mi><mi>j</mi></msub></mrow></mrow></msup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mo>\u2062</mo><msub><mi>\u03b5</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $x_{i}$ is the deseasonalised price at time $t_i$ and $w_i$ is the sign of the $i$-th jump component.  From this the noise data $\\{\\varepsilon_{j}^{(k)}\\}_{j=1,\\ldots,N}$ for each MCMC iteration $k$ is obtained and subjected to a Kolmogorov-Smirnov (KS) test for the standard Normal distribution, yielding a $p$-value $p^{(k)}$.\nFollowing \\citet{rubin1984} we call the distribution of $p^{(k)}$ the posterior predictive check distribution. We refer to its mean as the {\\em posterior predictive $p$-value} and interpret it accordingly, cf. \\citet{gelman_bayesian_2003} and references therein.\n\n\nSimilarly we perform diagnostics on the jump processes sampled from our Markov chain. For each jump process $L_i$ at iteration $k$ of the Markov chain, the set of jump sizes and the set of interarrival times are both subjected to KS tests. The former set undergoes a KS test for the exponential distribution with mean $\\beta_i^{(k)}$. In the homogeneous Poisson process model, the latter set undergoes a KS test for the exponential distribution with mean $(\\eta_i^{(k)})^{-1}$; otherwise an independent sample is taken from the interarrival times of an inhomogeneous Poisson process with time varying intensity $I_i(\\vartheta^{(k)}_i,t)$ and its distribution compared with the latter set in \n a two-sample KS test. Posterior predictive $p$-values are reported.\n \n\\subsection{Implementation}\n\nThe parameter-dependent balance between jumps and diffusion in the spot price model \\eqref{eqn:superposition_model} raises a number of potential issues regarding the implementation of the MCMC procedure described above. Extensive testing was carried out with simulated data in order to probe these issues, and details are given in the Appendix.\n\nOur MCMC algorithms were implemented by combining Matlab and C++ MEX code, and were run on a 2.5GHz Intel Xeon E5 processor. For the 2-OU model with $1500$ observations  the computation time for completing 1000 MCMC iterations using a single core was approximately 1.9 seconds. The corresponding figure for the 3-OU model was about 3.6 seconds with a single update of the latent process $\\Phi$, and 8.8 seconds with 5 updates of $\\Phi$ per MCMC iteration. In the numerical examples of Section \\ref{sec:real}, a burn-in period of 500\\,000 iterations was allocated. The following 1.5 million were thinned by taking one sample every 100 iterations and used to establish the posterior distribution. This corresponds to around 1 hour running time for the 2-OU model and below 5 hours for the 3-OU model with the fivefold update of the latent process $\\Phi$.\n\n\\section{Application to the APXUK and EEX markets}\\label{sec:real}\n\n\nIn this section we apply the inference procedure described in Section \\ref{sec:inference} to daily average electricity prices corresponding to the APX Power UK spot base index (APXUK hereafter, quoted in \\pounds/MWh)\n\\footnote{\\url{https://www.apxgroup.com/market-results/apx-power-uk/ukpx-rpd-index-methodology/}\n} and the European Energy Exchange Phelix day base index (EEX, quoted in \\euro/MWh)\n\\footnote{\\url{http://www.epexspot.com/en/}\n}. The data were retrieved from Thompson Reuters Datastream. \n\nWeekends (which tend to differ statistically from weekdays due to a reduction in trading) are removed in both cases. Hence we assume a calendar year of 260 days and take $\\Delta_j=1$ so that parameters are reported in daily units.\n\n\\subsection{Deseasonalised time series}\nIn this paper we perform inference on deseasonalised data, treating the seasonal trend function $f(t)$ as a known characteristic of the particular energy market under study. For the purposes of the numerical illustration in this section we assume the form \\eqref{eq:seasonal-trend} and use the {\\tt nlinfit} Matlab function to solve a non-linear weighted least squares problem \n", "itemtype": "equation", "pos": 46817, "prevtext": "\nare independent and distributed as $\\mbox{N}(0,1)$. Given observations of $Y_{0}$ at sampling times $t_0, \\ldots, t_N$ the distribution of $\\{\\varepsilon_{1},\\dots,\\varepsilon_{N}\\}$ may then be tested, and this test may be repeated across MCMC iterations. At each iteration $k$ of the MCMC algorithm (assuming the Markov chain has reached stationarity) we use the current state of parameters  $\\Theta^{(k)}=\\{\\mu^{(k)},\\lambda_{i}^{(k)},\\sigma^{(k)},\\vartheta_{i}^{(k)},\\beta_{i}^{(k)}\\}$ and missing data $\\Phi^{(k)}$ to recover the path of each jump process $y_{i,j}^{(k)} ,j=0,\\dots,N$. The path of $Y_{0}^{(k)}$ at times $t_0, \\ldots, t_N$ is then computed as \n\n", "index": 77, "text": "\\begin{equation}\nz^{(k)}_{j} = x_{j}-\\sum_{i=1}^{n} w_i y_{i,j}^{(k)}, \\quad j=0, \\ldots, N, \\label{eq:KS-Y0k}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"z^{(k)}_{j}=x_{j}-\\sum_{i=1}^{n}w_{i}y_{i,j}^{(k)},\\quad j=0,\\ldots,N,\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>z</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><msub><mi>x</mi><mi>j</mi></msub><mo>-</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>\u2062</mo><msubsup><mi>y</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow></mrow></mrow><mo rspace=\"12.5pt\">,</mo><mrow><mi>j</mi><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi><mo>,</mo><mi>N</mi></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nwhere $S_{obs}(t)$ denotes the observed spot price at time $t$. Table \\ref{tab:estimated-seasonal-trend} presents estimated parameters for the trend functions.\n\nFigure \\ref{fig:deseasonalised-data} displays the resulting deseasonalised time series $X(t)=S_{obs}(t)e^{-f(t)}$. The presence of large positive price spikes is evident in both the APXUK and EEX series, but smaller negative price spikes are also suggested in the EEX series. The negative price spikes observed in the EEX market may be understood to be a consequence of the priority given to wind energy in that network: since the output of wind generation is highly variable, this priority can lead to correspondingly rapid decreases in demand for other sources of generation \\citep{benth_stochastic_2013}. The pattern of positive and negative spikes appears to differ across these markets and time periods, and in the following analysis we examine the corresponding statistical structure.\n\n\\subsection{2001-2006 APXUK data}\n\n\\begin{table}[tb]\n\\begin{onehalfspace}\n\n\\begin{center}\n\t\\begin{tabular}{cccccccc}\n\t\t\\hline \n\t\t&  & \\multicolumn{3}{c}{Prior properties } &  & \\multicolumn{2}{c}{Posterior properties}\\tabularnewline\n\t\t\\cline{3-8} \n\t\tParameter &  & Prior & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\\hline \n\t\t$\\mu$ &  & $\\mbox{N}(1,20^{2})$ & 1 & 20 &  & 0.9592 & 0.0308\\tabularnewline\n\t\t$\\sigma^{2}$ &  & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - &  & 0.0096 & 0.0008\\tabularnewline\n\t\t$e^{-1/\\lambda_{0}}$ &  & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$ &  & 0.9170 & 0.0116\\tabularnewline\n\t\t$(\\lambda_{0})$ &  & {(\\mbox{IG}(1,1))} & (- -)  & (- -) &  & (11.7936) & (1.8298)\\tabularnewline\n\t\t$e{}^{-1/\\lambda_1}$ &  & U$(0,1)$ & 0.5 & $0.2887$ &  & 0.1570 & 0.0189\\tabularnewline\n\t\t$(\\lambda_1)$ &  & {(\\mbox{IG}(1,1))} & (- -) & (- -) &  & (0.5403) & (0.0352)\\tabularnewline\n\t\t$\\eta$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.2499 & 0.0297\\tabularnewline\n\t\t$\\beta$ &  & $\\mbox{IG}(1,1)$ & - - & - -  &  & 0.7159 & 0.0738\\tabularnewline\n\t\t\\hline \n\t\\end{tabular}\n\t\\par\\end{center}\n\\end{onehalfspace}\n\n\\caption{\\label{tab:2OU-APXUK-prior-and-estimates} Prior distributions and posterior moments\nobtained when calibrating the 2-OU model to the 2001-2006 APXUK data.  The posteriors for the `indirect' parameters $\\lambda_i$ were obtained by transformation of the parameters $e{}^{-1/\\lambda_i}$ of the Markov chain at each step and their entries are given in brackets. }\n\\end{table}\n\n\n\\subsubsection{One jump component}\\label{sec:APXsingle}\nWe take the priors specified in Table \\ref{tab:2OU-APXUK-prior-and-estimates} as input to the 2-OU model with a single, positive jump component and constant intensity rate. The Markov chain was initialised with the state $(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\eta,\\beta, \\Phi)=(1,5,0.1,2,0.1,0.5,\\mathbf{0})$ where $\\mathbf{0}$ denotes the  absence of jumps, and the birth-and-death parameter $p$ was set equal to 0.5 (ie. equal probability for the birth or death of a jump). Table \\ref{tab:2OU-APXUK-prior-and-estimates} presents summary statistics for the prior and posterior distributions of the univariate parameters. For those priors with a second moment, it may be observed that the standard deviation of the posterior is typically at least an order of magnitude smaller.\n\n\n\n\n\\subsubsection{Two jump components}\n\nWe also calibrate a 3-OU model with constant jump intensity and two positive jump components with the condition $\\lambda_1 > \\lambda_2$ introduced for identifiability (through the use of an appropriate prior as specified in Subsection \\ref{sec:Bayesian-inference-for-3-components}), ie. the jumps of $Y_2$ decay faster than those of $Y_1$. The initial state of the chain was set to \n", "itemtype": "equation", "pos": 50758, "prevtext": "\nwhere $x_{i}$ is the deseasonalised price at time $t_i$ and $w_i$ is the sign of the $i$-th jump component.  From this the noise data $\\{\\varepsilon_{j}^{(k)}\\}_{j=1,\\ldots,N}$ for each MCMC iteration $k$ is obtained and subjected to a Kolmogorov-Smirnov (KS) test for the standard Normal distribution, yielding a $p$-value $p^{(k)}$.\nFollowing \\citet{rubin1984} we call the distribution of $p^{(k)}$ the posterior predictive check distribution. We refer to its mean as the {\\em posterior predictive $p$-value} and interpret it accordingly, cf. \\citet{gelman_bayesian_2003} and references therein.\n\n\nSimilarly we perform diagnostics on the jump processes sampled from our Markov chain. For each jump process $L_i$ at iteration $k$ of the Markov chain, the set of jump sizes and the set of interarrival times are both subjected to KS tests. The former set undergoes a KS test for the exponential distribution with mean $\\beta_i^{(k)}$. In the homogeneous Poisson process model, the latter set undergoes a KS test for the exponential distribution with mean $(\\eta_i^{(k)})^{-1}$; otherwise an independent sample is taken from the interarrival times of an inhomogeneous Poisson process with time varying intensity $I_i(\\vartheta^{(k)}_i,t)$ and its distribution compared with the latter set in \n a two-sample KS test. Posterior predictive $p$-values are reported.\n \n\\subsection{Implementation}\n\nThe parameter-dependent balance between jumps and diffusion in the spot price model \\eqref{eqn:superposition_model} raises a number of potential issues regarding the implementation of the MCMC procedure described above. Extensive testing was carried out with simulated data in order to probe these issues, and details are given in the Appendix.\n\nOur MCMC algorithms were implemented by combining Matlab and C++ MEX code, and were run on a 2.5GHz Intel Xeon E5 processor. For the 2-OU model with $1500$ observations  the computation time for completing 1000 MCMC iterations using a single core was approximately 1.9 seconds. The corresponding figure for the 3-OU model was about 3.6 seconds with a single update of the latent process $\\Phi$, and 8.8 seconds with 5 updates of $\\Phi$ per MCMC iteration. In the numerical examples of Section \\ref{sec:real}, a burn-in period of 500\\,000 iterations was allocated. The following 1.5 million were thinned by taking one sample every 100 iterations and used to establish the posterior distribution. This corresponds to around 1 hour running time for the 2-OU model and below 5 hours for the 3-OU model with the fivefold update of the latent process $\\Phi$.\n\n\\section{Application to the APXUK and EEX markets}\\label{sec:real}\n\n\nIn this section we apply the inference procedure described in Section \\ref{sec:inference} to daily average electricity prices corresponding to the APX Power UK spot base index (APXUK hereafter, quoted in \\pounds/MWh)\n\\footnote{\\url{https://www.apxgroup.com/market-results/apx-power-uk/ukpx-rpd-index-methodology/}\n} and the European Energy Exchange Phelix day base index (EEX, quoted in \\euro/MWh)\n\\footnote{\\url{http://www.epexspot.com/en/}\n}. The data were retrieved from Thompson Reuters Datastream. \n\nWeekends (which tend to differ statistically from weekdays due to a reduction in trading) are removed in both cases. Hence we assume a calendar year of 260 days and take $\\Delta_j=1$ so that parameters are reported in daily units.\n\n\\subsection{Deseasonalised time series}\nIn this paper we perform inference on deseasonalised data, treating the seasonal trend function $f(t)$ as a known characteristic of the particular energy market under study. For the purposes of the numerical illustration in this section we assume the form \\eqref{eq:seasonal-trend} and use the {\\tt nlinfit} Matlab function to solve a non-linear weighted least squares problem \n", "index": 79, "text": "\n\\[\n\\sum_{i=0}^{N}\\left(\\log S_{obs}(t_i)-f(t_i)\\right)^{2} \\to \\min,\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex22.m1\" class=\"ltx_Math\" alttext=\"\\sum_{i=0}^{N}\\left(\\log S_{obs}(t_{i})-f(t_{i})\\right)^{2}\\to\\min,\" display=\"block\"><mrow><mrow><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>N</mi></munderover><msup><mrow><mo>(</mo><mrow><mrow><mrow><mi>log</mi><mo>\u2061</mo><msub><mi>S</mi><mrow><mi>o</mi><mo>\u2062</mo><mi>b</mi><mo>\u2062</mo><mi>s</mi></mrow></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>-</mo><mrow><mi>f</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow><mo>\u2192</mo><mi>min</mi></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": " \nSummary statistics for the prior and posterior distributions of the univariate parameters are given in Table \\ref{tab:prior-3OU-APXUK}. For each of the jump component parameters $\\lambda_i$, $\\eta_i$ and $\\beta_i$ the posterior distributions for the two jump components $i=1,2$ are well separated. \nIn particular the `new' jump component $Y_{2}$ suggests that the quickly decaying price shocks are both less frequent and larger on average than the more slowly decaying jumps given by $Y_1$. As may be anticipated, the posterior distribution of the volatility $\\sigma$ of the diffusion component $Y_{0}$ is correspondingly shifted lower with the inclusion of $Y_2$. However the posterior moments of the speed of mean reversion $\\lambda_0$ remained virtually unchanged.\n\n\\begin{table}[h]\n\t\\begin{onehalfspace}\n\t\t\\begin{center}\n\t\t\t\\begin{tabular}{cccccccc}\n\t\t\t\t\\hline \n\t\t\t\t&  & \\multicolumn{3}{c}{Prior properties } &  & \\multicolumn{2}{c}{Posterior properties}\\tabularnewline\n\t\t\t\t\\cline{3-8} \n\t\t\t\tParameter &  & Prior & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ &  & $\\mbox{N}(1,20^{2})$ & 1 & 20 &  & 0.8693 & 0.0284\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ &  & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - &  & 0.0057 & 0.0006\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ &  & $\\mbox{U}(0,1)$ & 0.5 & 0.2887 &  & 0.9176 & 0.0128\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ &  & ($\\mbox{IG}(1,1)$)  & (- -) & (- -) &  & (11.9352) & (1.9892)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ &  & U$(0,1)$ & 0.5 & 0.2887 &  & 0.6605 & 0.0342\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ &  & ($\\mbox{IG}(1,1)$) & (- -) & (- -) &  & (2.4408) & (0.3075)\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{2}}$ &  & - - & 0.25 & 0.2205 &  & 0.0742 & 0.0148\\tabularnewline\n\t\t\t\t$(\\lambda_{2})$ &  & (- -) & (- -) & (- -) &  & (0.3839) & (0.0297)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.2412 & 0.0487\\tabularnewline\n\t\t\t\t$\\eta_{2}$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.1698 & 0.0250\\tabularnewline\n\t\t\t\t$\\beta_{1}$ &  & $\\mbox{IG}(1,1)$ & - - & - - &  & 0.2243 & 0.0291\\tabularnewline\n\t\t\t\t$\\beta_{2}$ &  & $\\mbox{IG}(1,1)$ & - - & - - &  & 0.8544 & 0.1047\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{center}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:prior-3OU-APXUK}Prior distributions and posterior properties obtained when calibrating the 3-OU model to the 2001-2006 APXUK data. The indirect parameters $\\lambda_i$ are treated as described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}. The distribution and moments of $\\rho_2=e^{-1/\\lambda_2}$ are calculated in the Appendix.}\n\\end{table}\n\n\\subsubsection{Augmentation of the state space}\\label{sub:model-comparison-APXUK}\nIn order to illustrate the role of the latent variables introduced in the augmented state space of our Markov chain, and to show how these may vary between the 2-OU and 3-OU models, Figure \\ref{fig:2c-APXUK-path-y0y1} gives a representation of one posterior sample for each model via their respective latent processes $Y_i$. For clarity of the plot a restricted period of $200$ days is shown, giving the paths of the jump processes, plus the deseasonalised APXUK price superimposed on the implied diffusion $Y_0 = X - \\sum_{i=1}^n Y_i$.\n(For both models these samples are in fact the last state of the simulated Markov chain.)\n\\begin{figure}[p]\n\t\\begin{centering}\n\t\t\\includegraphics[scale = 0.7]{figures/2c-APXUK-path2}\n\t\t\\includegraphics[scale = 0.7]{figures/3c-APXUK-path2}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{fig:2c-APXUK-path-y0y1}Samples from the final state of the Markov chain for the jump processes, plus a section of the deseasonalised 2001-2006 APXUK time series superimposed on the implied diffusion process $Y_0$. Top: 2-OU model, bottom: 3-OU model.}\n\\end{figure}\n\nFrom Table $\\ref{tab:2OU-APXUK-prior-and-estimates}$ the jumps of $Y_1$ are relatively large (their distributional mean size $\\beta$ has posterior expected value $0.72$) and the decay rate $\\lambda_1$ has posterior mean $0.54$. The 3-OU model identifies both slowly decaying small jumps and rapidly decaying large jumps. Inspecting the plots in Figure \\ref{fig:2c-APXUK-path-y0y1} for the 2-OU model around day $600$, it is therefore apparent that in this illustrative example runs of consecutive quickly decaying jumps combine to produce an apparently larger and more slowly decaying disturbance, while some single jumps such as that around day $630$ yield quickly decaying large spikes. In contrast the runs of overlapping spikes are much reduced in the plots for the 3-OU model. \n\n\n\n\\subsubsection{Diagnostics}\n\nThe posterior predictive $p$-values for the diffusion process $Y_0$ are 0.0617 and 0.335 for the 2-OU and 3-OU model respectively. Taking a posterior predictive $p$-value in excess of 0.1 to be acceptable, two jump components are therefore required in order to give the diffusion process an acceptable fit on the basis of this diagnostic.\n\nWe also test the modelling assumption of Poisson jump arrivals with a constant intensity using the diagnostic described in Section \\ref{sec:Diagnostics-theory}. In some electricity markets, in particular in the US and Europe, seasonality  has been observed in the rate of price spikes \\citep{geman_understanding_2006, benth_critical_2012}. A priori this jump seasonality may be explained by greater levels of stress in the power system during the extremes of seasonal variation in weather. In winter, for example, this stress could come from increased demand for heating during cold snaps. However there are a number of fundamental differences between the UK,  US and continental European markets and also differences in the severity of weather,\n\nso it is interesting to check whether the APXUK data requires seasonality in the spike arrivals. \n\nIndeed, in an apparent contrast to the abovementioned markets, the constant jump intensity model is acceptable for the APXUK data with a Bayesian $p$-value for the distribution of spike interarrival times of approximately $0.4$, see Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}. We note finally that the exponential model for jump sizes is acceptable in all cases (with the Bayesian $p$-value exceeding $0.3$). \n\n\\begin{table}[htb]\n\t\\begin{centering}\n\t\t\\begin{tabular}{ccccccc}\n\t\t\t\t\t\t& \\multicolumn{3}{c}{APXUK (2001-6)} & \\multicolumn{3}{c}{EEX (2000-6)}\\tabularnewline\n\t\t\t\\cline{2-7} \n\t\tJump times of\t& 2-OU & 3-OU &  & 2-OU & 3-OU & 3-OU-$I_1$ \\tabularnewline\n\\hline\n $\\Phi_{1}$ \\qquad & 0.0525 & 0.4003 &  & 0.0099 & 0.0185 & 0.1643\\tabularnewline\n\t\t\t $\\Phi_{2}$ \\qquad & - - & 0.3089 &  & - - & 0.4681 & 0.4738\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}\n\t\tPosterior predictive $p$-values for the model of jump times for processes $\\Phi_{i}$.}\n\t\n\t\n\\end{table}\n\n\\subsection{2000-2006 EEX data}\nWe also calibrate 2-OU and 3-OU models to the 2000-2006 EEX data. Since exploratory analysis of the EEX dataset suggests the presence of frequent negative price spikes, our 3-OU model for the EEX series will differ from that for the APXUK dataset by specifying a negative sign for the second jump component $Y_2$.\nIndeed, calibration of the 3-OU model with two positive jump components yields a diagnostic $p$-value for the process $Y_0$ less than $0.005$ and the posterior distributions for the parameters of the two positive jump components are not well separated (data not shown), indicating that the {\\em positive} price spikes in the EEX market tend to have uniform dynamics. In the 3-OU model in \\eqref{eqn:superposition_model} we will therefore set $w_{0}=w_{1}=1,w_{2}=-1$. \n\nFurther, taking into account the literature mentioned above we consider both the constant and periodic jump rates for the positive jump process $L_1(t)$, taking \nthe intensity function $I_1(\\vartheta_1,t)$ given in \\eqref{eq:periodic-intensity-rate} with $k=130$ days for the latter (which corresponds to a period of one half-year) and referring to it as the 3-OU-$I_1$ model.\nWe take the same priors as in the APXUK studies above, now removing the restriction on the decay rates so that the prior for $\\rho_2$ (or equivalently for $\\lambda_2$) is independent and distributed as that for $\\rho_1$ (or $\\lambda_1$), since with jumps of opposite direction there should be no issue of identifiability.  Further, for the 3-OU-$I_1$ model the priors for $\\eta_1$ and $\\delta_1$ are both Ga$(1,1)$, while for  $\\theta_1$ a U$(65,195)$ prior is taken. \n\n\\subsubsection{Number of jump components}\n\n\\begin{sidewaystable}\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{cccccccccccc}\n\t\t\t\t\\hline \n\t\t\t\tParameter & \\multicolumn{3}{c}{Prior properties} & \\multicolumn{2}{c}{2-OU} & \\multicolumn{2}{c}{2-OU-$I_{1}$} & \\multicolumn{2}{c}{3-OU} & \\multicolumn{2}{c}{3-OU-$I_{1}$}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t& Prior & Mean & SD & Mean & SD & Mean & SD & Mean & SD & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ & $\\mbox{N}(1,20^{2})$ & 1 & 20 & 0.9978 & 0.0182 & 0.9954 & (0.0184) & 1.0171 & 0.0230 & 1.0146 & 0.0226\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - & 0.0271 & 0.0014 & 0.0269 & (0.0014) & 0.0122 & 0.0013 & 0.0119 & 0.0012\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ & $\\mbox{U}(0,1)$ & 0.5 & 0.2887 & 0.7978 & 0.0166 & 0.7980 & (0.0162) & 0.8821 & 0.0151 & 0.8835 & 0.0150\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & (4.4612) & (0.4203) & (4.4635) & (0.4071) & (8.1130) & (1.1438) & (8.2193) & (1.1698)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ & U$(0,1)$ & 0.5 & 0.2887 & 0.1057 & 0.0267 & 0.1142 & (0.0246) & 0.1915 & 0.0313 & 0.1809 & 0.0344\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & (0.4441) & (0.0512) & (0.4603) & (0.0465) & (0.6060) & (0.0601) & (0.5859) & (0.0657)\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{2}}$ & U$(0,1)$ & 0.5 & 0.2887 & - - & - - & - - & - - & 0.2295 & 0.0348 & 0.2230 & 0.0384\\tabularnewline\n\t\t\t\t$(\\lambda_{2})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & - - & - - & - - & - - & (0.6814) & (0.0709) & (0.6687) & (0.0775)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & 0.1049 & 0.0185 & - - & - - & 0.1274 & 0.0192 & - - & - -\\tabularnewline\n\t\t\t\t$\\eta_{1}^{*}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & 0.2881 & (0.0619) & - - & - - & 0.2515 & 0.0428\\tabularnewline\n\t\t\t\t$\\eta_{2}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & - - & - - & 0.1438 & 0.0335 & 0.1422 & 0.0320\\tabularnewline\n\t\t\t\t$\\beta_{1}$ & $\\mbox{IG}(1,1)$ & - - & - - & 1.0971 & 0.1435 & 1.0737 & (0.1401) & 0.9045 & 0.1088 & 0.8998 & 0.1052\\tabularnewline\n\t\t\t\t$\\beta_{2}$ & $\\mbox{IG}(1,1)$ & - - & - - & - - & - - & - -  & - - & 0.4176 & 0.0734 & 0.4308 & 0.0793\\tabularnewline\n\t\t\t\t$\\theta_{1}$ & U$(65,195)$ & 130 & 37.5278 & - - & - - & 135.0048 & (2.8474) & - - & - - & 141.3725 & 3.5071\\tabularnewline\n\t\t\t\t$\\delta_{1}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & 0.6271 & (0.1281) & - - & - - & 0.3408 & 0.0884\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\t\n\t\\caption{\\label{tab:prior-3OU-EEX-5Lup-1}Prior distributions and posterior properties\n\t\t\twhen fitting the 2- and 3-OU models to the 2000-2006 EEX data. ${}^*$ In the 2-OU-$I_1$ and 3-OU-$I_1$ models the parameter $\\eta_1$ indicates the maximum jump rate of the periodic intensity function $I_1$. The\n\t\t\tthird OU component $Y_{2}$ of the models 3-OU and 3-OU-$I_1$ is negative. The indirect parameters $\\lambda_i$ are treated as described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}.\t\n\t\t}\n\\end{sidewaystable}\n\nTable \\ref{tab:prior-3OU-EEX-5Lup-1} presents summary statistics for the posterior distributions of the parameters for both the 2-OU model and the 3-OU models applied to the 2000-2006 EEX data. There is agreement across the first two moments of the posterior distributions for all parameters common to the 3-OU and 3-OU-$I_1$ models. Further the posterior diagnostic for the diffusion component $Y_0$ is acceptable for both these three-component models while, as in the APXUK case, the two-component model does not appear to be satisfactory: the posterior $p$-value for\n$Y_0$ is equal to $0.0021$ for the 2-OU model and equal to 0.192 and 0.26 for the 3-OU and 3-OU-$I_1$ models respectively. This is explained by the fact that negative price jumps are not accounted for with the 2-OU model, frequently resulting in large residuals for $Y_0$. \n\nIn contrast with the 2001-2006 APXUK dataset, however, the results for EEX support the presence of seasonality in the occurrence of price spikes, see Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}. The constant jump intensity model appears to be unsatisfactory for the first jump component $\\Phi_1$, with a corresponding $p$-value of 0.0185 in the 3-OU model, while the 3-OU-$I_1$ returns a $p$-value of 0.1643. \nFigure \\ref{3c-EEX-average-number-pos-jumps} displays the number of positive jumps on the EEX market by month, averaged over \nour posterior samples of the process $\\Phi_1$ in the 3-OU-$I_1$ model. \n\n\n\\subsection{2011 - 2015 data}\n\n\\begin{table}[p]\n\t\\begin{centering}\n\t\t\\begin{tabular}{cccccc}\n\t\t\t\\hline \n\t\t\t& APXUK (2011-15)&  & \\multicolumn{3}{c}{EEX (2011-15)}\\tabularnewline\n\t\t\t\\cline{2-2} \\cline{4-6} \n\t\t\t& 2-OU &  & 2-OU & 2-OU-$I_{1}$ & 2-OU$^{-}$\\tabularnewline\n\t\t\t\\hline \n\t\t\t$Y_{0}$ & 0.2167 &  & 0.0001 & 0.0012 & 0.1502\\tabularnewline\n\t\t\tJump times of $\\Phi_{1}$ & 0.3521 &  & 0.4219 & 0.3207 & 0.4452\\tabularnewline\n\t\t\tJump sizes of $\\Phi_{1}$ & 0.4574 &  & 0.5121 & 0.4554 & 0.4998\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1}Posterior predictive\t$p$-values for a range of models for the APXUK and EEX indices over the sample period January 24, 2011 to February 2, 2015.}\n\\end{table}\n\nMotivated by visual inspection of the price data in Figure \\ref{fig:deseasonalised-data}, as discussed in Section \\ref{sec:motivation} we wish to examine whether the statistical structure of the price data differs in periods before and after the global financial crises of 2007-8 and 2009. The models given by \\eqref{eqn:superposition_model} were therefore calibrated to the APXUK and EEX indices over the sample period ranging from January 24, 2011 to February 16, 2015, and the simplest acceptable models were identified on the basis of  posterior predictive $p$-values (again taking 0.1 as the minimum acceptable level). It may be seen from Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1} that the 2011-2015 APXUK data supports the 2-OU model with one positive jump component. In order to discuss the statistics of the jump processes we will refer to the posterior mean values presented in Table \\ref{tab:prior-3OU-APXUK} as `Old' and in Table \\ref{tab:MCMC-realdata-2010-2015} as `New'. Although both the `New' values lie between the corresponding `Old' values,\n$\\beta_1^{\\text {Old}} < \\beta_1^{\\text{New}}<\\beta_2^{\\text{Old}}$ and $\\lambda_1^{\\text {Old}} < \\lambda_1^{\\text{New}}<\\lambda_2^{\\text{Old}}$, the new jump process cannot be interpreted as simply a statistical mixture of the two old jump processes since its intensity is lower than both of the old jump intensities.\\footnote{Also, the sum of two jump OU processes with different mean reversion rates is statistically significantly different from one jump OU process and cannot, therefore, be successfully approximated by the latter.} Indeed, on average the total number of jumps (of any size) per unit time is less than a third for the 2011-2015 data compared to 2001-2006.\n\n\n\nFrom Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1}, the 2011-2015 EEX data in fact supports the 2-OU$^-$ model which has a single, negative jump component (motivating the superscript minus in the notation). In this model the small number of significant upward price movements in Figure \\ref{fig:deseasonalised-data} must therefore be accounted for by correspondingly large residuals in the diffusion component $Y_0$, and this explains the relatively low predictive $p$-value (0.1502) for $Y_0$. With regard to the statistics of the negative jump component, the values $\\lambda_1, \\eta_1, \\beta_1$ in Table \\ref{tab:MCMC-realdata-2010-2015} should be compared to the values of $\\lambda_2, \\eta_2, \\beta_2$ in Table \\ref{tab:prior-3OU-EEX-5Lup-1}. Since negative prices were introduced in this market on September 1, 2008 \\citep{genoese2010occurrence}, in general larger negative jumps were possible in the 2011-2015 data. Indeed the most significant downward jump in 2011-2015 was to a large negative price, and our finding $0.593=\\beta_1^\\text{New}>\\beta_2^\\text{Old}=0.4308$ is consistent with this change to the EEX market structure.\n\n\n\nIn both markets, therefore, we have found statistical evidence that both the frequency and size of positive jumps was decreased in the period after the recent global financial crises relative to the period before. A further common finding is that the diffusion component, which represents `normal' market movements in these models, reverts significantly more quickly in the recent data. This corresponds to a reduction in the coefficient $\\lambda_0$, from 11.9 and 8.22 for the APXUK and EEX markets respectively to approximately 3.6, a value which happens to be consistent across both markets.\n\n\\begin{table}[p]\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{ccccccc}\n\t\t\t\t\\cline{3-7} \n\t\t\t\t&  & \\multicolumn{2}{c}{APXUK (2011-15)} &  & \\multicolumn{2}{c}{EEX (2011-15)}\\tabularnewline\n\t\t\t\t\\cline{3-7} \n\t\t\t\t&  & \\multicolumn{2}{c}{2-OU model} &  & \\multicolumn{2}{c}{2-OU$^{-}$ model}\\tabularnewline\n\t\t\t\t\\cline{3-7} \n\t\t\t\tParameter &  & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ &  & 0.9865 & 0.0095 &  & 1.0480 & 0.0149\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ &  & 0.0071 & 0.0006 &  & 0.0170 & 0.0016\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ &  & 0.7537 & 0.0232 &  & 0.7590 & 0.0251\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ &  & (3.5727) & (0.3976) &  & (3.6736) & (0.4526)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ &  & 0.2104 & 0.0394 &  & 0.1941 & 0.0381\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ &  & (0.6435) & (0.0781) &  & (0.6115) & (0.0741)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ &  & 0.1172 & 0.0324 &  & 0.1105 & 0.0310\\tabularnewline\n\t\t\t\t$\\beta_{1}$ &  & 0.3981 & 0.0921 &  & 0.5930 & 0.1325\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:MCMC-realdata-2010-2015}Posterior properties obtained when calibrating the 2-OU (one positive jump component) and 2-OU$^{-}$ (one negative jump component) models to the APXUK and EEX datasets respectively. The sample period is January 24, 2011 to February 16, 2015.}\n\\end{table}\n\n\n\\section{Conclusions}\n\\label{sec:conclusion}\n\nBy modelling mean-reverting deseasonalised electricity spot prices as the sum of a diffusion process and multiple signed jump processes of deterministic intensity, and applying a Bayesian calibration procedure and posterior diagnostics, we have identified a class of  multifactor models suitable for modelling empirical prices across two different markets and two apparently different time periods.\nIn contrast with several recent studies using stochastic volatility models \nwe have employed multiple signed jump components, albeit with simpler\ndeterministic volatilities (either constant, or deterministic and periodic). This approach allows straightforward comparison of the statistical structure of prices across different markets and time periods: each model has a number of signed jump components with distinguished jump intensities, decay rates and size distributions. In both the APXUK and EEX markets it was found that the statistical structure of the price series differs before and after the period 2007-2010 and, in particular, that the number of positive jump components decreased (from 2 to 1 and 1 to 0 respectively), with the mean reversion speed of the diffusive price component also increasing significantly\nin both markets. Seasonality in the jump intensity was found to be necessary only in the earlier (2000-2006) EEX data and only for its positive jump component.\n\n\\section*{Acknowledgements}\nJM and JG were supported by grants EP/K00557X and EP/I031650 respectively, both from the UK Engineering and Physical Sciences Research Council. JP was supported in part by MNiSzW grant UMO-2012/07/B/ST1/03298.\n\n\\bibliographystyle{apalike}\n\n\n\\bibliography{../../mylibrary}\n\n\n\\appendix\n\\setcounter{figure}{0}\n\\setcounter{table}{0}\n\\label{sec:Appendix}\n\n\\section{Notes on implementation}\n\nIn the first three sections of this Appendix we explore in detail selected aspects of our inference procedure by the use of simulated data. In Section \\ref{sec:simul} we examine the balance between jumps and diffusion in the model, since very frequent jumps may potentially be accumulated into the diffusion component during inference. Then in Section \\ref{sec:multiple} we explain how a particular implementation issue in the 3-OU model was addressed, where the presence of two positive jump components resulted in  slow mixing. In Section \\ref{sec:repn} we illustrate the algorithm's performance in estimating the high-dimensional state of the latent jump process. Further analysis of our MCMC algorithm can be found in \\citet[Chapter 5]{gonzalez_modelling_2015}, where  extensive testing for the 2-OU and 3-OU models on simulated data is carried out. \n\nSection \\ref{subsec:moments_rho_2} explores the prior distribution of $\\rho_2$ when there are two jump components of the same sign and an ordering between $\\lambda_1$ and $\\lambda_2$ (and consequently between $\\rho_1$ and $\\rho_2$) is imposed through the joint prior. The final two sections provide further details of the case studies of Section \\ref{sec:real}, namely deseasonalisation of the raw data (Section \\ref{sec:fit-of-seasonal-trend-function}) and the sensitivity of the results to the choices of prior distributions  (Section \\ref{sec:psa}).\n\n\n\\subsection{Dependence of posterior distributions on $\\eta$}\n\\label{sec:simul}\n\nTo explore the influence of actual jump rates on the output posterior distributions we simulate daily data for 1000 days from the model in\nequation (\\ref{eqn:superposition_model}) with $n=1$ and a range of constant jump intensities $\\eta$, corresponding to averages from 13 to 78 jumps per year, with all other parameters fixed as in Table \\ref{tab:simulation-study-true-values-priors}. This range of jump intensities has been reported in the literature for energy spot price models (cf. \\citet{seifert_modelling_2007,meyer-brandis_multi-factor_2008,benth_stochastic_2008,benth_critical_2012}). Taking the prior distributions listed in Table \\ref{tab:simulation-study-true-values-priors} we then apply our MCMC algorithm. Table \\ref{tab:simulation-study} summarises the results. It may be seen that the accurate separation between the jump process and the diffusion, as measured by the posterior moments of the diffusion coefficient $\\sigma$, is maintained even with a large number of jumps. Furthermore there is generally a negligible influence of the jump intensity on the posterior distributions of other parameters. The main exception is the posterior distribution of the jump size parameter $\\beta$, which becomes more concentrated with its mean closer to the simulation value with increasing values of $\\eta$, the result of more informative data (more jumps) being available for estimation.\n\n\\begin{table}[p]\n\\begin{onehalfspace}\n\\begin{centering}\n\t\\begin{tabular}{ccccc}\n\t\t\\hline \n\t\t&  & \\multicolumn{3}{c}{Prior properties}\\tabularnewline\n\t\t\\hline \n\t\tParameter & Simulation value & Prior & Mean & SD\\tabularnewline\n\t\t\\hline \n\t\t$\\mu$ & 1 & $\\mbox{N}(1,20^{2})$ & 1 & 20\\tabularnewline\n\t\t$\\sigma^{2}$ & 0.01 & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - -\\tabularnewline\n\t\t$e^{-1/\\lambda_0}$ & $e^{-1/8}\\approx0.8825$ & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$\\tabularnewline\n\t\t$(\\lambda_{0})$ & (8) & - - & - - & - -\\tabularnewline\n\t\t$e^{-1/\\lambda_1}$ & $e^{-1/2}\\approx0.6065$ & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$\\tabularnewline\n\t\t$(\\lambda_1$) & (2) & - - & - -  & - - \\tabularnewline\n\t\t$\\eta$ & $\\{0.05,0.1,0.2,0.3\\}$ & $\\mbox{Ga}(1,\\eta_{true}^{-1})$ & $\\eta_{true}$ & $\\eta_{true}$\\tabularnewline\n\t\t$\\beta$ & 0.7 & $\\mbox{IG}(1,1)$ & - - & - -\\tabularnewline\n\t\t\\hline \n\t\\end{tabular}\n\t\\par\\end{centering}\n\\end{onehalfspace}\n\n\\caption{\\label{tab:simulation-study-true-values-priors}Parameter values used to generate simulated data and the prior distributions used in the calibration exercise. Where specified in the prior distribution, $\\eta_{true}$ takes the value of the jump intensity $\\eta$ used in the simulation.}\n\\end{table}\n\n\\begin{table}[p]\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{ccccccccc}\n\t\t\t\t\\hline \n\t\t\t\t\\multicolumn{2}{c}{True value} & \\multicolumn{1}{c}{$\\eta=0.05$} &  & \\multicolumn{1}{c}{$\\eta=0.1$} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{$\\eta=0.2$} &  & \\multicolumn{1}{c}{$\\eta=0.3$}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ & 1 & 0.9999 &  & 0.9959 &  & 0.9954 &  & 0.9988\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.9527, 1.0471)} &  & {\\footnotesize{}(0.9535, 1.0383)} &  & {\\footnotesize{}(0.9404, 1.0504)} &  & {\\footnotesize{}(0.9452, 1.0524)}\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ & 0.01 & 0.0101 &  & 0.0101 &  & 0.0100 &  & 0.0101\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.009, 0.0112)} &  & {\\footnotesize{}(0.009, 0.0111)} &  & {\\footnotesize{}(0.0087, 0.0113)} &  & {\\footnotesize{}(0.0088, 0.0115)}\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ & 0.8825 & 0.8806 &  & 0.8820 &  & 0.8767 &  & 0.8819\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.8457, 0.9155)} &  & {\\footnotesize{}(0.854, 0.91)} &  & {\\footnotesize{}(0.843, 0.9104)} &  & {\\footnotesize{}(0.8506, 0.9132)}\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ & (8) & 8.0463 &  & 8.0892 &  & 7.7580 &  & 8.1052\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(5.5261, 10.5664)} &  & {\\footnotesize{}(6.0167, 10.1618)} &  & {\\footnotesize{}(5.4788, 10.0372)} &  & {\\footnotesize{}(5.8665, 10.3439)}\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_1}$ & 0.6065 & 0.6082 &  & 0.6074 &  & 0.6084 &  & 0.6077\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.5755, 0.6409)} &  & {\\footnotesize{}(0.5808, 0.6339)} &  & {\\footnotesize{}(0.5874, 0.6293)} &  & {\\footnotesize{}(0.5908, 0.6246)}\\tabularnewline\n\t\t\t\t$(\\lambda_1)$ & (2) & 2.0157 &  & 2.0086 &  & 2.0140 &  & 2.0087\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(1.7945, 2.237)} &  & {\\footnotesize{}(1.8267, 2.1905)} &  & {\\footnotesize{}(1.8736, 2.1543)} &  & {\\footnotesize{}(1.8963, 2.1212)}\\tabularnewline\n\t\t\t\t$\\eta$ & - - & 0.0474 &  & 0.0982 &  & 0.1954 &  & 0.2993\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.0279, 0.067)} &  & {\\footnotesize{}(0.0698, 0.1265)} &  & {\\footnotesize{}(0.1522, 0.2385)} &  & {\\footnotesize{}(0.2547, 0.344)}\\tabularnewline\n\t\t\t\t$\\beta$ & 0.7 & 0.7915 &  & 0.7455 &  & 0.7302 &  & 0.7151\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.5398, 1.0433)} &  & {\\footnotesize{}(0.5784, 0.9126)} &  & {\\footnotesize{}(0.5937, 0.8667)} &  & {\\footnotesize{}(0.5891, 0.8412)}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:simulation-study}Average and spread of posterior means across 60\n\t\truns of the MCMC algorithm as the simulation value of $\\eta$ varies. The intervals shown represent this average plus and minus 1.96 standard deviations of the posterior mean values.\n\t\tThe indirect parameters $\\lambda_i$ are treated\n\t\tas described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}.}\n\\end{table}\n\n\n\n\n\\subsection{Multiple updates of the latent process}\n\\label{sec:multiple}\nThe dimensionality of the latent process is much higher than that of the other variables (model parameters) targeted by the Markov chain described in Subsection \\ref{sec:MCMC_implementation} (it is potentially infinite). A single update of the jump process $\\Phi_i$ can affect as little as one jump and therefore can have a much smaller effect on the process than a single update in any other step of the Gibbs sampler. This results in slow mixing of the chain, which becomes most pronounced in the 3-OU model. In this case the algorithm is therefore modified so that the updates to both $\\Phi_{1}$ and $\\Phi_{2}$ described in Section \\ref{sec:phiupdate} are applied five times per single MCMC iteration. This modification results in significant improvements to observed mixing for all model parameters. As an illustration, Figure \\ref{fig:3c-sim-acf-eta-1vs5Lupdates} provides the autocorrelation function (ACF) of\n$\\eta_{1}$ when using the original and the modified schemes for updating $\\Phi$.\n\n\\begin{figure}[p]\n\\begin{centering}\n\\includegraphics[scale = 0.6]{figures/3c-sim-compare-1vs5Lupdates}\n\\par\\end{centering}\n\n\\caption{\\label{fig:3c-sim-acf-eta-1vs5Lupdates}The autocorrelation function of $\\eta_{1}$ when\nfitting the 3-OU model with two positive jump components to simulated data, using one (blue line) and\nfive (orange line) updates of the latent process $\\Phi$ per update\nof the remaining parameters.}\n\\end{figure}\n\n\\subsection{Jump process posteriors}\n\\label{sec:repn}\n\nIn order to illustrate the posterior distributions obtained for the latent jump processes $\\Phi_1$ and $\\Phi_2$, Figure \\ref{fig:3c-true-and-estimated-L} presents results from a simulation study with the 3-OU model. Data was generated from model \\eqref{eqn:superposition_model} with $n=2$ with the following parameter values:\n", "itemtype": "equation", "pos": -1, "prevtext": "\nwhere $S_{obs}(t)$ denotes the observed spot price at time $t$. Table \\ref{tab:estimated-seasonal-trend} presents estimated parameters for the trend functions.\n\nFigure \\ref{fig:deseasonalised-data} displays the resulting deseasonalised time series $X(t)=S_{obs}(t)e^{-f(t)}$. The presence of large positive price spikes is evident in both the APXUK and EEX series, but smaller negative price spikes are also suggested in the EEX series. The negative price spikes observed in the EEX market may be understood to be a consequence of the priority given to wind energy in that network: since the output of wind generation is highly variable, this priority can lead to correspondingly rapid decreases in demand for other sources of generation \\citep{benth_stochastic_2013}. The pattern of positive and negative spikes appears to differ across these markets and time periods, and in the following analysis we examine the corresponding statistical structure.\n\n\\subsection{2001-2006 APXUK data}\n\n\\begin{table}[tb]\n\\begin{onehalfspace}\n\n\\begin{center}\n\t\\begin{tabular}{cccccccc}\n\t\t\\hline \n\t\t&  & \\multicolumn{3}{c}{Prior properties } &  & \\multicolumn{2}{c}{Posterior properties}\\tabularnewline\n\t\t\\cline{3-8} \n\t\tParameter &  & Prior & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\\hline \n\t\t$\\mu$ &  & $\\mbox{N}(1,20^{2})$ & 1 & 20 &  & 0.9592 & 0.0308\\tabularnewline\n\t\t$\\sigma^{2}$ &  & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - &  & 0.0096 & 0.0008\\tabularnewline\n\t\t$e^{-1/\\lambda_{0}}$ &  & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$ &  & 0.9170 & 0.0116\\tabularnewline\n\t\t$(\\lambda_{0})$ &  & {(\\mbox{IG}(1,1))} & (- -)  & (- -) &  & (11.7936) & (1.8298)\\tabularnewline\n\t\t$e{}^{-1/\\lambda_1}$ &  & U$(0,1)$ & 0.5 & $0.2887$ &  & 0.1570 & 0.0189\\tabularnewline\n\t\t$(\\lambda_1)$ &  & {(\\mbox{IG}(1,1))} & (- -) & (- -) &  & (0.5403) & (0.0352)\\tabularnewline\n\t\t$\\eta$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.2499 & 0.0297\\tabularnewline\n\t\t$\\beta$ &  & $\\mbox{IG}(1,1)$ & - - & - -  &  & 0.7159 & 0.0738\\tabularnewline\n\t\t\\hline \n\t\\end{tabular}\n\t\\par\\end{center}\n\\end{onehalfspace}\n\n\\caption{\\label{tab:2OU-APXUK-prior-and-estimates} Prior distributions and posterior moments\nobtained when calibrating the 2-OU model to the 2001-2006 APXUK data.  The posteriors for the `indirect' parameters $\\lambda_i$ were obtained by transformation of the parameters $e{}^{-1/\\lambda_i}$ of the Markov chain at each step and their entries are given in brackets. }\n\\end{table}\n\n\n\\subsubsection{One jump component}\\label{sec:APXsingle}\nWe take the priors specified in Table \\ref{tab:2OU-APXUK-prior-and-estimates} as input to the 2-OU model with a single, positive jump component and constant intensity rate. The Markov chain was initialised with the state $(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\eta,\\beta, \\Phi)=(1,5,0.1,2,0.1,0.5,\\mathbf{0})$ where $\\mathbf{0}$ denotes the  absence of jumps, and the birth-and-death parameter $p$ was set equal to 0.5 (ie. equal probability for the birth or death of a jump). Table \\ref{tab:2OU-APXUK-prior-and-estimates} presents summary statistics for the prior and posterior distributions of the univariate parameters. For those priors with a second moment, it may be observed that the standard deviation of the posterior is typically at least an order of magnitude smaller.\n\n\n\n\n\\subsubsection{Two jump components}\n\nWe also calibrate a 3-OU model with constant jump intensity and two positive jump components with the condition $\\lambda_1 > \\lambda_2$ introduced for identifiability (through the use of an appropriate prior as specified in Subsection \\ref{sec:Bayesian-inference-for-3-components}), ie. the jumps of $Y_2$ decay faster than those of $Y_1$. The initial state of the chain was set to \n", "index": 81, "text": "$$(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\eta_{1},\\beta_{1},\\lambda_{2},\\eta_{2},\\beta_{2},\\Phi)=(1,5,0.2,5,0.001,0.5,1,0.001,0.5, \\mathbf{0}).$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex23.m1\" class=\"ltx_Math\" alttext=\"(\\mu,\\lambda_{0},\\sigma,\\lambda_{1},\\eta_{1},\\beta_{1},\\lambda_{2},\\eta_{2},%&#10;\\beta_{2},\\Phi)=(1,5,0.2,5,0.001,0.5,1,0.001,0.5,\\mathbf{0}).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b7</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03bb</mi><mn>2</mn></msub><mo>,</mo><msub><mi>\u03b7</mi><mn>2</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant=\"normal\">\u03a6</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>,</mo><mn>5</mn><mo>,</mo><mn>0.2</mn><mo>,</mo><mn>5</mn><mo>,</mo><mn>0.001</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>0.001</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn/><mo stretchy=\"false\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\n\nOur 3-OU MCMC algorithm was then applied taking the priors in Table \\ref{tab:prior-3OU-APXUK}. Figure \\ref{fig:3c-true-and-estimated-L} provides a representation of the last 5000 states of the jump processes in the Markov chain, as follows. For each day $j$ having one or more jumps in at least 3000 of these states, the observed jump sizes were averaged;  in states where there was more than one jump on that day, the sum of these jump sizes was taken. This average observed jump size $\\bar{\\xi}_j$ was then plotted against day $j$.\n\n\\begin{figure}[p]\n\\includegraphics[width=\\textwidth]{figures/3c-simulations-true-L1-L2}\n\\caption{\\label{fig:3c-true-and-estimated-L}The simulated jump processes $\\Phi_{1}$ \nand $\\Phi_{2}$ for the 3-OU algorithm (red) and a representation of the last 5000 states of the jump processes in the Markov chain (blue, for details see Appendix \\ref{sec:repn}).}\n\\end{figure}\n\n\\subsection{Prior moments of $\\rho_2$}\\label{subsec:moments_rho_2}\nWhen both jump components have the same sign we impose the condition $\\lambda_1 > \\lambda_2$ via specification of the prior: $\\rho_2 \\sim \\rho_1 U(0,1)$. The resulting distribution of $\\rho_2$ is non-standard with the cumulative distribution function\n", "itemtype": "equation", "pos": 84144, "prevtext": " \nSummary statistics for the prior and posterior distributions of the univariate parameters are given in Table \\ref{tab:prior-3OU-APXUK}. For each of the jump component parameters $\\lambda_i$, $\\eta_i$ and $\\beta_i$ the posterior distributions for the two jump components $i=1,2$ are well separated. \nIn particular the `new' jump component $Y_{2}$ suggests that the quickly decaying price shocks are both less frequent and larger on average than the more slowly decaying jumps given by $Y_1$. As may be anticipated, the posterior distribution of the volatility $\\sigma$ of the diffusion component $Y_{0}$ is correspondingly shifted lower with the inclusion of $Y_2$. However the posterior moments of the speed of mean reversion $\\lambda_0$ remained virtually unchanged.\n\n\\begin{table}[h]\n\t\\begin{onehalfspace}\n\t\t\\begin{center}\n\t\t\t\\begin{tabular}{cccccccc}\n\t\t\t\t\\hline \n\t\t\t\t&  & \\multicolumn{3}{c}{Prior properties } &  & \\multicolumn{2}{c}{Posterior properties}\\tabularnewline\n\t\t\t\t\\cline{3-8} \n\t\t\t\tParameter &  & Prior & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ &  & $\\mbox{N}(1,20^{2})$ & 1 & 20 &  & 0.8693 & 0.0284\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ &  & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - &  & 0.0057 & 0.0006\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ &  & $\\mbox{U}(0,1)$ & 0.5 & 0.2887 &  & 0.9176 & 0.0128\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ &  & ($\\mbox{IG}(1,1)$)  & (- -) & (- -) &  & (11.9352) & (1.9892)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ &  & U$(0,1)$ & 0.5 & 0.2887 &  & 0.6605 & 0.0342\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ &  & ($\\mbox{IG}(1,1)$) & (- -) & (- -) &  & (2.4408) & (0.3075)\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{2}}$ &  & - - & 0.25 & 0.2205 &  & 0.0742 & 0.0148\\tabularnewline\n\t\t\t\t$(\\lambda_{2})$ &  & (- -) & (- -) & (- -) &  & (0.3839) & (0.0297)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.2412 & 0.0487\\tabularnewline\n\t\t\t\t$\\eta_{2}$ &  & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 &  & 0.1698 & 0.0250\\tabularnewline\n\t\t\t\t$\\beta_{1}$ &  & $\\mbox{IG}(1,1)$ & - - & - - &  & 0.2243 & 0.0291\\tabularnewline\n\t\t\t\t$\\beta_{2}$ &  & $\\mbox{IG}(1,1)$ & - - & - - &  & 0.8544 & 0.1047\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{center}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:prior-3OU-APXUK}Prior distributions and posterior properties obtained when calibrating the 3-OU model to the 2001-2006 APXUK data. The indirect parameters $\\lambda_i$ are treated as described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}. The distribution and moments of $\\rho_2=e^{-1/\\lambda_2}$ are calculated in the Appendix.}\n\\end{table}\n\n\\subsubsection{Augmentation of the state space}\\label{sub:model-comparison-APXUK}\nIn order to illustrate the role of the latent variables introduced in the augmented state space of our Markov chain, and to show how these may vary between the 2-OU and 3-OU models, Figure \\ref{fig:2c-APXUK-path-y0y1} gives a representation of one posterior sample for each model via their respective latent processes $Y_i$. For clarity of the plot a restricted period of $200$ days is shown, giving the paths of the jump processes, plus the deseasonalised APXUK price superimposed on the implied diffusion $Y_0 = X - \\sum_{i=1}^n Y_i$.\n(For both models these samples are in fact the last state of the simulated Markov chain.)\n\\begin{figure}[p]\n\t\\begin{centering}\n\t\t\\includegraphics[scale = 0.7]{figures/2c-APXUK-path2}\n\t\t\\includegraphics[scale = 0.7]{figures/3c-APXUK-path2}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{fig:2c-APXUK-path-y0y1}Samples from the final state of the Markov chain for the jump processes, plus a section of the deseasonalised 2001-2006 APXUK time series superimposed on the implied diffusion process $Y_0$. Top: 2-OU model, bottom: 3-OU model.}\n\\end{figure}\n\nFrom Table $\\ref{tab:2OU-APXUK-prior-and-estimates}$ the jumps of $Y_1$ are relatively large (their distributional mean size $\\beta$ has posterior expected value $0.72$) and the decay rate $\\lambda_1$ has posterior mean $0.54$. The 3-OU model identifies both slowly decaying small jumps and rapidly decaying large jumps. Inspecting the plots in Figure \\ref{fig:2c-APXUK-path-y0y1} for the 2-OU model around day $600$, it is therefore apparent that in this illustrative example runs of consecutive quickly decaying jumps combine to produce an apparently larger and more slowly decaying disturbance, while some single jumps such as that around day $630$ yield quickly decaying large spikes. In contrast the runs of overlapping spikes are much reduced in the plots for the 3-OU model. \n\n\n\n\\subsubsection{Diagnostics}\n\nThe posterior predictive $p$-values for the diffusion process $Y_0$ are 0.0617 and 0.335 for the 2-OU and 3-OU model respectively. Taking a posterior predictive $p$-value in excess of 0.1 to be acceptable, two jump components are therefore required in order to give the diffusion process an acceptable fit on the basis of this diagnostic.\n\nWe also test the modelling assumption of Poisson jump arrivals with a constant intensity using the diagnostic described in Section \\ref{sec:Diagnostics-theory}. In some electricity markets, in particular in the US and Europe, seasonality  has been observed in the rate of price spikes \\citep{geman_understanding_2006, benth_critical_2012}. A priori this jump seasonality may be explained by greater levels of stress in the power system during the extremes of seasonal variation in weather. In winter, for example, this stress could come from increased demand for heating during cold snaps. However there are a number of fundamental differences between the UK,  US and continental European markets and also differences in the severity of weather,\n\nso it is interesting to check whether the APXUK data requires seasonality in the spike arrivals. \n\nIndeed, in an apparent contrast to the abovementioned markets, the constant jump intensity model is acceptable for the APXUK data with a Bayesian $p$-value for the distribution of spike interarrival times of approximately $0.4$, see Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}. We note finally that the exponential model for jump sizes is acceptable in all cases (with the Bayesian $p$-value exceeding $0.3$). \n\n\\begin{table}[htb]\n\t\\begin{centering}\n\t\t\\begin{tabular}{ccccccc}\n\t\t\t\t\t\t& \\multicolumn{3}{c}{APXUK (2001-6)} & \\multicolumn{3}{c}{EEX (2000-6)}\\tabularnewline\n\t\t\t\\cline{2-7} \n\t\tJump times of\t& 2-OU & 3-OU &  & 2-OU & 3-OU & 3-OU-$I_1$ \\tabularnewline\n\\hline\n $\\Phi_{1}$ \\qquad & 0.0525 & 0.4003 &  & 0.0099 & 0.0185 & 0.1643\\tabularnewline\n\t\t\t $\\Phi_{2}$ \\qquad & - - & 0.3089 &  & - - & 0.4681 & 0.4738\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}\n\t\tPosterior predictive $p$-values for the model of jump times for processes $\\Phi_{i}$.}\n\t\n\t\n\\end{table}\n\n\\subsection{2000-2006 EEX data}\nWe also calibrate 2-OU and 3-OU models to the 2000-2006 EEX data. Since exploratory analysis of the EEX dataset suggests the presence of frequent negative price spikes, our 3-OU model for the EEX series will differ from that for the APXUK dataset by specifying a negative sign for the second jump component $Y_2$.\nIndeed, calibration of the 3-OU model with two positive jump components yields a diagnostic $p$-value for the process $Y_0$ less than $0.005$ and the posterior distributions for the parameters of the two positive jump components are not well separated (data not shown), indicating that the {\\em positive} price spikes in the EEX market tend to have uniform dynamics. In the 3-OU model in \\eqref{eqn:superposition_model} we will therefore set $w_{0}=w_{1}=1,w_{2}=-1$. \n\nFurther, taking into account the literature mentioned above we consider both the constant and periodic jump rates for the positive jump process $L_1(t)$, taking \nthe intensity function $I_1(\\vartheta_1,t)$ given in \\eqref{eq:periodic-intensity-rate} with $k=130$ days for the latter (which corresponds to a period of one half-year) and referring to it as the 3-OU-$I_1$ model.\nWe take the same priors as in the APXUK studies above, now removing the restriction on the decay rates so that the prior for $\\rho_2$ (or equivalently for $\\lambda_2$) is independent and distributed as that for $\\rho_1$ (or $\\lambda_1$), since with jumps of opposite direction there should be no issue of identifiability.  Further, for the 3-OU-$I_1$ model the priors for $\\eta_1$ and $\\delta_1$ are both Ga$(1,1)$, while for  $\\theta_1$ a U$(65,195)$ prior is taken. \n\n\\subsubsection{Number of jump components}\n\n\\begin{sidewaystable}\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{cccccccccccc}\n\t\t\t\t\\hline \n\t\t\t\tParameter & \\multicolumn{3}{c}{Prior properties} & \\multicolumn{2}{c}{2-OU} & \\multicolumn{2}{c}{2-OU-$I_{1}$} & \\multicolumn{2}{c}{3-OU} & \\multicolumn{2}{c}{3-OU-$I_{1}$}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t& Prior & Mean & SD & Mean & SD & Mean & SD & Mean & SD & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ & $\\mbox{N}(1,20^{2})$ & 1 & 20 & 0.9978 & 0.0182 & 0.9954 & (0.0184) & 1.0171 & 0.0230 & 1.0146 & 0.0226\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - - & 0.0271 & 0.0014 & 0.0269 & (0.0014) & 0.0122 & 0.0013 & 0.0119 & 0.0012\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ & $\\mbox{U}(0,1)$ & 0.5 & 0.2887 & 0.7978 & 0.0166 & 0.7980 & (0.0162) & 0.8821 & 0.0151 & 0.8835 & 0.0150\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & (4.4612) & (0.4203) & (4.4635) & (0.4071) & (8.1130) & (1.1438) & (8.2193) & (1.1698)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ & U$(0,1)$ & 0.5 & 0.2887 & 0.1057 & 0.0267 & 0.1142 & (0.0246) & 0.1915 & 0.0313 & 0.1809 & 0.0344\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & (0.4441) & (0.0512) & (0.4603) & (0.0465) & (0.6060) & (0.0601) & (0.5859) & (0.0657)\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{2}}$ & U$(0,1)$ & 0.5 & 0.2887 & - - & - - & - - & - - & 0.2295 & 0.0348 & 0.2230 & 0.0384\\tabularnewline\n\t\t\t\t$(\\lambda_{2})$ & ($\\mbox{IG}(1,1)$) & (- -) & (- -) & - - & - - & - - & - - & (0.6814) & (0.0709) & (0.6687) & (0.0775)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & 0.1049 & 0.0185 & - - & - - & 0.1274 & 0.0192 & - - & - -\\tabularnewline\n\t\t\t\t$\\eta_{1}^{*}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & 0.2881 & (0.0619) & - - & - - & 0.2515 & 0.0428\\tabularnewline\n\t\t\t\t$\\eta_{2}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & - - & - - & 0.1438 & 0.0335 & 0.1422 & 0.0320\\tabularnewline\n\t\t\t\t$\\beta_{1}$ & $\\mbox{IG}(1,1)$ & - - & - - & 1.0971 & 0.1435 & 1.0737 & (0.1401) & 0.9045 & 0.1088 & 0.8998 & 0.1052\\tabularnewline\n\t\t\t\t$\\beta_{2}$ & $\\mbox{IG}(1,1)$ & - - & - - & - - & - - & - -  & - - & 0.4176 & 0.0734 & 0.4308 & 0.0793\\tabularnewline\n\t\t\t\t$\\theta_{1}$ & U$(65,195)$ & 130 & 37.5278 & - - & - - & 135.0048 & (2.8474) & - - & - - & 141.3725 & 3.5071\\tabularnewline\n\t\t\t\t$\\delta_{1}$ & $\\mbox{Ga}(1,10)$ & 0.1 & 0.1 & - - & - - & 0.6271 & (0.1281) & - - & - - & 0.3408 & 0.0884\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\t\n\t\\caption{\\label{tab:prior-3OU-EEX-5Lup-1}Prior distributions and posterior properties\n\t\t\twhen fitting the 2- and 3-OU models to the 2000-2006 EEX data. ${}^*$ In the 2-OU-$I_1$ and 3-OU-$I_1$ models the parameter $\\eta_1$ indicates the maximum jump rate of the periodic intensity function $I_1$. The\n\t\t\tthird OU component $Y_{2}$ of the models 3-OU and 3-OU-$I_1$ is negative. The indirect parameters $\\lambda_i$ are treated as described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}.\t\n\t\t}\n\\end{sidewaystable}\n\nTable \\ref{tab:prior-3OU-EEX-5Lup-1} presents summary statistics for the posterior distributions of the parameters for both the 2-OU model and the 3-OU models applied to the 2000-2006 EEX data. There is agreement across the first two moments of the posterior distributions for all parameters common to the 3-OU and 3-OU-$I_1$ models. Further the posterior diagnostic for the diffusion component $Y_0$ is acceptable for both these three-component models while, as in the APXUK case, the two-component model does not appear to be satisfactory: the posterior $p$-value for\n$Y_0$ is equal to $0.0021$ for the 2-OU model and equal to 0.192 and 0.26 for the 3-OU and 3-OU-$I_1$ models respectively. This is explained by the fact that negative price jumps are not accounted for with the 2-OU model, frequently resulting in large residuals for $Y_0$. \n\nIn contrast with the 2001-2006 APXUK dataset, however, the results for EEX support the presence of seasonality in the occurrence of price spikes, see Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX}. The constant jump intensity model appears to be unsatisfactory for the first jump component $\\Phi_1$, with a corresponding $p$-value of 0.0185 in the 3-OU model, while the 3-OU-$I_1$ returns a $p$-value of 0.1643. \nFigure \\ref{3c-EEX-average-number-pos-jumps} displays the number of positive jumps on the EEX market by month, averaged over \nour posterior samples of the process $\\Phi_1$ in the 3-OU-$I_1$ model. \n\n\n\\subsection{2011 - 2015 data}\n\n\\begin{table}[p]\n\t\\begin{centering}\n\t\t\\begin{tabular}{cccccc}\n\t\t\t\\hline \n\t\t\t& APXUK (2011-15)&  & \\multicolumn{3}{c}{EEX (2011-15)}\\tabularnewline\n\t\t\t\\cline{2-2} \\cline{4-6} \n\t\t\t& 2-OU &  & 2-OU & 2-OU-$I_{1}$ & 2-OU$^{-}$\\tabularnewline\n\t\t\t\\hline \n\t\t\t$Y_{0}$ & 0.2167 &  & 0.0001 & 0.0012 & 0.1502\\tabularnewline\n\t\t\tJump times of $\\Phi_{1}$ & 0.3521 &  & 0.4219 & 0.3207 & 0.4452\\tabularnewline\n\t\t\tJump sizes of $\\Phi_{1}$ & 0.4574 &  & 0.5121 & 0.4554 & 0.4998\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\t\\par\\end{centering}\n\t\n\t\\caption{\\label{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1}Posterior predictive\t$p$-values for a range of models for the APXUK and EEX indices over the sample period January 24, 2011 to February 2, 2015.}\n\\end{table}\n\nMotivated by visual inspection of the price data in Figure \\ref{fig:deseasonalised-data}, as discussed in Section \\ref{sec:motivation} we wish to examine whether the statistical structure of the price data differs in periods before and after the global financial crises of 2007-8 and 2009. The models given by \\eqref{eqn:superposition_model} were therefore calibrated to the APXUK and EEX indices over the sample period ranging from January 24, 2011 to February 16, 2015, and the simplest acceptable models were identified on the basis of  posterior predictive $p$-values (again taking 0.1 as the minimum acceptable level). It may be seen from Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1} that the 2011-2015 APXUK data supports the 2-OU model with one positive jump component. In order to discuss the statistics of the jump processes we will refer to the posterior mean values presented in Table \\ref{tab:prior-3OU-APXUK} as `Old' and in Table \\ref{tab:MCMC-realdata-2010-2015} as `New'. Although both the `New' values lie between the corresponding `Old' values,\n$\\beta_1^{\\text {Old}} < \\beta_1^{\\text{New}}<\\beta_2^{\\text{Old}}$ and $\\lambda_1^{\\text {Old}} < \\lambda_1^{\\text{New}}<\\lambda_2^{\\text{Old}}$, the new jump process cannot be interpreted as simply a statistical mixture of the two old jump processes since its intensity is lower than both of the old jump intensities.\\footnote{Also, the sum of two jump OU processes with different mean reversion rates is statistically significantly different from one jump OU process and cannot, therefore, be successfully approximated by the latter.} Indeed, on average the total number of jumps (of any size) per unit time is less than a third for the 2011-2015 data compared to 2001-2006.\n\n\n\nFrom Table \\ref{tab:Bayesian-pvalues-times-sizes-APXUK-EEX-1-1-1}, the 2011-2015 EEX data in fact supports the 2-OU$^-$ model which has a single, negative jump component (motivating the superscript minus in the notation). In this model the small number of significant upward price movements in Figure \\ref{fig:deseasonalised-data} must therefore be accounted for by correspondingly large residuals in the diffusion component $Y_0$, and this explains the relatively low predictive $p$-value (0.1502) for $Y_0$. With regard to the statistics of the negative jump component, the values $\\lambda_1, \\eta_1, \\beta_1$ in Table \\ref{tab:MCMC-realdata-2010-2015} should be compared to the values of $\\lambda_2, \\eta_2, \\beta_2$ in Table \\ref{tab:prior-3OU-EEX-5Lup-1}. Since negative prices were introduced in this market on September 1, 2008 \\citep{genoese2010occurrence}, in general larger negative jumps were possible in the 2011-2015 data. Indeed the most significant downward jump in 2011-2015 was to a large negative price, and our finding $0.593=\\beta_1^\\text{New}>\\beta_2^\\text{Old}=0.4308$ is consistent with this change to the EEX market structure.\n\n\n\nIn both markets, therefore, we have found statistical evidence that both the frequency and size of positive jumps was decreased in the period after the recent global financial crises relative to the period before. A further common finding is that the diffusion component, which represents `normal' market movements in these models, reverts significantly more quickly in the recent data. This corresponds to a reduction in the coefficient $\\lambda_0$, from 11.9 and 8.22 for the APXUK and EEX markets respectively to approximately 3.6, a value which happens to be consistent across both markets.\n\n\\begin{table}[p]\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{ccccccc}\n\t\t\t\t\\cline{3-7} \n\t\t\t\t&  & \\multicolumn{2}{c}{APXUK (2011-15)} &  & \\multicolumn{2}{c}{EEX (2011-15)}\\tabularnewline\n\t\t\t\t\\cline{3-7} \n\t\t\t\t&  & \\multicolumn{2}{c}{2-OU model} &  & \\multicolumn{2}{c}{2-OU$^{-}$ model}\\tabularnewline\n\t\t\t\t\\cline{3-7} \n\t\t\t\tParameter &  & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ &  & 0.9865 & 0.0095 &  & 1.0480 & 0.0149\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ &  & 0.0071 & 0.0006 &  & 0.0170 & 0.0016\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ &  & 0.7537 & 0.0232 &  & 0.7590 & 0.0251\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ &  & (3.5727) & (0.3976) &  & (3.6736) & (0.4526)\\tabularnewline\n\t\t\t\t$e{}^{-1/\\lambda_{1}}$ &  & 0.2104 & 0.0394 &  & 0.1941 & 0.0381\\tabularnewline\n\t\t\t\t$(\\lambda_{1})$ &  & (0.6435) & (0.0781) &  & (0.6115) & (0.0741)\\tabularnewline\n\t\t\t\t$\\eta_{1}$ &  & 0.1172 & 0.0324 &  & 0.1105 & 0.0310\\tabularnewline\n\t\t\t\t$\\beta_{1}$ &  & 0.3981 & 0.0921 &  & 0.5930 & 0.1325\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:MCMC-realdata-2010-2015}Posterior properties obtained when calibrating the 2-OU (one positive jump component) and 2-OU$^{-}$ (one negative jump component) models to the APXUK and EEX datasets respectively. The sample period is January 24, 2011 to February 16, 2015.}\n\\end{table}\n\n\n\\section{Conclusions}\n\\label{sec:conclusion}\n\nBy modelling mean-reverting deseasonalised electricity spot prices as the sum of a diffusion process and multiple signed jump processes of deterministic intensity, and applying a Bayesian calibration procedure and posterior diagnostics, we have identified a class of  multifactor models suitable for modelling empirical prices across two different markets and two apparently different time periods.\nIn contrast with several recent studies using stochastic volatility models \nwe have employed multiple signed jump components, albeit with simpler\ndeterministic volatilities (either constant, or deterministic and periodic). This approach allows straightforward comparison of the statistical structure of prices across different markets and time periods: each model has a number of signed jump components with distinguished jump intensities, decay rates and size distributions. In both the APXUK and EEX markets it was found that the statistical structure of the price series differs before and after the period 2007-2010 and, in particular, that the number of positive jump components decreased (from 2 to 1 and 1 to 0 respectively), with the mean reversion speed of the diffusive price component also increasing significantly\nin both markets. Seasonality in the jump intensity was found to be necessary only in the earlier (2000-2006) EEX data and only for its positive jump component.\n\n\\section*{Acknowledgements}\nJM and JG were supported by grants EP/K00557X and EP/I031650 respectively, both from the UK Engineering and Physical Sciences Research Council. JP was supported in part by MNiSzW grant UMO-2012/07/B/ST1/03298.\n\n\\bibliographystyle{apalike}\n\n\n\\bibliography{../../mylibrary}\n\n\n\\appendix\n\\setcounter{figure}{0}\n\\setcounter{table}{0}\n\\label{sec:Appendix}\n\n\\section{Notes on implementation}\n\nIn the first three sections of this Appendix we explore in detail selected aspects of our inference procedure by the use of simulated data. In Section \\ref{sec:simul} we examine the balance between jumps and diffusion in the model, since very frequent jumps may potentially be accumulated into the diffusion component during inference. Then in Section \\ref{sec:multiple} we explain how a particular implementation issue in the 3-OU model was addressed, where the presence of two positive jump components resulted in  slow mixing. In Section \\ref{sec:repn} we illustrate the algorithm's performance in estimating the high-dimensional state of the latent jump process. Further analysis of our MCMC algorithm can be found in \\citet[Chapter 5]{gonzalez_modelling_2015}, where  extensive testing for the 2-OU and 3-OU models on simulated data is carried out. \n\nSection \\ref{subsec:moments_rho_2} explores the prior distribution of $\\rho_2$ when there are two jump components of the same sign and an ordering between $\\lambda_1$ and $\\lambda_2$ (and consequently between $\\rho_1$ and $\\rho_2$) is imposed through the joint prior. The final two sections provide further details of the case studies of Section \\ref{sec:real}, namely deseasonalisation of the raw data (Section \\ref{sec:fit-of-seasonal-trend-function}) and the sensitivity of the results to the choices of prior distributions  (Section \\ref{sec:psa}).\n\n\n\\subsection{Dependence of posterior distributions on $\\eta$}\n\\label{sec:simul}\n\nTo explore the influence of actual jump rates on the output posterior distributions we simulate daily data for 1000 days from the model in\nequation (\\ref{eqn:superposition_model}) with $n=1$ and a range of constant jump intensities $\\eta$, corresponding to averages from 13 to 78 jumps per year, with all other parameters fixed as in Table \\ref{tab:simulation-study-true-values-priors}. This range of jump intensities has been reported in the literature for energy spot price models (cf. \\citet{seifert_modelling_2007,meyer-brandis_multi-factor_2008,benth_stochastic_2008,benth_critical_2012}). Taking the prior distributions listed in Table \\ref{tab:simulation-study-true-values-priors} we then apply our MCMC algorithm. Table \\ref{tab:simulation-study} summarises the results. It may be seen that the accurate separation between the jump process and the diffusion, as measured by the posterior moments of the diffusion coefficient $\\sigma$, is maintained even with a large number of jumps. Furthermore there is generally a negligible influence of the jump intensity on the posterior distributions of other parameters. The main exception is the posterior distribution of the jump size parameter $\\beta$, which becomes more concentrated with its mean closer to the simulation value with increasing values of $\\eta$, the result of more informative data (more jumps) being available for estimation.\n\n\\begin{table}[p]\n\\begin{onehalfspace}\n\\begin{centering}\n\t\\begin{tabular}{ccccc}\n\t\t\\hline \n\t\t&  & \\multicolumn{3}{c}{Prior properties}\\tabularnewline\n\t\t\\hline \n\t\tParameter & Simulation value & Prior & Mean & SD\\tabularnewline\n\t\t\\hline \n\t\t$\\mu$ & 1 & $\\mbox{N}(1,20^{2})$ & 1 & 20\\tabularnewline\n\t\t$\\sigma^{2}$ & 0.01 & $\\mbox{IG}(1.5,0.005)$ & 0.01 & - -\\tabularnewline\n\t\t$e^{-1/\\lambda_0}$ & $e^{-1/8}\\approx0.8825$ & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$\\tabularnewline\n\t\t$(\\lambda_{0})$ & (8) & - - & - - & - -\\tabularnewline\n\t\t$e^{-1/\\lambda_1}$ & $e^{-1/2}\\approx0.6065$ & $\\mbox{U}(0,1)$ & 0.5 & $0.2887$\\tabularnewline\n\t\t$(\\lambda_1$) & (2) & - - & - -  & - - \\tabularnewline\n\t\t$\\eta$ & $\\{0.05,0.1,0.2,0.3\\}$ & $\\mbox{Ga}(1,\\eta_{true}^{-1})$ & $\\eta_{true}$ & $\\eta_{true}$\\tabularnewline\n\t\t$\\beta$ & 0.7 & $\\mbox{IG}(1,1)$ & - - & - -\\tabularnewline\n\t\t\\hline \n\t\\end{tabular}\n\t\\par\\end{centering}\n\\end{onehalfspace}\n\n\\caption{\\label{tab:simulation-study-true-values-priors}Parameter values used to generate simulated data and the prior distributions used in the calibration exercise. Where specified in the prior distribution, $\\eta_{true}$ takes the value of the jump intensity $\\eta$ used in the simulation.}\n\\end{table}\n\n\\begin{table}[p]\n\t\\begin{onehalfspace}\n\t\t\\begin{centering}\n\t\t\t\\begin{tabular}{ccccccccc}\n\t\t\t\t\\hline \n\t\t\t\t\\multicolumn{2}{c}{True value} & \\multicolumn{1}{c}{$\\eta=0.05$} &  & \\multicolumn{1}{c}{$\\eta=0.1$} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{$\\eta=0.2$} &  & \\multicolumn{1}{c}{$\\eta=0.3$}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\t$\\mu$ & 1 & 0.9999 &  & 0.9959 &  & 0.9954 &  & 0.9988\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.9527, 1.0471)} &  & {\\footnotesize{}(0.9535, 1.0383)} &  & {\\footnotesize{}(0.9404, 1.0504)} &  & {\\footnotesize{}(0.9452, 1.0524)}\\tabularnewline\n\t\t\t\t$\\sigma^{2}$ & 0.01 & 0.0101 &  & 0.0101 &  & 0.0100 &  & 0.0101\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.009, 0.0112)} &  & {\\footnotesize{}(0.009, 0.0111)} &  & {\\footnotesize{}(0.0087, 0.0113)} &  & {\\footnotesize{}(0.0088, 0.0115)}\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_{0}}$ & 0.8825 & 0.8806 &  & 0.8820 &  & 0.8767 &  & 0.8819\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.8457, 0.9155)} &  & {\\footnotesize{}(0.854, 0.91)} &  & {\\footnotesize{}(0.843, 0.9104)} &  & {\\footnotesize{}(0.8506, 0.9132)}\\tabularnewline\n\t\t\t\t$(\\lambda_{0})$ & (8) & 8.0463 &  & 8.0892 &  & 7.7580 &  & 8.1052\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(5.5261, 10.5664)} &  & {\\footnotesize{}(6.0167, 10.1618)} &  & {\\footnotesize{}(5.4788, 10.0372)} &  & {\\footnotesize{}(5.8665, 10.3439)}\\tabularnewline\n\t\t\t\t$e^{-1/\\lambda_1}$ & 0.6065 & 0.6082 &  & 0.6074 &  & 0.6084 &  & 0.6077\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.5755, 0.6409)} &  & {\\footnotesize{}(0.5808, 0.6339)} &  & {\\footnotesize{}(0.5874, 0.6293)} &  & {\\footnotesize{}(0.5908, 0.6246)}\\tabularnewline\n\t\t\t\t$(\\lambda_1)$ & (2) & 2.0157 &  & 2.0086 &  & 2.0140 &  & 2.0087\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(1.7945, 2.237)} &  & {\\footnotesize{}(1.8267, 2.1905)} &  & {\\footnotesize{}(1.8736, 2.1543)} &  & {\\footnotesize{}(1.8963, 2.1212)}\\tabularnewline\n\t\t\t\t$\\eta$ & - - & 0.0474 &  & 0.0982 &  & 0.1954 &  & 0.2993\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.0279, 0.067)} &  & {\\footnotesize{}(0.0698, 0.1265)} &  & {\\footnotesize{}(0.1522, 0.2385)} &  & {\\footnotesize{}(0.2547, 0.344)}\\tabularnewline\n\t\t\t\t$\\beta$ & 0.7 & 0.7915 &  & 0.7455 &  & 0.7302 &  & 0.7151\\tabularnewline\n\t\t\t\t&  & {\\footnotesize{}(0.5398, 1.0433)} &  & {\\footnotesize{}(0.5784, 0.9126)} &  & {\\footnotesize{}(0.5937, 0.8667)} &  & {\\footnotesize{}(0.5891, 0.8412)}\\tabularnewline\n\t\t\t\t\\hline \n\t\t\t\\end{tabular}\n\t\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:simulation-study}Average and spread of posterior means across 60\n\t\truns of the MCMC algorithm as the simulation value of $\\eta$ varies. The intervals shown represent this average plus and minus 1.96 standard deviations of the posterior mean values.\n\t\tThe indirect parameters $\\lambda_i$ are treated\n\t\tas described in the caption to Table \\ref{tab:2OU-APXUK-prior-and-estimates}.}\n\\end{table}\n\n\n\n\n\\subsection{Multiple updates of the latent process}\n\\label{sec:multiple}\nThe dimensionality of the latent process is much higher than that of the other variables (model parameters) targeted by the Markov chain described in Subsection \\ref{sec:MCMC_implementation} (it is potentially infinite). A single update of the jump process $\\Phi_i$ can affect as little as one jump and therefore can have a much smaller effect on the process than a single update in any other step of the Gibbs sampler. This results in slow mixing of the chain, which becomes most pronounced in the 3-OU model. In this case the algorithm is therefore modified so that the updates to both $\\Phi_{1}$ and $\\Phi_{2}$ described in Section \\ref{sec:phiupdate} are applied five times per single MCMC iteration. This modification results in significant improvements to observed mixing for all model parameters. As an illustration, Figure \\ref{fig:3c-sim-acf-eta-1vs5Lupdates} provides the autocorrelation function (ACF) of\n$\\eta_{1}$ when using the original and the modified schemes for updating $\\Phi$.\n\n\\begin{figure}[p]\n\\begin{centering}\n\\includegraphics[scale = 0.6]{figures/3c-sim-compare-1vs5Lupdates}\n\\par\\end{centering}\n\n\\caption{\\label{fig:3c-sim-acf-eta-1vs5Lupdates}The autocorrelation function of $\\eta_{1}$ when\nfitting the 3-OU model with two positive jump components to simulated data, using one (blue line) and\nfive (orange line) updates of the latent process $\\Phi$ per update\nof the remaining parameters.}\n\\end{figure}\n\n\\subsection{Jump process posteriors}\n\\label{sec:repn}\n\nIn order to illustrate the posterior distributions obtained for the latent jump processes $\\Phi_1$ and $\\Phi_2$, Figure \\ref{fig:3c-true-and-estimated-L} presents results from a simulation study with the 3-OU model. Data was generated from model \\eqref{eqn:superposition_model} with $n=2$ with the following parameter values:\n", "index": 83, "text": "\n\\[ \n(\\mu,\\lambda_{0},\\lambda_{1},\\lambda_2,\\sigma,\\beta_1,\\beta_2,\\eta_1,\\eta_2)=(1,8,3,0.5,0.15,0.5,1,0.1,0.05).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex24.m1\" class=\"ltx_Math\" alttext=\"(\\mu,\\lambda_{0},\\lambda_{1},\\lambda_{2},\\sigma,\\beta_{1},\\beta_{2},\\eta_{1},%&#10;\\eta_{2})=(1,8,3,0.5,0.15,0.5,1,0.1,0.05).\" display=\"block\"><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mi>\u03bc</mi><mo>,</mo><msub><mi>\u03bb</mi><mn>0</mn></msub><mo>,</mo><msub><mi>\u03bb</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03bb</mi><mn>2</mn></msub><mo>,</mo><mi>\u03c3</mi><mo>,</mo><msub><mi>\u03b2</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b2</mi><mn>2</mn></msub><mo>,</mo><msub><mi>\u03b7</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\u03b7</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>,</mo><mn>8</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.15</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mn>0.05</mn><mo stretchy=\"false\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02900.tex", "nexttext": "\nUsing integration by parts we compute the first moment $\\mathbb{E} (\\rho_2) = 1/4$ and the second moment $\\mathbb{E} (\\rho^2_2) = 1/9$.\n\n\n\\subsection{Deseasonalisation}\\label{sec:fit-of-seasonal-trend-function}\n\nFor completeness Table \\ref{tab:estimated-seasonal-trend} presents coefficients from fitting the seasonal trend in \\eqref{eq:seasonal-trend}. In the case of 2011-2015 EEX data, which contains three instances of negative prices, these were replaced by averages of the neighbouring price values for the purposes of deseasonalisation only.\n\n\\begin{table}[p]\n\t\\begin{onehalfspace}\n\t\\begin{centering}\n\t\t\\begin{tabular}{cccccccc}\n\t\t\t\\hline \n\t\t\tDataset &  & $a_{1}$ & $a_{2}$ & $a_{3}$ & $a_{4}$ & $a_{5}$ & $a_{6}$\\tabularnewline\n\t\t\t\\hline \n\t\t\tAPXUK (2001-6) &  & 2.5770 & 0.0008 & -0.0817 & 0.0443 & -0.0097 & -0.0395\\tabularnewline\n\t\t\tEEX (2000-6) &  & 2.9399 & 0.0006 & 0.0055 & -0.0803 & 0.0415 & -0.0140\\tabularnewline\n\t\t\tAPXUK (2011-15) &  & 3.9005 & -0.0001 & -0.0014 & 0.0342 & 0.0104 & -0.0368\\tabularnewline\n\t\t\tEEX (2011-15) &  & 4.0399 & -0.0005 & -0.0585 & 0.0156 & 0.0298 & -0.0315\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:estimated-seasonal-trend}Fitted seasonal trend coefficients in daily units.}\n\t\n\t\n\\end{table}\n\n\\subsection{Prior sensitivity analysis}\n\\label{sec:psa}\nOur aim in the empirical studies of Section \\ref{sec:real} was to let the data speak for itself. In order to explore the degree of sensitivity of the above results to the choice of prior distributions we apply the 3-OU-$I_1$ algorithm, which is the most complex of the above algorithms, to the 2000-2006 EEX  dataset. Among the large number of parameters we choose to vary the priors of $\\sigma^2,\\eta_{1}$ and $\\eta_{2}$, since these parameters proved to exhibit relatively slow mixing, which might point to difficulties with estimation.\nWe make the following variations to the set of priors (replacing the corresponding Gibbs steps with Metropolis-Hastings steps as necessary):\n\\begin{itemize}\n\t\\item Prior 1: as in Table \\ref{tab:prior-3OU-EEX-5Lup-1}\n\t\\item Prior 2: as in Table \\ref{tab:prior-3OU-EEX-5Lup-1}, except that $\\sigma^{2}\\sim\\mbox{U}(0,0.25^{2})$,\n\t\\item Prior 3: as in Table \\ref{tab:prior-3OU-EEX-5Lup-1}, except that $\\pi(\\eta_{i})\\propto 1_{\\{\\eta_i>0\\}}, i=1,2$ \\emph{(improper uninformative priors)}.\n\\end{itemize}\nTable \\ref{tab:3c-EEX-sensitivity} presents the first two moments of the posterior distributions under these alternative sets of priors. The variations in these moments are insignificant, indicating that the data provides a clear indication of the parameter values.\n\n\\begin{table}[btp]\n\t\\begin{onehalfspace}\n\t\\begin{centering}\n\t\t\\begin{tabular}{cccccccccc}\n\t\t\t\\hline \n\t\t\t& \\multicolumn{9}{c}{Posterior properties}\\tabularnewline\n\t\t\t\\cline{3-10} \n\t\t\t&  & \\multicolumn{2}{c}{Prior 1} &  & \\multicolumn{2}{c}{Prior 2} &  & \\multicolumn{2}{c}{Prior 3}\\tabularnewline\n\t\t\t\\cline{3-10} \n\t\t\tParameter &  & Mean & SD &  & Mean & SD &  & Mean & SD\\tabularnewline\n\t\t\t\\hline \n\t\t\t$\\mu$ &  & 1.0146 & 0.0226 &  & 1.0144 & 0.0224 &  & 1.0149 & 0.0222\\tabularnewline\n\t\t\t$\\sigma^{2}$ &  & 0.0119 & 0.0012 &  & 0.0123 & 0.0013 &  & 0.0123 & 0.0014\\tabularnewline\n\t\t\t$e^{-1/\\lambda_{0}}$ &  & 0.8835 & 0.0150 &  & 0.8804 & 0.0151 &  & 0.8809 & 0.0158\\tabularnewline\n\t\t\t$\\lambda_{0}$ &  & 8.2193 & 1.1698 &  & 7.9874 & 1.1095 &  & 8.0406 & 1.1894\\tabularnewline\n\t\t\t$e{}^{-1/\\lambda_{1}}$ &  & 0.1809 & 0.0344 &  & 0.1905 & 0.0327 &  & 0.1826 & 0.0314\\tabularnewline\n\t\t\t$\\lambda_{1}$ &  & 0.5859 & 0.0657 &  & 0.6043 & 0.0628 &  & 0.5889 & 0.0601\\tabularnewline\n\t\t\t$e^{-1/\\lambda_{2}}$ &  & 0.2230 & 0.0384 &  & 0.2282 & 0.0374 &  & 0.2481 & 0.0446\\tabularnewline\n\t\t\t$\\lambda_{2}$ &  & 0.6687 & 0.0775 &  & 0.6791 & 0.0764 &  & 0.6730 & 0.0733\\tabularnewline\n\t\t\t$\\eta_{1}$ &  & 0.2515 & 0.0428 &  & 0.2492 & 0.0431 &  & 0.2253 & 0.0362\\tabularnewline\n\t\t\t$\\eta_{2}$ &  & 0.1422 & 0.0320 &  & 0.1381 & 0.0308 &  & 0.1329 & 0.0223\\tabularnewline\n\t\t\t$\\beta_{1}$ &  & 0.8998 & 0.1052 &  & 0.8928 & 0.1129 &  & 0.9105 & 0.1169\\tabularnewline\n\t\t\t$\\beta_{2}$ &  & 0.4308 & 0.0793 &  & 0.4272 & 0.0792 &  & 0.4329 & 0.0671\\tabularnewline\n\t\t\t$\\theta_{1}$ &  & 141.3725 & 3.5071 &  & 140.6855 & 3.5296 &  & 140.8370 & 3.5109\\tabularnewline\n\t\t\t$\\delta_{1}$ &  & 0.3408 & 0.0884 &  & 0.3531 & 0.0892 &  & 0.3546 & 0.0899\\tabularnewline\n\t\t\t\\hline \n\t\t\\end{tabular}\n\t\t\\par\\end{centering}\n\t\\end{onehalfspace}\n\t\n\t\\caption{\\label{tab:3c-EEX-sensitivity}Prior sensitivity analysis for the 3-0U-$I_1$ model.}\n\\end{table}\n\n\n\n", "itemtype": "equation", "pos": 85483, "prevtext": "\n\nOur 3-OU MCMC algorithm was then applied taking the priors in Table \\ref{tab:prior-3OU-APXUK}. Figure \\ref{fig:3c-true-and-estimated-L} provides a representation of the last 5000 states of the jump processes in the Markov chain, as follows. For each day $j$ having one or more jumps in at least 3000 of these states, the observed jump sizes were averaged;  in states where there was more than one jump on that day, the sum of these jump sizes was taken. This average observed jump size $\\bar{\\xi}_j$ was then plotted against day $j$.\n\n\\begin{figure}[p]\n\\includegraphics[width=\\textwidth]{figures/3c-simulations-true-L1-L2}\n\\caption{\\label{fig:3c-true-and-estimated-L}The simulated jump processes $\\Phi_{1}$ \nand $\\Phi_{2}$ for the 3-OU algorithm (red) and a representation of the last 5000 states of the jump processes in the Markov chain (blue, for details see Appendix \\ref{sec:repn}).}\n\\end{figure}\n\n\\subsection{Prior moments of $\\rho_2$}\\label{subsec:moments_rho_2}\nWhen both jump components have the same sign we impose the condition $\\lambda_1 > \\lambda_2$ via specification of the prior: $\\rho_2 \\sim \\rho_1 U(0,1)$. The resulting distribution of $\\rho_2$ is non-standard with the cumulative distribution function\n", "index": 85, "text": "\n\\[\n\\mathbb{P}(\\rho_2 \\le x) = \\int_0^1 \\Big(\\frac{x}{\\rho_1} \\wedge 1\\Big) d\\rho_1 = x (1 - \\log(x)), \\quad x \\in (0,1).\n\\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex25.m1\" class=\"ltx_Math\" alttext=\"\\mathbb{P}(\\rho_{2}\\leq x)=\\int_{0}^{1}\\Big{(}\\frac{x}{\\rho_{1}}\\wedge 1\\Big{)%&#10;}d\\rho_{1}=x(1-\\log(x)),\\quad x\\in(0,1).\" display=\"block\"><mrow><mi>\u2119</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03c1</mi><mn>2</mn></msub><mo>\u2264</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><msubsup><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mn>0</mn><mn>1</mn></msubsup><mrow><mo maxsize=\"160%\" minsize=\"160%\">(</mo><mfrac><mi>x</mi><msub><mi>\u03c1</mi><mn>1</mn></msub></mfrac><mo>\u2227</mo><mn>1</mn><mo maxsize=\"160%\" minsize=\"160%\">)</mo></mrow><mi>d</mi><msub><mi>\u03c1</mi><mn>1</mn></msub><mo>=</mo><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>log</mi><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">)</mo></mrow><mo rspace=\"12.5pt\">,</mo><mi>x</mi><mo>\u2208</mo><mrow><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}]