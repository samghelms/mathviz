[{"file": "1601.02304.tex", "nexttext": "\nwhere $D$, $\\tau$ and $a$ are known environmental and sensor parameters,\n\n", "itemtype": "equation", "pos": 8715, "prevtext": "\n\n\\begin{frontmatter}\n\n\\title{Localisation of a source of biochemical agent dispersion using binary measurements} \n\n\n\n\n\n\n\\author[dsto]{Branko Ristic\\fnref{fnBranko}}\n\n\\author[dsto]{Ajith Gunatilaka\\corref{mycorrespondingauthor}}\n\\ead{ajith.gunatilaka@dsto.defence.gov.au}\n\n\n\\author[dsto]{Ralph Gailis\\fnref{fnRalph}}\n\n\\cortext[mycorrespondingauthor]{Corresponding author}\n\n\n\\fntext[fnBranko]{Now with RMIT University}\n\n\\fntext[fnRalph]{Now with NSID, DST Group}\n\\address[dsto]{Land Division, DST Group, Melbourne, Australia}\n\n\n\\begin{abstract}\nUsing the measurements collected at a number of known locations by a moving binary sensor,\ncharacterised by an unknown threshold, the problem is to estimate\nthe parameters of a biochemical source, continuously releasing material into the\natmosphere.  The solution is formulated in the Bayesian framework\nusing a dispersion model of Poisson distributed particle encounters\nin a turbulent flow.  The method is implemented using the importance\nsampling technique and successfully validated with three\nexperimental datasets under different wind conditions.\n\\end{abstract}\n\n\\begin{keyword}\nBayesian parameter estimation, binary sensor, turbulent\ndispersion, source localisation\n\\end{keyword}\n\n\\end{frontmatter}\n\n\n\n\\section{Introduction}\n\\label{sec:intro}\n\nLocalisation of a source of biological or chemical agent dispersing\nin the atmosphere is an important problem for national security\nand environmental monitoring applications \\cite{kendal}. Wind, as\nthe dominant transport mechanism in the atmosphere, \ncan generate strong turbulent motion, causing the released agent to\ndisperse as a plume whose spread increases with the downwind\ndistance \\cite{arya_98}. Assuming a constant release of the\ncontaminant, the problem involves estimation of source parameters:\nits location and intensity (release-rate). Two types of measurements\nare generally at disposal for source localisation: (i) the\nconcentration measurements at spatially distributed sensor\nlocations; (ii) the average wind speed and wind direction (typically\navailable from a nearby meteorological station).\n\nMany references are available on the topic of biochemical source\nlocalisation, assuming un-quantised (analog) concentration\nmeasurements. Standard solutions are based on optimisation\ntechniques, such as the nonlinear least squares \\cite{matthes_05} or\nsimulated annealing \\cite{thomson_07}. These methods are unreliable\ndue to local minima or poor convergence; in addition, they provide\nonly point estimates, without uncertainty intervals. The preferred\nalternative is the use of Bayesian techniques; they result in the\nposterior probability density function (PDF) of the source parameter\nvector, thereby providing an uncertainty measure to any point\nestimate derived from it. Most Bayesian methods for source\nestimation are based on Markov chain Monte Carlo (MCMC) technique,\nassuming either Gaussian or log-Gausiian likelihood function of\nmeasurements \\cite{keats_07,humphries_12,ortner,senocak_08}.\nRecently, a likelihood-free Bayesian method for source localisation\nwas proposed in \\cite{ristic_15}. \n\n\nBinary sensor networks have become widespread in environmental monitoring applications\nbecause binary sensors generate as little as one bit of information.\nSuch binary sensors allow inexpensive sensing with minimal communication\nrequirements \\cite{aslam_03}. In the context of binary sensor\nnetworks, an excellent overview of non-Bayesian chemical source\nlocalisation techniques is presented in \\cite{chen2008greedy}. Best\nachievable accuracy of source localisation using binary sensors has\nbeen discussed in \\cite{Ristic2014}.\n\nPrior work in using binary sensor data for biochemical source localisation assumes that the detection threshold\nof the sensor is known. It is a reasonable assumption for a commercial sensor whose sensitivity is specified (for example, in  parts per\nmillion by volume (ppm$_v$) or grams per cubic meter) by the manufacturer and when the sensor is well calibrated. However, we consider at least two scenarios where the detection threshold of a binary sensor may not be accurately known. The first scenario is when a sensor's detection threshold goes off calibration due to environmental conditions such as temperature or humidity or ageing of the sensor. The second scenario is where the sensor is a human rather than a device. For example, imagine a person smelling a strong odour such as due to a gas leak or a decomposing animal carcass. When the person moves around, the smell will be detected in some locations but not in others, producing a binary measurement sequence without knowing the exact value of the threshold in ppm or g/m$^3$. In this paper, we develop a Bayesian algorithm that carries out source parameter estimation based on such\n{\\em binary concentration measurements} where the sensor threshold is unknown. A Monte Carlo technique, importance sampling, is applied to calculate the posterior PDF approximately. The method is successfully\nvalidated using three experimental datasets obtained under different wind conditions.\n\n\n\n \n\n\\section{Models}\n\\label{s:2}\n\n\\subsection{Dispersion model}\nTo solve the source localisation problem described above, we propose a solution  formulated in the Bayesian framework which relies on\ntwo mathematical models: the atmospheric dispersion model and the\nconcentration measurement model. A dispersion model mathematically describes the physical processes that govern the\natmospheric dispersion of the released agent within the plume. The\nprimary purpose of a dispersion model is to calculate the mean\nconcentration of emitted material at a given sensor location. A\nplethora of dispersion models are in use today\n\\cite{holmes_morawska_06} to account for specific weather\nconditions, terrain, source height, etc. In this paper, we adopt a\ntwo-dimensional dispersion model of ``particle encounters'' in a\nturbulent flow, described in \\cite{vergassola_07}. During a certain sensing\nperiod, each sensor  experiences a Poisson distributed number of\n``encounters'' with released particles. The binary nature of\nmeasurements indicates that a sensor reading of binary ``1'' or a ``positive detection''  corresponds to\nthe number of such encounters exceeding a particular threshold.\n\n If a binary sensor with a particular threshold makes\npositive detections (binary ``1'') at some locations and zero detections (binary ``0'') at other locations due to a source of \na certain release rate, the measurements at these locations will be the same even if both the source release rate and the sensor detection\nthreshold were scaled up or down together by the same amount; it is  the ratio between the source release rate and the sensor threshold that determines \nwhich sensor locations will have positive or zero readings. Therefore, when we estimate the source parameters using binary data from a sensor whose\ndetection threshold is unknown, it is not possible to estimate the absolute value of the source release rate; only the release rate normalised by the assumed sensor threshold can be estimated. Nevertheless, the source location, which is actually the parameter of main interest, can be estimated.  Without loss of generality, in our \nexperiments, we assumed the sensor to output binary ``1'' if it encounters at least one particle during a sensing period and output a binary  ``0'' otherwise. \n\nLet us assume that the biochemical source is located at  $(x_0, y_0)$, with a normalised release rate of $Q_0$.  The particles released from the source propagate with the isotropic diffusivity $D$, but can  also be advected by wind. We assume the released particles to have an average lifetime of  $\\tau$. While the wind speed is typically available from meteorological data from a nearby measuring station, we use this speed as the prior guess for a Bayesian estimate of the true, effective wind speed affecting the advection of particles. Accordingly, let us  assume that the mean wind speed is $V$ and  the mean wind  direction coincides with the direction of the $x$ axis. We denote the PDF of the wind speed by $\\pi(V)$.  A spherical sensor of\nsmall size $a$ at a location with coordinates $(x,y)$, non-coincidental with the source location $(x_0,y_0)$, will experience a series\nof encounters with the released particles. \n\n    \nDenoting the parameter vector we wish to estimate, consisting of the source coordinates  ($x_0$, $y_0$), normalised source release rate $Q_0$, and the wind speed $V$, by  ${\\mbox{\\boldmath$\\theta$}} = [x_0\\;y_0\\;\nQ_0\\; V]^\\intercal$, the rate of particle encounters by the sensor at the  $i$th location (where $i=1,\\dots,M$) with coordinates $(x_i,y_i)$ can be modelled\nas \\cite{vergassola_07}:\n\n", "index": 1, "text": "\\begin{equation}\nR(x_i,y_i|{\\mbox{\\boldmath$\\theta$}}) =\n\\frac{Q_0}{\\ln\\left(\\frac{\\lambda}{a}\\right)}\\,\\exp\\left[{\\frac{(x_0-x_i)V}{2D}}\\right]\\cdot\nK_0\\left(\\frac{d_i({\\mbox{\\boldmath$\\theta$}})}{\\lambda}\\right)  \\label{e:disp}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"R(x_{i},y_{i}|{\\mbox{\\boldmath$\\theta$}})=\\frac{Q_{0}}{\\ln\\left(\\frac{\\lambda}%&#10;{a}\\right)}\\,\\exp\\left[{\\frac{(x_{0}-x_{i})V}{2D}}\\right]\\cdot K_{0}\\left(%&#10;\\frac{d_{i}({\\mbox{\\boldmath$\\theta$}})}{\\lambda}\\right)\" display=\"block\"><mrow><mi>R</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mpadded width=\"+1.7pt\"><mfrac><msub><mi>Q</mi><mn>0</mn></msub><mrow><mi>ln</mi><mo>\u2061</mo><mrow><mo>(</mo><mfrac><mi>\u03bb</mi><mi>a</mi></mfrac><mo>)</mo></mrow></mrow></mfrac></mpadded><mi>exp</mi><mrow><mo>[</mo><mfrac><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>-</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>V</mi></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi>D</mi></mrow></mfrac><mo>]</mo></mrow><mo>\u22c5</mo><msub><mi>K</mi><mn>0</mn></msub><mrow><mo>(</mo><mfrac><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mi>\u03bb</mi></mfrac><mo>)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nis the distance from the source to  $i$th sensor location, $K_0$ is the modified\nBessel function of order zero, and\n\n", "itemtype": "equation", "pos": 9033, "prevtext": "\nwhere $D$, $\\tau$ and $a$ are known environmental and sensor parameters,\n\n", "index": 3, "text": "\\begin{equation}\nd_i({\\mbox{\\boldmath$\\theta$}}) = \\sqrt{(x_i-x_0)^2+(y_i-y_0)^2}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"d_{i}({\\mbox{\\boldmath$\\theta$}})=\\sqrt{(x_{i}-x_{0})^{2}+(y_{i}-y_{0})^{2}}\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><msqrt><mrow><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>-</mo><msub><mi>y</mi><mn>0</mn></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\n\n\n\\subsection{Measurement model}\nThe stochastic process of sensor encounters with released particles\nis modelled by a Poisson distribution. The probability that \nsensor at location $(x_i,y_i)$ encounters\n$z\\in\\mathbb{Z}^+\\cup\\{0\\}$ particles ($z$ is a non-negative\ninteger) during a time interval $t_0$ is then:\n\n", "itemtype": "equation", "pos": 9246, "prevtext": "\nis the distance from the source to  $i$th sensor location, $K_0$ is the modified\nBessel function of order zero, and\n\n", "index": 5, "text": "\\begin{equation}\n\\lambda = \\sqrt{\\frac{D\\tau}{1+\\frac{V^2\\tau}{4D}}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\lambda=\\sqrt{\\frac{D\\tau}{1+\\frac{V^{2}\\tau}{4D}}}.\" display=\"block\"><mrow><mrow><mi>\u03bb</mi><mo>=</mo><msqrt><mfrac><mrow><mi>D</mi><mo>\u2062</mo><mi>\u03c4</mi></mrow><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><msup><mi>V</mi><mn>2</mn></msup><mo>\u2062</mo><mi>\u03c4</mi></mrow><mrow><mn>4</mn><mo>\u2062</mo><mi>D</mi></mrow></mfrac></mrow></mfrac></msqrt></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nwhere $\\mu_i =  t_0\\cdot R(x_i,y_i|{\\mbox{\\boldmath$\\theta$}}) $ is the mean concentration\nat $(x_i,y_i)$. Equation (\\ref{e:likf}) represents the full\nspecification of the likelihood function of parameter vector ${\\mbox{\\boldmath$\\theta$}}$,\ngiven the sensor encounters $z$ counts at the  $i$th position.\n\nHowever, because the actual sensor is binary, the measurement model is\n\n", "itemtype": "equation", "pos": 9643, "prevtext": "\n\n\n\\subsection{Measurement model}\nThe stochastic process of sensor encounters with released particles\nis modelled by a Poisson distribution. The probability that \nsensor at location $(x_i,y_i)$ encounters\n$z\\in\\mathbb{Z}^+\\cup\\{0\\}$ particles ($z$ is a non-negative\ninteger) during a time interval $t_0$ is then:\n\n", "index": 7, "text": "\\begin{equation}\n\\mathcal{P}(z; \\mu_i) = \\frac{(\\mu_i)^{z}}{z!}e^{-\\mu_i}\n\\label{e:likf}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{P}(z;\\mu_{i})=\\frac{(\\mu_{i})^{z}}{z!}e^{-\\mu_{i}}\" display=\"block\"><mrow><mrow><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcab</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mo>;</mo><msub><mi>\u03bc</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><msup><mrow><mo stretchy=\"false\">(</mo><msub><mi>\u03bc</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><mi>z</mi></msup><mrow><mi>z</mi><mo lspace=\"0pt\" rspace=\"3.5pt\">!</mo></mrow></mfrac><mo>\u2062</mo><msup><mi>e</mi><mrow><mo>-</mo><msub><mi>\u03bc</mi><mi>i</mi></msub></mrow></msup></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nNote that $b_i$ is a Bernoulli random variable with the parameter\n\\begin{eqnarray} q_i({\\mbox{\\boldmath$\\theta$}}) & = & \\text{Pr}\\{b_i=1\\}\\\\\n   & = & \\sum_{z=1}^{\\infty} \\mathcal{P}(z;\\mu_i) \\\\\n   & = & 1 -  \\mathcal{P}(0;\\mu_i) \\\\\n   & = & 1 - e^{-\\mu_i}.\n   \\end{eqnarray}\nThe likelihood function for the sensor when it is at the $i$th location is then:\n\n", "itemtype": "equation", "pos": 10124, "prevtext": "\nwhere $\\mu_i =  t_0\\cdot R(x_i,y_i|{\\mbox{\\boldmath$\\theta$}}) $ is the mean concentration\nat $(x_i,y_i)$. Equation (\\ref{e:likf}) represents the full\nspecification of the likelihood function of parameter vector ${\\mbox{\\boldmath$\\theta$}}$,\ngiven the sensor encounters $z$ counts at the  $i$th position.\n\nHowever, because the actual sensor is binary, the measurement model is\n\n", "index": 9, "text": "\\begin{equation}\nb_i = \\begin{cases} 1, & \\text{if } z =1,2,3,\\dots\\\\\n0, & \\text{if } z = 0.\n\\end{cases}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"b_{i}=\\begin{cases}1,&amp;\\text{if }z=1,2,3,\\dots\\\\&#10;0,&amp;\\text{if }z=0.\\end{cases}\" display=\"block\"><mrow><msub><mi>b</mi><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"left\"><mrow><mn>1</mn><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>z</mi></mrow><mo>=</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mi mathvariant=\"normal\">\u2026</mi></mrow></mrow></mtd></mtr><mtr><mtd columnalign=\"left\"><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd columnalign=\"left\"><mrow><mrow><mrow><mtext>if\u00a0</mtext><mo>\u2062</mo><mi>z</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nAssuming sensor measurements are conditionally independent, the likelihood\nfunction of the parameter vector ${\\mbox{\\boldmath$\\theta$}}$,  given the binary\nmeasurement vector ${\\mathbf{b}} = [b_1,\\dots,b_M]^\\intercal$, is a product:\n\n", "itemtype": "equation", "pos": 10601, "prevtext": "\nNote that $b_i$ is a Bernoulli random variable with the parameter\n\\begin{eqnarray} q_i({\\mbox{\\boldmath$\\theta$}}) & = & \\text{Pr}\\{b_i=1\\}\\\\\n   & = & \\sum_{z=1}^{\\infty} \\mathcal{P}(z;\\mu_i) \\\\\n   & = & 1 -  \\mathcal{P}(0;\\mu_i) \\\\\n   & = & 1 - e^{-\\mu_i}.\n   \\end{eqnarray}\nThe likelihood function for the sensor when it is at the $i$th location is then:\n\n", "index": 11, "text": "\\begin{equation}\np(b_i|{\\mbox{\\boldmath$\\theta$}}) = [q_i({\\mbox{\\boldmath$\\theta$}})]^{b_i} \\, [1-q_i({\\mbox{\\boldmath$\\theta$}})]^{1-b_i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"p(b_{i}|{\\mbox{\\boldmath$\\theta$}})=[q_{i}({\\mbox{\\boldmath$\\theta$}})]^{b_{i}%&#10;}\\,[1-q_{i}({\\mbox{\\boldmath$\\theta$}})]^{1-b_{i}}.\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy=\"false\">|</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mpadded width=\"+1.7pt\"><msup><mrow><mo stretchy=\"false\">[</mo><msub><mi>q</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><msub><mi>b</mi><mi>i</mi></msub></msup></mpadded><msup><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo>-</mo><msub><mi>q</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\n\n\n\\section{Parameter estimation}\n\nThe estimation problem is formulated in the Bayesian framework. The goal\nis to compute the posterior PDF: the probability distribution of the\nparameter vector ${\\mbox{\\boldmath$\\theta$}}$  conditional on the measurement vector\n${\\mathbf{b}}$. The posterior PDF provides a complete probabilistic\ndescription of the information contained in the measurements about\nthe parameter vector ${\\mbox{\\boldmath$\\theta$}}$. The basic elements required to compute the\nposterior distribution of are: (i) the prior distribution for the\nparameter vector $\\pi({\\mbox{\\boldmath$\\theta$}})$ and (ii) the likelihood function\n$p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}})$. Given these quantities, Bayes rule can be used to\nfind the posterior PDF  as\n\n", "itemtype": "equation", "pos": 10990, "prevtext": "\nAssuming sensor measurements are conditionally independent, the likelihood\nfunction of the parameter vector ${\\mbox{\\boldmath$\\theta$}}$,  given the binary\nmeasurement vector ${\\mathbf{b}} = [b_1,\\dots,b_M]^\\intercal$, is a product:\n\n", "index": 13, "text": "\\begin{equation}\np({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}}) = \\prod_{i=1}^M  [q_i({\\mbox{\\boldmath$\\theta$}})]^{b_i} \\,\n[1-q_i({\\mbox{\\boldmath$\\theta$}})]^{1-b_i}. \\label{e:lik}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}})=\\prod_{i=1}^{M}[q_{i}({\\mbox{%&#10;\\boldmath$\\theta$}})]^{b_{i}}\\,[1-q_{i}({\\mbox{\\boldmath$\\theta$}})]^{1-b_{i}}.\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u220f</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mpadded width=\"+1.7pt\"><msup><mrow><mo stretchy=\"false\">[</mo><msub><mi>q</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><msub><mi>b</mi><mi>i</mi></msub></msup></mpadded><msup><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo>-</mo><msub><mi>q</mi><mi>i</mi></msub><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mo stretchy=\"false\">]</mo></mrow><mrow><mn>1</mn><mo>-</mo><msub><mi>b</mi><mi>i</mi></msub></mrow></msup><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nThe prior distribution $\\pi({\\mbox{\\boldmath$\\theta$}})$ is typically non-Gaussian. For\nexample, the source position can be restricted to polygon regions,\nwhile $Q_0$ and $V$ are strictly positive random variables.\nQuantities of interest related to ${\\mbox{\\boldmath$\\theta$}}$ (e.g., the posterior mean,\nvariance) can be computed from the posterior PDF.\n\n\\begin{figure*}[t!]\n\\centering\n\\begin{tabular}{cc}\n\\includegraphics[height=7.0cm]{data1_a.eps} &\n\\includegraphics[height=7.0cm]{data1_d.eps}\\\\\n\\includegraphics[height=5.3cm]{data1_bc.eps} &\n\\includegraphics[height=5.3cm]{data1_ef.eps}\n\\end{tabular}\n \\caption{\\footnotesize Estimation results for dataset 1: the left column is the prior PDF; the right column is the posterior\n PDF. Marginalised prior PDF $\\pi(x_0,y_0)$ in (a) and the marginalised posterior PDF $p(x_0,y_0|{\\mathbf{b}})$ in\n (d), approximated by random samples (indicated by scattered red dots).\nSensor locations (green squares are positive readings,\n blue circles are non-detections), as well as the building contours (black lines), also indicated in (a) and (d).\n Wind direction coincides with the $x$ axis. True source marked in (d) at $(-298.4,-342.6)$ (grey asterix). Figures (b) and (e) show the histograms corresponding to\n $\\pi(Q_0)$ and $p(Q_0|{\\mathbf{b}})$, respectively. Figures (c) and (f) show the histograms corresponding to $\\pi(V)$ and $p(V|{\\mathbf{b}})$, respectively.}\n \\label{f:1}\n\\end{figure*}\n\nOptimal Bayesian estimation is generally impossible because the\nposterior PDF cannot be found in closed-form; this is certainly the\ncase for the likelihood function specified in Sec.\\ref{s:2} and a\nnon-Gaussian prior $\\pi({\\mbox{\\boldmath$\\theta$}})$. Hence we apply a Monte Carlo\napproximation technique of the optimal Bayesian estimation, known as\nimportance sampling \\cite{robert_casella}. This technique\napproximates the posterior PDF by a weighted random sample\n$\\{w_n,{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$, which is created as follows.\nFirst, a sample $\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$ is drawn from an\nimportance distribution $\\varrho$, i.e., ${\\mbox{\\boldmath$\\theta$}}_n\\sim \\varrho({\\mbox{\\boldmath$\\theta$}})$,\nfor $n=1,\\dots,N$. The unnormalised  weights are then computed as:\n\n", "itemtype": "equation", "pos": 11947, "prevtext": "\n\n\n\\section{Parameter estimation}\n\nThe estimation problem is formulated in the Bayesian framework. The goal\nis to compute the posterior PDF: the probability distribution of the\nparameter vector ${\\mbox{\\boldmath$\\theta$}}$  conditional on the measurement vector\n${\\mathbf{b}}$. The posterior PDF provides a complete probabilistic\ndescription of the information contained in the measurements about\nthe parameter vector ${\\mbox{\\boldmath$\\theta$}}$. The basic elements required to compute the\nposterior distribution of are: (i) the prior distribution for the\nparameter vector $\\pi({\\mbox{\\boldmath$\\theta$}})$ and (ii) the likelihood function\n$p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}})$. Given these quantities, Bayes rule can be used to\nfind the posterior PDF  as\n\n", "index": 15, "text": "\\begin{equation}\np({\\mbox{\\boldmath$\\theta$}}|{\\mathbf{b}}) = \\frac{p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}})\\pi({\\mbox{\\boldmath$\\theta$}})}{\\int p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}})\\pi({\\mbox{\\boldmath$\\theta$}})\nd{\\mbox{\\boldmath$\\theta$}}}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"p({\\mbox{\\boldmath$\\theta$}}|{\\mathbf{b}})=\\frac{p({\\mathbf{b}}|{\\mbox{%&#10;\\boldmath$\\theta$}})\\pi({\\mbox{\\boldmath$\\theta$}})}{\\int p({\\mathbf{b}}|{%&#10;\\mbox{\\boldmath$\\theta$}})\\pi({\\mbox{\\boldmath$\\theta$}})d{\\mbox{\\boldmath$%&#10;\\theta$}}}.\" display=\"block\"><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mo largeop=\"true\" symmetric=\"true\">\u222b</mo><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mi>\u03c0</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow><mi>d</mi><mi>\ud835\udf3d</mi></mrow></mfrac><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nfor $n=1,\\dots,N$. Finally, the weights are normalised, i.e., $w_n =\n\\tilde{w}_n /\\sum_{n=1}^N \\tilde{w}_n$, for $n=1,\\dots,N$. The\nchoice of importance distribution $\\varrho$ plays a significant role\nin the convergence of point estimators based on the approximation\n$\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$. Ideally $\\varrho$ should resemble the\nposterior. Since the posterior is unknown, good importance\ndistributions are often designed iteratively (population Monte Carlo\n\\cite{robert_casella},  progressive correction \\cite{musso_et_al_00,\nmorelande_ristic_rad}). As $N\\rightarrow \\infty$, however, the\nchoice of $\\varrho$ is less relevant and even the prior $\\pi$ may be\nused as an (admittedly inefficient) importance distribution; this is\ndone in our implementation for convenience. Furthermore, once the weighted random\nsample $\\{w_n,{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$ is computed, resampling\n(with replacement) is carried out \\cite{pfbook} resulting in a\nsample with uniform weights. This last step was carried out mainly\nto improve the effect of visualisation of the posterior PDF (see\nfigures in the next section). In our implementation, the prior PDF\nis adopted as:\n\n", "itemtype": "equation", "pos": 14471, "prevtext": "\nThe prior distribution $\\pi({\\mbox{\\boldmath$\\theta$}})$ is typically non-Gaussian. For\nexample, the source position can be restricted to polygon regions,\nwhile $Q_0$ and $V$ are strictly positive random variables.\nQuantities of interest related to ${\\mbox{\\boldmath$\\theta$}}$ (e.g., the posterior mean,\nvariance) can be computed from the posterior PDF.\n\n\\begin{figure*}[t!]\n\\centering\n\\begin{tabular}{cc}\n\\includegraphics[height=7.0cm]{data1_a.eps} &\n\\includegraphics[height=7.0cm]{data1_d.eps}\\\\\n\\includegraphics[height=5.3cm]{data1_bc.eps} &\n\\includegraphics[height=5.3cm]{data1_ef.eps}\n\\end{tabular}\n \\caption{\\footnotesize Estimation results for dataset 1: the left column is the prior PDF; the right column is the posterior\n PDF. Marginalised prior PDF $\\pi(x_0,y_0)$ in (a) and the marginalised posterior PDF $p(x_0,y_0|{\\mathbf{b}})$ in\n (d), approximated by random samples (indicated by scattered red dots).\nSensor locations (green squares are positive readings,\n blue circles are non-detections), as well as the building contours (black lines), also indicated in (a) and (d).\n Wind direction coincides with the $x$ axis. True source marked in (d) at $(-298.4,-342.6)$ (grey asterix). Figures (b) and (e) show the histograms corresponding to\n $\\pi(Q_0)$ and $p(Q_0|{\\mathbf{b}})$, respectively. Figures (c) and (f) show the histograms corresponding to $\\pi(V)$ and $p(V|{\\mathbf{b}})$, respectively.}\n \\label{f:1}\n\\end{figure*}\n\nOptimal Bayesian estimation is generally impossible because the\nposterior PDF cannot be found in closed-form; this is certainly the\ncase for the likelihood function specified in Sec.\\ref{s:2} and a\nnon-Gaussian prior $\\pi({\\mbox{\\boldmath$\\theta$}})$. Hence we apply a Monte Carlo\napproximation technique of the optimal Bayesian estimation, known as\nimportance sampling \\cite{robert_casella}. This technique\napproximates the posterior PDF by a weighted random sample\n$\\{w_n,{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$, which is created as follows.\nFirst, a sample $\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$ is drawn from an\nimportance distribution $\\varrho$, i.e., ${\\mbox{\\boldmath$\\theta$}}_n\\sim \\varrho({\\mbox{\\boldmath$\\theta$}})$,\nfor $n=1,\\dots,N$. The unnormalised  weights are then computed as:\n\n", "index": 17, "text": "\\begin{equation}\n\\tilde{w}_n = \\frac{\\pi({\\mbox{\\boldmath$\\theta$}}_n)}{\\varrho({\\mbox{\\boldmath$\\theta$}}_n)}\\,p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}}_n)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"\\tilde{w}_{n}=\\frac{\\pi({\\mbox{\\boldmath$\\theta$}}_{n})}{\\varrho({\\mbox{%&#10;\\boldmath$\\theta$}}_{n})}\\,p({\\mathbf{b}}|{\\mbox{\\boldmath$\\theta$}}_{n})\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi>w</mi><mo stretchy=\"false\">~</mo></mover><mi>n</mi></msub><mo>=</mo><mpadded width=\"+1.7pt\"><mfrac><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udf3d</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>\u03f1</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udf3d</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac></mpadded><mi>p</mi><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc1b</mi><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udf3d</mi><mi>n</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow></math>", "type": "latex"}, {"file": "1601.02304.tex", "nexttext": "\nwhere: $\\pi(x_0,y_0)$ is a uniform distribution over designated\npolygon areas (e.g., buildings); $\\pi(Q_0)$ is a Gamma distribution\nwith shape $k$ and scale parameter $\\eta$; $\\pi(V)$ is a normal\ndistribution with mean $\\bar{V}$ and standard deviation $\\sigma_V$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\section{Experimental results}\n\n\n\nThree experimental datasets collected using a single moving binary sensor with unknown detection threshold were used in the paper to demonstrate the algorithm performance(further details of the experiments cannot be revealed on security grounds).  In all cases, algorithm parameters were\nadopted as follows: $a=0.2$ m, $D=1$ m$^2$/s, $\\tau = 1000$ s,\n$t_0=1$ s,  sample size $N=5000$, shape parameter $k=3$, scale\nparameter $\\eta=7$, standard deviation of wind speed $\\sigma_V =\n0.2$ m/s. The wind conditions were different for the three datasets.\nThe mean wind direction was specified by angle $\\alpha$, measured\nanticlockwise from the $x$ axis. The values of wind parameters\n$(\\bar{V},\\alpha)$ were $(0.28 \\text{ m/s}, 195^\\circ)$, $(0.12\n\\text{m/s},-10^\\circ)$ and $(0.14 \\text{m/s},150^\\circ)$ for the\nfirst, second and the third dataset, respectively.\n\n\n\nFig.\\ref{f:1} shows the results obtained using dataset 1: the left\ncolumn displays the prior PDF $\\pi({\\mbox{\\boldmath$\\theta$}})$; the right column - the\nposterior PDF $p({\\mbox{\\boldmath$\\theta$}}|{\\mathbf{b}})$. Figs. \\ref{f:1}.(a) and \\ref{f:1}.(d)\ndisplay the top down view of the area where the experiment was\ncarried out. The placement and the readings of the binary sensor\nare also marked (the number of sensor locations in dataset 1 is $M=45$).\nThe locations where the sensor reported positive readings (i.e., $b_i=1$), are marked by\ngreen squares; the remaining (non-detecting) sensor locations are marked by blue circles. Based on prior knowledge (e.g., intelligence reports), figures (a) and (d) also indicate the circular area where the source must be located (circle drawn in cyan colour). The center of this circle is the mean position of the sensor locations with\npositive readings; its radius is $150$m. Furthermore, figures (a)\nand (d) also display the countours of the buildings (black lines).\nBoth the marginal prior $\\pi(x_0,y_0)$ and the marginal posterior\nPDF $p(x_0,y_0|{\\mathbf{b}})$, are approximated by random samples marked by\nscattered red dots. Assuming the source must be inside one of the\nbuildings, the marginal prior PDF $\\pi(x_0,y_0)$ shown in figure (a)\nis a uniform PDF over the intersection of the cyan color bounded\ncircular area and the area covered by the buildings. The marginal\nposterior PDF $p(x_0,y_0|{\\mathbf{b}})$, shown in figure (d), concentrates in\nthe upper left corner of one of the buildings, thus \ndramatically reducing the initial uncertainty in the source location. The\ntrue source location is marked by an asterisk at $(-298.4,-342.6)$.\nFigs.\\ref{f:1}. (b) and (c) show the histograms of random samples\napproximating $\\pi(Q_0)$; and $\\pi(V)$, respectively. Figs.\n\\ref{f:1}.(e) and \\ref{f:1}.(f) display the histograms of random\nsamples approximating the marginal posteriors $p(Q_0|{\\mathbf{b}})$ and\n$\\pi(V|{\\mathbf{b}})$, respectively.\n\n\\begin{figure}[h!]\n\\centerline{\\includegraphics[height=7.0cm]{data2_a.eps}}\n\\centerline{\\includegraphics[height=5.3cm]{data2_bc.eps}}\n \\caption{\\footnotesize Estimation results obtained by processing dataset 2: (a)  Marginalised posterior PDF $p(x_0,y_0|{\\mathbf{b}})$\n  (scatter plot, red dots); sensor locations (green squares are positive readings,\n blue circles are non-detections); building contours (black lines);\n true source location at $(125.6,436.6)$ (grey asterix).\n Wind direction coincides with the $x$ axis. Figures (b) and (c) display the histograms of random samples approximating $p(Q_0|{\\mathbf{b}})$ and\n  $p(V|{\\mathbf{b}})$, respectively. }\n \\label{f:2}\n\\end{figure}\n\n\\begin{figure}[h!]\n\\centerline{\\includegraphics[height=7.0cm]{data3_a.eps}}\n\\centerline{\\includegraphics[height=5.3cm]{data3_bc.eps}}\n \\caption{\\footnotesize Estimation results obtained by processing dataset 3: (a)  Marginalised posterior PDF $p(x_0,y_0|{\\mathbf{b}})$\n  (scatter plot, red dots); sensor locations (green squares are positive readings,\n blue circles are non-detections); building contours (black lines).\n True source location at $(31.2,-453.2)$ (grey asterix).\n Wind direction coincides with the $x$ axis.  }\n \\label{f:3}\n\\end{figure}\n\n\nThe marginal posterior PDFs, obtained by processing dataset 2, are\nshown in Fig.\\ref{f:2}. The number of  sensor measurement locations in this case\nwas $M=25$. The initial random sample $\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$\nwas created in the same manner as for the case of dataset 1. From\nFig.\\ref{f:2}.(a) we can observe that the posterior PDF\n$p(x_0,y_0|{\\mathbf{b}})$ indicates fairly accurately the true source\nlocation marked by an asterisk at coordinates $(125.6,436.6)$.\n\n\n\nFinally, the marginal posterior PDFs, obtained by processing dataset\n3, are shown in Fig.\\ref{f:3}. The number of  sensor locations in\nthis case was $M=27$. The initial random sample $\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n\n\\leq N}$ was created in the same manner as for the case of dataset\n1. From Fig.\\ref{f:3}.(a) we can observe that the support of the\nmarginal posterior PDF $p(x_0,y_0|{\\mathbf{b}})$ indeed contains the true\nsource location at coordinates $(31.2,-453.2)$. However, the\nconditions were such (the placement of sensor, the wind speed) that\nsome ambiguity in the source location remains.  The resulting\nposterior PDF is bi-modal (two buildings contain scattered red\ndots), suggesting that the source must be located in one of them.\n\n\n\n\n\n\\section{Conclusions}\n\\label{s:6}\n\nThe paper proposed a simple Bayesian estimation algorithm for\nlocalisation of a continuous source of biochemical agent dispersing in the\natmosphere, using measurements collected at multiple locations by a single moving binary sensor whose detection threshold is unknown. The algorithm would also be applicable to  a single snapshot of the measurements from a network of identical binary sensors. The sensor detection threshold may be unknown because it may have been drifted due to temperature, humidity, ageing, etc. Another possible scenario where the detection threshold of a binary sensor  may be unknown is when a human, rather than a device, detects an odour at some locations but not  others. In this scenario, the person can easily make the binary measurements of ``detection'' or ``non-detection'' without knowing the exact detection threshold in terms of ppm or g/m$^3$ of the detected material. To enable source localisation in such scenarios, in our algorithm, we treat the source release rate, as well as the binary sensor threshold, as being unknown. Under these conditions, the algorithm can not estimate the absolute value of the source release rate and is only able to estimate the release rate normalised by the unknown sensor threshold. However, the algorithm can correctly estimate the location of the biochemical source.  The performance of the\nalgorithm is demonstrated using three experimental datasets\ncollected in a semi-urban environment. In all three cases, the\nposterior density function included the true source location,\nthereby validating the proposed algorithm. Future work will consider\nintroducing the uncertainty in the mean wind direction and more\ndetailed dispersion models for urban environments.\n\n\\section*{References}\n\n\\bibliographystyle{elsarticle-num}\n\\bibliography{binary_GPS}\n\n\n\n\n\n\n\n", "itemtype": "equation", "pos": 15845, "prevtext": "\nfor $n=1,\\dots,N$. Finally, the weights are normalised, i.e., $w_n =\n\\tilde{w}_n /\\sum_{n=1}^N \\tilde{w}_n$, for $n=1,\\dots,N$. The\nchoice of importance distribution $\\varrho$ plays a significant role\nin the convergence of point estimators based on the approximation\n$\\{{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$. Ideally $\\varrho$ should resemble the\nposterior. Since the posterior is unknown, good importance\ndistributions are often designed iteratively (population Monte Carlo\n\\cite{robert_casella},  progressive correction \\cite{musso_et_al_00,\nmorelande_ristic_rad}). As $N\\rightarrow \\infty$, however, the\nchoice of $\\varrho$ is less relevant and even the prior $\\pi$ may be\nused as an (admittedly inefficient) importance distribution; this is\ndone in our implementation for convenience. Furthermore, once the weighted random\nsample $\\{w_n,{\\mbox{\\boldmath$\\theta$}}_n\\}_{1\\leq n \\leq N}$ is computed, resampling\n(with replacement) is carried out \\cite{pfbook} resulting in a\nsample with uniform weights. This last step was carried out mainly\nto improve the effect of visualisation of the posterior PDF (see\nfigures in the next section). In our implementation, the prior PDF\nis adopted as:\n\n", "index": 19, "text": "\\begin{equation}\n\\pi({\\mbox{\\boldmath$\\theta$}}) = \\pi(x_0,y_0)\\, \\pi(Q_0)\\, \\pi(V)\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"\\pi({\\mbox{\\boldmath$\\theta$}})=\\pi(x_{0},y_{0})\\,\\pi(Q_{0})\\,\\pi(V)\" display=\"block\"><mrow><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udf3d</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo>,</mo><msub><mi>y</mi><mn>0</mn></msub><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>Q</mi><mn>0</mn></msub><mo rspace=\"4.2pt\" stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mi>\u03c0</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>V</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></math>", "type": "latex"}]