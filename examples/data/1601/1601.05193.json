[{"file": "1601.05193.tex", "nexttext": "\nfor $0 \\leq j \\leq {K} N - {K}_p-1$, where $y_{j}^{(t)}$ is the $j$-th component of $\\boldsymbol{y}^{(t)}$ and $z_{j}^{(t)}$ is a sample from an independent Gaussian random variable with distribution $\\mathcal{N}(0, \\sigma^2)$.\n\nThe decoding algorithm for systematic BMST-R codes can be described as an iterative message processing/passing algorithm over the associated Forney-style factor graph, which is also known as a normal graph~\\cite{Forney01}. In the normal graph, edges represent variables and vertices~(nodes) represent constraints. All edges connected to a node must satisfy the specific constraint of the node. A full-edge connects to two nodes, while a half-edge connects to only one node. A half-edge is also connected to a special symbol, called a ``dongle\", that denotes coupling to other parts of the transmission system~(say, the channel or the information source)~\\cite{Forney01}. Fig.~\\ref{BMST_decoder} shows the normal graph of a systematic BMST-R code with $N=4$, $m=1$ and $L=3$. It is indeed a high-level normal graph, where each edge represents a sequence of random variables. There are four types of nodes in the normal graph of the systematic BMST-R code.\n\\begin{itemize}\n  \\item \\textbf{Node} $\\fbox{+}$: All edges~(variables) connected to node $\\fbox{+}$ must sum to the all-zero vector. The message updating rule at node $\\fbox{+}$ is similar to that of a check node in the factor graph of a binary LDPC code. The only difference is that the messages on the half-edges are obtained from the channel observations.\n\n  \\item \\textbf{Node} $\\fbox{=}$: All edges~(variables) connected to node $\\fbox{=}$ must take the same (binary) values. The messages on the half-edges are obtained from both the channel observations and the information source.\\footnote{The half-edges~(variables) connected to the information source, which are omitted in Fig.~\\ref{BMST_decoder} to avoid confusion and messy plots, are assumed to be independent and uniformly distributed over $\\mathbb{F}_2^{K}$.} The message updating rule at node $\\fbox{=}$ is the same as that of a variable node in the factor graph of a binary LDPC code.\n\n  \\item \\textbf{Node} \\fbox{$\\Pi_{i,j}$}: The node \\fbox{$\\Pi_{i,j}$} represents the $(i,j)$-th interleaver, which interleaves or de-interleaves the input messages.\n\n  \\item \\textbf{Node} \\fbox{P}: Two edges~(variables) connected to node \\fbox{P} must satisfy the constraint specified by the puncturing rules.\n\\end{itemize}\n\n\\begin{figure}[t]\n   \\centering\n   \\includegraphics[angle=270, clip, width={0.48\\textwidth}]{Decoder_new.eps}\n   \\caption{Normal graph of a systematic BMST-R code with $N=4$, $m=1$ and $L=3$.}\n   \\label{BMST_decoder}\n\\end{figure}\n\nThe normal graph of a systematic BMST-R code can be divided into \\emph{layers}, where each layer typically consists of a node of type \\fbox{=}, $N-1$ nodes of type \\fbox{+}, $(m+1)(N-1)$ nodes of type \\fbox{$\\Pi$}, and a node of type \\fbox{P}~(see Fig.~\\ref{BMST_decoder}).\n\nSimilar to SC-LDPC codes, an iterative sliding window decoding algorithm with decoding delay $d$ performing over a subgraph consisting of $d+1$ consecutive layers can be implemented for systematic BMST-R codes. For each window position, the sliding window decoding algorithm can be implemented using the parallel~(flooding) updating schedule within the decoding window. The first layer in any window is called the {\\em target layer}. Decoding proceeds until a fixed number of iterations has been performed or certain given stopping criterion is satisfied, in which case the window shifts to the right by one layer and the symbols corresponding to the target layer shifted out of the window are decoded.\n\n\\subsection{Relations of Systematic BMST-R Codes to Existing Codes}\\label{subsec:AlgebraicDescription}\nFrom Fig.~\\ref{BMST_encoder}, we can see that systematic BMST-R codes resemble the classical RCPC codes~\\cite{Hagenauer88}. Evidently, we can start from a rate $1/N$ systematic BMST-R code~(the mother code), where $N$ is as large as required. By puncturing\\footnote{If needed, one or more whole branches in Fig.~\\ref{BMST_encoder} can be removed.}, one can obtain all code rates of interest from $1/N$ to 1, all of which can be implemented with essentially the same pair of encoder and decoder. The difference between systematic BMST-R codes and RCPC codes is also obvious. The encoding of systematic BMST-R codes is block-oriented and the decoding is typically not implementable by the Viterbi algorithm~\\cite{Forney73} due to the huge constraint length induced by the block-oriented encoding process.\n\nAlternatively, systematic BMST-R codes are decodable with a sliding window decoding algorithm, which is similar to SC-LDPC codes. More generally, systematic BMST-R codes can be viewed as a special class of spatially coupled codes, since spatial coupling can be interpreted as introducing memory among successive independent transmissions, where extra edges are allowed to be added during the coupling process~\\cite{Huang15JSAC}. In contrast to SC-LDPC codes, which are usually defined by the null space of a sparse parity-check matrix, systematic BMST-R codes are easily described using generator matrices. Further, since the encoder for a systematic BMST-R code is non-recursive, an all-zero tail can be added to drive the encoders to the zero state at the end of the encoding process. This is different from SC-LDPC codes, where the tail is usually non-zero and depends on the encoded information bits~(see Section~IV of~\\cite{Pusane08}). As a result, the encoding procedure for systematic BMST-R codes is simpler than for SC-LDPC codes.\n\nWhen described in terms of generator matrices, systematic BMST codes can also be viewed as a special class of spatially coupled low-density generator-matrix (SC-LDGM) codes~\\cite{Aref12,Kumar_IT14}. However, as an ensemble, systematic BMST-R codes are different from SC-LDGM codes. SC-LDGM code ensembles are usually defined in terms of their node distributions, while systematic BMST-R code ensembles are defined in terms of their interleavers~(see Fig.~\\ref{BMST_encoder}).\n\nAs another evidence that systematic BMST-R codes are different from existing codes, we would like to emphasize that systematic BMST-R codes have a simple lower bound on the BER performance, as described in the next section.\n\n\n\\section{Performance and Complexity Analysis}\\label{SecIII}\nA reasonable criterion for a construction to be good is its ability to make trade-offs between complexity and performance. Specifically, if the error performance required by the user is relaxed or, if the gap between the code rate and the capacity is more tolerant, the encoding/decoding complexity should be reduced. In this section, we will find a relation of the performance to the complexity for {\\em terminated} systematic BMST-R codes. We start with a general systematic linear block code.\n\n\\subsection{Basic Notations of Systematic Linear Block Codes}\\label{subsec:Notation}\nA binary linear block code $\\mathcal{C}[{n},{k}]$ is a ${k}$-dimensional subspace of $\\mathbb{F}_2^{n}$. An encoding algorithm can be described simply by\n\n", "itemtype": "equation", "pos": 14324, "prevtext": "\n\\title{Systematic Block Markov Superposition Transmission of Repetition Codes}\n\n\n\n\n\n\n\n\n\n\n\n\n\\author{Xiao~Ma,~\\IEEEmembership{Member,~IEEE}, Kechao~Huang,~\\IEEEmembership{Student~Member,~IEEE},\n        and~Baoming~Bai,~\\IEEEmembership{Member,~IEEE}\n        \\thanks{This work was partially supported by the $973$ Program (No. $2012$CB$316100$), the $863$ Program (No. $2015$AA$01$A$709$), and the China NSF (No. 91438101 and No. 61172082).}\n        \\thanks{X.~Ma and K.~Huang are with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China~(e-mail:~maxiao@mail.sysu.edu.cn; hkech@mail2.sysu.edu.cn).}\n        \\thanks{B.~Bai is with the State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China (e-mail:~bmbai@mail.xidian.edu.cn).}\n}\n\n\n\n\n\n\n\n\n\n\n\n\\maketitle\n\\IEEEpeerreviewmaketitle\n\n\\begin{abstract}\nIn this paper, we propose systematic block Markov superposition transmission of repetition~(BMST-R) codes, which can support a wide range of code rates but maintain essentially the same encoding/decoding hardware structure. The systematic BMST-R codes resemble the classical rate-compatible punctured convolutional~(RCPC) codes, except that they are typically non-decodable by the Viterbi algorithm due to the huge constraint length induced by the block-oriented encoding process. The information sequence is partitioned equally into blocks and transmitted directly, while their replicas are interleaved and transmitted in a block Markov superposition manner. By taking into account that the codes are systematic, we derive both upper and lower bounds on the bit-error-rate~(BER) under maximum {\\em a posteriori}~(MAP) decoding. The derived lower bound reveals connections among BER, encoding memory and code rate, which provides a way to design good systematic BMST-R codes and also allows us to make trade-offs among efficiency, performance and complexity. Numerical results show that:~1)~the proposed bounds are tight in the high signal-to-noise ratio~(SNR) region;~2)~systematic BMST-R codes perform well in a wide range of code rates; and~3)~systematic BMST-R codes outperform spatially coupled low-density parity-check~(SC-LDPC) codes under an equal decoding latency constraint.\n\\end{abstract}\n\n\n\\begin{IEEEkeywords}\nBlock Markov superposition transmission~(BMST), lower bounds, maximum {\\em a posteriori}~(MAP) decoding, rate-compatible codes, upper bounds, sliding window decoding, systematic codes.\n\\end{IEEEkeywords}\n\n\n\\section{Introduction}\nSince the invention of turbo codes~\\cite{Berrou93} and the rediscovery of low-density parity-check~(LDPC) codes~\\cite{Gallager63}, constructing practical good codes has been being an active research topic in our field. Recent developments include the invention of polar codes~\\cite{Arikan09} and flourishment of spatially coupled LDPC~(SC-LDPC) codes~(first introduced as LDPC convolutional codes~\\cite{Felstrom99} and later recast as SC-LDPC codes~\\cite{Kudekar11}), both of which are provable capacity-achieving~\\cite{Arikan09,Lentmaier10,Kudekar11,Kudekar13} over memoryless binary-input symmetric-output channels. Despite this success in theory, more flexible constructions are still desired in practice. Especially, it is often desirable in practice to design codes that support a variety of code rates but maintain essentially the same encoding/decoding hardware structure. One way to achieve this is the use of rate-compatible codes, which can be constructed from a mother code by using the puncturing and/or extending techniques. The former starts with a low-rate mother code and punctures some coded bits to achieve higher rates~\\cite{Hagenauer88,Acikel99,Rowitch00,Ha04,Nik07}, while the latter starts with a high-rate code and extends its parity-check matrix to achieve lower rates~\\cite{Yazdani04,Khamy09,NguyenTV12,NguyenTV13,Chen15}. Both puncturing and extending require optimizations. For example, the puncturing patterns for rate-compatible punctured convolutional~(RCPC) codes in~\\cite{Hagenauer88} were selected by maximizing the average free distance, while the puncturing distributions for rate-compatible LDPC codes in~\\cite{Yazdani04} were optimized by density evolution. In~\\cite{Chen15}, the incremental protomatrices for protograph-based raptor-like~(PBRL) LDPC codes were chosen by maximizing the density evolution threshold. To reduce the construction complexity caused by the optimizations, one can use random puncturing, as proposed in~\\cite{Mitchell_16JSAC}. However, similar to the conventional punctured LDPC codes~\\cite{Yazdani04}, the performance of the randomly punctured LDPC codes degrades significantly when the puncturing fraction increases beyond a threshold. To the best of our knowledge, no methods were reported along with simulations in the literature that can construct good rate-compatible codes over all rates of interest in the interval (0,1).\n\n\n\n\nRecently, a coding scheme called block Markov superposition transmission~(BMST) of short codes~(referred to as \\emph{basic codes}) was proposed~\\cite{Ma15}, which has a good performance over the binary-input additive white Gaussian noise~(AWGN) channel. It has been pointed out in~\\cite{Ma15} that any short code~(linear or nonlinear) with fast encoding algorithm and efficient soft-in soft-out~(SISO) decoding algorithm can be chosen as the basic code. A BMST code is indeed a convolutional code with extremely large constraint length, which has a simple encoding algorithm and a low complexity sliding window decoding algorithm. More importantly, BMST codes have near-capacity performance~(observed by simulation and confirmed by extrinsic information transfer~(EXIT) chart analysis~\\cite{Huang15JSAC}) in the waterfall region of the bit-error-rate (BER) curve and an error floor~(predicted by analysis) that can be controlled by the encoding memory. In~\\cite{Liang15}, short Hadamard transform~(HT) codes are taken as the basic codes, resulting in a class of multiple-rate codes with fixed code length, referred to as BMST-HT codes. An even simpler construction for multiple-rate BMST codes was proposed in~\\cite{Hu14a}, where the involved basic codes consist of repetition~(R) codes and single-parity-check~(SPC) codes, resulting in BMST-RSPC codes. Different from BMST-HT codes which adjust their code rates by setting properly the number of frozen bits in the short HT codes, BMST-RSPC codes adjust the code rates by time-sharing between the R code and the SPC code. The construction of BMST codes is flexible, in the sense that it applies to all code rates of interest in the interval (0,1). However, original BMST codes~\\cite{Ma15,Huang15JSAC,Liang15,Hu14a} are neither rate-compatible nor systematic. Note that systematic codes may be more attractive in practical applications since the information bits can be extracted directly from the estimated codeword. Even worse, original BMST codes do not perform well over block fading channels due to errors propagating to successive decoding windows.\n\nIn this paper, we propose systematic BMST of repetition codes, referred to as systematic BMST-R codes. For encoding, the information sequence is partitioned equally into blocks and transmitted directly, while their replicas are interleaved and transmitted in a block Markov superposition manner. For decoding, a sliding window decoding algorithm with a tunable decoding delay can be implemented, as with SC-LDPC codes~\\cite{Lentmaier10,Iyengar12}. Systematic BMST-R codes not only preserve the advantages of the original non-systematic BMST codes, namely, low encoding complexity, effective sliding window decoding algorithm and predictable error floors, but also have improved decoding performance especially in short-to-moderate decoding latency.\n\nThe main contributions of this paper include:\n\\begin{enumerate}\n  \\item We propose systematic rate-compatible BMST-R codes by using both extending and puncturing. The construction requires no optimization but applies universally to all code rates varying ``continuously\" from zero to one.\n  \\item We propose an upper bound on the BER of a systematic BMST-R code ensemble under maximum {\\em a posteriori}~(MAP) decoding, which can be evaluated by calculating partial input-redundancy weight enumerating function~(IRWEF) with truncated information weight.\n  \\item We propose a lower bound on the BER of a systematic BMST-R code ensemble under MAP decoding, which depends on the encoding memory and code rate. The derived lower bound reveals connections among BER, encoding memory and code rate, which provides a way to design good systematic BMST-R codes and also allows us to make trade-offs among efficiency, performance and complexity.\n  \\item We investigate the impact of various parameters on the performance of systematic BMST-R codes, and then present a performance comparison of systematic BMST-R codes and SC-LDPC codes on the basis of equal decoding latency.\n\\end{enumerate}\n\nSimulation results show that: 1)~the upper and lower bounds are tight in the high signal-to-noise ratio~(SNR) region; 2)~with a moderate decoding delay, the BER curves can match the respective lower bounds in the low BER region, implying that the iterative sliding window decoding algorithm is near optimal; 3)~systematic BMST-R codes perform well~(within one dB away from the corresponding Shannon limits) in a wide range of code rates, confirming the effectiveness of the construction procedure; and 4)~over both AWGN channels and block fading channels, systematic BMST-R codes, overcoming the weakness of non-systematic BMST codes, can have better performance than SC-LDPC codes in the waterfall region under the equal decoding latency constraint.\n\nThe rest of the paper is structured as follows. In Section~\\ref{SecII}, we present the encoding and decoding algorithms of systematic BMST-R codes. In Section~\\ref{SecIII}, we analyze the performance and complexity of systematic BMST-R codes. Numerical analysis and performance comparison are presented in Section~\\ref{SecIV}. Finally, some concluding remarks are given in Section~\\ref{sec:Conclusion}.\n\n\\section{Systematic BMST-R Codes}\\label{SecII}\n\\subsection{Encoding Algorithm}\\label{subsec:encoding}\nLet $\\mathbb{F}_2 = \\{0, 1\\}$ be the binary field. Let $\\boldsymbol{u}=(\\boldsymbol{u}^{(0)}$, $\\boldsymbol{u}^{(1)}$, $\\cdots)$ be the information sequence to be transmitted, where $\\boldsymbol{u}^{(t)} \\in \\mathbb{F}_2^{K}$ is the information subsequence of length ${K}$. The encoding algorithm of a systematic BMST-R code of rate $1/N$ with encoding memory $m$ is described as follows~(see Fig.~\\ref{BMST_encoder} for reference), where $\\boldsymbol{\\Pi}_{i,j}$ $(1 \\leq i \\leq N-1,~0 \\leq j \\leq {m})$ are interleavers of size ${K}$.\n\n\\begin{figure}[t]\n   \\centering\n   \\includegraphics[angle=270, clip, width={0.48\\textwidth}]{Encoder_new.eps}\n   \\caption{Encoder of a systematic BMST-R code with repetition degree $N$ and encoding memory ${m}$, where the information subsequence $\\boldsymbol{u}^{(t)}$ at time $t$ is encoded into the subcodeword $\\boldsymbol{c}^{(t)}=\\{\\boldsymbol{c}_0^{(t)},\\boldsymbol{c}_1^{(t)},\\boldsymbol{c}_2^{(t)},\\cdots,\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}\\}$ for transmission.}\n   \\label{BMST_encoder}\n\\end{figure}\n\n\\vspace{0.10cm}\n\\begin{algorithm}{Encoding of Systematic BMST-R Codes}\\label{alg:encoding}\n\\begin{enumerate}\n  \\item{\\bf{Initialization}:} \\label{step:encoding_initialize} For $t < 0$ and $1 \\leq i \\leq N-1$, set $\\boldsymbol{v}_i^{(t)} = \\boldsymbol{0} \\in \\mathbb{F}_2^{K}$.\n  \\item{\\bf{Loop}:} \\label{step:encoding_iteration} For $t \\geq 0$,\n        \\begin{itemize}\n          \\item Repeat $\\boldsymbol{u}^{(t)}$ $N$ times such that $\\boldsymbol{c}_0^{(t)}= \\boldsymbol{u}^{(t)} \\in \\mathbb{F}_2^{K}$ and $\\boldsymbol{v}_i^{(t)}= \\boldsymbol{u}^{(t)} \\in \\mathbb{F}_2^{K}$ for $1 \\leq i \\leq N-1$;\n          \\item For $1 \\leq i \\leq N-1$,\n              \\begin{enumerate}\n                \\item For $0\\leq j \\leq m$, interleave $\\boldsymbol{v}_i^{(t-j)}$ into $\\boldsymbol{w}_i^{(t,j)}$ using the $(i,j)$-th interleaver $\\boldsymbol{\\Pi}_{i,j}$;\n                \\item Compute $\\boldsymbol{c}_i^{(t)} = \\sum_{0\\leq j \\leq m} \\boldsymbol{w}_i^{(t,j)}$.\n              \\end{enumerate}\n          \\item Take $\\boldsymbol{c}^{(t)}=\\{\\boldsymbol{c}_0^{(t)},\\boldsymbol{c}_1^{(t)},\\boldsymbol{c}_2^{(t)},\\cdots,\\boldsymbol{c}_{N-1}^{(t)}\\}$ as the $t$-th block of transmission.\n        \\end{itemize}\n  \\end{enumerate}\n\\end{algorithm}\n\\vspace{0.10cm}\n\nThe above encoding structure can implement all code rates of the form $1/N$, $N = 2, 3, \\cdots$. If ${K}_p$ of ${K}$ bits in $\\boldsymbol{c}_{N-1}^{(t)}$ are randomly punctured resulting in $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$, we can implement a code rate $\\frac{1}{N-\\theta} \\in (\\frac{1}{N}, \\frac{1}{N-1})$, where $\\theta \\stackrel{\\Delta}{=} \\frac{{K}_p}{{K}}$ is the puncturing fraction. In practice, the code need to be terminated. This can be done easily by driving the encoder to the zero state with a zero-tail of length $m{K}$ after $L$ blocks of data. That is, for $t = L$, $L+1$, $\\cdots$, $L+m-1$, we set $ \\boldsymbol{u}^{(t)} = \\boldsymbol{0} \\in \\mathbb{F}_2^{K}$, compute $\\boldsymbol{c}^{(t)}$ following~{\\bf Loop} in Algorithm~\\ref{alg:encoding}, and then take the redundant check part of $\\boldsymbol{c}^{(t)}$ as the $t$-th block of transmission. The rate of the resulting terminated systematic BMST-R code is\n\\begin{eqnarray}\\label{BMST_RateL}\n  R_L &=& \\frac{{K} L}{{K} L+{K} (N-1)(L+{m})-{K}_p(L+{m})} \\nonumber\\\\\n  ~ &=& \\frac{1}{N-\\theta+(N-1-\\theta)\\frac{m}{L}},\n\\end{eqnarray}\nwhich is less than that of the unterminated code. However, the rate loss is negligible for large $L$.\n\nIn summary, all code rates of interest in the interval (0,1) can be implemented by adjusting the \\emph{repetition degree} $N$ and the \\emph{puncturing fraction} $\\theta$, all with the encoding structure as shown in Fig.~\\ref{BMST_encoder}, where \\fbox{P} stands for the optional puncturing.\n\n\n\\subsection{Decoding Algorithm}\\label{subsec:Decoding}\nAssume that the subcodeword $\\boldsymbol{c}^{(t)}$ is modulated using binary phase-shift keying~(BPSK) with 0 and 1 mapped to $+1$ and $-1$, respectively, and transmitted over an AWGN channel, resulting in a received vector $\\boldsymbol{y}^{(t)}$ expressed as\n\n", "index": 1, "text": "\\begin{equation}\\label{AWGNChannels}\n  y_{j}^{(t)} = c_{j}^{(t)} + z_{j}^{(t)},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"y_{j}^{(t)}=c_{j}^{(t)}+z_{j}^{(t)},\" display=\"block\"><mrow><mrow><msubsup><mi>y</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><msubsup><mi>c</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>+</mo><msubsup><mi>z</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere ${\\boldsymbol u} \\in \\mathbb{F}_2^{k}$ is the information vector, ${\\boldsymbol c}$ is the associated codeword, and ${\\boldsymbol G}$ is a generator matrix of size ${k} \\times {n}$ with rank of ${k}$. Define\n\n", "itemtype": "equation", "pos": 21538, "prevtext": "\nfor $0 \\leq j \\leq {K} N - {K}_p-1$, where $y_{j}^{(t)}$ is the $j$-th component of $\\boldsymbol{y}^{(t)}$ and $z_{j}^{(t)}$ is a sample from an independent Gaussian random variable with distribution $\\mathcal{N}(0, \\sigma^2)$.\n\nThe decoding algorithm for systematic BMST-R codes can be described as an iterative message processing/passing algorithm over the associated Forney-style factor graph, which is also known as a normal graph~\\cite{Forney01}. In the normal graph, edges represent variables and vertices~(nodes) represent constraints. All edges connected to a node must satisfy the specific constraint of the node. A full-edge connects to two nodes, while a half-edge connects to only one node. A half-edge is also connected to a special symbol, called a ``dongle\", that denotes coupling to other parts of the transmission system~(say, the channel or the information source)~\\cite{Forney01}. Fig.~\\ref{BMST_decoder} shows the normal graph of a systematic BMST-R code with $N=4$, $m=1$ and $L=3$. It is indeed a high-level normal graph, where each edge represents a sequence of random variables. There are four types of nodes in the normal graph of the systematic BMST-R code.\n\\begin{itemize}\n  \\item \\textbf{Node} $\\fbox{+}$: All edges~(variables) connected to node $\\fbox{+}$ must sum to the all-zero vector. The message updating rule at node $\\fbox{+}$ is similar to that of a check node in the factor graph of a binary LDPC code. The only difference is that the messages on the half-edges are obtained from the channel observations.\n\n  \\item \\textbf{Node} $\\fbox{=}$: All edges~(variables) connected to node $\\fbox{=}$ must take the same (binary) values. The messages on the half-edges are obtained from both the channel observations and the information source.\\footnote{The half-edges~(variables) connected to the information source, which are omitted in Fig.~\\ref{BMST_decoder} to avoid confusion and messy plots, are assumed to be independent and uniformly distributed over $\\mathbb{F}_2^{K}$.} The message updating rule at node $\\fbox{=}$ is the same as that of a variable node in the factor graph of a binary LDPC code.\n\n  \\item \\textbf{Node} \\fbox{$\\Pi_{i,j}$}: The node \\fbox{$\\Pi_{i,j}$} represents the $(i,j)$-th interleaver, which interleaves or de-interleaves the input messages.\n\n  \\item \\textbf{Node} \\fbox{P}: Two edges~(variables) connected to node \\fbox{P} must satisfy the constraint specified by the puncturing rules.\n\\end{itemize}\n\n\\begin{figure}[t]\n   \\centering\n   \\includegraphics[angle=270, clip, width={0.48\\textwidth}]{Decoder_new.eps}\n   \\caption{Normal graph of a systematic BMST-R code with $N=4$, $m=1$ and $L=3$.}\n   \\label{BMST_decoder}\n\\end{figure}\n\nThe normal graph of a systematic BMST-R code can be divided into \\emph{layers}, where each layer typically consists of a node of type \\fbox{=}, $N-1$ nodes of type \\fbox{+}, $(m+1)(N-1)$ nodes of type \\fbox{$\\Pi$}, and a node of type \\fbox{P}~(see Fig.~\\ref{BMST_decoder}).\n\nSimilar to SC-LDPC codes, an iterative sliding window decoding algorithm with decoding delay $d$ performing over a subgraph consisting of $d+1$ consecutive layers can be implemented for systematic BMST-R codes. For each window position, the sliding window decoding algorithm can be implemented using the parallel~(flooding) updating schedule within the decoding window. The first layer in any window is called the {\\em target layer}. Decoding proceeds until a fixed number of iterations has been performed or certain given stopping criterion is satisfied, in which case the window shifts to the right by one layer and the symbols corresponding to the target layer shifted out of the window are decoded.\n\n\\subsection{Relations of Systematic BMST-R Codes to Existing Codes}\\label{subsec:AlgebraicDescription}\nFrom Fig.~\\ref{BMST_encoder}, we can see that systematic BMST-R codes resemble the classical RCPC codes~\\cite{Hagenauer88}. Evidently, we can start from a rate $1/N$ systematic BMST-R code~(the mother code), where $N$ is as large as required. By puncturing\\footnote{If needed, one or more whole branches in Fig.~\\ref{BMST_encoder} can be removed.}, one can obtain all code rates of interest from $1/N$ to 1, all of which can be implemented with essentially the same pair of encoder and decoder. The difference between systematic BMST-R codes and RCPC codes is also obvious. The encoding of systematic BMST-R codes is block-oriented and the decoding is typically not implementable by the Viterbi algorithm~\\cite{Forney73} due to the huge constraint length induced by the block-oriented encoding process.\n\nAlternatively, systematic BMST-R codes are decodable with a sliding window decoding algorithm, which is similar to SC-LDPC codes. More generally, systematic BMST-R codes can be viewed as a special class of spatially coupled codes, since spatial coupling can be interpreted as introducing memory among successive independent transmissions, where extra edges are allowed to be added during the coupling process~\\cite{Huang15JSAC}. In contrast to SC-LDPC codes, which are usually defined by the null space of a sparse parity-check matrix, systematic BMST-R codes are easily described using generator matrices. Further, since the encoder for a systematic BMST-R code is non-recursive, an all-zero tail can be added to drive the encoders to the zero state at the end of the encoding process. This is different from SC-LDPC codes, where the tail is usually non-zero and depends on the encoded information bits~(see Section~IV of~\\cite{Pusane08}). As a result, the encoding procedure for systematic BMST-R codes is simpler than for SC-LDPC codes.\n\nWhen described in terms of generator matrices, systematic BMST codes can also be viewed as a special class of spatially coupled low-density generator-matrix (SC-LDGM) codes~\\cite{Aref12,Kumar_IT14}. However, as an ensemble, systematic BMST-R codes are different from SC-LDGM codes. SC-LDGM code ensembles are usually defined in terms of their node distributions, while systematic BMST-R code ensembles are defined in terms of their interleavers~(see Fig.~\\ref{BMST_encoder}).\n\nAs another evidence that systematic BMST-R codes are different from existing codes, we would like to emphasize that systematic BMST-R codes have a simple lower bound on the BER performance, as described in the next section.\n\n\n\\section{Performance and Complexity Analysis}\\label{SecIII}\nA reasonable criterion for a construction to be good is its ability to make trade-offs between complexity and performance. Specifically, if the error performance required by the user is relaxed or, if the gap between the code rate and the capacity is more tolerant, the encoding/decoding complexity should be reduced. In this section, we will find a relation of the performance to the complexity for {\\em terminated} systematic BMST-R codes. We start with a general systematic linear block code.\n\n\\subsection{Basic Notations of Systematic Linear Block Codes}\\label{subsec:Notation}\nA binary linear block code $\\mathcal{C}[{n},{k}]$ is a ${k}$-dimensional subspace of $\\mathbb{F}_2^{n}$. An encoding algorithm can be described simply by\n\n", "index": 3, "text": "\\begin{equation}\\label{encoding}\n\\begin{array}{cc}\n  \\phi:~\\mathbb{F}_2^{k} \\rightarrow \\mathbb{F}_2^{n}\\\\\n  ~~~~~~~~~{\\boldsymbol u} \\rightarrow {\\boldsymbol c}={\\boldsymbol u}{\\boldsymbol G},\n  \\end{array}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{cc}\\phi:~{}\\mathbb{F}_{2}^{k}\\rightarrow\\mathbb{F}_{2}^{n}\\\\&#10;~{}~{}~{}~{}~{}~{}~{}~{}~{}{\\boldsymbol{u}}\\rightarrow{\\boldsymbol{c}}={%&#10;\\boldsymbol{u}}{\\boldsymbol{G}},\\end{array}\" display=\"block\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mi>\u03d5</mi><mo rspace=\"5.8pt\">:</mo><mrow><msubsup><mi>\ud835\udd3d</mi><mn>2</mn><mi>k</mi></msubsup><mo>\u2192</mo><msubsup><mi>\ud835\udd3d</mi><mn>2</mn><mi>n</mi></msubsup></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"center\"><mrow><mrow><mpadded lspace=\"29.7pt\" width=\"+29.7pt\"><mi>\ud835\udc96</mi></mpadded><mo>\u2192</mo><mi>\ud835\udc84</mi><mo>=</mo><mrow><mi>\ud835\udc96</mi><mo>\u2062</mo><mi>\ud835\udc6e</mi></mrow></mrow><mo>,</mo></mrow></mtd><mtd/></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nLet $d_{\\min,i}$ be the minimum Hamming weight of $\\mathcal{C}_{1,i}$, i.e.,\n\n", "itemtype": "equation", "pos": 21975, "prevtext": "\nwhere ${\\boldsymbol u} \\in \\mathbb{F}_2^{k}$ is the information vector, ${\\boldsymbol c}$ is the associated codeword, and ${\\boldsymbol G}$ is a generator matrix of size ${k} \\times {n}$ with rank of ${k}$. Define\n\n", "index": 5, "text": "\\begin{equation}\\label{C_1i}\n\\mathcal{C}_{1,i} \\stackrel{\\Delta}{=} \\{{\\boldsymbol{c} = \\boldsymbol{u}\\boldsymbol{G}: ~u_i = 1}\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\mathcal{C}_{1,i}\\stackrel{\\Delta}{=}\\{{\\boldsymbol{c}=\\boldsymbol{u}%&#10;\\boldsymbol{G}:~{}u_{i}=1}\\}.\" display=\"block\"><mrow><mrow><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub><mover><mo movablelimits=\"false\">=</mo><mi mathsize=\"142%\" mathvariant=\"normal\">\u0394</mi></mover><mrow><mo stretchy=\"false\">{</mo><mrow><mi>\ud835\udc84</mi><mo>=</mo><mrow><mi>\ud835\udc96</mi><mo>\u2062</mo><mi>\ud835\udc6e</mi></mrow></mrow><mo rspace=\"5.8pt\">:</mo><mrow><msub><mi>u</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><mo stretchy=\"false\">}</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere $W_H(\\cdot)$ represents the Hamming weight. Obviously, the minimum Hamming weight $d_{\\min}$ of the linear block code $\\mathcal{C}$ can be given by\n\n", "itemtype": "equation", "pos": 22198, "prevtext": "\nLet $d_{\\min,i}$ be the minimum Hamming weight of $\\mathcal{C}_{1,i}$, i.e.,\n\n", "index": 7, "text": "\\begin{equation}\\label{d_mini}\n  d_{\\min,i}  \\stackrel{\\Delta}{=}  \\min\\limits_{\\boldsymbol{c} \\in \\mathcal{C}_{1,i}} W_H(\\boldsymbol{c}),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"d_{\\min,i}\\stackrel{\\Delta}{=}\\min\\limits_{\\boldsymbol{c}\\in\\mathcal{C}_{1,i}}%&#10;W_{H}(\\boldsymbol{c}),\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mrow><mi>min</mi><mo>,</mo><mi>i</mi></mrow></msub><mover><mo movablelimits=\"false\">=</mo><mi mathsize=\"142%\" mathvariant=\"normal\">\u0394</mi></mover><mrow><mrow><munder><mi>min</mi><mrow><mi>\ud835\udc84</mi><mo>\u2208</mo><msub><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9e</mi><mrow><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub></mrow></munder><mo>\u2061</mo><msub><mi>W</mi><mi>H</mi></msub></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc84</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\nAssume that the codeword $\\boldsymbol{c}$ is modulated using BPSK and transmitted over an AWGN channel, resulting in a received vector $\\boldsymbol{y}$. A decoding algorithm is defined as a mapping\n\n", "itemtype": "equation", "pos": 22506, "prevtext": "\nwhere $W_H(\\cdot)$ represents the Hamming weight. Obviously, the minimum Hamming weight $d_{\\min}$ of the linear block code $\\mathcal{C}$ can be given by\n\n", "index": 9, "text": "\\begin{equation}\\label{dmin}\n  d_{\\min}= \\min\\limits_i d_{\\min,i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"d_{\\min}=\\min\\limits_{i}d_{\\min,i}.\" display=\"block\"><mrow><mrow><msub><mi>d</mi><mi>min</mi></msub><mo>=</mo><mrow><munder><mi>min</mi><mi>i</mi></munder><mo>\u2061</mo><msub><mi>d</mi><mrow><mi>min</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere $\\mathcal{Y} \\subset \\mathbb{R}$. Given the signal mapping $0\\rightarrow +1$ and $1\\rightarrow -1$, the SNR is given by $10 \\log_{10} (1/\\sigma^2)$ in dB, where $\\sigma^2$ is the variance of the noise.\n\nSuppose that $\\boldsymbol{U}$ is distributed uniformly at random over $\\mathbb{F}_2^{k}$. Let $E \\stackrel{\\Delta}{=} \\{\\hat{\\boldsymbol{U}} \\neq {\\boldsymbol{U}}\\}$ be the error event that the decoder output $\\hat{\\boldsymbol{U}}$ is not equal to the encoder input vector $\\boldsymbol{U}$, and let $E_{i} \\stackrel{\\Delta}{=} \\{ {\\boldsymbol{\\hat U}}_i \\neq \\boldsymbol{U}_i\\}$ be the error event that the $i$-th estimated bit $\\hat{\\boldsymbol{U}}_i$ at the decoder is not equal to the $i$-th input bit $\\boldsymbol{U}_i$. Obviously, $E = \\bigcup\\limits_{0\\leq i \\leq {k}-1} E_{i}$. Then, under the given decoding algorithm $\\psi$, we can define frame error probability\n\n", "itemtype": "equation", "pos": 22787, "prevtext": "\n\nAssume that the codeword $\\boldsymbol{c}$ is modulated using BPSK and transmitted over an AWGN channel, resulting in a received vector $\\boldsymbol{y}$. A decoding algorithm is defined as a mapping\n\n", "index": 11, "text": "\\begin{equation}\\label{decoding}\n  \\begin{array}{cc}\n  \\psi:~\\mathcal{Y}^{n} \\rightarrow \\mathbb{F}_2^{k} \\\\\n  ~~~~~~~~~~~{\\boldsymbol y} \\rightarrow \\hat{\\boldsymbol u}=\\psi({\\boldsymbol y}),\n  \\end{array}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"\\begin{array}[]{cc}\\psi:~{}\\mathcal{Y}^{n}\\rightarrow\\mathbb{F}_{2}^{k}\\\\&#10;~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}{\\boldsymbol{y}}\\rightarrow\\hat{\\boldsymbol{u%&#10;}}=\\psi({\\boldsymbol{y}}),\\end{array}\" display=\"block\"><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mi>\u03c8</mi><mo rspace=\"5.8pt\">:</mo><mrow><msup><mi class=\"ltx_font_mathcaligraphic\">\ud835\udcb4</mi><mi>n</mi></msup><mo>\u2192</mo><msubsup><mi>\ud835\udd3d</mi><mn>2</mn><mi>k</mi></msubsup></mrow></mrow></mtd><mtd/></mtr><mtr><mtd columnalign=\"center\"><mrow><mrow><mpadded lspace=\"36.3pt\" width=\"+36.3pt\"><mi>\ud835\udc9a</mi></mpadded><mo>\u2192</mo><mover accent=\"true\"><mi>\ud835\udc96</mi><mo stretchy=\"false\">^</mo></mover><mo>=</mo><mrow><mi>\u03c8</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc9a</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd/></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nand bit-error probability\n\n", "itemtype": "equation", "pos": 23890, "prevtext": "\nwhere $\\mathcal{Y} \\subset \\mathbb{R}$. Given the signal mapping $0\\rightarrow +1$ and $1\\rightarrow -1$, the SNR is given by $10 \\log_{10} (1/\\sigma^2)$ in dB, where $\\sigma^2$ is the variance of the noise.\n\nSuppose that $\\boldsymbol{U}$ is distributed uniformly at random over $\\mathbb{F}_2^{k}$. Let $E \\stackrel{\\Delta}{=} \\{\\hat{\\boldsymbol{U}} \\neq {\\boldsymbol{U}}\\}$ be the error event that the decoder output $\\hat{\\boldsymbol{U}}$ is not equal to the encoder input vector $\\boldsymbol{U}$, and let $E_{i} \\stackrel{\\Delta}{=} \\{ {\\boldsymbol{\\hat U}}_i \\neq \\boldsymbol{U}_i\\}$ be the error event that the $i$-th estimated bit $\\hat{\\boldsymbol{U}}_i$ at the decoder is not equal to the $i$-th input bit $\\boldsymbol{U}_i$. Obviously, $E = \\bigcup\\limits_{0\\leq i \\leq {k}-1} E_{i}$. Then, under the given decoding algorithm $\\psi$, we can define frame error probability\n\n", "index": 13, "text": "\\begin{equation}\\label{PeDef0}\n\n    {\\rm FER}_{\\psi} \\stackrel{\\Delta}{=} {\\rm Pr}\\{E\\},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E7.m1\" class=\"ltx_Math\" alttext=\"\\par&#10;{\\rm FER}_{\\psi}\\stackrel{\\Delta}{=}{\\rm Pr}\\{E\\},\" display=\"block\"><mrow><mrow><msub><mi>FER</mi><mi>\u03c8</mi></msub><mover><mo movablelimits=\"false\">=</mo><mi mathsize=\"142%\" mathvariant=\"normal\">\u0394</mi></mover><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><mi>E</mi><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nFrom the definitions of BER and FER, we have\n    \n", "itemtype": "equation", "pos": 24020, "prevtext": "\nand bit-error probability\n\n", "index": 15, "text": "\\begin{equation}\\label{PbDef0}\n    {\\rm BER}_{\\psi} \\stackrel{\\Delta}{=} \\frac{1}{{k}} \\sum_{0\\leq i\\leq {k}-1} {\\rm Pr}\\{ E_{i}\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E8.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER}_{\\psi}\\stackrel{\\Delta}{=}\\frac{1}{{k}}\\sum_{0\\leq i\\leq{k}-1}{\\rm Pr%&#10;}\\{E_{i}\\}.\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>\u03c8</mi></msub><mover><mo movablelimits=\"false\">=</mo><mi mathsize=\"142%\" mathvariant=\"normal\">\u0394</mi></mover><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mn>0</mn><mo>\u2264</mo><mi>i</mi><mo>\u2264</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mrow></munder><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nWe also have\n    \n", "itemtype": "equation", "pos": 24216, "prevtext": "\nFrom the definitions of BER and FER, we have\n    \n", "index": 17, "text": "\\begin{equation}\\label{Proof1}\n        {\\rm FER_{\\psi}} = {\\rm Pr}\\left\\{ \\bigcup_i E_{i}\\right\\} \\geq \\max_i {\\rm Pr}\\{ E_{i}\\} \\geq {\\rm BER_{\\psi}}.\n    \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E9.m1\" class=\"ltx_Math\" alttext=\"{\\rm FER_{\\psi}}={\\rm Pr}\\left\\{\\bigcup_{i}E_{i}\\right\\}\\geq\\max_{i}{\\rm Pr}\\{%&#10;E_{i}\\}\\geq{\\rm BER_{\\psi}}.\" display=\"block\"><mrow><mrow><msub><mi>FER</mi><mi>\u03c8</mi></msub><mo>=</mo><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo>{</mo><mrow><munder><mo largeop=\"true\" mathsize=\"160%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u22c3</mo><mi>i</mi></munder><msub><mi>E</mi><mi>i</mi></msub></mrow><mo>}</mo></mrow></mrow><mo>\u2265</mo><mrow><mrow><munder><mi>max</mi><mi>i</mi></munder><mo>\u2061</mo><mi>Pr</mi></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><mo>\u2265</mo><msub><mi>BER</mi><mi>\u03c8</mi></msub></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nThus, we have\n    \n", "itemtype": "equation", "pos": 24404, "prevtext": "\nWe also have\n    \n", "index": 19, "text": "\\begin{equation}\\label{Proof2}\n        {\\rm FER_{\\psi}} = {\\rm Pr}\\left\\{ \\bigcup_i E_{i}\\right\\} \\leq\n        \\sum_{0\\leq i\\leq {k}-1} {\\rm Pr}\\{ E_{i}\\} = {k}~{\\rm BER}_{\\psi}.\n    \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E10.m1\" class=\"ltx_Math\" alttext=\"{\\rm FER_{\\psi}}={\\rm Pr}\\left\\{\\bigcup_{i}E_{i}\\right\\}\\leq\\sum_{0\\leq i\\leq{%&#10;k}-1}{\\rm Pr}\\{E_{i}\\}={k}~{}{\\rm BER}_{\\psi}.\" display=\"block\"><mrow><mrow><msub><mi>FER</mi><mi>\u03c8</mi></msub><mo>=</mo><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo>{</mo><mrow><munder><mo largeop=\"true\" mathsize=\"160%\" movablelimits=\"false\" stretchy=\"false\" symmetric=\"true\">\u22c3</mo><mi>i</mi></munder><msub><mi>E</mi><mi>i</mi></msub></mrow><mo>}</mo></mrow></mrow><mo>\u2264</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mn>0</mn><mo>\u2264</mo><mi>i</mi><mo>\u2264</mo><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mrow></munder><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow></mrow><mo>=</mo><mrow><mpadded width=\"+3.3pt\"><mi>k</mi></mpadded><mo>\u2062</mo><msub><mi>BER</mi><mi>\u03c8</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\nThe maximum-likelihood~(ML) decoding algorithm selects a codeword $\\hat{\\boldsymbol{c}}$ such that $f(\\boldsymbol{y}|\\hat{\\boldsymbol{c}}) \\geq f({\\boldsymbol{y}}|{\\boldsymbol{c}})$ for all codewords ${\\boldsymbol{c}}$. If ties happen, the ML decoding algorithm can randomly select one candidate as the decoder output. Since $\\boldsymbol{U}$ is distributed uniformly at random over $\\mathbb{F}_2^{{k}}$, the ML decoding algorithm is optimal in the sense that it minimizes the FER. To minimize the BER, the MAP decoding algorithm computes\n\\begin{eqnarray}\\label{bit}\n    {\\rm Pr}(U_i=0|{\\boldsymbol{y}}) &=& \\frac{\\sum\\limits_{\\boldsymbol{u}:u_i=0}{\\rm Pr}(\\boldsymbol{u})f({\\boldsymbol{y}}|\\boldsymbol{u}\\boldsymbol{G})}{\\sum\\limits_{\\boldsymbol{u}\\in \\mathbb{F}_2^{{k}}}{\\rm Pr}(\\boldsymbol{u})f({\\boldsymbol{y}}|\\boldsymbol{u}\\boldsymbol{G})},\n\\end{eqnarray}\nfor all $i$. For each $i = 0, 1,\\cdots,{{k}}-1$, the MAP decoding algorithm outputs ${\\hat u_i}=0$ if ${\\rm Pr}(U_i=0|{\\boldsymbol{y}}) > 0.5$ and ${\\hat u_i}=1$ otherwise.\n\nThe IRWEF of a systematic block code can be given as~\\cite{Benedetto96}\n\n", "itemtype": "equation", "pos": 24620, "prevtext": "\nThus, we have\n    \n", "index": 21, "text": "\\begin{equation}\\label{Eq1}\n        {\\rm BER_{\\psi}} \\leq {\\rm FER_{\\psi}} \\leq {k}~{\\rm BER_{\\psi}}.\n    \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E11.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{\\psi}}\\leq{\\rm FER_{\\psi}}\\leq{k}~{}{\\rm BER_{\\psi}}.\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>\u03c8</mi></msub><mo>\u2264</mo><msub><mi>FER</mi><mi>\u03c8</mi></msub><mo>\u2264</mo><mrow><mpadded width=\"+3.3pt\"><mi>k</mi></mpadded><mo>\u2062</mo><msub><mi>BER</mi><mi>\u03c8</mi></msub></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere $X$, $Y$ are two dummy variables and $A_{i,j}$ denotes the number of codewords having input~(information bits) weight $i$ and redundancy~(parity check bits) weight $j$. The IRWEF can also be written in a more compact form as\n\n", "itemtype": "equation", "pos": 25849, "prevtext": "\n\nThe maximum-likelihood~(ML) decoding algorithm selects a codeword $\\hat{\\boldsymbol{c}}$ such that $f(\\boldsymbol{y}|\\hat{\\boldsymbol{c}}) \\geq f({\\boldsymbol{y}}|{\\boldsymbol{c}})$ for all codewords ${\\boldsymbol{c}}$. If ties happen, the ML decoding algorithm can randomly select one candidate as the decoder output. Since $\\boldsymbol{U}$ is distributed uniformly at random over $\\mathbb{F}_2^{{k}}$, the ML decoding algorithm is optimal in the sense that it minimizes the FER. To minimize the BER, the MAP decoding algorithm computes\n\\begin{eqnarray}\\label{bit}\n    {\\rm Pr}(U_i=0|{\\boldsymbol{y}}) &=& \\frac{\\sum\\limits_{\\boldsymbol{u}:u_i=0}{\\rm Pr}(\\boldsymbol{u})f({\\boldsymbol{y}}|\\boldsymbol{u}\\boldsymbol{G})}{\\sum\\limits_{\\boldsymbol{u}\\in \\mathbb{F}_2^{{k}}}{\\rm Pr}(\\boldsymbol{u})f({\\boldsymbol{y}}|\\boldsymbol{u}\\boldsymbol{G})},\n\\end{eqnarray}\nfor all $i$. For each $i = 0, 1,\\cdots,{{k}}-1$, the MAP decoding algorithm outputs ${\\hat u_i}=0$ if ${\\rm Pr}(U_i=0|{\\boldsymbol{y}}) > 0.5$ and ${\\hat u_i}=1$ otherwise.\n\nThe IRWEF of a systematic block code can be given as~\\cite{Benedetto96}\n\n", "index": 23, "text": "\\begin{equation}\\label{eq:IRWEF}\n    A \\left( X, Y \\right) \\triangleq \\sum_{i,j} A_{i,j} X^{i} Y^{j},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E12.m1\" class=\"ltx_Math\" alttext=\"A\\left(X,Y\\right)\\triangleq\\sum_{i,j}A_{i,j}X^{i}Y^{j},\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>\u225c</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msup><mi>X</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mi>Y</mi><mi>j</mi></msup></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere\n\n", "itemtype": "equation", "pos": 26197, "prevtext": "\nwhere $X$, $Y$ are two dummy variables and $A_{i,j}$ denotes the number of codewords having input~(information bits) weight $i$ and redundancy~(parity check bits) weight $j$. The IRWEF can also be written in a more compact form as\n\n", "index": 25, "text": "\\begin{equation}\\label{eq:IRWEFCompact}\n    A \\left( X, Y \\right) = \\sum_{i} A_{i}\\left( Y \\right) X^{i},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E13.m1\" class=\"ltx_Math\" alttext=\"A\\left(X,Y\\right)=\\sum_{i}A_{i}\\left(Y\\right)X^{i},\" display=\"block\"><mrow><mrow><mrow><mi>A</mi><mo>\u2062</mo><mrow><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>i</mi></munder><mrow><msub><mi>A</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>X</mi><mi>i</mi></msup></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nis the conditional redundancy weight enumerating function~(CRWEF), which enumerates redundancy weight for a given input weight $i$.\n\n\n\n\n\\subsection{Upper Bound on BER Performance}\\label{subsec:UpperBound}\nSince MAP decoding is optimal in the sense that it minimizes the BER, an upper bound on BER performance under any decoding algorithm is applicable to the MAP decoding algorithm. In the following, we consider a suboptimal list decoding algorithm.\n\n\\vspace{0.15cm}\n\\begin{algorithm}{A List Decoding Algorithm for the Purpose of Performance Analysis}\\label{alg:ListDecoding}\n\\begin{enumerate}\n  \\item Make hard decisions on the information part of the received vector $\\boldsymbol{y}$, resulting in a vector $\\hat{\\boldsymbol{y}}$ of length ${k}$. Then the channel becomes a memoryless binary symmetric channel~(BSC) with cross probability\n        \n", "itemtype": "equation", "pos": 26324, "prevtext": "\nwhere\n\n", "index": 27, "text": "\\begin{equation}\\label{eq:CRWEF}\n    A_i \\left( Y \\right) \\triangleq \\sum_{j} A_{i,j} Y^{j}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E14.m1\" class=\"ltx_Math\" alttext=\"A_{i}\\left(Y\\right)\\triangleq\\sum_{j}A_{i,j}Y^{j}\" display=\"block\"><mrow><mrow><msub><mi>A</mi><mi>i</mi></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>\u225c</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><msup><mi>Y</mi><mi>j</mi></msup></mrow></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\n  \\item List all sequences of length ${k}$ within the Hamming sphere with center at $\\hat{\\boldsymbol{y}}$ of radius $r^*\\geq 0$. The resulting list is denoted as $\\mathcal{L}_{\\boldsymbol{y}}$.\n\n  \\item Encode each sequence in $\\mathcal{L}_{\\boldsymbol{y}}$ by the encoding algorithm of the systematic code, resulting in a list of codewords, denoted as $\\mathcal{L}_{\\boldsymbol{c}}$.\n\n  \\item Find the codeword ${\\boldsymbol{c}}^*\\in\\mathcal{L}_{\\boldsymbol{c}}$ that is closest to $\\boldsymbol{y}$. Output the information part $\\hat{\\boldsymbol{u}}$ of ${\\boldsymbol{c}^*}$ as the decoding result.\n\\end{enumerate}\n\\end{algorithm}\n\\vspace{0.15cm}\n\nThe above list decoding algorithm is similar to but different from the algorithm presented in~\\cite{Ma13Bound}. The {\\em list region} in~\\cite{Ma13Bound} is an $n$-dimensional Hamming sphere with center at the hard decision of the whole received sequence, while the list region here is a $k$-dimensional Hamming sphere with center at the hard decision of the information part of the received sequence. By analyzing the BER performance of the proposed list decoding algorithm, we have the following theorem.\n\n\n\n\n\n\\vspace{0.15cm}\n\\begin{theorem}\\label{TheoremUpperBound}\nFor any integer $r^* \\geq 0$, the bit-error probability of systematic codes under MAP decoding is upper-bounded by\n\\ifCLASSOPTIONonecolumn\n\n", "itemtype": "equation", "pos": 27281, "prevtext": "\nis the conditional redundancy weight enumerating function~(CRWEF), which enumerates redundancy weight for a given input weight $i$.\n\n\n\n\n\\subsection{Upper Bound on BER Performance}\\label{subsec:UpperBound}\nSince MAP decoding is optimal in the sense that it minimizes the BER, an upper bound on BER performance under any decoding algorithm is applicable to the MAP decoding algorithm. In the following, we consider a suboptimal list decoding algorithm.\n\n\\vspace{0.15cm}\n\\begin{algorithm}{A List Decoding Algorithm for the Purpose of Performance Analysis}\\label{alg:ListDecoding}\n\\begin{enumerate}\n  \\item Make hard decisions on the information part of the received vector $\\boldsymbol{y}$, resulting in a vector $\\hat{\\boldsymbol{y}}$ of length ${k}$. Then the channel becomes a memoryless binary symmetric channel~(BSC) with cross probability\n        \n", "index": 29, "text": "\\begin{equation}\\label{epsilon}\n          \\varepsilon \\stackrel{\\Delta}{=}Q\\left(\\frac{1}{\\sigma}\\right).\n        \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E15.m1\" class=\"ltx_Math\" alttext=\"\\varepsilon\\stackrel{\\Delta}{=}Q\\left(\\frac{1}{\\sigma}\\right).\" display=\"block\"><mrow><mrow><mi>\u03b5</mi><mover><mo movablelimits=\"false\">=</mo><mi mathsize=\"142%\" mathvariant=\"normal\">\u0394</mi></mover><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><mn>1</mn><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "itemtype": "equation", "pos": 28769, "prevtext": "\n\n  \\item List all sequences of length ${k}$ within the Hamming sphere with center at $\\hat{\\boldsymbol{y}}$ of radius $r^*\\geq 0$. The resulting list is denoted as $\\mathcal{L}_{\\boldsymbol{y}}$.\n\n  \\item Encode each sequence in $\\mathcal{L}_{\\boldsymbol{y}}$ by the encoding algorithm of the systematic code, resulting in a list of codewords, denoted as $\\mathcal{L}_{\\boldsymbol{c}}$.\n\n  \\item Find the codeword ${\\boldsymbol{c}}^*\\in\\mathcal{L}_{\\boldsymbol{c}}$ that is closest to $\\boldsymbol{y}$. Output the information part $\\hat{\\boldsymbol{u}}$ of ${\\boldsymbol{c}^*}$ as the decoding result.\n\\end{enumerate}\n\\end{algorithm}\n\\vspace{0.15cm}\n\nThe above list decoding algorithm is similar to but different from the algorithm presented in~\\cite{Ma13Bound}. The {\\em list region} in~\\cite{Ma13Bound} is an $n$-dimensional Hamming sphere with center at the hard decision of the whole received sequence, while the list region here is a $k$-dimensional Hamming sphere with center at the hard decision of the information part of the received sequence. By analyzing the BER performance of the proposed list decoding algorithm, we have the following theorem.\n\n\n\n\n\n\\vspace{0.15cm}\n\\begin{theorem}\\label{TheoremUpperBound}\nFor any integer $r^* \\geq 0$, the bit-error probability of systematic codes under MAP decoding is upper-bounded by\n\\ifCLASSOPTIONonecolumn\n\n", "index": 31, "text": "\\begin{equation}\\label{UpperBound}\n    {\\rm BER_{MAP}}\\leq \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E16.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\leq\\sum\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(\\sum\\limits_{j%&#10;}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)+\\sum_{i=r^{*}+1}^{{k}%&#10;}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}{i}\\varepsilon^{i}(1-\\varepsilon)^{%&#10;{k}-i}.\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder><mrow><mfrac><mi>i</mi><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover><mrow><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\end{theorem}\n\n\n\n\\begin{IEEEproof}\nConsider the list decoding algorithm~(Algorithm~\\ref{alg:ListDecoding}). The decoding error occurs in two cases under the assumption that the all-zero codeword is transmitted.\n\\begin{enumerate}\n  \\item The all-zero sequence of length ${k}$ is not in the list $\\mathcal{L}_{\\boldsymbol{y}}$, i.e., the hard-decisions have $i \\geq r^*+1$ errors. In this case, the decoder output has at most $i+r^*$ erroneous bits. Hence, the bit-error probability, denoted as $p_1$, is upper-bounded by\n        \n", "itemtype": "equation", "pos": 29096, "prevtext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "index": 33, "text": "\\begin{align}\\label{UpperBound}\n    {\\rm BER_{MAP}}\\leq \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)~~~~~~\\nonumber\\\\\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i}.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{MAP}}\\leq\\sum\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(%&#10;\\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\" display=\"inline\"><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mi>i</mi><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder></mstyle><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E17.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum_{i=r^{*}+1}^{{k}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}%&#10;{i}\\varepsilon^{i}(1-\\varepsilon)^{{k}-i}.\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac></mstyle><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\n  \\item The all-zero sequence of length ${k}$ is in the list $\\mathcal{L}_{\\boldsymbol{y}}$, but the all-zero codeword $\\boldsymbol{c}^{(0)}$ is not the closest one to $\\boldsymbol{y}$. In this case, the bit-error probability, denoted as $p_2$, is upper-bounded by\n        \n", "itemtype": "equation", "pos": 29938, "prevtext": "\n\\fi\n\\end{theorem}\n\n\n\n\\begin{IEEEproof}\nConsider the list decoding algorithm~(Algorithm~\\ref{alg:ListDecoding}). The decoding error occurs in two cases under the assumption that the all-zero codeword is transmitted.\n\\begin{enumerate}\n  \\item The all-zero sequence of length ${k}$ is not in the list $\\mathcal{L}_{\\boldsymbol{y}}$, i.e., the hard-decisions have $i \\geq r^*+1$ errors. In this case, the decoder output has at most $i+r^*$ erroneous bits. Hence, the bit-error probability, denoted as $p_1$, is upper-bounded by\n        \n", "index": 35, "text": "\\begin{equation}\\label{p1}\n            p_1 \\leq \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i}.\n        \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E18.m1\" class=\"ltx_Math\" alttext=\"p_{1}\\leq\\sum_{i=r^{*}+1}^{{k}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}{i}%&#10;\\varepsilon^{i}(1-\\varepsilon)^{{k}-i}.\" display=\"block\"><mrow><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>\u2264</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover><mrow><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{enumerate}\n\nIn summary, for any given radius $r^*$, we have\n\\ifCLASSOPTIONonecolumn\n\n", "itemtype": "equation", "pos": 30386, "prevtext": "\n\n  \\item The all-zero sequence of length ${k}$ is in the list $\\mathcal{L}_{\\boldsymbol{y}}$, but the all-zero codeword $\\boldsymbol{c}^{(0)}$ is not the closest one to $\\boldsymbol{y}$. In this case, the bit-error probability, denoted as $p_2$, is upper-bounded by\n        \n", "index": 37, "text": "\\begin{equation}\\label{p2}\n            p_2 \\leq \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right).\n        \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E19.m1\" class=\"ltx_Math\" alttext=\"p_{2}\\leq\\sum\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(\\sum\\limits_{j}A_{i,j}Q%&#10;\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right).\" display=\"block\"><mrow><mrow><msub><mi>p</mi><mn>2</mn></msub><mo>\u2264</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder><mrow><mfrac><mi>i</mi><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "itemtype": "equation", "pos": 30663, "prevtext": "\n\\end{enumerate}\n\nIn summary, for any given radius $r^*$, we have\n\\ifCLASSOPTIONonecolumn\n\n", "index": 39, "text": "\\begin{equation}\\label{List}\n    {\\rm BER_{List}}\\leq \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E20.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{List}}\\leq\\sum\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(\\sum\\limits_{%&#10;j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)+\\sum_{i=r^{*}+1}^{{k%&#10;}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}{i}\\varepsilon^{i}(1-\\varepsilon)^%&#10;{{k}-i}.\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>List</mi></msub><mo>\u2264</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder><mrow><mfrac><mi>i</mi><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover><mrow><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\nCombining~(\\ref{List}) and the fact that ${\\rm BER_{MAP}} \\leq {\\rm BER_{List}}$, we complete the proof.\n\\end{IEEEproof}\n\nFrom Theorem~\\ref{TheoremUpperBound}, we have the following three corollaries.\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary1}\n\n", "itemtype": "equation", "pos": 30985, "prevtext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "index": 41, "text": "\\begin{align}\\label{List}\n    {\\rm BER_{List}}\\leq \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)~~~~~~\\nonumber\\\\\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i}.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{List}}\\leq\\sum\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(%&#10;\\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\" display=\"inline\"><mrow><msub><mi>BER</mi><mi>List</mi></msub><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mi>i</mi><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder></mstyle><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E21.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum_{i=r^{*}+1}^{{k}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}%&#10;{i}\\varepsilon^{i}(1-\\varepsilon)^{{k}-i}.\" display=\"inline\"><mrow><mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac></mstyle><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt can be proved by simply setting $r^*={k}$ in~(\\ref{UpperBound}).\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary2}\n\n", "itemtype": "equation", "pos": 31548, "prevtext": "\n\\fi\nCombining~(\\ref{List}) and the fact that ${\\rm BER_{MAP}} \\leq {\\rm BER_{List}}$, we complete the proof.\n\\end{IEEEproof}\n\nFrom Theorem~\\ref{TheoremUpperBound}, we have the following three corollaries.\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary1}\n\n", "index": 43, "text": "\\begin{align}\n    {\\rm BER_{MAP}} \\leq \\sum\\limits_{i=1}^{{k}}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right).\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E22.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{MAP}}\\leq\\sum\\limits_{i=1}^{{k}}\\frac{i}{{k}}\\left(\\sum%&#10;\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right).\" display=\"inline\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover></mstyle><mrow><mstyle displaystyle=\"true\"><mfrac><mi>i</mi><mi>k</mi></mfrac></mstyle><mo>\u2062</mo><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder></mstyle><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nBy simply setting $r^*=0$ in~(\\ref{UpperBound}), we have\n\\begin{eqnarray}\\label{Corollary2Proof}\n    {\\rm BER_{MAP}} &\\leq& \\sum_{i=1}^{{k}}\\frac{i}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i} \\nonumber \\\\\n    \n    &=& \\varepsilon = Q\\left(\\frac{1}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary3}\nAssuming that we know only the truncated IRWEF $\\{A_{i,j}$, $0 \\leq i \\leq T\\}$ of systematic codes, we have\n\\ifCLASSOPTIONonecolumn\n\n", "itemtype": "equation", "pos": 31886, "prevtext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt can be proved by simply setting $r^*={k}$ in~(\\ref{UpperBound}).\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary2}\n\n", "index": 45, "text": "\\begin{align}\\label{CorollaryMAP2}\n    {\\rm BER_{MAP}} \\leq Q\\left(\\frac{1}{\\sigma}\\right).\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E23.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{MAP}}\\leq Q\\left(\\frac{1}{\\sigma}\\right).\" display=\"inline\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "itemtype": "equation", "pos": 32520, "prevtext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nBy simply setting $r^*=0$ in~(\\ref{UpperBound}), we have\n\\begin{eqnarray}\\label{Corollary2Proof}\n    {\\rm BER_{MAP}} &\\leq& \\sum_{i=1}^{{k}}\\frac{i}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i} \\nonumber \\\\\n    \n    &=& \\varepsilon = Q\\left(\\frac{1}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary3}\nAssuming that we know only the truncated IRWEF $\\{A_{i,j}$, $0 \\leq i \\leq T\\}$ of systematic codes, we have\n\\ifCLASSOPTIONonecolumn\n\n", "index": 47, "text": "\\begin{equation}\\label{MAP_UpperBound}\n    {\\rm BER_{MAP}} \\leq \\min\\limits_{0\\leq r^*\\leq T/2}\\Bigg\\{  \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i} \\Bigg\\}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E24.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\leq\\min\\limits_{0\\leq r^{*}\\leq T/2}\\Bigg{\\{}\\sum\\limits_{i%&#10;\\leq 2r^{*}}\\frac{i}{{k}}\\left(\\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}%&#10;{\\sigma}}\\right)\\right)+\\sum_{i=r^{*}+1}^{{k}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}%&#10;\\binom{{k}}{i}\\varepsilon^{i}(1-\\varepsilon)^{{k}-i}\\Bigg{\\}}.\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><mrow><munder><mi>min</mi><mrow><mn>0</mn><mo>\u2264</mo><msup><mi>r</mi><mo>*</mo></msup><mo>\u2264</mo><mrow><mi>T</mi><mo>/</mo><mn>2</mn></mrow></mrow></munder><mo>\u2061</mo><mrow><mo maxsize=\"260%\" minsize=\"260%\">{</mo><mrow><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder><mrow><mfrac><mi>i</mi><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>+</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover><mrow><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b5</mi><mi>i</mi></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b5</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup></mrow></mrow></mrow><mo maxsize=\"260%\" minsize=\"260%\">}</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt is obvious and omitted here.\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Corollary~\\ref{Corollary1} is the well-known union bound, while Corollary~\\ref{Corollary2} is almost trivial, which can be easily understood by noting that setting $r^*=0$ in  Algorithm~\\ref{alg:ListDecoding} is equivalent to taking directly the hard decisions $\\hat{\\boldsymbol{y}}$ as the decoding result $\\hat{\\boldsymbol{u}}$~(one of the simplest sub-optimal decoding algorithms). Given that only the truncated IRWEF is available, Corollary~\\ref{Corollary3} is the tightest upper bound of this type.\n\n\\subsection{Lower Bound on BER Performance}\\label{subsec:LowerBound}\n\nThere exist several lower bounds on FER under ML decoding~\\cite{Seguin98,Cohen04,Sason06,Behnamfar07}. However, lower bounds on BER are rarely mentioned in the literature. Any lower bound on ${\\rm FER_{ML}}$ can be adapted to a lower bound on BER by noticing that ${\\rm BER_{ML}} \\geq \\frac{1}{{k}}~{\\rm FER_{ML}}$ from~(\\ref{Eq1}). The simplest lower bound on FER under ML decoding over AWGN channels is given by\n\n", "itemtype": "equation", "pos": 32900, "prevtext": "\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "index": 49, "text": "\\begin{align}\\label{MAP_UpperBound}\n    {\\rm BER_{MAP}} \\leq \\min\\limits_{0\\leq r^*\\leq T/2}\\Bigg\\{  \\sum\\limits_{i \\leq 2r^*}\\frac{i}{{k}}\\left( \\sum\\limits_{j}A_{i,j}Q\\left({\\frac{\\sqrt{i+j}}{\\sigma}}\\right)\\right)\\nonumber\\\\\n    + \\sum_{i=r^*+1}^{{k}}\\frac{\\min\\{i+r^*,{k}\\}}{{k}}\\binom{{k}}{i} \\varepsilon^i (1-\\varepsilon)^{{k}-i} \\Bigg\\}.\n\\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{MAP}}\\leq\\min\\limits_{0\\leq r^{*}\\leq T/2}\\Bigg{\\{}\\sum%&#10;\\limits_{i\\leq 2r^{*}}\\frac{i}{{k}}\\left(\\sum\\limits_{j}A_{i,j}Q\\left({\\frac{%&#10;\\sqrt{i+j}}{\\sigma}}\\right)\\right)\" display=\"inline\"><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2264</mo><munder><mi>min</mi><mrow><mn>0</mn><mo>\u2264</mo><msup><mi>r</mi><mo>*</mo></msup><mo>\u2264</mo><mrow><mi>T</mi><mo>/</mo><mn>2</mn></mrow></mrow></munder><mrow><mo maxsize=\"260%\" minsize=\"260%\">{</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>\u2264</mo><mrow><mn>2</mn><mo>\u2062</mo><msup><mi>r</mi><mo>*</mo></msup></mrow></mrow></munder></mstyle><mstyle displaystyle=\"true\"><mfrac><mi>i</mi><mi>k</mi></mfrac></mstyle><mrow><mo>(</mo><mstyle displaystyle=\"true\"><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mi>j</mi></munder></mstyle><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mi>Q</mi><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><msqrt><mrow><mi>i</mi><mo>+</mo><mi>j</mi></mrow></msqrt><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow><mo>)</mo></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E25.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle+\\sum_{i=r^{*}+1}^{{k}}\\frac{\\min\\{i+r^{*},{k}\\}}{{k}}\\binom{{k}}%&#10;{i}\\varepsilon^{i}(1-\\varepsilon)^{{k}-i}\\Bigg{\\}}.\" display=\"inline\"><mrow><mo>+</mo><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mrow><msup><mi>r</mi><mo>*</mo></msup><mo>+</mo><mn>1</mn></mrow></mrow><mi>k</mi></munderover></mstyle><mstyle displaystyle=\"true\"><mfrac><mrow><mi>min</mi><mo>\u2061</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mi>i</mi><mo>+</mo><msup><mi>r</mi><mo>*</mo></msup></mrow><mo>,</mo><mi>k</mi><mo stretchy=\"false\">}</mo></mrow></mrow><mi>k</mi></mfrac></mstyle><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mi>k</mi><mi>i</mi></mfrac></mstyle><mo>)</mo></mrow><msup><mi>\u03b5</mi><mi>i</mi></msup><msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>\u03b5</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>k</mi><mo>-</mo><mi>i</mi></mrow></msup><mo maxsize=\"260%\" minsize=\"260%\">}</mo><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhich leads to\n\n", "itemtype": "equation", "pos": 34352, "prevtext": "\n\\fi\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt is obvious and omitted here.\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Corollary~\\ref{Corollary1} is the well-known union bound, while Corollary~\\ref{Corollary2} is almost trivial, which can be easily understood by noting that setting $r^*=0$ in  Algorithm~\\ref{alg:ListDecoding} is equivalent to taking directly the hard decisions $\\hat{\\boldsymbol{y}}$ as the decoding result $\\hat{\\boldsymbol{u}}$~(one of the simplest sub-optimal decoding algorithms). Given that only the truncated IRWEF is available, Corollary~\\ref{Corollary3} is the tightest upper bound of this type.\n\n\\subsection{Lower Bound on BER Performance}\\label{subsec:LowerBound}\n\nThere exist several lower bounds on FER under ML decoding~\\cite{Seguin98,Cohen04,Sason06,Behnamfar07}. However, lower bounds on BER are rarely mentioned in the literature. Any lower bound on ${\\rm FER_{ML}}$ can be adapted to a lower bound on BER by noticing that ${\\rm BER_{ML}} \\geq \\frac{1}{{k}}~{\\rm FER_{ML}}$ from~(\\ref{Eq1}). The simplest lower bound on FER under ML decoding over AWGN channels is given by\n\n", "index": 51, "text": "\\begin{equation}\\label{ML_propoFER}\n    {\\rm FER_{ML}} \\geq ~Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right),\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E26.m1\" class=\"ltx_Math\" alttext=\"{\\rm FER_{ML}}\\geq~{}Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right),\" display=\"block\"><mrow><mrow><msub><mi>FER</mi><mi>ML</mi></msub><mo rspace=\"5.8pt\">\u2265</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mi>min</mi></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nLogically, it is not safe to conclude from the above derivation that the lower bound~(\\ref{ML_propo}) applies to MAP decoding. This is subtle due to the fact that ML decoding is not optimal for minimizing the bit-error probability. In the following, we will show that the lower bound on ${\\rm BER_{ML}}$~(\\ref{ML_propo}) is indeed a lower but usually loose bound on ${\\rm BER_{MAP}}$ by proving an improved lower bound.\\footnote{A slightly surprising fact is that no lower bound on ${\\rm BER_{MAP}}$ was found with proof in the literature.} To see the looseness of the lower bound, we consider the following toy example.\n\nLet $\\mathcal{A} = \\{00, 10\\}$ with $d_{\\rm min} = 1$ and $\\mathcal{B} = \\{00, 11\\}$ with $d_{\\rm min} = 2$ be two codes. Define $\\mathcal{C} = \\mathcal{A} \\times \\mathcal{B}^{9999}$, whose codewords are in a Cartesian product form $(\\boldsymbol{c}_0, \\boldsymbol{c}_1, \\cdots, \\boldsymbol{c}_{9999})$, where $\\boldsymbol{c}_0 \\in \\mathcal{A}$ and $\\boldsymbol{c}_i \\in \\mathcal{B}$ for $1 \\leq i \\leq 9999$. Obviously, the code $\\mathcal{C}$ has minimum Hamming weight $d_{\\rm min} = 1$. However, for BPSK modulation over an AWGN channel, the BER for the code $\\mathcal{C}$ is dominated by the code $\\mathcal{B}$ rather than the code $\\mathcal{A}$. To be precise,\n\\begin{eqnarray}\\label{MAP_ML}\n  {\\rm BER_{MAP}} = \\frac{1}{10000}Q\\left(\\frac{1}{\\sigma}\\right) + \\frac{9999}{10000}Q\\left(\\frac{\\sqrt{2}}{\\sigma}\\right),\n\\end{eqnarray}\nwhich implies that the lower bound ${\\rm BER_{MAP}} \\geq \\frac{1}{10000}Q\\left(\\frac{1}{\\sigma}\\right)$ can be very loose in the low SNR region. In the following we present an improved lower bound under MAP decoding.\n\n\\vspace{0.15cm}\n\\begin{theorem}\\label{MAPLowerBound}\nThe bit-error probability for the linear block code $\\mathcal{C}$ under MAP decoding can be lower-bounded by\n\n", "itemtype": "equation", "pos": 34489, "prevtext": "\nwhich leads to\n\n", "index": 53, "text": "\\begin{equation}\\label{ML_propo}\n    {\\rm BER_{ML}} \\geq \\frac{1}{{k}}~{\\rm FER_{ML}} \\geq \\frac{1}{{{k}}}~Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E27.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{ML}}\\geq\\frac{1}{{k}}~{}{\\rm FER_{ML}}\\geq\\frac{1}{{{k}}}~{}Q\\left(%&#10;\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>ML</mi></msub><mo>\u2265</mo><mrow><mpadded width=\"+3.3pt\"><mfrac><mn>1</mn><mi>k</mi></mfrac></mpadded><mo>\u2062</mo><msub><mi>FER</mi><mi>ML</mi></msub></mrow><mo>\u2265</mo><mrow><mpadded width=\"+3.3pt\"><mfrac><mn>1</mn><mi>k</mi></mfrac></mpadded><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mi>min</mi></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{theorem}\n\n\\begin{IEEEproof}\nIt suffices to prove that ${\\rm Pr}\\{E_i\\} \\geq Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right)$ for each given $i$~$(0\\leq i \\leq {k}-1)$. Let $\\boldsymbol{c}^{(1)} \\in \\mathcal{C}_{1,i}$ be a codeword such that $ d_{\\min,i}= W_H(\\boldsymbol{c}^{(1)})$. There must exist an invertible matrix $\\boldsymbol{T}$ of size ${k}\\times {k}$ such that $\\boldsymbol{G}=\\boldsymbol{T}\\widetilde{\\boldsymbol{G}}$ with the first row of $\\widetilde{\\boldsymbol{G}}$ being $\\boldsymbol{c}^{(1)}$. Assume $\\boldsymbol{U} \\in \\mathbb{F}_2^{{k}}$ be the information vector and $\\boldsymbol{C}=\\boldsymbol{U}\\boldsymbol{G}$ be the codeword to be transmitted. Define $\\boldsymbol{V}=\\boldsymbol{U}\\boldsymbol{T}$. The MAP decoder for a binary linear block code computes ${\\rm Pr}\\left\\{ u_i|\\boldsymbol{y} \\right\\}$. We know that if ${\\rm Pr}\\{u_i | \\boldsymbol{y}\\} > 0.5$, the decoding output is correct for this considered bit. In the meanwhile, we assume a \\emph{genie-aided decoder}, which computes ${\\rm Pr}\\{u_i | \\boldsymbol{y}, \\boldsymbol{v}'\\}$ with $\\boldsymbol{v}' = (v_1, v_{2}, \\cdots, v_{{k}-1})$ available. Likewise, if ${\\rm Pr}\\{u_i | \\boldsymbol{y}, \\boldsymbol{v}'\\} > 0.5$, the decoding output is correct for this considered bit. For a specific $\\boldsymbol{u}$ and $\\boldsymbol{y}$, it is possible that ${\\rm Pr}\\{u_i | \\boldsymbol{v}', \\boldsymbol{y}\\} < {\\rm Pr}\\{u_i | \\boldsymbol{y}\\}$. However, the expectation\n\\begin{eqnarray}\\label{eq:MutualINfo}\n\\mathbb{E}\\left[ \\log \\frac{{\\rm Pr}\\{u_i | \\boldsymbol{v}',\n\\boldsymbol{y}\\}}{{\\rm Pr}\\{u_i | \\boldsymbol{y}\\}} \\right] = I\n\\left(U_i; \\boldsymbol{V}' | \\boldsymbol{Y}\\right)\n\\geq 0,\n\\end{eqnarray}\nwhere $I \\left(U_i; \\boldsymbol{V}'  | \\boldsymbol{Y}\\right)$ is the conditional mutual information. This implies that the genie-aided decoder performs statistically no worse than the MAP decoder of the binary linear block code. Under the condition that $\\boldsymbol{v}'$ is available, there exist only two codewords whose Hamming distance is $d_{\\min,i}$. Thus, the bit-error probability with the genie-aided decoder for the binary-input AWGN channels is ${\\rm Pr}\\{E_i\\}_{\\rm Genie}=Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right)$. It follows that\n\n", "itemtype": "equation", "pos": 36495, "prevtext": "\nLogically, it is not safe to conclude from the above derivation that the lower bound~(\\ref{ML_propo}) applies to MAP decoding. This is subtle due to the fact that ML decoding is not optimal for minimizing the bit-error probability. In the following, we will show that the lower bound on ${\\rm BER_{ML}}$~(\\ref{ML_propo}) is indeed a lower but usually loose bound on ${\\rm BER_{MAP}}$ by proving an improved lower bound.\\footnote{A slightly surprising fact is that no lower bound on ${\\rm BER_{MAP}}$ was found with proof in the literature.} To see the looseness of the lower bound, we consider the following toy example.\n\nLet $\\mathcal{A} = \\{00, 10\\}$ with $d_{\\rm min} = 1$ and $\\mathcal{B} = \\{00, 11\\}$ with $d_{\\rm min} = 2$ be two codes. Define $\\mathcal{C} = \\mathcal{A} \\times \\mathcal{B}^{9999}$, whose codewords are in a Cartesian product form $(\\boldsymbol{c}_0, \\boldsymbol{c}_1, \\cdots, \\boldsymbol{c}_{9999})$, where $\\boldsymbol{c}_0 \\in \\mathcal{A}$ and $\\boldsymbol{c}_i \\in \\mathcal{B}$ for $1 \\leq i \\leq 9999$. Obviously, the code $\\mathcal{C}$ has minimum Hamming weight $d_{\\rm min} = 1$. However, for BPSK modulation over an AWGN channel, the BER for the code $\\mathcal{C}$ is dominated by the code $\\mathcal{B}$ rather than the code $\\mathcal{A}$. To be precise,\n\\begin{eqnarray}\\label{MAP_ML}\n  {\\rm BER_{MAP}} = \\frac{1}{10000}Q\\left(\\frac{1}{\\sigma}\\right) + \\frac{9999}{10000}Q\\left(\\frac{\\sqrt{2}}{\\sigma}\\right),\n\\end{eqnarray}\nwhich implies that the lower bound ${\\rm BER_{MAP}} \\geq \\frac{1}{10000}Q\\left(\\frac{1}{\\sigma}\\right)$ can be very loose in the low SNR region. In the following we present an improved lower bound under MAP decoding.\n\n\\vspace{0.15cm}\n\\begin{theorem}\\label{MAPLowerBound}\nThe bit-error probability for the linear block code $\\mathcal{C}$ under MAP decoding can be lower-bounded by\n\n", "index": 55, "text": "\\begin{equation}\\label{BitBound}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E28.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\geq\\frac{1}{{k}}\\sum\\limits_{i=0}^{{k}-1}Q\\left(\\frac{\\sqrt{d_%&#10;{\\min,i}}}{\\sigma}\\right).\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2265</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mrow><mi>min</mi><mo>,</mo><mi>i</mi></mrow></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Theorem~\\ref{MAPLowerBound} also applies to {\\em non-systematic} linear block codes. However, it does not apply to non-linear codes, indicating that the proof is not that simple as considering only the two closest codewords.\n\n\nFrom Theorem~\\ref{MAPLowerBound}, we have the following three corollaries.\n\n\n\\begin{corollary}\\label{ML_LowerBound2MAP}\n\\begin{eqnarray}\\label{ML_LowerBound2MAP_eq}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{{k}}}~Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nCombining~(\\ref{dmin}) and Theorem~\\ref{MAPLowerBound}, we have\n\n", "itemtype": "equation", "pos": 38898, "prevtext": "\n\\end{theorem}\n\n\\begin{IEEEproof}\nIt suffices to prove that ${\\rm Pr}\\{E_i\\} \\geq Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right)$ for each given $i$~$(0\\leq i \\leq {k}-1)$. Let $\\boldsymbol{c}^{(1)} \\in \\mathcal{C}_{1,i}$ be a codeword such that $ d_{\\min,i}= W_H(\\boldsymbol{c}^{(1)})$. There must exist an invertible matrix $\\boldsymbol{T}$ of size ${k}\\times {k}$ such that $\\boldsymbol{G}=\\boldsymbol{T}\\widetilde{\\boldsymbol{G}}$ with the first row of $\\widetilde{\\boldsymbol{G}}$ being $\\boldsymbol{c}^{(1)}$. Assume $\\boldsymbol{U} \\in \\mathbb{F}_2^{{k}}$ be the information vector and $\\boldsymbol{C}=\\boldsymbol{U}\\boldsymbol{G}$ be the codeword to be transmitted. Define $\\boldsymbol{V}=\\boldsymbol{U}\\boldsymbol{T}$. The MAP decoder for a binary linear block code computes ${\\rm Pr}\\left\\{ u_i|\\boldsymbol{y} \\right\\}$. We know that if ${\\rm Pr}\\{u_i | \\boldsymbol{y}\\} > 0.5$, the decoding output is correct for this considered bit. In the meanwhile, we assume a \\emph{genie-aided decoder}, which computes ${\\rm Pr}\\{u_i | \\boldsymbol{y}, \\boldsymbol{v}'\\}$ with $\\boldsymbol{v}' = (v_1, v_{2}, \\cdots, v_{{k}-1})$ available. Likewise, if ${\\rm Pr}\\{u_i | \\boldsymbol{y}, \\boldsymbol{v}'\\} > 0.5$, the decoding output is correct for this considered bit. For a specific $\\boldsymbol{u}$ and $\\boldsymbol{y}$, it is possible that ${\\rm Pr}\\{u_i | \\boldsymbol{v}', \\boldsymbol{y}\\} < {\\rm Pr}\\{u_i | \\boldsymbol{y}\\}$. However, the expectation\n\\begin{eqnarray}\\label{eq:MutualINfo}\n\\mathbb{E}\\left[ \\log \\frac{{\\rm Pr}\\{u_i | \\boldsymbol{v}',\n\\boldsymbol{y}\\}}{{\\rm Pr}\\{u_i | \\boldsymbol{y}\\}} \\right] = I\n\\left(U_i; \\boldsymbol{V}' | \\boldsymbol{Y}\\right)\n\\geq 0,\n\\end{eqnarray}\nwhere $I \\left(U_i; \\boldsymbol{V}'  | \\boldsymbol{Y}\\right)$ is the conditional mutual information. This implies that the genie-aided decoder performs statistically no worse than the MAP decoder of the binary linear block code. Under the condition that $\\boldsymbol{v}'$ is available, there exist only two codewords whose Hamming distance is $d_{\\min,i}$. Thus, the bit-error probability with the genie-aided decoder for the binary-input AWGN channels is ${\\rm Pr}\\{E_i\\}_{\\rm Genie}=Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right)$. It follows that\n\n", "index": 57, "text": "\\begin{equation}\\label{Theorem2_eq}\n    {\\rm Pr}\\{E_i\\} \\geq {\\rm Pr}\\{E_i\\}_{\\rm Genie}= Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E29.m1\" class=\"ltx_Math\" alttext=\"{\\rm Pr}\\{E_{i}\\}\\geq{\\rm Pr}\\{E_{i}\\}_{\\rm Genie}=Q\\left(\\frac{\\sqrt{d_{\\min,%&#10;i}}}{\\sigma}\\right).\" display=\"block\"><mrow><mrow><mrow><mi>Pr</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow></mrow><mo>\u2265</mo><mrow><mi>Pr</mi><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow><mi>Genie</mi></msub></mrow><mo>=</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mrow><mi>min</mi><mo>,</mo><mi>i</mi></mrow></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{IEEEproof}\n\n\n\n\\begin{corollary}\\label{Cyclic_LowerBound}\nIf a code\\footnote{A cyclic code can be such an example.} has the property that $d_{\\min,i}=d_{\\min}$ for all $i$, we have\n\\begin{eqnarray}\\label{Pb_AWGN}\n    {\\rm BER_{MAP}} \\geq Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt is obvious and omitted here.\n\\end{IEEEproof}\n\n\n\n\\begin{corollary}\\label{LDGM_LowerBound}\nIf the row weights of the generator matrix $\\boldsymbol{G}$ for a linear block code $\\mathcal{C}$ are $w_0, w_1, \\cdots,w_{{{k}}-1}$, we have\n\\begin{eqnarray}\\label{LDGM_LowerBound_sq}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} Q \\left(\\frac{\\sqrt{w_{i}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nThis can be proved by noting that $d_{\\min,i} \\leq w_{i}$ and that $Q(x)$ is a decreasing function.\n\\end{IEEEproof}\n\n\n\\textbf{Remarks.}~Corollary~\\ref{ML_LowerBound2MAP} shows that the lower bound~(\\ref{ML_propo}) on ${\\rm BER_{ML}}$ is also a lower bound on the ${\\rm BER_{MAP}}$, while Corollary~\\ref{Cyclic_LowerBound} indicates that the lower bound~(\\ref{ML_propo}) can be very loose. Corollary~\\ref{LDGM_LowerBound} indicates that an LDGM code may have a higher error floor compared to an LDPC code, since the generator matrix for an LDPC code is typically high-density.\n\n\n\\subsection{Applications to Systematic BMST-R Codes}\\label{subsec:ApplicationBound}\nTo apply the derived bounds to systematic BMST-R codes, we need calculate the IRWEF. For systematic BMST-R codes, we have\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\n A(X, Y)&=& \\sum_{i,j} A_{i,j} X^{i} Y^{j} \\nonumber \\\\\n        &=& \\sum_{\\boldsymbol{u}}X^{W_H(\\boldsymbol{u})} \\prod\\limits_{t = 0}^{L+m-1} \\left( Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})} \\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})} \\right) \\nonumber \\\\\n        &=& \\sum_{\\boldsymbol{u}}\\prod_{t = 0}^{L+m-1} \\left(X^{W_H(\\boldsymbol{u}^{(t)})}Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})}\\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})}\\right),\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\\begin{eqnarray}\nA(X, Y)=\\sum_{i,j} A_{i,j} X^{i} Y^{j} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nonumber \\\\\n        = \\sum_{\\boldsymbol{u}}X^{W_H(\\boldsymbol{u})} \\prod\\limits_{t = 0}^{L+m-1} \\left( Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})} \\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})} \\right) ~~\\nonumber \\\\\n        = \\sum_{\\boldsymbol{u}}\\prod_{t = 0}^{L+m-1} \\left(X^{W_H(\\boldsymbol{u}^{(t)})}Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})}\\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})}\\right),\n\\end{eqnarray}\n\\fi\nwhere the summation is over all possible data sequences $\\boldsymbol{u}$ with $\\boldsymbol{u}^{(t)} = \\boldsymbol{0}$ for $t \\geq L$. Since it is a sum of products, $A(X, Y)$ can be computed in principle by a trellis-based algorithm over the polynomial ring. For specific interleavers, the trellis has a state space of size $2^{m{K}}$, which makes the computation intractable for large $m{K}$. To circumvent this issue, we turn to an ensemble of systematic BMST-R codes by assuming that all the interleavers~(see Fig.~\\ref{BMST_encoder} for reference) are chosen at each time independently and uniformly at random, and that $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is obtained by randomly puncturing ${K}_p$ of ${K}$ bits in $\\boldsymbol{c}_{N-1}^{(t)}$. With the assumption that all interleavers are uniform interleavers~\\cite{Benedetto96}, we can see that $W_H(\\boldsymbol{c}_{i}^{(t)})$, for $1 \\leq i \\leq N-1$, is a random variable which depends {\\em only} on the Hamming weights $\\{W_H(\\boldsymbol{u}^{(t-j)}), 0 \\leq j \\leq m\\}$. This admits a reduced-complexity trellis representation of the average IRWEF of the defined systematic BMST-R code ensemble.\n\n\n\n\nThe trellis is time-invariant. At stage $t$, the trellis has $({K} +1)^{m}$ states, each of which corresponds to a vector of Hamming weights $\\boldsymbol{p} = \\left(W_H(\\boldsymbol{u}^{(t-1)}),W_H(\\boldsymbol{u}^{(t-2)}),\\cdots,W_H(\\boldsymbol{u}^{(t-m)})\\right)$. A state $\\boldsymbol{p}$ at stage $t$ and a state $\\boldsymbol{q}$ at stage $t+1$ are connected~(with a branch denoted by $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$) if and only if $p_{j} = q_{j+1}$ for $0 \\leq j \\leq m-2$, where $p_j$ and $q_j$ are the $j$-th components of $\\boldsymbol{p}$ and $\\boldsymbol{q}$, respectively. Evidently, emitting from~(or entering into) each state, there are ${K} +1$ branches. Associated with a branch $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$ are a deterministic input weight $q_0$ but a random redundancy weight due to the existence of random interleavers. The weight distribution of the parity check vector $\\boldsymbol{c}_{1}^{(t)}$ is given by\n\n", "itemtype": "equation", "pos": 39680, "prevtext": "\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Theorem~\\ref{MAPLowerBound} also applies to {\\em non-systematic} linear block codes. However, it does not apply to non-linear codes, indicating that the proof is not that simple as considering only the two closest codewords.\n\n\nFrom Theorem~\\ref{MAPLowerBound}, we have the following three corollaries.\n\n\n\\begin{corollary}\\label{ML_LowerBound2MAP}\n\\begin{eqnarray}\\label{ML_LowerBound2MAP_eq}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{{k}}}~Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nCombining~(\\ref{dmin}) and Theorem~\\ref{MAPLowerBound}, we have\n\n", "index": 59, "text": "\\begin{equation}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} Q \\left(\\frac{\\sqrt{d_{\\min,i}}}{\\sigma}\\right)  \\geq \\frac{1}{{{k}}}~Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E30.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\geq\\frac{1}{{k}}\\sum\\limits_{i=0}^{{k}-1}Q\\left(\\frac{\\sqrt{d_%&#10;{\\min,i}}}{\\sigma}\\right)\\geq\\frac{1}{{{k}}}~{}Q\\left(\\frac{\\sqrt{d_{\\min}}}{%&#10;\\sigma}\\right).\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2265</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mrow><mi>min</mi><mo>,</mo><mi>i</mi></mrow></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow></mrow><mo>\u2265</mo><mrow><mpadded width=\"+3.3pt\"><mfrac><mn>1</mn><mi>k</mi></mfrac></mpadded><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>d</mi><mi>min</mi></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere $f(r|\\boldsymbol{p},q_0)$ is interpreted as the probability of current outputs $\\boldsymbol{c}_{1}^{(t)}$ having weight $r$ given that the weight vector of previous $m$ input blocks $\\left(W_H(\\boldsymbol{u}^{(t-1)}),W_H(\\boldsymbol{u}^{(t-2)}),\\cdots,W_H(\\boldsymbol{u}^{(t-m)})\\right)=\\boldsymbol{p}$ and the current input weight $W_H(\\boldsymbol{u}^{(t)}) = q_0$. By symmetry, it is easy to see that the weight distribution of $\\boldsymbol{c}_{i}^{(t)}$ for $1 \\leq i \\leq N-2$ is the same as $\\gamma_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}}$. Since the parity check vector $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is obtained by randomly puncturing ${K}_p$ of ${K}$ bits in $\\boldsymbol{c}_{N-1}^{(t)}$, the weight distribution of $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is given by\\footnote{By a general definition, the binomial coefficient $\\binom{n}{k}$ is equal to zero for $k<0$ or $k>n$.}\n\n", "itemtype": "equation", "pos": 44672, "prevtext": "\n\\end{IEEEproof}\n\n\n\n\\begin{corollary}\\label{Cyclic_LowerBound}\nIf a code\\footnote{A cyclic code can be such an example.} has the property that $d_{\\min,i}=d_{\\min}$ for all $i$, we have\n\\begin{eqnarray}\\label{Pb_AWGN}\n    {\\rm BER_{MAP}} \\geq Q\\left(\\frac{\\sqrt{d_{\\min}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nIt is obvious and omitted here.\n\\end{IEEEproof}\n\n\n\n\\begin{corollary}\\label{LDGM_LowerBound}\nIf the row weights of the generator matrix $\\boldsymbol{G}$ for a linear block code $\\mathcal{C}$ are $w_0, w_1, \\cdots,w_{{{k}}-1}$, we have\n\\begin{eqnarray}\\label{LDGM_LowerBound_sq}\n    {\\rm BER_{MAP}} \\geq \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} Q \\left(\\frac{\\sqrt{w_{i}}}{\\sigma}\\right).\n\\end{eqnarray}\n\\end{corollary}\n\n\\begin{IEEEproof}\nThis can be proved by noting that $d_{\\min,i} \\leq w_{i}$ and that $Q(x)$ is a decreasing function.\n\\end{IEEEproof}\n\n\n\\textbf{Remarks.}~Corollary~\\ref{ML_LowerBound2MAP} shows that the lower bound~(\\ref{ML_propo}) on ${\\rm BER_{ML}}$ is also a lower bound on the ${\\rm BER_{MAP}}$, while Corollary~\\ref{Cyclic_LowerBound} indicates that the lower bound~(\\ref{ML_propo}) can be very loose. Corollary~\\ref{LDGM_LowerBound} indicates that an LDGM code may have a higher error floor compared to an LDPC code, since the generator matrix for an LDPC code is typically high-density.\n\n\n\\subsection{Applications to Systematic BMST-R Codes}\\label{subsec:ApplicationBound}\nTo apply the derived bounds to systematic BMST-R codes, we need calculate the IRWEF. For systematic BMST-R codes, we have\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\n A(X, Y)&=& \\sum_{i,j} A_{i,j} X^{i} Y^{j} \\nonumber \\\\\n        &=& \\sum_{\\boldsymbol{u}}X^{W_H(\\boldsymbol{u})} \\prod\\limits_{t = 0}^{L+m-1} \\left( Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})} \\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})} \\right) \\nonumber \\\\\n        &=& \\sum_{\\boldsymbol{u}}\\prod_{t = 0}^{L+m-1} \\left(X^{W_H(\\boldsymbol{u}^{(t)})}Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})}\\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})}\\right),\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\\begin{eqnarray}\nA(X, Y)=\\sum_{i,j} A_{i,j} X^{i} Y^{j} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nonumber \\\\\n        = \\sum_{\\boldsymbol{u}}X^{W_H(\\boldsymbol{u})} \\prod\\limits_{t = 0}^{L+m-1} \\left( Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})} \\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})} \\right) ~~\\nonumber \\\\\n        = \\sum_{\\boldsymbol{u}}\\prod_{t = 0}^{L+m-1} \\left(X^{W_H(\\boldsymbol{u}^{(t)})}Y^{W_H(\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)})}\\prod\\limits_{i=1}^{N-2} Y^{W_H(\\boldsymbol{c}_i^{(t)})}\\right),\n\\end{eqnarray}\n\\fi\nwhere the summation is over all possible data sequences $\\boldsymbol{u}$ with $\\boldsymbol{u}^{(t)} = \\boldsymbol{0}$ for $t \\geq L$. Since it is a sum of products, $A(X, Y)$ can be computed in principle by a trellis-based algorithm over the polynomial ring. For specific interleavers, the trellis has a state space of size $2^{m{K}}$, which makes the computation intractable for large $m{K}$. To circumvent this issue, we turn to an ensemble of systematic BMST-R codes by assuming that all the interleavers~(see Fig.~\\ref{BMST_encoder} for reference) are chosen at each time independently and uniformly at random, and that $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is obtained by randomly puncturing ${K}_p$ of ${K}$ bits in $\\boldsymbol{c}_{N-1}^{(t)}$. With the assumption that all interleavers are uniform interleavers~\\cite{Benedetto96}, we can see that $W_H(\\boldsymbol{c}_{i}^{(t)})$, for $1 \\leq i \\leq N-1$, is a random variable which depends {\\em only} on the Hamming weights $\\{W_H(\\boldsymbol{u}^{(t-j)}), 0 \\leq j \\leq m\\}$. This admits a reduced-complexity trellis representation of the average IRWEF of the defined systematic BMST-R code ensemble.\n\n\n\n\nThe trellis is time-invariant. At stage $t$, the trellis has $({K} +1)^{m}$ states, each of which corresponds to a vector of Hamming weights $\\boldsymbol{p} = \\left(W_H(\\boldsymbol{u}^{(t-1)}),W_H(\\boldsymbol{u}^{(t-2)}),\\cdots,W_H(\\boldsymbol{u}^{(t-m)})\\right)$. A state $\\boldsymbol{p}$ at stage $t$ and a state $\\boldsymbol{q}$ at stage $t+1$ are connected~(with a branch denoted by $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$) if and only if $p_{j} = q_{j+1}$ for $0 \\leq j \\leq m-2$, where $p_j$ and $q_j$ are the $j$-th components of $\\boldsymbol{p}$ and $\\boldsymbol{q}$, respectively. Evidently, emitting from~(or entering into) each state, there are ${K} +1$ branches. Associated with a branch $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$ are a deterministic input weight $q_0$ but a random redundancy weight due to the existence of random interleavers. The weight distribution of the parity check vector $\\boldsymbol{c}_{1}^{(t)}$ is given by\n\n", "index": 61, "text": "\\begin{equation}\n\\gamma_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}}=\\sum\\limits_{r=0}^{{K}} f(r|\\boldsymbol{p},q_0) Y^{r},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E31.m1\" class=\"ltx_Math\" alttext=\"\\gamma_{\\boldsymbol{p}\\rightarrow\\boldsymbol{q}}=\\sum\\limits_{r=0}^{{K}}f(r|%&#10;\\boldsymbol{p},q_{0})Y^{r},\" display=\"block\"><mrow><msub><mi>\u03b3</mi><mrow><mi>\ud835\udc91</mi><mo>\u2192</mo><mi>\ud835\udc92</mi></mrow></msub><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>0</mn></mrow><mi>K</mi></munderover><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc91</mi><mo>,</mo><msub><mi>q</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><msup><mi>Y</mi><mi>r</mi></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\nTo calculate the probability $f(r|\\boldsymbol{p},q_0)$, we define $g\\left( r|p,q \\right)$ as the probability that a vector of length ${K}$ has weight $r$, given that the vector is obtained by superimposing two randomly interleaved vectors of~(respective) weights $p$ and $q$. Define $w \\stackrel{\\Delta}{=} p+q-r$. Following the same lines as the method in Section~IV-B of~\\cite{Ma15}, the probability $g\\left( r|p,q \\right)$ is given by\n\n", "itemtype": "equation", "pos": 45717, "prevtext": "\nwhere $f(r|\\boldsymbol{p},q_0)$ is interpreted as the probability of current outputs $\\boldsymbol{c}_{1}^{(t)}$ having weight $r$ given that the weight vector of previous $m$ input blocks $\\left(W_H(\\boldsymbol{u}^{(t-1)}),W_H(\\boldsymbol{u}^{(t-2)}),\\cdots,W_H(\\boldsymbol{u}^{(t-m)})\\right)=\\boldsymbol{p}$ and the current input weight $W_H(\\boldsymbol{u}^{(t)}) = q_0$. By symmetry, it is easy to see that the weight distribution of $\\boldsymbol{c}_{i}^{(t)}$ for $1 \\leq i \\leq N-2$ is the same as $\\gamma_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}}$. Since the parity check vector $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is obtained by randomly puncturing ${K}_p$ of ${K}$ bits in $\\boldsymbol{c}_{N-1}^{(t)}$, the weight distribution of $\\widetilde{\\boldsymbol{c}}_{N-1}^{(t)}$ is given by\\footnote{By a general definition, the binomial coefficient $\\binom{n}{k}$ is equal to zero for $k<0$ or $k>n$.}\n\n", "index": 63, "text": "\\begin{equation}\n\\widetilde{\\gamma}_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}}=\\sum\\limits_{r=0}^{{K}} \\left( f(r|\\boldsymbol{p},q_0) \\sum\\limits_{w=0}^{{K}} \\frac{\\binom{r}{w}\\binom{{K}-r}{{K}_p-w}}{\\binom{{K}}{{K}_p}}Y^{r-w} \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E32.m1\" class=\"ltx_Math\" alttext=\"\\widetilde{\\gamma}_{\\boldsymbol{p}\\rightarrow\\boldsymbol{q}}=\\sum\\limits_{r=0}%&#10;^{{K}}\\left(f(r|\\boldsymbol{p},q_{0})\\sum\\limits_{w=0}^{{K}}\\frac{\\binom{r}{w}%&#10;\\binom{{K}-r}{{K}_{p}-w}}{\\binom{{K}}{{K}_{p}}}Y^{r-w}\\right).\" display=\"block\"><mrow><msub><mover accent=\"true\"><mi>\u03b3</mi><mo>~</mo></mover><mrow><mi>\ud835\udc91</mi><mo>\u2192</mo><mi>\ud835\udc92</mi></mrow></msub><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>r</mi><mo>=</mo><mn>0</mn></mrow><mi>K</mi></munderover><mrow><mo>(</mo><mi>f</mi><mrow><mo stretchy=\"false\">(</mo><mi>r</mi><mo stretchy=\"false\">|</mo><mi>\ud835\udc91</mi><mo>,</mo><msub><mi>q</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>w</mi><mo>=</mo><mn>0</mn></mrow><mi>K</mi></munderover><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>r</mi><mi>w</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mi>r</mi></mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>-</mo><mi>w</mi></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac><msup><mi>Y</mi><mrow><mi>r</mi><mo>-</mo><mi>w</mi></mrow></msup><mo>)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nThen, $f(r|\\boldsymbol{p},q_0)$ can be calculated as described in Algorithm~\\ref{alg:f_pqr}.\n\n\\newpage\n\n\\begin{algorithm}{Computing the probability $f(r|\\boldsymbol{p},q_0)$}\\label{alg:f_pqr}\n\\begin{enumerate}\n  \\item Initialize a vector $\\boldsymbol{\\alpha}^{(0)}$ of length ${K}+1$ such that its components are all zero except that the $q_0$-th component is 1.\n  \\item For $j = 0$, $1$, $\\cdots$, $m-1$, compute\n        \n", "itemtype": "equation", "pos": 46407, "prevtext": "\n\nTo calculate the probability $f(r|\\boldsymbol{p},q_0)$, we define $g\\left( r|p,q \\right)$ as the probability that a vector of length ${K}$ has weight $r$, given that the vector is obtained by superimposing two randomly interleaved vectors of~(respective) weights $p$ and $q$. Define $w \\stackrel{\\Delta}{=} p+q-r$. Following the same lines as the method in Section~IV-B of~\\cite{Ma15}, the probability $g\\left( r|p,q \\right)$ is given by\n\n", "index": 65, "text": "\\begin{equation}\\label{Prob_pqr}\n  g\\left( r|p,q \\right) =\n          \\left\\{ \\begin{array}{cc}\n            \\frac{ \\binom{q}{w/2}\\binom{{K}-q}{p-w/2} }{ \\binom{{K}}{p} }, &{\\rm if}~w~{\\rm is~even},\\\\\n            0, &{\\rm otherwise}.\n        \\end{array}\\right.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E33.m1\" class=\"ltx_Math\" alttext=\"g\\left(r|p,q\\right)=\\left\\{\\begin{array}[]{cc}\\frac{\\binom{q}{w/2}\\binom{{K}-q%&#10;}{p-w/2}}{\\binom{{K}}{p}},&amp;{\\rm if}~{}w~{}{\\rm is~{}even},\\\\&#10;0,&amp;{\\rm otherwise}.\\end{array}\\right.\" display=\"block\"><mrow><mi>g</mi><mrow><mo>(</mo><mi>r</mi><mo stretchy=\"false\">|</mo><mi>p</mi><mo>,</mo><mi>q</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>q</mi><mrow><mi>w</mi><mo>/</mo><mn>2</mn></mrow></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mi>q</mi></mrow><mrow><mi>p</mi><mo>-</mo><mrow><mi>w</mi><mo>/</mo><mn>2</mn></mrow></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><mi>p</mi></mfrac><mo>)</mo></mrow></mfrac><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mrow><mpadded width=\"+3.3pt\"><mi>if</mi></mpadded><mo>\u2062</mo><mpadded width=\"+3.3pt\"><mi>w</mi></mpadded><mo>\u2062</mo><mpadded width=\"+3.3pt\"><mi>is</mi></mpadded><mo>\u2062</mo><mi>even</mi></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mi>otherwise</mi><mo>.</mo></mrow></mtd></mtr></mtable></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n        for $0 \\leq i \\leq {K}$, where $\\alpha_{\\ell}^{(j)}$ is the $\\ell$-th component of $\\boldsymbol{\\alpha}^{(j)}$ and $p_{j}$ is the $j$-th component of $\\boldsymbol{p}$.\n  \\item We have $f(r|\\boldsymbol{p},q_0)=\\alpha_{r}^{(m)}$ for $r = 0$, $1$, $\\cdots$, ${K}$.\n\\end{enumerate}\n\\end{algorithm}\n\\vspace{0.15cm}\n\n\nFinally, $A(X,Y)$ can be calculated recursively by performing a forward trellis-based algorithm~\\cite{Ma03} over the polynomial ring in Algorithm~\\ref{alg:IOWEF}.\n\n\n\\vspace{0.15cm}\n\\begin{algorithm}{Computing IRWEF of Systematic BMST-R Codes}\\label{alg:IOWEF}\n\\begin{enumerate}\n  \\item Initialize $\\beta_0(\\boldsymbol{p})=1$ if $\\boldsymbol{p}$ is the all-zero state; otherwise, initialize $\\beta_0(\\boldsymbol{p})=0$.\n  \\item For $t = 0$, $1$, $\\cdots$, $L+m-1$, for each state $\\boldsymbol{q}$,\n        \n", "itemtype": "equation", "pos": 47103, "prevtext": "\nThen, $f(r|\\boldsymbol{p},q_0)$ can be calculated as described in Algorithm~\\ref{alg:f_pqr}.\n\n\\newpage\n\n\\begin{algorithm}{Computing the probability $f(r|\\boldsymbol{p},q_0)$}\\label{alg:f_pqr}\n\\begin{enumerate}\n  \\item Initialize a vector $\\boldsymbol{\\alpha}^{(0)}$ of length ${K}+1$ such that its components are all zero except that the $q_0$-th component is 1.\n  \\item For $j = 0$, $1$, $\\cdots$, $m-1$, compute\n        \n", "index": 67, "text": "\\begin{equation}\n          \\alpha_{i}^{(j+1)}=\\sum\\limits_{\\ell=0}^{{K}} \\alpha_{\\ell}^{(j)} g\\left( i|\\ell,p_{j} \\right),\n          \\nonumber\n        \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex4.m1\" class=\"ltx_Math\" alttext=\"\\alpha_{i}^{(j+1)}=\\sum\\limits_{\\ell=0}^{{K}}\\alpha_{\\ell}^{(j)}g\\left(i|\\ell,%&#10;p_{j}\\right),\" display=\"block\"><mrow><msubsup><mi>\u03b1</mi><mi>i</mi><mrow><mo stretchy=\"false\">(</mo><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>0</mn></mrow><mi>K</mi></munderover><msubsup><mi>\u03b1</mi><mi mathvariant=\"normal\">\u2113</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mi>g</mi><mrow><mo>(</mo><mi>i</mi><mo stretchy=\"false\">|</mo><mi mathvariant=\"normal\">\u2113</mi><mo>,</mo><msub><mi>p</mi><mi>j</mi></msub><mo>)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n        where $q_0 \\in \\{0,1,\\cdots,{K}\\}$ is the first component of $\\boldsymbol{q}$.\n  \\item At time $L+m$, we have $A(X,Y)=\\beta_{L+m}(\\boldsymbol{0})$.\n\\end{enumerate}\n\\end{algorithm}\\vspace{0.15cm}\n\n\\textbf{Remarks.}~The summation for Step~2) in Algorithm~\\ref{alg:IOWEF} is over ${K}+1$ possible states $\\boldsymbol{p}$ for a given state $\\boldsymbol{q}$. The computation of Algorithm~\\ref{alg:IOWEF} becomes more complicated and even intractable for large $m$ and/or ${K}$ due to the huge number of trellis states $({K} +1)^{m}$. Fortunately, as shown in Section~\\ref{subsec:UpperBound}, we can calculate bounds by the use of a truncated IRWEF, which can be obtained by removing certain states and branches from the trellis. Specifically, for a given truncating parameter $T$ which corresponds to the maximum input weight, we remove all the branches $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$ with $q_0 + \\sum\\limits_{j=0}^{m-1} p_j > T$ and keep only those terms $X^i A_i(Y)$ with $i \\leq T$ of the polynomial $\\beta_{t}(\\boldsymbol{q})$ for $0 \\leq t \\leq L+m$.\n\n\n\nFrom Corollary~\\ref{Corollary3}, the upper bounds may be improved by increasing the truncating parameter $T$, which usually needs more computational and memory loads. However, the lower bound~(as well as the upper bound in the high SNR region) is dominated by the CRWEFs with input weights 1 and 2, which can be given explicitly as below.\n\nWe first show the CRWEFs for a systematic BMST-R code ensemble without puncturing. We have\n\n", "itemtype": "equation", "pos": 48094, "prevtext": "\n        for $0 \\leq i \\leq {K}$, where $\\alpha_{\\ell}^{(j)}$ is the $\\ell$-th component of $\\boldsymbol{\\alpha}^{(j)}$ and $p_{j}$ is the $j$-th component of $\\boldsymbol{p}$.\n  \\item We have $f(r|\\boldsymbol{p},q_0)=\\alpha_{r}^{(m)}$ for $r = 0$, $1$, $\\cdots$, ${K}$.\n\\end{enumerate}\n\\end{algorithm}\n\\vspace{0.15cm}\n\n\nFinally, $A(X,Y)$ can be calculated recursively by performing a forward trellis-based algorithm~\\cite{Ma03} over the polynomial ring in Algorithm~\\ref{alg:IOWEF}.\n\n\n\\vspace{0.15cm}\n\\begin{algorithm}{Computing IRWEF of Systematic BMST-R Codes}\\label{alg:IOWEF}\n\\begin{enumerate}\n  \\item Initialize $\\beta_0(\\boldsymbol{p})=1$ if $\\boldsymbol{p}$ is the all-zero state; otherwise, initialize $\\beta_0(\\boldsymbol{p})=0$.\n  \\item For $t = 0$, $1$, $\\cdots$, $L+m-1$, for each state $\\boldsymbol{q}$,\n        \n", "index": 69, "text": "\\begin{equation}\n          \\beta_{t+1}(\\boldsymbol{q})=\\sum_{\\boldsymbol{p}:\\boldsymbol{p}\\rightarrow \\boldsymbol{q}} \\binom{{K}}{q_0}X^{q_0} \\widetilde{\\gamma}_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}} \\left(\\gamma_{\\boldsymbol{p}\\rightarrow \\boldsymbol{q}}\\right)^{N-2} \\beta_t(\\boldsymbol{p}),\n          \\nonumber\n        \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex5.m1\" class=\"ltx_Math\" alttext=\"\\beta_{t+1}(\\boldsymbol{q})=\\sum_{\\boldsymbol{p}:\\boldsymbol{p}\\rightarrow%&#10;\\boldsymbol{q}}\\binom{{K}}{q_{0}}X^{q_{0}}\\widetilde{\\gamma}_{\\boldsymbol{p}%&#10;\\rightarrow\\boldsymbol{q}}\\left(\\gamma_{\\boldsymbol{p}\\rightarrow\\boldsymbol{q%&#10;}}\\right)^{N-2}\\beta_{t}(\\boldsymbol{p}),\" display=\"block\"><mrow><mrow><mrow><msub><mi>\u03b2</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc92</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>\ud835\udc91</mi><mo>:</mo><mrow><mi>\ud835\udc91</mi><mo>\u2192</mo><mi>\ud835\udc92</mi></mrow></mrow></munder><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>q</mi><mn>0</mn></msub></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>X</mi><msub><mi>q</mi><mn>0</mn></msub></msup><mo>\u2062</mo><msub><mover accent=\"true\"><mi>\u03b3</mi><mo>~</mo></mover><mrow><mi>\ud835\udc91</mi><mo>\u2192</mo><mi>\ud835\udc92</mi></mrow></msub><mo>\u2062</mo><msup><mrow><mo>(</mo><msub><mi>\u03b3</mi><mrow><mi>\ud835\udc91</mi><mo>\u2192</mo><mi>\ud835\udc92</mi></mrow></msub><mo>)</mo></mrow><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow></msup><mo>\u2062</mo><msub><mi>\u03b2</mi><mi>t</mi></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc91</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nFor the CRWEF $A_2(Y)$, we consider the following three cases.\n\\begin{enumerate}\n  \\item The two non-zero information bits are in the same layer. In this case, the corresponding CRWEF $A_2^{(1)} \\left( Y \\right)$ is given by\n      \\begin{eqnarray}\\label{eq:A2_1}\n            A_2^{(1)} \\left( Y \\right) = \\frac{{K}({K}-1)L}{2} Y^{2(m+1)(N-1)}.\n      \\end{eqnarray}\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$~(spaced away from $\\ell-1$ layers) satisfying that $1\\leq \\ell \\leq m$. In this case, the corresponding CRWEF $A_2^{(2)} \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "itemtype": "equation", "pos": 49940, "prevtext": "\n        where $q_0 \\in \\{0,1,\\cdots,{K}\\}$ is the first component of $\\boldsymbol{q}$.\n  \\item At time $L+m$, we have $A(X,Y)=\\beta_{L+m}(\\boldsymbol{0})$.\n\\end{enumerate}\n\\end{algorithm}\\vspace{0.15cm}\n\n\\textbf{Remarks.}~The summation for Step~2) in Algorithm~\\ref{alg:IOWEF} is over ${K}+1$ possible states $\\boldsymbol{p}$ for a given state $\\boldsymbol{q}$. The computation of Algorithm~\\ref{alg:IOWEF} becomes more complicated and even intractable for large $m$ and/or ${K}$ due to the huge number of trellis states $({K} +1)^{m}$. Fortunately, as shown in Section~\\ref{subsec:UpperBound}, we can calculate bounds by the use of a truncated IRWEF, which can be obtained by removing certain states and branches from the trellis. Specifically, for a given truncating parameter $T$ which corresponds to the maximum input weight, we remove all the branches $\\boldsymbol{p}\\rightarrow \\boldsymbol{q}$ with $q_0 + \\sum\\limits_{j=0}^{m-1} p_j > T$ and keep only those terms $X^i A_i(Y)$ with $i \\leq T$ of the polynomial $\\beta_{t}(\\boldsymbol{q})$ for $0 \\leq t \\leq L+m$.\n\n\n\nFrom Corollary~\\ref{Corollary3}, the upper bounds may be improved by increasing the truncating parameter $T$, which usually needs more computational and memory loads. However, the lower bound~(as well as the upper bound in the high SNR region) is dominated by the CRWEFs with input weights 1 and 2, which can be given explicitly as below.\n\nWe first show the CRWEFs for a systematic BMST-R code ensemble without puncturing. We have\n\n", "index": 71, "text": "\\begin{equation}\\label{eq:A1}\n    A_1 \\left( Y \\right) = L{K} Y^{(m+1)(N-1)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E34.m1\" class=\"ltx_Math\" alttext=\"A_{1}\\left(Y\\right)=L{K}Y^{(m+1)(N-1)}.\" display=\"block\"><mrow><mrow><mrow><msub><mi>A</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>L</mi><mo>\u2062</mo><mi>K</mi><mo>\u2062</mo><msup><mi>Y</mi><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "itemtype": "equation", "pos": 50673, "prevtext": "\nFor the CRWEF $A_2(Y)$, we consider the following three cases.\n\\begin{enumerate}\n  \\item The two non-zero information bits are in the same layer. In this case, the corresponding CRWEF $A_2^{(1)} \\left( Y \\right)$ is given by\n      \\begin{eqnarray}\\label{eq:A2_1}\n            A_2^{(1)} \\left( Y \\right) = \\frac{{K}({K}-1)L}{2} Y^{2(m+1)(N-1)}.\n      \\end{eqnarray}\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$~(spaced away from $\\ell-1$ layers) satisfying that $1\\leq \\ell \\leq m$. In this case, the corresponding CRWEF $A_2^{(2)} \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "index": 73, "text": "\\begin{equation}\\label{eq:A2_2}\n        A_2^{(2)} \\left( Y \\right) =\n        \\sum\\limits_{\\ell=1}^{m} (L-\\ell){K}^2\n        Y^{2\\ell(N-1)}\\left(\\frac{1}{{K}}+\\frac{{K}-1}{{K}}Y^2\\right)^{(m+1-\\ell)(N-1)}.\n      \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E35.m1\" class=\"ltx_Math\" alttext=\"A_{2}^{(2)}\\left(Y\\right)=\\sum\\limits_{\\ell=1}^{m}(L-\\ell){K}^{2}Y^{2\\ell(N-1)%&#10;}\\left(\\frac{1}{{K}}+\\frac{{K}-1}{{K}}Y^{2}\\right)^{(m+1-\\ell)(N-1)}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mi mathvariant=\"normal\">\u2113</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>K</mi></mfrac><mo>+</mo><mrow><mfrac><mrow><mi>K</mi><mo>-</mo><mn>1</mn></mrow><mi>K</mi></mfrac><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $m+1\\leq \\ell \\leq L-1$. In this case, the corresponding CRWEF $A_2^{(3)} \\left( Y \\right)$ is given by\n      \n", "itemtype": "equation", "pos": 50945, "prevtext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "index": 75, "text": "\\begin{align}\\label{eq:A2_2}\n        A_2^{(2)} \\left( Y \\right) = ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nonumber \\\\\n        \\sum\\limits_{\\ell=1}^{m} (L-\\ell){K}^2\n        Y^{2\\ell(N-1)}\\left(\\frac{1}{{K}}+\\frac{{K}-1}{{K}}Y^2\\right)^{(m+1-\\ell)(N-1)}.\n      \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex6.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A_{2}^{(2)}\\left(Y\\right)=\" display=\"inline\"><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E36.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum\\limits_{\\ell=1}^{m}(L-\\ell){K}^{2}Y^{2\\ell(N-1)}\\left(\\frac{%&#10;1}{{K}}+\\frac{{K}-1}{{K}}Y^{2}\\right)^{(m+1-\\ell)(N-1)}.\" display=\"inline\"><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mi mathvariant=\"normal\">\u2113</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>K</mi></mfrac></mstyle><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>-</mo><mn>1</mn></mrow><mi>K</mi></mfrac></mstyle><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{enumerate}\nIn summary, the CRWEF $A_2(Y)$ for a systematic BMST-R code ensemble without puncturing is given by\n\n", "itemtype": "equation", "pos": 51455, "prevtext": "\n      \\fi\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $m+1\\leq \\ell \\leq L-1$. In this case, the corresponding CRWEF $A_2^{(3)} \\left( Y \\right)$ is given by\n      \n", "index": 77, "text": "\\begin{equation}\\label{eq:A2_3}\n        A_2^{(3)} \\left( Y \\right) = \\sum\\limits_{\\ell=m+1}^{L-1} (L-\\ell){K}^2 \\cdot Y^{2(m+1)(N-1)}.\n      \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E37.m1\" class=\"ltx_Math\" alttext=\"A_{2}^{(3)}\\left(Y\\right)=\\sum\\limits_{\\ell=m+1}^{L-1}(L-\\ell){K}^{2}\\cdot Y^{%&#10;2(m+1)(N-1)}.\" display=\"block\"><mrow><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup></mrow><mo>\u22c5</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\nThen, we consider the CRWEFs for a systematic BMST-R code ensemble with ${K}_p$ bits in each layer punctured. Taking into account the puncturing effect, when ${K}_p$ bits of a sequence with length ${K}$ and weight 1 are randomly punctured, the resulting weight enumerator $B_1 \\left( Y \\right)$ is given by\n\\begin{eqnarray}\\label{eq:B_Y1}\n    B_1 \\left( Y \\right) &=& \\frac{\\binom{{K}-1}{{K}_p-1}}{\\binom{{K}}{{K}_p}}\n    +\\frac{\\binom{{K}-1}{{K}_p}}{\\binom{{K}}{{K}_p}}Y  \\nonumber \\\\\n    &=& \\frac{{K}_p}{{K}}+\\frac{{K}-{K}_p}{{K}}Y \\nonumber \\\\\n    &=& \\theta+(1-\\theta)Y.\n\\end{eqnarray}\nWhen ${K}_p$ bits of a sequence with length ${K}$ and weight 2 are punctured, the resulting weight enumerator $B_2 \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "itemtype": "equation", "pos": 51727, "prevtext": "\n\\end{enumerate}\nIn summary, the CRWEF $A_2(Y)$ for a systematic BMST-R code ensemble without puncturing is given by\n\n", "index": 79, "text": "\\begin{equation}\\label{eq:A2}\n    A_2 \\left( Y \\right) = A_2^{(1)} \\left( Y \\right) + A_2^{(2)} \\left( Y \\right) + A_2^{(3)} \\left( Y \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E38.m1\" class=\"ltx_Math\" alttext=\"A_{2}\\left(Y\\right)=A_{2}^{(1)}\\left(Y\\right)+A_{2}^{(2)}\\left(Y\\right)+A_{2}^%&#10;{(3)}\\left(Y\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mi>A</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "itemtype": "equation", "pos": 52658, "prevtext": "\n\nThen, we consider the CRWEFs for a systematic BMST-R code ensemble with ${K}_p$ bits in each layer punctured. Taking into account the puncturing effect, when ${K}_p$ bits of a sequence with length ${K}$ and weight 1 are randomly punctured, the resulting weight enumerator $B_1 \\left( Y \\right)$ is given by\n\\begin{eqnarray}\\label{eq:B_Y1}\n    B_1 \\left( Y \\right) &=& \\frac{\\binom{{K}-1}{{K}_p-1}}{\\binom{{K}}{{K}_p}}\n    +\\frac{\\binom{{K}-1}{{K}_p}}{\\binom{{K}}{{K}_p}}Y  \\nonumber \\\\\n    &=& \\frac{{K}_p}{{K}}+\\frac{{K}-{K}_p}{{K}}Y \\nonumber \\\\\n    &=& \\theta+(1-\\theta)Y.\n\\end{eqnarray}\nWhen ${K}_p$ bits of a sequence with length ${K}$ and weight 2 are punctured, the resulting weight enumerator $B_2 \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "index": 81, "text": "\\begin{equation}\\label{eq:B_Y2}\n        B_2 \\left( Y \\right) =\n        \\left\\{ \\begin{array}{cc}\n            \\frac{2{K}_p}{{K}}Y + \\frac{{K}-2{K}_p}{{K}}Y^2, &{K}_p = 0,1,\\\\\n            \\frac{\\binom{2}{2}\\binom{{K}-2}{{K}_p-2}}{\\binom{{K}}{{K}_p}} + \\frac{\\binom{2}{1}\\binom{{K}-2}{{K}_p-1}}{\\binom{{K}}{{K}_p}}Y + \\frac{\\binom{{K}-2}{{K}_p}}{\\binom{{K}}{{K}_p}}Y^2, &{K}_p \\geq 2.\n        \\end{array}\\right.\n      \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E39.m1\" class=\"ltx_Math\" alttext=\"B_{2}\\left(Y\\right)=\\left\\{\\begin{array}[]{cc}\\frac{2{K}_{p}}{{K}}Y+\\frac{{K}-%&#10;2{K}_{p}}{{K}}Y^{2},&amp;{K}_{p}=0,1,\\\\&#10;\\frac{\\binom{2}{2}\\binom{{K}-2}{{K}_{p}-2}}{\\binom{{K}}{{K}_{p}}}+\\frac{\\binom%&#10;{2}{1}\\binom{{K}-2}{{K}_{p}-1}}{\\binom{{K}}{{K}_{p}}}Y+\\frac{\\binom{{K}-2}{{K}%&#10;_{p}}}{\\binom{{K}}{{K}_{p}}}Y^{2},&amp;{K}_{p}\\geq 2.\\end{array}\\right.\" display=\"block\"><mrow><mrow><msub><mi>B</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mrow><mrow><mfrac><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>K</mi><mi>p</mi></msub></mrow><mi>K</mi></mfrac><mo>\u2062</mo><mi>Y</mi></mrow><mo>+</mo><mrow><mfrac><mrow><mi>K</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>K</mi><mi>p</mi></msub></mrow></mrow><mi>K</mi></mfrac><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mrow><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mn>2</mn><mn>2</mn></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>-</mo><mn>2</mn></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac><mo>+</mo><mrow><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mn>2</mn><mn>1</mn></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>-</mo><mn>1</mn></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac><mo>\u2062</mo><mi>Y</mi></mrow><mo>+</mo><mrow><mfrac><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>\u2265</mo><mn>2</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\nThen we have\n    \\ifCLASSOPTIONonecolumn\n    \\begin{eqnarray}\\label{eq:A1-Pun}\n        A_1 \\left( Y \\right) &=& L{K} Y^{(m+1)(N-2)}\\left(B_1 \\left( Y \\right)\\right)^{m+1} \\nonumber \\\\\n        &=& L{K} Y^{(m+1)(N-2)} \\sum\\limits_{\\ell=0}^{m+1} \\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}Y^{\\ell} .\n    \\end{eqnarray}\n    \\fi\n    \\ifCLASSOPTIONtwocolumn\n    \\begin{eqnarray}\\label{eq:A1-Pun}\n        A_1 \\left( Y \\right) = L{K} Y^{(m+1)(N-2)}\\left(B_1 \\left( Y \\right)\\right)^{m+1} ~~~~~~~~~~~~~~~~\\nonumber \\\\\n        = L{K} Y^{(m+1)(N-2)} \\sum\\limits_{\\ell=0}^{m+1} \\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}Y^{\\ell} .\n    \\end{eqnarray}\n    \\fi\n\nFor the CRWEF $A_2(Y)$, we consider the following three cases.\n\\begin{enumerate}\n  \\item The two non-zero information bits are in the same layer. In this case, the corresponding CRWEF $A_2^{(1)} \\left( Y \\right)$ is given by\n      \\begin{eqnarray}\\label{eq:A2_1-Pun}\n            A_2^{(1)} \\left( Y \\right) = \\frac{{K}({K}-1)L}{2}Y^{2(m+1)(N-2)}\\left( B_2(Y) \\right)^{m+1}.\n      \\end{eqnarray}\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $1\\leq \\ell \\leq m$. In this case, the corresponding CRWEF $A_2^{(2)} \\left( Y \\right)$ is given by\n\n\n\n\n\n\n\n\n\n      \n", "itemtype": "equation", "pos": 53134, "prevtext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "index": 83, "text": "\\begin{align}\\label{eq:B_Y2}\n        B_2 \\left( Y \\right) = ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nonumber\\\\\n        \\left\\{ \\begin{array}{cc}\n            \\frac{2{K}_p}{{K}}Y + \\frac{{K}-2{K}_p}{{K}}Y^2, &{K}_p = 0,1,\\\\\n            \\frac{\\binom{2}{2}\\binom{{K}-2}{{K}_p-2}}{\\binom{{K}}{{K}_p}} + \\frac{\\binom{2}{1}\\binom{{K}-2}{{K}_p-1}}{\\binom{{K}}{{K}_p}}Y + \\frac{\\binom{{K}-2}{{K}_p}}{\\binom{{K}}{{K}_p}}Y^2, &{K}_p \\geq 2.\n        \\end{array}\\right.\n      \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex7.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle B_{2}\\left(Y\\right)=\" display=\"inline\"><mrow><mrow><msub><mi>B</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E40.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\left\\{\\begin{array}[]{cc}\\frac{2{K}_{p}}{{K}}Y+\\frac{{K}-2{K}_{p%&#10;}}{{K}}Y^{2},&amp;{K}_{p}=0,1,\\\\&#10;\\frac{\\binom{2}{2}\\binom{{K}-2}{{K}_{p}-2}}{\\binom{{K}}{{K}_{p}}}+\\frac{\\binom%&#10;{2}{1}\\binom{{K}-2}{{K}_{p}-1}}{\\binom{{K}}{{K}_{p}}}Y+\\frac{\\binom{{K}-2}{{K}%&#10;_{p}}}{\\binom{{K}}{{K}_{p}}}Y^{2},&amp;{K}_{p}\\geq 2.\\end{array}\\right.\" display=\"inline\"><mrow><mo>{</mo><mtable columnspacing=\"5pt\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"center\"><mrow><mrow><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>K</mi><mi>p</mi></msub></mrow><mi>K</mi></mfrac></mstyle><mo>\u2062</mo><mi>Y</mi></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>-</mo><mrow><mn>2</mn><mo>\u2062</mo><msub><mi>K</mi><mi>p</mi></msub></mrow></mrow><mi>K</mi></mfrac></mstyle><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>=</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign=\"center\"><mrow><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mn>2</mn><mn>2</mn></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>-</mo><mn>2</mn></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac></mstyle><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mn>2</mn><mn>1</mn></mfrac><mo>)</mo></mrow><mo>\u2062</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>-</mo><mn>1</mn></mrow></mfrac><mo>)</mo></mrow></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac></mstyle><mo>\u2062</mo><mi>Y</mi></mrow><mo>+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>K</mi><mo>-</mo><mn>2</mn></mrow><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mi>K</mi><msub><mi>K</mi><mi>p</mi></msub></mfrac><mo>)</mo></mrow></mfrac></mstyle><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>,</mo></mrow></mtd><mtd columnalign=\"center\"><mrow><mrow><msub><mi>K</mi><mi>p</mi></msub><mo>\u2265</mo><mn>2</mn></mrow><mo>.</mo></mrow></mtd></mtr></mtable><mi/></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $m+1\\leq \\ell \\leq L-1$. In this case, the corresponding CRWEF $A_2^{(3)} \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "itemtype": "equation", "pos": 54914, "prevtext": "\n      \\fi\nThen we have\n    \\ifCLASSOPTIONonecolumn\n    \\begin{eqnarray}\\label{eq:A1-Pun}\n        A_1 \\left( Y \\right) &=& L{K} Y^{(m+1)(N-2)}\\left(B_1 \\left( Y \\right)\\right)^{m+1} \\nonumber \\\\\n        &=& L{K} Y^{(m+1)(N-2)} \\sum\\limits_{\\ell=0}^{m+1} \\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}Y^{\\ell} .\n    \\end{eqnarray}\n    \\fi\n    \\ifCLASSOPTIONtwocolumn\n    \\begin{eqnarray}\\label{eq:A1-Pun}\n        A_1 \\left( Y \\right) = L{K} Y^{(m+1)(N-2)}\\left(B_1 \\left( Y \\right)\\right)^{m+1} ~~~~~~~~~~~~~~~~\\nonumber \\\\\n        = L{K} Y^{(m+1)(N-2)} \\sum\\limits_{\\ell=0}^{m+1} \\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}Y^{\\ell} .\n    \\end{eqnarray}\n    \\fi\n\nFor the CRWEF $A_2(Y)$, we consider the following three cases.\n\\begin{enumerate}\n  \\item The two non-zero information bits are in the same layer. In this case, the corresponding CRWEF $A_2^{(1)} \\left( Y \\right)$ is given by\n      \\begin{eqnarray}\\label{eq:A2_1-Pun}\n            A_2^{(1)} \\left( Y \\right) = \\frac{{K}({K}-1)L}{2}Y^{2(m+1)(N-2)}\\left( B_2(Y) \\right)^{m+1}.\n      \\end{eqnarray}\n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $1\\leq \\ell \\leq m$. In this case, the corresponding CRWEF $A_2^{(2)} \\left( Y \\right)$ is given by\n\n\n\n\n\n\n\n\n\n      \n", "index": 85, "text": "\\begin{align}\\label{eq:A2_2-Pun}\n        A_2^{(2)} \\left( Y \\right) = \\sum\\limits_{\\ell=1}^{m} (L-\\ell){K}^2\n        Y^{2\\ell(N-2)} (B_1(Y))^{2\\ell} ~~~~~~~~~~~~~\\nonumber\\\\\n        \\cdot \\left(\\frac{1}{{K}}\\!+\\!\\frac{{K}-1}{{K}}Y^2\\right)^{(m\\!+\\!1\\!-\\!\\ell)(N\\!-\\!2)}\\!\n        \\left(\\frac{1}{{K}}\\!+\\!\\frac{{K}\\!-\\!1}{{K}}B_2(Y)\\right)^{m\\!+\\!1\\!-\\!\\ell}.\n      \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex8.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A_{2}^{(2)}\\left(Y\\right)=\\sum\\limits_{\\ell=1}^{m}(L-\\ell){K}^{2%&#10;}Y^{2\\ell(N-2)}(B_{1}(Y))^{2\\ell}\" display=\"inline\"><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup><mo>\u2062</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mi mathvariant=\"normal\">\u2113</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E41.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\cdot\\left(\\frac{1}{{K}}\\!+\\!\\frac{{K}-1}{{K}}Y^{2}\\right)^{(m\\!+%&#10;\\!1\\!-\\!\\ell)(N\\!-\\!2)}\\!\\left(\\frac{1}{{K}}\\!+\\!\\frac{{K}\\!-\\!1}{{K}}B_{2}(Y)%&#10;\\right)^{m\\!+\\!1\\!-\\!\\ell}.\" display=\"inline\"><mrow><mrow><mi/><mo>\u22c5</mo><mrow><mpadded width=\"-1.7pt\"><msup><mrow><mo>(</mo><mrow><mpadded width=\"-1.7pt\"><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>K</mi></mfrac></mstyle></mpadded><mo rspace=\"0.8pt\">+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mi>K</mi><mo>-</mo><mn>1</mn></mrow><mi>K</mi></mfrac></mstyle><mo>\u2062</mo><msup><mi>Y</mi><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mrow><mpadded width=\"-1.7pt\"><mi>m</mi></mpadded><mo rspace=\"0.8pt\">+</mo><mpadded width=\"-1.7pt\"><mn>1</mn></mpadded></mrow><mo rspace=\"0.8pt\">-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mpadded width=\"-1.7pt\"><mi>N</mi></mpadded><mo rspace=\"0.8pt\">-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mpadded><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><mpadded width=\"-1.7pt\"><mstyle displaystyle=\"true\"><mfrac><mn>1</mn><mi>K</mi></mfrac></mstyle></mpadded><mo rspace=\"0.8pt\">+</mo><mrow><mstyle displaystyle=\"true\"><mfrac><mrow><mpadded width=\"-1.7pt\"><mi>K</mi></mpadded><mo rspace=\"0.8pt\">-</mo><mn>1</mn></mrow><mi>K</mi></mfrac></mstyle><mo>\u2062</mo><msub><mi>B</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mrow><mrow><mpadded width=\"-1.7pt\"><mi>m</mi></mpadded><mo rspace=\"0.8pt\">+</mo><mpadded width=\"-1.7pt\"><mn>1</mn></mpadded></mrow><mo rspace=\"0.8pt\">-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "itemtype": "equation", "pos": 55543, "prevtext": "\n      \n\n  \\item The two non-zero information bits are in two different layers with a gap $\\ell$ satisfying that $m+1\\leq \\ell \\leq L-1$. In this case, the corresponding CRWEF $A_2^{(3)} \\left( Y \\right)$ is given by\n      \\ifCLASSOPTIONonecolumn\n      \n", "index": 87, "text": "\\begin{align}\\label{eq:A2_3-Pun}\n        A_2^{(3)} \\left( Y \\right) =\n        \\sum\\limits_{\\ell=m+1}^{L-1} (L-\\ell){K}^2\n        \\cdot Y^{2(m+1)(N-2)}\\left(B_1(Y)\\right)^{2(m+1)}.\n      \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E42.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A_{2}^{(3)}\\left(Y\\right)=\\sum\\limits_{\\ell=m+1}^{L-1}(L-\\ell){K%&#10;}^{2}\\cdot Y^{2(m+1)(N-2)}\\left(B_{1}(Y)\\right)^{2(m+1)}.\" display=\"inline\"><mrow><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup></mrow><mo>\u22c5</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n      \\fi\n\\end{enumerate}\nIn summary, the CRWEF $A_2(Y)$ for a systematic BMST-R code ensemble with ${K}_p$ bits in each layer punctured is given by\n\n", "itemtype": "equation", "pos": 55787, "prevtext": "\n      \\fi\n      \\ifCLASSOPTIONtwocolumn\n      \n", "index": 89, "text": "\\begin{align}\\label{eq:A2_3-Pun}\n        A_2^{(3)} \\left( Y \\right) =  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\nonumber\\\\\n        \\sum\\limits_{\\ell=m+1}^{L-1} (L-\\ell){K}^2\n        \\cdot Y^{2(m+1)(N-2)}\\left(B_1(Y)\\right)^{2(m+1)}.\n      \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex9.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle A_{2}^{(3)}\\left(Y\\right)=\" display=\"inline\"><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E43.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum\\limits_{\\ell=m+1}^{L-1}(L-\\ell){K}^{2}\\cdot Y^{2(m+1)(N-2)}%&#10;\\left(B_{1}(Y)\\right)^{2(m+1)}.\" display=\"inline\"><mrow><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover></mstyle><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mi>L</mi><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><msup><mi>K</mi><mn>2</mn></msup></mrow><mo>\u22c5</mo><msup><mi>Y</mi><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow><mo>\u2062</mo><msup><mrow><mo>(</mo><mrow><msub><mi>B</mi><mn>1</mn></msub><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>)</mo></mrow><mrow><mn>2</mn><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\n\n\nFrom Theorem~\\ref{MAPLowerBound}, we know that the bit-error probability for systematic codes under MAP decoding can be lower-bounded in terms of the minimum Hamming weights $d_{\\min,i}$ of $\\mathcal{C}_{1,i}$. However, these minimum weights are usually not available for a general code. If this is the case, we can use instead the row weights of the generator matrix to calculate a looser lower bound as shown in Corollary~\\ref{LDGM_LowerBound}, where the $i$-th row weight can be determined by setting the binary information data $\\boldsymbol{u}$ to a nonzero sequence with only the $i$-th component $u_i=1$. Then we have the following two corollaries.\n\n\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{CorollaryEnsembleLowerBound}\nThe bit-error probability of a systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n    \\ifCLASSOPTIONonecolumn\n    \n", "itemtype": "equation", "pos": 56190, "prevtext": "\n      \\fi\n\\end{enumerate}\nIn summary, the CRWEF $A_2(Y)$ for a systematic BMST-R code ensemble with ${K}_p$ bits in each layer punctured is given by\n\n", "index": 91, "text": "\\begin{equation}\\label{eq:A2-Pun}\n    A_2 \\left( Y \\right) = A_2^{(1)} \\left( Y \\right) + A_2^{(2)} \\left( Y \\right) + A_2^{(3)} \\left( Y \\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E44.m1\" class=\"ltx_Math\" alttext=\"A_{2}\\left(Y\\right)=A_{2}^{(1)}\\left(Y\\right)+A_{2}^{(2)}\\left(Y\\right)+A_{2}^%&#10;{(3)}\\left(Y\\right).\" display=\"block\"><mrow><mrow><mrow><msub><mi>A</mi><mn>2</mn></msub><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msubsup><mi>A</mi><mn>2</mn><mrow><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n    \\fi\n    \\ifCLASSOPTIONtwocolumn\n    \n", "itemtype": "equation", "pos": 57220, "prevtext": "\n\n\n\nFrom Theorem~\\ref{MAPLowerBound}, we know that the bit-error probability for systematic codes under MAP decoding can be lower-bounded in terms of the minimum Hamming weights $d_{\\min,i}$ of $\\mathcal{C}_{1,i}$. However, these minimum weights are usually not available for a general code. If this is the case, we can use instead the row weights of the generator matrix to calculate a looser lower bound as shown in Corollary~\\ref{LDGM_LowerBound}, where the $i$-th row weight can be determined by setting the binary information data $\\boldsymbol{u}$ to a nonzero sequence with only the $i$-th component $u_i=1$. Then we have the following two corollaries.\n\n\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{CorollaryEnsembleLowerBound}\nThe bit-error probability of a systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n    \\ifCLASSOPTIONonecolumn\n    \n", "index": 93, "text": "\\begin{equation}\\label{EnsembleLowerBound}\n        {\\rm BER_{MAP}} \\geq \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}\n        Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right),\n    \\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E45.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\geq\\sum_{\\ell=0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1%&#10;-\\theta)^{\\ell}Q\\left(\\frac{\\sqrt{N+{m}(N-2)-1+\\ell}}{\\sigma}\\right),\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2265</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></munderover><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u2113</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b8</mi><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi></msup><mo>\u2062</mo><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mrow><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mo>+</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n    \\fi\nwhere $\\theta$ is the puncturing fraction.\n\\end{corollary}\n\n\\begin{IEEEproof}\nDue to the random puncturing, the $i$-th row weight $W_i$ of the generator matrix for a systematic BMST-R code ensemble is a random variable. Given a puncturing fraction $\\theta$, the probability mass function of $W_i$ can be calculated as\n\n", "itemtype": "equation", "pos": 57495, "prevtext": "\n    \\fi\n    \\ifCLASSOPTIONtwocolumn\n    \n", "index": 95, "text": "\\begin{align}\\label{EnsembleLowerBound}\n        {\\rm BER_{MAP}} \\geq \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell} ~~~~~~~~~~~~\\nonumber\\\\\n        Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right),\n    \\end{align}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex10.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle{\\rm BER_{MAP}}\\geq\\sum_{\\ell=0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta%&#10;^{m+1-\\ell}(1-\\theta)^{\\ell}\" display=\"inline\"><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2265</mo><mrow><mstyle displaystyle=\"true\"><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></munderover></mstyle><mrow><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac linethickness=\"0pt\"><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u2113</mi></mfrac></mstyle><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b8</mi><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi></msup></mrow></mrow></mrow></math>\n<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E46.m1\" class=\"ltx_Math\" alttext=\"\\displaystyle Q\\left(\\frac{\\sqrt{N+{m}(N-2)-1+\\ell}}{\\sigma}\\right),\" display=\"inline\"><mrow><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mstyle displaystyle=\"true\"><mfrac><msqrt><mrow><mrow><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mo>+</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msqrt><mi>\u03c3</mi></mfrac></mstyle><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nwhere $\\ell \\in \\{0,1,\\cdots,{m}+1\\}$. Thus, the error probability of the $i$-th estimated bit of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\\label{BitEnsembleLowerBound}\n    {\\rm Pr}\\{E_i\\}_{\\rm MAP}\n    \n    &\\geq& \\mathbb{E}\\left[ Q \\left(\\frac{\\sqrt{W_i}}{\\sigma}\\right) \\right] \\nonumber\\\\\n    &=& \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}\\!+\\!1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell} Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "itemtype": "equation", "pos": 58074, "prevtext": "\n    \\fi\nwhere $\\theta$ is the puncturing fraction.\n\\end{corollary}\n\n\\begin{IEEEproof}\nDue to the random puncturing, the $i$-th row weight $W_i$ of the generator matrix for a systematic BMST-R code ensemble is a random variable. Given a puncturing fraction $\\theta$, the probability mass function of $W_i$ can be calculated as\n\n", "index": 97, "text": "\\begin{equation}\\label{prob}\n    {\\rm Pr}\\left\\{W_i=N + {m}(N-2)-1 + \\ell \\right\\} = \\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell},\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E47.m1\" class=\"ltx_Math\" alttext=\"{\\rm Pr}\\left\\{W_{i}=N+{m}(N-2)-1+\\ell\\right\\}=\\binom{{m}+1}{\\ell}\\theta^{m+1-%&#10;\\ell}(1-\\theta)^{\\ell},\" display=\"block\"><mrow><mi>Pr</mi><mrow><mo>{</mo><msub><mi>W</mi><mi>i</mi></msub><mo>=</mo><mi>N</mi><mo>+</mo><mi>m</mi><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo>-</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow><mo>-</mo><mn>1</mn><mo>+</mo><mi mathvariant=\"normal\">\u2113</mi><mo>}</mo></mrow><mo>=</mo><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u2113</mi></mfrac><mo>)</mo></mrow><msup><mi>\u03b8</mi><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup><msup><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>-</mo><mi>\u03b8</mi><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi></msup><mo>,</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\nIt follows that the bit-error probability of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\n    {\\rm BER_{MAP}} &=& \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} {\\rm Pr}\\{E_i\\}_{\\rm MAP} \\nonumber\\\\\n    &\\geq& \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}\n    Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "itemtype": "equation", "pos": 58791, "prevtext": "\nwhere $\\ell \\in \\{0,1,\\cdots,{m}+1\\}$. Thus, the error probability of the $i$-th estimated bit of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\\label{BitEnsembleLowerBound}\n    {\\rm Pr}\\{E_i\\}_{\\rm MAP}\n    \n    &\\geq& \\mathbb{E}\\left[ Q \\left(\\frac{\\sqrt{W_i}}{\\sigma}\\right) \\right] \\nonumber\\\\\n    &=& \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}\\!+\\!1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell} Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "index": 99, "text": "\\begin{equation}\\label{BitEnsembleLowerBound}\n\\begin{split}\n    {\\rm Pr}\\{E_i\\}_{\\rm MAP}\n    \n    &\\geq \\mathbb{E}\\left[ Q \\left(\\frac{\\sqrt{W_i}}{\\sigma}\\right) \\right] \\\\\n    &= \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}\\!+\\!1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}\\\\\n    &~~~~~~~~~~~~~~~Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E48.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle{\\rm Pr}\\{E_{i}\\}_{\\rm MAP}\\par&#10;&amp;\\displaystyle\\geq%&#10;\\mathbb{E}\\left[Q\\left(\\frac{\\sqrt{W_{i}}}{\\sigma}\\right)\\right]\\\\&#10;&amp;\\displaystyle=\\sum_{\\ell=0}^{{m}+1}\\binom{{m}\\!+\\!1}{\\ell}\\theta^{m+1-\\ell}(1%&#10;-\\theta)^{\\ell}\\\\&#10;&amp;\\displaystyle~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}Q\\left(\\frac{\\sqrt{%&#10;N+{m}(N-2)-1+\\ell}}{\\sigma}\\right).\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><mrow><mi>Pr</mi><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow><mi>MAP</mi></msub></mrow></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>\u2265</mo><mrow><mi>\ud835\udd3c</mi><mo>\u2062</mo><mrow><mo>[</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><msub><mi>W</mi><mi>i</mi></msub></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></munderover><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mpadded width=\"-1.7pt\"><mi>m</mi></mpadded><mo rspace=\"0.8pt\">+</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u2113</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b8</mi><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi></msup></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mpadded lspace=\"49.5pt\" width=\"+49.5pt\"><mi>Q</mi></mpadded><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mrow><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mo>+</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\fi\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary8}\nThe bit-error probability of a systematic BMST-R code ensemble without puncturing~(i.e., with puncturing fraction $\\theta=0$) under MAP decoding can be lower-bounded by\n\n", "itemtype": "equation", "pos": 59626, "prevtext": "\n\\fi\nIt follows that the bit-error probability of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\ifCLASSOPTIONonecolumn\n\\begin{eqnarray}\n    {\\rm BER_{MAP}} &=& \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} {\\rm Pr}\\{E_i\\}_{\\rm MAP} \\nonumber\\\\\n    &\\geq& \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}\n    Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\n\\end{eqnarray}\n\\fi\n\\ifCLASSOPTIONtwocolumn\n\n", "index": 101, "text": "\\begin{equation}\n\\begin{split}\n    {\\rm BER_{MAP}} &= \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} {\\rm Pr}\\{E_i\\}_{\\rm MAP} \\\\\n    &\\geq \\sum_{\\ell = 0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-\\theta)^{\\ell}\\\\\n    &~~~~~~~~~~~~~\\cdot Q\\left(\\frac{\\sqrt{N + {m}(N-2)-1 + \\ell}}{\\sigma}\\right).\\\\\n\\end{split}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E49.m1\" class=\"ltx_Math\" alttext=\"\\begin{split}\\displaystyle{\\rm BER_{MAP}}&amp;\\displaystyle=\\frac{1}{{k}}\\sum%&#10;\\limits_{i=0}^{{k}-1}{\\rm Pr}\\{E_{i}\\}_{\\rm MAP}\\\\&#10;&amp;\\displaystyle\\geq\\sum_{\\ell=0}^{{m}+1}\\binom{{m}+1}{\\ell}\\theta^{m+1-\\ell}(1-%&#10;\\theta)^{\\ell}\\\\&#10;&amp;\\displaystyle~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}~{}\\cdot Q\\left(\\frac{\\sqrt{%&#10;N+{m}(N-2)-1+\\ell}}{\\sigma}\\right).\\\\&#10;\\end{split}\" display=\"block\"><mtable columnspacing=\"0pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd columnalign=\"right\"><msub><mi>BER</mi><mi>MAP</mi></msub></mtd><mtd columnalign=\"left\"><mrow><mi/><mo>=</mo><mrow><mfrac><mn>1</mn><mi>k</mi></mfrac><mo>\u2062</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>Pr</mi><mo>\u2062</mo><msub><mrow><mo stretchy=\"false\">{</mo><msub><mi>E</mi><mi>i</mi></msub><mo stretchy=\"false\">}</mo></mrow><mi>MAP</mi></msub></mrow></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mi/><mo>\u2265</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi mathvariant=\"normal\">\u2113</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></munderover><mrow><mrow><mo>(</mo><mfrac linethickness=\"0pt\"><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mi mathvariant=\"normal\">\u2113</mi></mfrac><mo>)</mo></mrow><mo>\u2062</mo><msup><mi>\u03b8</mi><mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msup><mo>\u2062</mo><msup><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><mi>\u03b8</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mi mathvariant=\"normal\">\u2113</mi></msup></mrow></mrow></mrow></mtd></mtr><mtr><mtd/><mtd columnalign=\"left\"><mrow><mrow><mi/><mo lspace=\"45.4pt\">\u22c5</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mrow><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>2</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>-</mo><mn>1</mn></mrow><mo>+</mo><mi mathvariant=\"normal\">\u2113</mi></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></mtd></mtr></mtable></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nFor a specific $i$~$(0 \\leq i \\leq {k}-1)$, we can see from~(\\ref{eq:A1}) that the $i$-th row of the generator matrix has a deterministic weight\n\n", "itemtype": "equation", "pos": 60192, "prevtext": "\n\\fi\n\\end{IEEEproof}\n\n\\vspace{0.15cm}\n\\begin{corollary}\\label{Corollary8}\nThe bit-error probability of a systematic BMST-R code ensemble without puncturing~(i.e., with puncturing fraction $\\theta=0$) under MAP decoding can be lower-bounded by\n\n", "index": 103, "text": "\\begin{equation}\\label{CodeLowerBound}\n    {\\rm BER_{MAP}} \\geq Q\\left({\\frac{\\sqrt{N + {m}(N-1)}}{\\sigma}}\\right).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E50.m1\" class=\"ltx_Math\" alttext=\"{\\rm BER_{MAP}}\\geq Q\\left({\\frac{\\sqrt{N+{m}(N-1)}}{\\sigma}}\\right).\" display=\"block\"><mrow><mrow><msub><mi>BER</mi><mi>MAP</mi></msub><mo>\u2265</mo><mrow><mi>Q</mi><mo>\u2062</mo><mrow><mo>(</mo><mfrac><msqrt><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></msqrt><mi>\u03c3</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nThus, the error probability of the $i$-th estimated bit of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\begin{eqnarray}\n    {\\rm Pr}\\{E_i\\}_{\\rm MAP}\n    \n    &\\geq& Q \\left(\\frac{\\sqrt{w_i}}{\\sigma}\\right) \\nonumber\\\\\n    &=& Q \\left(\\frac{\\sqrt{N + {m}(N-1)}}{\\sigma} \\right).\n\\end{eqnarray}\nIt follows that the bit-error probability of the systematic BMST-R code ensemble without puncturing under MAP decoding can be lower-bounded by\n\\begin{eqnarray}\n    {\\rm BER_{MAP}} &=& \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} {\\rm Pr}\\{E_i\\}_{\\rm MAP} \\nonumber\\\\\n    &\\geq& Q \\left(\\frac{\\sqrt{N + {m}(N-1)}}{\\sigma} \\right).\n\\end{eqnarray}\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Corollaries~\\ref{CorollaryEnsembleLowerBound} and~\\ref{Corollary8} also hold for systematic BMST-R codes with specific interleavers for the reason that the interleavers have no effect on the row weights of the generator matrix. Since the lower bound~(\\ref{CodeLowerBound}) without puncturing is equivalent to the lower bound~(\\ref{EnsembleLowerBound}) with puncturing fraction $\\theta=0$, in the rest of the paper, we consider for generality the lower bound~(\\ref{EnsembleLowerBound}).\n\n\\subsection{Trade-Off Between Performance and Complexity}\\label{subsec:TradeOff}\n\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ComputationalComplexity_DiffRate.eps}\n    \\caption{Decoding complexity for systematic BMST-R codes as a function of code rate that requires an SNR of 2 dB to achieve target BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$.}\n    \\label{Fig_Complexity_DiffRate}\n\\end{figure}\n\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ComputationalComplexity_Rate0.5.eps}\n    \\caption{Decoding complexity for rate 1/2 systematic BMST-R codes as a function of SNR with target BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$.}\n    \\label{Fig_Complexity_Rate0.5}\n\\end{figure}\n\nThe implementation complexity of systematic BMST-R codes can be analyzed as with their non-systematic counterpart. For encoding, the information sequence is partitioned equally into blocks and transmitted directly, while their replicas are interleaved and transmitted in a block Markov superposition manner. This shows that the encoding complexity grows linearly with the encoding memory ${m}$. For decoding, a sliding window decoding algorithm with a tunable decoding delay can be implemented over the normal graph~(see Fig.~\\ref{BMST_decoder}). The decoding complexity for node \\fbox{+} and node \\fbox{=} of systematic BMST-R codes grows linearly with the encoding memory ${m}$. Furthermore, similar to non-systematic BMST codes, a decoding delay $d = 2m \\!\\sim\\! 3 m$ is required to achieve the lower bound on the performance. As a result, the decoding complexity for systematic BMST-R codes can be roughly given as $\\mathcal{O}(N{m} d)$, or equivalently, $\\mathcal{O}(N{m}^2)$.\n\n\n\nThe above analysis shows that the decoding complexity is closely related to the repetition degree $N$ and the encoding memory ${m}$, both of which in turn determine the lower bound~(\\ref{EnsembleLowerBound}). This allows us to make trade-offs among efficiency, performance and complexity. To be precise, we consider the following two cases.\n\\begin{enumerate}\n  \\item Fixed SNR. We can observe from the lower bound~(\\ref{EnsembleLowerBound}) that, for a given SNR and BER, the required encoding memory ${m}$ decreases as the repetition degree $N$ increases~(accordingly, the code rate decreases), resulting in a lower complexity. Fig.~\\ref{Fig_Complexity_DiffRate} shows the decoding complexity for systematic BMST-R codes as a function of code rate that requires an SNR of 2 dB to achieve BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$. As expected, for fixed BER, the greater the code rate is, the higher the decoding complexity is. We also see that for fixed code rate, the higher the performance requirement~(equivalently, the more stringent the BER) is, the higher the decoding complexity is.\n  \\item Fixed code rate. We can observe from the lower bound~(\\ref{EnsembleLowerBound}) that, for a given rate and BER, the required encoding memory ${m}$ decreases as the SNR increases, resulting in a lower decoding complexity. This is reasonable since more excessive SNR is available compared to the corresponding Shannon limit. Fig.~\\ref{Fig_Complexity_Rate0.5} shows the decoding complexity for rate 1/2 systematic BMST-R codes as a function of SNR with BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$. As expected, for fixed BER, the greater the SNR is, the lower the decoding complexity is. We also observe that for fixed SNR, the more stringent the BER is, the higher the decoding complexity is.\n\\end{enumerate}\n\n\\section{Numerical Analysis and Performance Comparison}\\label{SecIV}\nIn this section, all simulations are performed assuming BPSK modulation and transmitted over an AWGN channel, unless otherwise specified. The $(m+1)(N-1)$ random interleavers~(randomly generated but fixed) of size ${K}$ are used for encoding. The iterative sliding window decoding algorithm for systematic BMST-R codes is performed using the parallel (flooding) updating schedule within the decoding window with a maximum iteration number of 18, and the entropy stopping criterion~\\cite{Ma04,Ma15} with a preselected threshold of $10^{-6}$ is employed.\n\n\\subsection{Performance Bounds and Code Construction}\\label{SecIV-A}\n\nIn this subsection, we present an example to study the performance bounds on BER of systematic BMST-R codes. We consider systematic BMST-R codes with repetition degree $N=2$ and puncturing fraction $\\theta=0$. The decoding delay $d$ for the sliding window decoding is specified as $d=3m$.\n\n\\begin{example}\\label{Example1}\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{CodeSpectrum.eps}\n    \\caption{Spectrum $\\{D_s\\}~(0\\leq s\\leq 60)$ of systematic BMST-R code ensembles with encoding encoding memory $m=0$, $m=1$ and $m=2$ in Example 1. Assume $L=20$ blocks of information data, where the information subsequence has length ${K}=30$. The systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. The truncating parameter is set to $T=60$. The code rates of systematic BMST-R code ensembles with $m=0$, $m=1$ and $m=2$ are 0.5, 0.4878 and 0.4762, respectively.}\n    \\label{Fig_Spectrum}\n\\end{figure}\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{LowerUpperBoundOptimal.eps}\n    \\caption{Performance of systematic BMST-R code ensembles with encoding encoding memory $m=0$, $m=1$ and $m=2$ in Example 1. The systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. Assume $L=20$ blocks of information data, where the information subsequence has length ${K}=30$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The decoding delay $d$ is specified as $d=3m$. The truncating parameter is set to $T=60$. The code rates of systematic BMST-R code ensembles with $m=0$, $m=1$ and $m=2$ are 0.5, 0.4878 and 0.4762, respectively.}\n    \\label{Fig_PerformanceBounds}\n\\end{figure}\nAssume that there are $L=20$ blocks of information data to be transmitted, where the information subsequence have length ${K}=30$. We consider systematic BMST-R code ensembles with encoding memory $m=0$, $m=1$ and $m=2$, whose code rates are 0.5, 0.4878 and 0.4762, respectively. Here, the systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. Assume that we only calculate the truncated IRWEF $\\{A_{i,j}$, $0 \\leq i \\leq 60\\}$. That is, the truncating parameter is set to $T=60$. Fig.~\\ref{Fig_Spectrum} shows the spectrum $\\{D_s\\}~(0< s\\leq T)$ of systematic BMST-R code ensembles, where\n\n", "itemtype": "equation", "pos": 60503, "prevtext": "\n\\end{corollary}\n\n\\begin{IEEEproof}\nFor a specific $i$~$(0 \\leq i \\leq {k}-1)$, we can see from~(\\ref{eq:A1}) that the $i$-th row of the generator matrix has a deterministic weight\n\n", "index": 105, "text": "\\begin{equation}\\label{d_i}\n  w_i = N + {m}(N-1).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E51.m1\" class=\"ltx_Math\" alttext=\"w_{i}=N+{m}(N-1).\" display=\"block\"><mrow><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mrow><mi>N</mi><mo>+</mo><mrow><mi>m</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nFrom Fig.~\\ref{Fig_Spectrum}, we see that the spectrum of the systematic BMST-R code ensembles with $m=1$ and $m=2$ have less number of codewords with small Hamming weights. We also see that the minimum Hamming distances of systematic BMST-R code ensembles with encoding memory $m=0$, $m=1$ and $m=2$ are 2, 3 and 4, respectively. These indicate that the systematic BMST-R codes have potentially better performance than the independent transmission system. The simulation results are shown in Fig.~\\ref{Fig_PerformanceBounds}, where we observe that\n\\begin{enumerate}\n  \\item The lower and upper bounds on the BER performance of systematic BMST-R codes are tight in the high SNR region.\n  \\item The simulated BER performance curves match well with the bounds in the high SNR region, indicating that the sliding window decoding algorithm is near optimal in the high SNR region.\n  \\item The systematic BMST-R codes outperform the independent transmission system~(i.e., the systematic BMST-R code with $m=0$). Furthermore, the systematic BMST-R code with encoding memory $m=2$ outperforms the systematic BMST-R code with $m=1$. Taking into account the rate loss, the systematic BMST-R code with $m=2$ obtains a net gain of 1.175 dB in terms of $E_b/N_0$ at a BER of $10^{-5}$, compared to the systematic BMST-R code with $m=1$.\n\\end{enumerate}\n\\end{example}\n\nGiven the tightness of the lower bound~(\\ref{EnsembleLowerBound}) as demonstrated in Example~\\ref{Example1}, we have the following simple procedure to construct good codes. Let $R \\in (0,1)$ be the target code rate and $p_{\\rm target}$ be the target BER. The object is to construct a code with rate $R_L \\approx R$, which can approach the Shannon limit at the target BER. A systematic BMST-R code has the following five parameters: repetition degree $N$, information subsequence length ${K}$, puncturing length ${K}_p$, data block length $L$, and encoding memory $m$. These parameters can be determined as follows.\n\n\n\n\n\\begin{enumerate}\n  \\item Determine the repetition degree $N$ and puncturing fraction $\\theta$ such that $\\frac{1}{N-\\theta} = R$. Choose sufficiently large information subsequence length\\footnote{By simulation, we find that ${K}\\geq 2500$ suffices to approach the Shannon limit within around half dB.} ${K}$ and puncturing length ${K}_p$ such that ${K}_p/{K} \\approx \\theta$;\n  \\item Find the Shannon limit for the given code rate $R$ and target BER $p_{\\rm target}$;\n  \\item Determine the minimum encoding memory $m$ such that the lower bound of ${\\rm BER_{MAP}}$ in~(\\ref{EnsembleLowerBound}) at the Shannon limit is not greater than the preselected target BER $p_{\\rm target}$;\n  \\item Choose a data block length $L$ such that the rate loss (i.e., $R-R_L$) due to the termination is small;\n  \\item Generate $(m+1)(N-1)$ interleavers randomly.\n\\end{enumerate}\n\nEvidently, the above procedure requires no optimization and hence can be easily implemented. The encoding memories for some systematic BMST-R codes required to approach the corresponding Shannon limits at given target BERs are shown in Table~\\ref{Table1}. As expected, the lower the target BER is, the greater the required encoding memory ${m}$ is.\n\n\\begin{table*}\n\\caption{Encoding memories for systematic BMST-R codes required to approach the corresponding Shannon limits at given target BERs}\\label{Table1}\n  \\centering\n  \\begin{tabular}{|c||c|c|c|c|}\n  \\hline\n  \n  \\multirow{2}{*}{Systematic BMST-R Codes} &\\multicolumn{4}{c|}{Encoding Memory $m$}\\\\ \\cline{2-5}\n   &${\\rm BER}=10^{-3}$ &${\\rm BER}=10^{-4}$ &${\\rm BER}=10^{-5}$ &${\\rm BER}=10^{-6}$\\\\ \\hline\n  ${\\rm Rate}~2/3$, $N=2$, $\\theta=0.5$                    &12 &18 &24 &31 \\\\\\hline\n  ${\\rm Rate}~1/2$, $N=2$, $\\theta=0$                       &8 &12 &16 &20  \\\\\\hline\n  ${\\rm Rate}~2/5$, $N=3$, $\\theta=0.5$                     &8 &11 &15 &19  \\\\\\hline\n  ${\\rm Rate}~1/3$, $N=3$, $\\theta=0$                      &7 &11 &14 &18 \\\\\\hline\n  ${\\rm Rate}~1/4$, $N=4$, $\\theta=0$                       &7 &10 &14 &17  \\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Impact of Parameters on BER}\nIn this subsection, we study the impact of various parameters~(e.g., encoding memory ${m}$, information subsequence length ${K}$ and decoding delay $d$) on the BER performance of systematic BMST-R codes with fixed code rate. Note that, as pointed out in~Section~\\ref{subsec:encoding}, varying repetition degree $N$ and puncturing fraction $\\theta$ results in systematic codes with different rates. For simplicity, we focus on $R_L=0.49$ systematic BMST-R codes with repetition degree $N=2$ and puncturing fraction $\\theta=0$. Three regimes are considered: (1)~fixed ${m}$ and ${K}$, increasing $d$, (2)~fixed ${m}$ and $d$, increasing ${K}$, and (3)~fixed ${K}$, increasing ${m}$~(and hence $d$).\n\n\\begin{example}[Fixed ${m}$ and ${K}$, Increasing $d$]\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ImpactParameters_DiffDelay_SNR_K.eps}\n    \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes decoded with different decoding delays $d$ in Example 2. Information subsequence length ${K}=300$, encoding memory ${m}=16$ and data block length $L=392$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding window decoding thresholds and the lower bound are also plotted.}\n    \\label{Fig_ImpactParameters_DiffDelay}\n\\end{figure}\nConsider a systematic BMST-R code with information subsequence length ${K}=300$, encoding memory ${m}=16$ and data block length $L=392$. The BER performance of the systematic BMST-R code decoded with different decoding delays $d$ is shown in Fig.~\\ref{Fig_ImpactParameters_DiffDelay}. The asymptotic threshold performance obtained by using the EXIT chart analysis method in~\\cite{Huang15JSAC} is also included. From Fig.~\\ref{Fig_ImpactParameters_DiffDelay}, we observe that\n\\begin{enumerate}\n  \\item The BER performance of the systematic BMST-R code decoded with different delays $d$ matches well with the corresponding window decoding thresholds in the high SNR region.\n  \\item The BER performance in the waterfall region improves as the decoding delay $d$ increases, but it does not improve much further beyond a certain decoding delay~(roughly $d=20$).\n  \\item The BER performance in the error floor region improves as the decoding delay $d$ increases, and it matches well with the lower bound for the systematic BMST-R code with ${m}=16$ when $d$ increases up to a certain point~(roughly $d=32$).\n\\end{enumerate}\n\n\\end{example}\n\n\n\\begin{example}[Fixed ${m}$ and $d$, Increasing ${K}$]\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ImpactParameters_DiffCartesianProductOrder_SNR_K.eps}\n    \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes with different information subsequence lengths ${K}$ in Example 3. The codes are constructed with encoding memory ${m}=16$ and data block length $L=392$, and decoded with decoding delay $d=32$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding lower bound is also plotted.}\n    \\label{Fig_ImpactParameters_DiffCartesianProductOrder}\n\\end{figure}\nConsider systematic BMST-R codes constructed with encoding memory ${m}=16$, data block length $L=392$ and decoded with decoding delay $d=32$. The BER performance of systematic BMST-R codes constructed with different information subsequence lengths ${K}$ is shown in Fig.~\\ref{Fig_ImpactParameters_DiffCartesianProductOrder}, where we observe that\n\\begin{enumerate}\n  \\item Increasing the information subsequence length ${K}$ can improve waterfall region performance. As expected, this improvement saturates for sufficiently large ${K}$. For example, the improvement at a BER of $10^{-5}$ from ${K}=200$ to ${K}=450$, both decoded with $d=16$, is about 0.25 dB, while the improvement decreases to about 0.05 dB from ${K}=700$ to ${K}=950$.\n\n  \\item The error floors, which are determined by the encoding memory and code rate~(see Corollary~\\ref{CorollaryEnsembleLowerBound}), cannot be lowered by increasing ${K}$.\n\\end{enumerate}\n\\end{example}\n\n\n\\begin{example}[Fixed ${K}$, Increasing ${m}$~(and hence $d$)]\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{ImpactParameters_DiffMemory_2500_SNR_K.eps}\n  \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes constructed with different encoding memories ${m}$ and decoded with decoding delay $d=2{m}$ in Example 4. The information subsequence length of the involved systematic BMST-R codes is ${K}=2500$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding window decoding thresholds and lower bounds for systematic BMST-R codes are also plotted.}\n  \\label{Fig_ImpactParameters_DiffMemory}\n\\end{figure}\nConsider systematic BMST-R codes constructed with information subsequence length ${K}=2500$ and encoding memories ${m}=8$, $12$ and $16$. The performance with sufficiently large decoding delay $d=2{m}$ of the systematic BMST-R codes is shown in Fig.~\\ref{Fig_ImpactParameters_DiffMemory}, where we observe that\n\\begin{enumerate}\n  \\item The BER performance of systematic BMST-R codes matches well with the corresponding window decoding thresholds in the high SNR region.\n  \\item For a high target BER~(roughly above $10^{-3}$), the BER performance improves as the encoding memory ${m}$ increases, which is consistent with the threshold analysis performance. Note that this phenomenon does not exist for non-systematic BMST codes whose performance degrades slightly as ${m}$ increases~(see Section~V-C of~\\cite{Huang15JSAC}).\n  \\item The error floor can be lowered by increasing the encoding memory ${m}$~(and hence the decoding delay $d$).\n\\end{enumerate}\n\\end{example}\n\n\n\\subsection{Decoding Performance Based on Latency}\nIn addition to decoding performance, the latency introduced by employing channel coding is a crucial factor in the design of a practical communication system, such as personal wireless communication and real-time audio and video. In this subsection, we study the BER performance of systematic BMST-R codes based on their decoding latency.\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[clip,width={0.48\\textwidth}]{EqualDecodingLatency_SNR_K.eps}\n  \\caption{Required SNR to achieve a BER of $10^{-5}$ for finite-length systematic BMST-R codes, non-systematic BMST-R codes in~\\cite{Huang15JSAC}, $(3,6)$-regular SC-LDPC codes, and $(4,8)$-regular SC-LDPC codes as a function of decoding latency. All the codes have rate 0.49. The decoding delays for $(3,6)$-regular SC-LDPC codes and $(4,8)$-regular SC-LDPC codes are $5$ and $3$, respectively. The encoding memories for non-systematic BMST-R codes and systematic BMST-R codes are 8 and 16, respectively. The values of the information subsequence length and decoding delay for the non-systematic BMST-R codes are chosen such that the combination gives the best decoding performance. The decoding delays for the systematic BMST-R codes are $d=16$, $17$, $\\cdots$, $24$. The codeword is modulated using BPSK and transmitted over an AWGN channel.}\n  \\label{Fig_EqualDecodingLatency}\n\\end{figure}\n\n\\begin{example}\nWe consider rate $R_L=0.49$ systematic BMST-R codes with encoding memory ${m}=16$, repetition degree $N=2$ and puncturing fraction $\\theta=0$. The decoding latency of the sliding window decoder, in terms of bits, is given by\n\n", "itemtype": "equation", "pos": 68403, "prevtext": "\nThus, the error probability of the $i$-th estimated bit of the systematic BMST-R code ensemble under MAP decoding can be lower-bounded by\n\\begin{eqnarray}\n    {\\rm Pr}\\{E_i\\}_{\\rm MAP}\n    \n    &\\geq& Q \\left(\\frac{\\sqrt{w_i}}{\\sigma}\\right) \\nonumber\\\\\n    &=& Q \\left(\\frac{\\sqrt{N + {m}(N-1)}}{\\sigma} \\right).\n\\end{eqnarray}\nIt follows that the bit-error probability of the systematic BMST-R code ensemble without puncturing under MAP decoding can be lower-bounded by\n\\begin{eqnarray}\n    {\\rm BER_{MAP}} &=& \\frac{1}{{k}} \\sum\\limits_{i=0}^{{k}-1} {\\rm Pr}\\{E_i\\}_{\\rm MAP} \\nonumber\\\\\n    &\\geq& Q \\left(\\frac{\\sqrt{N + {m}(N-1)}}{\\sigma} \\right).\n\\end{eqnarray}\n\\end{IEEEproof}\n\n\\textbf{Remarks.}~Corollaries~\\ref{CorollaryEnsembleLowerBound} and~\\ref{Corollary8} also hold for systematic BMST-R codes with specific interleavers for the reason that the interleavers have no effect on the row weights of the generator matrix. Since the lower bound~(\\ref{CodeLowerBound}) without puncturing is equivalent to the lower bound~(\\ref{EnsembleLowerBound}) with puncturing fraction $\\theta=0$, in the rest of the paper, we consider for generality the lower bound~(\\ref{EnsembleLowerBound}).\n\n\\subsection{Trade-Off Between Performance and Complexity}\\label{subsec:TradeOff}\n\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ComputationalComplexity_DiffRate.eps}\n    \\caption{Decoding complexity for systematic BMST-R codes as a function of code rate that requires an SNR of 2 dB to achieve target BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$.}\n    \\label{Fig_Complexity_DiffRate}\n\\end{figure}\n\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ComputationalComplexity_Rate0.5.eps}\n    \\caption{Decoding complexity for rate 1/2 systematic BMST-R codes as a function of SNR with target BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$.}\n    \\label{Fig_Complexity_Rate0.5}\n\\end{figure}\n\nThe implementation complexity of systematic BMST-R codes can be analyzed as with their non-systematic counterpart. For encoding, the information sequence is partitioned equally into blocks and transmitted directly, while their replicas are interleaved and transmitted in a block Markov superposition manner. This shows that the encoding complexity grows linearly with the encoding memory ${m}$. For decoding, a sliding window decoding algorithm with a tunable decoding delay can be implemented over the normal graph~(see Fig.~\\ref{BMST_decoder}). The decoding complexity for node \\fbox{+} and node \\fbox{=} of systematic BMST-R codes grows linearly with the encoding memory ${m}$. Furthermore, similar to non-systematic BMST codes, a decoding delay $d = 2m \\!\\sim\\! 3 m$ is required to achieve the lower bound on the performance. As a result, the decoding complexity for systematic BMST-R codes can be roughly given as $\\mathcal{O}(N{m} d)$, or equivalently, $\\mathcal{O}(N{m}^2)$.\n\n\n\nThe above analysis shows that the decoding complexity is closely related to the repetition degree $N$ and the encoding memory ${m}$, both of which in turn determine the lower bound~(\\ref{EnsembleLowerBound}). This allows us to make trade-offs among efficiency, performance and complexity. To be precise, we consider the following two cases.\n\\begin{enumerate}\n  \\item Fixed SNR. We can observe from the lower bound~(\\ref{EnsembleLowerBound}) that, for a given SNR and BER, the required encoding memory ${m}$ decreases as the repetition degree $N$ increases~(accordingly, the code rate decreases), resulting in a lower complexity. Fig.~\\ref{Fig_Complexity_DiffRate} shows the decoding complexity for systematic BMST-R codes as a function of code rate that requires an SNR of 2 dB to achieve BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$. As expected, for fixed BER, the greater the code rate is, the higher the decoding complexity is. We also see that for fixed code rate, the higher the performance requirement~(equivalently, the more stringent the BER) is, the higher the decoding complexity is.\n  \\item Fixed code rate. We can observe from the lower bound~(\\ref{EnsembleLowerBound}) that, for a given rate and BER, the required encoding memory ${m}$ decreases as the SNR increases, resulting in a lower decoding complexity. This is reasonable since more excessive SNR is available compared to the corresponding Shannon limit. Fig.~\\ref{Fig_Complexity_Rate0.5} shows the decoding complexity for rate 1/2 systematic BMST-R codes as a function of SNR with BERs of $10^{-3}$, $10^{-4}$ and $10^{-5}$. As expected, for fixed BER, the greater the SNR is, the lower the decoding complexity is. We also observe that for fixed SNR, the more stringent the BER is, the higher the decoding complexity is.\n\\end{enumerate}\n\n\\section{Numerical Analysis and Performance Comparison}\\label{SecIV}\nIn this section, all simulations are performed assuming BPSK modulation and transmitted over an AWGN channel, unless otherwise specified. The $(m+1)(N-1)$ random interleavers~(randomly generated but fixed) of size ${K}$ are used for encoding. The iterative sliding window decoding algorithm for systematic BMST-R codes is performed using the parallel (flooding) updating schedule within the decoding window with a maximum iteration number of 18, and the entropy stopping criterion~\\cite{Ma04,Ma15} with a preselected threshold of $10^{-6}$ is employed.\n\n\\subsection{Performance Bounds and Code Construction}\\label{SecIV-A}\n\nIn this subsection, we present an example to study the performance bounds on BER of systematic BMST-R codes. We consider systematic BMST-R codes with repetition degree $N=2$ and puncturing fraction $\\theta=0$. The decoding delay $d$ for the sliding window decoding is specified as $d=3m$.\n\n\\begin{example}\\label{Example1}\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{CodeSpectrum.eps}\n    \\caption{Spectrum $\\{D_s\\}~(0\\leq s\\leq 60)$ of systematic BMST-R code ensembles with encoding encoding memory $m=0$, $m=1$ and $m=2$ in Example 1. Assume $L=20$ blocks of information data, where the information subsequence has length ${K}=30$. The systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. The truncating parameter is set to $T=60$. The code rates of systematic BMST-R code ensembles with $m=0$, $m=1$ and $m=2$ are 0.5, 0.4878 and 0.4762, respectively.}\n    \\label{Fig_Spectrum}\n\\end{figure}\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{LowerUpperBoundOptimal.eps}\n    \\caption{Performance of systematic BMST-R code ensembles with encoding encoding memory $m=0$, $m=1$ and $m=2$ in Example 1. The systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. Assume $L=20$ blocks of information data, where the information subsequence has length ${K}=30$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The decoding delay $d$ is specified as $d=3m$. The truncating parameter is set to $T=60$. The code rates of systematic BMST-R code ensembles with $m=0$, $m=1$ and $m=2$ are 0.5, 0.4878 and 0.4762, respectively.}\n    \\label{Fig_PerformanceBounds}\n\\end{figure}\nAssume that there are $L=20$ blocks of information data to be transmitted, where the information subsequence have length ${K}=30$. We consider systematic BMST-R code ensembles with encoding memory $m=0$, $m=1$ and $m=2$, whose code rates are 0.5, 0.4878 and 0.4762, respectively. Here, the systematic BMST-R code with $m=0$ is equivalent to the independent transmission of rate 0.5 repetition code. Assume that we only calculate the truncated IRWEF $\\{A_{i,j}$, $0 \\leq i \\leq 60\\}$. That is, the truncating parameter is set to $T=60$. Fig.~\\ref{Fig_Spectrum} shows the spectrum $\\{D_s\\}~(0< s\\leq T)$ of systematic BMST-R code ensembles, where\n\n", "index": 107, "text": "\\begin{equation}\\label{eq:Ds}\n  D_{s} = \\sum_{i=1}^{T}\\frac{i}{{k}}A_{i,s-i}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E52.m1\" class=\"ltx_Math\" alttext=\"D_{s}=\\sum_{i=1}^{T}\\frac{i}{{k}}A_{i,s-i}.\" display=\"block\"><mrow><mrow><msub><mi>D</mi><mi>s</mi></msub><mo>=</mo><mrow><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mrow><mfrac><mi>i</mi><mi>k</mi></mfrac><mo>\u2062</mo><msub><mi>A</mi><mrow><mi>i</mi><mo>,</mo><mrow><mi>s</mi><mo>-</mo><mi>i</mi></mrow></mrow></msub></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nThe SNR required to achieve a BER of $10^{-5}$ as a function of decoding latency is shown in Fig.~\\ref{Fig_EqualDecodingLatency}. We observe that the performance of systematic BMST-R codes~(with fixed information subsequence length ${K}$) improves as the decoding delay $d$~(and hence the latency) increases, but it does not improve much further beyond a certain decoding delay. Moreover, beyond a certain latency, using a greater information subsequence length ${K}$ with a smaller decoding delay $d$ gives better performance. For example, the systematic BMST-R code constructed with a greater information subsequence length ${K}=300$ and decoded with a smaller decoding delay $d=19$ outperforms the systematic BMST-R code constructed with a small information subsequence length ${K}=250$ and decoded with a greater decoding delay $d=23$~(both have the same decoding latency of 12000 bits).\n\nWe also compare the performance of systematic BMST-R codes, non-systematic BMST-R codes in~\\cite{Huang15JSAC}, and SC-LDPC codes when the decoding latencies are equal, as shown in Fig.~\\ref{Fig_EqualDecodingLatency}. All the codes have rate 0.49. We restrict consideration to $(3,6)$-regular SC-LDPC codes with two component submatrices $\\mathbf{B}_{0}=[2~1]$ and $\\mathbf{B}_{1}=[1~2]$, and $(4,8)$-regular SC-LDPC codes with two component submatrices $\\mathbf{B}_{0}=[3~1]$ and $\\mathbf{B}_{1}=[1~3]$. The decoding delays for $(3,6)$-regular SC-LDPC codes and $(4,8)$-regular SC-LDPC codes are $5$ and $3$, respectively, which are good choices to achieve optimum performance when the decoding latencies are fixed.\\footnote{For a more in-depth discussion of the relationship between the protograph lifting factor, the decoding window size and the decoding performance of SC-LDPC codes when the decoding latency is fixed, we refer the reader to~\\cite{Huang14}.} The encoding memories for non-systematic BMST-R codes and systematic BMST-R codes are 8 and 16, respectively. The values of the information subsequence length and decoding delay for the non-systematic BMST-R codes are chosen such that the combination gives the best decoding performance~(see Section~VI-A of~\\cite{Huang15JSAC}). The decoding delays for the systematic BMST-R codes are $d=16$, $17$, $\\cdots$, $24$. We observe that the systematic BMST-R codes perform better than both the non-systematic BMST-R codes and the SC-LDPC codes. For example, in the decoding latency of 12000 bits, the systematic BMST-R code with information subsequence length ${K}=300$ and decoding delay $d=19$ gains 0.12 dB, 0.21 dB and 0.24 dB, respectively, compared to the non-systematic BMST-R code, $(3,6)$-regular SC-LDPC code, and $(4,8)$-regular SC-LDPC code.\n\n\\end{example}\n\n\n\\subsection{Rate-Compatible Property}\nIn this subsection, we show the performance of systematic BMST-R codes with different rates by varying repetition degree $N$ and puncturing fraction $\\theta$.\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{BERMultiRate.eps}\n  \\caption{Simulated decoding performance of systematic BMST-R codes with information subsequence length ${K}=500$ and data block length $L=500$. The repetition degree $N$, encoding memories $m$ and puncturing fraction $\\theta$ are specified in the legends. The decoding delay is specified as $d=2m$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding lower bounds~(dotted magenta) for systematic BMST-R codes are also plotted. The rates of the systematic BMST-R codes corresponding to the BER curves from left to right in the figure are $0.1631,0.1959,0.2449, 0.2801, 0.3272, 0.3929, 0.4921, 0.5623, 0.6562,$ and $0.7874$.}\n  \\label{Fig_BERMultiRate}\n\\end{figure}\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{RequiredSNRMultiRate_K.eps}\n  \\caption{Required SNR to achieve a BER of $10^{-5}$ for systematic BMST-R codes with information subsequence length ${K}=500$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The performances of three AR4JA LDPC codes with code rates $1/2$, $2/3$ and $4/5$ in the CCSDS standard~\\cite{CCSDS12Coding}, and five PBRL LDPC codes~\\cite{Chen15} with code rates $1/4$, $1/3$, $1/2$, $2/3$, and $4/5$, all of which have information length $16384$, are also included.}\n  \\label{Fig_RequiredSNRMultiRate}\n\\end{figure}\n\n\\begin{example}\nConsider systematic BMST-R codes with information subsequence length ${K}=500$ and data block length $L=500$. The encoding memories $m$ for systematic BMST-R codes required to approach the Shannon limits at a target BER of $10^{-5}$ are determined following the procedure described in Section~\\ref{SecIV-A}. The decoding delay is specified as $d=2m$. Simulation results for systematic BMST-R codes with different rates are shown in Fig.~\\ref{Fig_BERMultiRate}. We observe that the performances for all code rates are almost the same as that for uncoded code in the relatively low SNR region. This is different from non-systematic BMST codes whose performance in the relatively low SNR region is very bad due to error propagation. We also observe that, as the SNR increases, the performance curves of the systematic BMST-R codes drop down to the respective lower bounds for all considered code rates.\n\n\nTo evaluate the bandwidth efficiency, we plot the required SNR to achieve a BER of $10^{-5}$ of the systematic BMST-R codes with information subsequence length ${K}=500$ against the code rate in Fig.~\\ref{Fig_RequiredSNRMultiRate}, where we observe that the systematic BMST-R codes achieve the BER of $10^{-5}$ within one dB from the Shannon limits for all considered code rates. In Fig.~\\ref{Fig_RequiredSNRMultiRate}, we also include the simulation results of three AR4JA LDPC codes with code rates $1/2$, $2/3$ and $4/5$ in the CCSDS standard~\\cite{CCSDS12Coding}, and five PBRL LDPC codes~\\cite{Chen15} with code rates $1/4$, $1/3$, $1/2$, $2/3$, and $4/5$, all of which have information length $16384$. We observe that the systematic BMST-R codes have a similar performance as both AR4JA LDPC codes and PBRL LDPC codes over such code rates. Note that no simulation results were reported for AR4JA LDPC codes and PBRL LDPC codes with rates less than $1/4$, while codes of all rates of interest in the interval (0,1) can be constructed using the systematic BMST-R construction. Actually, to the best of our knowledge, no other methods were reported along with simulations in the literature that can construct good rate-compatible codes over such a wide range of code rates.\n\n\n\\end{example}\n\n\\subsection{Further Discussions}\nAll the examples above assume that the subcodewords are modulated using BPSK and transmitted over an AWGN channel. In this subsection, we study the performance of systematic BMST-R codes transmitted over a block fading channel. The word-error-rate~(WER) is defined as the ratio between the number of erroneous subcodewords and the total number of subcodewords transmitted.\n\nAssume that the subcodeword $\\boldsymbol{c}^{(t)}$ is modulated using BPSK with 0 and 1 mapped to $+1$ and $-1$, respectively, and transmitted over a block fading channel, resulting in a received vector $\\boldsymbol{y}^{(t)}$ expressed as\n\n", "itemtype": "equation", "pos": 79975, "prevtext": "\nFrom Fig.~\\ref{Fig_Spectrum}, we see that the spectrum of the systematic BMST-R code ensembles with $m=1$ and $m=2$ have less number of codewords with small Hamming weights. We also see that the minimum Hamming distances of systematic BMST-R code ensembles with encoding memory $m=0$, $m=1$ and $m=2$ are 2, 3 and 4, respectively. These indicate that the systematic BMST-R codes have potentially better performance than the independent transmission system. The simulation results are shown in Fig.~\\ref{Fig_PerformanceBounds}, where we observe that\n\\begin{enumerate}\n  \\item The lower and upper bounds on the BER performance of systematic BMST-R codes are tight in the high SNR region.\n  \\item The simulated BER performance curves match well with the bounds in the high SNR region, indicating that the sliding window decoding algorithm is near optimal in the high SNR region.\n  \\item The systematic BMST-R codes outperform the independent transmission system~(i.e., the systematic BMST-R code with $m=0$). Furthermore, the systematic BMST-R code with encoding memory $m=2$ outperforms the systematic BMST-R code with $m=1$. Taking into account the rate loss, the systematic BMST-R code with $m=2$ obtains a net gain of 1.175 dB in terms of $E_b/N_0$ at a BER of $10^{-5}$, compared to the systematic BMST-R code with $m=1$.\n\\end{enumerate}\n\\end{example}\n\nGiven the tightness of the lower bound~(\\ref{EnsembleLowerBound}) as demonstrated in Example~\\ref{Example1}, we have the following simple procedure to construct good codes. Let $R \\in (0,1)$ be the target code rate and $p_{\\rm target}$ be the target BER. The object is to construct a code with rate $R_L \\approx R$, which can approach the Shannon limit at the target BER. A systematic BMST-R code has the following five parameters: repetition degree $N$, information subsequence length ${K}$, puncturing length ${K}_p$, data block length $L$, and encoding memory $m$. These parameters can be determined as follows.\n\n\n\n\n\\begin{enumerate}\n  \\item Determine the repetition degree $N$ and puncturing fraction $\\theta$ such that $\\frac{1}{N-\\theta} = R$. Choose sufficiently large information subsequence length\\footnote{By simulation, we find that ${K}\\geq 2500$ suffices to approach the Shannon limit within around half dB.} ${K}$ and puncturing length ${K}_p$ such that ${K}_p/{K} \\approx \\theta$;\n  \\item Find the Shannon limit for the given code rate $R$ and target BER $p_{\\rm target}$;\n  \\item Determine the minimum encoding memory $m$ such that the lower bound of ${\\rm BER_{MAP}}$ in~(\\ref{EnsembleLowerBound}) at the Shannon limit is not greater than the preselected target BER $p_{\\rm target}$;\n  \\item Choose a data block length $L$ such that the rate loss (i.e., $R-R_L$) due to the termination is small;\n  \\item Generate $(m+1)(N-1)$ interleavers randomly.\n\\end{enumerate}\n\nEvidently, the above procedure requires no optimization and hence can be easily implemented. The encoding memories for some systematic BMST-R codes required to approach the corresponding Shannon limits at given target BERs are shown in Table~\\ref{Table1}. As expected, the lower the target BER is, the greater the required encoding memory ${m}$ is.\n\n\\begin{table*}\n\\caption{Encoding memories for systematic BMST-R codes required to approach the corresponding Shannon limits at given target BERs}\\label{Table1}\n  \\centering\n  \\begin{tabular}{|c||c|c|c|c|}\n  \\hline\n  \n  \\multirow{2}{*}{Systematic BMST-R Codes} &\\multicolumn{4}{c|}{Encoding Memory $m$}\\\\ \\cline{2-5}\n   &${\\rm BER}=10^{-3}$ &${\\rm BER}=10^{-4}$ &${\\rm BER}=10^{-5}$ &${\\rm BER}=10^{-6}$\\\\ \\hline\n  ${\\rm Rate}~2/3$, $N=2$, $\\theta=0.5$                    &12 &18 &24 &31 \\\\\\hline\n  ${\\rm Rate}~1/2$, $N=2$, $\\theta=0$                       &8 &12 &16 &20  \\\\\\hline\n  ${\\rm Rate}~2/5$, $N=3$, $\\theta=0.5$                     &8 &11 &15 &19  \\\\\\hline\n  ${\\rm Rate}~1/3$, $N=3$, $\\theta=0$                      &7 &11 &14 &18 \\\\\\hline\n  ${\\rm Rate}~1/4$, $N=4$, $\\theta=0$                       &7 &10 &14 &17  \\\\\\hline\n\\end{tabular}\n\\end{table*}\n\n\\subsection{Impact of Parameters on BER}\nIn this subsection, we study the impact of various parameters~(e.g., encoding memory ${m}$, information subsequence length ${K}$ and decoding delay $d$) on the BER performance of systematic BMST-R codes with fixed code rate. Note that, as pointed out in~Section~\\ref{subsec:encoding}, varying repetition degree $N$ and puncturing fraction $\\theta$ results in systematic codes with different rates. For simplicity, we focus on $R_L=0.49$ systematic BMST-R codes with repetition degree $N=2$ and puncturing fraction $\\theta=0$. Three regimes are considered: (1)~fixed ${m}$ and ${K}$, increasing $d$, (2)~fixed ${m}$ and $d$, increasing ${K}$, and (3)~fixed ${K}$, increasing ${m}$~(and hence $d$).\n\n\\begin{example}[Fixed ${m}$ and ${K}$, Increasing $d$]\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ImpactParameters_DiffDelay_SNR_K.eps}\n    \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes decoded with different decoding delays $d$ in Example 2. Information subsequence length ${K}=300$, encoding memory ${m}=16$ and data block length $L=392$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding window decoding thresholds and the lower bound are also plotted.}\n    \\label{Fig_ImpactParameters_DiffDelay}\n\\end{figure}\nConsider a systematic BMST-R code with information subsequence length ${K}=300$, encoding memory ${m}=16$ and data block length $L=392$. The BER performance of the systematic BMST-R code decoded with different decoding delays $d$ is shown in Fig.~\\ref{Fig_ImpactParameters_DiffDelay}. The asymptotic threshold performance obtained by using the EXIT chart analysis method in~\\cite{Huang15JSAC} is also included. From Fig.~\\ref{Fig_ImpactParameters_DiffDelay}, we observe that\n\\begin{enumerate}\n  \\item The BER performance of the systematic BMST-R code decoded with different delays $d$ matches well with the corresponding window decoding thresholds in the high SNR region.\n  \\item The BER performance in the waterfall region improves as the decoding delay $d$ increases, but it does not improve much further beyond a certain decoding delay~(roughly $d=20$).\n  \\item The BER performance in the error floor region improves as the decoding delay $d$ increases, and it matches well with the lower bound for the systematic BMST-R code with ${m}=16$ when $d$ increases up to a certain point~(roughly $d=32$).\n\\end{enumerate}\n\n\\end{example}\n\n\n\\begin{example}[Fixed ${m}$ and $d$, Increasing ${K}$]\n\\begin{figure}[t]\n    \\center\n    \\includegraphics[clip, width={0.48\\textwidth}]{ImpactParameters_DiffCartesianProductOrder_SNR_K.eps}\n    \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes with different information subsequence lengths ${K}$ in Example 3. The codes are constructed with encoding memory ${m}=16$ and data block length $L=392$, and decoded with decoding delay $d=32$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding lower bound is also plotted.}\n    \\label{Fig_ImpactParameters_DiffCartesianProductOrder}\n\\end{figure}\nConsider systematic BMST-R codes constructed with encoding memory ${m}=16$, data block length $L=392$ and decoded with decoding delay $d=32$. The BER performance of systematic BMST-R codes constructed with different information subsequence lengths ${K}$ is shown in Fig.~\\ref{Fig_ImpactParameters_DiffCartesianProductOrder}, where we observe that\n\\begin{enumerate}\n  \\item Increasing the information subsequence length ${K}$ can improve waterfall region performance. As expected, this improvement saturates for sufficiently large ${K}$. For example, the improvement at a BER of $10^{-5}$ from ${K}=200$ to ${K}=450$, both decoded with $d=16$, is about 0.25 dB, while the improvement decreases to about 0.05 dB from ${K}=700$ to ${K}=950$.\n\n  \\item The error floors, which are determined by the encoding memory and code rate~(see Corollary~\\ref{CorollaryEnsembleLowerBound}), cannot be lowered by increasing ${K}$.\n\\end{enumerate}\n\\end{example}\n\n\n\\begin{example}[Fixed ${K}$, Increasing ${m}$~(and hence $d$)]\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{ImpactParameters_DiffMemory_2500_SNR_K.eps}\n  \\caption{Simulated decoding performance of rate $R_L=0.49$ systematic BMST-R codes constructed with different encoding memories ${m}$ and decoded with decoding delay $d=2{m}$ in Example 4. The information subsequence length of the involved systematic BMST-R codes is ${K}=2500$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding window decoding thresholds and lower bounds for systematic BMST-R codes are also plotted.}\n  \\label{Fig_ImpactParameters_DiffMemory}\n\\end{figure}\nConsider systematic BMST-R codes constructed with information subsequence length ${K}=2500$ and encoding memories ${m}=8$, $12$ and $16$. The performance with sufficiently large decoding delay $d=2{m}$ of the systematic BMST-R codes is shown in Fig.~\\ref{Fig_ImpactParameters_DiffMemory}, where we observe that\n\\begin{enumerate}\n  \\item The BER performance of systematic BMST-R codes matches well with the corresponding window decoding thresholds in the high SNR region.\n  \\item For a high target BER~(roughly above $10^{-3}$), the BER performance improves as the encoding memory ${m}$ increases, which is consistent with the threshold analysis performance. Note that this phenomenon does not exist for non-systematic BMST codes whose performance degrades slightly as ${m}$ increases~(see Section~V-C of~\\cite{Huang15JSAC}).\n  \\item The error floor can be lowered by increasing the encoding memory ${m}$~(and hence the decoding delay $d$).\n\\end{enumerate}\n\\end{example}\n\n\n\\subsection{Decoding Performance Based on Latency}\nIn addition to decoding performance, the latency introduced by employing channel coding is a crucial factor in the design of a practical communication system, such as personal wireless communication and real-time audio and video. In this subsection, we study the BER performance of systematic BMST-R codes based on their decoding latency.\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[clip,width={0.48\\textwidth}]{EqualDecodingLatency_SNR_K.eps}\n  \\caption{Required SNR to achieve a BER of $10^{-5}$ for finite-length systematic BMST-R codes, non-systematic BMST-R codes in~\\cite{Huang15JSAC}, $(3,6)$-regular SC-LDPC codes, and $(4,8)$-regular SC-LDPC codes as a function of decoding latency. All the codes have rate 0.49. The decoding delays for $(3,6)$-regular SC-LDPC codes and $(4,8)$-regular SC-LDPC codes are $5$ and $3$, respectively. The encoding memories for non-systematic BMST-R codes and systematic BMST-R codes are 8 and 16, respectively. The values of the information subsequence length and decoding delay for the non-systematic BMST-R codes are chosen such that the combination gives the best decoding performance. The decoding delays for the systematic BMST-R codes are $d=16$, $17$, $\\cdots$, $24$. The codeword is modulated using BPSK and transmitted over an AWGN channel.}\n  \\label{Fig_EqualDecodingLatency}\n\\end{figure}\n\n\\begin{example}\nWe consider rate $R_L=0.49$ systematic BMST-R codes with encoding memory ${m}=16$, repetition degree $N=2$ and puncturing fraction $\\theta=0$. The decoding latency of the sliding window decoder, in terms of bits, is given by\n\n", "index": 109, "text": "\\begin{equation}\\label{BMST_RC_latency}\n    \\tau=2{K}(d+1).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E53.m1\" class=\"ltx_Math\" alttext=\"\\tau=2{K}(d+1).\" display=\"block\"><mrow><mrow><mi>\u03c4</mi><mo>=</mo><mrow><mn>2</mn><mo>\u2062</mo><mi>K</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>d</mi><mo>+</mo><mn>1</mn></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.05193.tex", "nexttext": "\nfor $0 \\leq j \\leq {K} N-{K}_p$, where $y_{j}^{(t)}$ is the $j$-th component of $\\boldsymbol{y}^{(t)}$, $z_{j}^{(t)}$ is a sample from an independent Gaussian random variable with distribution $\\mathcal{N}(0, \\sigma^2)$, and $a_{j}^{(t)}$ is a fading coefficient.\nIn this paper, we consider a Rayleigh fading channel, where $a_{j}^{(t)}$ is a sample from a Rayleigh distribution $\\mathcal{R}$ with $\\mathbb{E}\\left[ \\mathcal{R} ^2\\right]=1$. For block fading channels with a coherence period of $B_f$ symbols, we assume that $a_{j}^{(t)}$~(perfectly known at the receiver) remains constant over $B_f$ symbols within the same period and is independent identically distributed across different coherence periods.\n\n\n\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{PBMST_Diff_m_FadingChannel_SNR.eps}\n  \\caption{Performance of $R_L=0.49$ systematic BMST-R codes with information subsequence length ${K}=100$, repetition degree $N=2$ and puncturing fraction $\\theta=0$ over a block fading channel. The encoding memories are ${m}=4,6,8,$ and $10$. The decoding delay is specified as $d=2{m}$.}\n  \\label{Fig_PBMST_Diff_m_FadingChannel}\n\\end{figure}\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{PBMST_SCLDPC_FadingChannel_SNR.eps}\n  \\caption{Performance comparison of the systematic BMST-R code and the SC-LDPC code with BPSK modulation over a block fading channel. The systematic BMST-R code is constructed with information subsequence length ${K}=100$, encoding memory ${m}=8$, repetition degree $N=2$, and puncturing fraction $\\theta=0$, and decoded with decoding delay $d=9$. The $(3,6)$-regular SC-LDPC codes is constructed with the protograph lifting factor 100 and three component submatrices $\\mathbf{B}_{0}=\\mathbf{B}_{1}=\\mathbf{B}_{2}=[1~1]$, and decoded with decoding delay $d=9$. The decoding latencies of two codes are the same.}\n  \\label{Fig_PBMST_SCLDPC_FadingChannel}\n\\end{figure}\n\n\\begin{example}\nConsider $R_L=0.49$ systematic BMST-R codes with information subsequence length ${K}=100$, repetition degree $N=2$ and puncturing fraction $\\theta=0$. The subcodewords are modulated using BPSK and transmitted over a block fading channel with a coherence period of $B_f=100$ symbols. That is, a subcodeword $\\boldsymbol{c}^{(t)}$ has $F={{K} N}/{B_f}=2$ independent fading values. The WER curves of systematic BMST-R codes constructed with encoding memory ${m}=4,6,8,$ and $10$, and decoded with decoding delay $d=2{m}$ are shown in Fig.~\\ref{Fig_PBMST_Diff_m_FadingChannel}, where we observe that the performance of systematic BMST-R code improves with increasing encoding memory ${m}$ until ${m}=8$ and then it degrades slightly as ${m}$ increases further. This implies that ${m}=8$ is a good choice for optimum performance.\n\nThe performance comparison\\footnote{The simulation results~(not included in the figure) suggest that non-systematic BMST codes suffer from severe performance degradation caused by the error propagation.} of the systematic BMST-R code and the SC-LDPC code over a block fading channel is shown in Fig.~\\ref{Fig_PBMST_SCLDPC_FadingChannel}. The systematic BMST-R code is constructed with information subsequence length ${K}=100$, encoding memory ${m}=8$, repetition degree $N=2$, and puncturing fraction $\\theta=0$, and decoded with decoding delay $d=9$. The $(3,6)$-regular SC-LDPC code is constructed with the protograph lifting factor 100 and three component submatrices $\\mathbf{B}_{0}=\\mathbf{B}_{1}=\\mathbf{B}_{2}=[1~1]$, and decoded with decoding delay $d=9$ presented in~\\cite{Hassan14ISIT}. Thus, the decoding latencies of two codes are the same. We see from Fig.~\\ref{Fig_PBMST_SCLDPC_FadingChannel} that, in the low WER region, the systematic BMST-R code performs better than the $(3,6)$-regular SC-LDPC code under the equal decoding latency constraint. For example, at a WER of $10^{-4}$, the systematic BMST-R code gains about one dB compared to the equal latency $(3,6)$-regular SC-LDPC code. These results confirm that systematic BMST-R codes without any further optimization can perform well over block fading channels.\n\n\\end{example}\n\n\\section{Conclusions}\\label{sec:Conclusion}\nIn this paper, we have proposed systematic block Markov superposition transmission~(BMST) of repetition codes, referred to as systematic BMST-R codes. Using both extending and puncturing, systematic BMST-R codes support a wide range of code rates but maintain essentially the same encoding/decoding hardware structure. The systematic BMST-R codes not only preserve the advantages of the original non-systematic BMST codes, namely, low encoding complexity, effective sliding window decoding algorithm and predictable error floors, but also have improved decoding performance especially in short-to-moderate decoding latency. A simple lower bound and an upper bound were derived to analyze the performance of systematic BMST-R codes under MAP decoding. Simulation results show that, over an AWGN channel, 1)~the performance of systematic BMST-R codes around or below the BER of $10^{-5}$ can be predicted by the lower bound; 2)~systematic BMST-R codes can approach the Shannon limit at a BER of $10^{-5}$ within one dB for a wide range of code rates; and 3)~systematic BMST-R codes can outperform both non-systematic BMST codes and SC-LDPC codes in the waterfall region under the equal decoding latency constraint. Simulation results also show that, systematic BMST-R codes without any further optimization can outperform $(3,6)$-regular SC-LDPC codes over a block fading channel. A final note is that the construction of systematic BMST-R codes can be extended to high-order Abelian groups since only addition is required during the encoding process.\n\n\n\n\n\n\n\\section*{Acknowledgment}\nThe authors would like to thank Prof. Costello from University of Notre Dame for his helpful comments on the performance lower bounds. The second author, ever visiting University of Notre Dame for one year as an exchange student, is also grateful to Prof. Costello for his insightful supervision on the related research. The authors would also like to thank Dr. Chulong Liang and Dr. Jia Liu for helpful discussions.\n\n\n\n\n\n\\ifCLASSOPTIONcaptionsoff\n  \\newpage\n\\fi\n\\bibliographystyle{IEEEtran}\n\n\n\\begin{thebibliography}{10}\n\\providecommand{\\url}[1]{#1}\n\\csname url@samestyle\\endcsname\n\\providecommand{\\newblock}{\\relax}\n\\providecommand{\\bibinfo}[2]{#2}\n\\providecommand{\\BIBentrySTDinterwordspacing}{\\spaceskip=0pt\\relax}\n\\providecommand{\\BIBentryALTinterwordstretchfactor}{4}\n\\providecommand{\\BIBentryALTinterwordspacing}{\\spaceskip=\\fontdimen2\\font plus\n\\BIBentryALTinterwordstretchfactor\\fontdimen3\\font minus\n  \\fontdimen4\\font\\relax}\n\\providecommand{\\BIBforeignlanguage}[2]{{\n\\expandafter\\ifx\\csname l@#1\\endcsname\\relax\n\\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}\n\\typeout{** loaded for the language `#1'. Using the pattern for}\n\\typeout{** the default language instead.}\n\\else\n\\language=\\csname l@#1\\endcsname\n\\fi\n#2}}\n\\providecommand{\\BIBdecl}{\\relax}\n\\BIBdecl\n\n\\bibitem{Berrou93}\nC.~Berrou, A.~Glavieux, and P.~Thitimajshima, ``{Near Shannon limit\n  error-correcting coding and decoding: Turbo codes},'' in \\emph{Proc. Int.\n  Conf. Commun.}, Geneva, Switzerland, May 1993, pp. 1064--1070.\n\n\\bibitem{Gallager63}\nR.~G. Gallager, \\emph{{Low-Density Parity-Check Codes}}.\\hskip 1em plus 0.5em\n  minus 0.4em\\relax Cambridge, MA: MIT Press, 1963.\n\n\\bibitem{Arikan09}\nE.~Arikan, ``{Channel polarization: A method for constructing\n  capacity-achieving codes for symmetric binary-input memoryless channels},''\n  \\emph{IEEE Trans. Inf. Theory}, vol.~55, pp. 3051--3073, July 2009.\n\n\\bibitem{Felstrom99}\nA.~J. Felstr\\\"{o}m and K.~S. Zigangirov, ``{Time-varying periodic convolutional\n  codes with low-density parity-check matrix},'' \\emph{IEEE Trans. Inf.\n  Theory}, vol.~45, no.~6, pp. 2181--2191, Sept. 1999.\n\n\\bibitem{Kudekar11}\nS.~Kudekar, T.~J. Richardson, and R.~L. Urbanke, ``{Threshold saturation via\n  spatial coupling: Why convolutional LDPC ensembles perform so well over the\n  BEC},'' \\emph{IEEE Trans.~Inf.~Theory}, vol.~57, no.~4, pp. 803--834, Feb.\n  2011.\n\n\\bibitem{Lentmaier10}\nM.~Lentmaier, A.~Sridharan, D.~J. Costello, Jr., and K.~S. Zigangirov,\n  ``{Iterative decoding threshold analysis for LDPC convolutional codes},''\n  \\emph{IEEE Trans. Inf. Theory}, vol.~56, no.~10, pp. 5274--5289, Oct. 2010.\n\n\\bibitem{Kudekar13}\nS.~Kudekar, T.~J. Richardson, and R.~L. Urbanke, ``{Spatially coupled ensembles\n  universally achieve capacity under belief propagation},'' \\emph{IEEE\n  Trans.~Inf.~Theory}, vol.~59, no.~12, pp. 7761--7813, Dec. 2013.\n\n\\bibitem{Hagenauer88}\nJ.~Hagenauer, ``Rate-compatible punctured convolutional codes~({RCPC} codes)\n  and their application,'' \\emph{IEEE Trans.~Commun.}, vol.~36, pp. 389--400,\n  Apr. 1988.\n\n\\bibitem{Acikel99}\nO.~Acikel and W.~Ryan, ``Punctured turbo-codes for {BPSK/QPSK} channels,''\n  \\emph{IEEE Trans. Commun.}, vol.~47, no.~9, pp. 1315--1323, Sept. 1999.\n\n\\bibitem{Rowitch00}\nD.~Rowitch and L.~Milstein, ``{On the performance of hybrid FEC/ARQ systems\n  using rate compatible punctured turbo (RCPT) codes},'' \\emph{IEEE\n  Trans.~Commun.}, vol.~48, no.~6, pp. 948--959, Jun 2000.\n\n\\bibitem{Ha04}\nJ.~Ha, J.~Kim, and S.~McLaughlin, ``Rate-compatible puncturing of low-density\n  parity-check codes,'' \\emph{IEEE Trans. Inf. Theory}, vol.~50, no.~11, pp.\n  2824--2836, Nov. 2004.\n\n\\bibitem{Nik07}\nH.~Pishro-Nik and F.~Fekri, ``Results on punctured low-density parity-check\n  codes and improved iterative decoding techniques,'' \\emph{IEEE Trans. Inf.\n  Theory}, vol.~53, no.~2, pp. 599--614, Feb. 2007.\n\n\\bibitem{Yazdani04}\nM.~Yazdani and A.~Banihashemi, ``On construction of rate-compatible low-density\n  parity-check codes,'' \\emph{IEEE Commun. Lett.}, vol.~8, no.~3, pp. 159--161,\n  Mar. 2004.\n\n\\bibitem{Khamy09}\nM.~El-Khamy, J.~Hou, and N.~Bhushan, ``{Design of rate-compatible structured\n  LDPC codes for hybrid ARQ applications},'' \\emph{IEEE J. Sel. Areas Commun.},\n  vol.~27, no.~6, pp. 965--973, Aug. 2009.\n\n\\bibitem{NguyenTV12}\nT.~Nguyen, A.~Nosratinia, and D.~Divsalar, ``The design of rate-compatible\n  protograph {LDPC} codes,'' \\emph{IEEE Trans. Commun.}, vol.~60, no.~10, pp.\n  2841--2850, Oct. 2012.\n\n\\bibitem{NguyenTV13}\nT.~Nguyen and A.~Nosratinia, ``{Rate-compatible short-length protograph LDPC\n  codes},'' \\emph{IEEE Commun. Lett.}, vol.~17, no.~5, pp. 948--951, May 2013.\n\n\\bibitem{Chen15}\nT.-Y. Chen, K.~Vakilinia, D.~Divsalar, and R.~Wesel, ``Protograph-based\n  raptor-like {LDPC} codes,'' \\emph{IEEE Trans. Commun.}, vol.~63, no.~5, pp.\n  1522--1532, May 2015.\n\n\\bibitem{Mitchell_16JSAC}\nD.~G.~M. Mitchell, M.~Lentmaier, A.~E. Pusane, and D.~J. Costello, Jr.,\n  ``{Randomly punctured LDPC codes},'' \\emph{IEEE J. Sel. Areas Commun.},\n  vol.~34, no.~2, pp. 408--421, Feb. 2016.\n\n\\bibitem{Ma15}\nX.~Ma, C.~Liang, K.~Huang, and Q.~Zhuang, ``{Block Markov superposition\n  transmission: Construction of big convolutional codes from short codes},''\n  \\emph{IEEE Trans. Inf. Theory}, vol.~61, no.~6, pp. 3150--3163, June 2015.\n\n\\bibitem{Huang15JSAC}\nK.~Huang and X.~Ma, ``{Performance analysis of block Markov superposition\n  transmission of short codes},'' \\emph{IEEE J. Sel. Areas Commun.}, vol.~34,\n  no.~2, pp. 362--374, Feb. 2016.\n\n\\bibitem{Liang15}\nC.~Liang, J.~Hu, X.~Ma, and B.~Bai, ``{A new class of multiple-rate codes based\n  on block Markov superposition transmission},'' \\emph{IEEE Trans. Signal\n  Process.}, vol.~63, no.~16, pp. 4236--4244, Aug. 2015.\n\n\\bibitem{Hu14a}\nJ.~Hu, X.~Ma, and C.~Liang, ``{Block Markov superposition transmission of\n  repetition and single-parity-check codes},'' \\emph{IEEE Commun. Lett.},\n  vol.~19, no.~2, pp. 131--134, Feb. 2015.\n\n\\bibitem{Iyengar12}\nA.~R. Iyengar, M.~Papaleo, P.~H. Siegel, J.~K. Wolf, A.~Vanelli-Coralli, and\n  G.~E. Corazza, ``{Windowed decoding of protograph-based LDPC convolutional\n  codes over erasure channels},'' \\emph{IEEE Trans. Inf. Theory}, vol.~58,\n  no.~4, pp. 2303--2320, Apr. 2012.\n\n\\bibitem{Forney01}\nG.~D. Forney, Jr., ``{Codes on graphs: Normal realizations},'' \\emph{IEEE\n  Trans.~Inf.~Theory}, vol.~47, no.~2, pp. 520--548, Feb. 2001.\n\n\\bibitem{Forney73}\n------, ``{The Viterbi algorithm},'' \\emph{Proceedings of the IEEE}, vol.~61,\n  no.~3, pp. 268--278, Mar. 1973.\n\n\\bibitem{Pusane08}\nA.~E. Pusane, A.~J. Felstr\\\"{o}m, A.~Sridharan, M.~Lentmaier, K.~S. Zigangirov,\n  and D.~J. Costello, Jr., ``{Implementation aspects of LDPC convolutional\n  codes},'' \\emph{IEEE Trans.~Commun.}, vol.~56, no.~7, pp. 1060--1069, July\n  2008.\n\n\\bibitem{Aref12}\nV.~Aref, N.~Macris, R.~Urbanke, and M.~Vuffray, ``{Lossy source coding via\n  spatially coupled LDGM ensembles},'' in \\emph{Proc. IEEE Int. Symp. on Inf.\n  Theory}, Cambridge, MA, July 2012, pp. 373--377.\n\n\\bibitem{Kumar_IT14}\nS.~Kumar, A.~J. Young, N.~Macris, and H.~D. Pfister, ``{Threshold saturation\n  for spatially coupled LDPC and LDGM codes on BMS channels},'' \\emph{IEEE\n  Trans.~Inf.~Theory}, vol.~60, no.~12, pp. 7389--7415, Dec. 2014.\n\n\\bibitem{Benedetto96}\nS.~Benedetto and G.~Montorsi, ``{Unveiling turbo codes: Some results on\n  parallel concatenated coding schemes},'' \\emph{IEEE Trans. Inf. Theory},\n  vol.~42, no.~2, pp. 409--428, Mar. 1996.\n\n\\bibitem{Ma13Bound}\nX.~Ma, J.~Liu, and B.~Bai, ``{New techniques for upper-bounding the ML decoding\n  performance of binary linear codes},'' \\emph{IEEE Trans.~Commun.}, vol.~61,\n  no.~3, pp. 842--851, Mar. 2013.\n\n\\bibitem{Seguin98}\nG.~Seguin, ``{A lower bound on the error probability for signals in white\n  Gaussian noise},'' \\emph{IEEE Trans.~Inf.~Theory}, vol.~44, no.~7, pp.\n  3168--3175, Nov. 1998.\n\n\\bibitem{Cohen04}\nA.~Cohen and N.~Merhav, ``{Lower bounds on the error probability of block codes\n  based on improvements on de Caen's inequality},'' \\emph{IEEE Trans. Inf.\n  Theory}, vol.~50, no.~2, pp. 290--310, Feb. 2004.\n\n\\bibitem{Sason06}\nI.~Sason and S.~Shamai, ``{Performance analysis of linear codes under\n  maximum-likelihood decoding: A tutorial},'' in \\emph{Foundations and Trends\n  in Communications and Information Theory}, vol.~3, no. 1-2.\\hskip 1em plus\n  0.5em minus 0.4em\\relax Delft, The Netherlands: NOW, 2006, pp. 1--225.\n\n\\bibitem{Behnamfar07}\nF.~Behnamfar, F.~Alajaji, and T.~Linder, ``{An efficient algorithmic lower\n  bound for the error rate of linear block codes},'' \\emph{IEEE\n  Trans.~Commun.}, vol.~55, no.~6, pp. 1093--1098, June 2007.\n\n\\bibitem{Ma03}\nX.~Ma and A.~Kav\\v{c}i\\'c, ``Path partition and forward-only trellis\n  algorithms,'' \\emph{IEEE Trans. Inf. Theory}, vol.~49, no.~1, pp. 38--52,\n  Jan. 2003.\n\n\\bibitem{Ma04}\nX.~Ma and L.~Ping, ``Coded modulation using superimposed binary codes,''\n  \\emph{IEEE Trans. Inf. Theory}, vol.~50, no.~12, pp. 3331--3343, Dec. 2004.\n\n\\bibitem{Huang14}\nK.~Huang, D.~G.~M. Mitchell, L.~Wei, X.~Ma, and D.~J. Costello, Jr.,\n  ``{Performance comparison of LDPC block and spatially coupled codes over\n  GF$(q)$},'' \\emph{IEEE Trans.~Commun.}, vol.~63, no.~3, pp. 592--604, Mar.\n  2015.\n\n\\bibitem{CCSDS12Coding}\n\\BIBentryALTinterwordspacing\n\\emph{{TM Synchronization and Channel Coding--Summary of Concept and\n  Rationale}}, Consultative Committee for Space Data Systems~(CCSDS) Std., Nov.\n  2012. [Online]. Available:\n  \\url{http://public.ccsds.org/publications/archive/130x1g2.pdf}\n\\BIBentrySTDinterwordspacing\n\n\\bibitem{Hassan14ISIT}\nN.~ul~Hassan, M.~Lentmaier, I.~Andriyanova, and G.~P. Fettweis, ``{Improving\n  code diversity on block-fading channels by spatial coupling},'' in\n  \\emph{Proc. IEEE Int. Symp. on Inf. Theory}, Honolulu, HI, June 2014, pp.\n  2311--2315.\n\n\\end{thebibliography}\n\n\n\n\n", "itemtype": "equation", "pos": 87267, "prevtext": "\nThe SNR required to achieve a BER of $10^{-5}$ as a function of decoding latency is shown in Fig.~\\ref{Fig_EqualDecodingLatency}. We observe that the performance of systematic BMST-R codes~(with fixed information subsequence length ${K}$) improves as the decoding delay $d$~(and hence the latency) increases, but it does not improve much further beyond a certain decoding delay. Moreover, beyond a certain latency, using a greater information subsequence length ${K}$ with a smaller decoding delay $d$ gives better performance. For example, the systematic BMST-R code constructed with a greater information subsequence length ${K}=300$ and decoded with a smaller decoding delay $d=19$ outperforms the systematic BMST-R code constructed with a small information subsequence length ${K}=250$ and decoded with a greater decoding delay $d=23$~(both have the same decoding latency of 12000 bits).\n\nWe also compare the performance of systematic BMST-R codes, non-systematic BMST-R codes in~\\cite{Huang15JSAC}, and SC-LDPC codes when the decoding latencies are equal, as shown in Fig.~\\ref{Fig_EqualDecodingLatency}. All the codes have rate 0.49. We restrict consideration to $(3,6)$-regular SC-LDPC codes with two component submatrices $\\mathbf{B}_{0}=[2~1]$ and $\\mathbf{B}_{1}=[1~2]$, and $(4,8)$-regular SC-LDPC codes with two component submatrices $\\mathbf{B}_{0}=[3~1]$ and $\\mathbf{B}_{1}=[1~3]$. The decoding delays for $(3,6)$-regular SC-LDPC codes and $(4,8)$-regular SC-LDPC codes are $5$ and $3$, respectively, which are good choices to achieve optimum performance when the decoding latencies are fixed.\\footnote{For a more in-depth discussion of the relationship between the protograph lifting factor, the decoding window size and the decoding performance of SC-LDPC codes when the decoding latency is fixed, we refer the reader to~\\cite{Huang14}.} The encoding memories for non-systematic BMST-R codes and systematic BMST-R codes are 8 and 16, respectively. The values of the information subsequence length and decoding delay for the non-systematic BMST-R codes are chosen such that the combination gives the best decoding performance~(see Section~VI-A of~\\cite{Huang15JSAC}). The decoding delays for the systematic BMST-R codes are $d=16$, $17$, $\\cdots$, $24$. We observe that the systematic BMST-R codes perform better than both the non-systematic BMST-R codes and the SC-LDPC codes. For example, in the decoding latency of 12000 bits, the systematic BMST-R code with information subsequence length ${K}=300$ and decoding delay $d=19$ gains 0.12 dB, 0.21 dB and 0.24 dB, respectively, compared to the non-systematic BMST-R code, $(3,6)$-regular SC-LDPC code, and $(4,8)$-regular SC-LDPC code.\n\n\\end{example}\n\n\n\\subsection{Rate-Compatible Property}\nIn this subsection, we show the performance of systematic BMST-R codes with different rates by varying repetition degree $N$ and puncturing fraction $\\theta$.\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{BERMultiRate.eps}\n  \\caption{Simulated decoding performance of systematic BMST-R codes with information subsequence length ${K}=500$ and data block length $L=500$. The repetition degree $N$, encoding memories $m$ and puncturing fraction $\\theta$ are specified in the legends. The decoding delay is specified as $d=2m$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The corresponding lower bounds~(dotted magenta) for systematic BMST-R codes are also plotted. The rates of the systematic BMST-R codes corresponding to the BER curves from left to right in the figure are $0.1631,0.1959,0.2449, 0.2801, 0.3272, 0.3929, 0.4921, 0.5623, 0.6562,$ and $0.7874$.}\n  \\label{Fig_BERMultiRate}\n\\end{figure}\n\n\\begin{figure}[t]\n  \\centering\n  \\includegraphics[width={0.48\\textwidth}]{RequiredSNRMultiRate_K.eps}\n  \\caption{Required SNR to achieve a BER of $10^{-5}$ for systematic BMST-R codes with information subsequence length ${K}=500$. The codeword is modulated using BPSK and transmitted over an AWGN channel. The performances of three AR4JA LDPC codes with code rates $1/2$, $2/3$ and $4/5$ in the CCSDS standard~\\cite{CCSDS12Coding}, and five PBRL LDPC codes~\\cite{Chen15} with code rates $1/4$, $1/3$, $1/2$, $2/3$, and $4/5$, all of which have information length $16384$, are also included.}\n  \\label{Fig_RequiredSNRMultiRate}\n\\end{figure}\n\n\\begin{example}\nConsider systematic BMST-R codes with information subsequence length ${K}=500$ and data block length $L=500$. The encoding memories $m$ for systematic BMST-R codes required to approach the Shannon limits at a target BER of $10^{-5}$ are determined following the procedure described in Section~\\ref{SecIV-A}. The decoding delay is specified as $d=2m$. Simulation results for systematic BMST-R codes with different rates are shown in Fig.~\\ref{Fig_BERMultiRate}. We observe that the performances for all code rates are almost the same as that for uncoded code in the relatively low SNR region. This is different from non-systematic BMST codes whose performance in the relatively low SNR region is very bad due to error propagation. We also observe that, as the SNR increases, the performance curves of the systematic BMST-R codes drop down to the respective lower bounds for all considered code rates.\n\n\nTo evaluate the bandwidth efficiency, we plot the required SNR to achieve a BER of $10^{-5}$ of the systematic BMST-R codes with information subsequence length ${K}=500$ against the code rate in Fig.~\\ref{Fig_RequiredSNRMultiRate}, where we observe that the systematic BMST-R codes achieve the BER of $10^{-5}$ within one dB from the Shannon limits for all considered code rates. In Fig.~\\ref{Fig_RequiredSNRMultiRate}, we also include the simulation results of three AR4JA LDPC codes with code rates $1/2$, $2/3$ and $4/5$ in the CCSDS standard~\\cite{CCSDS12Coding}, and five PBRL LDPC codes~\\cite{Chen15} with code rates $1/4$, $1/3$, $1/2$, $2/3$, and $4/5$, all of which have information length $16384$. We observe that the systematic BMST-R codes have a similar performance as both AR4JA LDPC codes and PBRL LDPC codes over such code rates. Note that no simulation results were reported for AR4JA LDPC codes and PBRL LDPC codes with rates less than $1/4$, while codes of all rates of interest in the interval (0,1) can be constructed using the systematic BMST-R construction. Actually, to the best of our knowledge, no other methods were reported along with simulations in the literature that can construct good rate-compatible codes over such a wide range of code rates.\n\n\n\\end{example}\n\n\\subsection{Further Discussions}\nAll the examples above assume that the subcodewords are modulated using BPSK and transmitted over an AWGN channel. In this subsection, we study the performance of systematic BMST-R codes transmitted over a block fading channel. The word-error-rate~(WER) is defined as the ratio between the number of erroneous subcodewords and the total number of subcodewords transmitted.\n\nAssume that the subcodeword $\\boldsymbol{c}^{(t)}$ is modulated using BPSK with 0 and 1 mapped to $+1$ and $-1$, respectively, and transmitted over a block fading channel, resulting in a received vector $\\boldsymbol{y}^{(t)}$ expressed as\n\n", "index": 111, "text": "\\begin{equation}\\label{TwoChannels}\n  y_{j}^{(t)} = a_{j}^{(t)}c_{j}^{(t)} + z_{j}^{(t)}\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E54.m1\" class=\"ltx_Math\" alttext=\"y_{j}^{(t)}=a_{j}^{(t)}c_{j}^{(t)}+z_{j}^{(t)}\" display=\"block\"><mrow><msubsup><mi>y</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mrow><mrow><msubsup><mi>a</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>\u2062</mo><msubsup><mi>c</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow><mo>+</mo><msubsup><mi>z</mi><mi>j</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></mrow></mrow></math>", "type": "latex"}]