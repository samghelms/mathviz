[{"file": "1601.08197.tex", "nexttext": "\n\nIntuitively, $Q_{\\mathbf{X}_{1}}^2$ represents the proportion of the variation of the response $\\mathbf{y}$ that is expected to be explained by $f(\\mathbf{X}_{1})$ in new individuals , re-scaled by the total amount of prediction variation in the response $\\mathbf{y}$. In the worst case scenario, when $\\mathbf{p}_{1}=\\mathbf{p}_{0}$ ($\\mathbf{X}_{1}$ as predictive as a null model based on the mean of $\\mathbf{y}$) $Q_{\\mathbf{X}_{1}}^2=0$ and $Q_{\\mathbf{X}_{1}}^2=1$ if $\\mathbf{p}_{1}=\\mathbf{y}$. Since the computation of $p_{1j}$, $j\\in S^{(j)}$ for each of the $j=1,\\ldots,J$ random splits of the sample $S$ is based on the observations not belonging to $S^{(j)}$, we proceed in an analogous way to compute the average predicted variation of $\\mathbf{y}$. Hence, in order to get an appropriate re-scaling factor, for each subset $S^{(j)}$, we compute $\\bar{y}^{(-j)}$, the mean value of the outcome variable $\\mathbf{y}$ calculated without the observations belonging to $S^{(j)}$. \n\nThe contribution of the second omic source, $\\mathbf{X}_{2}$, in the prediction of $\\mathbf{y}$ can be summarized by \n\n\n", "itemtype": "equation", "pos": 16930, "prevtext": "\n\\begin{center}{\n\\textbf{\\Large Sequential double cross-validation for augmented prediction assessment in high-dimensional omic applications}\\\\\n}\n\\end{center}\n\nMar Rodr\\'{i}guez-Girondo$^{1}$, Perttu Salo$^{2}$, Tomasz Burzykowski$^{3}$, Markus Perola$^{2}$, Jeanine Houwing-Duistermaat$^{1,4}$ and Bart Mertens$^{1}$\n\\bigskip\n\n\\noindent\n$^{1}$Department of Medical Statistics and Bioinformatics, Leiden University Medical Center, Leiden, The Netherlands.\n\n\\noindent\n$^{2}$National Institute For Health and Welfare, Helsinki, Finland.\n\n\\noindent\n$^{3}$Interuniversity Institute for Biostatistics and statistical Bioinformatics (I-BioStat), Hasselt University, Hasselt, Belgium.\n\n\\noindent\n$^{4}$Department of Statistics, Leeds University, Leeds, United Kingdom.\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\\begin{abstract}\nAugmentation of previously established high-dimensional predictive models with new biomolecular markers is an important task in omic applications. We introduce a two-step procedure for the assessment of the augmented predictive value of omic predictors, based on sequential double cross-validation and regularized regression models. We propose several performance indices to summarize the two-stage prediction procedure and a permutation test to formally assess the augmented predictive value of a second omic set of predictors over a primary omic source. The performance of the test is investigated through simulations. We illustrate the new method through the systematic assessment and comparison of the performance of transcriptomics and metabolomics sources in the prediction of body mass index (BMI) using data from the Dietary, Lifestyle, and Genetic determinants of Obesity and Metabolic syndrome (DILGOM) study, a population-based cohort, from Finland.\n\\end{abstract}\n\n\n{\\bf Keywords:} {\\it Augmented prediction; double cross-validation; regularized regression}\n\n\n\n\n\n\\section{Introduction\\label{section intro}}\nDuring the past decade, much attention has been devoted to accommodate single high-dimensional sources of molecular data (omics) in the calibration of prediction models for health traits. Genomic, transcriptomics and proteomics data have been established as widely used omic predictors of health outcomes, alone or in combination with (low-dimensional) clinical covariates \\cite{preval1, preval2}. Nowadays, novel omic measures, such as metabolomics \\cite{Inouye1} and glycomics \\cite{Zoldos}, among others, are emerging as powerful new biomolecular marker sets with the potential to substantively enhance the predictive capacity of existing markers.  As a result, it is increasingly common for studies to collect a range of  omic measurements in the same set of individuals, possibly using different measurement platforms and covering different aspects of human biology. This causes new statistical challenges to emerge, among which  the augmentation of prediction models based on previously established omic sources with novel biomolecular predictive measures, and the quantification of their additional predictive value. The assessment of such augmented value would clearly arise in situations where, due to economical or technical reasons, one is interested in explicitly imposing a hierarchical structure between the different sets of available predictors. An example is the addition of more expensive and/or less reliable predictors to potentially improve the performance of a prediction rule based on more economic and/or stable sources. The assessment of augmented value of a novel biomarker set would however also arise when the hierarchy is implicitly assumed in a scientific research field,  when a new molecular marker set emerges due to (technical) advances in the field or evolving biological knowledge, and must prove its worth in the face of existing knowledge on the predictive capacity of an established biomarker set. \n\n\n\nWe can identify different inferential scenarios which could all be addressed under the common label of `augmentation of predictive models'. For example, we could investigate the augmentation of the Framingham risk score or some published transcriptomics-based score with metabolome measurements for the prediction of the occurrence of myocardial infarction. We refer to such situations as {\\it external augmentation}, when the  primary predictor is provided and based on model fitting in a prior experiment's data (possibly made available through published papers). In such situations,  the novel experimental data,  containing the new marker set of interest for which we want to assess the augmented value with respect to the established marker set, is not used for calibration purposes,  but only for evaluation of the additional predictive value relative to the externally developed prediction model score. In this work, we focus on a more challenging situation. We consider {\\it internal augmentation } of predictive models, where we must both calibrate the predictive model based on the primary source of omic predictors and assess the added predictive value of a secondary one relative to the first set, {\\it using the same set of observations}. In this situation, the assessment of the impact of the data augmentation in a predictive sense will depend on the prior calibration on the first source and must be accounted for. To provide realistic estimates of the predictive ability of the secondary source, it is of great importance to control for the re-use of the data, which has already been employed for the development of a predictive model based on the first source of predictors within the same observations. Similar problems have previously been recognized in the context of parallel combination of distinct predictors derived from  different calibration models and can be solved by appropriate  use of cross-validation techniques \\cite{Leblanc, superlearner, Alexia}, among others.\n\n\nInternal sequential augmentation with omic sources involves a number of  extra difficulties. Omic sets of predictors are typically high-dimensional ($n<p$, $n$ sample size and $p$ the number of predictors), and correlation between features is typically high. Furthermore, several potential predictor sets measured on the same subjects may share (part of) the underlying biological information, which thus introduces correlation between the distinct omic sources. \nAn illustrative example of these new methodological challenges is given by our motivating data. We consider data from a population-based cohort, the Dietary, Lifestyle, and Genetic determinants of\nObesity and Metabolic syndrome (DILGOM) study, sampled from the Helsinki area, in Finland \\cite{Inouye1}. Serum metabolites, genome-wide profiles of genetic and transcriptional variation from blood leukocytes were measured, together with a large number of clinical and demographic factors. Our goal is to develop statistical methodology which can aid decision making in the comparison of different available omic sources in terms of their predictive ability, with special focus on assessing the gain in situations in which a secondary omic source is added to a primary omic predictor. To focus our discussion,  we consider a systematic assessment and comparison of the  performance of transcriptomics and metabolomics sources in the prediction of the body mass index (BMI) and to establish their additional predictive value with respect to each other. Naturally the same approach could be used to tackle any outcome requiring seriously invasive measurements, such as intracranial pressure or cerebrospinal fluid glucose concentration. \n\n\n\nThe reminder of the paper is organized as follows: in Section 2, we introduce a two-step procedure for the asessment of added value of predictors, based on sequential double cross-validation prediction and regularized regression models.  \n\nWe propose several performance indices to summarize the two-stage prediction procedure and a permutation test to formally assess the augmented predictive value of a second omic set of predictors over a primary omic source. \n\nAn intensive simulation study is presented in Section 3. In Section 4 we apply our methods to DILGOM data and we conclude in Section 5 with a summary and discussion.\n\\section{Methods}\n\\subsection{Sequential double cross-validation prediction}\nLet the observed data be given by $(\\mathbf{y},\\mathbf{X}_{1},\\mathbf{X}_{2})$, where $\\mathbf{y}=(y_{1},\\ldots,y_{n})^{\\intercal}$ is the continuous outcome measured in $n$ independent individuals and $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ are two matrices of dimension $n\\times p$ and  $n \\times q$, respectively, representing two omic predictor sources with $p$ and $q$ features. We assume that we are in a high-dimensional setting ($p,q>n$) and that the main goal is to evaluate the augmented or added value of $\\mathbf{X}_2$ beyond $\\mathbf{X}_1$ in order to predict $\\mathbf{y}$ in new observations. \n\nWe propose a two-step  procedure based  on the replacement of the original (high-dimensional) sources of predictors by their corresponding estimated values of $\\mathbf{y}$ based on single-source-specific prediction models. In the first step, the  double cross-validated predictions of $\\mathbf{y}$ based on $\\mathbf{X}_{1}$ and a given model specification $f$, $\\mathbf{p}_{1}=f(\\mathbf{X}_{1})=(p_{11},\\ldots,p_{1n})^{\\intercal}$ are estimated. Then, for each individual $i$, we take the deletion residual $res_{i}=y_{i}-p_{1i}$, we consider $\\mathbf{res}=(res_{1},\\ldots,res_{n})^{\\intercal}$ as new response and construct a second prediction model based on $\\mathbf{X}_2$ as predictor source.\n\nTwo crucial difficulties in high-dimensional prediction problems are the control of the optimal level of shrinkage (or in general, any tuning parameter $\\lambda$ associated with the statistical model $f$ used to obtain estimates of $\\mathbf{y}$ based on a single high-dimensional source of predictors) and the quantification of the error of the resulting predictions in new data. To reduce the risk of overfitting in $n<p$ situations, cross-validation procedures \\cite{Stone} have  become very popular to determine the optimal level of complexity of a prediction model (given by $\\lambda$). A more subtle danger arises when computing the predicted values in the original sample based on the resulting predictive rule. Error measurements based on such `simple' or `one-deep' cross-validation will, in general, be (optimistically) biased \\cite{Jonathan,Varma} and, hence, downstream analyses based on such predictions may lead to incorrect inferences. This issue is of crucial importance in our setting, given the internal nature of the augmentation procedure. The use of $\\mathbf{res}=\\mathbf{y}-\\mathbf{p}_{1}$ as outcome for the calibration of a second prediction model based on $\\mathbf{X}_2$ is  an example of downstream analyses of the first fit (used to obtain $\\mathbf{p}_{1}$). This has motivated extensions of the single cross-validatory analysis, such  as double cross-validation algorithms \\cite{Stone, Breiman, Jonathan, Mertens0, Mertens1, Mertens2}, consisting of two (or more) nested loops. In the inner loop a cross-validated grid-selection is used to determine the optimal prediction rule, i.e., for model selection, while the outer loop  is used to estimate the prediction performance by application of models developed in the inner loop part of the data (training sets) to the remaining unused data (validation sets). In this manner, double cross-validation is capable of jointly calibrating and assessing models in a predictive sense,  while also avoiding the bias in estimates of predictive ability which would result from use of a single-cross-validatory approach only. In our setting, the outer loop of a `double' cross-validatory calculation allows us to obtain `predictive'-deletion residuals which fully account for the inherent uncertainty of model fitting on the primary source ($\\mathbf{X}_{1}$),  before assessing the augmented predictive value from adding the new set of measurements $\\mathbf{X}_{2}$ for prediction. The basic structure of the two-step procedure is as follows:\n\n\\begin{description}\n\\item[Step 1]\nObtain  double cross-validation predictions of $\\mathbf{y}$, $\\mathbf{p}_{1}=(p_{11},\\ldots,p_{1n})$, based on $\\mathbf{X_{1}}$:\n\\begin{description}\n\\item[] {\\bf Outer CV loop}\n\\begin{description}\n\\item[-] Randomly split the sample $S$ in $J$ mutually exclusive and exhaustive sub-samples of approximately equal size $S^{(1)},\\ldots, S^{(J)}$\n\\item[-] For each $j=1,\\ldots,J$, merge $J-1$ subsamples into $S^{(-j)}=S-S^{(j)}$\n\\item[] {\\bf Inner CV loop}\n\\begin{description}\n\\item[-] Randomly split the sample  $S^{(-j)}$ in $K$ sub-samples $(S^{(-j)})^{(1)},\\ldots,(S^{(-j)})^{(K)}$\n\\item[-] For each $k=1,\\ldots,K$, merge $K-1$ subsubsamples into $(S^{(-j)})^{(-k)}=S^{(-j)}-(S^{(-j)})^{(k)}$\n\\begin{description} \n\\item[*] Fit regression model $\\mathbf{y}=\\widehat{f}_{\\lambda_{l}}^{(-k)}(\\mathbf{X}_{1})+\\boldsymbol\\epsilon$ for a grid of values of shrinkage parameters $\\lambda_l$, $l=1,\\ldots,L$ to $(S^{(-j)})^{(-k)}$\n\n\\item[*] Evaluate $\\widehat{f}_{\\lambda_{l}}^{(-k)}$,$l=1,\\ldots,L$ in the $kth$ held-out sub-sample $(S^{(-j)})^{(k)}$ by calculating $\\widehat{e}_{\\lambda_{l}}^{k}=\\sum_{(\\mathbf{y},\\mathbf{X}_{1})\\in (S^{(-j)})^{(k) } }(\\mathbf{y}-\\widehat{f}^{(-k)}_{\\lambda_{l}}(\\mathbf{X}_{1}))^2$\n\\end{description}\n\\item[-] Compute overall cross-validation error: $\\widehat{e}_{\\lambda_{l}}^{(-j)}=\\frac{1}{K}\\sum_{k=1}^{K}\\widehat{e}_{\\lambda_{l}^{k}}$, $l=1,\\ldots,L$\n\\end{description}\n\\item[] {\\bf End inner CV loop}\n\\item[-] Choose $\\lambda_{opt}^{(-j)}=min_{l=1,\\ldots,L}(\\widehat{e}_{\\lambda_{l}}^{(-j)})$ and calculate predictions of $\\mathbf{y}$ in the $jth$ held-out sub-sample $S^{(j)}$, $p_{1}=\\widehat{f}_{\\lambda_{opt}^{(-j)}}(\\mathbf{X}_{1})$, $(\\mathbf{y},\\mathbf{X}_{1})\\in S^{(j)}$\n\\end{description}\n\\item[] {\\bf End outer CV loop}\n\\end{description}\n\\item[Step 2] Repeat the process detailed in Step 1 considering the double cross-validated residuals $\\mathbf{res}=(y_{1}-p_{11},\\ldots,y_{n}-p_{1n})$, as outcome and $\\mathbf{X_{2}}$ as set of predictors and obtain the double cross-validation predictions $\\mathbf{p}_{2}=(p_{21},\\ldots,p_{2n})^{\\intercal}$. \n\n\\end{description}\n\n\nSeveral statistical methods are available to derive prediction models of continuous outcomes in high-dimensional settings. In this work, we focus on regularized linear regression models \\cite{Hastie1},\n\n\n\nwhere $f(\\mathbf{X})=\\mathbf{X}\\boldsymbol \\beta$ and \n\nthe estimation of $\\boldsymbol{\\beta}$ is conducted by solving $min_{\\boldsymbol \\beta}(\\mathbf{X}\\boldsymbol \\beta-\\mathbf{Y})^{\\intercal}(\\mathbf{X}\\boldsymbol \\beta-\\mathbf{Y})+\\lambda pen(\\boldsymbol \\beta)$, where $pen(\\boldsymbol \\beta)=\\frac{1-\\alpha}{2}||\\boldsymbol \\beta||_{2}^{2}+\\alpha||\\boldsymbol \\beta||_{1}$. The penalty parameter $\\lambda$ regularizes the $\\boldsymbol \\beta$ coefficients, by shrinking large coefficients in order to control the bias-variance trade-off. The pre-fixed parameter $\\alpha$ determines the type of imposed  penalization. We used two widely used penalization types: $\\alpha=0$ (ridge, i.e., \\ $\\ell_{2}$ type penalty \\cite{Hoerl}) and $\\alpha=1$ (lasso, i.e., \\ $\\ell_{1}$ penalty \\cite{Tibshirani1}). Note that other  model building strategies for prediction of continuous outcomes could have been used in this framework, such as the elastic net penalization \\cite{Zou} by setting $\\alpha=0.5$, or  boosting methods \\cite{Tutz, Buhlmann, Kneib}, among others.\n\n\\subsection{Summary measures of predictive accuracy}\nIn order to evaluate the performance of the sequential procedure introduced in Subsection 2.1., we propose three measures of predictive accuracy, denoted by $Q^{2}_{\\mathbf{X}_1}$, $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$, and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}$, based on cross-validated sum of squares. They can be regarded as high-dimensional equivalents of calibration measurements for continuous outcomes in low-dimensional settings \\cite{Schemper, Westerhuis}, and an extension of previously discussed proposals in the cross-validation literature \\cite{Jonathan}.\n\nDenote by $PRESS(\\mathbf{y},\\mathbf{p})=\\sum_{i=1}^{n}(y_{i}-p_{i})^{2}$ the prediction sum of squares based on a vector of predictions $\\mathbf{p}$, obtained from some arbitrary model $f$, $\\mathbf{p}=(p_{1},\\ldots,p_{n})^{\\intercal}=E_{f}(\\mathbf{y}|\\mathbf{X})$ and by $CVSS(\\mathbf{p}_{1},\\mathbf{p}_{2})=\\sum_{i=1}^{n}(p_{1i}-p_{2i})^{2}$ the cross-validated sum of squared differences between two  vectors of predictions, e.g. $\\mathbf{p}_{1}=E_{f}(\\mathbf{y}|\\mathbf{X}_{1})$, $\\mathbf{p}_{2}=E_{f}(\\mathbf{y}|\\mathbf{X}_{2})$. Let $\\mathbf{p}_{0}$ be the simplest cross-validated predictor of $\\mathbf{y}$, based on the sample mean of $\\mathbf{y}$ only. To summarize the first step of the sequential procedure, we use double cross-validation to estimate the predictive ability of $\\mathbf{X}_{1}$ by\n\n\n", "index": 1, "text": "\\begin{equation}\nQ_{\\mathbf{X}_{1}}^{2}=\\frac{CVSS(\\mathbf{p_{1}},\\mathbf{p_{0}})}{PRESS(\\mathbf{y},\\mathbf{p_{0}})}=\\frac{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(p_{1j}-\\overline{y}^{(-j)}\\right)^2}{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}-\\bar{y}^{(-j)}\\right)^2}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E1.m1\" class=\"ltx_Math\" alttext=\"Q_{\\mathbf{X}_{1}}^{2}=\\frac{CVSS(\\mathbf{p_{1}},\\mathbf{p_{0}})}{PRESS(%&#10;\\mathbf{y},\\mathbf{p_{0}})}=\\frac{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(p_{1j%&#10;}-\\overline{y}^{(-j)}\\right)^{2}}{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}%&#10;-\\bar{y}^{(-j)}\\right)^{2}}.\" display=\"block\"><mrow><mrow><msubsup><mi>Q</mi><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mi>C</mi><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfcf</mn></msub><mo>,</mo><msub><mi>\ud835\udc29</mi><mn/></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mi>R</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><msub><mi>\ud835\udc29</mi><mn/></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><msup><mover accent=\"true\"><mi>y</mi><mo>\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>-</mo><msup><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\n\n$Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ accounts for the predictive capacity of $f(\\mathbf{X}_{2})$, after removing the part of variation in $\\mathbf{y}$ that can be predicted by the first source of predictors $\\mathbf{X}_{1}$. Its computation relies on the squared difference between $\\mathbf{p}_2$ (the double cross-validated predictions resulting from the second step of the proposed procedure) and the corresponding residual from the step 1 ($\\mathbf{res}=\\mathbf{y}-\\mathbf{p}_{1}$) based on $\\mathbf{X}_{1}$, re-scaled by the remaining predicted variation on $\\mathbf{y}$ after the first step of the procedure. As a result, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ can be regarded as the expected ability of $\\mathbf{X}_{2}$ to predict the part of $\\mathbf{y}$, after adjusting for the predictive capacity of $f(\\mathbf{X}_{1})$ and accounting for all model fitting in the first stage of the assessment. Following the same arguments used in deriving expression (1), for each subset $S^{(j)}$, the computation of the average variation of $\\mathbf{res}$  is based on $\\overline{(y-p_{1})}^{(-j)}$, i.e., excluding the observations belonging to $S^{(j)}$. Note that in Step 1 of the sequential procedure $J$ models are fitted, each based on $S^{(-j)}$, providing residuals with expected zero mean (given specification (1)), i.e., $\\overline{(y-p_{1})}^{(-j)}\\approx0$, $j=1,\\ldots,J$. Hence, ${\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}-p_{1j}-\\overline{(y-p_{1})}^{(-j)}\\right)^2}\\approx \\sum_{i=1}^{n}\\left(y_{i}-p_{1i}\\right)^2$ and thus\n\n", "itemtype": "equation", "pos": 18326, "prevtext": "\n\nIntuitively, $Q_{\\mathbf{X}_{1}}^2$ represents the proportion of the variation of the response $\\mathbf{y}$ that is expected to be explained by $f(\\mathbf{X}_{1})$ in new individuals , re-scaled by the total amount of prediction variation in the response $\\mathbf{y}$. In the worst case scenario, when $\\mathbf{p}_{1}=\\mathbf{p}_{0}$ ($\\mathbf{X}_{1}$ as predictive as a null model based on the mean of $\\mathbf{y}$) $Q_{\\mathbf{X}_{1}}^2=0$ and $Q_{\\mathbf{X}_{1}}^2=1$ if $\\mathbf{p}_{1}=\\mathbf{y}$. Since the computation of $p_{1j}$, $j\\in S^{(j)}$ for each of the $j=1,\\ldots,J$ random splits of the sample $S$ is based on the observations not belonging to $S^{(j)}$, we proceed in an analogous way to compute the average predicted variation of $\\mathbf{y}$. Hence, in order to get an appropriate re-scaling factor, for each subset $S^{(j)}$, we compute $\\bar{y}^{(-j)}$, the mean value of the outcome variable $\\mathbf{y}$ calculated without the observations belonging to $S^{(j)}$. \n\nThe contribution of the second omic source, $\\mathbf{X}_{2}$, in the prediction of $\\mathbf{y}$ can be summarized by \n\n\n", "index": 3, "text": "\\begin{equation}\n\nQ_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}=\\frac{CVSS(\\mathbf{p_{2}},\\overline{\\mathbf{y}-\\mathbf{p_{1}})}}{PRESS(\\mathbf{y}-\\mathbf{p_{1}},\\overline{\\mathbf{y}-\\mathbf{p_{1}}})}=\\frac{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(p_{2j}-\\overline{(y_{j}-p_{1j})}^{(-j)}\\right)^2}{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}-p_{1j}-\\overline{(y_{j}-p_{1j})}^{(-j)}\\right)^2}.\n\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E2.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}=\\frac{CVSS(\\mathbf{p_{2}},%&#10;\\overline{\\mathbf{y}-\\mathbf{p_{1}})}}{PRESS(\\mathbf{y}-\\mathbf{p_{1}},%&#10;\\overline{\\mathbf{y}-\\mathbf{p_{1}}})}=\\frac{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}%&#10;\\left(p_{2j}-\\overline{(y_{j}-p_{1j})}^{(-j)}\\right)^{2}}{\\sum_{j=1}^{J}\\sum_{%&#10;j\\in S^{(j)}}\\left(y_{j}-p_{1j}-\\overline{(y_{j}-p_{1j})}^{(-j)}\\right)^{2}}.\\par&#10;\" display=\"block\"><mrow><mrow><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mi>C</mi><mi>V</mi><mi>S</mi><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfd0</mn></msub><mo>,</mo><mover accent=\"true\"><mrow><mi>\ud835\udc32</mi><mo>-</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfcf</mn></msub><mo stretchy=\"false\">)</mo></mrow><mo>\u00af</mo></mover></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mi>R</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mi>\ud835\udc32</mi><mo>-</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfcf</mn></msub></mrow><mo>,</mo><mover accent=\"true\"><mrow><mi>\ud835\udc32</mi><mo>-</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfcf</mn></msub></mrow><mo>\u00af</mo></mover><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><msub><mi>p</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><msup><mover accent=\"true\"><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>-</mo><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>-</mo><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>-</mo><msup><mover accent=\"true\"><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>-</mo><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\nFinally, we derive a third summarizing measurement of the overall sequential process, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}$, defined as: \n\n", "itemtype": "equation", "pos": 20271, "prevtext": "\n\n$Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ accounts for the predictive capacity of $f(\\mathbf{X}_{2})$, after removing the part of variation in $\\mathbf{y}$ that can be predicted by the first source of predictors $\\mathbf{X}_{1}$. Its computation relies on the squared difference between $\\mathbf{p}_2$ (the double cross-validated predictions resulting from the second step of the proposed procedure) and the corresponding residual from the step 1 ($\\mathbf{res}=\\mathbf{y}-\\mathbf{p}_{1}$) based on $\\mathbf{X}_{1}$, re-scaled by the remaining predicted variation on $\\mathbf{y}$ after the first step of the procedure. As a result, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ can be regarded as the expected ability of $\\mathbf{X}_{2}$ to predict the part of $\\mathbf{y}$, after adjusting for the predictive capacity of $f(\\mathbf{X}_{1})$ and accounting for all model fitting in the first stage of the assessment. Following the same arguments used in deriving expression (1), for each subset $S^{(j)}$, the computation of the average variation of $\\mathbf{res}$  is based on $\\overline{(y-p_{1})}^{(-j)}$, i.e., excluding the observations belonging to $S^{(j)}$. Note that in Step 1 of the sequential procedure $J$ models are fitted, each based on $S^{(-j)}$, providing residuals with expected zero mean (given specification (1)), i.e., $\\overline{(y-p_{1})}^{(-j)}\\approx0$, $j=1,\\ldots,J$. Hence, ${\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}-p_{1j}-\\overline{(y-p_{1})}^{(-j)}\\right)^2}\\approx \\sum_{i=1}^{n}\\left(y_{i}-p_{1i}\\right)^2$ and thus\n\n", "index": 5, "text": "\\begin{equation}\n\nQ_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}\\approx\\frac{\\sum_{i=1}^{n}p_{2i}^2}{\\sum_{i=1}^{n}\\left(y_{i}-p_{1i}\\right)^2}.\n\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E3.m1\" class=\"ltx_Math\" alttext=\"\\par&#10; Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}\\approx\\frac{\\sum_{i=1}^{n}p_{2i}^{%&#10;2}}{\\sum_{i=1}^{n}\\left(y_{i}-p_{1i}\\right)^{2}}.\\par&#10;\" display=\"block\"><mrow><mrow><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mn>2</mn></msubsup><mo>\u2248</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msubsup><mi>p</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>i</mi></mrow><mn>2</mn></msubsup></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msup><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>-</mo><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\n$Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$ represents the total predictive capacity of the overall sequential procedure based on $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$. Note that $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$ is based on the same squared difference between $\\mathbf{p}_2$ and $\\mathbf{res}=\\mathbf{y}-\\mathbf{p}_{1}$ than $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$, but the re-scaling factor refers to the total predictive variation of the original response $\\mathbf{y}$. \n\nThe three introduced measures jointly summarize the  performance of the two omic sources under study and their interplay in order to predict the outcome $\\mathbf{y}$. In all the cases higher values are indicative of higher predictive ability. The three measurements vary between 0 (null predictive ability) and the maximal value of 1. The interpretation of $Q^{2}_{\\mathbf{X}_1}$ is straightforward, as it simply captures the predictive capacity of the firstly evaluated omic source. However, given the sequential nature of the procedure, $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}$ should be cautiously interpreted. Note that the difference between $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}$ relies on the denominator. In general, if $\\mathbf{X}_{1}$ is informative, the denominator in expression (2) will be smaller than in expression (4). Thus, the residual variation after Step 1 will be smaller than the total initial variation. \n\nThe three summary measures are related by the following expression:\n\n", "itemtype": "equation", "pos": 20563, "prevtext": "\nFinally, we derive a third summarizing measurement of the overall sequential process, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}$, defined as: \n\n", "index": 7, "text": "\\begin{equation}\nQ_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2=\\frac{CVSS(\\mathbf{p_{1}}+\\mathbf{p_{2}},\\mathbf{p_{0}})}{PRESS(\\mathbf{y},\\mathbf{p_{0}})}=\\frac{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(p_{1j}+p_{2j}-\\bar{y}^{(-j)}\\right)^2}{\\sum_{j=1}^{J}\\sum_{j\\in S^{(j)}}\\left(y_{j}-\\bar{y}^{(-j)}\\right)^2}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E4.m1\" class=\"ltx_Math\" alttext=\"Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}=\\frac{CVSS(\\mathbf{p_{1}}+\\mathbf{p_{2}}%&#10;,\\mathbf{p_{0}})}{PRESS(\\mathbf{y},\\mathbf{p_{0}})}=\\frac{\\sum_{j=1}^{J}\\sum_{%&#10;j\\in S^{(j)}}\\left(p_{1j}+p_{2j}-\\bar{y}^{(-j)}\\right)^{2}}{\\sum_{j=1}^{J}\\sum%&#10;_{j\\in S^{(j)}}\\left(y_{j}-\\bar{y}^{(-j)}\\right)^{2}}.\" display=\"block\"><mrow><mrow><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc17</mi><mn>2</mn></msub></mrow><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mi>C</mi><mo>\u2062</mo><mi>V</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>\ud835\udc29</mi><mn>\ud835\udfcf</mn></msub><mo>+</mo><msub><mi>\ud835\udc29</mi><mn>\ud835\udfd0</mn></msub></mrow><mo>,</mo><msub><mi>\ud835\udc29</mi><mn/></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mrow><mi>P</mi><mo>\u2062</mo><mi>R</mi><mo>\u2062</mo><mi>E</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mi>S</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>\ud835\udc32</mi><mo>,</mo><msub><mi>\ud835\udc29</mi><mn/></msub><mo stretchy=\"false\">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><mrow><msub><mi>p</mi><mrow><mn>1</mn><mo>\u2062</mo><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>p</mi><mrow><mn>2</mn><mo>\u2062</mo><mi>j</mi></mrow></msub></mrow><mo>-</mo><msup><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mrow><msubsup><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mrow><msub><mo largeop=\"true\" symmetric=\"true\">\u2211</mo><mrow><mi>j</mi><mo>\u2208</mo><msup><mi>S</mi><mrow><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><msup><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>j</mi></msub><mo>-</mo><msup><mover accent=\"true\"><mi>y</mi><mo stretchy=\"false\">\u00af</mo></mover><mrow><mo stretchy=\"false\">(</mo><mrow><mo>-</mo><mi>j</mi></mrow><mo stretchy=\"false\">)</mo></mrow></msup></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\n\nConsequently, we can rewrite $Q_{\\mathbf{X}_2|\\mathbf{X}_1}^2$ as follows:\n\n", "itemtype": "equation", "pos": 22428, "prevtext": "\n$Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$ represents the total predictive capacity of the overall sequential procedure based on $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$. Note that $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$ is based on the same squared difference between $\\mathbf{p}_2$ and $\\mathbf{res}=\\mathbf{y}-\\mathbf{p}_{1}$ than $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$, but the re-scaling factor refers to the total predictive variation of the original response $\\mathbf{y}$. \n\nThe three introduced measures jointly summarize the  performance of the two omic sources under study and their interplay in order to predict the outcome $\\mathbf{y}$. In all the cases higher values are indicative of higher predictive ability. The three measurements vary between 0 (null predictive ability) and the maximal value of 1. The interpretation of $Q^{2}_{\\mathbf{X}_1}$ is straightforward, as it simply captures the predictive capacity of the firstly evaluated omic source. However, given the sequential nature of the procedure, $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}$ should be cautiously interpreted. Note that the difference between $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}$ relies on the denominator. In general, if $\\mathbf{X}_{1}$ is informative, the denominator in expression (2) will be smaller than in expression (4). Thus, the residual variation after Step 1 will be smaller than the total initial variation. \n\nThe three summary measures are related by the following expression:\n\n", "index": 9, "text": "\\begin{equation}\n(1-Q_{\\mathbf{X}_1}^2)(1-Q_{\\mathbf{X}_2|\\mathbf{X}_1}^2)\\approx(1-Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2).\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E5.m1\" class=\"ltx_Math\" alttext=\"(1-Q_{\\mathbf{X}_{1}}^{2})(1-Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2})\\approx(1-Q%&#10;_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}).\" display=\"block\"><mrow><mrow><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msubsup><mi>Q</mi><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2248</mo><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc17</mi><mn>2</mn></msub></mrow><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\n\nNote that in cases in which $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}=0$, we get that $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1}}=0$, and viceversa. However,  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1}}$ differ when not zero. Specifically, from expression (6), we obtain that $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}\\geq Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1 }}$. In short, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ may be regarded as the conditional contribution of $\\mathbf{X}_{2}$ for the prediction of $\\mathbf{y}$ with respect to what may be predicted using $\\mathbf{X}_{1}$ alone. $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}-Q_{\\mathbf{X_{1}}}^{2}$ measures the absolute gain  in predictive ability from adding $\\mathbf{X_{2}}$  to $\\mathbf{X}_{1}$. Note that, because of the asymmetric nature of the procedure, a given source $\\mathbf{X}_{2}$ may present a large $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$  but be  of little relevance to improve predictions based on a  previously established $\\mathbf{X}_{1}$ due to the high predictive ability of $\\mathbf{X}_{1}$ itself. \n\n\\subsection{Permutation test for augmented prediction assessment}\nThe summary measures may be used to introduce formal tests for assessing the added or augmented predictive value of   $\\mathbf{X}_{2}$ over $\\mathbf{X}_{1}$ to predict $\\mathbf{y}$. We propose a permutation procedure to test the null hypothesis $H_{0}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2=0$ against the alternative hypothesis $H_{1}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2>0$. The test is based on permuting the residuals obtained after applying the first step of our two-stage procedure with the data at hand. Our goal is to remove the potential association between $\\mathbf{X}_2$ and $\\mathbf{y}$ while preserving the original association between $\\mathbf{y}$ and $\\mathbf{X}_1$. \n\n\nExplicitly, we propose the following algorithm:\n\n\\begin{description}\n\\item[Step 1] \nCalculate the residuals $\\mathbf{res}=\\mathbf{y}-\\mathbf{p_{1}}$ based on the predictions $\\mathbf{p_{1}}$ of $\\mathbf{y}$ based on $\\mathbf{X}_{1}$, obtained in the first step of the procedure presented in Section 2.1.\n\\item[Step 2]\nPermute the values of $\\mathbf{res}$, obtaining $\\mathbf{res}^{\\pi}$ and generate values of the response $\\mathbf{y}$ under the null hypothesis: $\\mathbf{y}^{*}=\\mathbf{p_{1}}+\\mathbf{res}^{\\pi}$.\n\\item[Step 3]\nRepeat the two-stage procedure from Section 2.1. for predicting $\\mathbf{y}^{*}$ and obtain the corresponding $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2*}$.\n\\end{description}\n\nThe procedure is repeated $M$ times and the resulting permutation p-values are obtained as follows:\n\n", "itemtype": "equation", "pos": 22641, "prevtext": "\n\nConsequently, we can rewrite $Q_{\\mathbf{X}_2|\\mathbf{X}_1}^2$ as follows:\n\n", "index": 11, "text": "\\begin{equation}\nQ_{\\mathbf{X}_2|\\mathbf{X}_1}^2\\approx\\frac{Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}-Q_{\\mathbf{X}_{1}}^{2}}{(1-Q_{\\mathbf{X}_{1}}^2)}.\n\\end{equation}\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.E6.m1\" class=\"ltx_Math\" alttext=\"Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}\\approx\\frac{Q_{\\mathbf{X}_{1},\\mathbf{X}%&#10;_{2}}^{2}-Q_{\\mathbf{X}_{1}}^{2}}{(1-Q_{\\mathbf{X}_{1}}^{2})}.\" display=\"block\"><mrow><mrow><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mn>2</mn></msubsup><mo>\u2248</mo><mfrac><mrow><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mo>,</mo><msub><mi>\ud835\udc17</mi><mn>2</mn></msub></mrow><mn>2</mn></msubsup><mo>-</mo><msubsup><mi>Q</mi><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mn>2</mn></msubsup></mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mn>1</mn><mo>-</mo><msubsup><mi>Q</mi><msub><mi>\ud835\udc17</mi><mn>1</mn></msub><mn>2</mn></msubsup></mrow><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.08197.tex", "nexttext": "\nwhere $M$ is the number of permutations, and $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ is the actual observed value with the data at hand. Note than in {\\bf Step 2}, we generate a `null' version of the original response $\\mathbf{y}$ and then we repeat the overall two-stage procedure, which implies that the `null' residuals used in {\\bf Step 3} are not fixed and are, in general, different from $\\mathbf{res}^{\\pi}$. This is necessary in order to capture all the variability of the two-stage procedure and to correctly generate the null hypothesis of interest.\n\nGiven the aforementioned relations between $Q_{\\mathbf{X}_1}^2$, $Q_{\\mathbf{X}_2|\\mathbf{X}_1}^2$, and $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$ specified by expression (6) , note that $H_{0}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2=0$ is equivalent to  $\\widetilde{H}_{0}:Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2-Q_{\\mathbf{X}_{1}}^2=0$. This result immediately follows from expression (6), using that $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2=0$ if and only if $1-Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2=1$ (assuming $Q^{2}_{\\mathbf{X}_{1}} \\neq 1$). Hence, both tests are equivalent provided that the distribution under the null hypothesis is generated by the aforementioned permutation procedure, i.e.,  the p-values, resulting from using $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ as test statistic or  $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}-Q_{\\mathbf{X}_{1}}^{2}$ are approximately the same.\n\n\nFinally, it is important to highlight that, in general, the predictive performance and the results of testing for added value of $\\mathbf{X}_{2}$ depend on the method used for deriving predictions. Both $\\mathbf{p}_{1}$ and $\\mathbf{p}_{2}$ depend on the model specification used  to derive predictions, in our particular setting, regularized linear regression. In general, if $\\mathbf{X}_{2}$ and the outcome $\\mathbf{y}$ are independent given $\\mathbf{X}_{1}$, one would expect that $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}=0$ and $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}=Q_{\\mathbf{X}_{1}}^{2}$.  However, model miss-specification in the first step may result in a  non-null $Q^{2}_{\\mathbf{X}_2|\\mathbf{X}_1}$ due to the correlation between $\\mathbf{X}_1$ and $\\mathbf{X}_2$, which may induce, for example, the re-calibration of $\\mathbf{X}_1$ via  $\\mathbf{X}_2$ \\cite{Alexia,Steyerberg}. \n\n\\section{Simulation study}\n\\subsection{Simulation setup}\nWe consider the simulation of two omic predictor sources $\\mathbf{X}_1$ (dimension $n\\times p$) and $\\mathbf{X}_2$ (dimension $n \\times q$) and a $n\\times1$ vector  $\\mathbf{y}$ which represents the continuous outcome. The simulation strategy is based on the generation of common `latent' factors associated with $\\mathbf{X}_1$, $\\mathbf{X}_2$ and $\\mathbf{y}$. To implement this approach, we use matrix singular value decomposition (svd, \\cite{Jolliffe}) of each of the two omic sources. By assuming common eigenvectors in the svd of $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$, we introduce correlation among the omic sources and we can simulate different patterns in terms of the conditional association between $\\mathbf{X}_{2}$ and $\\mathbf{y}$ (see Figure 1). The details of the data generation procedure are as follows:\n\n\n\n\n\n\n\n\\begin{figure}[h]\n\\begin{minipage}{0.45\\linewidth}\n\\begin{tikzpicture}\n\n\\node[draw,text centered] (X1) {$\\mathbf{X}_{1}$};\n\\node[draw, below = 0.5 of X1, text centered] (X2) {$\\mathbf{X}_{2}$};\n\\node[draw,left = 1.5 of X1, rectangle,dashed,text centered] (LJ) {$L_{C}$};\n\\node[draw, rectangle, dashed, above = 0.75 of LJ, text centered] (L1) {$L_{1}$};\n\\node[draw, rectangle, dashed, below = 0.75 of LJ, text centered] (L2) {$L_{2}$};\n\\node[draw,right = 1.5 of X1,text centered] (y) {$\\mathbf{y}$};\n \n\n\\draw[->, line width= 1,dashed] (L1) --  (X1);\n\\draw [->, line width= 1,dashed] (L2) -- (X2);\n\\draw [->, line width= 1,dashed] (LJ) -- (X2);\n\\draw [->, line width= 1,dashed] (LJ) -- (X1);\n\\draw[->, line width=1] (LJ) to  [out=120,in=120, looseness=0.5]  (y);\n\n\n\n\n\\end{tikzpicture}\n\\end{minipage}\n\\begin{minipage}{0.45\\linewidth}\n\\begin{tikzpicture}\n\n\\node[draw,text centered] (X1) {$\\mathbf{X}_{1}$};\n\\node[draw, below = 0.5 of X1, text centered] (X2) {$\\mathbf{X}_{2}$};\n\\node[draw,left = 1.5 of X1, rectangle,dashed,text centered] (LJ) {$L_{C}$};\n\\node[draw, rectangle, dashed, above = 0.75 of LJ, text centered] (L1) {$L_{1}$};\n\\node[draw, rectangle, dashed, below = 0.75 of LJ, text centered] (L2) {$L_{2}$};\n\\node[draw,right = 1.5 of X1,text centered] (y) {$\\mathbf{y}$};\n \n\n\\draw[->, line width= 1,dashed] (L1) --  (X1);\n\\draw [->, line width= 1,dashed] (L2) -- (X2);\n\\draw [->, line width= 1,dashed] (LJ) -- (X2);\n\\draw [->, line width= 1,dashed] (LJ) -- (X1);\n\\draw[->, line width=1] (L1) to  [out=120,in=120, looseness=0.5]  (y);\n\\draw[->, line width=1] (L2) to  [out=270,in=270, looseness=0.5]  (y);\n\\end{tikzpicture}\n\\end{minipage}\n\n\\caption{Simulation study. $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ are two omic predictors sources and $\\mathbf{y}$ is the outcome to be predicted. $\\mathbf{L}_{1}$, $\\mathbf{L}_{2}$ and $\\mathbf{L}_{C}$ represent three independent non-observed matrices used to generate $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$. Since $\\mathbf{L}_{C}$ is  associated with $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$, it induces correlation between them.  Left: Null case. No independent (of $\\mathbf{X}_{1}$) association between  $\\mathbf{X}_2$ and $\\mathbf{y}$ ($\\mathbf{y}$ is generated as a linear combination of columns of $\\mathbf{L}_{C}$ plus independent noise). Right: Alternative case. Independent (of $\\mathbf{X}_{1}$) association between $\\mathbf{X}_2$ and $\\mathbf{y}$ ($\\mathbf{y}$ is generated as a linear combination of $\\mathbf{L}_{1}$ and $\\mathbf{L}_{2}$ plus independent noise).}\n\\end{figure}\n\n\n\n\n\\textbf{Step 1} Generate $\\mathbf{L}\\sim N(0,\\mathbf{I}_{R})$,  a matrix of $r=1,\\ldots,R$ i.i.d.  latent factors of $\\mathbf{X}_1$ and $\\mathbf{X}_2$. \n\n\\textbf{Step 2} Define $\\mathbf{\\Sigma}_{1}$ ($p \\times p$) and $\\mathbf{\\Sigma}_{2}$ ($q \\times q$), the correlation matrices of $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$, respectively, according to a predefined covariance structure of interest. Following the recent literature on pathway and network analysis of omics data \\cite{Zhang}, we generated $\\boldsymbol{\\Sigma}_{i}$, $i=1,2$ according to a hub observation model \\cite{Hardin} such that it reflects the presence of several independently generated groups with different levels of correlation among features (see Figure 2). \n\n\n\\textbf{Step 3} Draw $\\mathbf{X^{*}}_{i}\\sim N(0,\\mathbf{\\Sigma}_{i})$, $i=1,2$, \nand obtain the singular value decomposition for each of the independent matrices $\\mathbf{X}_{1}^{*}$ and $\\mathbf{X}_{2}^{*}$:  $\\mathbf{X}_{i}^{*}=\\mathbf{U^{*}}_{i}\\mathbf{D}_{i}\\mathbf{V}_{i}^{T}, \\quad i=1,2$, where $\\mathbf{U^{*}}_{i}$ and $\\mathbf{V}_{i}$ are the orthogonal matrices of left and right eigenvectors, respectively, and $\\mathbf{D}_{i}$ is the diagonal matrix of eigenvalues in descending order. Note that each eigenvalue is proportional to the portion of variation that is explained by each of the corresponding eigenvectors.\n\n\\textbf{Step 4} Generate the final correlated $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ by  manipulation of $\\mathbf{U^{*}}_{1}$ and $\\mathbf{U^{*}}_{2}$, the left eigenvectors matrices from $\\mathbf{X^{*}}_{1}$ and $\\mathbf{X^{*}}_{2}$, respectively. Specifically, for a certain number ($C$) of predefined columns $C_{1}$ and $C_{2}$, the original submatrices $\\mathbf{U^{*}}_{1C_{1}}$ and $\\mathbf{U^{*}}_{2C_{2}}$ (independent) are replaced by $C$ common independent latent factors $L_{c}$, $c=1,\\ldots,C$ generated in \\textbf{Step 1}. The remaining columns of $\\mathbf{U^{*}}_{i}$, $i=1,2$ are replaced by independent and uncommon latent factors, also generated in \\textbf{Step 1}. In this manner, correlation between $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ is induced, while the within-omic source correlation structures $\\boldsymbol{\\Sigma}_{1}$ and $\\boldsymbol{\\Sigma}_{2}$ are preserved. Note that the correlation will be stronger if the common latent factors correspond with the first columns of the new eigenvectors matrices, denoted by $\\mathbf{U}_{1}$ and $\\mathbf{U}_{2}$ respectively (corresponding to the first eigenvalues in $\\mathbf{D}_{1}$ and $\\mathbf{D}_{2}$, and hence responsible for maximal variation).\n\n\n\\textbf{Step 5} Simulate the outcome $\\mathbf{y}=\\mathbf{X}_{1}\\boldsymbol{\\beta}_{1}+\\mathbf{X}_{2}\\boldsymbol{\\beta}_{2}+\\boldsymbol\\epsilon$, where $\\boldsymbol{\\beta}_{1}$ and $\\boldsymbol{\\beta}_{2}$ are vectors of regression coefficients of length $p$ and $q$, respectively and $\\boldsymbol\\epsilon\\sim N(0,1)$. Since $\\mathbf{X}_{i}=\\mathbf{U}_{i}\\mathbf{D}_{i}\\mathbf{V}_{i}^{T}$, $i=1,2$, we can rewrite $\\mathbf{X}_{i}\\boldsymbol{\\beta}_{i}=\\mathbf{U}_{i}\\mathbf{D}_{i}\\boldsymbol{\\beta}^{*}_{i }$ and thus, we have that $\\boldsymbol{\\beta}_{i}=\\mathbf{V}_{i}\\boldsymbol{\\beta}^{*}_{i}$, where $\\boldsymbol{\\beta}^{*}_{i}$ represents the association between $\\mathbf{X}_i$ and the outcome $\\mathbf{y}$ through the orthogonal directions given by $\\mathbf{U}_{i}$. Consequently, we first generate $\\boldsymbol\\beta^{*}_{i}$ and we then transform it to the predictor space by using $\\boldsymbol{\\beta}_{i}=\\mathbf{V}_{i}\\boldsymbol{\\beta}^{*}_{i}$. Given that the correlation among the observed omic sources $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ is also driven at the $\\mathbf{U}_{i}$ level, this general framework allows us to generate the association with $\\mathbf{y}$ in terms of latent factors associated with different proportions of the variation in $\\mathbf{X}_i$ and, at the same time, to generate different situations in terms of shared and independent associations between each omic source and the outcome.\n\n\n\n\n\n\\begin{figure}[h]\n\\begin{minipage}{0.45\\linewidth}\n\\includegraphics[width=5cm,height=5cm]{test.png}\n\\end{minipage}\n\\begin{minipage}{0.45\\linewidth}\n\\includegraphics[width=5cm,height=5cm]{Cor2_q100_2blocks.pdf}\n\\end{minipage}\n\\caption{Simulation study. Left: Correlation matrix of $\\mathbf{X}_1$ ($p=1000$), 4 groups of 250 features each. Right: Correlation matrix of $\\mathbf{X}_2$ ($q=100$), 2 groups of 50 features each.}\n\\end{figure}\n\n\n\n\n\\noindent\\textbf{Simulation 1 (`Null' scenarios):}\nWe first investigate 'null' scenarios, where the second omic $\\mathbf{X}_{2}$ source is non-informative, i.e., $\\boldsymbol{\\beta}_{2}^{*}=\\mathbf{0}$, but is strongly correlated to $\\mathbf{X}_{1}$, by imposing common first columns of $\\mathbf{U}_{1}$ and $\\mathbf{U}_{2}$ ($\\mathbf{U}_{11}=\\mathbf{U}_{21}$, the correlation between omic sources is driven through the maximal variance subspace). We considered different assumptions regarding the regression dependence of $\\mathbf{y}$ on $\\mathbf{X}_{1}$ which has an impact on  the ability to calibrate prediction rules based on $\\mathbf{X}_1$ for  $\\mathbf{y}$. We consider two situations in which the association with $\\mathbf{y}$ is unifactorial, in the sense that only one latent factor (one column of $\\mathbf{U}_1$) is associated with $\\mathbf{y}$ and two multi-factorial situations. One of our objectives is to illustrate how changing the complexity of the calibration of a prediction rule based on $\\mathbf{X}_{1}$ (by formulating the problem trough regression on either larger or smaller variance latent factors) may affect the results. We consider the following `null' scenarios: \n\\begin{description}\n\\item[Scenario 1a] $\\beta_{1j}^{*}=0.01$, $j=1$; $\\beta_{1j}^{*}=0,\\quad j \\neq 1$.  $\\mathbf{y}$ is associated to high-variance subspace of $\\mathbf{U}_{1}$, corresponding to the largest eigenvalue of $\\mathbf{X}_{1}$.\n\n\\item[Scenario 1b] $\\beta_{1j}^{*}=1$, $j=6$, $\\beta_{1j}^{*}=0,\\quad j \\neq 6$. The association with $\\mathbf{y}$ relies on a low-variance subspace of $\\mathbf{U}_{1}$. Hence, we expect lower values of $Q^{2}_{\\mathbf{X}_1}$, compared to Scenario 1a.\n\n\\item[Scenario 1c] $\\beta_{1j}^{*}=1,\\quad j=1,2$, $\\beta_{1j}^{*}=0$ otherwise. In this setting we consider a bifactorial regression, as association with $\\mathbf{y}$ is a combination of the effect of the two first eigenvectors of $\\mathbf{X}_1$. \n\n\\item[Scenario 1d] $\\beta_{1j}^{*}=1,\\quad j=1,\\ldots, 4$, $\\beta_{1j}^{*}=0$ otherwise. In this setting we consider a multifactorial regression, as association with $\\mathbf{y}$ is a combination of the effect of the four first eigenvectors of $\\mathbf{X}_1$. \n\\end{description}\n\n\\noindent\\textbf{Simulation 2 (`Alternative' scenarios):}\n\nWe also considered alternative settings, in which $\\mathbf{X}_{2}$ is associated with $\\mathbf{y}$ through latent factors non-shared with $\\mathbf{X}_{1}$. The following `alternative' scenarios are investigated:\n\n\\begin{description}\n\\item[Scenario 2a] $\\boldsymbol{\\beta}_{1j}^{*}=\\boldsymbol{\\beta}_{2j}^{*}=0.01$, $j=1$, $\\boldsymbol{\\beta}_{1j}^{*}=\\boldsymbol{\\beta}_{2j}^{*}=0$, $j\\neq1$. The eigenvector related to the largest eigenvalue of each source is associated to $\\mathbf{y}$ and the association between $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ is generated by sharing the second eigenvectors, i.e., by setting $\\mathbf{U}_{12}=\\mathbf{U}_{22}$.\n\n\\item[Scenario 2b] $\\boldsymbol{\\beta}_{1j}^{*}=0.01$, $j=1$, $\\boldsymbol{\\beta}_{1j}^{*}=0$, $j\\neq1$  and $\\boldsymbol{\\beta}_{2j}^{*}=0.01$, $j=3$, $\\boldsymbol{\\beta}_{2j}^{*}=0$, $j\\neq3$, and the association between $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ is generated by setting $\\mathbf{U}_{11}=\\mathbf{U}_{21}$.\n\\item[Scenario 2c] $\\boldsymbol{\\beta}_{1j}^{*}=0.01$, $j=6$, $\\boldsymbol{\\beta}_{1j}^{*}=0$, $j\\neq1$  and $\\boldsymbol{\\beta}_{2j}^{*}=0.01$, $j=3$, $\\boldsymbol{\\beta}_{2j}^{*}=0$, $j\\neq3$, and the association between $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$ is generated by setting $\\mathbf{U}_{11}=\\mathbf{U}_{21}$.\n\\end{description}\n\nThe three studied alternative scenarios differ in several aspects. On the one hand, in both 2a and 2b scenarios, the association between the first source of predictors $\\mathbf{X}_1$ and $\\mathbf{y}$ is driven through the highest variance subspace, while 2c relies on a situation in which $\\mathbf{X}_1$ is associated with $\\mathbf{y}$ through a low variance subspace (and hence the predictive problem of the first stage is more difficult). On the other hand, we expect that $\\mathbf{X}_{2}$ has a larger impact in the prediction of $\\mathbf{y}$ in scenario 2a than in scenarios 2b and 2c, as the association with the outcome is driven through a higher variance subspace.  \n\nFigure 3 shows a Monte Carlo approximation based on a sample of $n=10.000$ observations of the regression coefficients $\\boldsymbol{\\beta}_{1}$ and $\\boldsymbol{\\beta}_{2}$ in the studied simulated scenarios. From panels 3(a) to 3(d), we can observe that the different simulation settings differ in the level of imposed sparsity in the association between $\\boldsymbol{y}$ and $\\mathbf{X}_{1}$. On the one hand, scenarios presented in panels 3(a) (scenarios 1a, 2a ad 2b) and 3(b) (scenario 1b) are relatively sparse, with most of the simulated coefficients close to zero. On the other hand, the $\\boldsymbol{\\beta}_{1}$ of scenario 1c (represented in panel 3(c)) and specially of scenario 1d (represented in panel 3(d)) are less sparse, based on a large number of non-null regression coefficients in $\\mathbf{X}_{1}$. With regard to $\\boldsymbol{\\beta}_{2}$, panel 3(e) (scenario 2a) represents a sparser situation than panel 3(f) (scenarios 2b and 2b).\n\n\\begin{figure}\n\n\n\n\\includegraphics[scale=0.25]{BetaX1_1a2a2b_p1000.pdf}\n\n\n\n\n\\includegraphics[scale=0.25]{BetaX1_1b2c_p1000.pdf}\n\n\n\n\n\\includegraphics[scale=0.25]{BetaX1_1c_p1000.pdf}\\\\\n\n\n\n\n\\includegraphics[scale=0.25]{BetaX1_1d_p1000.pdf}\n\n\n\n\n\\includegraphics[scale=0.25]{BetaX2_2a_q100.pdf}\n\\includegraphics[scale=0.25]{BetaX2_2b2c_q100.pdf}\n\n\n\n\n\\caption{Simulation study. Regression coefficients for $\\mathbf{X}_{1}$ ($\\boldsymbol{\\beta}_{1}$) and $\\mathbf{X}_{2}$ ($\\boldsymbol{\\beta}_{2}$), the outcome variable is generated as  $\\mathbf{y}=\\mathbf{X}_{1}\\boldsymbol{\\beta}_{1}+\\mathbf{X}_{2}\\boldsymbol{\\beta}_{2}+\\boldsymbol\\epsilon$.(a)-(d) provide information about association between $\\mathbf{y}$ and $\\mathbf{X}_1$ and (e) and (f) corresponds to the independent association between $\\mathbf{y}$ and $\\mathbf{X}_2$ in the alternative scenarios (for the null scenarios 1a-1d the independent association between $\\mathbf{y}$ and $\\mathbf{X}_2$ is null). (a) corresponds to scenarios 1a, 2a and 2b, (b) correspond to scenarios 1b and 2c respectively, while (c) and (d) correspond to scenario 1c and 1d. (e) shows the association ($\\boldsymbol{\\beta}_{2}$) between $\\mathbf{X}_2$ and $\\mathbf{y}$ in scenario 2a and (e) shows $\\boldsymbol{\\beta}_{2}$ for scenarios 2b and 2c.}\n\\end{figure}\n\n\n\nIn our basic setting, we considered $n=100$ observations, $p=1000$ features in $\\mathbf{X}_{1}$ and $q=100$ features in $\\mathbf{X}_{2}$. For each scenario, we provide the mean values and standard deviations of $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$, and $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$, based on 5-folds double cross-validation, jointly with the rejection proportions for testing $H_{0}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ along $M=500$ Monte Carlo trials. We evaluated the permutation test introduced in Subsection 2.3. using $n_{perm}=200$ permutations. We complemented our empirical evaluations of the proposed sequential double cross-validation procedure by extending our basic simulation setting in two directions. We checked the impact on modifying sample size ($n=50$) and the complexity of the problem by varying the number of variables considered in the first stage ($p=4000$).\n\n\n\nAdditionally, we compared the performance  of our procedure based on double-cross validation with two alternative strategies. On the one hand, we provide results based on a two-stage procedure using a single cross-validation loop (cross-validation is used for model choice but predictions and therefore the residuals used as outcome in the second stage are directly computed on the complete sample). On the other hand, we check the impact on the results of over-penalization. Specifically, instead of taking $\\lambda_{opt}$ as defined in the inner loop of the double cross-validation procedure presented in Subsection 2.1., we choose a larger value for $\\lambda$, namely $\\lambda_{opt}+1 s.e.(\\lambda_{opt})$. Both are usual strategies in penalized regression in single omic prediction frameworks, so it is of practical interest to quantify their impact from the added predictive value point of view. The results of these alternative strategies are provided as Supplemental material but discussed in the main text.\n \n\n\n\\subsection{Simulation results}\n\nThe results for the sequential double cross-validation procedure (labeled as `CV type= $CV_{D}$, $\\lambda_{opt}$') are summarized in Tables 1 and 2. The top part of each table contains the results concerning the `null' scenarios (no added value of $\\mathbf{X}_{2}$), while the bottom part shows the results of the `alternative' scenarios (added value of $\\mathbf{X}_{2}$). Table 1 contains results based on ridge regression, $\\alpha=0$ in expression (1), while Table 2 summarizes the results for the lasso penalty type ($\\alpha=1$).\n\n\\subsubsection{Ridge regression}\n\n\nFor the four `null' scenarios 1a-1d, given that $\\mathbf{X}_{2}$ is not independently associated to $\\mathbf{y}$, we expect $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}=0$ and rejection proportions of $H_{0}$ about 0.05. \n\nThe results of the sequential double cross-validation procedure based on ridge regression are satisfactory in this regard, with rejection proportions close to the nominal level in all the studied null scenarios and for different sample sizes ($n=50$, $n=100$) and levels of complexity of the first step ($p=1000$, $p=4000$).  \n\n\nThe top part of Table 1 shows that the estimated $Q_{\\mathbf{X}_{1}}^{2}$ for scenarios 1a, 1c and 1d are large and very similar ($Q_{\\mathbf{X}_{1}}^{2}\\sim 0.90$). As it was expected, the estimated predictive ability of $\\mathbf{X}_{1}$ is lower in scenario 1b and presents a larger variability, since the association between $\\mathbf{y}$ and $\\mathbf{X}_{1}$ relies on a small variance subspace. In general, for all 1a-1d scenarios the estimated $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ is close to zero. However, we observe that the sample size influences the estimated  $Q_{\\mathbf{X}_{1}}^2$ and hence, due to the correlation between $\\mathbf{X}_{1}$ and $\\mathbf{X}_{2}$, also affects the estimation of $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$. We observe systematically lower values of $Q_{\\mathbf{X}_{1}}$ for $n=50$ than for $n=100$ in all the studied `null' scenarios. This feature translates in systematically larger values of $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ for $n=50$ than for $n=100$. However, the permutation test is able to account for this issue and the level of the test is respected independently of the sample size. Analogously, increasing the number of features of the first source $\\mathbf{X}_{1}$ (from $p=1000$ to $p=4000$) while keeping fixed the number of features of $\\mathbf{X}_{2}$ ($q=100$) also affects the estimation of $Q_{\\mathbf{X}_{1}}$ and $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$. In this case, the values of $Q_{\\mathbf{X}_{1}}$ are larger and hence, the values of $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ tend to be closer to zero. Nicely, the level of the test is also well respected in this case.\n\n\nThe bottom part of Table 1 shows the results for the alternative scenarios. As desirable, the power increases with sample size for all the three studied alternative scenarios. As it was the case for the `null' scenarios, increasing the sample size tends to lead to better predictive ability of $\\mathbf{X}_{1}$. This result matches intuition, since larger sample sizes provide more information for model building, and hence, under correct model specification, the resulting predicting models are expected to behave better in new data. An exception to this is scenario 2c, where our double cross-validation procedure seems to overfit with $n=50$. This is due to the fact that scenario 2c, unlike scenarios 2a and 2b, is characterized as a `difficult' prediction problem when considering $\\mathbf{X}_{1}$ (association with $\\mathbf{y}$ is driven by a low-variance subspace of $\\mathbf{X}_{1}$). In line with this, the power of the test is different for the three different studied scenarios. The greatest power is reached in scenario 2a, in which the independent association between $\\mathbf{X}_{2}$ and $\\mathbf{y}$ is driven through the subspace of maximum variation and the first step of the procedure relies on a relatively `easy' prediction problem.\n\nEven if scenarios 2b and 2c are based on the same independent association between $\\mathbf{X}_2$ and $\\mathbf{y}$, the impact of the first source on the power of the test is large. Scenario 2b, in which $Q_{\\mathbf{X}_{1}}^{2}=0.87$ for $n=100$ reaches a power of 71 \\%, while the rejection rate reduces to 19\\% in scenario 2c, corresponding to a more `difficult' prediction problem in the first stage, reflected in a low and unstable $Q_{\\mathbf{X}_{1}}^{2}$ ($Q_{\\mathbf{X}_{1}}^{2}=0.28$ for $n=50$ and $Q_{\\mathbf{X}_{1}}^{2}=0.09$ for $n=100$).\n\n\n\n\\begin{table}[htbp]\n\\label{Table1}\n  \\centering\n  {\\footnotesize\n  \\caption{Ridge ($\\alpha=0$). Mean estimates (and standard deviation in brackets) of $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$  and rejection proportions of the permutation test based on  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ along 500 Monte Carlo trials.}\n \\begin{tabular}{cc|c|c|c|c}\n    \\\\\n    \n      \\hline\n    {\\footnotesize Scenario} & $n$&$Q_{\\mathbf{X}_{1}}^2$ (Step 1)    & $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$ (Step 2)& $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^ 2$ (Global)&{Rej. Prop.} \\\\   \n          \\hline \n            & & &&&\\\\\n                       &$n=50$ &0.85 (0.03)  &0.07 (0.09)&0.89 (0.05) &0.058\\\\     \n            1a  &$n=100$ & 0.88 (0.02) &0.03 (0.04)& 0.91 (0.03)&0.068\\\\     \n             &$n=100$, $p=4000$ &0.94 (0.02)  &0.03 (0.04)&0.99 (0.01) &0.056\\\\ \n          \n    & & &&&\\\\\n   &$n=50$ &0.31 (0.07) &0.04 (0.07)&0.34 (0.09) &0.044\\\\ \n              1b  &$n=100$& 0.41 (0.07)  &0.01 (0.02)&0.42 (0.07) &0.047\\\\     \n           & $n=100$, $p=4000$&0.50 (0.09) &0.01 (0.03)&0.72 (0.13) &0.060\\\\  \n          \n    & & &&&\\\\\n   \n     &$n=50$ &0.86 (0.03) &0.06 (0.08)&0.86 (0.04) &0.060\\\\\n                1c&$n=100$ &0.91 (0.02) &0.02 (0.03)&0.92 (0.02)&0.050\\\\     \n          &$n=100$, $p=4000$ &0.92 (0.05) &0.02 (0.04)&0.97 (0.05) &0.064\\\\     \n           \n  & & &&&\\\\\n                   &$n=50$&0.83 (0.03)&0.05 (0.08)&0.84 (0.04)&0.046\\\\\n                   1d&$n=100$ & 0.86 (0.02)  &0.00 (0.00)&0.97 (0.01)&0.062\\\\     \n           &$n=100$, $p=4000$ &0.88 (0.05)&0.00 (0.00)&0.97 (0.05)&0.044\\\\ \n   & & &&&\\\\ \n  \\hline\n  & & &&&\\\\   \n &$n=50$ & 0.64 (0.13) &0.50 (0.15)&0.76 (0.16) &0.936\\\\\n             2a &$n=100$ & 0.68 (0.10)   &0.60 (0.12) & 0.91 (0.11)&0.997\\\\     \n            &$n=100$, $p=4000$ &  0.89 (0.05)&0.59 (0.08)&0.93 (0.06) &0.996\\\\         \n  & & &&&\\\\ \n  \n   &$n=50$ &0.84 (0.04)  &0.16 (0.11)&0.93 (0.04) &0.236\\\\                            \n               2b &$n=100$ &0.87 (0.03)&0.11 (0.06)&0.95 (0.01) &0.712\\\\     \n          & $n=100$, $p=4000$& 0.88 (0.02)& 0.10 (0.06)& 0.94 (0.03) &0.652\\\\  \n  & & &&&\\\\ \n     &$n=50$ &0.28 (0.07)  &0.11 (0.11)&0.36 (0.11) &0.184\\\\          \n2c &$n=100$ &   0.09 (0.08)  &0.01 (0.00) &0.13 (0.16) &0.186\\\\     \n    &$n=100$, $p=4000$ &0.16 (0.09)&0.08 (0.06)&0.52 (0.09) &0.526\\\\ \n  & & &&&\\\\          \n  \\hline              \n    \\end{tabular}\n  \\label{tab:addlabel}\n}\\end{table}\n\n\n\n\n\n\n\\subsubsection{Lasso regression}\nTable 2 shows the results for double cross-validation procedure based on the lasso specification ($\\alpha=1$). With regard to the `null' scenarios, we observe a good performance for scenarios 1a and 1b, with rejection proportions close to the nominal level. Interestingly, the rejection proportion of the permutation test increases with sample size and the number of features in the first source in scenarios 1c and 1d, which indicates a bad performance of the procedure based on laso regression in these settings. Namely, the bad performance of the lasso specification for scenario 1d does not improve by increasing sample size (7\\% of rejections with $n=50$, 9\\% of rejections with $n=100$ and 36\\% of rejections for $p=4000$). The reason behind this difference with the ridge-based results is the miss-specification of the lasso with respect to the underlying  generating-data mechanism. Lasso regression assumes that the true model is sparse, while,  as mentioned, scenario 1c and specially 1d correspond to non-sparse solutions.\n\nThese findings illustrate how model miss-specification may result in an improvement of predictions by adding a second source of predictors, not because of independent association to the outcome, but just because of the correlation with the first source of predictors.  \n\nThe bottom part of Table 1 shows the results for the alternative scenarios.\nWith respect to the alternative scenarios (bottom part of Table 2), the conclusions are similar to those observed  for ridge regression. The power increases with the sample size, and the rejection proportions differ across the three scenarios. However, we observe that ridge outperforms lasso in terms of power, specially for scenarios 2a and 2b.\n\n\\begin{table}[htbp]\n  \\centering\n  {\\footnotesize\n  \\caption{Lasso ($\\alpha=1$). Mean estimates (and standard deviation in brackets) of $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$  and rejection proportions of the permutation test based on  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ along 500 Monte Carlo trials.}\n    \\begin{tabular}{cc|c|c|c|c}\n    \\\\\n    \n      \\hline\n    {\\footnotesize Scenario} & $n$&$Q_{\\mathbf{X}_{1}}^2$ (Step 1)    & $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$ (Step 2)& $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^ 2$ (Global)&{Rej. Prop.} \\\\\n          \\hline \n            & & &&&\\\\   \n             & $n=50$&0.79 (0.06)  &0.15 (0.14)&0.88 (0.05) &0.058\\\\ \n             1a &$n=100$ &  0.86 (0.03)  &0.05 (0.06)&0.91 (0.03)&0.054\\\\     \n           & $n=100$, $p=4000$&0.89 (0.02)  &0.10 (0.06)&0.95 (0.01) &0.140\\\\\n  & & &&&\\\\ \n   &$n=50$ &0.18 (0.11) &0.08 (0.12)&0.27 (0.16) &0.056\\\\\n              1b  &$n=100$ & 0.33 (0.09)  &0.02 (0.04)&0.35 (0.09) &0.056\\\\     \n           &$n=100$, $p=4000$ &0.44(0.07) &0.03 (0.05)&0.45 (0.07) &0.058\\\\\n   & & &&&\\\\\n     & $n=50$&0.80 (0.05) &0.12 (0.13)&0.84 (0.05) &0.054\\\\ \n                1c&$n=100$ & 0.89 (0.02)  &0.04 (0.05)&0.90 (0.03) &0.068\\\\     \n             &$n=100$, $p=4000$&0.85 (0.28) &0.13 (0.09)&0.90 (0.03) &0.352\\\\ \n  & & &&&\\\\ \n   &$n=50$&0.67 (0.06)&0.14 (0.12)&0.72 (0.07)&0.070\\\\ \n                1d   &$n=100$ & 0.83 (0.03)   &0.05 (0.05)&0.85 (0.03)&0.094\\\\     \n           &$n=100$, $p=4000$ &0.73 (0.04)&0.12 (0.09)&0.78 (0.04)&0.360\\\\ \n          & & &&&\\\\   \n  \\hline\n    & & &&&\\\\ \n       & $n=50$& 0.58 (0.09) &0.44 (0.14)&0.69 (0.13) &0.768\\\\         \n             2a  &$n=100$ &0.67 (0.07)   &0.53 (0.09)&0.90 (0.03)&1.000\\\\     \n           & $n=100$, $p=4000$&0.84 (0.04)  &0.47 (0.09)& 0.84 (0.06)&1.000\\\\         \n    & & &&&\\\\  \n     & $n=50$&0.77 (0.07) &0.21 (0.15) &0.89 (0.06)  &0.106\\\\  \n               2b &$n=100$ & 0.84 (0.04)  &0.12 (0.09)&0.92 (0.02) &0.481\\\\     \n         &$n=100$, $p=4000$ &0.83 (0.02) &0.18 (0.09) &0.96 (0.02) &0.506\\\\ \n    & & &&&\\\\ \n     & $n=50$&0.15 (0.10)&0.12 (0.13)&0.28 (0.17) &0.086\\\\\n                2c &$n=100$ &0.27 (0.09)   &0.09 (0.07) &0.33 (0.11)&0.351\\\\     \n    &$n=100$, $p=4000$&0.07 (0.07)&0.06 (0.06)&0.43 (0.07) &0.227\\\\     \n     & & &&&\\\\          \n  \\hline       \n    \\end{tabular}\n  \\label{tab:addlabel}\n}\\end{table}\n\n\\subsubsection{Alternative procedures}\nTables S2 and S3 summarize the results for the two aforementioned alternative strategies in the basic setting ($p=1000$, $q=100$) and two sample sizes ($n=50$, $n=100$):  `$CV_{D}$, $\\lambda_{1se}$' corresponds to the strategy in which the sequential double cross-validation is over-shrunk (by taking $\\lambda_{opt}+1s.e.(\\lambda_{opt})$ instead of $\\lambda_{opt}$ in the inner cross-validation loop) and `$CV_{S}$, $\\lambda_{opt}$' represents the sequential procedure based on one single cross-validation loop (standard residuals as opposed to deletion-based residuals). \n\nIn general, these two alternative strategies provide different estimates for the predictive ability of the two studied sources of predictors. Taking the double-cross validation approach  as gold-standard, we observe that the over-shrinkage of the predictions in the first step of the `$CV_{D}$, $\\lambda_{1se}$' method provokes an under-estimation of $Q_{\\mathbf{X}_{1}}^{2}$, while the `$CV_{S}$, $\\lambda_{opt}$' provides an over-estimation, specially when the association between outcome and first source of predictors is driven through a low-variance space. For example, in the scenario 1b, for $n=100$, $Q_{\\mathbf{X}_{1}}^{2}=0.69$ when based on a single cross-validation approach, notably larger than $Q_{\\mathbf{X}_{1}}^{2}=0.41$ estimated by the double cross-validation approach.   Moreover, we observe that the effect of re-using the data is larger for small sample sizes, with systematically larger $Q_{\\mathbf{X}_{1}}^{2}$ for $n=50$ than for $n=100$. However, under the null hypothesis, the introduced bias on the first step for both alternatives does not translate in an inflated type I error. The method labeled as `$CV_{D}$, $\\lambda_{1se}$', based on double cross-validation but based on under-fitting by over-penalization controls the false discovery rate under the null hypothesis in similar fashion than the procedure introduce in Subsection 2.1. With regard to the method based on single cross-validation (`$CV_{S}$, $\\lambda_{opt}$'), its behavior is slightly conservative under the null hypothesis. \n\n\nFor the alternative scenarios, as $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ and $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}$, are underestimated by `$CV_{D}$, $\\lambda_{1se}$', while `$CV_{S}$, $\\lambda_{opt}$' overfits both. Even if power increases with sample size, both methods are systematically less powerful than our proposal,`$CV_{D}$, $\\lambda_{opt}$, which makes it the preferable method from both an estimation and testing point of view.  \n\n\n\n\\section{Application: DILGOM data}\nTo illustrate the performance of the sequential double cross-validation procedure introduced in Section 2, and to compare it to the alternative strategies discussed in Section 3, we analyzed data from the DILGOM study, introduced in Section 1. We are interested in getting insights on the role of two different omic sources in the prediction of the body mass index (BMI), using serum NMR metabolites measures on the one hand and gene expression levels on the other. The metabolomic predictor data consists of quantitative information on 139 metabolic measures, mainly composed of measures on different lipid subclasses, but also amino acids, and creatine. The gene expression profiles were derived from Illumina 610-Quad SNParrays (Illumina Inc., San Diego, CA, USA). Initially, 35,419 expression probes were available after quality filtering. In addition to the pre-processing steps described by \\cite{Inouye1}, we conducted a prior filtering approach and removed from our analyses those probes with extremely low variation (see \\cite{Liu} for details on the conducted pre-processing). As a result, we retained measures from 7380 beads for our analyses. The analyzed sample contained $n=406$ individuals for which both types of omic measurements and the outcome of interest (BMI log-transformed) were available. We carried out two distinct analyses using the augmented assessment approach described in this paper. As a first analysis, we consider the metabolic profile as primary omic source for the prediction of BMI and evaluated the added value of the blood gene expression profiles. In a second analysis, we reversed the roles of the omic sources,  first fitting a model based on gene expression. We then evaluated  the added value of the metabolome. As in the simulation study, we considered ridge and lasso regression as prediction models, using the same alternative strategies to the sequential double cross-validation procedure presented in section 3 (`$CV_{D}$, $\\lambda_{opt}$'): `$CV_{D}$, $\\lambda_{1se}$', and `$CV_{S}$, $\\lambda_{opt}$'. The main findings are summarized in Table 3. Additionally, we conducted a sensitivity analysis to check the impact of the sample size on the estimation of the predictive ability of each of the considered sources of predictors. Namely, we reduced the sample size of the DILGOM data in order to check the robustness of the results based on the sequential double cross-validation procedure. The additional results of the sensitivity analysis are given as Supplemental material.\n\n\n\n\n\\begin{table}[htbp]\n  \\centering\n  \\caption{Application to DILGOM data. Alternative cross-validation strategies. P-values based on 1000 permutations}\n    \\begin{tabular}{cc|c|c|c|c}\n    \n      \\hline\n      \n\n $\\alpha$&CV type&$Q_{Metab}^2$ & $Q_{GE|Metab}^2$&$Q_{Metab,GE}^2$&p-value \\\\\n          \\hline\n          & &&   &  &\\\\  \n$\\alpha=0$&$CV_{D}$,$\\lambda_{opt}$ & 0.365& 0.068  & 0.476 &$<0.001$\\\\\n$\\alpha=0$&$CV_{D}$,$\\lambda_{1se}$ &0.211& 0.014  & 0.235 &$<0.001$\\\\    \n$\\alpha=0$&$CV_{S}$,$\\lambda_{opt}$ & 0.348& 0.103  & 0.484 &$<0.001$\\\\    \n & &&   &  &\\\\\n$\\alpha=1$&$CV_{D}$,$\\lambda_{opt}$ & 0.384& 0.113  & 0.526 &$<0.001$\\\\\n$\\alpha=1$&$CV_{D}$,$\\lambda_{1se}$ & 0.178&0.048  & 0.250&$<0.001$\\\\    \n$\\alpha=1$&$CV_{S}$,$\\lambda_{opt}$ &0.382 &0.110   & 0.526&0.001\\\\    \n & &&   &  &\\\\\n   \\hline\n $\\alpha$&CV type&$Q_{GE}^2$ & $Q_{Metab|GE}^2$&$Q_{GE,Metab}^2$&p-value \\\\ \n           \\hline\n          & &&   &  &\\\\   \n$\\alpha=0$&$CV_{D}$,$\\lambda_{opt}$ & 0.102& 0.271  & 0.446&$<0.001$\\\\ \n   $\\alpha=0$&$CV_{D}$,$\\lambda_{1se}$ &0.051 & 0.164  & 0.250 &$<0.001$\\\\    \n$\\alpha=0$&$CV_{S}$,$\\lambda_{opt}$&0.134 &0.264 & 0.450  &$<0.001$ \\\\    \n & &&   &  &\\\\\n$\\alpha=1$&$CV_{D}$,$\\lambda_{opt}$ & 0.295& 0.215  & 0.613&$<0.001$\\\\ \n$\\alpha=1$&$CV_{D}$,$\\lambda_{1se}$ &0.119 &0.092   &0.265  &$<0.001$\\\\    \n$\\alpha=1$&$CV_{S}$,$\\lambda_{opt}$ &0.338 &0.188  & 0.590 &$<0.001$\\\\ \n  \\hline\n    \\end{tabular}\n  \\label{tab:addlabel}\n\\end{table}\n\n\nIn Table 3, we observe that both gene expression and metabolome present significant added value for the prediction of the log-transformed BMI. However, the size of the augmented value differs according to the choice in the order of the two omic sources under investigation since $Q^{2}_{Metab|GE}$ and $Q^{2}_{GE|Metab}$ summarize two different sequential procedures and their interpretation also differs. For ridge regression, we obtained a 4-fold larger added value of metabolome on top of transcriptomics than when considering the metabolites as primary source, the magnitude of the difference is less pronounced for lasso regression, but still $Q^{2}_{Metab|GE}$ is almost twice larger than $Q^{2}_{GE|Metab}$. These results also illustrate that the chosen penalty type affects the estimation of the added value. Using ridge regression we estimate the added predictive value of the gene expression on top of the metabolome to be only 7\\%, while the metabolome explains about 27\\% of the remaining variation of the outcome after accounting for the ridge-regression-based prediction calibration using gene expression data.  When using lasso regression, the estimated augmented value of gene expression is  larger ($Q^{2}_{GE|Metab}=0.113$), while the added value of the metabolome is slightly smaller as compared to ridge regression ($Q^{2}_{Metab|GE}=0.215$). These results are supported by our sensitivity analysis consisting of artificially reducing the sample size of the available DILGOM data to check the stability of the estimated added predictive ability of the considered omic sources, measured through $Q_{Metab|GE}^{2}$ and $Q_{GE|METAB}^{2}$. In Table S1 and Figure S1, we observe that the results based on a random subsample of the data of $n=200$ individuals are similar to those obtained with the actual sample, which indicates that the estimated added predictive values shown in Table 3 are reflecting the independent contribution of the secondary source in the prediction of BMI and not the effect of recalibrating the primary source through the second one due to scarcity of data in the first stage. That seems to be the case if we consider a random subsample of the DILGOM data of $n=100$, when the added predictive ability of the secondary source is presumably overestimated due to the underestimation of the predictive ability of the primary source in the first stage of the procedure. With regard to the alternative strategies, Table 3 shows that the use of a single cross-validation approach slightly overestimates the added value of the studied sources, while the over-shrinkage of the penalty parameter in the inner loop of the double cross-validation (`2CV, $\\lambda_{1se}$') leads to a more pessimistic estimation of the summary measures in each of the steps of the procedure, particularly when using ridge regression and the case where the gene expression is the second source to be considered  ($Q^{2}_{GE|Metab}=0.014$). According to our results, a cautious interpretation might suggest that the metabolomics data could  be prioritized  if the goal is to predict BMI, while the additional consideration of transcriptomics seems to be of little value. \n\n\n\n\\section{Summary and discussion}\nThis paper  has addressed the problem of evaluating the augmented value of high-dimensional omic sets in the context of prediction of a given continuous outcome of interest. \n\nWhile our paper has focused on application in high-dimensional (omic) data problems,  the methodology is also directly relevant and applicable to more classical biostatistical applications, where the predictor sets may be of smaller dimensionality. A good example is that of adding a novel (biomolecular) marker set or new omic source over a set of clinical parameters or in addition to an established risk score,  such as a Framingham,  Karnofsky or ECOG score \\cite{preval1, preval2, boosting}. \n\n\n\n\nBecause of the close connection with classical clinical biostatistics,  we have taken care to emphasize the difference between the so-called {\\it internal} versus {\\it external} data augmentation scenarios we introduced in the introduction. In classical low-dimensional applications, the external augmentation scenario may be more common, particularly in the case of adding new information to established risk scores. \n\nHowever,  we expect that for omics research the internal augmentation scenario will be most relevant.  This is because of the large number of distinct omics measures for assessing different levels of human biology now available. This development is now causing the expansion of many clinical databases with sequences of novel biomarker measure sets,  evaluated on the same patients,  and clustered by measurement type and the distinct biological processes which they target,  as for the Finrisk (DILGOM) which we analysed in this paper. \n\nClosely connected to the difference between the internal and external augmentation,  is the issue of choice between standard classic (lack-of-fit) residuals and the deletion-prediction residuals employed in this paper.  Use of standard residuals may suffice when adding novel predictor data to an established and known (external) risk score,  but in general greater caution should be applied.  Nevertheless,  use of standard residuals from previous model fitting when assessing added-value still seems to be the norm in most analyses. This applies not only to biostatistics,  but also to related fields such as chemometrics \\cite{Martens}.   \n\n\nEven if classical residuals may be useful in low-level exploratory analysis of complex omic datasets, they may be highly misleading when applied in the prediction context.\n\nWe have shown through simulations and the analysis of the DILGOM data that use of deletion-residuals is essential to avoid substantial bias in the assessment of the added value of a secondary predictor set,  when added to a primary set using the same patient data. Failure to do so renders results essentially meaningless and non-interpretable. \n\n\n\nAnother feature of the deletion residuals is that they do not only account for the predictive capacity of the first predictor set,  but are also dependent on model choice and fitting procedure employed (and any errors or inappropriate choices therein). Hence, our augmented prediction assessment is not just evaluating the predictive impact of a secondary set of measurements in its own right,  but rather the joint impact of choice of predictors,  model and estimation approach.  This must of course not be taken as a criticism of the approach, but rather on the contrary, predictive assessment can only be conditional on choices of models and estimation approach.  \n\n\nAn unavoidable consequence of this is that any assessment will necessarily depend on the {\\it chosen} order of adding predictors to a model,  within the sequential approach,  and thus results may differ depending on whether a given predictor set is added sooner rather than later to the predictor.  Indeed,  we should expect any reasonable statistical approach to the assessment of added predictive value to have sensitivity to the order of addition of predictors as a property. \n\nWe have applied the augmented assessment methodology to evaluate the predictive capacities of transcriptomics and metabolomics measures for the prediction of BMI. Our results suggest that transcriptomics are of little use for augmentation of predictions which are already utilizing the  metabolomics expression. The reverse is not true, as enriching a predictor with metabolomics measures leads to more accurate predictions as compared to predictors using the transcriptomics measures only. Given the cross-sectional nature of the study and the non-invasive nature of the BMI determination, our analysis may be regarded as a proof of concept of our methodology. The application of our method to other omic predictors and outcomes in prospective studies (e.g., to predict BMI in 10 years or memory function in old age) given baseline omic information may potentially help to the understand the role of different molecular levels from a predictive point of view.\n\n\nThe present work may be extended in several directions. \n\n\nThe two-step sequential approach presented for continuous outcome may also be immediately extended to other outcome types, particularly to the classification context (binary outcome) and to time-to-event data, for which generalisations of linear regularized regression in high-dimensional settings are available. \n\nMoreover, in the implementation of the augmented assessment method, alternative prediction rules could also be used, beyond linear regularized regression considered here. Boosting algorithms might be an interesting choice worthy of further study in the high-dimensional augmented predictive framework, as an extension of \\cite{boosting}. Also, investigation  of more complex model specifications, such as the inclusion of  non-linear and interaction terms \\cite{Mar} are left as future research.\n\n\\section*{Acknowledgements}\nWork supported by Grant Grant MIMOmics of the European Union's\nSeventh Framework Programme (FP7-Health-F5-2012) number 305280.\n    \n\\begin{thebibliography}{99}\n\n\n\\bibitem[\\protect\\citeauthoryear{Tibshirani and Efron}{2002}]{preval1}\nTibshirani, R.J., and Efron, B. \nPre-validation and inference in microarrays.\n{\\em Statistical Applications in Genetics\nand Molecular Biology} 2002; {\\bfseries 1}: Art. 1.\n\n\\bibitem[\\protect\\citeauthoryear{Hoefling and Tibshirani}{2008}]{preval2}\nHoefling, H., and Tibshirani, R.J. \nA study of pre-validation.\n{\\em The Annals of Applied Statistics} 2008; {\\bfseries 2}: 643--664. \n\n\n\\bibitem[\\protect\\citeauthoryear{Inouye et ~al.}{2010}]{Inouye1}\nInouye, M., Kettunen, J., Soininen, P., Silander, K., Ripatti, S. et ~al. \nMetabonomic, transcriptomic, and genomic variation\nof a population cohort.\n{\\em Molecular Systems Biology} 2010; {\\bfseries 6}: 441.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Zoldos et ~al.}{2013}]{Zoldos}\nZoldos, V., Horvat, T., and Lauc, G.\nGlycomics meets genomics, epigenomics and other high throughput omics for system biology studies.\n{\\em Current Opinion in Chemical Biology} 2013; {\\bfseries 17}: 34--40.\n\n\\bibitem[\\protect\\citeauthoryear{Leblanc and Tibshirani}{1996}]{Leblanc}\nLeblanc, M., and Tibshirani, R.\nCombining Estimates in Regression and Classification\n{\\em Journal of the American Statistical Association} 1996; {\\bfseries 91}: 1641--1650.\n\n\n\\bibitem[\\protect\\citeauthoryear{van der Laan, Polley and Hubbard}{2007}]{superlearner}\nvan der Laan, M.J., Polley, E.C., and Hubbard, A.E.\nSuper Learner.\n{\\em U.C. Berkeley Division of Biostatistics Working Paper Series} 2007; {\\bfseries  Working Paper 222.}\n\n\\bibitem[\\protect\\citeauthoryear{Kakourou, Vach and Mertens}{2014}]{Alexia}\nKakourou, A., Vach, W., and Mertens B.\nCombination Approaches Improve Predictive Performance of\nDiagnostic Rules for Mass-Spectrometry Proteomic Data.\n{\\em Journal of Computational Biology} 2014; {\\bfseries 21}: 898--914.\n\n\\bibitem[\\protect\\citeauthoryear{Stone}{1974}]{Stone}\nStone, M.\nCross-validatory choice and assessment of statistical predictions\n(with discussion).\n{\\em Journal of the Royal Statistical Society. Series B} 1974; {\\bfseries 36}: 111--147.\n\n\\bibitem[\\protect\\citeauthoryear{Jonathan et ~al.}{2000}]{Jonathan}\nJonathan, P., Krzanowski, W.J., and McCarthy, M.V.\nOn the use of cross-validation to assess\nperformance in multivariate prediction.\n{\\em Statistics and Computing} 2000; {\\bfseries 10}: 209--229.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Varma and Simon}{2006}]{Varma}\nVarma, S., and Simon, R.\nBias in error estimation when using cross-validation for model\nselection.\n{\\em BMC Bioinformatics} 2006; {\\bfseries 7}: 91.\n\n\\bibitem[\\protect\\citeauthoryear{Breiman}{1996}]{Breiman}\nBreiman, L. Stacked regressions.\n{\\em Machine Learning} 1996; {\\bfseries 24}: 49--64.\n\n\\bibitem[\\protect\\citeauthoryear{Mertens}{2003}]{Mertens0}\nMertens, B.J.A.  Microarrays, pattern recognition and exploratory data analysis.\n{\\em Statistics in Medicine} 2003; {\\bfseries 22}: 1879--1899\n\n\n\\bibitem[\\protect\\citeauthoryear{Mertens et ~al.}{2006}]{Mertens1}\nMertens, B.J.A., de Noo, M.E., Tollenaar, R.A.E.M. and Deelder, A.M.\nMass Spectrometry Proteomic Diagnosis: Enacting the Double CrossValidatory\nParadigm.\n{\\em Journal of Computational Biology} 2006; {\\bfseries 13}: 1591--1605.\n\n\n\\bibitem[\\protect\\citeauthoryear{Mertens et ~al.}{2011}]{Mertens2}\nMertens, B.J.A., van der Burgt, Y.E.M., Velstra, B., Mesker, W.E., Tollenaar, R.A.E.M., and Deelder, A.M. \nOn the use of double cross-validation for the combination of proteomic\nmass spectral data for enhanced diagnosis and prediction.\n{\\em Statistics and Probability Letters} 2011; {\\bfseries 81}: 759--766.\n\n\\bibitem[\\protect\\citeauthoryear{Hastie, Tibshirani and Friedman}{2001}]{Hastie1}\nHastie, T., Tibshirani, R., and Friedman, J.\n{\\em Elements of Statistical Learning: Data Mining, Inference, and\nPrediction.}\nNew York: Springer Series in Statistics, 2001.\n\n\\bibitem[\\protect\\citeauthoryear{Hoerl and Kennard}{1970}]{Hoerl}\nHoerl, A.E., and Kennard, R. \nRidge regression: Biased\nestimation for nonorthogonal problems.\n{\\em Technometrics} 1970; {\\bfseries 12}: 55--67.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Tibshirani}{1996}]{Tibshirani1}\nTibshirani, R.\nRegression Shrinkage and Selection via the Lasso.\n{\\em Journal of the Royal Statistical Society. Series B (Methodological)} 1996; {\\bfseries 58}: 267--288.\n\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Zou and Hastie}{2005}]{Zou}\nZou, H., and Hastie, T.\nRegularization and Variable Selection via the Elastic Net.\n{\\em Journal of the Royal Statistical Society. Series B} 2005; {\\bfseries 67}: 301--320.\n\n\n\\bibitem[\\protect\\citeauthoryear{Tutz and Binder}{2006}]{Tutz}\nTutz, G., and Binder, H.\nGeneralized additive modeling with implicit variable selection by likelihood-based boosting.\n{\\em Biometrics} 2006; {\\bfseries 62}: 961-971.\n\n\\bibitem[\\protect\\citeauthoryear{B\\\"{u}hlmann  and Hothorn}{2007}]{Buhlmann}\nB\\\"{u}hlmann, P., and Hothorn, T.\nBoosting algorithms: regularization, prediction and model fitting.\n{\\em Statistical Science} 2007; {\\bfseries 22}: 477-505.\n\n\\bibitem[\\protect\\citeauthoryear{Kneib, Hothorn and Tutz}{2009}]{Kneib}\nKneib, T., Hothorn, T., and Tutz, G.\nVariable selection and model choice in geoadditive regression models.\n{\\em Biometrics} 2009; {\\bfseries 65}: 626-634.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Schemper}{2003}]{Schemper}\nSchemper, M.\nPredictive accuracy and explained variation.\n{\\em Statistics in Medicine} 2003; {\\bfseries 22}: 2299--2308.\n\n\\bibitem[\\protect\\citeauthoryear{Westerhuis et ~al.}{2008}]{Westerhuis}\nWesterhuis, J.A., Hoefsloot, H.C.J., Smit, S., Vis, D.J., Smilde, A.K., van Velzen, E.J.J., van Duijnhoven, J.P.M., and van Dorsten, F.A. \nAssessment of PLSDA cross validation.\n{\\em Metabolomics} 2008; {\\bfseries 4}: 81--89.\n\n\n\\bibitem[\\protect\\citeauthoryear{Steyerberg et ~al.}{2004}]{Steyerberg}\nSteyerberg, E.W., Borsboom, G.J.J.M., van Houwelingen, H.C., Eijkemans, M.J.C., and Habbema, J.D.F.  \nValidation and updating of predictive logistic regression\nmodels: a study on sample size and shrinkage.\n{\\em Statistics in Medicine} 2004; {\\bfseries 23}: 2567--2586.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Jolliffe}{2002}]{Jolliffe}\nJolliffe, I.T. (2008)  {\\em Principal component analysis}. Springer-Verlag,\nNew York, second edition.\n\n\n\\bibitem[\\protect\\citeauthoryear{Zhang and Horvath}{2005}]{Zhang}\nZhang, B. and Horvath, S.\nA general framework for weighted gene co-expression network analysis.\n{\\em Statistical Applications in Genetics and Molecular Biology} 2005; {\\bfseries 4}: Art. 17, 45pp (electronic).\n\n\n\\bibitem[\\protect\\citeauthoryear{Hardin et ~al.}{2013}]{Hardin}\nHardin, J., Garc\\'{i}\u00c2\u00ada, S.R. and  Golan, D.\nA method for generating realistic correlation matrices. \n{\\em The Annals of Applied Statistics} 2013; {\\bfseries 7}: 1733--1762.\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Liu et ~al.}{2014}]{Liu}\nLiu, H., D'Andrade , P., Fulmer-Smentek, S., Lorenzi, P., Kohn, K.W., Weinstein, J.N., Pommier, Y., and Reinhold, W.C. mRNA and microRNA expression profiles of the NCI-60 integrated with drug activities\n{\\em Mol Cancer Ther} 2010; {\\bfseries 9}: 1080--1091.\n\n\n\\bibitem[\\protect\\citeauthoryear{Boulesteix and Hothorn}{2010}]{boosting}\nBoulesteix,A-L., and Hothorn, T.\nTesting the additional predictive value of\nhigh-dimensional molecular data.\n{\\em BMC Bioinformatics} 2010; {\\bfseries 11}: 78. \n\n\\bibitem[\\protect\\citeauthoryear{Martens}{1989}]{Martens}\nMartens, H. and Naes, T. {\\em Multivariate calibration.} Willey \\& Sons, 1989.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\bibitem[\\protect\\citeauthoryear{Rodr\\'{i}\u00c2\u00adguez-Girondo et ~al.}{2013}]{Mar}\nRodr\\'{i}\u00c2\u00adguez-Girondo, M., Kneib, T., Cadarso-Su\\'{a}rez, C., and Abu-Assi, E.\nModel building in nonproportional hazard regression.\n{\\em Statistics in Medicine} 2013; {\\bfseries 32}: 5301--5314.\n\n\n\n\n\n\n\n\n\\end{thebibliography}\n\n\n\\beginsupplement\n\\section*{SUPPLEMENTAL MATERIAL}\n\n\n\\subsection*{Supplement A. Application to DILGOM data. Sensitivity analysis}\n\nSensitivity analysis to check the impact of the sample size on the estimation of the predictive ability of each of the considered sources of predictors for BMI in the DILGOM data. The sample size is reduced ($n=50$, $n=100$, $n=200$) in order to check the robustness of the results based on the sequential double cross-validation procedure.\n\n\\begin{table}[h]\n  \\centering\n  \\caption{Application to DILGOM data. Sensitivity analysis: check impact of sample size. P-values based on 1000 permutations}\n    \\begin{tabular}{cc|c|c|c|c}   \n      \\hline\n      \n\n& CV type&$Q_{Metab}^2$ & $Q_{GE|Metab}^2$&$Q_{G}^2$&p-value \\\\\n          \\hline\n  \n$n=406$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ & 0.365& 0.068  & 0.476 &$<0.001$\\\\    \n$n=200$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ & 0.323& 0.069   & 0.394 &$<0.001$\\\\    \n$n=100$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ & 0.125& 0.131 & 0.217 &$<0.001$\\\\    \n$n=50$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ & 0.100& 0.058 & 0.218 &0.117\\\\                   \n  \\hline\n$n=406$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.384 & 0.113 &0.526  &$<0.001$\\\\    \n$n=200$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.318 & 0.098   &0.447  &0.012\\\\    \n$n=100$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.163 &0.355  & 0.420 &0.002\\\\    \n$n=50$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.246 & 0.142 & 0.441 &0.159\\\\  \n  \\hline\n  \\hline\n& CV type&$Q_{GE}^2$ & $Q_{Metab|GE}^2$&$Q_{G}^2$& p-value\\\\\n          \\hline\n $n=406$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ &0.102 & 0.271 &0.446  &$<0.001$\\\\    \n$n=200$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ &0.101& 0.243  &0.406  &$<0.001$\\\\    \n$n=100$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ & 0.104&0.061  &0.174  &$<0.001$\\\\    \n$n=50$&$\\alpha=0$,$CV_{D}$,$\\lambda_{opt}$ &0.002 &0.039  &0.043  &0.065\\\\   \n          \\hline\n $n=406$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.295 & 0.215 &0.613  &$<0.001$\\\\    \n$n=200$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.312 & 0.149   & 0.566 &0.004\\\\    \n$n=100$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ & 0.071&0.256  &0.398  &0.002\\\\    \n$n=50$&$\\alpha=1$,$CV_{D}$,$\\lambda_{opt}$ &0.099 & 0.096&0.027  &0.214\\\\   \n  \\hline\n    \\end{tabular}\n  \\label{tab:addlabel}\n\\end{table}\n\n\\begin{figure}[htb]\n\\begin{minipage}{0.45\\linewidth}\n\\includegraphics[width=7cm,height=7cm]{DILGOM_Sensitivity1.pdf}\n\\end{minipage}\n\\begin{minipage}{0.45\\linewidth}\n\\includegraphics[width=7cm,height=7cm]{DILGOM_Sensitivity2.pdf}\n\\end{minipage}\n\\caption{Application to DILGOM data. Sensitivity analysis to investigate the impact of sample size on the predictive ability and added value. Left: Evaluation of added predictive value of transcriptomics (GE) on top of metabolomics (Metab). Right: Evaluation of added predictive value of metabolomics (Metab) on top of transcriptomics (GE).}\n\\end{figure}\n\n\\newpage\n\\subsection*{Supplement B. Simulation study. Alternative approaches}\nSimulation results based on two modification of the two-stage procedure presented in Section 2: $CV_{S}$,$\\lambda_{opt}$ relies on single cross-validation (cross-validation is used for model choice but predictions and therefore the residuals used as outcome in the second stage are directly computed on the complete sample); $CV_{D}$,$\\lambda_{1se}$ relies on  over-penalization. Specifically, instead of taking $\\lambda_{opt}$ as defined in the inner loop of the double cross-validation procedure presented in Subsection 2.1., we choose a larger value for $\\lambda$, namely $\\lambda_{opt}+1 s.e.(\\lambda_{opt})$. Simulations for these two approaches are based on the same specifications detailed in Subsection 3.1., considering $p=1000$ and $q=100$.\n\n\\begin{table}[h]\n\\label{TableS1}\n  \\centering\n  \\caption{Ridge ($\\alpha=0$). Mean estimates (and standard deviation in brackets) of $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$  and rejection proportions of the permutation test based on  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ along 500 Monte Carlo trials. $p=1000$, $q=100$.}\n \\begin{tabular}{cc|c|c|c|c}\n    \\\\\n    \n      \\hline\n    {\\footnotesize Scenario} & CV type&$Q_{\\mathbf{X}_{1}}^2$ (Step 1)    & $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$ (Step 2)& $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^ 2$ (Global)&{Rej. Prop.} \\\\   \n          \\hline \n             & & &&&\\\\   \n                &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.70 (0.13) &0.02 (0.07)&0.73 (0.09)&0.048\\\\  \n      1a      &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.76 (0.09) &0.00 (0.03)&0.77 (0.07)&0.030\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.95 (0.03)&0.06 (0.12)&0.97 (0.00) &0.014  \\\\\n                 &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.92 (0.02)&0.02 (0.03)&0.98 (0.01) &0.016  \\\\\n    & & &&&\\\\\n          &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.09 (0.08) &0.00 (0.01) &0.10 (0.07)&0.042\\\\\n          1b   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.16 (0.09) &0.00 (0.00) &0.16 (0.09)&0.074\\\\ \n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.87 (0.16) &0.04 (0.11)&  0.98 (0.10)&0.048\\\\\n              &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.69 (0.13) &0.01 (0.03)&  0.94 (0.05)&0.018\\\\\n & & &&&\\\\   \n     &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.79 (0.04) &0.00 (0.02)&0.79 (0.04)  &0.034\\\\\n           1c   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.84 (0.02) &0.00 (0.01)&0.84 (0.02)  &0.056\\\\\n             &$n=50$, $CV_{S}$,$\\lambda_{opt}$ & 0.97 (0.01) &0.04 (0.10)&0.99 (0.00) &0.014\\\\\n            &$n=100$, $CV_{S}$,$\\lambda_{opt}$ & 0.95 (0.02) &0.02 (0.04)&0.99 (0.00) &0.012\\\\\n & & &&&\\\\\n     &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.79 (0.04) &0.00 (0.02)&0.79 (0.04)&0.056\\\\\n           1d   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.86 (0.02) &0.00 (0.00)&0.86 (0.02)&0.044\\\\\n             &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &  0.97 (0.00) &0.04 (0.10)& 0.99 (0.00)  &0.028\\\\\n            &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &  0.97 (0.01) &0.01 (0.03)& 0.99 (0.00)  &0.020\\\\\n            & & &&&\\\\ \n  \\hline\n     & & &&&\\\\\n         &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.04 (0.09)  &0.01 (0.02) & 0.05 (0.09) &0.088\\\\\n           2a   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.02 (0.06)  &0.01 (0.01) & 0.01 (0.07) &0.073\\\\\n            &$n=50$,$CV_{S}$, $\\lambda_{opt}$ &0.75 (0.21) &0.61 (0.16) &  0.94 (0.18)&0.746\\\\\n            &$n=100$,$CV_{S}$, $\\lambda_{opt}$ &0.74 (0.12) &0.66 (0.10) &  0.96 (0.11)&0.972\\\\\n & & &&&\\\\    \n    &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.61 (0.19) &0.08 (0.13)&0.71 (0.12)&0.170\\\\        \n           2b   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.64 (0.19) &0.01 (0.01)&0.78 (0.24)&0.258\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.94 (0.04)&0.20 (0.15)&0.99 (0.00) &0.116\\\\\n             &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.91 (0.03)&0.14 (0.08)&0.99 (0.01) &0.498\\\\\n & & &&&\\\\  \n    &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.05 (0.06) &0.01 (0.02)&0.06 (0.06) &0.100\\\\  \n           2d   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.08 (0.08) &0.01 (0.01)&0.08 (0.08) &0.217\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.68 (0.21)&0.14 (0.15)& 0.96 (0.10) &0.032\\\\\n             &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.61 (0.14)&0.12 (0.08)& 0.93 (0.06) &0.202\\\\\n             & & &&&\\\\ \n\\hline  \n\\end{tabular}\n  \\label{tab:addlabel}\n\\end{table}\n\n\n\\begin{table}[h]\n\\label{TableS2}\n  \\centering\n  \\caption{Lasso ($\\alpha=1$). Mean estimates (and standard deviation in brackets) of $Q_{\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$, $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^2$  and rejection proportions of the permutation test based on  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ along 500 Monte Carlo trials. $p=1000$, $q=100$.}\n    \\begin{tabular}{cc|c|c|c|c}\n    \\\\\n    \n      \\hline\n    {\\footnotesize Scenario} & CV type&$Q_{\\mathbf{X}_{1}}^2$ (Step 1)    & $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2$ (Step 2)& $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^ 2$ (Global)&{Rej. Prop.} \\\\\n          \\hline   \n            & & &&&\\\\\n               &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.71 (0.07)  &0.05 (0.06)&0.76 (0.06)&0.068\\\\\n           1a   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.79 (0.04)  &0.01 (0.01)&0.81 (0.04)&0.024\\\\\n             &$n=50$, $CV_{S}$,$\\lambda_{opt}$ & 0.93 (0.04)  &0.09 (0.14)&0.99 (0.01) &0.038\\\\\n               &$n=100$, $CV_{S}$,$\\lambda_{opt}$ & 0.92 (0.03)  &0.04 (0.05)&0.98 (0.01) &0.052\\\\\n& & &&&\\\\\n                 &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.05 (0.05)  &0.01 (0.03) &0.07 (0.06) &0.034\\\\ \n           1b   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.15 (0.07)  &0.00 (0.02) &0.15 (0.07) &0.036\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ & 0.46 (0.33)   &0.05 (0.12)&0.73 (0.32) &0.046\\\\\n              &$n=100$, $CV_{S}$,$\\lambda_{opt}$ & 0.51 (0.17)   &0.02 (0.06)&0.83 (0.11) &0.054\\\\\n& & &&&\\\\\n                 &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.73 (0.06) &0.03 (0.06)&0.75 (0.07)&0.078\\\\   \n           1c   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.83 (0.03) &0.01 (0.02)&0.84 (0.03)&0.074\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.96 (0.02) &0.08 (0.15)&1.00 (0.00)&0.012\\\\\n            &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.95 (0.02) &0.03 (0.05)&1.00 (0.01)&0.042\\\\\n& & &&&\\\\\n          &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.60 (0.07)  &0.03 (0.05)&0.61 (0.07)&0.070\\\\\n                  \n           1d   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.78 (0.04)  &0.01 (0.02)&0.78 (0.04)&0.103\\\\\n            &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.96 (0.00)&0.10 (0.15)&0.99 (0.00)  &0.036\\\\\n            &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.96 (0.01)&0.03 (0.06)&0.99 (0.01)  &0.024\\\\\n  & & &&&\\\\\n  \\hline\n  & & &&&\\\\\n     &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.41(0.11) &0.17 (0.12)&0.45 (0.13)  &0.782\\\\\n       2a   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.50 (0.08) &0.28 (0.09)&0.86 (0.05)  &1.000\\\\\n           &$n=50$, $CV_{S}$,$\\lambda_{opt}$ & 0.71 (0.14)  & 0.50 (0.16)& 0.98 (0.03)&0.614\\\\\n            &$n=100$, $CV_{S}$,$\\lambda_{opt}$ & 0.71 (0.08)  & 0.59 (0.09)& 0.97 (0.01)&0.958\\\\\n & & &&&\\\\\n            &$n=50$, $CV_{D}$,$\\lambda_{1se}$ & 0.67 (0.08) &0.08 (0.07)&0.76 (0.07)  &0.130\\\\                  \n           2b   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ & 0.75 (0.05) &0.05 (0.05)&0.92 (0.02)  &0.424\\\\\n             &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.91 (0.05) &0.20 (0.19)&0.99 (0.01)&0.072\\\\\n             &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.90 (0.04) &0.13 (0.13)&0.98 (0.01)&0.380\\\\\n & & &&&\\\\\n           &$n=50$, $CV_{D}$,$\\lambda_{1se}$ &0.03 (0.05)  & 0.02 (0.05)& 0.05 (0.07) &0.098\\\\                 \n           2c   &$n=100$, $CV_{D}$,$\\lambda_{1se}$ &0.10 (0.06)  & 0.01 (0.02)& 0.10 (0.06) &0.283\\\\\n             &$n=50$, $CV_{S}$,$\\lambda_{opt}$ &0.36 (0.32)  & 0.10 (0.17) &0.68 (0.32)&0.106\\\\\n             &$n=100$, $CV_{S}$,$\\lambda_{opt}$ &0.42 (0.19)  & 0.09 (0.10) &0.54 (0.12)&0.257\\\\\n & & &&&\\\\  \n\\hline   \n    \\end{tabular}\n  \\label{tab:addlabel}\n\\end{table}\n\n\n\n\n", "itemtype": "equation", "pos": 25522, "prevtext": "\n\nNote that in cases in which $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}=0$, we get that $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1}}=0$, and viceversa. However,  $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ and $Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1}}$ differ when not zero. Specifically, from expression (6), we obtain that $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}\\geq Q^{2}_{\\mathbf{X}_{1},\\mathbf{X}_{2}}-Q^{2}_{\\mathbf{X}_{1 }}$. In short, $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$ may be regarded as the conditional contribution of $\\mathbf{X}_{2}$ for the prediction of $\\mathbf{y}$ with respect to what may be predicted using $\\mathbf{X}_{1}$ alone. $Q_{\\mathbf{X}_{1},\\mathbf{X}_{2}}^{2}-Q_{\\mathbf{X_{1}}}^{2}$ measures the absolute gain  in predictive ability from adding $\\mathbf{X_{2}}$  to $\\mathbf{X}_{1}$. Note that, because of the asymmetric nature of the procedure, a given source $\\mathbf{X}_{2}$ may present a large $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}$  but be  of little relevance to improve predictions based on a  previously established $\\mathbf{X}_{1}$ due to the high predictive ability of $\\mathbf{X}_{1}$ itself. \n\n\\subsection{Permutation test for augmented prediction assessment}\nThe summary measures may be used to introduce formal tests for assessing the added or augmented predictive value of   $\\mathbf{X}_{2}$ over $\\mathbf{X}_{1}$ to predict $\\mathbf{y}$. We propose a permutation procedure to test the null hypothesis $H_{0}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2=0$ against the alternative hypothesis $H_{1}:Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2>0$. The test is based on permuting the residuals obtained after applying the first step of our two-stage procedure with the data at hand. Our goal is to remove the potential association between $\\mathbf{X}_2$ and $\\mathbf{y}$ while preserving the original association between $\\mathbf{y}$ and $\\mathbf{X}_1$. \n\n\nExplicitly, we propose the following algorithm:\n\n\\begin{description}\n\\item[Step 1] \nCalculate the residuals $\\mathbf{res}=\\mathbf{y}-\\mathbf{p_{1}}$ based on the predictions $\\mathbf{p_{1}}$ of $\\mathbf{y}$ based on $\\mathbf{X}_{1}$, obtained in the first step of the procedure presented in Section 2.1.\n\\item[Step 2]\nPermute the values of $\\mathbf{res}$, obtaining $\\mathbf{res}^{\\pi}$ and generate values of the response $\\mathbf{y}$ under the null hypothesis: $\\mathbf{y}^{*}=\\mathbf{p_{1}}+\\mathbf{res}^{\\pi}$.\n\\item[Step 3]\nRepeat the two-stage procedure from Section 2.1. for predicting $\\mathbf{y}^{*}$ and obtain the corresponding $Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2*}$.\n\\end{description}\n\nThe procedure is repeated $M$ times and the resulting permutation p-values are obtained as follows:\n\n", "index": 13, "text": "$$\n\\text{p-value}=\\frac{1}{M}\\sum_{i=1}^{M}I(Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2*i}>Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^2),\n$$\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"\\text{p-value}=\\frac{1}{M}\\sum_{i=1}^{M}I(Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2%&#10;*i}&gt;Q_{\\mathbf{X}_{2}|\\mathbf{X}_{1}}^{2}),\" display=\"block\"><mrow><mtext>p-value</mtext><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo largeop=\"true\" movablelimits=\"false\" symmetric=\"true\">\u2211</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mi>I</mi><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mrow><mn>2</mn><mo>*</mo><mi>i</mi></mrow></msubsup><mo>&gt;</mo><msubsup><mi>Q</mi><mrow><msub><mi>\ud835\udc17</mi><mn>2</mn></msub><mo stretchy=\"false\">|</mo><msub><mi>\ud835\udc17</mi><mn>1</mn></msub></mrow><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><mo>,</mo></mrow></math>", "type": "latex"}]