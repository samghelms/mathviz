[{"file": "1601.04231.tex", "nexttext": "\nBasically {task \\hbox{$\\mathcal{D}$}}{} bears its name from the fact that it deals with the system\n\\emph{d\\/}atabase of the backbone, while {task \\hbox{$\\mathcal{I}$}}{} manages ``I'm alive'' signals,\nand {task \\hbox{$\\mathcal{R}$}}{} deals with error \\emph{r\\/}ecovery (see further on).\nWe call ``agent''  any such triplet. At initialisation time, on each node\nthere is exactly one agent, identified\nthrough the label of the node where it runs on.\nFor any $0\\le k<n$, we  call ``$t[k]$''  task  $t$ of\nagent $k$. Agents  play two  roles: coordinator\n(also called manager)  and assistant (also called backup agent or\nsimply ``backup'').  In the initial, correct  state there is\njust one coordinator. The  choice of which node should host the coordinator,\nas well as system configuration and node labeling is  done at compile time\nthrough a configuration script.\n\nFigure~\\ref{fig:5} displays a backbone running on a four node system\n(a Parsytec Xplorer MIMD engine based on PowerPC microprocessors).\nIn this case, node zero hosts the coordinator while nodes 1--3\nexecute as assistants. In the portrayed situation no errors\nhave been detected, and this is rendered with green circles and\na status label equal to``OK''.\n\n\\begin{figure}[t]\n\\hskip-0.7cm\\hbox{\\psfig{figure=demo1.ps,width=9.8cm}}\n\\caption{A Netscape browser offers a global view of the TIRAN backbone:\nnumber, role, and state of each component is displayed.\n``DIR net'' is a nickname for the backbone.\n``OK'' means that no faults have been detected.\nWhen the user selects a component, further information related to that\ncomponent is displayed. The small icon on bottom links to a page with\ninformation related to error recovery.}\n\\label{fig:5}\n\\end{figure}\n\n\n\nEach  agent, be it a coordinator or an assistant, executes a number of\ncommon tasks.  Among  these  tasks  we  have:\n\n\n\\begin{enumerate}\n  \\item Interfacing the instances of the basic tools of the framework---this is to be\n     carried out by {task \\hbox{$\\mathcal{D}$}}.\n  \\item Organizing/maintaining data gathered from the instances---also\n     specific of {task \\hbox{$\\mathcal{D}$}}.\n  \\item Error recovery and reconfiguration management ({task \\hbox{$\\mathcal{R}$}}).\n  \\item Self-check. This takes place through a distributed algorithm that is\n     executed by {task \\hbox{$\\mathcal{D}$}}{} and {task \\hbox{$\\mathcal{I}$}}{} in all agents in the case that $n>1$.\n\\end{enumerate}\n\n\n\nThis article does not cover points 1--3; in particular points 1 and 2\nare dealt with as reported in~\\cite{DDLB99a}, while the issue of\nerror recovery and reconfiguration management is described in~\\cite{DeDL99a}.\nIn the following, we describe the algorithm mentioned at point 4. As the key\npoint of this algorithm is the fact that the coordinator and \nassistants mutually question their state, we call this\nthe algorithm of mutual suspicion (AMS). \n\n\n\n\\Section{The algorithm of mutual suspicion}\nThis Section describes AMS. Simulation and testing show that\nAMS is capable of tolerating crash failures\nof up to $n-1$ agents (some or all of which may by caused by a node crash).\nThis implies fail-stop behaviour, that can be reached in hardware, e.g.,\nby architectures based on duplication and comparison~\\cite{Pra96},\nand coupled with other\ntechniques like, e.g., control flow monitoring~\\cite{Sc87}\nor diversification and comparison~\\cite{Pow97a}.\nIf a coordinator or its node crash, a non-crashed assistant becomes\ncoordinator. Whenever a crashed agent is restarted, possibly after\na node reboot, it is inserted again in the backbone as an assistant.\nLet us first sketch the structure of AMS. Let $m$ be the node where\nthe coordinator first runs on. In short:\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=Manager.eps,width=7.0cm}}\n\\caption{A representation of the algorithm of the manager.}\n\\label{fig:1}\n\\end{figure}\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=Backup.eps,width=7.5cm}}\n\\caption{A representation of the algorithm of the assistant.}\n\\label{fig:2}\n\\end{figure}\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=IAT.eps,width=4.0cm}}\n\\caption{A representation of the conjoint action of {task \\hbox{$\\mathcal{I}$}}{} and {task \\hbox{$\\mathcal{D}$}}{} on\nthe ``I'm alive'' flag.}\n\\label{fig:3}\n\\end{figure}\n\n\n\n\\begin{itemize}\n   \\item The coordinator periodically broadcasts a MIA (manager is alive)\n     message as part of its {task \\hbox{$\\mathcal{D}$}}, the assistants periodically send the\n     coordinator a TAIA (this assistant is alive) message as part of their\n     {task \\hbox{$\\mathcal{D}$}}.\n\n   \\item For each $0\\le k<n$, {task \\hbox{$\\mathcal{D}$}}$[k]$ periodically sets a flag. This\n     flag is periodically cleared by {task \\hbox{$\\mathcal{I}$}}[$k]$.\n\n   \\item If, for any valid $j$, {task \\hbox{$\\mathcal{I}$}}$[j]$ finds that the flag has not been set during\n     the period just elapsed, {task \\hbox{$\\mathcal{I}$}}[$j]$ broadcasts a TEIF (this entity is\n     faulty) message.\n\n   \\item When any agent, say the agent on node $g$, does not receive any timely message from\n     an other agent, say the agent on node $f$, be that a MIA or a TAIA message, then agent $g$\n     enters a so-called suspicion-period by setting flag sus$[f]$. This state\n     leads to three possible next states, corresponding to these events:\n\n\\begin{enumerate}\n  \\item Agent $g$ receives a TEIF from {task \\hbox{$\\mathcal{I}$}}$[f]$ within a specific time period,\n     say $t$ clock ticks.\n  \\item Agent $g$ receives a (late) TAIA from {task \\hbox{$\\mathcal{D}$}}$[f]$ within $t$ clock ticks.\n  \\item No message is received by agent $g$ from neither {task \\hbox{$\\mathcal{I}$}}$[f]$ nor {task \\hbox{$\\mathcal{D}$}}$[f]$\n     within $t$ clock ticks.\n\\end{enumerate}\n\n     State 1  corresponds to deduction ``agent on node $f$  has crashed, \n     though node $f$ is still operational''. State 2 translates into deduction \n     ``both agent on node $f$ and node  $f$ are  operational, though for  \n     some reason agent  $f$ or its communication means have been\n     slowed down''. State 3 is the detection of a crash failure for node $f$.\n     These deductions  lead to actions  aiming at recovering agent  $f$ or (if\n     possible)  the  whole  node $f$,  possibly  electing  a new  coordinator.\n     In the present version of AMS, the election algorithm is simply carried out\n     assuming the next coordinator to be the assistant on node $m+1 \\,{\\hbox{mod}}\\, n$.\n\\end{itemize}\n\n\n\\begin{figure}\n\\psfig{figure=manager.scheme.eps,width=20.4cm,angle=-90}\n\\caption{Pseudo-code of the coordinator.}\n\\label{pseudoc}\n\\end{figure}\n\nAs compliant to the timed asynchronous distributed system model,\nwe assume the presence of an alarm manager task ({task \\hbox{$\\mathcal{A}$}}) on each node of the\nsystem,  spawned at  initialization time  by the  agent. {Task \\hbox{$\\mathcal{A}$}}{} is  used to\ntranslate  time-related clauses, e.g.,  ``$t$  clock ticks have  elapsed'', into\nmessage arrivals. Let  us call {task \\hbox{$\\mathcal{A}$}}$[j]$ the {task \\hbox{$\\mathcal{A}$}}{} running on node $j$,  $0\\le j<n$. {Task \\hbox{$\\mathcal{A}$}}{}\nmay be represented as a function\n\n                                 \n", "itemtype": "equation", "pos": 6615, "prevtext": "\n\\thispagestyle{empty}\n\n\n\\title{An Algorithm for Tolerating Crash Failures in Distributed Systems}\n\n\n\\author{Vincenzo De Florio, Geert Deconinck, and Rudy Lauwereins}\n\n\n\\affiliation{Katholieke Universiteit Leuven, \\\\\nElectrical Engineering Department, ACCA Group, \\\\\nKard. Mercierlaan 94, B-3001 Heverlee, Belgium.}\n\n\\email{$\\{$vincenzo.deflorio$|$lauwerin$\\}$@gmail.com}\n\n\\maketitle\n\n\n\\begin{abstract}\n\\noindent\nIn the framework of the ESPRIT project 28620 ``TIRAN'' (tailorable fault tolerance \nframeworks for embedded applications), a toolset of error detection, isolation,\nand recovery components is being designed to serve as a basic means for orchestrating\napplication-level \nfault tolerance.  These tools will be used either as stand-alone components \nor as the peripheral components of a distributed application, that we\ncall ``the backbone''. The backbone is to run in the background of the \nuser application. Its objectives include (1) gathering and maintaining \nerror detection information produced by TIRAN components like\nwatchdog timers, trap handlers, or by external detection services\nworking at kernel or driver level, and (2) using this information\nat error recovery time. In particular, those TIRAN tools related to error\ndetection and fault masking will forward their deductions to the backbone\nthat, in turn, will make use of this information to orchestrate error recovery,\nrequesting recovery and reconfiguration actions to those tools\nrelated to error isolation and recovery.\nClearly a key point in this approach is guaranteeing that the backbone itself\ntolerates internal and external faults. In this article\nwe describe one of the means that are used within the TIRAN backbone\nto fulfill this goal: a distributed algorithm for tolerating crash failures\ntriggered by faults affecting at most all but one of the components of\nthe backbone or at most all but one of the nodes of the system.\nWe call this the algorithm of mutual suspicion.\n\n\n\n\n\n\\end{abstract}\n\n\n\n\n\n\\Section{Introduction}\nIn the framework of the ESPRIT project 28620 ``TIRAN''~\\cite{BDDC99+},\na toolset of error detection, isolation, and recovery components is being\ndeveloped\nto serve as a basic means for orchestrating application-level software \nfault tolerance. The basic components of this toolset can be considered\nas ready-made software tools that the developer has to embed into \nhis/her application so to enhance its dependability. These tools \ninclude, e.g., watchdog timers, trap handlers, local and distributed\nvoting tools.\n\nThe main difference between TIRAN and other\nlibraries with similar purposes, e.g., ISIS~\\cite{Bir85} or HATS~\\cite{HuKi95},\nis the adoption of a special component, located between the basic\ntoolset and the user application. This entity is\ntransparently replicated on each node\nof the system, to keep track of events originating in the basic layer\n(e.g., a missing heartbeat from a task guarded by a watchdog)\nor in the user application (e.g., the spawning of a new task),\nand to allow the orchestration of system-wide error recovery\nand reconfiguration. We call this component ``the backbone''.\n\nIn order to perform these tasks, the backbone hooks to each \nactive instance of the basic tools and is transparently informed of \nany error detection or fault masking event taking place in the\nsystem. Similarly, it also hooks to a library of basic services.\nThis library includes, among others, functions for remote\ncommunication, for task creation and management, and to access\nthe local hardware clock. These functions are instrumented so\nto transparently forward to the backbone notifications\nof events like the creation or the termination of a thread.\nSpecial low-level services at kernel or at driver-level are also\nhooked to the backbone---for example, on a custom board\nbased on Analog Devices ADSP-21020 DSP and on IEEE 1355-compliant\ncommunication chips~\\cite{ieee1355}, communication\nfaults are transparently notified to the backbone by driver-level tools.\nDoing this, an information stream flows on each node\nfrom different abstract layers to the local component of\nthe backbone. This component maintains and updates\nthis information in the form of a system database, also \nreplicating it on different nodes. \n\nWhenever an error is detected or a fault is masked,\nthose TIRAN tools related to error detection and fault masking\nforward their deductions to the backbone that, in turn,\nmakes use of this information to manage error recovery,\nrequesting recovery and reconfiguration actions to those tools\nrelated to error isolation and recovery (see Fig.~\\ref{Fig:Interactions}).\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=Interactions.eps,height=6.2cm}}\n\\caption{Each processing node of the system hosts one agent of the\n  backbone. This component is the intermediary of the backbone on that\n  node. In particular, it gathers information from the TIRAN tools\n  for error detection and fault containment (grey circles) and forwards\n  requests to those tools managing error containment and recovery (light\n  grey circles). These latter execute recovery actions and possibly, at\n  test time, fault injection requests.}\n\\label{Fig:Interactions}\n\\end{figure}\n\nThe specification of which actions to take is to be supplied \nby the user in the form of a ``recovery script'', \na sort of ancillary application context devoted to error recovery concerns,\nconsisting of a number of guarded commands: the execution of blocks of\nbasic recovery actions, e.g., restarting a group of tasks, rebooting a node\nand so forth, is then subject to the evaluation of boolean clauses based on\nthe current contents of the system database---for further\ninformation on this subject see~\\cite{DeDL99a,GTDR99}.\n\n\nClearly a key point in this scheme is guaranteeing that the backbone\nitself tolerates internal as well external faults. In this article\nwe describe one of the means that have been designed within the TIRAN backbone\nto fulfill this goal: a distributed algorithm for tolerating crash failures\ntriggered by faults affecting at most all but one of the components of\nthe backbone. We call this the algorithm of mutual suspicion.\nAs in~\\cite{Cri95b}, we assume a timed asynchronous distributed\nsystem model~\\cite{CrFe99}.\nFurthermore, we assume the availability of asynchronous communication\nmeans. No atomic broadcast primitive is required.\n\n\n\n\\Section{Basic assumptions}\nThe target system is a distributed system consisting of $n$ nodes ($n\\ge1$).\nNodes are assumed to be labeled\nwith a unique number in  $\\{0,\\dots,n-1\\}$. The backbone is a  distributed\napplication consisting of $n$ triplets of tasks:\n\t \n", "index": 1, "text": "\\[ (\\hbox{{task \\hbox{$\\mathcal{D}$}}}, \\hbox{{task \\hbox{$\\mathcal{I}$}}}, \\hbox{{task \\hbox{$\\mathcal{R}$}}}). \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex1.m1\" class=\"ltx_Math\" alttext=\"(\\hbox{{task \\hbox{$\\mathcal{D}$}}},\\hbox{{task \\hbox{$\\mathcal{I}$}}},\\hbox{{%&#10;task \\hbox{$\\mathcal{R}$}}}).\" display=\"block\"><mrow><mrow><mo stretchy=\"false\">(</mo><mrow><mtext>task\u00a0</mtext><mi class=\"ltx_font_mathcaligraphic\">\ud835\udc9f</mi></mrow><mo>,</mo><mrow><mtext>task\u00a0</mtext><mi class=\"ltx_font_mathcaligraphic\">\u2110</mi></mrow><mo>,</mo><mrow><mtext>task\u00a0</mtext><mi class=\"ltx_font_mathcaligraphic\">\u211b</mi></mrow><mo stretchy=\"false\">)</mo></mrow><mo>.</mo></mrow></math>", "type": "latex"}, {"file": "1601.04231.tex", "nexttext": "\n\\noindent\nsuch that, for any  time-related clause $c\\in C$,\n", "itemtype": "equation", "pos": 13847, "prevtext": "\nBasically {task \\hbox{$\\mathcal{D}$}}{} bears its name from the fact that it deals with the system\n\\emph{d\\/}atabase of the backbone, while {task \\hbox{$\\mathcal{I}$}}{} manages ``I'm alive'' signals,\nand {task \\hbox{$\\mathcal{R}$}}{} deals with error \\emph{r\\/}ecovery (see further on).\nWe call ``agent''  any such triplet. At initialisation time, on each node\nthere is exactly one agent, identified\nthrough the label of the node where it runs on.\nFor any $0\\le k<n$, we  call ``$t[k]$''  task  $t$ of\nagent $k$. Agents  play two  roles: coordinator\n(also called manager)  and assistant (also called backup agent or\nsimply ``backup'').  In the initial, correct  state there is\njust one coordinator. The  choice of which node should host the coordinator,\nas well as system configuration and node labeling is  done at compile time\nthrough a configuration script.\n\nFigure~\\ref{fig:5} displays a backbone running on a four node system\n(a Parsytec Xplorer MIMD engine based on PowerPC microprocessors).\nIn this case, node zero hosts the coordinator while nodes 1--3\nexecute as assistants. In the portrayed situation no errors\nhave been detected, and this is rendered with green circles and\na status label equal to``OK''.\n\n\\begin{figure}[t]\n\\hskip-0.7cm\\hbox{\\psfig{figure=demo1.ps,width=9.8cm}}\n\\caption{A Netscape browser offers a global view of the TIRAN backbone:\nnumber, role, and state of each component is displayed.\n``DIR net'' is a nickname for the backbone.\n``OK'' means that no faults have been detected.\nWhen the user selects a component, further information related to that\ncomponent is displayed. The small icon on bottom links to a page with\ninformation related to error recovery.}\n\\label{fig:5}\n\\end{figure}\n\n\n\nEach  agent, be it a coordinator or an assistant, executes a number of\ncommon tasks.  Among  these  tasks  we  have:\n\n\n\\begin{enumerate}\n  \\item Interfacing the instances of the basic tools of the framework---this is to be\n     carried out by {task \\hbox{$\\mathcal{D}$}}.\n  \\item Organizing/maintaining data gathered from the instances---also\n     specific of {task \\hbox{$\\mathcal{D}$}}.\n  \\item Error recovery and reconfiguration management ({task \\hbox{$\\mathcal{R}$}}).\n  \\item Self-check. This takes place through a distributed algorithm that is\n     executed by {task \\hbox{$\\mathcal{D}$}}{} and {task \\hbox{$\\mathcal{I}$}}{} in all agents in the case that $n>1$.\n\\end{enumerate}\n\n\n\nThis article does not cover points 1--3; in particular points 1 and 2\nare dealt with as reported in~\\cite{DDLB99a}, while the issue of\nerror recovery and reconfiguration management is described in~\\cite{DeDL99a}.\nIn the following, we describe the algorithm mentioned at point 4. As the key\npoint of this algorithm is the fact that the coordinator and \nassistants mutually question their state, we call this\nthe algorithm of mutual suspicion (AMS). \n\n\n\n\\Section{The algorithm of mutual suspicion}\nThis Section describes AMS. Simulation and testing show that\nAMS is capable of tolerating crash failures\nof up to $n-1$ agents (some or all of which may by caused by a node crash).\nThis implies fail-stop behaviour, that can be reached in hardware, e.g.,\nby architectures based on duplication and comparison~\\cite{Pra96},\nand coupled with other\ntechniques like, e.g., control flow monitoring~\\cite{Sc87}\nor diversification and comparison~\\cite{Pow97a}.\nIf a coordinator or its node crash, a non-crashed assistant becomes\ncoordinator. Whenever a crashed agent is restarted, possibly after\na node reboot, it is inserted again in the backbone as an assistant.\nLet us first sketch the structure of AMS. Let $m$ be the node where\nthe coordinator first runs on. In short:\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=Manager.eps,width=7.0cm}}\n\\caption{A representation of the algorithm of the manager.}\n\\label{fig:1}\n\\end{figure}\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=Backup.eps,width=7.5cm}}\n\\caption{A representation of the algorithm of the assistant.}\n\\label{fig:2}\n\\end{figure}\n\n\\begin{figure}[t]\n\\centerline{\\psfig{figure=IAT.eps,width=4.0cm}}\n\\caption{A representation of the conjoint action of {task \\hbox{$\\mathcal{I}$}}{} and {task \\hbox{$\\mathcal{D}$}}{} on\nthe ``I'm alive'' flag.}\n\\label{fig:3}\n\\end{figure}\n\n\n\n\\begin{itemize}\n   \\item The coordinator periodically broadcasts a MIA (manager is alive)\n     message as part of its {task \\hbox{$\\mathcal{D}$}}, the assistants periodically send the\n     coordinator a TAIA (this assistant is alive) message as part of their\n     {task \\hbox{$\\mathcal{D}$}}.\n\n   \\item For each $0\\le k<n$, {task \\hbox{$\\mathcal{D}$}}$[k]$ periodically sets a flag. This\n     flag is periodically cleared by {task \\hbox{$\\mathcal{I}$}}[$k]$.\n\n   \\item If, for any valid $j$, {task \\hbox{$\\mathcal{I}$}}$[j]$ finds that the flag has not been set during\n     the period just elapsed, {task \\hbox{$\\mathcal{I}$}}[$j]$ broadcasts a TEIF (this entity is\n     faulty) message.\n\n   \\item When any agent, say the agent on node $g$, does not receive any timely message from\n     an other agent, say the agent on node $f$, be that a MIA or a TAIA message, then agent $g$\n     enters a so-called suspicion-period by setting flag sus$[f]$. This state\n     leads to three possible next states, corresponding to these events:\n\n\\begin{enumerate}\n  \\item Agent $g$ receives a TEIF from {task \\hbox{$\\mathcal{I}$}}$[f]$ within a specific time period,\n     say $t$ clock ticks.\n  \\item Agent $g$ receives a (late) TAIA from {task \\hbox{$\\mathcal{D}$}}$[f]$ within $t$ clock ticks.\n  \\item No message is received by agent $g$ from neither {task \\hbox{$\\mathcal{I}$}}$[f]$ nor {task \\hbox{$\\mathcal{D}$}}$[f]$\n     within $t$ clock ticks.\n\\end{enumerate}\n\n     State 1  corresponds to deduction ``agent on node $f$  has crashed, \n     though node $f$ is still operational''. State 2 translates into deduction \n     ``both agent on node $f$ and node  $f$ are  operational, though for  \n     some reason agent  $f$ or its communication means have been\n     slowed down''. State 3 is the detection of a crash failure for node $f$.\n     These deductions  lead to actions  aiming at recovering agent  $f$ or (if\n     possible)  the  whole  node $f$,  possibly  electing  a new  coordinator.\n     In the present version of AMS, the election algorithm is simply carried out\n     assuming the next coordinator to be the assistant on node $m+1 \\,{\\hbox{mod}}\\, n$.\n\\end{itemize}\n\n\n\\begin{figure}\n\\psfig{figure=manager.scheme.eps,width=20.4cm,angle=-90}\n\\caption{Pseudo-code of the coordinator.}\n\\label{pseudoc}\n\\end{figure}\n\nAs compliant to the timed asynchronous distributed system model,\nwe assume the presence of an alarm manager task ({task \\hbox{$\\mathcal{A}$}}) on each node of the\nsystem,  spawned at  initialization time  by the  agent. {Task \\hbox{$\\mathcal{A}$}}{} is  used to\ntranslate  time-related clauses, e.g.,  ``$t$  clock ticks have  elapsed'', into\nmessage arrivals. Let  us call {task \\hbox{$\\mathcal{A}$}}$[j]$ the {task \\hbox{$\\mathcal{A}$}}{} running on node $j$,  $0\\le j<n$. {Task \\hbox{$\\mathcal{A}$}}{}\nmay be represented as a function\n\n                                 \n", "index": 3, "text": "\\[ a: C \\to M \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex2.m1\" class=\"ltx_Math\" alttext=\"a:C\\to M\" display=\"block\"><mrow><mi>a</mi><mo>:</mo><mrow><mi>C</mi><mo>\u2192</mo><mi>M</mi></mrow></mrow></math>", "type": "latex"}, {"file": "1601.04231.tex", "nexttext": "\n\n{Task \\hbox{$\\mathcal{A}$}}$[j]$ monitors a set of time-related\nclauses and, each time  one of them occurs, say clause $c$, it sends {task \\hbox{$\\mathcal{D}$}}$[j]$\nmessage $a(c)$. Messages are sent via asynchronous primitives based on mailboxes.\n\n\n\nIn  particular, the  coordinator, which  we assume  to run\ninitially on node  $m$, instructs its {task \\hbox{$\\mathcal{A}$}}{} so  that the following clauses be\nmanaged:\n\n   \\begin{itemize}\n   \\item (MIA\\_SEND, $j$, MIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT), $j$ different from $m$: every\n     MIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT clock ticks, a message of type (MIA\\_SEND, $j$) should be\n     sent to {task \\hbox{$\\mathcal{D}$}}$[m]$, i.e., {task \\hbox{$\\mathcal{D}$}}{} on the current node. This latter will\n     respond to such event by sending each {task \\hbox{$\\mathcal{D}$}}$[j]$ a MIA (manager is\n     alive) message.\n\n   \\item (TAIA\\_RECV, $j$, TAIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT) for each $j$ different from $m$: every\n     TAIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT clock ticks at most, a message of type TAIA is to be\n     received from {task \\hbox{$\\mathcal{D}$}}$[j]$. The arrival of such a message or of any other\n     ``sign of life'' from {task \\hbox{$\\mathcal{D}$}}$[j]$ translates also in renewing the\n     corresponding alarm. On the other hand, the arrival of a message of\n     type (TAIA\\_RECV, $k$), $k$ different\n     from $m$, sent by {task \\hbox{$\\mathcal{A}$}}$[m]$, warns {task \\hbox{$\\mathcal{D}$}}$[m]$\n     that assistant on node $k$ sent no sign of life throughout\n     the TAIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT-clock-tick period just elapsed. This makes \n     {task \\hbox{$\\mathcal{D}$}}$[m]$ set its flag sus$[k]$.\n\n   \\item (I'M\\_ALIVE\\_SET, $m$, I'M\\_ALIVE\\_SET{\\hskip-1pt\\_}{}TIMEOUT): every I'M\\_ALIVE\\_SET{\\hskip-1pt\\_}{}TIMEOUT\n     clock ticks, {task \\hbox{$\\mathcal{A}$}}$[m]$ sends {task \\hbox{$\\mathcal{D}$}}$[m]$ an I'M\\_ALIVE\\_SET message. As a\n     response to this, {task \\hbox{$\\mathcal{D}$}}$[m]$ sets the ``I'm alive'' flag, a memory variable\n     that is shared between tasks of type $\\mathcal D$ and $\\mathcal I$.\n   \\end{itemize}\n\n\n\nFurthermore, whenever  flag sus$[k]$ is set,  for any $k$ different  from $m$, the\nfollowing clause is sent to {task \\hbox{$\\mathcal{A}$}}{} for being managed:\n\n\\begin{itemize}\n   \\item (TEIF{\\hskip-1pt\\_}{}RECV, $k$, TEIF{\\hskip-1pt\\_}{}RECV{\\hskip-1pt\\_}{}TIMEOUT): this clause simply \n     asks {task \\hbox{$\\mathcal{A}$}}$[m]$ to\n     schedule the sending of message (TEIF{\\hskip-1pt\\_}{}RECV, $k$) to {task \\hbox{$\\mathcal{D}$}}$[m]$ after\n     TEIF{\\hskip-1pt\\_}{}RECV{\\hskip-1pt\\_}{}TIMEOUT clock ticks. This action is canceled should a\n     late TAIA message arrive to {task \\hbox{$\\mathcal{D}$}}$[m]$ from task $k$, or should a TEIF\n     message from {task \\hbox{$\\mathcal{I}$}}$[k]$ arrive instead. In the first case, sus$[k]$ is\n     cleared and (possibly empty) actions corresponding to a slowed down\n     {task \\hbox{$\\mathcal{D}$}}$[k]$ are taken. In the latter case, {task \\hbox{$\\mathcal{D}$}}$[k]$ is assumed to have\n     crashed, its clauses are removed from the list of those managed by \n     {task \\hbox{$\\mathcal{A}$}}$[m]$, and flag sus$[k]$ is cleared. It is assumed that {task \\hbox{$\\mathcal{I}$}}$[k]$ will\n     take care in this case of reviving {task \\hbox{$\\mathcal{D}$}}$[k]$. Any future sign of life\n     from {task \\hbox{$\\mathcal{D}$}}$[k]$ is assumed to mean that {task \\hbox{$\\mathcal{D}$}}$[k]$ is back in operation.\n     In such a case {task \\hbox{$\\mathcal{D}$}}$[k]$ would then be re-entered in the list of\n     operational assistants, and {task \\hbox{$\\mathcal{D}$}}$[m]$ would then request {task \\hbox{$\\mathcal{A}$}}$[m]$ to include again an\n     alarm of type (MIA\\_SEND, $k$, MIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT) and an alarm of type\n     (TAIA\\_RECV, $k$, TAIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT) in its list. If a (TEIF{\\hskip-1pt\\_}{}RECV, $k$)\n     message reaches {task \\hbox{$\\mathcal{D}$}}$[m]$, the entire node $k$ is assumed to have\n     crashed. Node recovery may start at this point, if available, or\n     a warning message should be sent to an external operator so that, e.g.,\n     node $k$ be rebooted.\n\\end{itemize}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarly any  assistant, say the one on node $k$,  instructs its {task \\hbox{$\\mathcal{A}$}}{} so\nthat the following clauses be managed:\n\n\\begin{itemize}\n\\item (TAIA\\_SEND, $m$, TAIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT): every TAIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT clock ticks,\n     a message of type (TAIA\\_SEND, $m$) is to be sent to {task \\hbox{$\\mathcal{D}$}}$[k]$, i.e.,\n     {task \\hbox{$\\mathcal{D}$}}{} on the current node. This latter will respond to such event by\n     sending {task \\hbox{$\\mathcal{D}$}}$[m]$ (i.e., the manager) a TAIA (this agent is alive)\n     message. Should a data message be sent to the manager in the middle of\n     TAIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT-clock-tick period, alarm (TAIA\\_SEND, $m$,\n     TAIA\\_SEND{\\hskip-1pt\\_}{}TIMEOUT) is renewed. This may happen for instance because one\n     of the basic TIRAN tools for error detection\n     reports an event to {task \\hbox{$\\mathcal{D}$}}$[k]$. Such event must be sent\n     to the manager for it to update its database. In this case we say that\n     the TAIA message is sent in piggybacking with the event notification\n     message.\n\n\\begin{figure}\n\\psfig{figure=backup.scheme.eps,width=20.4cm,angle=-90}\n\\caption{Pseudo-code of the assistant.}\n\\label{pseudoa}\n\\end{figure}\n\n\\item (\\hbox{MIA\\_\\hskip1pt RECV}, $m$, MIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT): every MIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT clock ticks at\n     most, a message of type MIA is to be received from {task \\hbox{$\\mathcal{D}$}}$[m]$, i.e., the\n     manager. The arrival of such a message or of any other ``sign of life''\n     from the manager translates also in renewing the corresponding alarm.\n     If a message of type (MIA\\_RECV, $m$), is received from {task \\hbox{$\\mathcal{D}$}}$[k]$ and sent\n     by {task \\hbox{$\\mathcal{A}$}}$[k]$, this means that no sign of life has been received from\n     the manager throughout the MIA\\_RECV{\\hskip-1pt\\_}{}TIMEOUT-clock-tick period just\n     elapsed. This makes {task \\hbox{$\\mathcal{D}$}}$[k]$ set flag sus$[m]$.\n\n\\item (I'M\\_ALIVE\\_SET, $k$, I'M\\_ALIVE\\_SET{\\hskip-1pt\\_}{}TIMEOUT): every I'M\\_ALIVE\\_SET{\\hskip-1pt\\_}{}TIMEOUT\n     clock ticks, {task \\hbox{$\\mathcal{A}$}}$[k]$ sends {task \\hbox{$\\mathcal{D}$}}$[k]$ an I'M\\_ALIVE\\_SET message. As a\n     response to this, {task \\hbox{$\\mathcal{D}$}}$[k]$ sets the ``I'm alive'' flag.\n   \\end{itemize}\n\n\n\nFurthermore, whenever  flag sus$[m]$ is  set, the following clause  is sent to\n{task \\hbox{$\\mathcal{A}$}}$[k]$ for being managed:\n\n\\begin{itemize}\n\\item (TEIF{\\hskip-1pt\\_}{}RECV, $m$, TEIF{\\hskip-1pt\\_}{}RECV{\\hskip-1pt\\_}{}TIMEOUT): this clause simply asks {task \\hbox{$\\mathcal{A}$}}$[k]$ to\n     postpone sending message (TEIF{\\hskip-1pt\\_}{}RECV, $k$) to {task \\hbox{$\\mathcal{D}$}}$[k]$ of\n     TEIF{\\hskip-1pt\\_}{}RECV{\\hskip-1pt\\_}{}TIMEOUT clock ticks. This action is canceled should a\n     late MIA message arrive to {task \\hbox{$\\mathcal{D}$}}$[k]$ from the manager, or should a TEIF\n     message from {task \\hbox{$\\mathcal{I}$}}$[m]$ arrive instead. In the first case, sus$[m]$ is\n     cleared and possibly empty actions corresponding to a slowed down\n     manager are taken. In the latter case, {task \\hbox{$\\mathcal{D}$}}$[m]$ is assumed to have\n     crashed, its clause is removed from the list of those managed by \n     {task \\hbox{$\\mathcal{A}$}}$[k]$, and flag sus$[m]$ is cleared. It is assumed that {task \\hbox{$\\mathcal{I}$}}$[m]$ will\n     take care in this case of reviving {task \\hbox{$\\mathcal{D}$}}$[m]$. Any future sign of life\n     from {task \\hbox{$\\mathcal{D}$}}$[m]$ is assumed to mean that {task \\hbox{$\\mathcal{D}$}}$[m]$ is back in operation.\n     In such a case {task \\hbox{$\\mathcal{D}$}}$[m]$ would be demoted to the role of assistant\n     and entered in the list of operational assistants. The role of coordinator\n     would then have been assigned, via an election, to an agent formerly running as assistant.\n   \\end{itemize}\n\n     If a  (TEIF{\\hskip-1pt\\_}{}RECV, $m$) message reaches {task \\hbox{$\\mathcal{D}$}}$[k]$,  the entire node of the\n     manager is  assumed to  have crashed. Node  recovery may start  at this\n     point.   An election takes place---the next assistant (modulo $n$) is\n     elected   as  new   manager.\n\n\n\nAlso  {task \\hbox{$\\mathcal{I}$}}{}  on each node,  say node $k$,  instructs its  {task \\hbox{$\\mathcal{A}$}}{} so  that the\nfollowing clause be managed:\n\n\\begin{itemize}\n\\item (I'M\\_ALIVE{\\hskip-1pt\\_}{}CLEAR, $k$, I'M\\_ALIVE{\\hskip-1pt\\_}{}CLEAR{\\hskip-1pt\\_}{}TIMEOUT): every\n     I'M\\_ALIVE{\\hskip-1pt\\_}{}CLEAR{\\hskip-1pt\\_}{}TIMEOUT clock ticks {task \\hbox{$\\mathcal{A}$}}$[k]$ sends {task \\hbox{$\\mathcal{I}$}}$[k]$ an\n     I'M\\_ALIVE{\\hskip-1pt\\_}{}CLEAR message. As a response to this, {task \\hbox{$\\mathcal{I}$}}$[k]$ clears the\n     ``I'm alive'' flag.\n\\end{itemize}\n\nFigures~\\ref{fig:1}, \\ref{fig:2}, and~\\ref{fig:3} supply a\npictorial representation of this algorithm. Figure~\\ref{pseudoc}\nand Fig.~\\ref{pseudoa} respectively\nshow a pseudo-code of the coordinator and of the assistant.\n\n\\SubSection{The alarm manager class}\nThis section briefly describes  {task \\hbox{$\\mathcal{A}$}}. This task makes use of a special\nclass  to  manage  lists of alarms~\\cite{DeDL98h}.  The  class  allows the client  to\n``register'' alarms, specifying alarm-ids and deadlines.\n\nOnce the  first alarm is entered,  the task managing alarms  creates a\nlinked-list of alarms and polls the top of the list. For each new alarm\nto be  inserted, an entry in the list is found  and the list is modified\naccordingly.  If the  top entry  expires, a user-defined alarm function is invoked.\nThis is a general mechanism that allows to associate any event with the\nexpiring of an alarm. In the case of the backbone, {task \\hbox{$\\mathcal{A}$}}{} on node $k$\nsends a message to {task \\hbox{$\\mathcal{D}$}}$[k]$---the same result may also be achieved by sending\nan UNIX signal to {task \\hbox{$\\mathcal{D}$}}$[k]$.\nSpecial alarms are defined as ``cyclic'', i.e., they are automatically\nrenewed at  each new  expiration, after invoking the alarm function.\nA special  function restarts  an alarm,\ni.e.,  it deletes  and re-enters an  entry. It  is also  possible to\ntemporarily  suspend  an  alarm  and  re-enable it  afterwards.\n\n\n\n\n\n\\Section{Current status and future directions}\nA prototypal implementation of the TIRAN backbone is running on a Parsytec\nXplorer, a MIMD engine, using 4 PowerPC nodes. The system has been\ntested and proved to be able to tolerate a number of software-injected faults,\ne.g., component and node crashes (see Fig.~\\ref{Fig:AMS} and\nFig.~\\ref{fig:rec}).\nFaults are scheduled as another class of alarms that, when triggered,\nsend a fault injection message to the local {task \\hbox{$\\mathcal{D}$}}{} or {task \\hbox{$\\mathcal{I}$}}{}.\nThe specification of which fault to inject is read by the\nbackbone at initialisation time from a file called ``.faultrc''.\nThe user can specify fault injections by editing this file, e.g.,\nas follows:\n\\begin{quote}\nINJECT CRASH ON COMPONENT 1\\\\\n\\hspace*{33pt}      AFTER 5000000 TICKS\\\\\nINJECT CRASH ON NODE 0\\\\\n\\hspace*{33pt}      AFTER 10000000 TICKS.\n\\end{quote}\nThe first two lines inject a crash on {task \\hbox{$\\mathcal{D}$}}{}[1] after 5 seconds\nfrom the initialisation of the backbone, the second ones\ninject a system reboot of node 0 after 10 seconds.\nVia fault injection it is\nalso possible to slow down artificially a component for a given\nperiod. Slowed down components are temporarily and automatically\ndisconnected and then accepted again in the application when\ntheir performance goes back to normal values.\n\n\nScenarios are represented\ninto a Netscape window where a monitoring application displays\nthe structure of the user application, maps the backbone roles onto the\nprocessing nodes of the system, and constantly reports about the events\ntaking place in the system~\\cite{DeDe98}.\n\nThis system has been recently redeveloped so to enhance its portability\nand performance and to improve its resilience.\n\n\n\nThe backbone is currently being implemented\nfor target platforms based on Windows CE, VxWorks, and TEX~\\cite{Anon97b}.\nA GSPN model of the algorithm of mutual suspicion has been developed\nby the University of Turin, Italy, and has been used to validate\nand evaluate the system. Simulations of this model proved\nthe absence of deadlocks and livelocks.\nMeasurements of the overheads in fault free scenarios and when faults occur\nwill also be collected and analysed. \n\n\\begin{figure*}[t]\n\\hskip-1.0cm\\vbox{\\hbox{\\psfig{figure=demo4-slide1coloured.ps,width=9.7cm}\n\\psfig{figure=demo4-slide2coloured.ps,width=9.7cm}}\n\\hbox{\\psfig{figure=demo4-slide3coloured.ps,width=9.7cm}\n\\psfig{figure=demo4-slide4coloured.ps,width=9.7cm}}}\n\\caption{A fault is injected on node 0 of a system of four nodes.\nNode 0 hosts the manager of the backbone. In the top left picture the user\nselects the fault to be injected and connects to a remotely controllable\nNetscape browser. The top right picture shows this latter as it renders\nthe shape and state of the system. The textual window reports the\ncurrent contents of the list of alarms used by {task \\hbox{$\\mathcal{A}$}}[0].\nIn the bottom left picture the crash of node 0 has been\ndetected and a new manager has been elected. On election, the manager\nexpects node 0 to be back in operation after a recovery step. This \nrecovery step is not performed in this case. As a consequence,\nnode 0 is detected as inactive and labeled as ``KILLED''.}\n\\label{Fig:AMS}\n\\end{figure*}\n\n\\begin{figure*}[t]\n\\centerline{\\psfig{figure=demo4-slide5coloured.ps,width=12.135cm}}\n\\caption{When the user selects a circular icon in the \nWeb page of Fig.~\\ref{fig:5}, the browser\nreplies with a listing of all the events that took place on\nthe corresponding node.\nHere, a list of events occurred on {task \\hbox{$\\mathcal{D}$}}[1] during the\nexperiment shown in Fig.~\\ref{Fig:AMS} is displayed. Events are\nlabeled with an event-id and with the time of occurrence\n(in seconds). Note in particular event 15, corresponding\nto deduction ``a node has crashed'', and\nevents 16--18, in which the election of the manager takes place\nand {task \\hbox{$\\mathcal{D}$}}[1] takes over the role of the former manager, {task \\hbox{$\\mathcal{D}$}}[0].\nRestarting as manager, {task \\hbox{$\\mathcal{D}$}}[1] resets the local clock.}\n\\label{fig:rec}\n\\end{figure*}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\paragraph{Acknowledgments.}\nThis project is partly supported by an \nFWO Krediet aan Navorsers and by the ESPRIT-IV\nproject 28620 ``TIRAN''.\n\n\n\n\n\\bibliographystyle{latex8}\n\\begin{thebibliography}{12}\n\n\\bibitem{ieee1355}\nAnonymous.\n\\newblock {IEEE} standard for {H}eterogeneous {I}nter{C}onnect ({HIC})\n  ({L}ow-cost, low-latency scalable serial interconnect for parallel system\n  construction).\n\\newblock Technical Report 1355-1995 (ISO/IEC 14575), IEEE, 1995.\n\n\\bibitem{Anon97b}\nAnonymous.\n\\newblock {\\em TEX User Manual}.\n\\newblock TXT In\\-ge\\-gne\\-ria In\\-for\\-ma\\-ti\\-ca, Mi\\-la\\-no, Italy, 1997.\n\n\\bibitem{Bir85}\nK.~P. Birman.\n\\newblock Replication and fault tolerance in the {I}sis system.\n\\newblock {\\em ACM Operating Systems Review}, 19(5):79--86, 1985.\n\n\\bibitem{BDDC99+}\nOliver Botti, Vincenzo De~Florio, Geert Deconinck, Susanna Donatelli, Andrea\n  Bobbio, Axel Klein, H.~Kufner, Rudy Lauwereins, E.~Thurner, and E.~Verhulst.\n\\newblock {TIRAN}: Flexible and portable fault tolerance solutions for cost\n  effective dependable applications.\n\\newblock In P.~Amestoy et~al., editors, {\\em Proc. of the 5th Int. Euro-Par\n  Conference (EuroPar'99), Lecture Notes in Computer Science}, volume 1685,\n  pages 1166--1170, Toulouse, France, August/September 1999. Springer-Verlag,\n  Berlin.\n\n\\bibitem{CrFe99}\nFlaviu Cristian and Christof Fetzer.\n\\newblock The timed asynchronous distributed system model.\n\\newblock {\\em IEEE Trans. on Parallel and Distributed Systems},\n  10(6):642--657, June 1999.\n\n\\bibitem{Cri95b}\nFlaviu Cristian and Frank Schmuck.\n\\newblock Agreeing on processor group membership in asynchronous distributed\n  systems.\n\\newblock Technical Report CSE95-428, UCSD, 1995.\n\n\\bibitem{DeDe98}\nVincenzo De~Florio, Geert Deconinck, Mario Truyens, Wim Rosseel and Rudy Lauwereins.\n\\newblock A hypermedia distributed application for monitoring and\nfault-injection in embedded fault-tolerant parallel programs.\n\\newblock In {\\em Proc. of the 6th Euromicro Workshop on Parallel and\nDistributed Processing (PDP'98)},\npages 349--355,\nMadrid, Spain,\nJanuary 1998.\nIEEE Comp. Soc. Press.\n\n\\bibitem{DeDL98h}\nVincenzo De~Florio, Geert Deconinck, and Rudy Lauwereins.\n\\newblock A time-out management system for real-time distributed applications.\n\\newblock Submitted for publication in \n\\newblock {\\em IEEE Trans. on Computers}.\n\n\\bibitem{DeDL99a}\nVincenzo De~Florio, Geert Deconinck, and Rudy Lauwereins.\n\\newblock The recovery language approach for software-implemented fault\n  tolerance.\n\\newblock Submitted for publication in \n\\newblock {\\em ACM Transactions on Computer Systems}.\n\n\\bibitem{DDLB99a}\nGeert Deconinck, Vincenzo De~Florio, Rudy Lauwereins, and Ronnie Belmans.\n\\newblock A software library, a control backbone and user-specified recovery\n  strategies to enhance the dependability of embedded systems.\n\\newblock In {\\em Proc. of the 25th Euromicro Conference (Euromicro '99),\n  Workshop on Dependable Computing Systems}, volume~2, pages 98--104, Milan,\n  Italy, September 1999. IEEE Comp. Soc. Press.\n\n\\bibitem{GTDR99}\nGeert Deconinck, Mario Truyens, Vincenzo De~Florio, Wim Rosseel, Rudy\n  Lauwereins, and Ronnie Belmans.\n\\newblock A framework backbone for software fault tolerance in embedded\n  parallel applications.\n\\newblock In {\\em Proc. of the 7th Euromicro Workshop on Parallel and\n  Distributed Processing (PDP'99)}, pages 189--195, Funchal, Portugal, February\n  1999. IEEE Comp. Soc. Press.\n\n\\bibitem{HuKi95}\nYennun Huang and Chandra~M.R. Kintala.\n\\newblock Software fault tolerance in the application layer.\n\\newblock In Michael Lyu, editor, {\\em Software Fault Tolerance}, chapter~10,\n  pages 231--248. John Wiley \\& Sons, New York, 1995.\n\n\\bibitem{Pow97a}\nD.~Powell.\n\\newblock Preliminary definition of the {GUARDS} architecture.\n\\newblock Technical Report 96277, LAAS-CNRS, January 1997.\n\n\\bibitem{Pra96}\nD.~K. Pradhan.\n\\newblock {\\em Fault-Tolerant Computer Systems Design}.\n\\newblock Prentice-Hall, Upper Saddle River, NJ, 1996.\n\n\\bibitem{Sc87}\nM. Schuette and J. P. Shen.\n\\newblock Processor control flow monitoring using\n\t  signatured instruction streams.\n\\newblock {\\em IEEE Trans. on Computers},\n  36(3):264--276, March 1987.\n\\end{thebibliography}\n\n", "itemtype": "equation", "pos": 13923, "prevtext": "\n\\noindent\nsuch that, for any  time-related clause $c\\in C$,\n", "index": 5, "text": "\n\\[ a(c) = \\hbox{message ``clause $c$ has elapsed'' } \\in M. \\]\n", "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" id=\"S0.Ex3.m1\" class=\"ltx_Math\" alttext=\"a(c)=\\hbox{message ``clause $c$ has elapsed'' }\\in M.\" display=\"block\"><mrow><mrow><mrow><mi>a</mi><mo>\u2062</mo><mrow><mo stretchy=\"false\">(</mo><mi>c</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mtext>message \u201cclause\u00a0</mtext><mi>c</mi><mtext>\u00a0has elapsed\u201d\u00a0</mtext></mrow><mo>\u2208</mo><mi>M</mi></mrow><mo>.</mo></mrow></math>", "type": "latex"}]